{"version":3,"file":"index.js","mappings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v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vCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3oBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;;;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAKA;;;;;;;;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC57FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5wNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACj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jEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC9pEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7zDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/VA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1jBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACx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zDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5VA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpkCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC90BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjoBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnYA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrWA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3tBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3iBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5mBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACnFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC78BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvHA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC56LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACpGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5ZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AASA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACt2BA;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/bA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5qBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACnFA;;;;;;;;ACAA;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACVA;AACA;AACA;AACA;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5CA;AACA;;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxcA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzwCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjhBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AClPA;AACA;AACA;AACA;;;;;;;;ACHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/6BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/pCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChUA;AACA;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClcA;;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1PA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3GA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACh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rHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1YA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC9sBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACz1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvuBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7mBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrRA;AACA;AACA;AACA;AACA;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC9MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC9WA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC11BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvJA;AACA;AACA;AACA;AACA;;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC7YA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/dA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AChhBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvu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zdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC3PA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC9qBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/tEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5gCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjmBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/lDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACtrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACv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tYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AClXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACjEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACxUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC/FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3kBA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;AC1LA;AACA;AACA;AAEA;;;AAGA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;;AAxCA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACRA;AACA;AAOA;AACA;AACA;AACA;AAEA;AAEA;;;AAGA;AACA;AAEA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AA7BA;AA+BA;;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;;AAEA;AACA;AAMA;AAEA;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AA9CA;AAgDA;;AAEA;AACA;AAKA;AAEA;AACA;AACA;AACA;AAKA;AAfA;AAiBA;;AAEA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAjBA;AAmBA;;AAEA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AAEA;AACA;AAAA;AACA;AACA;AACA;AAhCA;AAkCA;;AAEA;AACA;AAKA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAnCA;AAqCA;;AAEA;AACA;AAYA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAMA;AACA;AACA;AA9DA;AAgEA;;AAEA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AAEA;AACA;AAEA;AAEA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAMA;AACA;AACA;AAnDA;AAqDA;;AAEA;AACA;AAUA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAMA;AACA;AAjCA;AAmCA;;AAEA;AACA;AAWA;AAEA;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AAEA;AAEA;AACA;AAMA;AACA;AAvDA;AAyDA;;AAEA;AACA;AAWA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AAEA;AAEA;AACA;AAMA;AACA;AA1CA;AA4CA;;AAEA;AACA;AAKA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAxBA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACjhBA;AACA;AACA;AAEA;;;;;;AAMA;AACA;AAKA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AACA;AAtCA;AAwCA;;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClEA;AACA;AACA;AACA;AACA;AAYA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AASA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAKA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAYA;AACA;AACA;AAEA;AACA;AAUA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAKA;AAEA;AACA;AAEA;AACA;AACA;AAWA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAWA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AAAA;AACA;AACA;AACA;AACA;AACA;AAtLA;AAwLA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AC5MA;AACA;AAMA;;AAEA;AACA;AAOA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;;;AAGA;AACA;AAQA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAOA;AACA;AACA;AAEA;AACA;AAQA;AAEA;AACA;AAGA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAzEA;AA2EA;;AAEA;AACA;AAQA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AAQA;AACA;AACA;AAEA;AACA;AAGA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAtEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACrLA;AAwBA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AACA;AACA;AAGA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAEA;AACA;AA1CA;AA4CA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AANA;;;;;;;;;ACtPA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/kBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACx/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACngCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC79DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzgDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjTA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACRA;AACA;AACA;AACA;AACA;;;;;ACJA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACNA;AACA;AACA;AACA;AACA;;;;ACJA;AACA;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;AErCA;AACA;AACA;AACA","sources":[".././node_modules/@actions/core/lib/command.js",".././node_modules/@actions/core/lib/core.js",".././node_modules/@actions/core/lib/file-command.js",".././node_modules/@actions/core/lib/oidc-utils.js",".././node_modules/@actions/core/lib/path-utils.js",".././node_modules/@actions/core/lib/platform.js",".././node_modules/@actions/core/lib/summary.js",".././node_modules/@actions/core/lib/utils.js",".././node_modules/@actions/exec/lib/exec.js",".././node_modules/@actions/exec/lib/toolrunner.js",".././node_modules/@actions/http-client/lib/auth.js",".././node_modules/@actions/http-client/lib/index.js",".././node_modules/@actions/http-client/lib/proxy.js",".././node_modules/@actions/io/lib/io-util.js",".././node_modules/@actions/io/lib/io.js",".././node_modules/@aws-crypto/crc32/build/main/aws_crc32.js",".././node_modules/@aws-crypto/crc32/build/main/index.js",".././node_modules/@aws-crypto/crc32c/build/main/aws_crc32c.js",".././node_modules/@aws-crypto/crc32c/build/main/index.js",".././node_modules/@aws-crypto/util/build/main/convertToBuffer.js",".././node_modules/@aws-crypto/util/build/main/index.js",".././node_modules/@aws-crypto/util/build/main/isEmptyData.js",".././node_modules/@aws-crypto/util/build/main/numToUint8.js",".././node_modules/@aws-crypto/util/build/main/uint32ArrayFrom.js",".././node_modules/@aws-crypto/util/node_modules/@smithy/is-array-buffer/dist-cjs/index.js",".././node_modules/@aws-crypto/util/node_modules/@smithy/util-buffer-from/dist-cjs/index.js",".././node_modules/@aws-crypto/util/node_modules/@smithy/util-utf8/dist-cjs/index.js",".././node_modules/@aws-sdk/client-elastic-beanstalk/dist-cjs/auth/httpAuthSchemeProvider.js",".././node_modules/@aws-sdk/client-elastic-beanstalk/dist-cjs/endpoint/endpointResolver.js",".././node_modules/@aws-sdk/client-elastic-beanstalk/dist-cjs/endpoint/ruleset.js",".././node_modules/@aws-sdk/client-elastic-beanstalk/dist-cjs/index.js",".././node_modules/@aws-sdk/client-elastic-beanstalk/dist-cjs/runtimeConfig.js",".././node_modules/@aws-sdk/client-elastic-beanstalk/dist-cjs/runtimeConfig.shared.js",".././node_modules/@aws-sdk/client-s3/dist-cjs/auth/httpAuthSchemeProvider.js",".././node_modules/@aws-sdk/client-s3/dist-cjs/endpoint/endpointResolver.js",".././node_modules/@aws-sdk/client-s3/dist-cjs/endpoint/ruleset.js",".././node_modules/@aws-sdk/client-s3/dist-cjs/index.js",".././node_modules/@aws-sdk/client-s3/dist-cjs/runtimeConfig.js",".././node_modules/@aws-sdk/client-s3/dist-cjs/runtimeConfig.shared.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/STSClient.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/auth/httpAuthExtensionConfiguration.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/auth/httpAuthSchemeProvider.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/endpoint/EndpointParameters.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/endpoint/endpointResolver.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/endpoint/ruleset.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/index.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/runtimeConfig.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/runtimeConfig.shared.js",".././node_modules/@aws-sdk/client-sts/dist-cjs/runtimeExtensions.js",".././node_modules/@aws-sdk/core/dist-cjs/index.js",".././node_modules/@aws-sdk/core/dist-cjs/submodules/client/index.js",".././node_modules/@aws-sdk/core/dist-cjs/submodules/protocols/index.js",".././node_modules/@aws-sdk/crc64-nvme/dist-cjs/index.js",".././node_modules/@aws-sdk/credential-provider-env/dist-cjs/index.js",".././node_modules/@aws-sdk/credential-provider-node/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-bucket-endpoint/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-expect-continue/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-flexible-checksums/dist-cjs/getCrc32ChecksumAlgorithmFunction.js",".././node_modules/@aws-sdk/middleware-flexible-checksums/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-host-header/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-location-constraint/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-logger/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-recursion-detection/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-recursion-detection/dist-cjs/recursionDetectionMiddleware.js",".././node_modules/@aws-sdk/middleware-sdk-s3/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-ssec/dist-cjs/index.js",".././node_modules/@aws-sdk/middleware-user-agent/dist-cjs/index.js",".././node_modules/@aws-sdk/region-config-resolver/dist-cjs/index.js",".././node_modules/@aws-sdk/region-config-resolver/dist-cjs/regionConfig/stsRegionDefaultResolver.js",".././node_modules/@aws-sdk/signature-v4-multi-region/dist-cjs/index.js",".././node_modules/@aws-sdk/util-arn-parser/dist-cjs/index.js",".././node_modules/@aws-sdk/util-endpoints/dist-cjs/index.js",".././node_modules/@aws-sdk/util-user-agent-node/dist-cjs/index.js",".././node_modules/@aws-sdk/xml-builder/dist-cjs/index.js",".././node_modules/@aws-sdk/xml-builder/dist-cjs/xml-parser.js",".././node_modules/@aws/lambda-invoke-store/dist-cjs/invoke-store.js",".././node_modules/@smithy/config-resolver/dist-cjs/index.js",".././node_modules/@smithy/core/dist-cjs/index.js",".././node_modules/@smithy/core/dist-cjs/submodules/cbor/index.js",".././node_modules/@smithy/core/dist-cjs/submodules/protocols/index.js",".././node_modules/@smithy/core/dist-cjs/submodules/schema/index.js",".././node_modules/@smithy/core/dist-cjs/submodules/serde/index.js",".././node_modules/@smithy/eventstream-codec/dist-cjs/index.js",".././node_modules/@smithy/eventstream-serde-config-resolver/dist-cjs/index.js",".././node_modules/@smithy/eventstream-serde-node/dist-cjs/index.js",".././node_modules/@smithy/eventstream-serde-universal/dist-cjs/index.js",".././node_modules/@smithy/fetch-http-handler/dist-cjs/index.js",".././node_modules/@smithy/hash-node/dist-cjs/index.js",".././node_modules/@smithy/hash-stream-node/dist-cjs/index.js",".././node_modules/@smithy/is-array-buffer/dist-cjs/index.js",".././node_modules/@smithy/middleware-content-length/dist-cjs/index.js",".././node_modules/@smithy/middleware-endpoint/dist-cjs/adaptors/getEndpointFromConfig.js",".././node_modules/@smithy/middleware-endpoint/dist-cjs/adaptors/getEndpointUrlConfig.js",".././node_modules/@smithy/middleware-endpoint/dist-cjs/index.js",".././node_modules/@smithy/middleware-retry/dist-cjs/index.js",".././node_modules/@smithy/middleware-retry/dist-cjs/isStreamingPayload/isStreamingPayload.js",".././node_modules/@smithy/middleware-serde/dist-cjs/index.js",".././node_modules/@smithy/middleware-stack/dist-cjs/index.js",".././node_modules/@smithy/node-config-provider/dist-cjs/index.js",".././node_modules/@smithy/node-http-handler/dist-cjs/index.js",".././node_modules/@smithy/property-provider/dist-cjs/index.js",".././node_modules/@smithy/protocol-http/dist-cjs/index.js",".././node_modules/@smithy/querystring-builder/dist-cjs/index.js",".././node_modules/@smithy/querystring-parser/dist-cjs/index.js",".././node_modules/@smithy/service-error-classification/dist-cjs/index.js",".././node_modules/@smithy/shared-ini-file-loader/dist-cjs/getHomeDir.js",".././node_modules/@smithy/shared-ini-file-loader/dist-cjs/getSSOTokenFilepath.js",".././node_modules/@smithy/shared-ini-file-loader/dist-cjs/getSSOTokenFromFile.js",".././node_modules/@smithy/shared-ini-file-loader/dist-cjs/index.js",".././node_modules/@smithy/shared-ini-file-loader/dist-cjs/readFile.js",".././node_modules/@smithy/signature-v4/dist-cjs/index.js",".././node_modules/@smithy/smithy-client/dist-cjs/index.js",".././node_modules/@smithy/types/dist-cjs/index.js",".././node_modules/@smithy/url-parser/dist-cjs/index.js",".././node_modules/@smithy/util-base64/dist-cjs/fromBase64.js",".././node_modules/@smithy/util-base64/dist-cjs/index.js",".././node_modules/@smithy/util-base64/dist-cjs/toBase64.js",".././node_modules/@smithy/util-body-length-browser/dist-cjs/index.js",".././node_modules/@smithy/util-body-length-node/dist-cjs/index.js",".././node_modules/@smithy/util-buffer-from/dist-cjs/index.js",".././node_modules/@smithy/util-config-provider/dist-cjs/index.js",".././node_modules/@smithy/util-defaults-mode-node/dist-cjs/index.js",".././node_modules/@smithy/util-endpoints/dist-cjs/index.js",".././node_modules/@smithy/util-hex-encoding/dist-cjs/index.js",".././node_modules/@smithy/util-middleware/dist-cjs/index.js",".././node_modules/@smithy/util-retry/dist-cjs/index.js",".././node_modules/@smithy/util-stream/dist-cjs/ByteArrayCollector.js",".././node_modules/@smithy/util-stream/dist-cjs/checksum/ChecksumStream.browser.js",".././node_modules/@smithy/util-stream/dist-cjs/checksum/ChecksumStream.js",".././node_modules/@smithy/util-stream/dist-cjs/checksum/createChecksumStream.browser.js",".././node_modules/@smithy/util-stream/dist-cjs/checksum/createChecksumStream.js",".././node_modules/@smithy/util-stream/dist-cjs/createBufferedReadable.js",".././node_modules/@smithy/util-stream/dist-cjs/createBufferedReadableStream.js",".././node_modules/@smithy/util-stream/dist-cjs/getAwsChunkedEncodingStream.browser.js",".././node_modules/@smithy/util-stream/dist-cjs/getAwsChunkedEncodingStream.js",".././node_modules/@smithy/util-stream/dist-cjs/headStream.browser.js",".././node_modules/@smithy/util-stream/dist-cjs/headStream.js",".././node_modules/@smithy/util-stream/dist-cjs/index.js",".././node_modules/@smithy/util-stream/dist-cjs/sdk-stream-mixin.browser.js",".././node_modules/@smithy/util-stream/dist-cjs/sdk-stream-mixin.js",".././node_modules/@smithy/util-stream/dist-cjs/splitStream.browser.js",".././node_modules/@smithy/util-stream/dist-cjs/splitStream.js",".././node_modules/@smithy/util-stream/dist-cjs/stream-type-check.js",".././node_modules/@smithy/util-uri-escape/dist-cjs/index.js",".././node_modules/@smithy/util-utf8/dist-cjs/index.js",".././node_modules/@smithy/util-waiter/dist-cjs/index.js",".././node_modules/@smithy/uuid/dist-cjs/index.js",".././node_modules/@smithy/uuid/dist-cjs/randomUUID.js",".././node_modules/abort-controller/dist/abort-controller.js",".././node_modules/archiver-utils/file.js",".././node_modules/archiver-utils/index.js",".././node_modules/archiver/index.js",".././node_modules/archiver/lib/core.js",".././node_modules/archiver/lib/error.js",".././node_modules/archiver/lib/plugins/json.js",".././node_modules/archiver/lib/plugins/tar.js",".././node_modules/archiver/lib/plugins/zip.js",".././node_modules/async/dist/async.js",".././node_modules/b4a/index.js",".././node_modules/balanced-match/index.js",".././node_modules/brace-expansion/index.js",".././node_modules/compress-commons/lib/archivers/archive-entry.js",".././node_modules/compress-commons/lib/archivers/archive-output-stream.js",".././node_modules/compress-commons/lib/archivers/zip/constants.js",".././node_modules/compress-commons/lib/archivers/zip/general-purpose-bit.js",".././node_modules/compress-commons/lib/archivers/zip/unix-stat.js",".././node_modules/compress-commons/lib/archivers/zip/util.js",".././node_modules/compress-commons/lib/archivers/zip/zip-archive-entry.js",".././node_modules/compress-commons/lib/archivers/zip/zip-archive-output-stream.js",".././node_modules/compress-commons/lib/compress-commons.js",".././node_modules/compress-commons/lib/util/index.js",".././node_modules/core-util-is/lib/util.js",".././node_modules/crc-32/crc32.js",".././node_modules/crc32-stream/lib/crc32-stream.js",".././node_modules/crc32-stream/lib/deflate-crc32-stream.js",".././node_modules/crc32-stream/lib/index.js",".././node_modules/event-target-shim/dist/event-target-shim.js",".././node_modules/events-universal/default.js",".././node_modules/fast-fifo/fixed-size.js",".././node_modules/fast-fifo/index.js",".././node_modules/graceful-fs/clone.js",".././node_modules/graceful-fs/graceful-fs.js",".././node_modules/graceful-fs/legacy-streams.js",".././node_modules/graceful-fs/polyfills.js",".././node_modules/inherits/inherits.js",".././node_modules/inherits/inherits_browser.js",".././node_modules/is-stream/index.js",".././node_modules/isarray/index.js",".././node_modules/lazystream/lib/lazystream.js",".././node_modules/lazystream/node_modules/readable-stream/lib/_stream_duplex.js",".././node_modules/lazystream/node_modules/readable-stream/lib/_stream_passthrough.js",".././node_modules/lazystream/node_modules/readable-stream/lib/_stream_readable.js",".././node_modules/lazystream/node_modules/readable-stream/lib/_stream_transform.js",".././node_modules/lazystream/node_modules/readable-stream/lib/_stream_writable.js",".././node_modules/lazystream/node_modules/readable-stream/lib/internal/streams/BufferList.js",".././node_modules/lazystream/node_modules/readable-stream/lib/internal/streams/destroy.js",".././node_modules/lazystream/node_modules/readable-stream/lib/internal/streams/stream.js",".././node_modules/lazystream/node_modules/readable-stream/passthrough.js",".././node_modules/lazystream/node_modules/readable-stream/readable.js",".././node_modules/lazystream/node_modules/safe-buffer/index.js",".././node_modules/lazystream/node_modules/string_decoder/lib/string_decoder.js",".././node_modules/lodash/_Hash.js",".././node_modules/lodash/_ListCache.js",".././node_modules/lodash/_Map.js",".././node_modules/lodash/_MapCache.js",".././node_modules/lodash/_Set.js",".././node_modules/lodash/_SetCache.js",".././node_modules/lodash/_Symbol.js",".././node_modules/lodash/_apply.js",".././node_modules/lodash/_arrayIncludes.js",".././node_modules/lodash/_arrayIncludesWith.js",".././node_modules/lodash/_arrayLikeKeys.js",".././node_modules/lodash/_arrayMap.js",".././node_modules/lodash/_arrayPush.js",".././node_modules/lodash/_assocIndexOf.js",".././node_modules/lodash/_baseDifference.js",".././node_modules/lodash/_baseFindIndex.js",".././node_modules/lodash/_baseFlatten.js",".././node_modules/lodash/_baseGetTag.js",".././node_modules/lodash/_baseIndexOf.js",".././node_modules/lodash/_baseIsArguments.js",".././node_modules/lodash/_baseIsNaN.js",".././node_modules/lodash/_baseIsNative.js",".././node_modules/lodash/_baseIsTypedArray.js",".././node_modules/lodash/_baseKeysIn.js",".././node_modules/lodash/_baseRest.js",".././node_modules/lodash/_baseSetToString.js",".././node_modules/lodash/_baseTimes.js",".././node_modules/lodash/_baseUnary.js",".././node_modules/lodash/_baseUniq.js",".././node_modules/lodash/_cacheHas.js",".././node_modules/lodash/_coreJsData.js",".././node_modules/lodash/_createSet.js",".././node_modules/lodash/_defineProperty.js",".././node_modules/lodash/_freeGlobal.js",".././node_modules/lodash/_getMapData.js",".././node_modules/lodash/_getNative.js",".././node_modules/lodash/_getPrototype.js",".././node_modules/lodash/_getRawTag.js",".././node_modules/lodash/_getValue.js",".././node_modules/lodash/_hashClear.js",".././node_modules/lodash/_hashDelete.js",".././node_modules/lodash/_hashGet.js",".././node_modules/lodash/_hashHas.js",".././node_modules/lodash/_hashSet.js",".././node_modules/lodash/_isFlattenable.js",".././node_modules/lodash/_isIndex.js",".././node_modules/lodash/_isIterateeCall.js",".././node_modules/lodash/_isKeyable.js",".././node_modules/lodash/_isMasked.js",".././node_modules/lodash/_isPrototype.js",".././node_modules/lodash/_listCacheClear.js",".././node_modules/lodash/_listCacheDelete.js",".././node_modules/lodash/_listCacheGet.js",".././node_modules/lodash/_listCacheHas.js",".././node_modules/lodash/_listCacheSet.js",".././node_modules/lodash/_mapCacheClear.js",".././node_modules/lodash/_mapCacheDelete.js",".././node_modules/lodash/_mapCacheGet.js",".././node_modules/lodash/_mapCacheHas.js",".././node_modules/lodash/_mapCacheSet.js",".././node_modules/lodash/_nativeCreate.js",".././node_modules/lodash/_nativeKeysIn.js",".././node_modules/lodash/_nodeUtil.js",".././node_modules/lodash/_objectToString.js",".././node_modules/lodash/_overArg.js",".././node_modules/lodash/_overRest.js",".././node_modules/lodash/_root.js",".././node_modules/lodash/_setCacheAdd.js",".././node_modules/lodash/_setCacheHas.js",".././node_modules/lodash/_setToArray.js",".././node_modules/lodash/_setToString.js",".././node_modules/lodash/_shortOut.js",".././node_modules/lodash/_strictIndexOf.js",".././node_modules/lodash/_toSource.js",".././node_modules/lodash/constant.js",".././node_modules/lodash/defaults.js",".././node_modules/lodash/difference.js",".././node_modules/lodash/eq.js",".././node_modules/lodash/flatten.js",".././node_modules/lodash/identity.js",".././node_modules/lodash/isArguments.js",".././node_modules/lodash/isArray.js",".././node_modules/lodash/isArrayLike.js",".././node_modules/lodash/isArrayLikeObject.js",".././node_modules/lodash/isBuffer.js",".././node_modules/lodash/isFunction.js",".././node_modules/lodash/isLength.js",".././node_modules/lodash/isObject.js",".././node_modules/lodash/isObjectLike.js",".././node_modules/lodash/isPlainObject.js",".././node_modules/lodash/isTypedArray.js",".././node_modules/lodash/keysIn.js",".././node_modules/lodash/noop.js",".././node_modules/lodash/stubFalse.js",".././node_modules/lodash/union.js",".././node_modules/normalize-path/index.js",".././node_modules/process-nextick-args/index.js",".././node_modules/process/index.js",".././node_modules/readable-stream/lib/internal/streams/add-abort-signal.js",".././node_modules/readable-stream/lib/internal/streams/buffer_list.js",".././node_modules/readable-stream/lib/internal/streams/compose.js",".././node_modules/readable-stream/lib/internal/streams/destroy.js",".././node_modules/readable-stream/lib/internal/streams/duplex.js",".././node_modules/readable-stream/lib/internal/streams/duplexify.js",".././node_modules/readable-stream/lib/internal/streams/end-of-stream.js",".././node_modules/readable-stream/lib/internal/streams/from.js",".././node_modules/readable-stream/lib/internal/streams/legacy.js",".././node_modules/readable-stream/lib/internal/streams/operators.js",".././node_modules/readable-stream/lib/internal/streams/passthrough.js",".././node_modules/readable-stream/lib/internal/streams/pipeline.js",".././node_modules/readable-stream/lib/internal/streams/readable.js",".././node_modules/readable-stream/lib/internal/streams/state.js",".././node_modules/readable-stream/lib/internal/streams/transform.js",".././node_modules/readable-stream/lib/internal/streams/utils.js",".././node_modules/readable-stream/lib/internal/streams/writable.js",".././node_modules/readable-stream/lib/internal/validators.js",".././node_modules/readable-stream/lib/ours/errors.js",".././node_modules/readable-stream/lib/ours/index.js",".././node_modules/readable-stream/lib/ours/primordials.js",".././node_modules/readable-stream/lib/ours/util.js",".././node_modules/readable-stream/lib/ours/util/inspect.js",".././node_modules/readable-stream/lib/stream.js",".././node_modules/readable-stream/lib/stream/promises.js",".././node_modules/readdir-glob/index.js",".././node_modules/readdir-glob/node_modules/minimatch/lib/path.js",".././node_modules/readdir-glob/node_modules/minimatch/minimatch.js",".././node_modules/safe-buffer/index.js",".././node_modules/streamx/index.js",".././node_modules/string_decoder/lib/string_decoder.js",".././node_modules/tar-stream/constants.js",".././node_modules/tar-stream/extract.js",".././node_modules/tar-stream/headers.js",".././node_modules/tar-stream/index.js",".././node_modules/tar-stream/pack.js",".././node_modules/text-decoder/index.js",".././node_modules/text-decoder/lib/pass-through-decoder.js",".././node_modules/text-decoder/lib/utf8-decoder.js",".././node_modules/tslib/tslib.js",".././node_modules/tunnel/index.js",".././node_modules/tunnel/lib/tunnel.js",".././node_modules/undici/index.js",".././node_modules/undici/lib/api/abort-signal.js",".././node_modules/undici/lib/api/api-connect.js",".././node_modules/undici/lib/api/api-pipeline.js",".././node_modules/undici/lib/api/api-request.js",".././node_modules/undici/lib/api/api-stream.js",".././node_modules/undici/lib/api/api-upgrade.js",".././node_modules/undici/lib/api/index.js",".././node_modules/undici/lib/api/readable.js",".././node_modules/undici/lib/api/util.js",".././node_modules/undici/lib/core/connect.js",".././node_modules/undici/lib/core/constants.js",".././node_modules/undici/lib/core/diagnostics.js",".././node_modules/undici/lib/core/errors.js",".././node_modules/undici/lib/core/request.js",".././node_modules/undici/lib/core/symbols.js",".././node_modules/undici/lib/core/tree.js",".././node_modules/undici/lib/core/util.js",".././node_modules/undici/lib/dispatcher/agent.js",".././node_modules/undici/lib/dispatcher/balanced-pool.js",".././node_modules/undici/lib/dispatcher/client-h1.js",".././node_modules/undici/lib/dispatcher/client-h2.js",".././node_modules/undici/lib/dispatcher/client.js",".././node_modules/undici/lib/dispatcher/dispatcher-base.js",".././node_modules/undici/lib/dispatcher/dispatcher.js",".././node_modules/undici/lib/dispatcher/env-http-proxy-agent.js",".././node_modules/undici/lib/dispatcher/fixed-queue.js",".././node_modules/undici/lib/dispatcher/pool-base.js",".././node_modules/undici/lib/dispatcher/pool-stats.js",".././node_modules/undici/lib/dispatcher/pool.js",".././node_modules/undici/lib/dispatcher/proxy-agent.js",".././node_modules/undici/lib/dispatcher/retry-agent.js",".././node_modules/undici/lib/global.js",".././node_modules/undici/lib/handler/decorator-handler.js",".././node_modules/undici/lib/handler/redirect-handler.js",".././node_modules/undici/lib/handler/retry-handler.js",".././node_modules/undici/lib/interceptor/dns.js",".././node_modules/undici/lib/interceptor/dump.js",".././node_modules/undici/lib/interceptor/redirect-interceptor.js",".././node_modules/undici/lib/interceptor/redirect.js",".././node_modules/undici/lib/interceptor/retry.js",".././node_modules/undici/lib/llhttp/constants.js",".././node_modules/undici/lib/llhttp/llhttp-wasm.js",".././node_modules/undici/lib/llhttp/llhttp_simd-wasm.js",".././node_modules/undici/lib/llhttp/utils.js",".././node_modules/undici/lib/mock/mock-agent.js",".././node_modules/undici/lib/mock/mock-client.js",".././node_modules/undici/lib/mock/mock-errors.js",".././node_modules/undici/lib/mock/mock-interceptor.js",".././node_modules/undici/lib/mock/mock-pool.js",".././node_modules/undici/lib/mock/mock-symbols.js",".././node_modules/undici/lib/mock/mock-utils.js",".././node_modules/undici/lib/mock/pending-interceptors-formatter.js",".././node_modules/undici/lib/mock/pluralizer.js",".././node_modules/undici/lib/util/timers.js",".././node_modules/undici/lib/web/cache/cache.js",".././node_modules/undici/lib/web/cache/cachestorage.js",".././node_modules/undici/lib/web/cache/symbols.js",".././node_modules/undici/lib/web/cache/util.js",".././node_modules/undici/lib/web/cookies/constants.js",".././node_modules/undici/lib/web/cookies/index.js",".././node_modules/undici/lib/web/cookies/parse.js",".././node_modules/undici/lib/web/cookies/util.js",".././node_modules/undici/lib/web/eventsource/eventsource-stream.js",".././node_modules/undici/lib/web/eventsource/eventsource.js",".././node_modules/undici/lib/web/eventsource/util.js",".././node_modules/undici/lib/web/fetch/body.js",".././node_modules/undici/lib/web/fetch/constants.js",".././node_modules/undici/lib/web/fetch/data-url.js",".././node_modules/undici/lib/web/fetch/dispatcher-weakref.js",".././node_modules/undici/lib/web/fetch/file.js",".././node_modules/undici/lib/web/fetch/formdata-parser.js",".././node_modules/undici/lib/web/fetch/formdata.js",".././node_modules/undici/lib/web/fetch/global.js",".././node_modules/undici/lib/web/fetch/headers.js",".././node_modules/undici/lib/web/fetch/index.js",".././node_modules/undici/lib/web/fetch/request.js",".././node_modules/undici/lib/web/fetch/response.js",".././node_modules/undici/lib/web/fetch/symbols.js",".././node_modules/undici/lib/web/fetch/util.js",".././node_modules/undici/lib/web/fetch/webidl.js",".././node_modules/undici/lib/web/fileapi/encoding.js",".././node_modules/undici/lib/web/fileapi/filereader.js",".././node_modules/undici/lib/web/fileapi/progressevent.js",".././node_modules/undici/lib/web/fileapi/symbols.js",".././node_modules/undici/lib/web/fileapi/util.js",".././node_modules/undici/lib/web/websocket/connection.js",".././node_modules/undici/lib/web/websocket/constants.js",".././node_modules/undici/lib/web/websocket/events.js",".././node_modules/undici/lib/web/websocket/frame.js",".././node_modules/undici/lib/web/websocket/permessage-deflate.js",".././node_modules/undici/lib/web/websocket/receiver.js",".././node_modules/undici/lib/web/websocket/sender.js",".././node_modules/undici/lib/web/websocket/symbols.js",".././node_modules/undici/lib/web/websocket/util.js",".././node_modules/undici/lib/web/websocket/websocket.js",".././node_modules/util-deprecate/node.js",".././node_modules/zip-stream/index.js",".././src/aws-clients.ts",".././src/aws-operations.ts",".././src/deploymentpackage.ts",".././src/main.ts",".././src/monitoring.ts",".././src/validations.ts","../external node-commonjs \"assert\"","../external node-commonjs \"buffer\"","../external node-commonjs \"child_process\"","../external node-commonjs \"constants\"","../external node-commonjs \"crypto\"","../external node-commonjs \"events\"","../external node-commonjs \"fs\"","../external node-commonjs \"fs/promises\"","../external node-commonjs \"http\"","../external node-commonjs \"http2\"","../external node-commonjs \"https\"","../external node-commonjs \"net\"","../external node-commonjs \"node:assert\"","../external node-commonjs \"node:async_hooks\"","../external node-commonjs \"node:buffer\"","../external node-commonjs \"node:console\"","../external node-commonjs \"node:crypto\"","../external node-commonjs \"node:diagnostics_channel\"","../external node-commonjs \"node:dns\"","../external node-commonjs \"node:events\"","../external node-commonjs \"node:fs\"","../external node-commonjs \"node:fs/promises\"","../external node-commonjs \"node:http\"","../external node-commonjs \"node:http2\"","../external node-commonjs \"node:net\"","../external node-commonjs \"node:os\"","../external node-commonjs \"node:path\"","../external node-commonjs \"node:perf_hooks\"","../external node-commonjs \"node:querystring\"","../external node-commonjs \"node:stream\"","../external node-commonjs \"node:string_decoder\"","../external node-commonjs \"node:tls\"","../external node-commonjs \"node:url\"","../external node-commonjs \"node:util\"","../external node-commonjs \"node:util/types\"","../external node-commonjs \"node:worker_threads\"","../external node-commonjs \"node:zlib\"","../external node-commonjs \"os\"","../external node-commonjs \"path\"","../external node-commonjs \"process\"","../external node-commonjs \"stream\"","../external node-commonjs \"string_decoder\"","../external node-commonjs \"timers\"","../external node-commonjs \"tls\"","../external node-commonjs \"url\"","../external node-commonjs \"util\"","../external node-commonjs \"zlib\"",".././node_modules/glob/dist/commonjs/glob.js",".././node_modules/glob/dist/commonjs/has-magic.js",".././node_modules/glob/dist/commonjs/ignore.js",".././node_modules/glob/dist/commonjs/index.js",".././node_modules/glob/dist/commonjs/pattern.js",".././node_modules/glob/dist/commonjs/processor.js",".././node_modules/glob/dist/commonjs/walker.js",".././node_modules/minimatch/dist/commonjs/assert-valid-pattern.js",".././node_modules/minimatch/dist/commonjs/ast.js",".././node_modules/minimatch/dist/commonjs/brace-expressions.js",".././node_modules/minimatch/dist/commonjs/escape.js",".././node_modules/minimatch/dist/commonjs/index.js",".././node_modules/minimatch/dist/commonjs/unescape.js",".././node_modules/minipass/dist/commonjs/index.js",".././node_modules/path-scurry/dist/commonjs/index.js",".././node_modules/path-scurry/node_modules/lru-cache/dist/commonjs/index.js",".././node_modules/buffer-crc32/dist/index.cjs",".././node_modules/fast-xml-parser/lib/fxp.cjs","../webpack/bootstrap","../webpack/runtime/create fake namespace object","../webpack/runtime/define property getters","../webpack/runtime/ensure chunk","../webpack/runtime/get javascript chunk filename","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/make namespace object","../webpack/runtime/node module decorator","../webpack/runtime/compat","../webpack/runtime/require chunk loading","../webpack/before-startup","../webpack/startup","../webpack/after-startup"],"sourcesContent":["\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issue = exports.issueCommand = void 0;\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return (0, utils_1.toCommandValue)(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return (0, utils_1.toCommandValue)(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.platform = exports.toPlatformPath = exports.toWin32Path = exports.toPosixPath = exports.markdownSummary = exports.summary = exports.getIDToken = exports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.notice = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\nconst oidc_utils_1 = require(\"./oidc-utils\");\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode || (exports.ExitCode = ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = (0, utils_1.toCommandValue)(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        return (0, file_command_1.issueFileCommand)('ENV', (0, file_command_1.prepareKeyValueMessage)(name, val));\n    }\n    (0, command_1.issueCommand)('set-env', { name }, convertedVal);\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    (0, command_1.issueCommand)('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        (0, file_command_1.issueFileCommand)('PATH', inputPath);\n    }\n    else {\n        (0, command_1.issueCommand)('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.\n * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.\n * Returns an empty string if the value is not defined.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    if (options && options.trimWhitespace === false) {\n        return val;\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Gets the values of an multiline input.  Each value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string[]\n *\n */\nfunction getMultilineInput(name, options) {\n    const inputs = getInput(name, options)\n        .split('\\n')\n        .filter(x => x !== '');\n    if (options && options.trimWhitespace === false) {\n        return inputs;\n    }\n    return inputs.map(input => input.trim());\n}\nexports.getMultilineInput = getMultilineInput;\n/**\n * Gets the input value of the boolean type in the YAML 1.2 \"core schema\" specification.\n * Support boolean input list: `true | True | TRUE | false | False | FALSE` .\n * The return value is also in boolean type.\n * ref: https://yaml.org/spec/1.2/spec.html#id2804923\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   boolean\n */\nfunction getBooleanInput(name, options) {\n    const trueValue = ['true', 'True', 'TRUE'];\n    const falseValue = ['false', 'False', 'FALSE'];\n    const val = getInput(name, options);\n    if (trueValue.includes(val))\n        return true;\n    if (falseValue.includes(val))\n        return false;\n    throw new TypeError(`Input does not meet YAML 1.2 \"Core Schema\" specification: ${name}\\n` +\n        `Support boolean input list: \\`true | True | TRUE | false | False | FALSE\\``);\n}\nexports.getBooleanInput = getBooleanInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    const filePath = process.env['GITHUB_OUTPUT'] || '';\n    if (filePath) {\n        return (0, file_command_1.issueFileCommand)('OUTPUT', (0, file_command_1.prepareKeyValueMessage)(name, value));\n    }\n    process.stdout.write(os.EOL);\n    (0, command_1.issueCommand)('set-output', { name }, (0, utils_1.toCommandValue)(value));\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    (0, command_1.issue)('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    (0, command_1.issueCommand)('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction error(message, properties = {}) {\n    (0, command_1.issueCommand)('error', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds a warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction warning(message, properties = {}) {\n    (0, command_1.issueCommand)('warning', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Adds a notice issue\n * @param message notice issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction notice(message, properties = {}) {\n    (0, command_1.issueCommand)('notice', (0, utils_1.toCommandProperties)(properties), message instanceof Error ? message.toString() : message);\n}\nexports.notice = notice;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    (0, command_1.issue)('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    (0, command_1.issue)('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    const filePath = process.env['GITHUB_STATE'] || '';\n    if (filePath) {\n        return (0, file_command_1.issueFileCommand)('STATE', (0, file_command_1.prepareKeyValueMessage)(name, value));\n    }\n    (0, command_1.issueCommand)('save-state', { name }, (0, utils_1.toCommandValue)(value));\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\nfunction getIDToken(aud) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return yield oidc_utils_1.OidcClient.getIDToken(aud);\n    });\n}\nexports.getIDToken = getIDToken;\n/**\n * Summary exports\n */\nvar summary_1 = require(\"./summary\");\nObject.defineProperty(exports, \"summary\", { enumerable: true, get: function () { return summary_1.summary; } });\n/**\n * @deprecated use core.summary\n */\nvar summary_2 = require(\"./summary\");\nObject.defineProperty(exports, \"markdownSummary\", { enumerable: true, get: function () { return summary_2.markdownSummary; } });\n/**\n * Path exports\n */\nvar path_utils_1 = require(\"./path-utils\");\nObject.defineProperty(exports, \"toPosixPath\", { enumerable: true, get: function () { return path_utils_1.toPosixPath; } });\nObject.defineProperty(exports, \"toWin32Path\", { enumerable: true, get: function () { return path_utils_1.toWin32Path; } });\nObject.defineProperty(exports, \"toPlatformPath\", { enumerable: true, get: function () { return path_utils_1.toPlatformPath; } });\n/**\n * Platform utilities exports\n */\nexports.platform = __importStar(require(\"./platform\"));\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.prepareKeyValueMessage = exports.issueFileCommand = void 0;\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst crypto = __importStar(require(\"crypto\"));\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\nfunction issueFileCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${(0, utils_1.toCommandValue)(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueFileCommand = issueFileCommand;\nfunction prepareKeyValueMessage(key, value) {\n    const delimiter = `ghadelimiter_${crypto.randomUUID()}`;\n    const convertedValue = (0, utils_1.toCommandValue)(value);\n    // These should realistically never happen, but just in case someone finds a\n    // way to exploit uuid generation let's not allow keys or values that contain\n    // the delimiter.\n    if (key.includes(delimiter)) {\n        throw new Error(`Unexpected input: name should not contain the delimiter \"${delimiter}\"`);\n    }\n    if (convertedValue.includes(delimiter)) {\n        throw new Error(`Unexpected input: value should not contain the delimiter \"${delimiter}\"`);\n    }\n    return `${key}<<${delimiter}${os.EOL}${convertedValue}${os.EOL}${delimiter}`;\n}\nexports.prepareKeyValueMessage = prepareKeyValueMessage;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.OidcClient = void 0;\nconst http_client_1 = require(\"@actions/http-client\");\nconst auth_1 = require(\"@actions/http-client/lib/auth\");\nconst core_1 = require(\"./core\");\nclass OidcClient {\n    static createHttpClient(allowRetry = true, maxRetry = 10) {\n        const requestOptions = {\n            allowRetries: allowRetry,\n            maxRetries: maxRetry\n        };\n        return new http_client_1.HttpClient('actions/oidc-client', [new auth_1.BearerCredentialHandler(OidcClient.getRequestToken())], requestOptions);\n    }\n    static getRequestToken() {\n        const token = process.env['ACTIONS_ID_TOKEN_REQUEST_TOKEN'];\n        if (!token) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_TOKEN env variable');\n        }\n        return token;\n    }\n    static getIDTokenUrl() {\n        const runtimeUrl = process.env['ACTIONS_ID_TOKEN_REQUEST_URL'];\n        if (!runtimeUrl) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_URL env variable');\n        }\n        return runtimeUrl;\n    }\n    static getCall(id_token_url) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            const httpclient = OidcClient.createHttpClient();\n            const res = yield httpclient\n                .getJson(id_token_url)\n                .catch(error => {\n                throw new Error(`Failed to get ID Token. \\n \n        Error Code : ${error.statusCode}\\n \n        Error Message: ${error.message}`);\n            });\n            const id_token = (_a = res.result) === null || _a === void 0 ? void 0 : _a.value;\n            if (!id_token) {\n                throw new Error('Response json body do not have ID Token field');\n            }\n            return id_token;\n        });\n    }\n    static getIDToken(audience) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                // New ID Token is requested from action service\n                let id_token_url = OidcClient.getIDTokenUrl();\n                if (audience) {\n                    const encodedAudience = encodeURIComponent(audience);\n                    id_token_url = `${id_token_url}&audience=${encodedAudience}`;\n                }\n                (0, core_1.debug)(`ID token url is ${id_token_url}`);\n                const id_token = yield OidcClient.getCall(id_token_url);\n                (0, core_1.setSecret)(id_token);\n                return id_token;\n            }\n            catch (error) {\n                throw new Error(`Error message: ${error.message}`);\n            }\n        });\n    }\n}\nexports.OidcClient = OidcClient;\n//# sourceMappingURL=oidc-utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toPlatformPath = exports.toWin32Path = exports.toPosixPath = void 0;\nconst path = __importStar(require(\"path\"));\n/**\n * toPosixPath converts the given path to the posix form. On Windows, \\\\ will be\n * replaced with /.\n *\n * @param pth. Path to transform.\n * @return string Posix path.\n */\nfunction toPosixPath(pth) {\n    return pth.replace(/[\\\\]/g, '/');\n}\nexports.toPosixPath = toPosixPath;\n/**\n * toWin32Path converts the given path to the win32 form. On Linux, / will be\n * replaced with \\\\.\n *\n * @param pth. Path to transform.\n * @return string Win32 path.\n */\nfunction toWin32Path(pth) {\n    return pth.replace(/[/]/g, '\\\\');\n}\nexports.toWin32Path = toWin32Path;\n/**\n * toPlatformPath converts the given path to a platform-specific path. It does\n * this by replacing instances of / and \\ with the platform-specific path\n * separator.\n *\n * @param pth The path to platformize.\n * @return string The platform-specific path.\n */\nfunction toPlatformPath(pth) {\n    return pth.replace(/[/\\\\]/g, path.sep);\n}\nexports.toPlatformPath = toPlatformPath;\n//# sourceMappingURL=path-utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getDetails = exports.isLinux = exports.isMacOS = exports.isWindows = exports.arch = exports.platform = void 0;\nconst os_1 = __importDefault(require(\"os\"));\nconst exec = __importStar(require(\"@actions/exec\"));\nconst getWindowsInfo = () => __awaiter(void 0, void 0, void 0, function* () {\n    const { stdout: version } = yield exec.getExecOutput('powershell -command \"(Get-CimInstance -ClassName Win32_OperatingSystem).Version\"', undefined, {\n        silent: true\n    });\n    const { stdout: name } = yield exec.getExecOutput('powershell -command \"(Get-CimInstance -ClassName Win32_OperatingSystem).Caption\"', undefined, {\n        silent: true\n    });\n    return {\n        name: name.trim(),\n        version: version.trim()\n    };\n});\nconst getMacOsInfo = () => __awaiter(void 0, void 0, void 0, function* () {\n    var _a, _b, _c, _d;\n    const { stdout } = yield exec.getExecOutput('sw_vers', undefined, {\n        silent: true\n    });\n    const version = (_b = (_a = stdout.match(/ProductVersion:\\s*(.+)/)) === null || _a === void 0 ? void 0 : _a[1]) !== null && _b !== void 0 ? _b : '';\n    const name = (_d = (_c = stdout.match(/ProductName:\\s*(.+)/)) === null || _c === void 0 ? void 0 : _c[1]) !== null && _d !== void 0 ? _d : '';\n    return {\n        name,\n        version\n    };\n});\nconst getLinuxInfo = () => __awaiter(void 0, void 0, void 0, function* () {\n    const { stdout } = yield exec.getExecOutput('lsb_release', ['-i', '-r', '-s'], {\n        silent: true\n    });\n    const [name, version] = stdout.trim().split('\\n');\n    return {\n        name,\n        version\n    };\n});\nexports.platform = os_1.default.platform();\nexports.arch = os_1.default.arch();\nexports.isWindows = exports.platform === 'win32';\nexports.isMacOS = exports.platform === 'darwin';\nexports.isLinux = exports.platform === 'linux';\nfunction getDetails() {\n    return __awaiter(this, void 0, void 0, function* () {\n        return Object.assign(Object.assign({}, (yield (exports.isWindows\n            ? getWindowsInfo()\n            : exports.isMacOS\n                ? getMacOsInfo()\n                : getLinuxInfo()))), { platform: exports.platform,\n            arch: exports.arch,\n            isWindows: exports.isWindows,\n            isMacOS: exports.isMacOS,\n            isLinux: exports.isLinux });\n    });\n}\nexports.getDetails = getDetails;\n//# sourceMappingURL=platform.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.summary = exports.markdownSummary = exports.SUMMARY_DOCS_URL = exports.SUMMARY_ENV_VAR = void 0;\nconst os_1 = require(\"os\");\nconst fs_1 = require(\"fs\");\nconst { access, appendFile, writeFile } = fs_1.promises;\nexports.SUMMARY_ENV_VAR = 'GITHUB_STEP_SUMMARY';\nexports.SUMMARY_DOCS_URL = 'https://docs.github.com/actions/using-workflows/workflow-commands-for-github-actions#adding-a-job-summary';\nclass Summary {\n    constructor() {\n        this._buffer = '';\n    }\n    /**\n     * Finds the summary file path from the environment, rejects if env var is not found or file does not exist\n     * Also checks r/w permissions.\n     *\n     * @returns step summary file path\n     */\n    filePath() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._filePath) {\n                return this._filePath;\n            }\n            const pathFromEnv = process.env[exports.SUMMARY_ENV_VAR];\n            if (!pathFromEnv) {\n                throw new Error(`Unable to find environment variable for $${exports.SUMMARY_ENV_VAR}. Check if your runtime environment supports job summaries.`);\n            }\n            try {\n                yield access(pathFromEnv, fs_1.constants.R_OK | fs_1.constants.W_OK);\n            }\n            catch (_a) {\n                throw new Error(`Unable to access summary file: '${pathFromEnv}'. Check if the file has correct read/write permissions.`);\n            }\n            this._filePath = pathFromEnv;\n            return this._filePath;\n        });\n    }\n    /**\n     * Wraps content in an HTML tag, adding any HTML attributes\n     *\n     * @param {string} tag HTML tag to wrap\n     * @param {string | null} content content within the tag\n     * @param {[attribute: string]: string} attrs key-value list of HTML attributes to add\n     *\n     * @returns {string} content wrapped in HTML element\n     */\n    wrap(tag, content, attrs = {}) {\n        const htmlAttrs = Object.entries(attrs)\n            .map(([key, value]) => ` ${key}=\"${value}\"`)\n            .join('');\n        if (!content) {\n            return `<${tag}${htmlAttrs}>`;\n        }\n        return `<${tag}${htmlAttrs}>${content}</${tag}>`;\n    }\n    /**\n     * Writes text in the buffer to the summary buffer file and empties buffer. Will append by default.\n     *\n     * @param {SummaryWriteOptions} [options] (optional) options for write operation\n     *\n     * @returns {Promise<Summary>} summary instance\n     */\n    write(options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const overwrite = !!(options === null || options === void 0 ? void 0 : options.overwrite);\n            const filePath = yield this.filePath();\n            const writeFunc = overwrite ? writeFile : appendFile;\n            yield writeFunc(filePath, this._buffer, { encoding: 'utf8' });\n            return this.emptyBuffer();\n        });\n    }\n    /**\n     * Clears the summary buffer and wipes the summary file\n     *\n     * @returns {Summary} summary instance\n     */\n    clear() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.emptyBuffer().write({ overwrite: true });\n        });\n    }\n    /**\n     * Returns the current summary buffer as a string\n     *\n     * @returns {string} string of summary buffer\n     */\n    stringify() {\n        return this._buffer;\n    }\n    /**\n     * If the summary buffer is empty\n     *\n     * @returns {boolen} true if the buffer is empty\n     */\n    isEmptyBuffer() {\n        return this._buffer.length === 0;\n    }\n    /**\n     * Resets the summary buffer without writing to summary file\n     *\n     * @returns {Summary} summary instance\n     */\n    emptyBuffer() {\n        this._buffer = '';\n        return this;\n    }\n    /**\n     * Adds raw text to the summary buffer\n     *\n     * @param {string} text content to add\n     * @param {boolean} [addEOL=false] (optional) append an EOL to the raw text (default: false)\n     *\n     * @returns {Summary} summary instance\n     */\n    addRaw(text, addEOL = false) {\n        this._buffer += text;\n        return addEOL ? this.addEOL() : this;\n    }\n    /**\n     * Adds the operating system-specific end-of-line marker to the buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addEOL() {\n        return this.addRaw(os_1.EOL);\n    }\n    /**\n     * Adds an HTML codeblock to the summary buffer\n     *\n     * @param {string} code content to render within fenced code block\n     * @param {string} lang (optional) language to syntax highlight code\n     *\n     * @returns {Summary} summary instance\n     */\n    addCodeBlock(code, lang) {\n        const attrs = Object.assign({}, (lang && { lang }));\n        const element = this.wrap('pre', this.wrap('code', code), attrs);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML list to the summary buffer\n     *\n     * @param {string[]} items list of items to render\n     * @param {boolean} [ordered=false] (optional) if the rendered list should be ordered or not (default: false)\n     *\n     * @returns {Summary} summary instance\n     */\n    addList(items, ordered = false) {\n        const tag = ordered ? 'ol' : 'ul';\n        const listItems = items.map(item => this.wrap('li', item)).join('');\n        const element = this.wrap(tag, listItems);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML table to the summary buffer\n     *\n     * @param {SummaryTableCell[]} rows table rows\n     *\n     * @returns {Summary} summary instance\n     */\n    addTable(rows) {\n        const tableBody = rows\n            .map(row => {\n            const cells = row\n                .map(cell => {\n                if (typeof cell === 'string') {\n                    return this.wrap('td', cell);\n                }\n                const { header, data, colspan, rowspan } = cell;\n                const tag = header ? 'th' : 'td';\n                const attrs = Object.assign(Object.assign({}, (colspan && { colspan })), (rowspan && { rowspan }));\n                return this.wrap(tag, data, attrs);\n            })\n                .join('');\n            return this.wrap('tr', cells);\n        })\n            .join('');\n        const element = this.wrap('table', tableBody);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds a collapsable HTML details element to the summary buffer\n     *\n     * @param {string} label text for the closed state\n     * @param {string} content collapsable content\n     *\n     * @returns {Summary} summary instance\n     */\n    addDetails(label, content) {\n        const element = this.wrap('details', this.wrap('summary', label) + content);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML image tag to the summary buffer\n     *\n     * @param {string} src path to the image you to embed\n     * @param {string} alt text description of the image\n     * @param {SummaryImageOptions} options (optional) addition image attributes\n     *\n     * @returns {Summary} summary instance\n     */\n    addImage(src, alt, options) {\n        const { width, height } = options || {};\n        const attrs = Object.assign(Object.assign({}, (width && { width })), (height && { height }));\n        const element = this.wrap('img', null, Object.assign({ src, alt }, attrs));\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML section heading element\n     *\n     * @param {string} text heading text\n     * @param {number | string} [level=1] (optional) the heading level, default: 1\n     *\n     * @returns {Summary} summary instance\n     */\n    addHeading(text, level) {\n        const tag = `h${level}`;\n        const allowedTag = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6'].includes(tag)\n            ? tag\n            : 'h1';\n        const element = this.wrap(allowedTag, text);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML thematic break (<hr>) to the summary buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addSeparator() {\n        const element = this.wrap('hr', null);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML line break (<br>) to the summary buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addBreak() {\n        const element = this.wrap('br', null);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML blockquote to the summary buffer\n     *\n     * @param {string} text quote text\n     * @param {string} cite (optional) citation url\n     *\n     * @returns {Summary} summary instance\n     */\n    addQuote(text, cite) {\n        const attrs = Object.assign({}, (cite && { cite }));\n        const element = this.wrap('blockquote', text, attrs);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML anchor tag to the summary buffer\n     *\n     * @param {string} text link text/content\n     * @param {string} href hyperlink\n     *\n     * @returns {Summary} summary instance\n     */\n    addLink(text, href) {\n        const element = this.wrap('a', text, { href });\n        return this.addRaw(element).addEOL();\n    }\n}\nconst _summary = new Summary();\n/**\n * @deprecated use `core.summary`\n */\nexports.markdownSummary = _summary;\nexports.summary = _summary;\n//# sourceMappingURL=summary.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toCommandProperties = exports.toCommandValue = void 0;\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n/**\n *\n * @param annotationProperties\n * @returns The command properties to send with the actual annotation command\n * See IssueCommandProperties: https://github.com/actions/runner/blob/main/src/Runner.Worker/ActionCommandManager.cs#L646\n */\nfunction toCommandProperties(annotationProperties) {\n    if (!Object.keys(annotationProperties).length) {\n        return {};\n    }\n    return {\n        title: annotationProperties.title,\n        file: annotationProperties.file,\n        line: annotationProperties.startLine,\n        endLine: annotationProperties.endLine,\n        col: annotationProperties.startColumn,\n        endColumn: annotationProperties.endColumn\n    };\n}\nexports.toCommandProperties = toCommandProperties;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getExecOutput = exports.exec = void 0;\nconst string_decoder_1 = require(\"string_decoder\");\nconst tr = __importStar(require(\"./toolrunner\"));\n/**\n * Exec a command.\n * Output will be streamed to the live console.\n * Returns promise with return code\n *\n * @param     commandLine        command to execute (can include additional args). Must be correctly escaped.\n * @param     args               optional arguments for tool. Escaping is handled by the lib.\n * @param     options            optional exec options.  See ExecOptions\n * @returns   Promise<number>    exit code\n */\nfunction exec(commandLine, args, options) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const commandArgs = tr.argStringToArray(commandLine);\n        if (commandArgs.length === 0) {\n            throw new Error(`Parameter 'commandLine' cannot be null or empty.`);\n        }\n        // Path to tool to execute should be first arg\n        const toolPath = commandArgs[0];\n        args = commandArgs.slice(1).concat(args || []);\n        const runner = new tr.ToolRunner(toolPath, args, options);\n        return runner.exec();\n    });\n}\nexports.exec = exec;\n/**\n * Exec a command and get the output.\n * Output will be streamed to the live console.\n * Returns promise with the exit code and collected stdout and stderr\n *\n * @param     commandLine           command to execute (can include additional args). Must be correctly escaped.\n * @param     args                  optional arguments for tool. Escaping is handled by the lib.\n * @param     options               optional exec options.  See ExecOptions\n * @returns   Promise<ExecOutput>   exit code, stdout, and stderr\n */\nfunction getExecOutput(commandLine, args, options) {\n    var _a, _b;\n    return __awaiter(this, void 0, void 0, function* () {\n        let stdout = '';\n        let stderr = '';\n        //Using string decoder covers the case where a mult-byte character is split\n        const stdoutDecoder = new string_decoder_1.StringDecoder('utf8');\n        const stderrDecoder = new string_decoder_1.StringDecoder('utf8');\n        const originalStdoutListener = (_a = options === null || options === void 0 ? void 0 : options.listeners) === null || _a === void 0 ? void 0 : _a.stdout;\n        const originalStdErrListener = (_b = options === null || options === void 0 ? void 0 : options.listeners) === null || _b === void 0 ? void 0 : _b.stderr;\n        const stdErrListener = (data) => {\n            stderr += stderrDecoder.write(data);\n            if (originalStdErrListener) {\n                originalStdErrListener(data);\n            }\n        };\n        const stdOutListener = (data) => {\n            stdout += stdoutDecoder.write(data);\n            if (originalStdoutListener) {\n                originalStdoutListener(data);\n            }\n        };\n        const listeners = Object.assign(Object.assign({}, options === null || options === void 0 ? void 0 : options.listeners), { stdout: stdOutListener, stderr: stdErrListener });\n        const exitCode = yield exec(commandLine, args, Object.assign(Object.assign({}, options), { listeners }));\n        //flush any remaining characters\n        stdout += stdoutDecoder.end();\n        stderr += stderrDecoder.end();\n        return {\n            exitCode,\n            stdout,\n            stderr\n        };\n    });\n}\nexports.getExecOutput = getExecOutput;\n//# sourceMappingURL=exec.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.argStringToArray = exports.ToolRunner = void 0;\nconst os = __importStar(require(\"os\"));\nconst events = __importStar(require(\"events\"));\nconst child = __importStar(require(\"child_process\"));\nconst path = __importStar(require(\"path\"));\nconst io = __importStar(require(\"@actions/io\"));\nconst ioUtil = __importStar(require(\"@actions/io/lib/io-util\"));\nconst timers_1 = require(\"timers\");\n/* eslint-disable @typescript-eslint/unbound-method */\nconst IS_WINDOWS = process.platform === 'win32';\n/*\n * Class for running command line tools. Handles quoting and arg parsing in a platform agnostic way.\n */\nclass ToolRunner extends events.EventEmitter {\n    constructor(toolPath, args, options) {\n        super();\n        if (!toolPath) {\n            throw new Error(\"Parameter 'toolPath' cannot be null or empty.\");\n        }\n        this.toolPath = toolPath;\n        this.args = args || [];\n        this.options = options || {};\n    }\n    _debug(message) {\n        if (this.options.listeners && this.options.listeners.debug) {\n            this.options.listeners.debug(message);\n        }\n    }\n    _getCommandString(options, noPrefix) {\n        const toolPath = this._getSpawnFileName();\n        const args = this._getSpawnArgs(options);\n        let cmd = noPrefix ? '' : '[command]'; // omit prefix when piped to a second tool\n        if (IS_WINDOWS) {\n            // Windows + cmd file\n            if (this._isCmdFile()) {\n                cmd += toolPath;\n                for (const a of args) {\n                    cmd += ` ${a}`;\n                }\n            }\n            // Windows + verbatim\n            else if (options.windowsVerbatimArguments) {\n                cmd += `\"${toolPath}\"`;\n                for (const a of args) {\n                    cmd += ` ${a}`;\n                }\n            }\n            // Windows (regular)\n            else {\n                cmd += this._windowsQuoteCmdArg(toolPath);\n                for (const a of args) {\n                    cmd += ` ${this._windowsQuoteCmdArg(a)}`;\n                }\n            }\n        }\n        else {\n            // OSX/Linux - this can likely be improved with some form of quoting.\n            // creating processes on Unix is fundamentally different than Windows.\n            // on Unix, execvp() takes an arg array.\n            cmd += toolPath;\n            for (const a of args) {\n                cmd += ` ${a}`;\n            }\n        }\n        return cmd;\n    }\n    _processLineBuffer(data, strBuffer, onLine) {\n        try {\n            let s = strBuffer + data.toString();\n            let n = s.indexOf(os.EOL);\n            while (n > -1) {\n                const line = s.substring(0, n);\n                onLine(line);\n                // the rest of the string ...\n                s = s.substring(n + os.EOL.length);\n                n = s.indexOf(os.EOL);\n            }\n            return s;\n        }\n        catch (err) {\n            // streaming lines to console is best effort.  Don't fail a build.\n            this._debug(`error processing line. Failed with error ${err}`);\n            return '';\n        }\n    }\n    _getSpawnFileName() {\n        if (IS_WINDOWS) {\n            if (this._isCmdFile()) {\n                return process.env['COMSPEC'] || 'cmd.exe';\n            }\n        }\n        return this.toolPath;\n    }\n    _getSpawnArgs(options) {\n        if (IS_WINDOWS) {\n            if (this._isCmdFile()) {\n                let argline = `/D /S /C \"${this._windowsQuoteCmdArg(this.toolPath)}`;\n                for (const a of this.args) {\n                    argline += ' ';\n                    argline += options.windowsVerbatimArguments\n                        ? a\n                        : this._windowsQuoteCmdArg(a);\n                }\n                argline += '\"';\n                return [argline];\n            }\n        }\n        return this.args;\n    }\n    _endsWith(str, end) {\n        return str.endsWith(end);\n    }\n    _isCmdFile() {\n        const upperToolPath = this.toolPath.toUpperCase();\n        return (this._endsWith(upperToolPath, '.CMD') ||\n            this._endsWith(upperToolPath, '.BAT'));\n    }\n    _windowsQuoteCmdArg(arg) {\n        // for .exe, apply the normal quoting rules that libuv applies\n        if (!this._isCmdFile()) {\n            return this._uvQuoteCmdArg(arg);\n        }\n        // otherwise apply quoting rules specific to the cmd.exe command line parser.\n        // the libuv rules are generic and are not designed specifically for cmd.exe\n        // command line parser.\n        //\n        // for a detailed description of the cmd.exe command line parser, refer to\n        // http://stackoverflow.com/questions/4094699/how-does-the-windows-command-interpreter-cmd-exe-parse-scripts/7970912#7970912\n        // need quotes for empty arg\n        if (!arg) {\n            return '\"\"';\n        }\n        // determine whether the arg needs to be quoted\n        const cmdSpecialChars = [\n            ' ',\n            '\\t',\n            '&',\n            '(',\n            ')',\n            '[',\n            ']',\n            '{',\n            '}',\n            '^',\n            '=',\n            ';',\n            '!',\n            \"'\",\n            '+',\n            ',',\n            '`',\n            '~',\n            '|',\n            '<',\n            '>',\n            '\"'\n        ];\n        let needsQuotes = false;\n        for (const char of arg) {\n            if (cmdSpecialChars.some(x => x === char)) {\n                needsQuotes = true;\n                break;\n            }\n        }\n        // short-circuit if quotes not needed\n        if (!needsQuotes) {\n            return arg;\n        }\n        // the following quoting rules are very similar to the rules that by libuv applies.\n        //\n        // 1) wrap the string in quotes\n        //\n        // 2) double-up quotes - i.e. \" => \"\"\n        //\n        //    this is different from the libuv quoting rules. libuv replaces \" with \\\", which unfortunately\n        //    doesn't work well with a cmd.exe command line.\n        //\n        //    note, replacing \" with \"\" also works well if the arg is passed to a downstream .NET console app.\n        //    for example, the command line:\n        //          foo.exe \"myarg:\"\"my val\"\"\"\n        //    is parsed by a .NET console app into an arg array:\n        //          [ \"myarg:\\\"my val\\\"\" ]\n        //    which is the same end result when applying libuv quoting rules. although the actual\n        //    command line from libuv quoting rules would look like:\n        //          foo.exe \"myarg:\\\"my val\\\"\"\n        //\n        // 3) double-up slashes that precede a quote,\n        //    e.g.  hello \\world    => \"hello \\world\"\n        //          hello\\\"world    => \"hello\\\\\"\"world\"\n        //          hello\\\\\"world   => \"hello\\\\\\\\\"\"world\"\n        //          hello world\\    => \"hello world\\\\\"\n        //\n        //    technically this is not required for a cmd.exe command line, or the batch argument parser.\n        //    the reasons for including this as a .cmd quoting rule are:\n        //\n        //    a) this is optimized for the scenario where the argument is passed from the .cmd file to an\n        //       external program. many programs (e.g. .NET console apps) rely on the slash-doubling rule.\n        //\n        //    b) it's what we've been doing previously (by deferring to node default behavior) and we\n        //       haven't heard any complaints about that aspect.\n        //\n        // note, a weakness of the quoting rules chosen here, is that % is not escaped. in fact, % cannot be\n        // escaped when used on the command line directly - even though within a .cmd file % can be escaped\n        // by using %%.\n        //\n        // the saving grace is, on the command line, %var% is left as-is if var is not defined. this contrasts\n        // the line parsing rules within a .cmd file, where if var is not defined it is replaced with nothing.\n        //\n        // one option that was explored was replacing % with ^% - i.e. %var% => ^%var^%. this hack would\n        // often work, since it is unlikely that var^ would exist, and the ^ character is removed when the\n        // variable is used. the problem, however, is that ^ is not removed when %* is used to pass the args\n        // to an external program.\n        //\n        // an unexplored potential solution for the % escaping problem, is to create a wrapper .cmd file.\n        // % can be escaped within a .cmd file.\n        let reverse = '\"';\n        let quoteHit = true;\n        for (let i = arg.length; i > 0; i--) {\n            // walk the string in reverse\n            reverse += arg[i - 1];\n            if (quoteHit && arg[i - 1] === '\\\\') {\n                reverse += '\\\\'; // double the slash\n            }\n            else if (arg[i - 1] === '\"') {\n                quoteHit = true;\n                reverse += '\"'; // double the quote\n            }\n            else {\n                quoteHit = false;\n            }\n        }\n        reverse += '\"';\n        return reverse\n            .split('')\n            .reverse()\n            .join('');\n    }\n    _uvQuoteCmdArg(arg) {\n        // Tool runner wraps child_process.spawn() and needs to apply the same quoting as\n        // Node in certain cases where the undocumented spawn option windowsVerbatimArguments\n        // is used.\n        //\n        // Since this function is a port of quote_cmd_arg from Node 4.x (technically, lib UV,\n        // see https://github.com/nodejs/node/blob/v4.x/deps/uv/src/win/process.c for details),\n        // pasting copyright notice from Node within this function:\n        //\n        //      Copyright Joyent, Inc. and other Node contributors. All rights reserved.\n        //\n        //      Permission is hereby granted, free of charge, to any person obtaining a copy\n        //      of this software and associated documentation files (the \"Software\"), to\n        //      deal in the Software without restriction, including without limitation the\n        //      rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n        //      sell copies of the Software, and to permit persons to whom the Software is\n        //      furnished to do so, subject to the following conditions:\n        //\n        //      The above copyright notice and this permission notice shall be included in\n        //      all copies or substantial portions of the Software.\n        //\n        //      THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n        //      IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n        //      FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n        //      AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n        //      LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n        //      FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n        //      IN THE SOFTWARE.\n        if (!arg) {\n            // Need double quotation for empty argument\n            return '\"\"';\n        }\n        if (!arg.includes(' ') && !arg.includes('\\t') && !arg.includes('\"')) {\n            // No quotation needed\n            return arg;\n        }\n        if (!arg.includes('\"') && !arg.includes('\\\\')) {\n            // No embedded double quotes or backslashes, so I can just wrap\n            // quote marks around the whole thing.\n            return `\"${arg}\"`;\n        }\n        // Expected input/output:\n        //   input : hello\"world\n        //   output: \"hello\\\"world\"\n        //   input : hello\"\"world\n        //   output: \"hello\\\"\\\"world\"\n        //   input : hello\\world\n        //   output: hello\\world\n        //   input : hello\\\\world\n        //   output: hello\\\\world\n        //   input : hello\\\"world\n        //   output: \"hello\\\\\\\"world\"\n        //   input : hello\\\\\"world\n        //   output: \"hello\\\\\\\\\\\"world\"\n        //   input : hello world\\\n        //   output: \"hello world\\\\\" - note the comment in libuv actually reads \"hello world\\\"\n        //                             but it appears the comment is wrong, it should be \"hello world\\\\\"\n        let reverse = '\"';\n        let quoteHit = true;\n        for (let i = arg.length; i > 0; i--) {\n            // walk the string in reverse\n            reverse += arg[i - 1];\n            if (quoteHit && arg[i - 1] === '\\\\') {\n                reverse += '\\\\';\n            }\n            else if (arg[i - 1] === '\"') {\n                quoteHit = true;\n                reverse += '\\\\';\n            }\n            else {\n                quoteHit = false;\n            }\n        }\n        reverse += '\"';\n        return reverse\n            .split('')\n            .reverse()\n            .join('');\n    }\n    _cloneExecOptions(options) {\n        options = options || {};\n        const result = {\n            cwd: options.cwd || process.cwd(),\n            env: options.env || process.env,\n            silent: options.silent || false,\n            windowsVerbatimArguments: options.windowsVerbatimArguments || false,\n            failOnStdErr: options.failOnStdErr || false,\n            ignoreReturnCode: options.ignoreReturnCode || false,\n            delay: options.delay || 10000\n        };\n        result.outStream = options.outStream || process.stdout;\n        result.errStream = options.errStream || process.stderr;\n        return result;\n    }\n    _getSpawnOptions(options, toolPath) {\n        options = options || {};\n        const result = {};\n        result.cwd = options.cwd;\n        result.env = options.env;\n        result['windowsVerbatimArguments'] =\n            options.windowsVerbatimArguments || this._isCmdFile();\n        if (options.windowsVerbatimArguments) {\n            result.argv0 = `\"${toolPath}\"`;\n        }\n        return result;\n    }\n    /**\n     * Exec a tool.\n     * Output will be streamed to the live console.\n     * Returns promise with return code\n     *\n     * @param     tool     path to tool to exec\n     * @param     options  optional exec options.  See ExecOptions\n     * @returns   number\n     */\n    exec() {\n        return __awaiter(this, void 0, void 0, function* () {\n            // root the tool path if it is unrooted and contains relative pathing\n            if (!ioUtil.isRooted(this.toolPath) &&\n                (this.toolPath.includes('/') ||\n                    (IS_WINDOWS && this.toolPath.includes('\\\\')))) {\n                // prefer options.cwd if it is specified, however options.cwd may also need to be rooted\n                this.toolPath = path.resolve(process.cwd(), this.options.cwd || process.cwd(), this.toolPath);\n            }\n            // if the tool is only a file name, then resolve it from the PATH\n            // otherwise verify it exists (add extension on Windows if necessary)\n            this.toolPath = yield io.which(this.toolPath, true);\n            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {\n                this._debug(`exec tool: ${this.toolPath}`);\n                this._debug('arguments:');\n                for (const arg of this.args) {\n                    this._debug(`   ${arg}`);\n                }\n                const optionsNonNull = this._cloneExecOptions(this.options);\n                if (!optionsNonNull.silent && optionsNonNull.outStream) {\n                    optionsNonNull.outStream.write(this._getCommandString(optionsNonNull) + os.EOL);\n                }\n                const state = new ExecState(optionsNonNull, this.toolPath);\n                state.on('debug', (message) => {\n                    this._debug(message);\n                });\n                if (this.options.cwd && !(yield ioUtil.exists(this.options.cwd))) {\n                    return reject(new Error(`The cwd: ${this.options.cwd} does not exist!`));\n                }\n                const fileName = this._getSpawnFileName();\n                const cp = child.spawn(fileName, this._getSpawnArgs(optionsNonNull), this._getSpawnOptions(this.options, fileName));\n                let stdbuffer = '';\n                if (cp.stdout) {\n                    cp.stdout.on('data', (data) => {\n                        if (this.options.listeners && this.options.listeners.stdout) {\n                            this.options.listeners.stdout(data);\n                        }\n                        if (!optionsNonNull.silent && optionsNonNull.outStream) {\n                            optionsNonNull.outStream.write(data);\n                        }\n                        stdbuffer = this._processLineBuffer(data, stdbuffer, (line) => {\n                            if (this.options.listeners && this.options.listeners.stdline) {\n                                this.options.listeners.stdline(line);\n                            }\n                        });\n                    });\n                }\n                let errbuffer = '';\n                if (cp.stderr) {\n                    cp.stderr.on('data', (data) => {\n                        state.processStderr = true;\n                        if (this.options.listeners && this.options.listeners.stderr) {\n                            this.options.listeners.stderr(data);\n                        }\n                        if (!optionsNonNull.silent &&\n                            optionsNonNull.errStream &&\n                            optionsNonNull.outStream) {\n                            const s = optionsNonNull.failOnStdErr\n                                ? optionsNonNull.errStream\n                                : optionsNonNull.outStream;\n                            s.write(data);\n                        }\n                        errbuffer = this._processLineBuffer(data, errbuffer, (line) => {\n                            if (this.options.listeners && this.options.listeners.errline) {\n                                this.options.listeners.errline(line);\n                            }\n                        });\n                    });\n                }\n                cp.on('error', (err) => {\n                    state.processError = err.message;\n                    state.processExited = true;\n                    state.processClosed = true;\n                    state.CheckComplete();\n                });\n                cp.on('exit', (code) => {\n                    state.processExitCode = code;\n                    state.processExited = true;\n                    this._debug(`Exit code ${code} received from tool '${this.toolPath}'`);\n                    state.CheckComplete();\n                });\n                cp.on('close', (code) => {\n                    state.processExitCode = code;\n                    state.processExited = true;\n                    state.processClosed = true;\n                    this._debug(`STDIO streams have closed for tool '${this.toolPath}'`);\n                    state.CheckComplete();\n                });\n                state.on('done', (error, exitCode) => {\n                    if (stdbuffer.length > 0) {\n                        this.emit('stdline', stdbuffer);\n                    }\n                    if (errbuffer.length > 0) {\n                        this.emit('errline', errbuffer);\n                    }\n                    cp.removeAllListeners();\n                    if (error) {\n                        reject(error);\n                    }\n                    else {\n                        resolve(exitCode);\n                    }\n                });\n                if (this.options.input) {\n                    if (!cp.stdin) {\n                        throw new Error('child process missing stdin');\n                    }\n                    cp.stdin.end(this.options.input);\n                }\n            }));\n        });\n    }\n}\nexports.ToolRunner = ToolRunner;\n/**\n * Convert an arg string to an array of args. Handles escaping\n *\n * @param    argString   string of arguments\n * @returns  string[]    array of arguments\n */\nfunction argStringToArray(argString) {\n    const args = [];\n    let inQuotes = false;\n    let escaped = false;\n    let arg = '';\n    function append(c) {\n        // we only escape double quotes.\n        if (escaped && c !== '\"') {\n            arg += '\\\\';\n        }\n        arg += c;\n        escaped = false;\n    }\n    for (let i = 0; i < argString.length; i++) {\n        const c = argString.charAt(i);\n        if (c === '\"') {\n            if (!escaped) {\n                inQuotes = !inQuotes;\n            }\n            else {\n                append(c);\n            }\n            continue;\n        }\n        if (c === '\\\\' && escaped) {\n            append(c);\n            continue;\n        }\n        if (c === '\\\\' && inQuotes) {\n            escaped = true;\n            continue;\n        }\n        if (c === ' ' && !inQuotes) {\n            if (arg.length > 0) {\n                args.push(arg);\n                arg = '';\n            }\n            continue;\n        }\n        append(c);\n    }\n    if (arg.length > 0) {\n        args.push(arg.trim());\n    }\n    return args;\n}\nexports.argStringToArray = argStringToArray;\nclass ExecState extends events.EventEmitter {\n    constructor(options, toolPath) {\n        super();\n        this.processClosed = false; // tracks whether the process has exited and stdio is closed\n        this.processError = '';\n        this.processExitCode = 0;\n        this.processExited = false; // tracks whether the process has exited\n        this.processStderr = false; // tracks whether stderr was written to\n        this.delay = 10000; // 10 seconds\n        this.done = false;\n        this.timeout = null;\n        if (!toolPath) {\n            throw new Error('toolPath must not be empty');\n        }\n        this.options = options;\n        this.toolPath = toolPath;\n        if (options.delay) {\n            this.delay = options.delay;\n        }\n    }\n    CheckComplete() {\n        if (this.done) {\n            return;\n        }\n        if (this.processClosed) {\n            this._setResult();\n        }\n        else if (this.processExited) {\n            this.timeout = timers_1.setTimeout(ExecState.HandleTimeout, this.delay, this);\n        }\n    }\n    _debug(message) {\n        this.emit('debug', message);\n    }\n    _setResult() {\n        // determine whether there is an error\n        let error;\n        if (this.processExited) {\n            if (this.processError) {\n                error = new Error(`There was an error when attempting to execute the process '${this.toolPath}'. This may indicate the process failed to start. Error: ${this.processError}`);\n            }\n            else if (this.processExitCode !== 0 && !this.options.ignoreReturnCode) {\n                error = new Error(`The process '${this.toolPath}' failed with exit code ${this.processExitCode}`);\n            }\n            else if (this.processStderr && this.options.failOnStdErr) {\n                error = new Error(`The process '${this.toolPath}' failed because one or more lines were written to the STDERR stream`);\n            }\n        }\n        // clear the timeout\n        if (this.timeout) {\n            clearTimeout(this.timeout);\n            this.timeout = null;\n        }\n        this.done = true;\n        this.emit('done', error, this.processExitCode);\n    }\n    static HandleTimeout(state) {\n        if (state.done) {\n            return;\n        }\n        if (!state.processClosed && state.processExited) {\n            const message = `The STDIO streams did not close within ${state.delay /\n                1000} seconds of the exit event from process '${state.toolPath}'. This may indicate a child process inherited the STDIO streams and has not yet exited.`;\n            state._debug(message);\n        }\n        state._setResult();\n    }\n}\n//# sourceMappingURL=toolrunner.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.PersonalAccessTokenCredentialHandler = exports.BearerCredentialHandler = exports.BasicCredentialHandler = void 0;\nclass BasicCredentialHandler {\n    constructor(username, password) {\n        this.username = username;\n        this.password = password;\n    }\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Basic ${Buffer.from(`${this.username}:${this.password}`).toString('base64')}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.BasicCredentialHandler = BasicCredentialHandler;\nclass BearerCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Bearer ${this.token}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.BearerCredentialHandler = BearerCredentialHandler;\nclass PersonalAccessTokenCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Basic ${Buffer.from(`PAT:${this.token}`).toString('base64')}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.PersonalAccessTokenCredentialHandler = PersonalAccessTokenCredentialHandler;\n//# sourceMappingURL=auth.js.map","\"use strict\";\n/* eslint-disable @typescript-eslint/no-explicit-any */\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.HttpClient = exports.isHttps = exports.HttpClientResponse = exports.HttpClientError = exports.getProxyUrl = exports.MediaTypes = exports.Headers = exports.HttpCodes = void 0;\nconst http = __importStar(require(\"http\"));\nconst https = __importStar(require(\"https\"));\nconst pm = __importStar(require(\"./proxy\"));\nconst tunnel = __importStar(require(\"tunnel\"));\nconst undici_1 = require(\"undici\");\nvar HttpCodes;\n(function (HttpCodes) {\n    HttpCodes[HttpCodes[\"OK\"] = 200] = \"OK\";\n    HttpCodes[HttpCodes[\"MultipleChoices\"] = 300] = \"MultipleChoices\";\n    HttpCodes[HttpCodes[\"MovedPermanently\"] = 301] = \"MovedPermanently\";\n    HttpCodes[HttpCodes[\"ResourceMoved\"] = 302] = \"ResourceMoved\";\n    HttpCodes[HttpCodes[\"SeeOther\"] = 303] = \"SeeOther\";\n    HttpCodes[HttpCodes[\"NotModified\"] = 304] = \"NotModified\";\n    HttpCodes[HttpCodes[\"UseProxy\"] = 305] = \"UseProxy\";\n    HttpCodes[HttpCodes[\"SwitchProxy\"] = 306] = \"SwitchProxy\";\n    HttpCodes[HttpCodes[\"TemporaryRedirect\"] = 307] = \"TemporaryRedirect\";\n    HttpCodes[HttpCodes[\"PermanentRedirect\"] = 308] = \"PermanentRedirect\";\n    HttpCodes[HttpCodes[\"BadRequest\"] = 400] = \"BadRequest\";\n    HttpCodes[HttpCodes[\"Unauthorized\"] = 401] = \"Unauthorized\";\n    HttpCodes[HttpCodes[\"PaymentRequired\"] = 402] = \"PaymentRequired\";\n    HttpCodes[HttpCodes[\"Forbidden\"] = 403] = \"Forbidden\";\n    HttpCodes[HttpCodes[\"NotFound\"] = 404] = \"NotFound\";\n    HttpCodes[HttpCodes[\"MethodNotAllowed\"] = 405] = \"MethodNotAllowed\";\n    HttpCodes[HttpCodes[\"NotAcceptable\"] = 406] = \"NotAcceptable\";\n    HttpCodes[HttpCodes[\"ProxyAuthenticationRequired\"] = 407] = \"ProxyAuthenticationRequired\";\n    HttpCodes[HttpCodes[\"RequestTimeout\"] = 408] = \"RequestTimeout\";\n    HttpCodes[HttpCodes[\"Conflict\"] = 409] = \"Conflict\";\n    HttpCodes[HttpCodes[\"Gone\"] = 410] = \"Gone\";\n    HttpCodes[HttpCodes[\"TooManyRequests\"] = 429] = \"TooManyRequests\";\n    HttpCodes[HttpCodes[\"InternalServerError\"] = 500] = \"InternalServerError\";\n    HttpCodes[HttpCodes[\"NotImplemented\"] = 501] = \"NotImplemented\";\n    HttpCodes[HttpCodes[\"BadGateway\"] = 502] = \"BadGateway\";\n    HttpCodes[HttpCodes[\"ServiceUnavailable\"] = 503] = \"ServiceUnavailable\";\n    HttpCodes[HttpCodes[\"GatewayTimeout\"] = 504] = \"GatewayTimeout\";\n})(HttpCodes || (exports.HttpCodes = HttpCodes = {}));\nvar Headers;\n(function (Headers) {\n    Headers[\"Accept\"] = \"accept\";\n    Headers[\"ContentType\"] = \"content-type\";\n})(Headers || (exports.Headers = Headers = {}));\nvar MediaTypes;\n(function (MediaTypes) {\n    MediaTypes[\"ApplicationJson\"] = \"application/json\";\n})(MediaTypes || (exports.MediaTypes = MediaTypes = {}));\n/**\n * Returns the proxy URL, depending upon the supplied url and proxy environment variables.\n * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n */\nfunction getProxyUrl(serverUrl) {\n    const proxyUrl = pm.getProxyUrl(new URL(serverUrl));\n    return proxyUrl ? proxyUrl.href : '';\n}\nexports.getProxyUrl = getProxyUrl;\nconst HttpRedirectCodes = [\n    HttpCodes.MovedPermanently,\n    HttpCodes.ResourceMoved,\n    HttpCodes.SeeOther,\n    HttpCodes.TemporaryRedirect,\n    HttpCodes.PermanentRedirect\n];\nconst HttpResponseRetryCodes = [\n    HttpCodes.BadGateway,\n    HttpCodes.ServiceUnavailable,\n    HttpCodes.GatewayTimeout\n];\nconst RetryableHttpVerbs = ['OPTIONS', 'GET', 'DELETE', 'HEAD'];\nconst ExponentialBackoffCeiling = 10;\nconst ExponentialBackoffTimeSlice = 5;\nclass HttpClientError extends Error {\n    constructor(message, statusCode) {\n        super(message);\n        this.name = 'HttpClientError';\n        this.statusCode = statusCode;\n        Object.setPrototypeOf(this, HttpClientError.prototype);\n    }\n}\nexports.HttpClientError = HttpClientError;\nclass HttpClientResponse {\n    constructor(message) {\n        this.message = message;\n    }\n    readBody() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {\n                let output = Buffer.alloc(0);\n                this.message.on('data', (chunk) => {\n                    output = Buffer.concat([output, chunk]);\n                });\n                this.message.on('end', () => {\n                    resolve(output.toString());\n                });\n            }));\n        });\n    }\n    readBodyBuffer() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {\n                const chunks = [];\n                this.message.on('data', (chunk) => {\n                    chunks.push(chunk);\n                });\n                this.message.on('end', () => {\n                    resolve(Buffer.concat(chunks));\n                });\n            }));\n        });\n    }\n}\nexports.HttpClientResponse = HttpClientResponse;\nfunction isHttps(requestUrl) {\n    const parsedUrl = new URL(requestUrl);\n    return parsedUrl.protocol === 'https:';\n}\nexports.isHttps = isHttps;\nclass HttpClient {\n    constructor(userAgent, handlers, requestOptions) {\n        this._ignoreSslError = false;\n        this._allowRedirects = true;\n        this._allowRedirectDowngrade = false;\n        this._maxRedirects = 50;\n        this._allowRetries = false;\n        this._maxRetries = 1;\n        this._keepAlive = false;\n        this._disposed = false;\n        this.userAgent = userAgent;\n        this.handlers = handlers || [];\n        this.requestOptions = requestOptions;\n        if (requestOptions) {\n            if (requestOptions.ignoreSslError != null) {\n                this._ignoreSslError = requestOptions.ignoreSslError;\n            }\n            this._socketTimeout = requestOptions.socketTimeout;\n            if (requestOptions.allowRedirects != null) {\n                this._allowRedirects = requestOptions.allowRedirects;\n            }\n            if (requestOptions.allowRedirectDowngrade != null) {\n                this._allowRedirectDowngrade = requestOptions.allowRedirectDowngrade;\n            }\n            if (requestOptions.maxRedirects != null) {\n                this._maxRedirects = Math.max(requestOptions.maxRedirects, 0);\n            }\n            if (requestOptions.keepAlive != null) {\n                this._keepAlive = requestOptions.keepAlive;\n            }\n            if (requestOptions.allowRetries != null) {\n                this._allowRetries = requestOptions.allowRetries;\n            }\n            if (requestOptions.maxRetries != null) {\n                this._maxRetries = requestOptions.maxRetries;\n            }\n        }\n    }\n    options(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('OPTIONS', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    get(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('GET', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    del(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('DELETE', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    post(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('POST', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    patch(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('PATCH', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    put(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('PUT', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    head(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('HEAD', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    sendStream(verb, requestUrl, stream, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request(verb, requestUrl, stream, additionalHeaders);\n        });\n    }\n    /**\n     * Gets a typed object from an endpoint\n     * Be aware that not found returns a null.  Other errors (4xx, 5xx) reject the promise\n     */\n    getJson(requestUrl, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            const res = yield this.get(requestUrl, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    postJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.post(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    putJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.put(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    patchJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.patch(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    /**\n     * Makes a raw http request.\n     * All other methods such as get, post, patch, and request ultimately call this.\n     * Prefer get, del, post and patch\n     */\n    request(verb, requestUrl, data, headers) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._disposed) {\n                throw new Error('Client has already been disposed.');\n            }\n            const parsedUrl = new URL(requestUrl);\n            let info = this._prepareRequest(verb, parsedUrl, headers);\n            // Only perform retries on reads since writes may not be idempotent.\n            const maxTries = this._allowRetries && RetryableHttpVerbs.includes(verb)\n                ? this._maxRetries + 1\n                : 1;\n            let numTries = 0;\n            let response;\n            do {\n                response = yield this.requestRaw(info, data);\n                // Check if it's an authentication challenge\n                if (response &&\n                    response.message &&\n                    response.message.statusCode === HttpCodes.Unauthorized) {\n                    let authenticationHandler;\n                    for (const handler of this.handlers) {\n                        if (handler.canHandleAuthentication(response)) {\n                            authenticationHandler = handler;\n                            break;\n                        }\n                    }\n                    if (authenticationHandler) {\n                        return authenticationHandler.handleAuthentication(this, info, data);\n                    }\n                    else {\n                        // We have received an unauthorized response but have no handlers to handle it.\n                        // Let the response return to the caller.\n                        return response;\n                    }\n                }\n                let redirectsRemaining = this._maxRedirects;\n                while (response.message.statusCode &&\n                    HttpRedirectCodes.includes(response.message.statusCode) &&\n                    this._allowRedirects &&\n                    redirectsRemaining > 0) {\n                    const redirectUrl = response.message.headers['location'];\n                    if (!redirectUrl) {\n                        // if there's no location to redirect to, we won't\n                        break;\n                    }\n                    const parsedRedirectUrl = new URL(redirectUrl);\n                    if (parsedUrl.protocol === 'https:' &&\n                        parsedUrl.protocol !== parsedRedirectUrl.protocol &&\n                        !this._allowRedirectDowngrade) {\n                        throw new Error('Redirect from HTTPS to HTTP protocol. This downgrade is not allowed for security reasons. If you want to allow this behavior, set the allowRedirectDowngrade option to true.');\n                    }\n                    // we need to finish reading the response before reassigning response\n                    // which will leak the open socket.\n                    yield response.readBody();\n                    // strip authorization header if redirected to a different hostname\n                    if (parsedRedirectUrl.hostname !== parsedUrl.hostname) {\n                        for (const header in headers) {\n                            // header names are case insensitive\n                            if (header.toLowerCase() === 'authorization') {\n                                delete headers[header];\n                            }\n                        }\n                    }\n                    // let's make the request with the new redirectUrl\n                    info = this._prepareRequest(verb, parsedRedirectUrl, headers);\n                    response = yield this.requestRaw(info, data);\n                    redirectsRemaining--;\n                }\n                if (!response.message.statusCode ||\n                    !HttpResponseRetryCodes.includes(response.message.statusCode)) {\n                    // If not a retry code, return immediately instead of retrying\n                    return response;\n                }\n                numTries += 1;\n                if (numTries < maxTries) {\n                    yield response.readBody();\n                    yield this._performExponentialBackoff(numTries);\n                }\n            } while (numTries < maxTries);\n            return response;\n        });\n    }\n    /**\n     * Needs to be called if keepAlive is set to true in request options.\n     */\n    dispose() {\n        if (this._agent) {\n            this._agent.destroy();\n        }\n        this._disposed = true;\n    }\n    /**\n     * Raw request.\n     * @param info\n     * @param data\n     */\n    requestRaw(info, data) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve, reject) => {\n                function callbackForResult(err, res) {\n                    if (err) {\n                        reject(err);\n                    }\n                    else if (!res) {\n                        // If `err` is not passed, then `res` must be passed.\n                        reject(new Error('Unknown error'));\n                    }\n                    else {\n                        resolve(res);\n                    }\n                }\n                this.requestRawWithCallback(info, data, callbackForResult);\n            });\n        });\n    }\n    /**\n     * Raw request with callback.\n     * @param info\n     * @param data\n     * @param onResult\n     */\n    requestRawWithCallback(info, data, onResult) {\n        if (typeof data === 'string') {\n            if (!info.options.headers) {\n                info.options.headers = {};\n            }\n            info.options.headers['Content-Length'] = Buffer.byteLength(data, 'utf8');\n        }\n        let callbackCalled = false;\n        function handleResult(err, res) {\n            if (!callbackCalled) {\n                callbackCalled = true;\n                onResult(err, res);\n            }\n        }\n        const req = info.httpModule.request(info.options, (msg) => {\n            const res = new HttpClientResponse(msg);\n            handleResult(undefined, res);\n        });\n        let socket;\n        req.on('socket', sock => {\n            socket = sock;\n        });\n        // If we ever get disconnected, we want the socket to timeout eventually\n        req.setTimeout(this._socketTimeout || 3 * 60000, () => {\n            if (socket) {\n                socket.end();\n            }\n            handleResult(new Error(`Request timeout: ${info.options.path}`));\n        });\n        req.on('error', function (err) {\n            // err has statusCode property\n            // res should have headers\n            handleResult(err);\n        });\n        if (data && typeof data === 'string') {\n            req.write(data, 'utf8');\n        }\n        if (data && typeof data !== 'string') {\n            data.on('close', function () {\n                req.end();\n            });\n            data.pipe(req);\n        }\n        else {\n            req.end();\n        }\n    }\n    /**\n     * Gets an http agent. This function is useful when you need an http agent that handles\n     * routing through a proxy server - depending upon the url and proxy environment variables.\n     * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n     */\n    getAgent(serverUrl) {\n        const parsedUrl = new URL(serverUrl);\n        return this._getAgent(parsedUrl);\n    }\n    getAgentDispatcher(serverUrl) {\n        const parsedUrl = new URL(serverUrl);\n        const proxyUrl = pm.getProxyUrl(parsedUrl);\n        const useProxy = proxyUrl && proxyUrl.hostname;\n        if (!useProxy) {\n            return;\n        }\n        return this._getProxyAgentDispatcher(parsedUrl, proxyUrl);\n    }\n    _prepareRequest(method, requestUrl, headers) {\n        const info = {};\n        info.parsedUrl = requestUrl;\n        const usingSsl = info.parsedUrl.protocol === 'https:';\n        info.httpModule = usingSsl ? https : http;\n        const defaultPort = usingSsl ? 443 : 80;\n        info.options = {};\n        info.options.host = info.parsedUrl.hostname;\n        info.options.port = info.parsedUrl.port\n            ? parseInt(info.parsedUrl.port)\n            : defaultPort;\n        info.options.path =\n            (info.parsedUrl.pathname || '') + (info.parsedUrl.search || '');\n        info.options.method = method;\n        info.options.headers = this._mergeHeaders(headers);\n        if (this.userAgent != null) {\n            info.options.headers['user-agent'] = this.userAgent;\n        }\n        info.options.agent = this._getAgent(info.parsedUrl);\n        // gives handlers an opportunity to participate\n        if (this.handlers) {\n            for (const handler of this.handlers) {\n                handler.prepareRequest(info.options);\n            }\n        }\n        return info;\n    }\n    _mergeHeaders(headers) {\n        if (this.requestOptions && this.requestOptions.headers) {\n            return Object.assign({}, lowercaseKeys(this.requestOptions.headers), lowercaseKeys(headers || {}));\n        }\n        return lowercaseKeys(headers || {});\n    }\n    _getExistingOrDefaultHeader(additionalHeaders, header, _default) {\n        let clientHeader;\n        if (this.requestOptions && this.requestOptions.headers) {\n            clientHeader = lowercaseKeys(this.requestOptions.headers)[header];\n        }\n        return additionalHeaders[header] || clientHeader || _default;\n    }\n    _getAgent(parsedUrl) {\n        let agent;\n        const proxyUrl = pm.getProxyUrl(parsedUrl);\n        const useProxy = proxyUrl && proxyUrl.hostname;\n        if (this._keepAlive && useProxy) {\n            agent = this._proxyAgent;\n        }\n        if (!useProxy) {\n            agent = this._agent;\n        }\n        // if agent is already assigned use that agent.\n        if (agent) {\n            return agent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        let maxSockets = 100;\n        if (this.requestOptions) {\n            maxSockets = this.requestOptions.maxSockets || http.globalAgent.maxSockets;\n        }\n        // This is `useProxy` again, but we need to check `proxyURl` directly for TypeScripts's flow analysis.\n        if (proxyUrl && proxyUrl.hostname) {\n            const agentOptions = {\n                maxSockets,\n                keepAlive: this._keepAlive,\n                proxy: Object.assign(Object.assign({}, ((proxyUrl.username || proxyUrl.password) && {\n                    proxyAuth: `${proxyUrl.username}:${proxyUrl.password}`\n                })), { host: proxyUrl.hostname, port: proxyUrl.port })\n            };\n            let tunnelAgent;\n            const overHttps = proxyUrl.protocol === 'https:';\n            if (usingSsl) {\n                tunnelAgent = overHttps ? tunnel.httpsOverHttps : tunnel.httpsOverHttp;\n            }\n            else {\n                tunnelAgent = overHttps ? tunnel.httpOverHttps : tunnel.httpOverHttp;\n            }\n            agent = tunnelAgent(agentOptions);\n            this._proxyAgent = agent;\n        }\n        // if tunneling agent isn't assigned create a new agent\n        if (!agent) {\n            const options = { keepAlive: this._keepAlive, maxSockets };\n            agent = usingSsl ? new https.Agent(options) : new http.Agent(options);\n            this._agent = agent;\n        }\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            agent.options = Object.assign(agent.options || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return agent;\n    }\n    _getProxyAgentDispatcher(parsedUrl, proxyUrl) {\n        let proxyAgent;\n        if (this._keepAlive) {\n            proxyAgent = this._proxyAgentDispatcher;\n        }\n        // if agent is already assigned use that agent.\n        if (proxyAgent) {\n            return proxyAgent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        proxyAgent = new undici_1.ProxyAgent(Object.assign({ uri: proxyUrl.href, pipelining: !this._keepAlive ? 0 : 1 }, ((proxyUrl.username || proxyUrl.password) && {\n            token: `Basic ${Buffer.from(`${proxyUrl.username}:${proxyUrl.password}`).toString('base64')}`\n        })));\n        this._proxyAgentDispatcher = proxyAgent;\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            proxyAgent.options = Object.assign(proxyAgent.options.requestTls || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return proxyAgent;\n    }\n    _performExponentialBackoff(retryNumber) {\n        return __awaiter(this, void 0, void 0, function* () {\n            retryNumber = Math.min(ExponentialBackoffCeiling, retryNumber);\n            const ms = ExponentialBackoffTimeSlice * Math.pow(2, retryNumber);\n            return new Promise(resolve => setTimeout(() => resolve(), ms));\n        });\n    }\n    _processResponse(res, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {\n                const statusCode = res.message.statusCode || 0;\n                const response = {\n                    statusCode,\n                    result: null,\n                    headers: {}\n                };\n                // not found leads to null obj returned\n                if (statusCode === HttpCodes.NotFound) {\n                    resolve(response);\n                }\n                // get the result from the body\n                function dateTimeDeserializer(key, value) {\n                    if (typeof value === 'string') {\n                        const a = new Date(value);\n                        if (!isNaN(a.valueOf())) {\n                            return a;\n                        }\n                    }\n                    return value;\n                }\n                let obj;\n                let contents;\n                try {\n                    contents = yield res.readBody();\n                    if (contents && contents.length > 0) {\n                        if (options && options.deserializeDates) {\n                            obj = JSON.parse(contents, dateTimeDeserializer);\n                        }\n                        else {\n                            obj = JSON.parse(contents);\n                        }\n                        response.result = obj;\n                    }\n                    response.headers = res.message.headers;\n                }\n                catch (err) {\n                    // Invalid resource (contents not json);  leaving result obj null\n                }\n                // note that 3xx redirects are handled by the http layer.\n                if (statusCode > 299) {\n                    let msg;\n                    // if exception/error in body, attempt to get better error\n                    if (obj && obj.message) {\n                        msg = obj.message;\n                    }\n                    else if (contents && contents.length > 0) {\n                        // it may be the case that the exception is in the body message as string\n                        msg = contents;\n                    }\n                    else {\n                        msg = `Failed request: (${statusCode})`;\n                    }\n                    const err = new HttpClientError(msg, statusCode);\n                    err.result = response.result;\n                    reject(err);\n                }\n                else {\n                    resolve(response);\n                }\n            }));\n        });\n    }\n}\nexports.HttpClient = HttpClient;\nconst lowercaseKeys = (obj) => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.checkBypass = exports.getProxyUrl = void 0;\nfunction getProxyUrl(reqUrl) {\n    const usingSsl = reqUrl.protocol === 'https:';\n    if (checkBypass(reqUrl)) {\n        return undefined;\n    }\n    const proxyVar = (() => {\n        if (usingSsl) {\n            return process.env['https_proxy'] || process.env['HTTPS_PROXY'];\n        }\n        else {\n            return process.env['http_proxy'] || process.env['HTTP_PROXY'];\n        }\n    })();\n    if (proxyVar) {\n        try {\n            return new DecodedURL(proxyVar);\n        }\n        catch (_a) {\n            if (!proxyVar.startsWith('http://') && !proxyVar.startsWith('https://'))\n                return new DecodedURL(`http://${proxyVar}`);\n        }\n    }\n    else {\n        return undefined;\n    }\n}\nexports.getProxyUrl = getProxyUrl;\nfunction checkBypass(reqUrl) {\n    if (!reqUrl.hostname) {\n        return false;\n    }\n    const reqHost = reqUrl.hostname;\n    if (isLoopbackAddress(reqHost)) {\n        return true;\n    }\n    const noProxy = process.env['no_proxy'] || process.env['NO_PROXY'] || '';\n    if (!noProxy) {\n        return false;\n    }\n    // Determine the request port\n    let reqPort;\n    if (reqUrl.port) {\n        reqPort = Number(reqUrl.port);\n    }\n    else if (reqUrl.protocol === 'http:') {\n        reqPort = 80;\n    }\n    else if (reqUrl.protocol === 'https:') {\n        reqPort = 443;\n    }\n    // Format the request hostname and hostname with port\n    const upperReqHosts = [reqUrl.hostname.toUpperCase()];\n    if (typeof reqPort === 'number') {\n        upperReqHosts.push(`${upperReqHosts[0]}:${reqPort}`);\n    }\n    // Compare request host against noproxy\n    for (const upperNoProxyItem of noProxy\n        .split(',')\n        .map(x => x.trim().toUpperCase())\n        .filter(x => x)) {\n        if (upperNoProxyItem === '*' ||\n            upperReqHosts.some(x => x === upperNoProxyItem ||\n                x.endsWith(`.${upperNoProxyItem}`) ||\n                (upperNoProxyItem.startsWith('.') &&\n                    x.endsWith(`${upperNoProxyItem}`)))) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.checkBypass = checkBypass;\nfunction isLoopbackAddress(host) {\n    const hostLower = host.toLowerCase();\n    return (hostLower === 'localhost' ||\n        hostLower.startsWith('127.') ||\n        hostLower.startsWith('[::1]') ||\n        hostLower.startsWith('[0:0:0:0:0:0:0:1]'));\n}\nclass DecodedURL extends URL {\n    constructor(url, base) {\n        super(url, base);\n        this._decodedUsername = decodeURIComponent(super.username);\n        this._decodedPassword = decodeURIComponent(super.password);\n    }\n    get username() {\n        return this._decodedUsername;\n    }\n    get password() {\n        return this._decodedPassword;\n    }\n}\n//# sourceMappingURL=proxy.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar _a;\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getCmdPath = exports.tryGetExecutablePath = exports.isRooted = exports.isDirectory = exports.exists = exports.READONLY = exports.UV_FS_O_EXLOCK = exports.IS_WINDOWS = exports.unlink = exports.symlink = exports.stat = exports.rmdir = exports.rm = exports.rename = exports.readlink = exports.readdir = exports.open = exports.mkdir = exports.lstat = exports.copyFile = exports.chmod = void 0;\nconst fs = __importStar(require(\"fs\"));\nconst path = __importStar(require(\"path\"));\n_a = fs.promises\n// export const {open} = 'fs'\n, exports.chmod = _a.chmod, exports.copyFile = _a.copyFile, exports.lstat = _a.lstat, exports.mkdir = _a.mkdir, exports.open = _a.open, exports.readdir = _a.readdir, exports.readlink = _a.readlink, exports.rename = _a.rename, exports.rm = _a.rm, exports.rmdir = _a.rmdir, exports.stat = _a.stat, exports.symlink = _a.symlink, exports.unlink = _a.unlink;\n// export const {open} = 'fs'\nexports.IS_WINDOWS = process.platform === 'win32';\n// See https://github.com/nodejs/node/blob/d0153aee367422d0858105abec186da4dff0a0c5/deps/uv/include/uv/win.h#L691\nexports.UV_FS_O_EXLOCK = 0x10000000;\nexports.READONLY = fs.constants.O_RDONLY;\nfunction exists(fsPath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        try {\n            yield exports.stat(fsPath);\n        }\n        catch (err) {\n            if (err.code === 'ENOENT') {\n                return false;\n            }\n            throw err;\n        }\n        return true;\n    });\n}\nexports.exists = exists;\nfunction isDirectory(fsPath, useStat = false) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const stats = useStat ? yield exports.stat(fsPath) : yield exports.lstat(fsPath);\n        return stats.isDirectory();\n    });\n}\nexports.isDirectory = isDirectory;\n/**\n * On OSX/Linux, true if path starts with '/'. On Windows, true for paths like:\n * \\, \\hello, \\\\hello\\share, C:, and C:\\hello (and corresponding alternate separator cases).\n */\nfunction isRooted(p) {\n    p = normalizeSeparators(p);\n    if (!p) {\n        throw new Error('isRooted() parameter \"p\" cannot be empty');\n    }\n    if (exports.IS_WINDOWS) {\n        return (p.startsWith('\\\\') || /^[A-Z]:/i.test(p) // e.g. \\ or \\hello or \\\\hello\n        ); // e.g. C: or C:\\hello\n    }\n    return p.startsWith('/');\n}\nexports.isRooted = isRooted;\n/**\n * Best effort attempt to determine whether a file exists and is executable.\n * @param filePath    file path to check\n * @param extensions  additional file extensions to try\n * @return if file exists and is executable, returns the file path. otherwise empty string.\n */\nfunction tryGetExecutablePath(filePath, extensions) {\n    return __awaiter(this, void 0, void 0, function* () {\n        let stats = undefined;\n        try {\n            // test file exists\n            stats = yield exports.stat(filePath);\n        }\n        catch (err) {\n            if (err.code !== 'ENOENT') {\n                // eslint-disable-next-line no-console\n                console.log(`Unexpected error attempting to determine if executable file exists '${filePath}': ${err}`);\n            }\n        }\n        if (stats && stats.isFile()) {\n            if (exports.IS_WINDOWS) {\n                // on Windows, test for valid extension\n                const upperExt = path.extname(filePath).toUpperCase();\n                if (extensions.some(validExt => validExt.toUpperCase() === upperExt)) {\n                    return filePath;\n                }\n            }\n            else {\n                if (isUnixExecutable(stats)) {\n                    return filePath;\n                }\n            }\n        }\n        // try each extension\n        const originalFilePath = filePath;\n        for (const extension of extensions) {\n            filePath = originalFilePath + extension;\n            stats = undefined;\n            try {\n                stats = yield exports.stat(filePath);\n            }\n            catch (err) {\n                if (err.code !== 'ENOENT') {\n                    // eslint-disable-next-line no-console\n                    console.log(`Unexpected error attempting to determine if executable file exists '${filePath}': ${err}`);\n                }\n            }\n            if (stats && stats.isFile()) {\n                if (exports.IS_WINDOWS) {\n                    // preserve the case of the actual file (since an extension was appended)\n                    try {\n                        const directory = path.dirname(filePath);\n                        const upperName = path.basename(filePath).toUpperCase();\n                        for (const actualName of yield exports.readdir(directory)) {\n                            if (upperName === actualName.toUpperCase()) {\n                                filePath = path.join(directory, actualName);\n                                break;\n                            }\n                        }\n                    }\n                    catch (err) {\n                        // eslint-disable-next-line no-console\n                        console.log(`Unexpected error attempting to determine the actual case of the file '${filePath}': ${err}`);\n                    }\n                    return filePath;\n                }\n                else {\n                    if (isUnixExecutable(stats)) {\n                        return filePath;\n                    }\n                }\n            }\n        }\n        return '';\n    });\n}\nexports.tryGetExecutablePath = tryGetExecutablePath;\nfunction normalizeSeparators(p) {\n    p = p || '';\n    if (exports.IS_WINDOWS) {\n        // convert slashes on Windows\n        p = p.replace(/\\//g, '\\\\');\n        // remove redundant slashes\n        return p.replace(/\\\\\\\\+/g, '\\\\');\n    }\n    // remove redundant slashes\n    return p.replace(/\\/\\/+/g, '/');\n}\n// on Mac/Linux, test the execute bit\n//     R   W  X  R  W X R W X\n//   256 128 64 32 16 8 4 2 1\nfunction isUnixExecutable(stats) {\n    return ((stats.mode & 1) > 0 ||\n        ((stats.mode & 8) > 0 && stats.gid === process.getgid()) ||\n        ((stats.mode & 64) > 0 && stats.uid === process.getuid()));\n}\n// Get the path of cmd.exe in windows\nfunction getCmdPath() {\n    var _a;\n    return (_a = process.env['COMSPEC']) !== null && _a !== void 0 ? _a : `cmd.exe`;\n}\nexports.getCmdPath = getCmdPath;\n//# sourceMappingURL=io-util.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.findInPath = exports.which = exports.mkdirP = exports.rmRF = exports.mv = exports.cp = void 0;\nconst assert_1 = require(\"assert\");\nconst path = __importStar(require(\"path\"));\nconst ioUtil = __importStar(require(\"./io-util\"));\n/**\n * Copies a file or folder.\n * Based off of shelljs - https://github.com/shelljs/shelljs/blob/9237f66c52e5daa40458f94f9565e18e8132f5a6/src/cp.js\n *\n * @param     source    source path\n * @param     dest      destination path\n * @param     options   optional. See CopyOptions.\n */\nfunction cp(source, dest, options = {}) {\n    return __awaiter(this, void 0, void 0, function* () {\n        const { force, recursive, copySourceDirectory } = readCopyOptions(options);\n        const destStat = (yield ioUtil.exists(dest)) ? yield ioUtil.stat(dest) : null;\n        // Dest is an existing file, but not forcing\n        if (destStat && destStat.isFile() && !force) {\n            return;\n        }\n        // If dest is an existing directory, should copy inside.\n        const newDest = destStat && destStat.isDirectory() && copySourceDirectory\n            ? path.join(dest, path.basename(source))\n            : dest;\n        if (!(yield ioUtil.exists(source))) {\n            throw new Error(`no such file or directory: ${source}`);\n        }\n        const sourceStat = yield ioUtil.stat(source);\n        if (sourceStat.isDirectory()) {\n            if (!recursive) {\n                throw new Error(`Failed to copy. ${source} is a directory, but tried to copy without recursive flag.`);\n            }\n            else {\n                yield cpDirRecursive(source, newDest, 0, force);\n            }\n        }\n        else {\n            if (path.relative(source, newDest) === '') {\n                // a file cannot be copied to itself\n                throw new Error(`'${newDest}' and '${source}' are the same file`);\n            }\n            yield copyFile(source, newDest, force);\n        }\n    });\n}\nexports.cp = cp;\n/**\n * Moves a path.\n *\n * @param     source    source path\n * @param     dest      destination path\n * @param     options   optional. See MoveOptions.\n */\nfunction mv(source, dest, options = {}) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (yield ioUtil.exists(dest)) {\n            let destExists = true;\n            if (yield ioUtil.isDirectory(dest)) {\n                // If dest is directory copy src into dest\n                dest = path.join(dest, path.basename(source));\n                destExists = yield ioUtil.exists(dest);\n            }\n            if (destExists) {\n                if (options.force == null || options.force) {\n                    yield rmRF(dest);\n                }\n                else {\n                    throw new Error('Destination already exists');\n                }\n            }\n        }\n        yield mkdirP(path.dirname(dest));\n        yield ioUtil.rename(source, dest);\n    });\n}\nexports.mv = mv;\n/**\n * Remove a path recursively with force\n *\n * @param inputPath path to remove\n */\nfunction rmRF(inputPath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (ioUtil.IS_WINDOWS) {\n            // Check for invalid characters\n            // https://docs.microsoft.com/en-us/windows/win32/fileio/naming-a-file\n            if (/[*\"<>|]/.test(inputPath)) {\n                throw new Error('File path must not contain `*`, `\"`, `<`, `>` or `|` on Windows');\n            }\n        }\n        try {\n            // note if path does not exist, error is silent\n            yield ioUtil.rm(inputPath, {\n                force: true,\n                maxRetries: 3,\n                recursive: true,\n                retryDelay: 300\n            });\n        }\n        catch (err) {\n            throw new Error(`File was unable to be removed ${err}`);\n        }\n    });\n}\nexports.rmRF = rmRF;\n/**\n * Make a directory.  Creates the full path with folders in between\n * Will throw if it fails\n *\n * @param   fsPath        path to create\n * @returns Promise<void>\n */\nfunction mkdirP(fsPath) {\n    return __awaiter(this, void 0, void 0, function* () {\n        assert_1.ok(fsPath, 'a path argument must be provided');\n        yield ioUtil.mkdir(fsPath, { recursive: true });\n    });\n}\nexports.mkdirP = mkdirP;\n/**\n * Returns path of a tool had the tool actually been invoked.  Resolves via paths.\n * If you check and the tool does not exist, it will throw.\n *\n * @param     tool              name of the tool\n * @param     check             whether to check if tool exists\n * @returns   Promise<string>   path to tool\n */\nfunction which(tool, check) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (!tool) {\n            throw new Error(\"parameter 'tool' is required\");\n        }\n        // recursive when check=true\n        if (check) {\n            const result = yield which(tool, false);\n            if (!result) {\n                if (ioUtil.IS_WINDOWS) {\n                    throw new Error(`Unable to locate executable file: ${tool}. Please verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. Also verify the file has a valid extension for an executable file.`);\n                }\n                else {\n                    throw new Error(`Unable to locate executable file: ${tool}. Please verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. Also check the file mode to verify the file is executable.`);\n                }\n            }\n            return result;\n        }\n        const matches = yield findInPath(tool);\n        if (matches && matches.length > 0) {\n            return matches[0];\n        }\n        return '';\n    });\n}\nexports.which = which;\n/**\n * Returns a list of all occurrences of the given tool on the system path.\n *\n * @returns   Promise<string[]>  the paths of the tool\n */\nfunction findInPath(tool) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if (!tool) {\n            throw new Error(\"parameter 'tool' is required\");\n        }\n        // build the list of extensions to try\n        const extensions = [];\n        if (ioUtil.IS_WINDOWS && process.env['PATHEXT']) {\n            for (const extension of process.env['PATHEXT'].split(path.delimiter)) {\n                if (extension) {\n                    extensions.push(extension);\n                }\n            }\n        }\n        // if it's rooted, return it if exists. otherwise return empty.\n        if (ioUtil.isRooted(tool)) {\n            const filePath = yield ioUtil.tryGetExecutablePath(tool, extensions);\n            if (filePath) {\n                return [filePath];\n            }\n            return [];\n        }\n        // if any path separators, return empty\n        if (tool.includes(path.sep)) {\n            return [];\n        }\n        // build the list of directories\n        //\n        // Note, technically \"where\" checks the current directory on Windows. From a toolkit perspective,\n        // it feels like we should not do this. Checking the current directory seems like more of a use\n        // case of a shell, and the which() function exposed by the toolkit should strive for consistency\n        // across platforms.\n        const directories = [];\n        if (process.env.PATH) {\n            for (const p of process.env.PATH.split(path.delimiter)) {\n                if (p) {\n                    directories.push(p);\n                }\n            }\n        }\n        // find all matches\n        const matches = [];\n        for (const directory of directories) {\n            const filePath = yield ioUtil.tryGetExecutablePath(path.join(directory, tool), extensions);\n            if (filePath) {\n                matches.push(filePath);\n            }\n        }\n        return matches;\n    });\n}\nexports.findInPath = findInPath;\nfunction readCopyOptions(options) {\n    const force = options.force == null ? true : options.force;\n    const recursive = Boolean(options.recursive);\n    const copySourceDirectory = options.copySourceDirectory == null\n        ? true\n        : Boolean(options.copySourceDirectory);\n    return { force, recursive, copySourceDirectory };\n}\nfunction cpDirRecursive(sourceDir, destDir, currentDepth, force) {\n    return __awaiter(this, void 0, void 0, function* () {\n        // Ensure there is not a run away recursive copy\n        if (currentDepth >= 255)\n            return;\n        currentDepth++;\n        yield mkdirP(destDir);\n        const files = yield ioUtil.readdir(sourceDir);\n        for (const fileName of files) {\n            const srcFile = `${sourceDir}/${fileName}`;\n            const destFile = `${destDir}/${fileName}`;\n            const srcFileStat = yield ioUtil.lstat(srcFile);\n            if (srcFileStat.isDirectory()) {\n                // Recurse\n                yield cpDirRecursive(srcFile, destFile, currentDepth, force);\n            }\n            else {\n                yield copyFile(srcFile, destFile, force);\n            }\n        }\n        // Change the mode for the newly created directory\n        yield ioUtil.chmod(destDir, (yield ioUtil.stat(sourceDir)).mode);\n    });\n}\n// Buffered file copy\nfunction copyFile(srcFile, destFile, force) {\n    return __awaiter(this, void 0, void 0, function* () {\n        if ((yield ioUtil.lstat(srcFile)).isSymbolicLink()) {\n            // unlink/re-link it\n            try {\n                yield ioUtil.lstat(destFile);\n                yield ioUtil.unlink(destFile);\n            }\n            catch (e) {\n                // Try to override file permission\n                if (e.code === 'EPERM') {\n                    yield ioUtil.chmod(destFile, '0666');\n                    yield ioUtil.unlink(destFile);\n                }\n                // other errors = it doesn't exist, no work to do\n            }\n            // Copy over symlink\n            const symlinkFull = yield ioUtil.readlink(srcFile);\n            yield ioUtil.symlink(symlinkFull, destFile, ioUtil.IS_WINDOWS ? 'junction' : null);\n        }\n        else if (!(yield ioUtil.exists(destFile)) || force) {\n            yield ioUtil.copyFile(srcFile, destFile);\n        }\n    });\n}\n//# sourceMappingURL=io.js.map","\"use strict\";\n// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AwsCrc32 = void 0;\nvar tslib_1 = require(\"tslib\");\nvar util_1 = require(\"@aws-crypto/util\");\nvar index_1 = require(\"./index\");\nvar AwsCrc32 = /** @class */ (function () {\n    function AwsCrc32() {\n        this.crc32 = new index_1.Crc32();\n    }\n    AwsCrc32.prototype.update = function (toHash) {\n        if ((0, util_1.isEmptyData)(toHash))\n            return;\n        this.crc32.update((0, util_1.convertToBuffer)(toHash));\n    };\n    AwsCrc32.prototype.digest = function () {\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\n            return tslib_1.__generator(this, function (_a) {\n                return [2 /*return*/, (0, util_1.numToUint8)(this.crc32.digest())];\n            });\n        });\n    };\n    AwsCrc32.prototype.reset = function () {\n        this.crc32 = new index_1.Crc32();\n    };\n    return AwsCrc32;\n}());\nexports.AwsCrc32 = AwsCrc32;\n//# sourceMappingURL=aws_crc32.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AwsCrc32 = exports.Crc32 = exports.crc32 = void 0;\nvar tslib_1 = require(\"tslib\");\nvar util_1 = require(\"@aws-crypto/util\");\nfunction crc32(data) {\n    return new Crc32().update(data).digest();\n}\nexports.crc32 = crc32;\nvar Crc32 = /** @class */ (function () {\n    function Crc32() {\n        this.checksum = 0xffffffff;\n    }\n    Crc32.prototype.update = function (data) {\n        var e_1, _a;\n        try {\n            for (var data_1 = tslib_1.__values(data), data_1_1 = data_1.next(); !data_1_1.done; data_1_1 = data_1.next()) {\n                var byte = data_1_1.value;\n                this.checksum =\n                    (this.checksum >>> 8) ^ lookupTable[(this.checksum ^ byte) & 0xff];\n            }\n        }\n        catch (e_1_1) { e_1 = { error: e_1_1 }; }\n        finally {\n            try {\n                if (data_1_1 && !data_1_1.done && (_a = data_1.return)) _a.call(data_1);\n            }\n            finally { if (e_1) throw e_1.error; }\n        }\n        return this;\n    };\n    Crc32.prototype.digest = function () {\n        return (this.checksum ^ 0xffffffff) >>> 0;\n    };\n    return Crc32;\n}());\nexports.Crc32 = Crc32;\n// prettier-ignore\nvar a_lookUpTable = [\n    0x00000000, 0x77073096, 0xEE0E612C, 0x990951BA,\n    0x076DC419, 0x706AF48F, 0xE963A535, 0x9E6495A3,\n    0x0EDB8832, 0x79DCB8A4, 0xE0D5E91E, 0x97D2D988,\n    0x09B64C2B, 0x7EB17CBD, 0xE7B82D07, 0x90BF1D91,\n    0x1DB71064, 0x6AB020F2, 0xF3B97148, 0x84BE41DE,\n    0x1ADAD47D, 0x6DDDE4EB, 0xF4D4B551, 0x83D385C7,\n    0x136C9856, 0x646BA8C0, 0xFD62F97A, 0x8A65C9EC,\n    0x14015C4F, 0x63066CD9, 0xFA0F3D63, 0x8D080DF5,\n    0x3B6E20C8, 0x4C69105E, 0xD56041E4, 0xA2677172,\n    0x3C03E4D1, 0x4B04D447, 0xD20D85FD, 0xA50AB56B,\n    0x35B5A8FA, 0x42B2986C, 0xDBBBC9D6, 0xACBCF940,\n    0x32D86CE3, 0x45DF5C75, 0xDCD60DCF, 0xABD13D59,\n    0x26D930AC, 0x51DE003A, 0xC8D75180, 0xBFD06116,\n    0x21B4F4B5, 0x56B3C423, 0xCFBA9599, 0xB8BDA50F,\n    0x2802B89E, 0x5F058808, 0xC60CD9B2, 0xB10BE924,\n    0x2F6F7C87, 0x58684C11, 0xC1611DAB, 0xB6662D3D,\n    0x76DC4190, 0x01DB7106, 0x98D220BC, 0xEFD5102A,\n    0x71B18589, 0x06B6B51F, 0x9FBFE4A5, 0xE8B8D433,\n    0x7807C9A2, 0x0F00F934, 0x9609A88E, 0xE10E9818,\n    0x7F6A0DBB, 0x086D3D2D, 0x91646C97, 0xE6635C01,\n    0x6B6B51F4, 0x1C6C6162, 0x856530D8, 0xF262004E,\n    0x6C0695ED, 0x1B01A57B, 0x8208F4C1, 0xF50FC457,\n    0x65B0D9C6, 0x12B7E950, 0x8BBEB8EA, 0xFCB9887C,\n    0x62DD1DDF, 0x15DA2D49, 0x8CD37CF3, 0xFBD44C65,\n    0x4DB26158, 0x3AB551CE, 0xA3BC0074, 0xD4BB30E2,\n    0x4ADFA541, 0x3DD895D7, 0xA4D1C46D, 0xD3D6F4FB,\n    0x4369E96A, 0x346ED9FC, 0xAD678846, 0xDA60B8D0,\n    0x44042D73, 0x33031DE5, 0xAA0A4C5F, 0xDD0D7CC9,\n    0x5005713C, 0x270241AA, 0xBE0B1010, 0xC90C2086,\n    0x5768B525, 0x206F85B3, 0xB966D409, 0xCE61E49F,\n    0x5EDEF90E, 0x29D9C998, 0xB0D09822, 0xC7D7A8B4,\n    0x59B33D17, 0x2EB40D81, 0xB7BD5C3B, 0xC0BA6CAD,\n    0xEDB88320, 0x9ABFB3B6, 0x03B6E20C, 0x74B1D29A,\n    0xEAD54739, 0x9DD277AF, 0x04DB2615, 0x73DC1683,\n    0xE3630B12, 0x94643B84, 0x0D6D6A3E, 0x7A6A5AA8,\n    0xE40ECF0B, 0x9309FF9D, 0x0A00AE27, 0x7D079EB1,\n    0xF00F9344, 0x8708A3D2, 0x1E01F268, 0x6906C2FE,\n    0xF762575D, 0x806567CB, 0x196C3671, 0x6E6B06E7,\n    0xFED41B76, 0x89D32BE0, 0x10DA7A5A, 0x67DD4ACC,\n    0xF9B9DF6F, 0x8EBEEFF9, 0x17B7BE43, 0x60B08ED5,\n    0xD6D6A3E8, 0xA1D1937E, 0x38D8C2C4, 0x4FDFF252,\n    0xD1BB67F1, 0xA6BC5767, 0x3FB506DD, 0x48B2364B,\n    0xD80D2BDA, 0xAF0A1B4C, 0x36034AF6, 0x41047A60,\n    0xDF60EFC3, 0xA867DF55, 0x316E8EEF, 0x4669BE79,\n    0xCB61B38C, 0xBC66831A, 0x256FD2A0, 0x5268E236,\n    0xCC0C7795, 0xBB0B4703, 0x220216B9, 0x5505262F,\n    0xC5BA3BBE, 0xB2BD0B28, 0x2BB45A92, 0x5CB36A04,\n    0xC2D7FFA7, 0xB5D0CF31, 0x2CD99E8B, 0x5BDEAE1D,\n    0x9B64C2B0, 0xEC63F226, 0x756AA39C, 0x026D930A,\n    0x9C0906A9, 0xEB0E363F, 0x72076785, 0x05005713,\n    0x95BF4A82, 0xE2B87A14, 0x7BB12BAE, 0x0CB61B38,\n    0x92D28E9B, 0xE5D5BE0D, 0x7CDCEFB7, 0x0BDBDF21,\n    0x86D3D2D4, 0xF1D4E242, 0x68DDB3F8, 0x1FDA836E,\n    0x81BE16CD, 0xF6B9265B, 0x6FB077E1, 0x18B74777,\n    0x88085AE6, 0xFF0F6A70, 0x66063BCA, 0x11010B5C,\n    0x8F659EFF, 0xF862AE69, 0x616BFFD3, 0x166CCF45,\n    0xA00AE278, 0xD70DD2EE, 0x4E048354, 0x3903B3C2,\n    0xA7672661, 0xD06016F7, 0x4969474D, 0x3E6E77DB,\n    0xAED16A4A, 0xD9D65ADC, 0x40DF0B66, 0x37D83BF0,\n    0xA9BCAE53, 0xDEBB9EC5, 0x47B2CF7F, 0x30B5FFE9,\n    0xBDBDF21C, 0xCABAC28A, 0x53B39330, 0x24B4A3A6,\n    0xBAD03605, 0xCDD70693, 0x54DE5729, 0x23D967BF,\n    0xB3667A2E, 0xC4614AB8, 0x5D681B02, 0x2A6F2B94,\n    0xB40BBE37, 0xC30C8EA1, 0x5A05DF1B, 0x2D02EF8D,\n];\nvar lookupTable = (0, util_1.uint32ArrayFrom)(a_lookUpTable);\nvar aws_crc32_1 = require(\"./aws_crc32\");\nObject.defineProperty(exports, \"AwsCrc32\", { enumerable: true, get: function () { return aws_crc32_1.AwsCrc32; } });\n//# sourceMappingURL=index.js.map","\"use strict\";\n// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AwsCrc32c = void 0;\nvar tslib_1 = require(\"tslib\");\nvar util_1 = require(\"@aws-crypto/util\");\nvar index_1 = require(\"./index\");\nvar AwsCrc32c = /** @class */ (function () {\n    function AwsCrc32c() {\n        this.crc32c = new index_1.Crc32c();\n    }\n    AwsCrc32c.prototype.update = function (toHash) {\n        if ((0, util_1.isEmptyData)(toHash))\n            return;\n        this.crc32c.update((0, util_1.convertToBuffer)(toHash));\n    };\n    AwsCrc32c.prototype.digest = function () {\n        return tslib_1.__awaiter(this, void 0, void 0, function () {\n            return tslib_1.__generator(this, function (_a) {\n                return [2 /*return*/, (0, util_1.numToUint8)(this.crc32c.digest())];\n            });\n        });\n    };\n    AwsCrc32c.prototype.reset = function () {\n        this.crc32c = new index_1.Crc32c();\n    };\n    return AwsCrc32c;\n}());\nexports.AwsCrc32c = AwsCrc32c;\n//# sourceMappingURL=aws_crc32c.js.map","\"use strict\";\n// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AwsCrc32c = exports.Crc32c = exports.crc32c = void 0;\nvar tslib_1 = require(\"tslib\");\nvar util_1 = require(\"@aws-crypto/util\");\nfunction crc32c(data) {\n    return new Crc32c().update(data).digest();\n}\nexports.crc32c = crc32c;\nvar Crc32c = /** @class */ (function () {\n    function Crc32c() {\n        this.checksum = 0xffffffff;\n    }\n    Crc32c.prototype.update = function (data) {\n        var e_1, _a;\n        try {\n            for (var data_1 = tslib_1.__values(data), data_1_1 = data_1.next(); !data_1_1.done; data_1_1 = data_1.next()) {\n                var byte = data_1_1.value;\n                this.checksum =\n                    (this.checksum >>> 8) ^ lookupTable[(this.checksum ^ byte) & 0xff];\n            }\n        }\n        catch (e_1_1) { e_1 = { error: e_1_1 }; }\n        finally {\n            try {\n                if (data_1_1 && !data_1_1.done && (_a = data_1.return)) _a.call(data_1);\n            }\n            finally { if (e_1) throw e_1.error; }\n        }\n        return this;\n    };\n    Crc32c.prototype.digest = function () {\n        return (this.checksum ^ 0xffffffff) >>> 0;\n    };\n    return Crc32c;\n}());\nexports.Crc32c = Crc32c;\n// prettier-ignore\nvar a_lookupTable = [\n    0x00000000, 0xF26B8303, 0xE13B70F7, 0x1350F3F4, 0xC79A971F, 0x35F1141C, 0x26A1E7E8, 0xD4CA64EB,\n    0x8AD958CF, 0x78B2DBCC, 0x6BE22838, 0x9989AB3B, 0x4D43CFD0, 0xBF284CD3, 0xAC78BF27, 0x5E133C24,\n    0x105EC76F, 0xE235446C, 0xF165B798, 0x030E349B, 0xD7C45070, 0x25AFD373, 0x36FF2087, 0xC494A384,\n    0x9A879FA0, 0x68EC1CA3, 0x7BBCEF57, 0x89D76C54, 0x5D1D08BF, 0xAF768BBC, 0xBC267848, 0x4E4DFB4B,\n    0x20BD8EDE, 0xD2D60DDD, 0xC186FE29, 0x33ED7D2A, 0xE72719C1, 0x154C9AC2, 0x061C6936, 0xF477EA35,\n    0xAA64D611, 0x580F5512, 0x4B5FA6E6, 0xB93425E5, 0x6DFE410E, 0x9F95C20D, 0x8CC531F9, 0x7EAEB2FA,\n    0x30E349B1, 0xC288CAB2, 0xD1D83946, 0x23B3BA45, 0xF779DEAE, 0x05125DAD, 0x1642AE59, 0xE4292D5A,\n    0xBA3A117E, 0x4851927D, 0x5B016189, 0xA96AE28A, 0x7DA08661, 0x8FCB0562, 0x9C9BF696, 0x6EF07595,\n    0x417B1DBC, 0xB3109EBF, 0xA0406D4B, 0x522BEE48, 0x86E18AA3, 0x748A09A0, 0x67DAFA54, 0x95B17957,\n    0xCBA24573, 0x39C9C670, 0x2A993584, 0xD8F2B687, 0x0C38D26C, 0xFE53516F, 0xED03A29B, 0x1F682198,\n    0x5125DAD3, 0xA34E59D0, 0xB01EAA24, 0x42752927, 0x96BF4DCC, 0x64D4CECF, 0x77843D3B, 0x85EFBE38,\n    0xDBFC821C, 0x2997011F, 0x3AC7F2EB, 0xC8AC71E8, 0x1C661503, 0xEE0D9600, 0xFD5D65F4, 0x0F36E6F7,\n    0x61C69362, 0x93AD1061, 0x80FDE395, 0x72966096, 0xA65C047D, 0x5437877E, 0x4767748A, 0xB50CF789,\n    0xEB1FCBAD, 0x197448AE, 0x0A24BB5A, 0xF84F3859, 0x2C855CB2, 0xDEEEDFB1, 0xCDBE2C45, 0x3FD5AF46,\n    0x7198540D, 0x83F3D70E, 0x90A324FA, 0x62C8A7F9, 0xB602C312, 0x44694011, 0x5739B3E5, 0xA55230E6,\n    0xFB410CC2, 0x092A8FC1, 0x1A7A7C35, 0xE811FF36, 0x3CDB9BDD, 0xCEB018DE, 0xDDE0EB2A, 0x2F8B6829,\n    0x82F63B78, 0x709DB87B, 0x63CD4B8F, 0x91A6C88C, 0x456CAC67, 0xB7072F64, 0xA457DC90, 0x563C5F93,\n    0x082F63B7, 0xFA44E0B4, 0xE9141340, 0x1B7F9043, 0xCFB5F4A8, 0x3DDE77AB, 0x2E8E845F, 0xDCE5075C,\n    0x92A8FC17, 0x60C37F14, 0x73938CE0, 0x81F80FE3, 0x55326B08, 0xA759E80B, 0xB4091BFF, 0x466298FC,\n    0x1871A4D8, 0xEA1A27DB, 0xF94AD42F, 0x0B21572C, 0xDFEB33C7, 0x2D80B0C4, 0x3ED04330, 0xCCBBC033,\n    0xA24BB5A6, 0x502036A5, 0x4370C551, 0xB11B4652, 0x65D122B9, 0x97BAA1BA, 0x84EA524E, 0x7681D14D,\n    0x2892ED69, 0xDAF96E6A, 0xC9A99D9E, 0x3BC21E9D, 0xEF087A76, 0x1D63F975, 0x0E330A81, 0xFC588982,\n    0xB21572C9, 0x407EF1CA, 0x532E023E, 0xA145813D, 0x758FE5D6, 0x87E466D5, 0x94B49521, 0x66DF1622,\n    0x38CC2A06, 0xCAA7A905, 0xD9F75AF1, 0x2B9CD9F2, 0xFF56BD19, 0x0D3D3E1A, 0x1E6DCDEE, 0xEC064EED,\n    0xC38D26C4, 0x31E6A5C7, 0x22B65633, 0xD0DDD530, 0x0417B1DB, 0xF67C32D8, 0xE52CC12C, 0x1747422F,\n    0x49547E0B, 0xBB3FFD08, 0xA86F0EFC, 0x5A048DFF, 0x8ECEE914, 0x7CA56A17, 0x6FF599E3, 0x9D9E1AE0,\n    0xD3D3E1AB, 0x21B862A8, 0x32E8915C, 0xC083125F, 0x144976B4, 0xE622F5B7, 0xF5720643, 0x07198540,\n    0x590AB964, 0xAB613A67, 0xB831C993, 0x4A5A4A90, 0x9E902E7B, 0x6CFBAD78, 0x7FAB5E8C, 0x8DC0DD8F,\n    0xE330A81A, 0x115B2B19, 0x020BD8ED, 0xF0605BEE, 0x24AA3F05, 0xD6C1BC06, 0xC5914FF2, 0x37FACCF1,\n    0x69E9F0D5, 0x9B8273D6, 0x88D28022, 0x7AB90321, 0xAE7367CA, 0x5C18E4C9, 0x4F48173D, 0xBD23943E,\n    0xF36E6F75, 0x0105EC76, 0x12551F82, 0xE03E9C81, 0x34F4F86A, 0xC69F7B69, 0xD5CF889D, 0x27A40B9E,\n    0x79B737BA, 0x8BDCB4B9, 0x988C474D, 0x6AE7C44E, 0xBE2DA0A5, 0x4C4623A6, 0x5F16D052, 0xAD7D5351,\n];\nvar lookupTable = (0, util_1.uint32ArrayFrom)(a_lookupTable);\nvar aws_crc32c_1 = require(\"./aws_crc32c\");\nObject.defineProperty(exports, \"AwsCrc32c\", { enumerable: true, get: function () { return aws_crc32c_1.AwsCrc32c; } });\n//# sourceMappingURL=index.js.map","\"use strict\";\n// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.convertToBuffer = void 0;\nvar util_utf8_1 = require(\"@smithy/util-utf8\");\n// Quick polyfill\nvar fromUtf8 = typeof Buffer !== \"undefined\" && Buffer.from\n    ? function (input) { return Buffer.from(input, \"utf8\"); }\n    : util_utf8_1.fromUtf8;\nfunction convertToBuffer(data) {\n    // Already a Uint8, do nothing\n    if (data instanceof Uint8Array)\n        return data;\n    if (typeof data === \"string\") {\n        return fromUtf8(data);\n    }\n    if (ArrayBuffer.isView(data)) {\n        return new Uint8Array(data.buffer, data.byteOffset, data.byteLength / Uint8Array.BYTES_PER_ELEMENT);\n    }\n    return new Uint8Array(data);\n}\nexports.convertToBuffer = convertToBuffer;\n//# sourceMappingURL=convertToBuffer.js.map","\"use strict\";\n// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.uint32ArrayFrom = exports.numToUint8 = exports.isEmptyData = exports.convertToBuffer = void 0;\nvar convertToBuffer_1 = require(\"./convertToBuffer\");\nObject.defineProperty(exports, \"convertToBuffer\", { enumerable: true, get: function () { return convertToBuffer_1.convertToBuffer; } });\nvar isEmptyData_1 = require(\"./isEmptyData\");\nObject.defineProperty(exports, \"isEmptyData\", { enumerable: true, get: function () { return isEmptyData_1.isEmptyData; } });\nvar numToUint8_1 = require(\"./numToUint8\");\nObject.defineProperty(exports, \"numToUint8\", { enumerable: true, get: function () { return numToUint8_1.numToUint8; } });\nvar uint32ArrayFrom_1 = require(\"./uint32ArrayFrom\");\nObject.defineProperty(exports, \"uint32ArrayFrom\", { enumerable: true, get: function () { return uint32ArrayFrom_1.uint32ArrayFrom; } });\n//# sourceMappingURL=index.js.map","\"use strict\";\n// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.isEmptyData = void 0;\nfunction isEmptyData(data) {\n    if (typeof data === \"string\") {\n        return data.length === 0;\n    }\n    return data.byteLength === 0;\n}\nexports.isEmptyData = isEmptyData;\n//# sourceMappingURL=isEmptyData.js.map","\"use strict\";\n// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.numToUint8 = void 0;\nfunction numToUint8(num) {\n    return new Uint8Array([\n        (num & 0xff000000) >> 24,\n        (num & 0x00ff0000) >> 16,\n        (num & 0x0000ff00) >> 8,\n        num & 0x000000ff,\n    ]);\n}\nexports.numToUint8 = numToUint8;\n//# sourceMappingURL=numToUint8.js.map","\"use strict\";\n// Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.uint32ArrayFrom = void 0;\n// IE 11 does not support Array.from, so we do it manually\nfunction uint32ArrayFrom(a_lookUpTable) {\n    if (!Uint32Array.from) {\n        var return_array = new Uint32Array(a_lookUpTable.length);\n        var a_index = 0;\n        while (a_index < a_lookUpTable.length) {\n            return_array[a_index] = a_lookUpTable[a_index];\n            a_index += 1;\n        }\n        return return_array;\n    }\n    return Uint32Array.from(a_lookUpTable);\n}\nexports.uint32ArrayFrom = uint32ArrayFrom;\n//# sourceMappingURL=uint32ArrayFrom.js.map","var __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// src/index.ts\nvar src_exports = {};\n__export(src_exports, {\n  isArrayBuffer: () => isArrayBuffer\n});\nmodule.exports = __toCommonJS(src_exports);\nvar isArrayBuffer = /* @__PURE__ */ __name((arg) => typeof ArrayBuffer === \"function\" && arg instanceof ArrayBuffer || Object.prototype.toString.call(arg) === \"[object ArrayBuffer]\", \"isArrayBuffer\");\n// Annotate the CommonJS export names for ESM import in node:\n\n0 && (module.exports = {\n  isArrayBuffer\n});\n\n","var __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// src/index.ts\nvar src_exports = {};\n__export(src_exports, {\n  fromArrayBuffer: () => fromArrayBuffer,\n  fromString: () => fromString\n});\nmodule.exports = __toCommonJS(src_exports);\nvar import_is_array_buffer = require(\"@smithy/is-array-buffer\");\nvar import_buffer = require(\"buffer\");\nvar fromArrayBuffer = /* @__PURE__ */ __name((input, offset = 0, length = input.byteLength - offset) => {\n  if (!(0, import_is_array_buffer.isArrayBuffer)(input)) {\n    throw new TypeError(`The \"input\" argument must be ArrayBuffer. Received type ${typeof input} (${input})`);\n  }\n  return import_buffer.Buffer.from(input, offset, length);\n}, \"fromArrayBuffer\");\nvar fromString = /* @__PURE__ */ __name((input, encoding) => {\n  if (typeof input !== \"string\") {\n    throw new TypeError(`The \"input\" argument must be of type string. Received type ${typeof input} (${input})`);\n  }\n  return encoding ? import_buffer.Buffer.from(input, encoding) : import_buffer.Buffer.from(input);\n}, \"fromString\");\n// Annotate the CommonJS export names for ESM import in node:\n\n0 && (module.exports = {\n  fromArrayBuffer,\n  fromString\n});\n\n","var __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// src/index.ts\nvar src_exports = {};\n__export(src_exports, {\n  fromUtf8: () => fromUtf8,\n  toUint8Array: () => toUint8Array,\n  toUtf8: () => toUtf8\n});\nmodule.exports = __toCommonJS(src_exports);\n\n// src/fromUtf8.ts\nvar import_util_buffer_from = require(\"@smithy/util-buffer-from\");\nvar fromUtf8 = /* @__PURE__ */ __name((input) => {\n  const buf = (0, import_util_buffer_from.fromString)(input, \"utf8\");\n  return new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength / Uint8Array.BYTES_PER_ELEMENT);\n}, \"fromUtf8\");\n\n// src/toUint8Array.ts\nvar toUint8Array = /* @__PURE__ */ __name((data) => {\n  if (typeof data === \"string\") {\n    return fromUtf8(data);\n  }\n  if (ArrayBuffer.isView(data)) {\n    return new Uint8Array(data.buffer, data.byteOffset, data.byteLength / Uint8Array.BYTES_PER_ELEMENT);\n  }\n  return new Uint8Array(data);\n}, \"toUint8Array\");\n\n// src/toUtf8.ts\n\nvar toUtf8 = /* @__PURE__ */ __name((input) => {\n  if (typeof input === \"string\") {\n    return input;\n  }\n  if (typeof input !== \"object\" || typeof input.byteOffset !== \"number\" || typeof input.byteLength !== \"number\") {\n    throw new Error(\"@smithy/util-utf8: toUtf8 encoder function only accepts string | Uint8Array.\");\n  }\n  return (0, import_util_buffer_from.fromArrayBuffer)(input.buffer, input.byteOffset, input.byteLength).toString(\"utf8\");\n}, \"toUtf8\");\n// Annotate the CommonJS export names for ESM import in node:\n\n0 && (module.exports = {\n  fromUtf8,\n  toUint8Array,\n  toUtf8\n});\n\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.resolveHttpAuthSchemeConfig = exports.defaultElasticBeanstalkHttpAuthSchemeProvider = exports.defaultElasticBeanstalkHttpAuthSchemeParametersProvider = void 0;\nconst core_1 = require(\"@aws-sdk/core\");\nconst util_middleware_1 = require(\"@smithy/util-middleware\");\nconst defaultElasticBeanstalkHttpAuthSchemeParametersProvider = async (config, context, input) => {\n    return {\n        operation: (0, util_middleware_1.getSmithyContext)(context).operation,\n        region: await (0, util_middleware_1.normalizeProvider)(config.region)() || (() => {\n            throw new Error(\"expected `region` to be configured for `aws.auth#sigv4`\");\n        })(),\n    };\n};\nexports.defaultElasticBeanstalkHttpAuthSchemeParametersProvider = defaultElasticBeanstalkHttpAuthSchemeParametersProvider;\nfunction createAwsAuthSigv4HttpAuthOption(authParameters) {\n    return {\n        schemeId: \"aws.auth#sigv4\",\n        signingProperties: {\n            name: \"elasticbeanstalk\",\n            region: authParameters.region,\n        },\n        propertiesExtractor: (config, context) => ({\n            signingProperties: {\n                config,\n                context,\n            },\n        }),\n    };\n}\nconst defaultElasticBeanstalkHttpAuthSchemeProvider = (authParameters) => {\n    const options = [];\n    switch (authParameters.operation) {\n        default: {\n            options.push(createAwsAuthSigv4HttpAuthOption(authParameters));\n        }\n    }\n    return options;\n};\nexports.defaultElasticBeanstalkHttpAuthSchemeProvider = defaultElasticBeanstalkHttpAuthSchemeProvider;\nconst resolveHttpAuthSchemeConfig = (config) => {\n    const config_0 = (0, core_1.resolveAwsSdkSigV4Config)(config);\n    return Object.assign(config_0, {\n        authSchemePreference: (0, util_middleware_1.normalizeProvider)(config.authSchemePreference ?? []),\n    });\n};\nexports.resolveHttpAuthSchemeConfig = resolveHttpAuthSchemeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.defaultEndpointResolver = void 0;\nconst util_endpoints_1 = require(\"@aws-sdk/util-endpoints\");\nconst util_endpoints_2 = require(\"@smithy/util-endpoints\");\nconst ruleset_1 = require(\"./ruleset\");\nconst cache = new util_endpoints_2.EndpointCache({\n    size: 50,\n    params: [\"Endpoint\", \"Region\", \"UseDualStack\", \"UseFIPS\"],\n});\nconst defaultEndpointResolver = (endpointParams, context = {}) => {\n    return cache.get(endpointParams, () => (0, util_endpoints_2.resolveEndpoint)(ruleset_1.ruleSet, {\n        endpointParams: endpointParams,\n        logger: context.logger,\n    }));\n};\nexports.defaultEndpointResolver = defaultEndpointResolver;\nutil_endpoints_2.customEndpointFunctions.aws = util_endpoints_1.awsEndpointFunctions;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ruleSet = void 0;\nconst u = \"required\", v = \"fn\", w = \"argv\", x = \"ref\";\nconst a = true, b = \"isSet\", c = \"booleanEquals\", d = \"error\", e = \"endpoint\", f = \"tree\", g = \"PartitionResult\", h = \"getAttr\", i = { [u]: false, \"type\": \"string\" }, j = { [u]: true, \"default\": false, \"type\": \"boolean\" }, k = { [x]: \"Endpoint\" }, l = { [v]: c, [w]: [{ [x]: \"UseFIPS\" }, true] }, m = { [v]: c, [w]: [{ [x]: \"UseDualStack\" }, true] }, n = {}, o = { [v]: h, [w]: [{ [x]: g }, \"supportsFIPS\"] }, p = { [x]: g }, q = { [v]: c, [w]: [true, { [v]: h, [w]: [p, \"supportsDualStack\"] }] }, r = [l], s = [m], t = [{ [x]: \"Region\" }];\nconst _data = { version: \"1.0\", parameters: { Region: i, UseDualStack: j, UseFIPS: j, Endpoint: i }, rules: [{ conditions: [{ [v]: b, [w]: [k] }], rules: [{ conditions: r, error: \"Invalid Configuration: FIPS and custom endpoint are not supported\", type: d }, { conditions: s, error: \"Invalid Configuration: Dualstack and custom endpoint are not supported\", type: d }, { endpoint: { url: k, properties: n, headers: n }, type: e }], type: f }, { conditions: [{ [v]: b, [w]: t }], rules: [{ conditions: [{ [v]: \"aws.partition\", [w]: t, assign: g }], rules: [{ conditions: [l, m], rules: [{ conditions: [{ [v]: c, [w]: [a, o] }, q], rules: [{ endpoint: { url: \"https://elasticbeanstalk-fips.{Region}.{PartitionResult#dualStackDnsSuffix}\", properties: n, headers: n }, type: e }], type: f }, { error: \"FIPS and DualStack are enabled, but this partition does not support one or both\", type: d }], type: f }, { conditions: r, rules: [{ conditions: [{ [v]: c, [w]: [o, a] }], rules: [{ conditions: [{ [v]: \"stringEquals\", [w]: [{ [v]: h, [w]: [p, \"name\"] }, \"aws-us-gov\"] }], endpoint: { url: \"https://elasticbeanstalk.{Region}.amazonaws.com\", properties: n, headers: n }, type: e }, { endpoint: { url: \"https://elasticbeanstalk-fips.{Region}.{PartitionResult#dnsSuffix}\", properties: n, headers: n }, type: e }], type: f }, { error: \"FIPS is enabled but this partition does not support FIPS\", type: d }], type: f }, { conditions: s, rules: [{ conditions: [q], rules: [{ endpoint: { url: \"https://elasticbeanstalk.{Region}.{PartitionResult#dualStackDnsSuffix}\", properties: n, headers: n }, type: e }], type: f }, { error: \"DualStack is enabled but this partition does not support DualStack\", type: d }], type: f }, { endpoint: { url: \"https://elasticbeanstalk.{Region}.{PartitionResult#dnsSuffix}\", properties: n, headers: n }, type: e }], type: f }], type: f }, { error: \"Invalid Configuration: Missing Region\", type: d }] };\nexports.ruleSet = _data;\n","'use strict';\n\nvar middlewareHostHeader = require('@aws-sdk/middleware-host-header');\nvar middlewareLogger = require('@aws-sdk/middleware-logger');\nvar middlewareRecursionDetection = require('@aws-sdk/middleware-recursion-detection');\nvar middlewareUserAgent = require('@aws-sdk/middleware-user-agent');\nvar configResolver = require('@smithy/config-resolver');\nvar core = require('@smithy/core');\nvar schema = require('@smithy/core/schema');\nvar middlewareContentLength = require('@smithy/middleware-content-length');\nvar middlewareEndpoint = require('@smithy/middleware-endpoint');\nvar middlewareRetry = require('@smithy/middleware-retry');\nvar smithyClient = require('@smithy/smithy-client');\nvar httpAuthSchemeProvider = require('./auth/httpAuthSchemeProvider');\nvar runtimeConfig = require('./runtimeConfig');\nvar regionConfigResolver = require('@aws-sdk/region-config-resolver');\nvar protocolHttp = require('@smithy/protocol-http');\nvar utilWaiter = require('@smithy/util-waiter');\n\nconst resolveClientEndpointParameters = (options) => {\n    return Object.assign(options, {\n        useDualstackEndpoint: options.useDualstackEndpoint ?? false,\n        useFipsEndpoint: options.useFipsEndpoint ?? false,\n        defaultSigningName: \"elasticbeanstalk\",\n    });\n};\nconst commonParams = {\n    UseFIPS: { type: \"builtInParams\", name: \"useFipsEndpoint\" },\n    Endpoint: { type: \"builtInParams\", name: \"endpoint\" },\n    Region: { type: \"builtInParams\", name: \"region\" },\n    UseDualStack: { type: \"builtInParams\", name: \"useDualstackEndpoint\" },\n};\n\nconst getHttpAuthExtensionConfiguration = (runtimeConfig) => {\n    const _httpAuthSchemes = runtimeConfig.httpAuthSchemes;\n    let _httpAuthSchemeProvider = runtimeConfig.httpAuthSchemeProvider;\n    let _credentials = runtimeConfig.credentials;\n    return {\n        setHttpAuthScheme(httpAuthScheme) {\n            const index = _httpAuthSchemes.findIndex((scheme) => scheme.schemeId === httpAuthScheme.schemeId);\n            if (index === -1) {\n                _httpAuthSchemes.push(httpAuthScheme);\n            }\n            else {\n                _httpAuthSchemes.splice(index, 1, httpAuthScheme);\n            }\n        },\n        httpAuthSchemes() {\n            return _httpAuthSchemes;\n        },\n        setHttpAuthSchemeProvider(httpAuthSchemeProvider) {\n            _httpAuthSchemeProvider = httpAuthSchemeProvider;\n        },\n        httpAuthSchemeProvider() {\n            return _httpAuthSchemeProvider;\n        },\n        setCredentials(credentials) {\n            _credentials = credentials;\n        },\n        credentials() {\n            return _credentials;\n        },\n    };\n};\nconst resolveHttpAuthRuntimeConfig = (config) => {\n    return {\n        httpAuthSchemes: config.httpAuthSchemes(),\n        httpAuthSchemeProvider: config.httpAuthSchemeProvider(),\n        credentials: config.credentials(),\n    };\n};\n\nconst resolveRuntimeExtensions = (runtimeConfig, extensions) => {\n    const extensionConfiguration = Object.assign(regionConfigResolver.getAwsRegionExtensionConfiguration(runtimeConfig), smithyClient.getDefaultExtensionConfiguration(runtimeConfig), protocolHttp.getHttpHandlerExtensionConfiguration(runtimeConfig), getHttpAuthExtensionConfiguration(runtimeConfig));\n    extensions.forEach((extension) => extension.configure(extensionConfiguration));\n    return Object.assign(runtimeConfig, regionConfigResolver.resolveAwsRegionExtensionConfiguration(extensionConfiguration), smithyClient.resolveDefaultRuntimeConfig(extensionConfiguration), protocolHttp.resolveHttpHandlerRuntimeConfig(extensionConfiguration), resolveHttpAuthRuntimeConfig(extensionConfiguration));\n};\n\nclass ElasticBeanstalkClient extends smithyClient.Client {\n    config;\n    constructor(...[configuration]) {\n        const _config_0 = runtimeConfig.getRuntimeConfig(configuration || {});\n        super(_config_0);\n        this.initConfig = _config_0;\n        const _config_1 = resolveClientEndpointParameters(_config_0);\n        const _config_2 = middlewareUserAgent.resolveUserAgentConfig(_config_1);\n        const _config_3 = middlewareRetry.resolveRetryConfig(_config_2);\n        const _config_4 = configResolver.resolveRegionConfig(_config_3);\n        const _config_5 = middlewareHostHeader.resolveHostHeaderConfig(_config_4);\n        const _config_6 = middlewareEndpoint.resolveEndpointConfig(_config_5);\n        const _config_7 = httpAuthSchemeProvider.resolveHttpAuthSchemeConfig(_config_6);\n        const _config_8 = resolveRuntimeExtensions(_config_7, configuration?.extensions || []);\n        this.config = _config_8;\n        this.middlewareStack.use(schema.getSchemaSerdePlugin(this.config));\n        this.middlewareStack.use(middlewareUserAgent.getUserAgentPlugin(this.config));\n        this.middlewareStack.use(middlewareRetry.getRetryPlugin(this.config));\n        this.middlewareStack.use(middlewareContentLength.getContentLengthPlugin(this.config));\n        this.middlewareStack.use(middlewareHostHeader.getHostHeaderPlugin(this.config));\n        this.middlewareStack.use(middlewareLogger.getLoggerPlugin(this.config));\n        this.middlewareStack.use(middlewareRecursionDetection.getRecursionDetectionPlugin(this.config));\n        this.middlewareStack.use(core.getHttpAuthSchemeEndpointRuleSetPlugin(this.config, {\n            httpAuthSchemeParametersProvider: httpAuthSchemeProvider.defaultElasticBeanstalkHttpAuthSchemeParametersProvider,\n            identityProviderConfigProvider: async (config) => new core.DefaultIdentityProviderConfig({\n                \"aws.auth#sigv4\": config.credentials,\n            }),\n        }));\n        this.middlewareStack.use(core.getHttpSigningPlugin(this.config));\n    }\n    destroy() {\n        super.destroy();\n    }\n}\n\nclass ElasticBeanstalkSyntheticServiceException extends smithyClient.ServiceException {\n    constructor(options) {\n        super(options);\n        Object.setPrototypeOf(this, ElasticBeanstalkSyntheticServiceException.prototype);\n    }\n}\n\nclass InsufficientPrivilegesException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"InsufficientPrivilegesException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"InsufficientPrivilegesException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, InsufficientPrivilegesException.prototype);\n    }\n}\nclass ElasticBeanstalkServiceException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"ElasticBeanstalkServiceException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"ElasticBeanstalkServiceException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, ElasticBeanstalkServiceException.prototype);\n    }\n}\nclass ManagedActionInvalidStateException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"ManagedActionInvalidStateException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"ManagedActionInvalidStateException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, ManagedActionInvalidStateException.prototype);\n    }\n}\nclass TooManyEnvironmentsException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"TooManyEnvironmentsException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"TooManyEnvironmentsException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, TooManyEnvironmentsException.prototype);\n    }\n}\nclass TooManyApplicationsException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"TooManyApplicationsException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"TooManyApplicationsException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, TooManyApplicationsException.prototype);\n    }\n}\nclass CodeBuildNotInServiceRegionException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"CodeBuildNotInServiceRegionException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"CodeBuildNotInServiceRegionException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, CodeBuildNotInServiceRegionException.prototype);\n    }\n}\nclass S3LocationNotInServiceRegionException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"S3LocationNotInServiceRegionException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"S3LocationNotInServiceRegionException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, S3LocationNotInServiceRegionException.prototype);\n    }\n}\nclass TooManyApplicationVersionsException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"TooManyApplicationVersionsException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"TooManyApplicationVersionsException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, TooManyApplicationVersionsException.prototype);\n    }\n}\nclass TooManyBucketsException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"TooManyBucketsException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"TooManyBucketsException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, TooManyBucketsException.prototype);\n    }\n}\nclass TooManyConfigurationTemplatesException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"TooManyConfigurationTemplatesException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"TooManyConfigurationTemplatesException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, TooManyConfigurationTemplatesException.prototype);\n    }\n}\nclass TooManyPlatformsException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"TooManyPlatformsException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"TooManyPlatformsException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, TooManyPlatformsException.prototype);\n    }\n}\nclass S3SubscriptionRequiredException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"S3SubscriptionRequiredException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"S3SubscriptionRequiredException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, S3SubscriptionRequiredException.prototype);\n    }\n}\nclass OperationInProgressException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"OperationInProgressException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"OperationInProgressException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, OperationInProgressException.prototype);\n    }\n}\nclass SourceBundleDeletionException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"SourceBundleDeletionException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"SourceBundleDeletionException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, SourceBundleDeletionException.prototype);\n    }\n}\nclass PlatformVersionStillReferencedException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"PlatformVersionStillReferencedException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"PlatformVersionStillReferencedException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, PlatformVersionStillReferencedException.prototype);\n    }\n}\nclass InvalidRequestException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"InvalidRequestException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"InvalidRequestException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, InvalidRequestException.prototype);\n    }\n}\nclass ResourceNotFoundException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"ResourceNotFoundException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"ResourceNotFoundException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, ResourceNotFoundException.prototype);\n    }\n}\nclass ResourceTypeNotSupportedException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"ResourceTypeNotSupportedException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"ResourceTypeNotSupportedException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, ResourceTypeNotSupportedException.prototype);\n    }\n}\nclass TooManyTagsException extends ElasticBeanstalkSyntheticServiceException {\n    name = \"TooManyTagsException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"TooManyTagsException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, TooManyTagsException.prototype);\n    }\n}\n\nconst _A = \"Application\";\nconst _AA = \"ApplicationArn\";\nconst _ACA = \"AutoCreateApplication\";\nconst _AD = \"ApplicationDescription\";\nconst _ADL = \"ApplicationDescriptionList\";\nconst _ADM = \"ApplicationDescriptionMessage\";\nconst _ADMp = \"ApplicationDescriptionsMessage\";\nconst _ADc = \"ActionDescription\";\nconst _AEMA = \"ApplyEnvironmentManagedAction\";\nconst _AEMAR = \"ApplyEnvironmentManagedActionRequest\";\nconst _AEMARp = \"ApplyEnvironmentManagedActionResult\";\nconst _AEOR = \"AssociateEnvironmentOperationsRole\";\nconst _AEORM = \"AssociateEnvironmentOperationsRoleMessage\";\nconst _AEU = \"AbortEnvironmentUpdate\";\nconst _AEUM = \"AbortEnvironmentUpdateMessage\";\nconst _AI = \"ActionId\";\nconst _AM = \"ApplicationMetrics\";\nconst _AN = \"ApplicationName\";\nconst _ANp = \"ApplicationNames\";\nconst _ANr = \"ArtifactName\";\nconst _ANt = \"AttributeNames\";\nconst _AOIP = \"AbortableOperationInProgress\";\nconst _AQ = \"ApplicationQuota\";\nconst _ARLC = \"ApplicationResourceLifecycleConfig\";\nconst _ARLDM = \"ApplicationResourceLifecycleDescriptionMessage\";\nconst _ARN = \"ARN\";\nconst _ASG = \"AutoScalingGroup\";\nconst _ASGL = \"AutoScalingGroupList\";\nconst _ASGu = \"AutoScalingGroups\";\nconst _ASSDL = \"AvailableSolutionStackDetailsList\";\nconst _AT = \"ActionType\";\nconst _AV = \"ApplicationVersion\";\nconst _AVA = \"ApplicationVersionArn\";\nconst _AVD = \"ApplicationVersionDescription\";\nconst _AVDL = \"ApplicationVersionDescriptionList\";\nconst _AVDM = \"ApplicationVersionDescriptionMessage\";\nconst _AVDMp = \"ApplicationVersionDescriptionsMessage\";\nconst _AVLC = \"ApplicationVersionLifecycleConfig\";\nconst _AVQ = \"ApplicationVersionQuota\";\nconst _AVp = \"ApplicationVersions\";\nconst _AZ = \"AvailabilityZone\";\nconst _Ap = \"Applications\";\nconst _At = \"Attribute\";\nconst _Av = \"Available\";\nconst _B = \"Builder\";\nconst _BA = \"BuildArn\";\nconst _BC = \"BuildConfiguration\";\nconst _BN = \"BranchName\";\nconst _BO = \"BranchOrder\";\nconst _C = \"Color\";\nconst _CA = \"CustomAmi\";\nconst _CAL = \"CustomAmiList\";\nconst _CAM = \"CreateApplicationMessage\";\nconst _CAV = \"CreateApplicationVersion\";\nconst _CAVM = \"CreateApplicationVersionMessage\";\nconst _CAr = \"CreateApplication\";\nconst _CBNISRE = \"CodeBuildNotInServiceRegionException\";\nconst _CBSR = \"CodeBuildServiceRole\";\nconst _CCT = \"CreateConfigurationTemplate\";\nconst _CCTM = \"CreateConfigurationTemplateMessage\";\nconst _CDNSA = \"CheckDNSAvailability\";\nconst _CDNSAM = \"CheckDNSAvailabilityMessage\";\nconst _CDNSARM = \"CheckDNSAvailabilityResultMessage\";\nconst _CE = \"ComposeEnvironments\";\nconst _CEM = \"ComposeEnvironmentsMessage\";\nconst _CEMr = \"CreateEnvironmentMessage\";\nconst _CEr = \"CreateEnvironment\";\nconst _CNAME = \"CNAME\";\nconst _CNAMEP = \"CNAMEPrefix\";\nconst _COD = \"ConfigurationOptionDescription\";\nconst _CODL = \"ConfigurationOptionDescriptionsList\";\nconst _CODo = \"ConfigurationOptionsDescription\";\nconst _COS = \"ConfigurationOptionSetting\";\nconst _COSL = \"ConfigurationOptionSettingsList\";\nconst _CPQ = \"CustomPlatformQuota\";\nconst _CPUU = \"CPUUtilization\";\nconst _CPV = \"CreatePlatformVersion\";\nconst _CPVR = \"CreatePlatformVersionRequest\";\nconst _CPVRr = \"CreatePlatformVersionResult\";\nconst _CS = \"ChangeSeverity\";\nconst _CSD = \"ConfigurationSettingsDescription\";\nconst _CSDL = \"ConfigurationSettingsDescriptionList\";\nconst _CSDo = \"ConfigurationSettingsDescriptions\";\nconst _CSL = \"CreateStorageLocation\";\nconst _CSLRM = \"CreateStorageLocationResultMessage\";\nconst _CSVM = \"ConfigurationSettingsValidationMessages\";\nconst _CSo = \"ConfigurationSettings\";\nconst _CT = \"ConfigurationTemplates\";\nconst _CTQ = \"ConfigurationTemplateQuota\";\nconst _CTo = \"ComputeType\";\nconst _Ca = \"Causes\";\nconst _D = \"Description\";\nconst _DA = \"DeleteApplication\";\nconst _DAA = \"DescribeAccountAttributes\";\nconst _DAAR = \"DescribeAccountAttributesResult\";\nconst _DAM = \"DeleteApplicationMessage\";\nconst _DAMe = \"DescribeApplicationsMessage\";\nconst _DAV = \"DeleteApplicationVersion\";\nconst _DAVM = \"DeleteApplicationVersionMessage\";\nconst _DAVMe = \"DescribeApplicationVersionsMessage\";\nconst _DAVe = \"DescribeApplicationVersions\";\nconst _DAe = \"DescribeApplications\";\nconst _DC = \"DateCreated\";\nconst _DCO = \"DescribeConfigurationOptions\";\nconst _DCOM = \"DescribeConfigurationOptionsMessage\";\nconst _DCS = \"DescribeConfigurationSettings\";\nconst _DCSM = \"DescribeConfigurationSettingsMessage\";\nconst _DCT = \"DeleteConfigurationTemplate\";\nconst _DCTM = \"DeleteConfigurationTemplateMessage\";\nconst _DE = \"DescribeEnvironments\";\nconst _DEC = \"DeleteEnvironmentConfiguration\";\nconst _DECM = \"DeleteEnvironmentConfigurationMessage\";\nconst _DEH = \"DescribeEnvironmentHealth\";\nconst _DEHR = \"DescribeEnvironmentHealthRequest\";\nconst _DEHRe = \"DescribeEnvironmentHealthResult\";\nconst _DEI = \"DestinationEnvironmentId\";\nconst _DEM = \"DescribeEnvironmentsMessage\";\nconst _DEMA = \"DescribeEnvironmentManagedActions\";\nconst _DEMAH = \"DescribeEnvironmentManagedActionHistory\";\nconst _DEMAHR = \"DescribeEnvironmentManagedActionHistoryRequest\";\nconst _DEMAHRe = \"DescribeEnvironmentManagedActionHistoryResult\";\nconst _DEMAR = \"DescribeEnvironmentManagedActionsRequest\";\nconst _DEMARe = \"DescribeEnvironmentManagedActionsResult\";\nconst _DEMe = \"DescribeEventsMessage\";\nconst _DEN = \"DestinationEnvironmentName\";\nconst _DEOR = \"DisassociateEnvironmentOperationsRole\";\nconst _DEORM = \"DisassociateEnvironmentOperationsRoleMessage\";\nconst _DER = \"DescribeEnvironmentResources\";\nconst _DERM = \"DescribeEnvironmentResourcesMessage\";\nconst _DEe = \"DescribeEvents\";\nconst _DI = \"DeploymentId\";\nconst _DIH = \"DescribeInstancesHealth\";\nconst _DIHR = \"DescribeInstancesHealthRequest\";\nconst _DIHRe = \"DescribeInstancesHealthResult\";\nconst _DPV = \"DeletePlatformVersion\";\nconst _DPVR = \"DeletePlatformVersionRequest\";\nconst _DPVRe = \"DeletePlatformVersionResult\";\nconst _DPVRes = \"DescribePlatformVersionRequest\";\nconst _DPVResc = \"DescribePlatformVersionResult\";\nconst _DPVe = \"DescribePlatformVersion\";\nconst _DS = \"DeploymentStatus\";\nconst _DSB = \"DeleteSourceBundle\";\nconst _DSFS = \"DeleteSourceFromS3\";\nconst _DT = \"DeploymentTime\";\nconst _DU = \"DateUpdated\";\nconst _DV = \"DefaultValue\";\nconst _De = \"Deployment\";\nconst _Deg = \"Degraded\";\nconst _Do = \"Domain\";\nconst _Du = \"Duration\";\nconst _E = \"Environments\";\nconst _EA = \"EnvironmentArn\";\nconst _EBSE = \"ElasticBeanstalkServiceException\";\nconst _ED = \"EnvironmentDescription\";\nconst _EDL = \"EnvironmentDescriptionsList\";\nconst _EDLv = \"EventDescriptionList\";\nconst _EDM = \"EnvironmentDescriptionsMessage\";\nconst _EDMv = \"EventDescriptionsMessage\";\nconst _EDv = \"EventDescription\";\nconst _EDve = \"EventDate\";\nconst _EI = \"EnvironmentId\";\nconst _EID = \"EnvironmentInfoDescription\";\nconst _EIDL = \"EnvironmentInfoDescriptionList\";\nconst _EII = \"Ec2InstanceId\";\nconst _EIn = \"EnvironmentIds\";\nconst _EInv = \"EnvironmentInfo\";\nconst _EL = \"EnvironmentLinks\";\nconst _ELn = \"EnvironmentLink\";\nconst _EN = \"EnvironmentName\";\nconst _ENn = \"EnvironmentNames\";\nconst _EQ = \"EnvironmentQuota\";\nconst _ER = \"EnvironmentResources\";\nconst _ERD = \"EnvironmentResourceDescription\";\nconst _ERDM = \"EnvironmentResourceDescriptionsMessage\";\nconst _ERDn = \"EnvironmentResourcesDescription\";\nconst _ET = \"EndTime\";\nconst _ETn = \"EnvironmentTier\";\nconst _ETx = \"ExecutedTime\";\nconst _EURL = \"EndpointURL\";\nconst _En = \"Enabled\";\nconst _Ev = \"Events\";\nconst _F = \"Filters\";\nconst _FD = \"FailureDescription\";\nconst _FQCNAME = \"FullyQualifiedCNAME\";\nconst _FT = \"FailureType\";\nconst _FTi = \"FinishedTime\";\nconst _FTo = \"ForceTerminate\";\nconst _Fr = \"Frameworks\";\nconst _GN = \"GroupName\";\nconst _H = \"Health\";\nconst _HS = \"HealthStatus\";\nconst _I = \"Image\";\nconst _ID = \"IncludeDeleted\";\nconst _IDBT = \"IncludedDeletedBackTo\";\nconst _IH = \"InstancesHealth\";\nconst _IHL = \"InstanceHealthList\";\nconst _IHS = \"InstanceHealthSummary\";\nconst _II = \"ImageId\";\nconst _IIn = \"InstanceId\";\nconst _IL = \"InstanceList\";\nconst _IOW = \"IOWait\";\nconst _IPE = \"InsufficientPrivilegesException\";\nconst _IRE = \"InvalidRequestException\";\nconst _IRQ = \"IRQ\";\nconst _IT = \"InfoType\";\nconst _ITn = \"InstanceType\";\nconst _Id = \"Idle\";\nconst _Id_ = \"Id\";\nconst _In = \"Instances\";\nconst _Inf = \"Info\";\nconst _Ins = \"Instance\";\nconst _K = \"Key\";\nconst _L = \"Latency\";\nconst _LA = \"LaunchedAt\";\nconst _LASS = \"ListAvailableSolutionStacks\";\nconst _LASSRM = \"ListAvailableSolutionStacksResultMessage\";\nconst _LAo = \"LoadAverage\";\nconst _LB = \"LoadBalancers\";\nconst _LBD = \"LoadBalancerDescription\";\nconst _LBL = \"LoadBalancerList\";\nconst _LBLD = \"LoadBalancerListenersDescription\";\nconst _LBN = \"LoadBalancerName\";\nconst _LBo = \"LoadBalancer\";\nconst _LC = \"LaunchConfigurations\";\nconst _LCL = \"LaunchConfigurationList\";\nconst _LCa = \"LaunchConfiguration\";\nconst _LN = \"LinkName\";\nconst _LPB = \"ListPlatformBranches\";\nconst _LPBR = \"ListPlatformBranchesRequest\";\nconst _LPBRi = \"ListPlatformBranchesResult\";\nconst _LPV = \"ListPlatformVersions\";\nconst _LPVR = \"ListPlatformVersionsRequest\";\nconst _LPVRi = \"ListPlatformVersionsResult\";\nconst _LS = \"LifecycleState\";\nconst _LT = \"LaunchTemplates\";\nconst _LTFR = \"ListTagsForResource\";\nconst _LTFRM = \"ListTagsForResourceMessage\";\nconst _LTL = \"LaunchTemplateList\";\nconst _LTa = \"LaunchTemplate\";\nconst _La = \"Label\";\nconst _Li = \"Listener\";\nconst _Lis = \"Listeners\";\nconst _M = \"Messages\";\nconst _MA = \"ManagedActions\";\nconst _MAHI = \"ManagedActionHistoryItems\";\nconst _MAHIa = \"ManagedActionHistoryItem\";\nconst _MAID = \"MaxAgeInDays\";\nconst _MAISE = \"ManagedActionInvalidStateException\";\nconst _MAR = \"MaxAgeRule\";\nconst _MAa = \"ManagedAction\";\nconst _MC = \"MaxCount\";\nconst _MCR = \"MaxCountRule\";\nconst _MI = \"MaxItems\";\nconst _ML = \"MaxLength\";\nconst _MR = \"MaxRecords\";\nconst _MV = \"MinValue\";\nconst _MVa = \"MaxValue\";\nconst _Ma = \"Maintainer\";\nconst _Max = \"Maximum\";\nconst _Me = \"Message\";\nconst _N = \"Name\";\nconst _ND = \"NoData\";\nconst _NT = \"NextToken\";\nconst _Na = \"Namespace\";\nconst _Ni = \"Nice\";\nconst _O = \"Options\";\nconst _OIPE = \"OperationInProgressException\";\nconst _ON = \"OptionName\";\nconst _OR = \"OperationsRole\";\nconst _ORR = \"OptionRestrictionRegex\";\nconst _OS = \"OptionSettings\";\nconst _OSL = \"OptionsSpecifierList\";\nconst _OSN = \"OperatingSystemName\";\nconst _OSV = \"OperatingSystemVersion\";\nconst _OSp = \"OptionSpecification\";\nconst _OTR = \"OptionsToRemove\";\nconst _Ok = \"Ok\";\nconst _Op = \"Operator\";\nconst _P = \"Privileged\";\nconst _PA = \"PlatformArn\";\nconst _PBLS = \"PlatformBranchLifecycleState\";\nconst _PBN = \"PlatformBranchName\";\nconst _PBS = \"PlatformBranchSummary\";\nconst _PBSL = \"PlatformBranchSummaryList\";\nconst _PC = \"PlatformCategory\";\nconst _PD = \"PlatformDescription\";\nconst _PDB = \"PlatformDefinitionBundle\";\nconst _PF = \"PlatformFilter\";\nconst _PFT = \"PermittedFileTypes\";\nconst _PFl = \"PlatformFramework\";\nconst _PFla = \"PlatformFilters\";\nconst _PFlat = \"PlatformFrameworks\";\nconst _PL = \"ProgrammingLanguages\";\nconst _PLS = \"PlatformLifecycleState\";\nconst _PN = \"PlatformName\";\nconst _PO = \"PlatformOwner\";\nconst _PPL = \"PlatformProgrammingLanguage\";\nconst _PPLl = \"PlatformProgrammingLanguages\";\nconst _PS = \"PlatformSummary\";\nconst _PSL = \"PlatformSummaryList\";\nconst _PSl = \"PlatformStatus\";\nconst _PV = \"PlatformVersion\";\nconst _PVSRE = \"PlatformVersionStillReferencedException\";\nconst _P_ = \"P999\";\nconst _P__ = \"P99\";\nconst _P___ = \"P95\";\nconst _P____ = \"P90\";\nconst _P_____ = \"P85\";\nconst _P______ = \"P75\";\nconst _P_______ = \"P50\";\nconst _P________ = \"P10\";\nconst _Pa = \"Pattern\";\nconst _Pe = \"Pending\";\nconst _Po = \"Port\";\nconst _Pr = \"Process\";\nconst _Pro = \"Protocol\";\nconst _Q = \"Queues\";\nconst _QL = \"QueueList\";\nconst _Qu = \"Queue\";\nconst _R = \"Regex\";\nconst _RA = \"RefreshedAt\";\nconst _RAS = \"RestartAppServer\";\nconst _RASM = \"RestartAppServerMessage\";\nconst _RAe = \"ResourceArn\";\nconst _RC = \"RequestCount\";\nconst _RE = \"RebuildEnvironment\";\nconst _REI = \"RequestEnvironmentInfo\";\nconst _REIM = \"RequestEnvironmentInfoMessage\";\nconst _REIMe = \"RetrieveEnvironmentInfoMessage\";\nconst _REIRM = \"RetrieveEnvironmentInfoResultMessage\";\nconst _REIe = \"RetrieveEnvironmentInfo\";\nconst _REM = \"RebuildEnvironmentMessage\";\nconst _RI = \"RequestId\";\nconst _RLC = \"ResourceLifecycleConfig\";\nconst _RN = \"ResourceName\";\nconst _RNFE = \"ResourceNotFoundException\";\nconst _RQ = \"ResourceQuotas\";\nconst _RQe = \"ResourceQuota\";\nconst _RT = \"ResourceTags\";\nconst _RTDM = \"ResourceTagsDescriptionMessage\";\nconst _RTNSE = \"ResourceTypeNotSupportedException\";\nconst _Re = \"Resources\";\nconst _S = \"Status\";\nconst _SAL = \"SupportedAddonList\";\nconst _SB = \"SourceBundle\";\nconst _SBDE = \"SourceBundleDeletionException\";\nconst _SBI = \"SourceBuildInformation\";\nconst _SBu = \"S3Bucket\";\nconst _SC = \"StatusCodes\";\nconst _SCo = \"SourceConfiguration\";\nconst _SECNAME = \"SwapEnvironmentCNAMEs\";\nconst _SECNAMEM = \"SwapEnvironmentCNAMEsMessage\";\nconst _SEI = \"SourceEnvironmentId\";\nconst _SEN = \"SourceEnvironmentName\";\nconst _SF = \"SearchFilter\";\nconst _SFe = \"SearchFilters\";\nconst _SIH = \"SingleInstanceHealth\";\nconst _SIRQ = \"SoftIRQ\";\nconst _SK = \"S3Key\";\nconst _SL = \"S3Location\";\nconst _SLNISRE = \"S3LocationNotInServiceRegionException\";\nconst _SLo = \"SourceLocation\";\nconst _SR = \"ServiceRole\";\nconst _SRo = \"SourceRepository\";\nconst _SS = \"SolutionStacks\";\nconst _SSD = \"SolutionStackDetails\";\nconst _SSDo = \"SolutionStackDescription\";\nconst _SSN = \"SolutionStackName\";\nconst _SSRE = \"S3SubscriptionRequiredException\";\nconst _SSy = \"SystemStatus\";\nconst _ST = \"StartTime\";\nconst _STL = \"SupportedTierList\";\nconst _STa = \"SampleTimestamp\";\nconst _STo = \"SourceType\";\nconst _Se = \"Severity\";\nconst _Sev = \"Severe\";\nconst _St = \"Status2xx\";\nconst _Sta = \"Status3xx\";\nconst _Stat = \"Status4xx\";\nconst _Statu = \"Status5xx\";\nconst _Sy = \"System\";\nconst _T = \"Tags\";\nconst _TE = \"TerminateEnvironment\";\nconst _TEBF = \"TerminateEnvByForce\";\nconst _TEM = \"TerminateEnvironmentMessage\";\nconst _TIM = \"TimeoutInMinutes\";\nconst _TL = \"TagList\";\nconst _TLr = \"TriggerList\";\nconst _TMAE = \"TooManyApplicationsException\";\nconst _TMAVE = \"TooManyApplicationVersionsException\";\nconst _TMBE = \"TooManyBucketsException\";\nconst _TMCTE = \"TooManyConfigurationTemplatesException\";\nconst _TMEE = \"TooManyEnvironmentsException\";\nconst _TMPE = \"TooManyPlatformsException\";\nconst _TMTE = \"TooManyTagsException\";\nconst _TN = \"TemplateName\";\nconst _TR = \"TerminateResources\";\nconst _TTA = \"TagsToAdd\";\nconst _TTR = \"TagsToRemove\";\nconst _Ta = \"Tag\";\nconst _Ti = \"Tier\";\nconst _Tr = \"Triggers\";\nconst _Tri = \"Trigger\";\nconst _Ty = \"Type\";\nconst _U = \"User\";\nconst _UA = \"UpdateApplication\";\nconst _UAM = \"UpdateApplicationMessage\";\nconst _UARL = \"UpdateApplicationResourceLifecycle\";\nconst _UARLM = \"UpdateApplicationResourceLifecycleMessage\";\nconst _UAV = \"UpdateApplicationVersion\";\nconst _UAVM = \"UpdateApplicationVersionMessage\";\nconst _UCT = \"UpdateConfigurationTemplate\";\nconst _UCTM = \"UpdateConfigurationTemplateMessage\";\nconst _UD = \"UserDefined\";\nconst _UE = \"UpdateEnvironment\";\nconst _UEM = \"UpdateEnvironmentMessage\";\nconst _URL = \"URL\";\nconst _UTFR = \"UpdateTagsForResource\";\nconst _UTFRM = \"UpdateTagsForResourceMessage\";\nconst _Un = \"Unknown\";\nconst _V = \"Versions\";\nconst _VCS = \"ValidateConfigurationSettings\";\nconst _VCSM = \"ValidateConfigurationSettingsMessage\";\nconst _VL = \"VersionLabel\";\nconst _VLC = \"VersionLifecycleConfig\";\nconst _VLe = \"VersionLabels\";\nconst _VM = \"ValidationMessage\";\nconst _VML = \"ValidationMessagesList\";\nconst _VO = \"ValueOptions\";\nconst _VT = \"ValueType\";\nconst _VTi = \"VirtualizationType\";\nconst _Va = \"Value\";\nconst _Val = \"Values\";\nconst _Ve = \"Version\";\nconst _W = \"Warning\";\nconst _WST = \"WindowStartTime\";\nconst _aQE = \"awsQueryError\";\nconst _c = \"client\";\nconst _e = \"error\";\nconst _hE = \"httpError\";\nconst _m = \"message\";\nconst _s = \"smithy.ts.sdk.synthetic.com.amazonaws.elasticbeanstalk\";\nconst n0 = \"com.amazonaws.elasticbeanstalk\";\nvar AbortEnvironmentUpdateMessage$ = [3, n0, _AEUM,\n    0,\n    [_EI, _EN],\n    [0, 0]\n];\nvar ApplicationDescription$ = [3, n0, _AD,\n    0,\n    [_AA, _AN, _D, _DC, _DU, _V, _CT, _RLC],\n    [0, 0, 0, 4, 4, 64 | 0, 64 | 0, () => ApplicationResourceLifecycleConfig$]\n];\nvar ApplicationDescriptionMessage$ = [3, n0, _ADM,\n    0,\n    [_A],\n    [() => ApplicationDescription$]\n];\nvar ApplicationDescriptionsMessage$ = [3, n0, _ADMp,\n    0,\n    [_Ap],\n    [() => ApplicationDescriptionList]\n];\nvar ApplicationMetrics$ = [3, n0, _AM,\n    0,\n    [_Du, _RC, _SC, _L],\n    [1, 1, () => StatusCodes$, () => Latency$]\n];\nvar ApplicationResourceLifecycleConfig$ = [3, n0, _ARLC,\n    0,\n    [_SR, _VLC],\n    [0, () => ApplicationVersionLifecycleConfig$]\n];\nvar ApplicationResourceLifecycleDescriptionMessage$ = [3, n0, _ARLDM,\n    0,\n    [_AN, _RLC],\n    [0, () => ApplicationResourceLifecycleConfig$]\n];\nvar ApplicationVersionDescription$ = [3, n0, _AVD,\n    0,\n    [_AVA, _AN, _D, _VL, _SBI, _BA, _SB, _DC, _DU, _S],\n    [0, 0, 0, 0, () => SourceBuildInformation$, 0, () => S3Location$, 4, 4, 0]\n];\nvar ApplicationVersionDescriptionMessage$ = [3, n0, _AVDM,\n    0,\n    [_AV],\n    [() => ApplicationVersionDescription$]\n];\nvar ApplicationVersionDescriptionsMessage$ = [3, n0, _AVDMp,\n    0,\n    [_AVp, _NT],\n    [() => ApplicationVersionDescriptionList, 0]\n];\nvar ApplicationVersionLifecycleConfig$ = [3, n0, _AVLC,\n    0,\n    [_MCR, _MAR],\n    [() => MaxCountRule$, () => MaxAgeRule$]\n];\nvar ApplyEnvironmentManagedActionRequest$ = [3, n0, _AEMAR,\n    0,\n    [_AI, _EN, _EI],\n    [0, 0, 0], 1\n];\nvar ApplyEnvironmentManagedActionResult$ = [3, n0, _AEMARp,\n    0,\n    [_AI, _ADc, _AT, _S],\n    [0, 0, 0, 0]\n];\nvar AssociateEnvironmentOperationsRoleMessage$ = [3, n0, _AEORM,\n    0,\n    [_EN, _OR],\n    [0, 0], 2\n];\nvar AutoScalingGroup$ = [3, n0, _ASG,\n    0,\n    [_N],\n    [0]\n];\nvar BuildConfiguration$ = [3, n0, _BC,\n    0,\n    [_CBSR, _I, _ANr, _CTo, _TIM],\n    [0, 0, 0, 0, 1], 2\n];\nvar Builder$ = [3, n0, _B,\n    0,\n    [_ARN],\n    [0]\n];\nvar CheckDNSAvailabilityMessage$ = [3, n0, _CDNSAM,\n    0,\n    [_CNAMEP],\n    [0], 1\n];\nvar CheckDNSAvailabilityResultMessage$ = [3, n0, _CDNSARM,\n    0,\n    [_Av, _FQCNAME],\n    [2, 0]\n];\nvar CodeBuildNotInServiceRegionException$ = [-3, n0, _CBNISRE,\n    { [_aQE]: [`CodeBuildNotInServiceRegionException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(CodeBuildNotInServiceRegionException$, CodeBuildNotInServiceRegionException);\nvar ComposeEnvironmentsMessage$ = [3, n0, _CEM,\n    0,\n    [_AN, _GN, _VLe],\n    [0, 0, 64 | 0]\n];\nvar ConfigurationOptionDescription$ = [3, n0, _COD,\n    0,\n    [_Na, _N, _DV, _CS, _UD, _VT, _VO, _MV, _MVa, _ML, _R],\n    [0, 0, 0, 0, 2, 0, 64 | 0, 1, 1, 1, () => OptionRestrictionRegex$]\n];\nvar ConfigurationOptionsDescription$ = [3, n0, _CODo,\n    0,\n    [_SSN, _PA, _O],\n    [0, 0, () => ConfigurationOptionDescriptionsList]\n];\nvar ConfigurationOptionSetting$ = [3, n0, _COS,\n    0,\n    [_RN, _Na, _ON, _Va],\n    [0, 0, 0, 0]\n];\nvar ConfigurationSettingsDescription$ = [3, n0, _CSD,\n    0,\n    [_SSN, _PA, _AN, _TN, _D, _EN, _DS, _DC, _DU, _OS],\n    [0, 0, 0, 0, 0, 0, 0, 4, 4, () => ConfigurationOptionSettingsList]\n];\nvar ConfigurationSettingsDescriptions$ = [3, n0, _CSDo,\n    0,\n    [_CSo],\n    [() => ConfigurationSettingsDescriptionList]\n];\nvar ConfigurationSettingsValidationMessages$ = [3, n0, _CSVM,\n    0,\n    [_M],\n    [() => ValidationMessagesList]\n];\nvar CPUUtilization$ = [3, n0, _CPUU,\n    0,\n    [_U, _Ni, _Sy, _Id, _IOW, _IRQ, _SIRQ, _P],\n    [1, 1, 1, 1, 1, 1, 1, 1]\n];\nvar CreateApplicationMessage$ = [3, n0, _CAM,\n    0,\n    [_AN, _D, _RLC, _T],\n    [0, 0, () => ApplicationResourceLifecycleConfig$, () => Tags], 1\n];\nvar CreateApplicationVersionMessage$ = [3, n0, _CAVM,\n    0,\n    [_AN, _VL, _D, _SBI, _SB, _BC, _ACA, _Pr, _T],\n    [0, 0, 0, () => SourceBuildInformation$, () => S3Location$, () => BuildConfiguration$, 2, 2, () => Tags], 2\n];\nvar CreateConfigurationTemplateMessage$ = [3, n0, _CCTM,\n    0,\n    [_AN, _TN, _SSN, _PA, _SCo, _EI, _D, _OS, _T],\n    [0, 0, 0, 0, () => SourceConfiguration$, 0, 0, () => ConfigurationOptionSettingsList, () => Tags], 2\n];\nvar CreateEnvironmentMessage$ = [3, n0, _CEMr,\n    0,\n    [_AN, _EN, _GN, _D, _CNAMEP, _Ti, _T, _VL, _TN, _SSN, _PA, _OS, _OTR, _OR],\n    [0, 0, 0, 0, 0, () => EnvironmentTier$, () => Tags, 0, 0, 0, 0, () => ConfigurationOptionSettingsList, () => OptionsSpecifierList, 0], 1\n];\nvar CreatePlatformVersionRequest$ = [3, n0, _CPVR,\n    0,\n    [_PN, _PV, _PDB, _EN, _OS, _T],\n    [0, 0, () => S3Location$, 0, () => ConfigurationOptionSettingsList, () => Tags], 3\n];\nvar CreatePlatformVersionResult$ = [3, n0, _CPVRr,\n    0,\n    [_PS, _B],\n    [() => PlatformSummary$, () => Builder$]\n];\nvar CreateStorageLocationResultMessage$ = [3, n0, _CSLRM,\n    0,\n    [_SBu],\n    [0]\n];\nvar CustomAmi$ = [3, n0, _CA,\n    0,\n    [_VTi, _II],\n    [0, 0]\n];\nvar DeleteApplicationMessage$ = [3, n0, _DAM,\n    0,\n    [_AN, _TEBF],\n    [0, 2], 1\n];\nvar DeleteApplicationVersionMessage$ = [3, n0, _DAVM,\n    0,\n    [_AN, _VL, _DSB],\n    [0, 0, 2], 2\n];\nvar DeleteConfigurationTemplateMessage$ = [3, n0, _DCTM,\n    0,\n    [_AN, _TN],\n    [0, 0], 2\n];\nvar DeleteEnvironmentConfigurationMessage$ = [3, n0, _DECM,\n    0,\n    [_AN, _EN],\n    [0, 0], 2\n];\nvar DeletePlatformVersionRequest$ = [3, n0, _DPVR,\n    0,\n    [_PA],\n    [0]\n];\nvar DeletePlatformVersionResult$ = [3, n0, _DPVRe,\n    0,\n    [_PS],\n    [() => PlatformSummary$]\n];\nvar Deployment$ = [3, n0, _De,\n    0,\n    [_VL, _DI, _S, _DT],\n    [0, 1, 0, 4]\n];\nvar DescribeAccountAttributesResult$ = [3, n0, _DAAR,\n    0,\n    [_RQ],\n    [() => ResourceQuotas$]\n];\nvar DescribeApplicationsMessage$ = [3, n0, _DAMe,\n    0,\n    [_ANp],\n    [64 | 0]\n];\nvar DescribeApplicationVersionsMessage$ = [3, n0, _DAVMe,\n    0,\n    [_AN, _VLe, _MR, _NT],\n    [0, 64 | 0, 1, 0]\n];\nvar DescribeConfigurationOptionsMessage$ = [3, n0, _DCOM,\n    0,\n    [_AN, _TN, _EN, _SSN, _PA, _O],\n    [0, 0, 0, 0, 0, () => OptionsSpecifierList]\n];\nvar DescribeConfigurationSettingsMessage$ = [3, n0, _DCSM,\n    0,\n    [_AN, _TN, _EN],\n    [0, 0, 0], 1\n];\nvar DescribeEnvironmentHealthRequest$ = [3, n0, _DEHR,\n    0,\n    [_EN, _EI, _ANt],\n    [0, 0, 64 | 0]\n];\nvar DescribeEnvironmentHealthResult$ = [3, n0, _DEHRe,\n    0,\n    [_EN, _HS, _S, _C, _Ca, _AM, _IH, _RA],\n    [0, 0, 0, 0, 64 | 0, () => ApplicationMetrics$, () => InstanceHealthSummary$, 4]\n];\nvar DescribeEnvironmentManagedActionHistoryRequest$ = [3, n0, _DEMAHR,\n    0,\n    [_EI, _EN, _NT, _MI],\n    [0, 0, 0, 1]\n];\nvar DescribeEnvironmentManagedActionHistoryResult$ = [3, n0, _DEMAHRe,\n    0,\n    [_MAHI, _NT],\n    [() => ManagedActionHistoryItems, 0]\n];\nvar DescribeEnvironmentManagedActionsRequest$ = [3, n0, _DEMAR,\n    0,\n    [_EN, _EI, _S],\n    [0, 0, 0]\n];\nvar DescribeEnvironmentManagedActionsResult$ = [3, n0, _DEMARe,\n    0,\n    [_MA],\n    [() => ManagedActions]\n];\nvar DescribeEnvironmentResourcesMessage$ = [3, n0, _DERM,\n    0,\n    [_EI, _EN],\n    [0, 0]\n];\nvar DescribeEnvironmentsMessage$ = [3, n0, _DEM,\n    0,\n    [_AN, _VL, _EIn, _ENn, _ID, _IDBT, _MR, _NT],\n    [0, 0, 64 | 0, 64 | 0, 2, 4, 1, 0]\n];\nvar DescribeEventsMessage$ = [3, n0, _DEMe,\n    0,\n    [_AN, _VL, _TN, _EI, _EN, _PA, _RI, _Se, _ST, _ET, _MR, _NT],\n    [0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 1, 0]\n];\nvar DescribeInstancesHealthRequest$ = [3, n0, _DIHR,\n    0,\n    [_EN, _EI, _ANt, _NT],\n    [0, 0, 64 | 0, 0]\n];\nvar DescribeInstancesHealthResult$ = [3, n0, _DIHRe,\n    0,\n    [_IHL, _RA, _NT],\n    [() => InstanceHealthList, 4, 0]\n];\nvar DescribePlatformVersionRequest$ = [3, n0, _DPVRes,\n    0,\n    [_PA],\n    [0]\n];\nvar DescribePlatformVersionResult$ = [3, n0, _DPVResc,\n    0,\n    [_PD],\n    [() => PlatformDescription$]\n];\nvar DisassociateEnvironmentOperationsRoleMessage$ = [3, n0, _DEORM,\n    0,\n    [_EN],\n    [0], 1\n];\nvar ElasticBeanstalkServiceException$ = [-3, n0, _EBSE,\n    { [_e]: _c },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(ElasticBeanstalkServiceException$, ElasticBeanstalkServiceException);\nvar EnvironmentDescription$ = [3, n0, _ED,\n    0,\n    [_EN, _EI, _AN, _VL, _SSN, _PA, _TN, _D, _EURL, _CNAME, _DC, _DU, _S, _AOIP, _H, _HS, _Re, _Ti, _EL, _EA, _OR],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 0, 2, 0, 0, () => EnvironmentResourcesDescription$, () => EnvironmentTier$, () => EnvironmentLinks, 0, 0]\n];\nvar EnvironmentDescriptionsMessage$ = [3, n0, _EDM,\n    0,\n    [_E, _NT],\n    [() => EnvironmentDescriptionsList, 0]\n];\nvar EnvironmentInfoDescription$ = [3, n0, _EID,\n    0,\n    [_IT, _EII, _STa, _Me],\n    [0, 0, 4, 0]\n];\nvar EnvironmentLink$ = [3, n0, _ELn,\n    0,\n    [_LN, _EN],\n    [0, 0]\n];\nvar EnvironmentResourceDescription$ = [3, n0, _ERD,\n    0,\n    [_EN, _ASGu, _In, _LC, _LT, _LB, _Tr, _Q],\n    [0, () => AutoScalingGroupList, () => InstanceList, () => LaunchConfigurationList, () => LaunchTemplateList, () => LoadBalancerList, () => TriggerList, () => QueueList]\n];\nvar EnvironmentResourceDescriptionsMessage$ = [3, n0, _ERDM,\n    0,\n    [_ER],\n    [() => EnvironmentResourceDescription$]\n];\nvar EnvironmentResourcesDescription$ = [3, n0, _ERDn,\n    0,\n    [_LBo],\n    [() => LoadBalancerDescription$]\n];\nvar EnvironmentTier$ = [3, n0, _ETn,\n    0,\n    [_N, _Ty, _Ve],\n    [0, 0, 0]\n];\nvar EventDescription$ = [3, n0, _EDv,\n    0,\n    [_EDve, _Me, _AN, _VL, _TN, _EN, _PA, _RI, _Se],\n    [4, 0, 0, 0, 0, 0, 0, 0, 0]\n];\nvar EventDescriptionsMessage$ = [3, n0, _EDMv,\n    0,\n    [_Ev, _NT],\n    [() => EventDescriptionList, 0]\n];\nvar Instance$ = [3, n0, _Ins,\n    0,\n    [_Id_],\n    [0]\n];\nvar InstanceHealthSummary$ = [3, n0, _IHS,\n    0,\n    [_ND, _Un, _Pe, _Ok, _Inf, _W, _Deg, _Sev],\n    [1, 1, 1, 1, 1, 1, 1, 1]\n];\nvar InsufficientPrivilegesException$ = [-3, n0, _IPE,\n    { [_aQE]: [`InsufficientPrivilegesException`, 403], [_e]: _c, [_hE]: 403 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(InsufficientPrivilegesException$, InsufficientPrivilegesException);\nvar InvalidRequestException$ = [-3, n0, _IRE,\n    { [_aQE]: [`InvalidRequestException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(InvalidRequestException$, InvalidRequestException);\nvar Latency$ = [3, n0, _L,\n    0,\n    [_P_, _P__, _P___, _P____, _P_____, _P______, _P_______, _P________],\n    [1, 1, 1, 1, 1, 1, 1, 1]\n];\nvar LaunchConfiguration$ = [3, n0, _LCa,\n    0,\n    [_N],\n    [0]\n];\nvar LaunchTemplate$ = [3, n0, _LTa,\n    0,\n    [_Id_],\n    [0]\n];\nvar ListAvailableSolutionStacksResultMessage$ = [3, n0, _LASSRM,\n    0,\n    [_SS, _SSD],\n    [64 | 0, () => AvailableSolutionStackDetailsList]\n];\nvar Listener$ = [3, n0, _Li,\n    0,\n    [_Pro, _Po],\n    [0, 1]\n];\nvar ListPlatformBranchesRequest$ = [3, n0, _LPBR,\n    0,\n    [_F, _MR, _NT],\n    [() => SearchFilters, 1, 0]\n];\nvar ListPlatformBranchesResult$ = [3, n0, _LPBRi,\n    0,\n    [_PBSL, _NT],\n    [() => PlatformBranchSummaryList, 0]\n];\nvar ListPlatformVersionsRequest$ = [3, n0, _LPVR,\n    0,\n    [_F, _MR, _NT],\n    [() => PlatformFilters, 1, 0]\n];\nvar ListPlatformVersionsResult$ = [3, n0, _LPVRi,\n    0,\n    [_PSL, _NT],\n    [() => PlatformSummaryList, 0]\n];\nvar ListTagsForResourceMessage$ = [3, n0, _LTFRM,\n    0,\n    [_RAe],\n    [0], 1\n];\nvar LoadBalancer$ = [3, n0, _LBo,\n    0,\n    [_N],\n    [0]\n];\nvar LoadBalancerDescription$ = [3, n0, _LBD,\n    0,\n    [_LBN, _Do, _Lis],\n    [0, 0, () => LoadBalancerListenersDescription]\n];\nvar ManagedAction$ = [3, n0, _MAa,\n    0,\n    [_AI, _ADc, _AT, _S, _WST],\n    [0, 0, 0, 0, 4]\n];\nvar ManagedActionHistoryItem$ = [3, n0, _MAHIa,\n    0,\n    [_AI, _AT, _ADc, _FT, _S, _FD, _ETx, _FTi],\n    [0, 0, 0, 0, 0, 0, 4, 4]\n];\nvar ManagedActionInvalidStateException$ = [-3, n0, _MAISE,\n    { [_aQE]: [`ManagedActionInvalidStateException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(ManagedActionInvalidStateException$, ManagedActionInvalidStateException);\nvar MaxAgeRule$ = [3, n0, _MAR,\n    0,\n    [_En, _MAID, _DSFS],\n    [2, 1, 2], 1\n];\nvar MaxCountRule$ = [3, n0, _MCR,\n    0,\n    [_En, _MC, _DSFS],\n    [2, 1, 2], 1\n];\nvar OperationInProgressException$ = [-3, n0, _OIPE,\n    { [_aQE]: [`OperationInProgressFailure`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(OperationInProgressException$, OperationInProgressException);\nvar OptionRestrictionRegex$ = [3, n0, _ORR,\n    0,\n    [_Pa, _La],\n    [0, 0]\n];\nvar OptionSpecification$ = [3, n0, _OSp,\n    0,\n    [_RN, _Na, _ON],\n    [0, 0, 0]\n];\nvar PlatformBranchSummary$ = [3, n0, _PBS,\n    0,\n    [_PN, _BN, _LS, _BO, _STL],\n    [0, 0, 0, 1, 64 | 0]\n];\nvar PlatformDescription$ = [3, n0, _PD,\n    0,\n    [_PA, _PO, _PN, _PV, _SSN, _PSl, _DC, _DU, _PC, _D, _Ma, _OSN, _OSV, _PL, _Fr, _CAL, _STL, _SAL, _PLS, _PBN, _PBLS],\n    [0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, () => PlatformProgrammingLanguages, () => PlatformFrameworks, () => CustomAmiList, 64 | 0, 64 | 0, 0, 0, 0]\n];\nvar PlatformFilter$ = [3, n0, _PF,\n    0,\n    [_Ty, _Op, _Val],\n    [0, 0, 64 | 0]\n];\nvar PlatformFramework$ = [3, n0, _PFl,\n    0,\n    [_N, _Ve],\n    [0, 0]\n];\nvar PlatformProgrammingLanguage$ = [3, n0, _PPL,\n    0,\n    [_N, _Ve],\n    [0, 0]\n];\nvar PlatformSummary$ = [3, n0, _PS,\n    0,\n    [_PA, _PO, _PSl, _PC, _OSN, _OSV, _STL, _SAL, _PLS, _PV, _PBN, _PBLS],\n    [0, 0, 0, 0, 0, 0, 64 | 0, 64 | 0, 0, 0, 0, 0]\n];\nvar PlatformVersionStillReferencedException$ = [-3, n0, _PVSRE,\n    { [_aQE]: [`PlatformVersionStillReferencedException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(PlatformVersionStillReferencedException$, PlatformVersionStillReferencedException);\nvar Queue$ = [3, n0, _Qu,\n    0,\n    [_N, _URL],\n    [0, 0]\n];\nvar RebuildEnvironmentMessage$ = [3, n0, _REM,\n    0,\n    [_EI, _EN],\n    [0, 0]\n];\nvar RequestEnvironmentInfoMessage$ = [3, n0, _REIM,\n    0,\n    [_IT, _EI, _EN],\n    [0, 0, 0], 1\n];\nvar ResourceNotFoundException$ = [-3, n0, _RNFE,\n    { [_aQE]: [`ResourceNotFoundException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(ResourceNotFoundException$, ResourceNotFoundException);\nvar ResourceQuota$ = [3, n0, _RQe,\n    0,\n    [_Max],\n    [1]\n];\nvar ResourceQuotas$ = [3, n0, _RQ,\n    0,\n    [_AQ, _AVQ, _EQ, _CTQ, _CPQ],\n    [() => ResourceQuota$, () => ResourceQuota$, () => ResourceQuota$, () => ResourceQuota$, () => ResourceQuota$]\n];\nvar ResourceTagsDescriptionMessage$ = [3, n0, _RTDM,\n    0,\n    [_RAe, _RT],\n    [0, () => TagList]\n];\nvar ResourceTypeNotSupportedException$ = [-3, n0, _RTNSE,\n    { [_aQE]: [`ResourceTypeNotSupportedException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(ResourceTypeNotSupportedException$, ResourceTypeNotSupportedException);\nvar RestartAppServerMessage$ = [3, n0, _RASM,\n    0,\n    [_EI, _EN],\n    [0, 0]\n];\nvar RetrieveEnvironmentInfoMessage$ = [3, n0, _REIMe,\n    0,\n    [_IT, _EI, _EN],\n    [0, 0, 0], 1\n];\nvar RetrieveEnvironmentInfoResultMessage$ = [3, n0, _REIRM,\n    0,\n    [_EInv],\n    [() => EnvironmentInfoDescriptionList]\n];\nvar S3Location$ = [3, n0, _SL,\n    0,\n    [_SBu, _SK],\n    [0, 0]\n];\nvar S3LocationNotInServiceRegionException$ = [-3, n0, _SLNISRE,\n    { [_aQE]: [`S3LocationNotInServiceRegionException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(S3LocationNotInServiceRegionException$, S3LocationNotInServiceRegionException);\nvar S3SubscriptionRequiredException$ = [-3, n0, _SSRE,\n    { [_aQE]: [`S3SubscriptionRequiredException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(S3SubscriptionRequiredException$, S3SubscriptionRequiredException);\nvar SearchFilter$ = [3, n0, _SF,\n    0,\n    [_At, _Op, _Val],\n    [0, 0, 64 | 0]\n];\nvar SingleInstanceHealth$ = [3, n0, _SIH,\n    0,\n    [_IIn, _HS, _C, _Ca, _LA, _AM, _Sy, _De, _AZ, _ITn],\n    [0, 0, 0, 64 | 0, 4, () => ApplicationMetrics$, () => SystemStatus$, () => Deployment$, 0, 0]\n];\nvar SolutionStackDescription$ = [3, n0, _SSDo,\n    0,\n    [_SSN, _PFT],\n    [0, 64 | 0]\n];\nvar SourceBuildInformation$ = [3, n0, _SBI,\n    0,\n    [_STo, _SRo, _SLo],\n    [0, 0, 0], 3\n];\nvar SourceBundleDeletionException$ = [-3, n0, _SBDE,\n    { [_aQE]: [`SourceBundleDeletionFailure`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(SourceBundleDeletionException$, SourceBundleDeletionException);\nvar SourceConfiguration$ = [3, n0, _SCo,\n    0,\n    [_AN, _TN],\n    [0, 0]\n];\nvar StatusCodes$ = [3, n0, _SC,\n    0,\n    [_St, _Sta, _Stat, _Statu],\n    [1, 1, 1, 1]\n];\nvar SwapEnvironmentCNAMEsMessage$ = [3, n0, _SECNAMEM,\n    0,\n    [_SEI, _SEN, _DEI, _DEN],\n    [0, 0, 0, 0]\n];\nvar SystemStatus$ = [3, n0, _SSy,\n    0,\n    [_CPUU, _LAo],\n    [() => CPUUtilization$, 64 | 1]\n];\nvar Tag$ = [3, n0, _Ta,\n    0,\n    [_K, _Va],\n    [0, 0]\n];\nvar TerminateEnvironmentMessage$ = [3, n0, _TEM,\n    0,\n    [_EI, _EN, _TR, _FTo],\n    [0, 0, 2, 2]\n];\nvar TooManyApplicationsException$ = [-3, n0, _TMAE,\n    { [_aQE]: [`TooManyApplicationsException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(TooManyApplicationsException$, TooManyApplicationsException);\nvar TooManyApplicationVersionsException$ = [-3, n0, _TMAVE,\n    { [_e]: _c },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(TooManyApplicationVersionsException$, TooManyApplicationVersionsException);\nvar TooManyBucketsException$ = [-3, n0, _TMBE,\n    { [_aQE]: [`TooManyBucketsException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(TooManyBucketsException$, TooManyBucketsException);\nvar TooManyConfigurationTemplatesException$ = [-3, n0, _TMCTE,\n    { [_aQE]: [`TooManyConfigurationTemplatesException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(TooManyConfigurationTemplatesException$, TooManyConfigurationTemplatesException);\nvar TooManyEnvironmentsException$ = [-3, n0, _TMEE,\n    { [_aQE]: [`TooManyEnvironmentsException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(TooManyEnvironmentsException$, TooManyEnvironmentsException);\nvar TooManyPlatformsException$ = [-3, n0, _TMPE,\n    { [_aQE]: [`TooManyPlatformsException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(TooManyPlatformsException$, TooManyPlatformsException);\nvar TooManyTagsException$ = [-3, n0, _TMTE,\n    { [_aQE]: [`TooManyTagsException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(TooManyTagsException$, TooManyTagsException);\nvar Trigger$ = [3, n0, _Tri,\n    0,\n    [_N],\n    [0]\n];\nvar UpdateApplicationMessage$ = [3, n0, _UAM,\n    0,\n    [_AN, _D],\n    [0, 0], 1\n];\nvar UpdateApplicationResourceLifecycleMessage$ = [3, n0, _UARLM,\n    0,\n    [_AN, _RLC],\n    [0, () => ApplicationResourceLifecycleConfig$], 2\n];\nvar UpdateApplicationVersionMessage$ = [3, n0, _UAVM,\n    0,\n    [_AN, _VL, _D],\n    [0, 0, 0], 2\n];\nvar UpdateConfigurationTemplateMessage$ = [3, n0, _UCTM,\n    0,\n    [_AN, _TN, _D, _OS, _OTR],\n    [0, 0, 0, () => ConfigurationOptionSettingsList, () => OptionsSpecifierList], 2\n];\nvar UpdateEnvironmentMessage$ = [3, n0, _UEM,\n    0,\n    [_AN, _EI, _EN, _GN, _D, _Ti, _VL, _TN, _SSN, _PA, _OS, _OTR],\n    [0, 0, 0, 0, 0, () => EnvironmentTier$, 0, 0, 0, 0, () => ConfigurationOptionSettingsList, () => OptionsSpecifierList]\n];\nvar UpdateTagsForResourceMessage$ = [3, n0, _UTFRM,\n    0,\n    [_RAe, _TTA, _TTR],\n    [0, () => TagList, 64 | 0], 1\n];\nvar ValidateConfigurationSettingsMessage$ = [3, n0, _VCSM,\n    0,\n    [_AN, _OS, _TN, _EN],\n    [0, () => ConfigurationOptionSettingsList, 0, 0], 2\n];\nvar ValidationMessage$ = [3, n0, _VM,\n    0,\n    [_Me, _Se, _Na, _ON],\n    [0, 0, 0, 0]\n];\nvar __Unit = \"unit\";\nvar ElasticBeanstalkSyntheticServiceException$ = [-3, _s, \"ElasticBeanstalkSyntheticServiceException\", 0, [], []];\nschema.TypeRegistry.for(_s).registerError(ElasticBeanstalkSyntheticServiceException$, ElasticBeanstalkSyntheticServiceException);\nvar ApplicationDescriptionList = [1, n0, _ADL,\n    0, () => ApplicationDescription$\n];\nvar ApplicationVersionDescriptionList = [1, n0, _AVDL,\n    0, () => ApplicationVersionDescription$\n];\nvar AutoScalingGroupList = [1, n0, _ASGL,\n    0, () => AutoScalingGroup$\n];\nvar AvailableSolutionStackDetailsList = [1, n0, _ASSDL,\n    0, () => SolutionStackDescription$\n];\nvar ConfigurationOptionDescriptionsList = [1, n0, _CODL,\n    0, () => ConfigurationOptionDescription$\n];\nvar ConfigurationOptionSettingsList = [1, n0, _COSL,\n    0, () => ConfigurationOptionSetting$\n];\nvar ConfigurationSettingsDescriptionList = [1, n0, _CSDL,\n    0, () => ConfigurationSettingsDescription$\n];\nvar CustomAmiList = [1, n0, _CAL,\n    0, () => CustomAmi$\n];\nvar EnvironmentDescriptionsList = [1, n0, _EDL,\n    0, () => EnvironmentDescription$\n];\nvar EnvironmentInfoDescriptionList = [1, n0, _EIDL,\n    0, () => EnvironmentInfoDescription$\n];\nvar EnvironmentLinks = [1, n0, _EL,\n    0, () => EnvironmentLink$\n];\nvar EventDescriptionList = [1, n0, _EDLv,\n    0, () => EventDescription$\n];\nvar InstanceHealthList = [1, n0, _IHL,\n    0, () => SingleInstanceHealth$\n];\nvar InstanceList = [1, n0, _IL,\n    0, () => Instance$\n];\nvar LaunchConfigurationList = [1, n0, _LCL,\n    0, () => LaunchConfiguration$\n];\nvar LaunchTemplateList = [1, n0, _LTL,\n    0, () => LaunchTemplate$\n];\nvar LoadBalancerList = [1, n0, _LBL,\n    0, () => LoadBalancer$\n];\nvar LoadBalancerListenersDescription = [1, n0, _LBLD,\n    0, () => Listener$\n];\nvar ManagedActionHistoryItems = [1, n0, _MAHI,\n    0, () => ManagedActionHistoryItem$\n];\nvar ManagedActions = [1, n0, _MA,\n    0, () => ManagedAction$\n];\nvar OptionsSpecifierList = [1, n0, _OSL,\n    0, () => OptionSpecification$\n];\nvar PlatformBranchSummaryList = [1, n0, _PBSL,\n    0, () => PlatformBranchSummary$\n];\nvar PlatformFilters = [1, n0, _PFla,\n    0, () => PlatformFilter$\n];\nvar PlatformFrameworks = [1, n0, _PFlat,\n    0, () => PlatformFramework$\n];\nvar PlatformProgrammingLanguages = [1, n0, _PPLl,\n    0, () => PlatformProgrammingLanguage$\n];\nvar PlatformSummaryList = [1, n0, _PSL,\n    0, () => PlatformSummary$\n];\nvar QueueList = [1, n0, _QL,\n    0, () => Queue$\n];\nvar SearchFilters = [1, n0, _SFe,\n    0, () => SearchFilter$\n];\nvar TagList = [1, n0, _TL,\n    0, () => Tag$\n];\nvar Tags = [1, n0, _T,\n    0, () => Tag$\n];\nvar TriggerList = [1, n0, _TLr,\n    0, () => Trigger$\n];\nvar ValidationMessagesList = [1, n0, _VML,\n    0, () => ValidationMessage$\n];\nvar AbortEnvironmentUpdate$ = [9, n0, _AEU,\n    0, () => AbortEnvironmentUpdateMessage$, () => __Unit\n];\nvar ApplyEnvironmentManagedAction$ = [9, n0, _AEMA,\n    0, () => ApplyEnvironmentManagedActionRequest$, () => ApplyEnvironmentManagedActionResult$\n];\nvar AssociateEnvironmentOperationsRole$ = [9, n0, _AEOR,\n    0, () => AssociateEnvironmentOperationsRoleMessage$, () => __Unit\n];\nvar CheckDNSAvailability$ = [9, n0, _CDNSA,\n    0, () => CheckDNSAvailabilityMessage$, () => CheckDNSAvailabilityResultMessage$\n];\nvar ComposeEnvironments$ = [9, n0, _CE,\n    0, () => ComposeEnvironmentsMessage$, () => EnvironmentDescriptionsMessage$\n];\nvar CreateApplication$ = [9, n0, _CAr,\n    0, () => CreateApplicationMessage$, () => ApplicationDescriptionMessage$\n];\nvar CreateApplicationVersion$ = [9, n0, _CAV,\n    0, () => CreateApplicationVersionMessage$, () => ApplicationVersionDescriptionMessage$\n];\nvar CreateConfigurationTemplate$ = [9, n0, _CCT,\n    0, () => CreateConfigurationTemplateMessage$, () => ConfigurationSettingsDescription$\n];\nvar CreateEnvironment$ = [9, n0, _CEr,\n    0, () => CreateEnvironmentMessage$, () => EnvironmentDescription$\n];\nvar CreatePlatformVersion$ = [9, n0, _CPV,\n    0, () => CreatePlatformVersionRequest$, () => CreatePlatformVersionResult$\n];\nvar CreateStorageLocation$ = [9, n0, _CSL,\n    0, () => __Unit, () => CreateStorageLocationResultMessage$\n];\nvar DeleteApplication$ = [9, n0, _DA,\n    0, () => DeleteApplicationMessage$, () => __Unit\n];\nvar DeleteApplicationVersion$ = [9, n0, _DAV,\n    0, () => DeleteApplicationVersionMessage$, () => __Unit\n];\nvar DeleteConfigurationTemplate$ = [9, n0, _DCT,\n    0, () => DeleteConfigurationTemplateMessage$, () => __Unit\n];\nvar DeleteEnvironmentConfiguration$ = [9, n0, _DEC,\n    0, () => DeleteEnvironmentConfigurationMessage$, () => __Unit\n];\nvar DeletePlatformVersion$ = [9, n0, _DPV,\n    0, () => DeletePlatformVersionRequest$, () => DeletePlatformVersionResult$\n];\nvar DescribeAccountAttributes$ = [9, n0, _DAA,\n    0, () => __Unit, () => DescribeAccountAttributesResult$\n];\nvar DescribeApplications$ = [9, n0, _DAe,\n    0, () => DescribeApplicationsMessage$, () => ApplicationDescriptionsMessage$\n];\nvar DescribeApplicationVersions$ = [9, n0, _DAVe,\n    0, () => DescribeApplicationVersionsMessage$, () => ApplicationVersionDescriptionsMessage$\n];\nvar DescribeConfigurationOptions$ = [9, n0, _DCO,\n    0, () => DescribeConfigurationOptionsMessage$, () => ConfigurationOptionsDescription$\n];\nvar DescribeConfigurationSettings$ = [9, n0, _DCS,\n    0, () => DescribeConfigurationSettingsMessage$, () => ConfigurationSettingsDescriptions$\n];\nvar DescribeEnvironmentHealth$ = [9, n0, _DEH,\n    0, () => DescribeEnvironmentHealthRequest$, () => DescribeEnvironmentHealthResult$\n];\nvar DescribeEnvironmentManagedActionHistory$ = [9, n0, _DEMAH,\n    0, () => DescribeEnvironmentManagedActionHistoryRequest$, () => DescribeEnvironmentManagedActionHistoryResult$\n];\nvar DescribeEnvironmentManagedActions$ = [9, n0, _DEMA,\n    0, () => DescribeEnvironmentManagedActionsRequest$, () => DescribeEnvironmentManagedActionsResult$\n];\nvar DescribeEnvironmentResources$ = [9, n0, _DER,\n    0, () => DescribeEnvironmentResourcesMessage$, () => EnvironmentResourceDescriptionsMessage$\n];\nvar DescribeEnvironments$ = [9, n0, _DE,\n    0, () => DescribeEnvironmentsMessage$, () => EnvironmentDescriptionsMessage$\n];\nvar DescribeEvents$ = [9, n0, _DEe,\n    0, () => DescribeEventsMessage$, () => EventDescriptionsMessage$\n];\nvar DescribeInstancesHealth$ = [9, n0, _DIH,\n    0, () => DescribeInstancesHealthRequest$, () => DescribeInstancesHealthResult$\n];\nvar DescribePlatformVersion$ = [9, n0, _DPVe,\n    0, () => DescribePlatformVersionRequest$, () => DescribePlatformVersionResult$\n];\nvar DisassociateEnvironmentOperationsRole$ = [9, n0, _DEOR,\n    0, () => DisassociateEnvironmentOperationsRoleMessage$, () => __Unit\n];\nvar ListAvailableSolutionStacks$ = [9, n0, _LASS,\n    0, () => __Unit, () => ListAvailableSolutionStacksResultMessage$\n];\nvar ListPlatformBranches$ = [9, n0, _LPB,\n    0, () => ListPlatformBranchesRequest$, () => ListPlatformBranchesResult$\n];\nvar ListPlatformVersions$ = [9, n0, _LPV,\n    0, () => ListPlatformVersionsRequest$, () => ListPlatformVersionsResult$\n];\nvar ListTagsForResource$ = [9, n0, _LTFR,\n    0, () => ListTagsForResourceMessage$, () => ResourceTagsDescriptionMessage$\n];\nvar RebuildEnvironment$ = [9, n0, _RE,\n    0, () => RebuildEnvironmentMessage$, () => __Unit\n];\nvar RequestEnvironmentInfo$ = [9, n0, _REI,\n    0, () => RequestEnvironmentInfoMessage$, () => __Unit\n];\nvar RestartAppServer$ = [9, n0, _RAS,\n    0, () => RestartAppServerMessage$, () => __Unit\n];\nvar RetrieveEnvironmentInfo$ = [9, n0, _REIe,\n    0, () => RetrieveEnvironmentInfoMessage$, () => RetrieveEnvironmentInfoResultMessage$\n];\nvar SwapEnvironmentCNAMEs$ = [9, n0, _SECNAME,\n    0, () => SwapEnvironmentCNAMEsMessage$, () => __Unit\n];\nvar TerminateEnvironment$ = [9, n0, _TE,\n    0, () => TerminateEnvironmentMessage$, () => EnvironmentDescription$\n];\nvar UpdateApplication$ = [9, n0, _UA,\n    0, () => UpdateApplicationMessage$, () => ApplicationDescriptionMessage$\n];\nvar UpdateApplicationResourceLifecycle$ = [9, n0, _UARL,\n    0, () => UpdateApplicationResourceLifecycleMessage$, () => ApplicationResourceLifecycleDescriptionMessage$\n];\nvar UpdateApplicationVersion$ = [9, n0, _UAV,\n    0, () => UpdateApplicationVersionMessage$, () => ApplicationVersionDescriptionMessage$\n];\nvar UpdateConfigurationTemplate$ = [9, n0, _UCT,\n    0, () => UpdateConfigurationTemplateMessage$, () => ConfigurationSettingsDescription$\n];\nvar UpdateEnvironment$ = [9, n0, _UE,\n    0, () => UpdateEnvironmentMessage$, () => EnvironmentDescription$\n];\nvar UpdateTagsForResource$ = [9, n0, _UTFR,\n    0, () => UpdateTagsForResourceMessage$, () => __Unit\n];\nvar ValidateConfigurationSettings$ = [9, n0, _VCS,\n    0, () => ValidateConfigurationSettingsMessage$, () => ConfigurationSettingsValidationMessages$\n];\n\nclass AbortEnvironmentUpdateCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"AbortEnvironmentUpdate\", {})\n    .n(\"ElasticBeanstalkClient\", \"AbortEnvironmentUpdateCommand\")\n    .sc(AbortEnvironmentUpdate$)\n    .build() {\n}\n\nclass ApplyEnvironmentManagedActionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"ApplyEnvironmentManagedAction\", {})\n    .n(\"ElasticBeanstalkClient\", \"ApplyEnvironmentManagedActionCommand\")\n    .sc(ApplyEnvironmentManagedAction$)\n    .build() {\n}\n\nclass AssociateEnvironmentOperationsRoleCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"AssociateEnvironmentOperationsRole\", {})\n    .n(\"ElasticBeanstalkClient\", \"AssociateEnvironmentOperationsRoleCommand\")\n    .sc(AssociateEnvironmentOperationsRole$)\n    .build() {\n}\n\nclass CheckDNSAvailabilityCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"CheckDNSAvailability\", {})\n    .n(\"ElasticBeanstalkClient\", \"CheckDNSAvailabilityCommand\")\n    .sc(CheckDNSAvailability$)\n    .build() {\n}\n\nclass ComposeEnvironmentsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"ComposeEnvironments\", {})\n    .n(\"ElasticBeanstalkClient\", \"ComposeEnvironmentsCommand\")\n    .sc(ComposeEnvironments$)\n    .build() {\n}\n\nclass CreateApplicationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"CreateApplication\", {})\n    .n(\"ElasticBeanstalkClient\", \"CreateApplicationCommand\")\n    .sc(CreateApplication$)\n    .build() {\n}\n\nclass CreateApplicationVersionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"CreateApplicationVersion\", {})\n    .n(\"ElasticBeanstalkClient\", \"CreateApplicationVersionCommand\")\n    .sc(CreateApplicationVersion$)\n    .build() {\n}\n\nclass CreateConfigurationTemplateCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"CreateConfigurationTemplate\", {})\n    .n(\"ElasticBeanstalkClient\", \"CreateConfigurationTemplateCommand\")\n    .sc(CreateConfigurationTemplate$)\n    .build() {\n}\n\nclass CreateEnvironmentCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"CreateEnvironment\", {})\n    .n(\"ElasticBeanstalkClient\", \"CreateEnvironmentCommand\")\n    .sc(CreateEnvironment$)\n    .build() {\n}\n\nclass CreatePlatformVersionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"CreatePlatformVersion\", {})\n    .n(\"ElasticBeanstalkClient\", \"CreatePlatformVersionCommand\")\n    .sc(CreatePlatformVersion$)\n    .build() {\n}\n\nclass CreateStorageLocationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"CreateStorageLocation\", {})\n    .n(\"ElasticBeanstalkClient\", \"CreateStorageLocationCommand\")\n    .sc(CreateStorageLocation$)\n    .build() {\n}\n\nclass DeleteApplicationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DeleteApplication\", {})\n    .n(\"ElasticBeanstalkClient\", \"DeleteApplicationCommand\")\n    .sc(DeleteApplication$)\n    .build() {\n}\n\nclass DeleteApplicationVersionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DeleteApplicationVersion\", {})\n    .n(\"ElasticBeanstalkClient\", \"DeleteApplicationVersionCommand\")\n    .sc(DeleteApplicationVersion$)\n    .build() {\n}\n\nclass DeleteConfigurationTemplateCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DeleteConfigurationTemplate\", {})\n    .n(\"ElasticBeanstalkClient\", \"DeleteConfigurationTemplateCommand\")\n    .sc(DeleteConfigurationTemplate$)\n    .build() {\n}\n\nclass DeleteEnvironmentConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DeleteEnvironmentConfiguration\", {})\n    .n(\"ElasticBeanstalkClient\", \"DeleteEnvironmentConfigurationCommand\")\n    .sc(DeleteEnvironmentConfiguration$)\n    .build() {\n}\n\nclass DeletePlatformVersionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DeletePlatformVersion\", {})\n    .n(\"ElasticBeanstalkClient\", \"DeletePlatformVersionCommand\")\n    .sc(DeletePlatformVersion$)\n    .build() {\n}\n\nclass DescribeAccountAttributesCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeAccountAttributes\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeAccountAttributesCommand\")\n    .sc(DescribeAccountAttributes$)\n    .build() {\n}\n\nclass DescribeApplicationsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeApplications\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeApplicationsCommand\")\n    .sc(DescribeApplications$)\n    .build() {\n}\n\nclass DescribeApplicationVersionsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeApplicationVersions\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeApplicationVersionsCommand\")\n    .sc(DescribeApplicationVersions$)\n    .build() {\n}\n\nclass DescribeConfigurationOptionsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeConfigurationOptions\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeConfigurationOptionsCommand\")\n    .sc(DescribeConfigurationOptions$)\n    .build() {\n}\n\nclass DescribeConfigurationSettingsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeConfigurationSettings\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeConfigurationSettingsCommand\")\n    .sc(DescribeConfigurationSettings$)\n    .build() {\n}\n\nclass DescribeEnvironmentHealthCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeEnvironmentHealth\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeEnvironmentHealthCommand\")\n    .sc(DescribeEnvironmentHealth$)\n    .build() {\n}\n\nclass DescribeEnvironmentManagedActionHistoryCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeEnvironmentManagedActionHistory\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeEnvironmentManagedActionHistoryCommand\")\n    .sc(DescribeEnvironmentManagedActionHistory$)\n    .build() {\n}\n\nclass DescribeEnvironmentManagedActionsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeEnvironmentManagedActions\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeEnvironmentManagedActionsCommand\")\n    .sc(DescribeEnvironmentManagedActions$)\n    .build() {\n}\n\nclass DescribeEnvironmentResourcesCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeEnvironmentResources\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeEnvironmentResourcesCommand\")\n    .sc(DescribeEnvironmentResources$)\n    .build() {\n}\n\nclass DescribeEnvironmentsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeEnvironments\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeEnvironmentsCommand\")\n    .sc(DescribeEnvironments$)\n    .build() {\n}\n\nclass DescribeEventsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeEvents\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeEventsCommand\")\n    .sc(DescribeEvents$)\n    .build() {\n}\n\nclass DescribeInstancesHealthCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribeInstancesHealth\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribeInstancesHealthCommand\")\n    .sc(DescribeInstancesHealth$)\n    .build() {\n}\n\nclass DescribePlatformVersionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DescribePlatformVersion\", {})\n    .n(\"ElasticBeanstalkClient\", \"DescribePlatformVersionCommand\")\n    .sc(DescribePlatformVersion$)\n    .build() {\n}\n\nclass DisassociateEnvironmentOperationsRoleCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"DisassociateEnvironmentOperationsRole\", {})\n    .n(\"ElasticBeanstalkClient\", \"DisassociateEnvironmentOperationsRoleCommand\")\n    .sc(DisassociateEnvironmentOperationsRole$)\n    .build() {\n}\n\nclass ListAvailableSolutionStacksCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"ListAvailableSolutionStacks\", {})\n    .n(\"ElasticBeanstalkClient\", \"ListAvailableSolutionStacksCommand\")\n    .sc(ListAvailableSolutionStacks$)\n    .build() {\n}\n\nclass ListPlatformBranchesCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"ListPlatformBranches\", {})\n    .n(\"ElasticBeanstalkClient\", \"ListPlatformBranchesCommand\")\n    .sc(ListPlatformBranches$)\n    .build() {\n}\n\nclass ListPlatformVersionsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"ListPlatformVersions\", {})\n    .n(\"ElasticBeanstalkClient\", \"ListPlatformVersionsCommand\")\n    .sc(ListPlatformVersions$)\n    .build() {\n}\n\nclass ListTagsForResourceCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"ListTagsForResource\", {})\n    .n(\"ElasticBeanstalkClient\", \"ListTagsForResourceCommand\")\n    .sc(ListTagsForResource$)\n    .build() {\n}\n\nclass RebuildEnvironmentCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"RebuildEnvironment\", {})\n    .n(\"ElasticBeanstalkClient\", \"RebuildEnvironmentCommand\")\n    .sc(RebuildEnvironment$)\n    .build() {\n}\n\nclass RequestEnvironmentInfoCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"RequestEnvironmentInfo\", {})\n    .n(\"ElasticBeanstalkClient\", \"RequestEnvironmentInfoCommand\")\n    .sc(RequestEnvironmentInfo$)\n    .build() {\n}\n\nclass RestartAppServerCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"RestartAppServer\", {})\n    .n(\"ElasticBeanstalkClient\", \"RestartAppServerCommand\")\n    .sc(RestartAppServer$)\n    .build() {\n}\n\nclass RetrieveEnvironmentInfoCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"RetrieveEnvironmentInfo\", {})\n    .n(\"ElasticBeanstalkClient\", \"RetrieveEnvironmentInfoCommand\")\n    .sc(RetrieveEnvironmentInfo$)\n    .build() {\n}\n\nclass SwapEnvironmentCNAMEsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"SwapEnvironmentCNAMEs\", {})\n    .n(\"ElasticBeanstalkClient\", \"SwapEnvironmentCNAMEsCommand\")\n    .sc(SwapEnvironmentCNAMEs$)\n    .build() {\n}\n\nclass TerminateEnvironmentCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"TerminateEnvironment\", {})\n    .n(\"ElasticBeanstalkClient\", \"TerminateEnvironmentCommand\")\n    .sc(TerminateEnvironment$)\n    .build() {\n}\n\nclass UpdateApplicationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"UpdateApplication\", {})\n    .n(\"ElasticBeanstalkClient\", \"UpdateApplicationCommand\")\n    .sc(UpdateApplication$)\n    .build() {\n}\n\nclass UpdateApplicationResourceLifecycleCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"UpdateApplicationResourceLifecycle\", {})\n    .n(\"ElasticBeanstalkClient\", \"UpdateApplicationResourceLifecycleCommand\")\n    .sc(UpdateApplicationResourceLifecycle$)\n    .build() {\n}\n\nclass UpdateApplicationVersionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"UpdateApplicationVersion\", {})\n    .n(\"ElasticBeanstalkClient\", \"UpdateApplicationVersionCommand\")\n    .sc(UpdateApplicationVersion$)\n    .build() {\n}\n\nclass UpdateConfigurationTemplateCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"UpdateConfigurationTemplate\", {})\n    .n(\"ElasticBeanstalkClient\", \"UpdateConfigurationTemplateCommand\")\n    .sc(UpdateConfigurationTemplate$)\n    .build() {\n}\n\nclass UpdateEnvironmentCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"UpdateEnvironment\", {})\n    .n(\"ElasticBeanstalkClient\", \"UpdateEnvironmentCommand\")\n    .sc(UpdateEnvironment$)\n    .build() {\n}\n\nclass UpdateTagsForResourceCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"UpdateTagsForResource\", {})\n    .n(\"ElasticBeanstalkClient\", \"UpdateTagsForResourceCommand\")\n    .sc(UpdateTagsForResource$)\n    .build() {\n}\n\nclass ValidateConfigurationSettingsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSElasticBeanstalkService\", \"ValidateConfigurationSettings\", {})\n    .n(\"ElasticBeanstalkClient\", \"ValidateConfigurationSettingsCommand\")\n    .sc(ValidateConfigurationSettings$)\n    .build() {\n}\n\nconst paginateDescribeEnvironmentManagedActionHistory = core.createPaginator(ElasticBeanstalkClient, DescribeEnvironmentManagedActionHistoryCommand, \"NextToken\", \"NextToken\", \"MaxItems\");\n\nconst paginateDescribeEvents = core.createPaginator(ElasticBeanstalkClient, DescribeEventsCommand, \"NextToken\", \"NextToken\", \"MaxRecords\");\n\nconst paginateListPlatformBranches = core.createPaginator(ElasticBeanstalkClient, ListPlatformBranchesCommand, \"NextToken\", \"NextToken\", \"MaxRecords\");\n\nconst paginateListPlatformVersions = core.createPaginator(ElasticBeanstalkClient, ListPlatformVersionsCommand, \"NextToken\", \"NextToken\", \"MaxRecords\");\n\nconst checkState$2 = async (client, input) => {\n    let reason;\n    try {\n        let result = await client.send(new DescribeEnvironmentsCommand(input));\n        reason = result;\n        try {\n            const returnComparator = () => {\n                let flat_1 = [].concat(...result.Environments);\n                let projection_3 = flat_1.map((element_2) => {\n                    return element_2.Status;\n                });\n                return projection_3;\n            };\n            let allStringEq_5 = (returnComparator().length > 0);\n            for (let element_4 of returnComparator()) {\n                allStringEq_5 = allStringEq_5 && (element_4 == \"Ready\");\n            }\n            if (allStringEq_5) {\n                return { state: utilWaiter.WaiterState.SUCCESS, reason };\n            }\n        }\n        catch (e) { }\n        try {\n            const returnComparator = () => {\n                let flat_1 = [].concat(...result.Environments);\n                let projection_3 = flat_1.map((element_2) => {\n                    return element_2.Status;\n                });\n                return projection_3;\n            };\n            let allStringEq_5 = (returnComparator().length > 0);\n            for (let element_4 of returnComparator()) {\n                allStringEq_5 = allStringEq_5 && (element_4 == \"Launching\");\n            }\n            if (allStringEq_5) {\n                return { state: utilWaiter.WaiterState.RETRY, reason };\n            }\n        }\n        catch (e) { }\n    }\n    catch (exception) {\n        reason = exception;\n    }\n    return { state: utilWaiter.WaiterState.RETRY, reason };\n};\nconst waitForEnvironmentExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 20, maxDelay: 120 };\n    return utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$2);\n};\nconst waitUntilEnvironmentExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 20, maxDelay: 120 };\n    const result = await utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$2);\n    return utilWaiter.checkExceptions(result);\n};\n\nconst checkState$1 = async (client, input) => {\n    let reason;\n    try {\n        let result = await client.send(new DescribeEnvironmentsCommand(input));\n        reason = result;\n        try {\n            const returnComparator = () => {\n                let flat_1 = [].concat(...result.Environments);\n                let projection_3 = flat_1.map((element_2) => {\n                    return element_2.Status;\n                });\n                return projection_3;\n            };\n            let allStringEq_5 = (returnComparator().length > 0);\n            for (let element_4 of returnComparator()) {\n                allStringEq_5 = allStringEq_5 && (element_4 == \"Terminated\");\n            }\n            if (allStringEq_5) {\n                return { state: utilWaiter.WaiterState.SUCCESS, reason };\n            }\n        }\n        catch (e) { }\n        try {\n            const returnComparator = () => {\n                let flat_1 = [].concat(...result.Environments);\n                let projection_3 = flat_1.map((element_2) => {\n                    return element_2.Status;\n                });\n                return projection_3;\n            };\n            let allStringEq_5 = (returnComparator().length > 0);\n            for (let element_4 of returnComparator()) {\n                allStringEq_5 = allStringEq_5 && (element_4 == \"Terminating\");\n            }\n            if (allStringEq_5) {\n                return { state: utilWaiter.WaiterState.RETRY, reason };\n            }\n        }\n        catch (e) { }\n    }\n    catch (exception) {\n        reason = exception;\n    }\n    return { state: utilWaiter.WaiterState.RETRY, reason };\n};\nconst waitForEnvironmentTerminated = async (params, input) => {\n    const serviceDefaults = { minDelay: 20, maxDelay: 120 };\n    return utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$1);\n};\nconst waitUntilEnvironmentTerminated = async (params, input) => {\n    const serviceDefaults = { minDelay: 20, maxDelay: 120 };\n    const result = await utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$1);\n    return utilWaiter.checkExceptions(result);\n};\n\nconst checkState = async (client, input) => {\n    let reason;\n    try {\n        let result = await client.send(new DescribeEnvironmentsCommand(input));\n        reason = result;\n        try {\n            const returnComparator = () => {\n                let flat_1 = [].concat(...result.Environments);\n                let projection_3 = flat_1.map((element_2) => {\n                    return element_2.Status;\n                });\n                return projection_3;\n            };\n            let allStringEq_5 = (returnComparator().length > 0);\n            for (let element_4 of returnComparator()) {\n                allStringEq_5 = allStringEq_5 && (element_4 == \"Ready\");\n            }\n            if (allStringEq_5) {\n                return { state: utilWaiter.WaiterState.SUCCESS, reason };\n            }\n        }\n        catch (e) { }\n        try {\n            const returnComparator = () => {\n                let flat_1 = [].concat(...result.Environments);\n                let projection_3 = flat_1.map((element_2) => {\n                    return element_2.Status;\n                });\n                return projection_3;\n            };\n            let allStringEq_5 = (returnComparator().length > 0);\n            for (let element_4 of returnComparator()) {\n                allStringEq_5 = allStringEq_5 && (element_4 == \"Updating\");\n            }\n            if (allStringEq_5) {\n                return { state: utilWaiter.WaiterState.RETRY, reason };\n            }\n        }\n        catch (e) { }\n    }\n    catch (exception) {\n        reason = exception;\n    }\n    return { state: utilWaiter.WaiterState.RETRY, reason };\n};\nconst waitForEnvironmentUpdated = async (params, input) => {\n    const serviceDefaults = { minDelay: 20, maxDelay: 120 };\n    return utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState);\n};\nconst waitUntilEnvironmentUpdated = async (params, input) => {\n    const serviceDefaults = { minDelay: 20, maxDelay: 120 };\n    const result = await utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState);\n    return utilWaiter.checkExceptions(result);\n};\n\nconst commands = {\n    AbortEnvironmentUpdateCommand,\n    ApplyEnvironmentManagedActionCommand,\n    AssociateEnvironmentOperationsRoleCommand,\n    CheckDNSAvailabilityCommand,\n    ComposeEnvironmentsCommand,\n    CreateApplicationCommand,\n    CreateApplicationVersionCommand,\n    CreateConfigurationTemplateCommand,\n    CreateEnvironmentCommand,\n    CreatePlatformVersionCommand,\n    CreateStorageLocationCommand,\n    DeleteApplicationCommand,\n    DeleteApplicationVersionCommand,\n    DeleteConfigurationTemplateCommand,\n    DeleteEnvironmentConfigurationCommand,\n    DeletePlatformVersionCommand,\n    DescribeAccountAttributesCommand,\n    DescribeApplicationsCommand,\n    DescribeApplicationVersionsCommand,\n    DescribeConfigurationOptionsCommand,\n    DescribeConfigurationSettingsCommand,\n    DescribeEnvironmentHealthCommand,\n    DescribeEnvironmentManagedActionHistoryCommand,\n    DescribeEnvironmentManagedActionsCommand,\n    DescribeEnvironmentResourcesCommand,\n    DescribeEnvironmentsCommand,\n    DescribeEventsCommand,\n    DescribeInstancesHealthCommand,\n    DescribePlatformVersionCommand,\n    DisassociateEnvironmentOperationsRoleCommand,\n    ListAvailableSolutionStacksCommand,\n    ListPlatformBranchesCommand,\n    ListPlatformVersionsCommand,\n    ListTagsForResourceCommand,\n    RebuildEnvironmentCommand,\n    RequestEnvironmentInfoCommand,\n    RestartAppServerCommand,\n    RetrieveEnvironmentInfoCommand,\n    SwapEnvironmentCNAMEsCommand,\n    TerminateEnvironmentCommand,\n    UpdateApplicationCommand,\n    UpdateApplicationResourceLifecycleCommand,\n    UpdateApplicationVersionCommand,\n    UpdateConfigurationTemplateCommand,\n    UpdateEnvironmentCommand,\n    UpdateTagsForResourceCommand,\n    ValidateConfigurationSettingsCommand,\n};\nconst paginators = {\n    paginateDescribeEnvironmentManagedActionHistory,\n    paginateDescribeEvents,\n    paginateListPlatformBranches,\n    paginateListPlatformVersions,\n};\nconst waiters = {\n    waitUntilEnvironmentExists,\n    waitUntilEnvironmentTerminated,\n    waitUntilEnvironmentUpdated,\n};\nclass ElasticBeanstalk extends ElasticBeanstalkClient {\n}\nsmithyClient.createAggregatedClient(commands, ElasticBeanstalk, { paginators, waiters });\n\nconst ActionHistoryStatus = {\n    Completed: \"Completed\",\n    Failed: \"Failed\",\n    Unknown: \"Unknown\",\n};\nconst ActionStatus = {\n    Pending: \"Pending\",\n    Running: \"Running\",\n    Scheduled: \"Scheduled\",\n    Unknown: \"Unknown\",\n};\nconst ActionType = {\n    InstanceRefresh: \"InstanceRefresh\",\n    PlatformUpdate: \"PlatformUpdate\",\n    Unknown: \"Unknown\",\n};\nconst SourceRepository = {\n    CodeCommit: \"CodeCommit\",\n    S3: \"S3\",\n};\nconst SourceType = {\n    Git: \"Git\",\n    Zip: \"Zip\",\n};\nconst ApplicationVersionStatus = {\n    Building: \"Building\",\n    Failed: \"Failed\",\n    Processed: \"Processed\",\n    Processing: \"Processing\",\n    Unprocessed: \"Unprocessed\",\n};\nconst EnvironmentHealth = {\n    Green: \"Green\",\n    Grey: \"Grey\",\n    Red: \"Red\",\n    Yellow: \"Yellow\",\n};\nconst EnvironmentHealthStatus = {\n    Degraded: \"Degraded\",\n    Info: \"Info\",\n    NoData: \"NoData\",\n    Ok: \"Ok\",\n    Pending: \"Pending\",\n    Severe: \"Severe\",\n    Suspended: \"Suspended\",\n    Unknown: \"Unknown\",\n    Warning: \"Warning\",\n};\nconst EnvironmentStatus = {\n    Aborting: \"Aborting\",\n    Launching: \"Launching\",\n    LinkingFrom: \"LinkingFrom\",\n    LinkingTo: \"LinkingTo\",\n    Ready: \"Ready\",\n    Terminated: \"Terminated\",\n    Terminating: \"Terminating\",\n    Updating: \"Updating\",\n};\nconst ComputeType = {\n    BUILD_GENERAL1_LARGE: \"BUILD_GENERAL1_LARGE\",\n    BUILD_GENERAL1_MEDIUM: \"BUILD_GENERAL1_MEDIUM\",\n    BUILD_GENERAL1_SMALL: \"BUILD_GENERAL1_SMALL\",\n};\nconst ConfigurationDeploymentStatus = {\n    deployed: \"deployed\",\n    failed: \"failed\",\n    pending: \"pending\",\n};\nconst PlatformStatus = {\n    Creating: \"Creating\",\n    Deleted: \"Deleted\",\n    Deleting: \"Deleting\",\n    Failed: \"Failed\",\n    Ready: \"Ready\",\n};\nconst ConfigurationOptionValueType = {\n    List: \"List\",\n    Scalar: \"Scalar\",\n};\nconst EnvironmentHealthAttribute = {\n    All: \"All\",\n    ApplicationMetrics: \"ApplicationMetrics\",\n    Causes: \"Causes\",\n    Color: \"Color\",\n    HealthStatus: \"HealthStatus\",\n    InstancesHealth: \"InstancesHealth\",\n    RefreshedAt: \"RefreshedAt\",\n    Status: \"Status\",\n};\nconst FailureType = {\n    CancellationFailed: \"CancellationFailed\",\n    InternalFailure: \"InternalFailure\",\n    InvalidEnvironmentState: \"InvalidEnvironmentState\",\n    PermissionsError: \"PermissionsError\",\n    RollbackFailed: \"RollbackFailed\",\n    RollbackSuccessful: \"RollbackSuccessful\",\n    UpdateCancelled: \"UpdateCancelled\",\n};\nconst EventSeverity = {\n    DEBUG: \"DEBUG\",\n    ERROR: \"ERROR\",\n    FATAL: \"FATAL\",\n    INFO: \"INFO\",\n    TRACE: \"TRACE\",\n    WARN: \"WARN\",\n};\nconst InstancesHealthAttribute = {\n    All: \"All\",\n    ApplicationMetrics: \"ApplicationMetrics\",\n    AvailabilityZone: \"AvailabilityZone\",\n    Causes: \"Causes\",\n    Color: \"Color\",\n    Deployment: \"Deployment\",\n    HealthStatus: \"HealthStatus\",\n    InstanceType: \"InstanceType\",\n    LaunchedAt: \"LaunchedAt\",\n    RefreshedAt: \"RefreshedAt\",\n    System: \"System\",\n};\nconst EnvironmentInfoType = {\n    bundle: \"bundle\",\n    tail: \"tail\",\n};\nconst ValidationSeverity = {\n    error: \"error\",\n    warning: \"warning\",\n};\n\nObject.defineProperty(exports, \"$Command\", {\n    enumerable: true,\n    get: function () { return smithyClient.Command; }\n});\nObject.defineProperty(exports, \"__Client\", {\n    enumerable: true,\n    get: function () { return smithyClient.Client; }\n});\nexports.AbortEnvironmentUpdate$ = AbortEnvironmentUpdate$;\nexports.AbortEnvironmentUpdateCommand = AbortEnvironmentUpdateCommand;\nexports.AbortEnvironmentUpdateMessage$ = AbortEnvironmentUpdateMessage$;\nexports.ActionHistoryStatus = ActionHistoryStatus;\nexports.ActionStatus = ActionStatus;\nexports.ActionType = ActionType;\nexports.ApplicationDescription$ = ApplicationDescription$;\nexports.ApplicationDescriptionMessage$ = ApplicationDescriptionMessage$;\nexports.ApplicationDescriptionsMessage$ = ApplicationDescriptionsMessage$;\nexports.ApplicationMetrics$ = ApplicationMetrics$;\nexports.ApplicationResourceLifecycleConfig$ = ApplicationResourceLifecycleConfig$;\nexports.ApplicationResourceLifecycleDescriptionMessage$ = ApplicationResourceLifecycleDescriptionMessage$;\nexports.ApplicationVersionDescription$ = ApplicationVersionDescription$;\nexports.ApplicationVersionDescriptionMessage$ = ApplicationVersionDescriptionMessage$;\nexports.ApplicationVersionDescriptionsMessage$ = ApplicationVersionDescriptionsMessage$;\nexports.ApplicationVersionLifecycleConfig$ = ApplicationVersionLifecycleConfig$;\nexports.ApplicationVersionStatus = ApplicationVersionStatus;\nexports.ApplyEnvironmentManagedAction$ = ApplyEnvironmentManagedAction$;\nexports.ApplyEnvironmentManagedActionCommand = ApplyEnvironmentManagedActionCommand;\nexports.ApplyEnvironmentManagedActionRequest$ = ApplyEnvironmentManagedActionRequest$;\nexports.ApplyEnvironmentManagedActionResult$ = ApplyEnvironmentManagedActionResult$;\nexports.AssociateEnvironmentOperationsRole$ = AssociateEnvironmentOperationsRole$;\nexports.AssociateEnvironmentOperationsRoleCommand = AssociateEnvironmentOperationsRoleCommand;\nexports.AssociateEnvironmentOperationsRoleMessage$ = AssociateEnvironmentOperationsRoleMessage$;\nexports.AutoScalingGroup$ = AutoScalingGroup$;\nexports.BuildConfiguration$ = BuildConfiguration$;\nexports.Builder$ = Builder$;\nexports.CPUUtilization$ = CPUUtilization$;\nexports.CheckDNSAvailability$ = CheckDNSAvailability$;\nexports.CheckDNSAvailabilityCommand = CheckDNSAvailabilityCommand;\nexports.CheckDNSAvailabilityMessage$ = CheckDNSAvailabilityMessage$;\nexports.CheckDNSAvailabilityResultMessage$ = CheckDNSAvailabilityResultMessage$;\nexports.CodeBuildNotInServiceRegionException = CodeBuildNotInServiceRegionException;\nexports.CodeBuildNotInServiceRegionException$ = CodeBuildNotInServiceRegionException$;\nexports.ComposeEnvironments$ = ComposeEnvironments$;\nexports.ComposeEnvironmentsCommand = ComposeEnvironmentsCommand;\nexports.ComposeEnvironmentsMessage$ = ComposeEnvironmentsMessage$;\nexports.ComputeType = ComputeType;\nexports.ConfigurationDeploymentStatus = ConfigurationDeploymentStatus;\nexports.ConfigurationOptionDescription$ = ConfigurationOptionDescription$;\nexports.ConfigurationOptionSetting$ = ConfigurationOptionSetting$;\nexports.ConfigurationOptionValueType = ConfigurationOptionValueType;\nexports.ConfigurationOptionsDescription$ = ConfigurationOptionsDescription$;\nexports.ConfigurationSettingsDescription$ = ConfigurationSettingsDescription$;\nexports.ConfigurationSettingsDescriptions$ = ConfigurationSettingsDescriptions$;\nexports.ConfigurationSettingsValidationMessages$ = ConfigurationSettingsValidationMessages$;\nexports.CreateApplication$ = CreateApplication$;\nexports.CreateApplicationCommand = CreateApplicationCommand;\nexports.CreateApplicationMessage$ = CreateApplicationMessage$;\nexports.CreateApplicationVersion$ = CreateApplicationVersion$;\nexports.CreateApplicationVersionCommand = CreateApplicationVersionCommand;\nexports.CreateApplicationVersionMessage$ = CreateApplicationVersionMessage$;\nexports.CreateConfigurationTemplate$ = CreateConfigurationTemplate$;\nexports.CreateConfigurationTemplateCommand = CreateConfigurationTemplateCommand;\nexports.CreateConfigurationTemplateMessage$ = CreateConfigurationTemplateMessage$;\nexports.CreateEnvironment$ = CreateEnvironment$;\nexports.CreateEnvironmentCommand = CreateEnvironmentCommand;\nexports.CreateEnvironmentMessage$ = CreateEnvironmentMessage$;\nexports.CreatePlatformVersion$ = CreatePlatformVersion$;\nexports.CreatePlatformVersionCommand = CreatePlatformVersionCommand;\nexports.CreatePlatformVersionRequest$ = CreatePlatformVersionRequest$;\nexports.CreatePlatformVersionResult$ = CreatePlatformVersionResult$;\nexports.CreateStorageLocation$ = CreateStorageLocation$;\nexports.CreateStorageLocationCommand = CreateStorageLocationCommand;\nexports.CreateStorageLocationResultMessage$ = CreateStorageLocationResultMessage$;\nexports.CustomAmi$ = CustomAmi$;\nexports.DeleteApplication$ = DeleteApplication$;\nexports.DeleteApplicationCommand = DeleteApplicationCommand;\nexports.DeleteApplicationMessage$ = DeleteApplicationMessage$;\nexports.DeleteApplicationVersion$ = DeleteApplicationVersion$;\nexports.DeleteApplicationVersionCommand = DeleteApplicationVersionCommand;\nexports.DeleteApplicationVersionMessage$ = DeleteApplicationVersionMessage$;\nexports.DeleteConfigurationTemplate$ = DeleteConfigurationTemplate$;\nexports.DeleteConfigurationTemplateCommand = DeleteConfigurationTemplateCommand;\nexports.DeleteConfigurationTemplateMessage$ = DeleteConfigurationTemplateMessage$;\nexports.DeleteEnvironmentConfiguration$ = DeleteEnvironmentConfiguration$;\nexports.DeleteEnvironmentConfigurationCommand = DeleteEnvironmentConfigurationCommand;\nexports.DeleteEnvironmentConfigurationMessage$ = DeleteEnvironmentConfigurationMessage$;\nexports.DeletePlatformVersion$ = DeletePlatformVersion$;\nexports.DeletePlatformVersionCommand = DeletePlatformVersionCommand;\nexports.DeletePlatformVersionRequest$ = DeletePlatformVersionRequest$;\nexports.DeletePlatformVersionResult$ = DeletePlatformVersionResult$;\nexports.Deployment$ = Deployment$;\nexports.DescribeAccountAttributes$ = DescribeAccountAttributes$;\nexports.DescribeAccountAttributesCommand = DescribeAccountAttributesCommand;\nexports.DescribeAccountAttributesResult$ = DescribeAccountAttributesResult$;\nexports.DescribeApplicationVersions$ = DescribeApplicationVersions$;\nexports.DescribeApplicationVersionsCommand = DescribeApplicationVersionsCommand;\nexports.DescribeApplicationVersionsMessage$ = DescribeApplicationVersionsMessage$;\nexports.DescribeApplications$ = DescribeApplications$;\nexports.DescribeApplicationsCommand = DescribeApplicationsCommand;\nexports.DescribeApplicationsMessage$ = DescribeApplicationsMessage$;\nexports.DescribeConfigurationOptions$ = DescribeConfigurationOptions$;\nexports.DescribeConfigurationOptionsCommand = DescribeConfigurationOptionsCommand;\nexports.DescribeConfigurationOptionsMessage$ = DescribeConfigurationOptionsMessage$;\nexports.DescribeConfigurationSettings$ = DescribeConfigurationSettings$;\nexports.DescribeConfigurationSettingsCommand = DescribeConfigurationSettingsCommand;\nexports.DescribeConfigurationSettingsMessage$ = DescribeConfigurationSettingsMessage$;\nexports.DescribeEnvironmentHealth$ = DescribeEnvironmentHealth$;\nexports.DescribeEnvironmentHealthCommand = DescribeEnvironmentHealthCommand;\nexports.DescribeEnvironmentHealthRequest$ = DescribeEnvironmentHealthRequest$;\nexports.DescribeEnvironmentHealthResult$ = DescribeEnvironmentHealthResult$;\nexports.DescribeEnvironmentManagedActionHistory$ = DescribeEnvironmentManagedActionHistory$;\nexports.DescribeEnvironmentManagedActionHistoryCommand = DescribeEnvironmentManagedActionHistoryCommand;\nexports.DescribeEnvironmentManagedActionHistoryRequest$ = DescribeEnvironmentManagedActionHistoryRequest$;\nexports.DescribeEnvironmentManagedActionHistoryResult$ = DescribeEnvironmentManagedActionHistoryResult$;\nexports.DescribeEnvironmentManagedActions$ = DescribeEnvironmentManagedActions$;\nexports.DescribeEnvironmentManagedActionsCommand = DescribeEnvironmentManagedActionsCommand;\nexports.DescribeEnvironmentManagedActionsRequest$ = DescribeEnvironmentManagedActionsRequest$;\nexports.DescribeEnvironmentManagedActionsResult$ = DescribeEnvironmentManagedActionsResult$;\nexports.DescribeEnvironmentResources$ = DescribeEnvironmentResources$;\nexports.DescribeEnvironmentResourcesCommand = DescribeEnvironmentResourcesCommand;\nexports.DescribeEnvironmentResourcesMessage$ = DescribeEnvironmentResourcesMessage$;\nexports.DescribeEnvironments$ = DescribeEnvironments$;\nexports.DescribeEnvironmentsCommand = DescribeEnvironmentsCommand;\nexports.DescribeEnvironmentsMessage$ = DescribeEnvironmentsMessage$;\nexports.DescribeEvents$ = DescribeEvents$;\nexports.DescribeEventsCommand = DescribeEventsCommand;\nexports.DescribeEventsMessage$ = DescribeEventsMessage$;\nexports.DescribeInstancesHealth$ = DescribeInstancesHealth$;\nexports.DescribeInstancesHealthCommand = DescribeInstancesHealthCommand;\nexports.DescribeInstancesHealthRequest$ = DescribeInstancesHealthRequest$;\nexports.DescribeInstancesHealthResult$ = DescribeInstancesHealthResult$;\nexports.DescribePlatformVersion$ = DescribePlatformVersion$;\nexports.DescribePlatformVersionCommand = DescribePlatformVersionCommand;\nexports.DescribePlatformVersionRequest$ = DescribePlatformVersionRequest$;\nexports.DescribePlatformVersionResult$ = DescribePlatformVersionResult$;\nexports.DisassociateEnvironmentOperationsRole$ = DisassociateEnvironmentOperationsRole$;\nexports.DisassociateEnvironmentOperationsRoleCommand = DisassociateEnvironmentOperationsRoleCommand;\nexports.DisassociateEnvironmentOperationsRoleMessage$ = DisassociateEnvironmentOperationsRoleMessage$;\nexports.ElasticBeanstalk = ElasticBeanstalk;\nexports.ElasticBeanstalkClient = ElasticBeanstalkClient;\nexports.ElasticBeanstalkServiceException = ElasticBeanstalkServiceException;\nexports.ElasticBeanstalkServiceException$ = ElasticBeanstalkServiceException$;\nexports.ElasticBeanstalkSyntheticServiceException = ElasticBeanstalkSyntheticServiceException;\nexports.ElasticBeanstalkSyntheticServiceException$ = ElasticBeanstalkSyntheticServiceException$;\nexports.EnvironmentDescription$ = EnvironmentDescription$;\nexports.EnvironmentDescriptionsMessage$ = EnvironmentDescriptionsMessage$;\nexports.EnvironmentHealth = EnvironmentHealth;\nexports.EnvironmentHealthAttribute = EnvironmentHealthAttribute;\nexports.EnvironmentHealthStatus = EnvironmentHealthStatus;\nexports.EnvironmentInfoDescription$ = EnvironmentInfoDescription$;\nexports.EnvironmentInfoType = EnvironmentInfoType;\nexports.EnvironmentLink$ = EnvironmentLink$;\nexports.EnvironmentResourceDescription$ = EnvironmentResourceDescription$;\nexports.EnvironmentResourceDescriptionsMessage$ = EnvironmentResourceDescriptionsMessage$;\nexports.EnvironmentResourcesDescription$ = EnvironmentResourcesDescription$;\nexports.EnvironmentStatus = EnvironmentStatus;\nexports.EnvironmentTier$ = EnvironmentTier$;\nexports.EventDescription$ = EventDescription$;\nexports.EventDescriptionsMessage$ = EventDescriptionsMessage$;\nexports.EventSeverity = EventSeverity;\nexports.FailureType = FailureType;\nexports.Instance$ = Instance$;\nexports.InstanceHealthSummary$ = InstanceHealthSummary$;\nexports.InstancesHealthAttribute = InstancesHealthAttribute;\nexports.InsufficientPrivilegesException = InsufficientPrivilegesException;\nexports.InsufficientPrivilegesException$ = InsufficientPrivilegesException$;\nexports.InvalidRequestException = InvalidRequestException;\nexports.InvalidRequestException$ = InvalidRequestException$;\nexports.Latency$ = Latency$;\nexports.LaunchConfiguration$ = LaunchConfiguration$;\nexports.LaunchTemplate$ = LaunchTemplate$;\nexports.ListAvailableSolutionStacks$ = ListAvailableSolutionStacks$;\nexports.ListAvailableSolutionStacksCommand = ListAvailableSolutionStacksCommand;\nexports.ListAvailableSolutionStacksResultMessage$ = ListAvailableSolutionStacksResultMessage$;\nexports.ListPlatformBranches$ = ListPlatformBranches$;\nexports.ListPlatformBranchesCommand = ListPlatformBranchesCommand;\nexports.ListPlatformBranchesRequest$ = ListPlatformBranchesRequest$;\nexports.ListPlatformBranchesResult$ = ListPlatformBranchesResult$;\nexports.ListPlatformVersions$ = ListPlatformVersions$;\nexports.ListPlatformVersionsCommand = ListPlatformVersionsCommand;\nexports.ListPlatformVersionsRequest$ = ListPlatformVersionsRequest$;\nexports.ListPlatformVersionsResult$ = ListPlatformVersionsResult$;\nexports.ListTagsForResource$ = ListTagsForResource$;\nexports.ListTagsForResourceCommand = ListTagsForResourceCommand;\nexports.ListTagsForResourceMessage$ = ListTagsForResourceMessage$;\nexports.Listener$ = Listener$;\nexports.LoadBalancer$ = LoadBalancer$;\nexports.LoadBalancerDescription$ = LoadBalancerDescription$;\nexports.ManagedAction$ = ManagedAction$;\nexports.ManagedActionHistoryItem$ = ManagedActionHistoryItem$;\nexports.ManagedActionInvalidStateException = ManagedActionInvalidStateException;\nexports.ManagedActionInvalidStateException$ = ManagedActionInvalidStateException$;\nexports.MaxAgeRule$ = MaxAgeRule$;\nexports.MaxCountRule$ = MaxCountRule$;\nexports.OperationInProgressException = OperationInProgressException;\nexports.OperationInProgressException$ = OperationInProgressException$;\nexports.OptionRestrictionRegex$ = OptionRestrictionRegex$;\nexports.OptionSpecification$ = OptionSpecification$;\nexports.PlatformBranchSummary$ = PlatformBranchSummary$;\nexports.PlatformDescription$ = PlatformDescription$;\nexports.PlatformFilter$ = PlatformFilter$;\nexports.PlatformFramework$ = PlatformFramework$;\nexports.PlatformProgrammingLanguage$ = PlatformProgrammingLanguage$;\nexports.PlatformStatus = PlatformStatus;\nexports.PlatformSummary$ = PlatformSummary$;\nexports.PlatformVersionStillReferencedException = PlatformVersionStillReferencedException;\nexports.PlatformVersionStillReferencedException$ = PlatformVersionStillReferencedException$;\nexports.Queue$ = Queue$;\nexports.RebuildEnvironment$ = RebuildEnvironment$;\nexports.RebuildEnvironmentCommand = RebuildEnvironmentCommand;\nexports.RebuildEnvironmentMessage$ = RebuildEnvironmentMessage$;\nexports.RequestEnvironmentInfo$ = RequestEnvironmentInfo$;\nexports.RequestEnvironmentInfoCommand = RequestEnvironmentInfoCommand;\nexports.RequestEnvironmentInfoMessage$ = RequestEnvironmentInfoMessage$;\nexports.ResourceNotFoundException = ResourceNotFoundException;\nexports.ResourceNotFoundException$ = ResourceNotFoundException$;\nexports.ResourceQuota$ = ResourceQuota$;\nexports.ResourceQuotas$ = ResourceQuotas$;\nexports.ResourceTagsDescriptionMessage$ = ResourceTagsDescriptionMessage$;\nexports.ResourceTypeNotSupportedException = ResourceTypeNotSupportedException;\nexports.ResourceTypeNotSupportedException$ = ResourceTypeNotSupportedException$;\nexports.RestartAppServer$ = RestartAppServer$;\nexports.RestartAppServerCommand = RestartAppServerCommand;\nexports.RestartAppServerMessage$ = RestartAppServerMessage$;\nexports.RetrieveEnvironmentInfo$ = RetrieveEnvironmentInfo$;\nexports.RetrieveEnvironmentInfoCommand = RetrieveEnvironmentInfoCommand;\nexports.RetrieveEnvironmentInfoMessage$ = RetrieveEnvironmentInfoMessage$;\nexports.RetrieveEnvironmentInfoResultMessage$ = RetrieveEnvironmentInfoResultMessage$;\nexports.S3Location$ = S3Location$;\nexports.S3LocationNotInServiceRegionException = S3LocationNotInServiceRegionException;\nexports.S3LocationNotInServiceRegionException$ = S3LocationNotInServiceRegionException$;\nexports.S3SubscriptionRequiredException = S3SubscriptionRequiredException;\nexports.S3SubscriptionRequiredException$ = S3SubscriptionRequiredException$;\nexports.SearchFilter$ = SearchFilter$;\nexports.SingleInstanceHealth$ = SingleInstanceHealth$;\nexports.SolutionStackDescription$ = SolutionStackDescription$;\nexports.SourceBuildInformation$ = SourceBuildInformation$;\nexports.SourceBundleDeletionException = SourceBundleDeletionException;\nexports.SourceBundleDeletionException$ = SourceBundleDeletionException$;\nexports.SourceConfiguration$ = SourceConfiguration$;\nexports.SourceRepository = SourceRepository;\nexports.SourceType = SourceType;\nexports.StatusCodes$ = StatusCodes$;\nexports.SwapEnvironmentCNAMEs$ = SwapEnvironmentCNAMEs$;\nexports.SwapEnvironmentCNAMEsCommand = SwapEnvironmentCNAMEsCommand;\nexports.SwapEnvironmentCNAMEsMessage$ = SwapEnvironmentCNAMEsMessage$;\nexports.SystemStatus$ = SystemStatus$;\nexports.Tag$ = Tag$;\nexports.TerminateEnvironment$ = TerminateEnvironment$;\nexports.TerminateEnvironmentCommand = TerminateEnvironmentCommand;\nexports.TerminateEnvironmentMessage$ = TerminateEnvironmentMessage$;\nexports.TooManyApplicationVersionsException = TooManyApplicationVersionsException;\nexports.TooManyApplicationVersionsException$ = TooManyApplicationVersionsException$;\nexports.TooManyApplicationsException = TooManyApplicationsException;\nexports.TooManyApplicationsException$ = TooManyApplicationsException$;\nexports.TooManyBucketsException = TooManyBucketsException;\nexports.TooManyBucketsException$ = TooManyBucketsException$;\nexports.TooManyConfigurationTemplatesException = TooManyConfigurationTemplatesException;\nexports.TooManyConfigurationTemplatesException$ = TooManyConfigurationTemplatesException$;\nexports.TooManyEnvironmentsException = TooManyEnvironmentsException;\nexports.TooManyEnvironmentsException$ = TooManyEnvironmentsException$;\nexports.TooManyPlatformsException = TooManyPlatformsException;\nexports.TooManyPlatformsException$ = TooManyPlatformsException$;\nexports.TooManyTagsException = TooManyTagsException;\nexports.TooManyTagsException$ = TooManyTagsException$;\nexports.Trigger$ = Trigger$;\nexports.UpdateApplication$ = UpdateApplication$;\nexports.UpdateApplicationCommand = UpdateApplicationCommand;\nexports.UpdateApplicationMessage$ = UpdateApplicationMessage$;\nexports.UpdateApplicationResourceLifecycle$ = UpdateApplicationResourceLifecycle$;\nexports.UpdateApplicationResourceLifecycleCommand = UpdateApplicationResourceLifecycleCommand;\nexports.UpdateApplicationResourceLifecycleMessage$ = UpdateApplicationResourceLifecycleMessage$;\nexports.UpdateApplicationVersion$ = UpdateApplicationVersion$;\nexports.UpdateApplicationVersionCommand = UpdateApplicationVersionCommand;\nexports.UpdateApplicationVersionMessage$ = UpdateApplicationVersionMessage$;\nexports.UpdateConfigurationTemplate$ = UpdateConfigurationTemplate$;\nexports.UpdateConfigurationTemplateCommand = UpdateConfigurationTemplateCommand;\nexports.UpdateConfigurationTemplateMessage$ = UpdateConfigurationTemplateMessage$;\nexports.UpdateEnvironment$ = UpdateEnvironment$;\nexports.UpdateEnvironmentCommand = UpdateEnvironmentCommand;\nexports.UpdateEnvironmentMessage$ = UpdateEnvironmentMessage$;\nexports.UpdateTagsForResource$ = UpdateTagsForResource$;\nexports.UpdateTagsForResourceCommand = UpdateTagsForResourceCommand;\nexports.UpdateTagsForResourceMessage$ = UpdateTagsForResourceMessage$;\nexports.ValidateConfigurationSettings$ = ValidateConfigurationSettings$;\nexports.ValidateConfigurationSettingsCommand = ValidateConfigurationSettingsCommand;\nexports.ValidateConfigurationSettingsMessage$ = ValidateConfigurationSettingsMessage$;\nexports.ValidationMessage$ = ValidationMessage$;\nexports.ValidationSeverity = ValidationSeverity;\nexports.paginateDescribeEnvironmentManagedActionHistory = paginateDescribeEnvironmentManagedActionHistory;\nexports.paginateDescribeEvents = paginateDescribeEvents;\nexports.paginateListPlatformBranches = paginateListPlatformBranches;\nexports.paginateListPlatformVersions = paginateListPlatformVersions;\nexports.waitForEnvironmentExists = waitForEnvironmentExists;\nexports.waitForEnvironmentTerminated = waitForEnvironmentTerminated;\nexports.waitForEnvironmentUpdated = waitForEnvironmentUpdated;\nexports.waitUntilEnvironmentExists = waitUntilEnvironmentExists;\nexports.waitUntilEnvironmentTerminated = waitUntilEnvironmentTerminated;\nexports.waitUntilEnvironmentUpdated = waitUntilEnvironmentUpdated;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getRuntimeConfig = void 0;\nconst tslib_1 = require(\"tslib\");\nconst package_json_1 = tslib_1.__importDefault(require(\"../package.json\"));\nconst core_1 = require(\"@aws-sdk/core\");\nconst credential_provider_node_1 = require(\"@aws-sdk/credential-provider-node\");\nconst util_user_agent_node_1 = require(\"@aws-sdk/util-user-agent-node\");\nconst config_resolver_1 = require(\"@smithy/config-resolver\");\nconst hash_node_1 = require(\"@smithy/hash-node\");\nconst middleware_retry_1 = require(\"@smithy/middleware-retry\");\nconst node_config_provider_1 = require(\"@smithy/node-config-provider\");\nconst node_http_handler_1 = require(\"@smithy/node-http-handler\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nconst util_body_length_node_1 = require(\"@smithy/util-body-length-node\");\nconst util_defaults_mode_node_1 = require(\"@smithy/util-defaults-mode-node\");\nconst util_retry_1 = require(\"@smithy/util-retry\");\nconst runtimeConfig_shared_1 = require(\"./runtimeConfig.shared\");\nconst getRuntimeConfig = (config) => {\n    (0, smithy_client_1.emitWarningIfUnsupportedVersion)(process.version);\n    const defaultsMode = (0, util_defaults_mode_node_1.resolveDefaultsModeConfig)(config);\n    const defaultConfigProvider = () => defaultsMode().then(smithy_client_1.loadConfigsForDefaultMode);\n    const clientSharedValues = (0, runtimeConfig_shared_1.getRuntimeConfig)(config);\n    (0, core_1.emitWarningIfUnsupportedVersion)(process.version);\n    const loaderConfig = {\n        profile: config?.profile,\n        logger: clientSharedValues.logger,\n    };\n    return {\n        ...clientSharedValues,\n        ...config,\n        runtime: \"node\",\n        defaultsMode,\n        authSchemePreference: config?.authSchemePreference ?? (0, node_config_provider_1.loadConfig)(core_1.NODE_AUTH_SCHEME_PREFERENCE_OPTIONS, loaderConfig),\n        bodyLengthChecker: config?.bodyLengthChecker ?? util_body_length_node_1.calculateBodyLength,\n        credentialDefaultProvider: config?.credentialDefaultProvider ?? credential_provider_node_1.defaultProvider,\n        defaultUserAgentProvider: config?.defaultUserAgentProvider ?? (0, util_user_agent_node_1.createDefaultUserAgentProvider)({ serviceId: clientSharedValues.serviceId, clientVersion: package_json_1.default.version }),\n        maxAttempts: config?.maxAttempts ?? (0, node_config_provider_1.loadConfig)(middleware_retry_1.NODE_MAX_ATTEMPT_CONFIG_OPTIONS, config),\n        region: config?.region ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_REGION_CONFIG_OPTIONS, { ...config_resolver_1.NODE_REGION_CONFIG_FILE_OPTIONS, ...loaderConfig }),\n        requestHandler: node_http_handler_1.NodeHttpHandler.create(config?.requestHandler ?? defaultConfigProvider),\n        retryMode: config?.retryMode ??\n            (0, node_config_provider_1.loadConfig)({\n                ...middleware_retry_1.NODE_RETRY_MODE_CONFIG_OPTIONS,\n                default: async () => (await defaultConfigProvider()).retryMode || util_retry_1.DEFAULT_RETRY_MODE,\n            }, config),\n        sha256: config?.sha256 ?? hash_node_1.Hash.bind(null, \"sha256\"),\n        streamCollector: config?.streamCollector ?? node_http_handler_1.streamCollector,\n        useDualstackEndpoint: config?.useDualstackEndpoint ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_USE_DUALSTACK_ENDPOINT_CONFIG_OPTIONS, loaderConfig),\n        useFipsEndpoint: config?.useFipsEndpoint ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_USE_FIPS_ENDPOINT_CONFIG_OPTIONS, loaderConfig),\n        userAgentAppId: config?.userAgentAppId ?? (0, node_config_provider_1.loadConfig)(util_user_agent_node_1.NODE_APP_ID_CONFIG_OPTIONS, loaderConfig),\n    };\n};\nexports.getRuntimeConfig = getRuntimeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getRuntimeConfig = void 0;\nconst core_1 = require(\"@aws-sdk/core\");\nconst protocols_1 = require(\"@aws-sdk/core/protocols\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nconst url_parser_1 = require(\"@smithy/url-parser\");\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst util_utf8_1 = require(\"@smithy/util-utf8\");\nconst httpAuthSchemeProvider_1 = require(\"./auth/httpAuthSchemeProvider\");\nconst endpointResolver_1 = require(\"./endpoint/endpointResolver\");\nconst getRuntimeConfig = (config) => {\n    return {\n        apiVersion: \"2010-12-01\",\n        base64Decoder: config?.base64Decoder ?? util_base64_1.fromBase64,\n        base64Encoder: config?.base64Encoder ?? util_base64_1.toBase64,\n        disableHostPrefix: config?.disableHostPrefix ?? false,\n        endpointProvider: config?.endpointProvider ?? endpointResolver_1.defaultEndpointResolver,\n        extensions: config?.extensions ?? [],\n        httpAuthSchemeProvider: config?.httpAuthSchemeProvider ?? httpAuthSchemeProvider_1.defaultElasticBeanstalkHttpAuthSchemeProvider,\n        httpAuthSchemes: config?.httpAuthSchemes ?? [\n            {\n                schemeId: \"aws.auth#sigv4\",\n                identityProvider: (ipc) => ipc.getIdentityProvider(\"aws.auth#sigv4\"),\n                signer: new core_1.AwsSdkSigV4Signer(),\n            },\n        ],\n        logger: config?.logger ?? new smithy_client_1.NoOpLogger(),\n        protocol: config?.protocol ?? protocols_1.AwsQueryProtocol,\n        protocolSettings: config?.protocolSettings ?? {\n            defaultNamespace: \"com.amazonaws.elasticbeanstalk\",\n            xmlNamespace: \"http://elasticbeanstalk.amazonaws.com/docs/2010-12-01/\",\n            version: \"2010-12-01\",\n            serviceTarget: \"AWSElasticBeanstalkService\",\n        },\n        serviceId: config?.serviceId ?? \"Elastic Beanstalk\",\n        urlParser: config?.urlParser ?? url_parser_1.parseUrl,\n        utf8Decoder: config?.utf8Decoder ?? util_utf8_1.fromUtf8,\n        utf8Encoder: config?.utf8Encoder ?? util_utf8_1.toUtf8,\n    };\n};\nexports.getRuntimeConfig = getRuntimeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.resolveHttpAuthSchemeConfig = exports.defaultS3HttpAuthSchemeProvider = exports.defaultS3HttpAuthSchemeParametersProvider = void 0;\nconst core_1 = require(\"@aws-sdk/core\");\nconst signature_v4_multi_region_1 = require(\"@aws-sdk/signature-v4-multi-region\");\nconst middleware_endpoint_1 = require(\"@smithy/middleware-endpoint\");\nconst util_middleware_1 = require(\"@smithy/util-middleware\");\nconst endpointResolver_1 = require(\"../endpoint/endpointResolver\");\nconst createEndpointRuleSetHttpAuthSchemeParametersProvider = (defaultHttpAuthSchemeParametersProvider) => async (config, context, input) => {\n    if (!input) {\n        throw new Error(\"Could not find `input` for `defaultEndpointRuleSetHttpAuthSchemeParametersProvider`\");\n    }\n    const defaultParameters = await defaultHttpAuthSchemeParametersProvider(config, context, input);\n    const instructionsFn = (0, util_middleware_1.getSmithyContext)(context)?.commandInstance?.constructor\n        ?.getEndpointParameterInstructions;\n    if (!instructionsFn) {\n        throw new Error(`getEndpointParameterInstructions() is not defined on '${context.commandName}'`);\n    }\n    const endpointParameters = await (0, middleware_endpoint_1.resolveParams)(input, { getEndpointParameterInstructions: instructionsFn }, config);\n    return Object.assign(defaultParameters, endpointParameters);\n};\nconst _defaultS3HttpAuthSchemeParametersProvider = async (config, context, input) => {\n    return {\n        operation: (0, util_middleware_1.getSmithyContext)(context).operation,\n        region: await (0, util_middleware_1.normalizeProvider)(config.region)() || (() => {\n            throw new Error(\"expected `region` to be configured for `aws.auth#sigv4`\");\n        })(),\n    };\n};\nexports.defaultS3HttpAuthSchemeParametersProvider = createEndpointRuleSetHttpAuthSchemeParametersProvider(_defaultS3HttpAuthSchemeParametersProvider);\nfunction createAwsAuthSigv4HttpAuthOption(authParameters) {\n    return {\n        schemeId: \"aws.auth#sigv4\",\n        signingProperties: {\n            name: \"s3\",\n            region: authParameters.region,\n        },\n        propertiesExtractor: (config, context) => ({\n            signingProperties: {\n                config,\n                context,\n            },\n        }),\n    };\n}\nfunction createAwsAuthSigv4aHttpAuthOption(authParameters) {\n    return {\n        schemeId: \"aws.auth#sigv4a\",\n        signingProperties: {\n            name: \"s3\",\n            region: authParameters.region,\n        },\n        propertiesExtractor: (config, context) => ({\n            signingProperties: {\n                config,\n                context,\n            },\n        }),\n    };\n}\nconst createEndpointRuleSetHttpAuthSchemeProvider = (defaultEndpointResolver, defaultHttpAuthSchemeResolver, createHttpAuthOptionFunctions) => {\n    const endpointRuleSetHttpAuthSchemeProvider = (authParameters) => {\n        const endpoint = defaultEndpointResolver(authParameters);\n        const authSchemes = endpoint.properties?.authSchemes;\n        if (!authSchemes) {\n            return defaultHttpAuthSchemeResolver(authParameters);\n        }\n        const options = [];\n        for (const scheme of authSchemes) {\n            const { name: resolvedName, properties = {}, ...rest } = scheme;\n            const name = resolvedName.toLowerCase();\n            if (resolvedName !== name) {\n                console.warn(`HttpAuthScheme has been normalized with lowercasing: '${resolvedName}' to '${name}'`);\n            }\n            let schemeId;\n            if (name === \"sigv4a\") {\n                schemeId = \"aws.auth#sigv4a\";\n                const sigv4Present = authSchemes.find((s) => {\n                    const name = s.name.toLowerCase();\n                    return name !== \"sigv4a\" && name.startsWith(\"sigv4\");\n                });\n                if (signature_v4_multi_region_1.SignatureV4MultiRegion.sigv4aDependency() === \"none\" && sigv4Present) {\n                    continue;\n                }\n            }\n            else if (name.startsWith(\"sigv4\")) {\n                schemeId = \"aws.auth#sigv4\";\n            }\n            else {\n                throw new Error(`Unknown HttpAuthScheme found in '@smithy.rules#endpointRuleSet': '${name}'`);\n            }\n            const createOption = createHttpAuthOptionFunctions[schemeId];\n            if (!createOption) {\n                throw new Error(`Could not find HttpAuthOption create function for '${schemeId}'`);\n            }\n            const option = createOption(authParameters);\n            option.schemeId = schemeId;\n            option.signingProperties = { ...(option.signingProperties || {}), ...rest, ...properties };\n            options.push(option);\n        }\n        return options;\n    };\n    return endpointRuleSetHttpAuthSchemeProvider;\n};\nconst _defaultS3HttpAuthSchemeProvider = (authParameters) => {\n    const options = [];\n    switch (authParameters.operation) {\n        default: {\n            options.push(createAwsAuthSigv4HttpAuthOption(authParameters));\n            options.push(createAwsAuthSigv4aHttpAuthOption(authParameters));\n        }\n    }\n    return options;\n};\nexports.defaultS3HttpAuthSchemeProvider = createEndpointRuleSetHttpAuthSchemeProvider(endpointResolver_1.defaultEndpointResolver, _defaultS3HttpAuthSchemeProvider, {\n    \"aws.auth#sigv4\": createAwsAuthSigv4HttpAuthOption,\n    \"aws.auth#sigv4a\": createAwsAuthSigv4aHttpAuthOption,\n});\nconst resolveHttpAuthSchemeConfig = (config) => {\n    const config_0 = (0, core_1.resolveAwsSdkSigV4Config)(config);\n    const config_1 = (0, core_1.resolveAwsSdkSigV4AConfig)(config_0);\n    return Object.assign(config_1, {\n        authSchemePreference: (0, util_middleware_1.normalizeProvider)(config.authSchemePreference ?? []),\n    });\n};\nexports.resolveHttpAuthSchemeConfig = resolveHttpAuthSchemeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.defaultEndpointResolver = void 0;\nconst util_endpoints_1 = require(\"@aws-sdk/util-endpoints\");\nconst util_endpoints_2 = require(\"@smithy/util-endpoints\");\nconst ruleset_1 = require(\"./ruleset\");\nconst cache = new util_endpoints_2.EndpointCache({\n    size: 50,\n    params: [\n        \"Accelerate\",\n        \"Bucket\",\n        \"DisableAccessPoints\",\n        \"DisableMultiRegionAccessPoints\",\n        \"DisableS3ExpressSessionAuth\",\n        \"Endpoint\",\n        \"ForcePathStyle\",\n        \"Region\",\n        \"UseArnRegion\",\n        \"UseDualStack\",\n        \"UseFIPS\",\n        \"UseGlobalEndpoint\",\n        \"UseObjectLambdaEndpoint\",\n        \"UseS3ExpressControlEndpoint\",\n    ],\n});\nconst defaultEndpointResolver = (endpointParams, context = {}) => {\n    return cache.get(endpointParams, () => (0, util_endpoints_2.resolveEndpoint)(ruleset_1.ruleSet, {\n        endpointParams: endpointParams,\n        logger: context.logger,\n    }));\n};\nexports.defaultEndpointResolver = defaultEndpointResolver;\nutil_endpoints_2.customEndpointFunctions.aws = util_endpoints_1.awsEndpointFunctions;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ruleSet = void 0;\nconst cs = \"required\", ct = \"type\", cu = \"rules\", cv = \"conditions\", cw = \"fn\", cx = \"argv\", cy = \"ref\", cz = \"assign\", cA = \"url\", cB = \"properties\", cC = \"backend\", cD = \"authSchemes\", cE = \"disableDoubleEncoding\", cF = \"signingName\", cG = \"signingRegion\", cH = \"headers\", cI = \"signingRegionSet\";\nconst a = 6, b = false, c = true, d = \"isSet\", e = \"booleanEquals\", f = \"error\", g = \"aws.partition\", h = \"stringEquals\", i = \"getAttr\", j = \"name\", k = \"substring\", l = \"bucketSuffix\", m = \"parseURL\", n = \"endpoint\", o = \"tree\", p = \"aws.isVirtualHostableS3Bucket\", q = \"{url#scheme}://{Bucket}.{url#authority}{url#path}\", r = \"not\", s = \"accessPointSuffix\", t = \"{url#scheme}://{url#authority}{url#path}\", u = \"hardwareType\", v = \"regionPrefix\", w = \"bucketAliasSuffix\", x = \"outpostId\", y = \"isValidHostLabel\", z = \"sigv4a\", A = \"s3-outposts\", B = \"s3\", C = \"{url#scheme}://{url#authority}{url#normalizedPath}{Bucket}\", D = \"https://{Bucket}.s3-accelerate.{partitionResult#dnsSuffix}\", E = \"https://{Bucket}.s3.{partitionResult#dnsSuffix}\", F = \"aws.parseArn\", G = \"bucketArn\", H = \"arnType\", I = \"\", J = \"s3-object-lambda\", K = \"accesspoint\", L = \"accessPointName\", M = \"{url#scheme}://{accessPointName}-{bucketArn#accountId}.{url#authority}{url#path}\", N = \"mrapPartition\", O = \"outpostType\", P = \"arnPrefix\", Q = \"{url#scheme}://{url#authority}{url#normalizedPath}{uri_encoded_bucket}\", R = \"https://s3.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", S = \"https://s3.{partitionResult#dnsSuffix}\", T = { [cs]: false, [ct]: \"string\" }, U = { [cs]: true, \"default\": false, [ct]: \"boolean\" }, V = { [cs]: false, [ct]: \"boolean\" }, W = { [cw]: e, [cx]: [{ [cy]: \"Accelerate\" }, true] }, X = { [cw]: e, [cx]: [{ [cy]: \"UseFIPS\" }, true] }, Y = { [cw]: e, [cx]: [{ [cy]: \"UseDualStack\" }, true] }, Z = { [cw]: d, [cx]: [{ [cy]: \"Endpoint\" }] }, aa = { [cw]: g, [cx]: [{ [cy]: \"Region\" }], [cz]: \"partitionResult\" }, ab = { [cw]: h, [cx]: [{ [cw]: i, [cx]: [{ [cy]: \"partitionResult\" }, j] }, \"aws-cn\"] }, ac = { [cw]: d, [cx]: [{ [cy]: \"Bucket\" }] }, ad = { [cy]: \"Bucket\" }, ae = { [cv]: [W], [f]: \"S3Express does not support S3 Accelerate.\", [ct]: f }, af = { [cv]: [Z, { [cw]: m, [cx]: [{ [cy]: \"Endpoint\" }], [cz]: \"url\" }], [cu]: [{ [cv]: [{ [cw]: d, [cx]: [{ [cy]: \"DisableS3ExpressSessionAuth\" }] }, { [cw]: e, [cx]: [{ [cy]: \"DisableS3ExpressSessionAuth\" }, true] }], [cu]: [{ [cv]: [{ [cw]: e, [cx]: [{ [cw]: i, [cx]: [{ [cy]: \"url\" }, \"isIp\"] }, true] }], [cu]: [{ [cv]: [{ [cw]: \"uriEncode\", [cx]: [ad], [cz]: \"uri_encoded_bucket\" }], [cu]: [{ [n]: { [cA]: \"{url#scheme}://{url#authority}/{uri_encoded_bucket}{url#path}\", [cB]: { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, [cH]: {} }, [ct]: n }], [ct]: o }], [ct]: o }, { [cv]: [{ [cw]: p, [cx]: [ad, false] }], [cu]: [{ [n]: { [cA]: q, [cB]: { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, [cH]: {} }, [ct]: n }], [ct]: o }, { [f]: \"S3Express bucket name is not a valid virtual hostable name.\", [ct]: f }], [ct]: o }, { [cv]: [{ [cw]: e, [cx]: [{ [cw]: i, [cx]: [{ [cy]: \"url\" }, \"isIp\"] }, true] }], [cu]: [{ [cv]: [{ [cw]: \"uriEncode\", [cx]: [ad], [cz]: \"uri_encoded_bucket\" }], [cu]: [{ [n]: { [cA]: \"{url#scheme}://{url#authority}/{uri_encoded_bucket}{url#path}\", [cB]: { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4-s3express\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, [cH]: {} }, [ct]: n }], [ct]: o }], [ct]: o }, { [cv]: [{ [cw]: p, [cx]: [ad, false] }], [cu]: [{ [n]: { [cA]: q, [cB]: { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4-s3express\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, [cH]: {} }, [ct]: n }], [ct]: o }, { [f]: \"S3Express bucket name is not a valid virtual hostable name.\", [ct]: f }], [ct]: o }, ag = { [cw]: m, [cx]: [{ [cy]: \"Endpoint\" }], [cz]: \"url\" }, ah = { [cw]: e, [cx]: [{ [cw]: i, [cx]: [{ [cy]: \"url\" }, \"isIp\"] }, true] }, ai = { [cy]: \"url\" }, aj = { [cw]: \"uriEncode\", [cx]: [ad], [cz]: \"uri_encoded_bucket\" }, ak = { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, al = {}, am = { [cw]: p, [cx]: [ad, false] }, an = { [f]: \"S3Express bucket name is not a valid virtual hostable name.\", [ct]: f }, ao = { [cw]: d, [cx]: [{ [cy]: \"UseS3ExpressControlEndpoint\" }] }, ap = { [cw]: e, [cx]: [{ [cy]: \"UseS3ExpressControlEndpoint\" }, true] }, aq = { [cw]: r, [cx]: [Z] }, ar = { [cw]: e, [cx]: [{ [cy]: \"UseDualStack\" }, false] }, as = { [cw]: e, [cx]: [{ [cy]: \"UseFIPS\" }, false] }, at = { [f]: \"Unrecognized S3Express bucket name format.\", [ct]: f }, au = { [cw]: r, [cx]: [ac] }, av = { [cy]: u }, aw = { [cv]: [aq], [f]: \"Expected a endpoint to be specified but no endpoint was found\", [ct]: f }, ax = { [cD]: [{ [cE]: true, [j]: z, [cF]: A, [cI]: [\"*\"] }, { [cE]: true, [j]: \"sigv4\", [cF]: A, [cG]: \"{Region}\" }] }, ay = { [cw]: e, [cx]: [{ [cy]: \"ForcePathStyle\" }, false] }, az = { [cy]: \"ForcePathStyle\" }, aA = { [cw]: e, [cx]: [{ [cy]: \"Accelerate\" }, false] }, aB = { [cw]: h, [cx]: [{ [cy]: \"Region\" }, \"aws-global\"] }, aC = { [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: B, [cG]: \"us-east-1\" }] }, aD = { [cw]: r, [cx]: [aB] }, aE = { [cw]: e, [cx]: [{ [cy]: \"UseGlobalEndpoint\" }, true] }, aF = { [cA]: \"https://{Bucket}.s3-fips.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: { [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: B, [cG]: \"{Region}\" }] }, [cH]: {} }, aG = { [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: B, [cG]: \"{Region}\" }] }, aH = { [cw]: e, [cx]: [{ [cy]: \"UseGlobalEndpoint\" }, false] }, aI = { [cA]: \"https://{Bucket}.s3-fips.{Region}.{partitionResult#dnsSuffix}\", [cB]: aG, [cH]: {} }, aJ = { [cA]: \"https://{Bucket}.s3-accelerate.dualstack.{partitionResult#dnsSuffix}\", [cB]: aG, [cH]: {} }, aK = { [cA]: \"https://{Bucket}.s3.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: aG, [cH]: {} }, aL = { [cw]: e, [cx]: [{ [cw]: i, [cx]: [ai, \"isIp\"] }, false] }, aM = { [cA]: C, [cB]: aG, [cH]: {} }, aN = { [cA]: q, [cB]: aG, [cH]: {} }, aO = { [n]: aN, [ct]: n }, aP = { [cA]: D, [cB]: aG, [cH]: {} }, aQ = { [cA]: \"https://{Bucket}.s3.{Region}.{partitionResult#dnsSuffix}\", [cB]: aG, [cH]: {} }, aR = { [f]: \"Invalid region: region was not a valid DNS name.\", [ct]: f }, aS = { [cy]: G }, aT = { [cy]: H }, aU = { [cw]: i, [cx]: [aS, \"service\"] }, aV = { [cy]: L }, aW = { [cv]: [Y], [f]: \"S3 Object Lambda does not support Dual-stack\", [ct]: f }, aX = { [cv]: [W], [f]: \"S3 Object Lambda does not support S3 Accelerate\", [ct]: f }, aY = { [cv]: [{ [cw]: d, [cx]: [{ [cy]: \"DisableAccessPoints\" }] }, { [cw]: e, [cx]: [{ [cy]: \"DisableAccessPoints\" }, true] }], [f]: \"Access points are not supported for this operation\", [ct]: f }, aZ = { [cv]: [{ [cw]: d, [cx]: [{ [cy]: \"UseArnRegion\" }] }, { [cw]: e, [cx]: [{ [cy]: \"UseArnRegion\" }, false] }, { [cw]: r, [cx]: [{ [cw]: h, [cx]: [{ [cw]: i, [cx]: [aS, \"region\"] }, \"{Region}\"] }] }], [f]: \"Invalid configuration: region from ARN `{bucketArn#region}` does not match client region `{Region}` and UseArnRegion is `false`\", [ct]: f }, ba = { [cw]: i, [cx]: [{ [cy]: \"bucketPartition\" }, j] }, bb = { [cw]: i, [cx]: [aS, \"accountId\"] }, bc = { [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: J, [cG]: \"{bucketArn#region}\" }] }, bd = { [f]: \"Invalid ARN: The access point name may only contain a-z, A-Z, 0-9 and `-`. Found: `{accessPointName}`\", [ct]: f }, be = { [f]: \"Invalid ARN: The account id may only contain a-z, A-Z, 0-9 and `-`. Found: `{bucketArn#accountId}`\", [ct]: f }, bf = { [f]: \"Invalid region in ARN: `{bucketArn#region}` (invalid DNS name)\", [ct]: f }, bg = { [f]: \"Client was configured for partition `{partitionResult#name}` but ARN (`{Bucket}`) has `{bucketPartition#name}`\", [ct]: f }, bh = { [f]: \"Invalid ARN: The ARN may only contain a single resource component after `accesspoint`.\", [ct]: f }, bi = { [f]: \"Invalid ARN: Expected a resource of the format `accesspoint:<accesspoint name>` but no name was provided\", [ct]: f }, bj = { [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: B, [cG]: \"{bucketArn#region}\" }] }, bk = { [cD]: [{ [cE]: true, [j]: z, [cF]: A, [cI]: [\"*\"] }, { [cE]: true, [j]: \"sigv4\", [cF]: A, [cG]: \"{bucketArn#region}\" }] }, bl = { [cw]: F, [cx]: [ad] }, bm = { [cA]: \"https://s3-fips.dualstack.{Region}.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: aG, [cH]: {} }, bn = { [cA]: \"https://s3-fips.{Region}.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: aG, [cH]: {} }, bo = { [cA]: \"https://s3.dualstack.{Region}.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: aG, [cH]: {} }, bp = { [cA]: Q, [cB]: aG, [cH]: {} }, bq = { [cA]: \"https://s3.{Region}.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: aG, [cH]: {} }, br = { [cy]: \"UseObjectLambdaEndpoint\" }, bs = { [cD]: [{ [cE]: true, [j]: \"sigv4\", [cF]: J, [cG]: \"{Region}\" }] }, bt = { [cA]: \"https://s3-fips.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: aG, [cH]: {} }, bu = { [cA]: \"https://s3-fips.{Region}.{partitionResult#dnsSuffix}\", [cB]: aG, [cH]: {} }, bv = { [cA]: \"https://s3.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: aG, [cH]: {} }, bw = { [cA]: t, [cB]: aG, [cH]: {} }, bx = { [cA]: \"https://s3.{Region}.{partitionResult#dnsSuffix}\", [cB]: aG, [cH]: {} }, by = [{ [cy]: \"Region\" }], bz = [{ [cy]: \"Endpoint\" }], bA = [ad], bB = [W], bC = [Z, ag], bD = [{ [cw]: d, [cx]: [{ [cy]: \"DisableS3ExpressSessionAuth\" }] }, { [cw]: e, [cx]: [{ [cy]: \"DisableS3ExpressSessionAuth\" }, true] }], bE = [aj], bF = [am], bG = [aa], bH = [X, Y], bI = [X, ar], bJ = [as, Y], bK = [as, ar], bL = [{ [cw]: k, [cx]: [ad, 6, 14, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 14, 16, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bM = [{ [cv]: [X, Y], [n]: { [cA]: \"https://{Bucket}.s3express-fips-{s3expressAvailabilityZoneId}.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: ak, [cH]: {} }, [ct]: n }, { [cv]: bI, [n]: { [cA]: \"https://{Bucket}.s3express-fips-{s3expressAvailabilityZoneId}.{Region}.{partitionResult#dnsSuffix}\", [cB]: ak, [cH]: {} }, [ct]: n }, { [cv]: bJ, [n]: { [cA]: \"https://{Bucket}.s3express-{s3expressAvailabilityZoneId}.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: ak, [cH]: {} }, [ct]: n }, { [cv]: bK, [n]: { [cA]: \"https://{Bucket}.s3express-{s3expressAvailabilityZoneId}.{Region}.{partitionResult#dnsSuffix}\", [cB]: ak, [cH]: {} }, [ct]: n }], bN = [{ [cw]: k, [cx]: [ad, 6, 15, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 15, 17, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bO = [{ [cw]: k, [cx]: [ad, 6, 19, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 19, 21, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bP = [{ [cw]: k, [cx]: [ad, 6, 20, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 20, 22, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bQ = [{ [cw]: k, [cx]: [ad, 6, 26, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 26, 28, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bR = [{ [cv]: [X, Y], [n]: { [cA]: \"https://{Bucket}.s3express-fips-{s3expressAvailabilityZoneId}.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4-s3express\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, [cH]: {} }, [ct]: n }, { [cv]: bI, [n]: { [cA]: \"https://{Bucket}.s3express-fips-{s3expressAvailabilityZoneId}.{Region}.{partitionResult#dnsSuffix}\", [cB]: { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4-s3express\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, [cH]: {} }, [ct]: n }, { [cv]: bJ, [n]: { [cA]: \"https://{Bucket}.s3express-{s3expressAvailabilityZoneId}.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4-s3express\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, [cH]: {} }, [ct]: n }, { [cv]: bK, [n]: { [cA]: \"https://{Bucket}.s3express-{s3expressAvailabilityZoneId}.{Region}.{partitionResult#dnsSuffix}\", [cB]: { [cC]: \"S3Express\", [cD]: [{ [cE]: true, [j]: \"sigv4-s3express\", [cF]: \"s3express\", [cG]: \"{Region}\" }] }, [cH]: {} }, [ct]: n }], bS = [ad, 0, 7, true], bT = [{ [cw]: k, [cx]: [ad, 7, 15, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 15, 17, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bU = [{ [cw]: k, [cx]: [ad, 7, 16, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 16, 18, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bV = [{ [cw]: k, [cx]: [ad, 7, 20, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 20, 22, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bW = [{ [cw]: k, [cx]: [ad, 7, 21, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 21, 23, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bX = [{ [cw]: k, [cx]: [ad, 7, 27, true], [cz]: \"s3expressAvailabilityZoneId\" }, { [cw]: k, [cx]: [ad, 27, 29, true], [cz]: \"s3expressAvailabilityZoneDelim\" }, { [cw]: h, [cx]: [{ [cy]: \"s3expressAvailabilityZoneDelim\" }, \"--\"] }], bY = [ac], bZ = [{ [cw]: y, [cx]: [{ [cy]: x }, false] }], ca = [{ [cw]: h, [cx]: [{ [cy]: v }, \"beta\"] }], cb = [\"*\"], cc = [{ [cw]: y, [cx]: [{ [cy]: \"Region\" }, false] }], cd = [{ [cw]: h, [cx]: [{ [cy]: \"Region\" }, \"us-east-1\"] }], ce = [{ [cw]: h, [cx]: [aT, K] }], cf = [{ [cw]: i, [cx]: [aS, \"resourceId[1]\"], [cz]: L }, { [cw]: r, [cx]: [{ [cw]: h, [cx]: [aV, I] }] }], cg = [aS, \"resourceId[1]\"], ch = [Y], ci = [{ [cw]: r, [cx]: [{ [cw]: h, [cx]: [{ [cw]: i, [cx]: [aS, \"region\"] }, I] }] }], cj = [{ [cw]: r, [cx]: [{ [cw]: d, [cx]: [{ [cw]: i, [cx]: [aS, \"resourceId[2]\"] }] }] }], ck = [aS, \"resourceId[2]\"], cl = [{ [cw]: g, [cx]: [{ [cw]: i, [cx]: [aS, \"region\"] }], [cz]: \"bucketPartition\" }], cm = [{ [cw]: h, [cx]: [ba, { [cw]: i, [cx]: [{ [cy]: \"partitionResult\" }, j] }] }], cn = [{ [cw]: y, [cx]: [{ [cw]: i, [cx]: [aS, \"region\"] }, true] }], co = [{ [cw]: y, [cx]: [bb, false] }], cp = [{ [cw]: y, [cx]: [aV, false] }], cq = [X], cr = [{ [cw]: y, [cx]: [{ [cy]: \"Region\" }, true] }];\nconst _data = { version: \"1.0\", parameters: { Bucket: T, Region: T, UseFIPS: U, UseDualStack: U, Endpoint: T, ForcePathStyle: U, Accelerate: U, UseGlobalEndpoint: U, UseObjectLambdaEndpoint: V, Key: T, Prefix: T, CopySource: T, DisableAccessPoints: V, DisableMultiRegionAccessPoints: U, UseArnRegion: V, UseS3ExpressControlEndpoint: V, DisableS3ExpressSessionAuth: V }, [cu]: [{ [cv]: [{ [cw]: d, [cx]: by }], [cu]: [{ [cv]: [W, X], error: \"Accelerate cannot be used with FIPS\", [ct]: f }, { [cv]: [Y, Z], error: \"Cannot set dual-stack in combination with a custom endpoint.\", [ct]: f }, { [cv]: [Z, X], error: \"A custom endpoint cannot be combined with FIPS\", [ct]: f }, { [cv]: [Z, W], error: \"A custom endpoint cannot be combined with S3 Accelerate\", [ct]: f }, { [cv]: [X, aa, ab], error: \"Partition does not support FIPS\", [ct]: f }, { [cv]: [ac, { [cw]: k, [cx]: [ad, 0, a, c], [cz]: l }, { [cw]: h, [cx]: [{ [cy]: l }, \"--x-s3\"] }], [cu]: [ae, af, { [cv]: [ao, ap], [cu]: [{ [cv]: bG, [cu]: [{ [cv]: [aj, aq], [cu]: [{ [cv]: bH, endpoint: { [cA]: \"https://s3express-control-fips.dualstack.{Region}.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: ak, [cH]: al }, [ct]: n }, { [cv]: bI, endpoint: { [cA]: \"https://s3express-control-fips.{Region}.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: ak, [cH]: al }, [ct]: n }, { [cv]: bJ, endpoint: { [cA]: \"https://s3express-control.dualstack.{Region}.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: ak, [cH]: al }, [ct]: n }, { [cv]: bK, endpoint: { [cA]: \"https://s3express-control.{Region}.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: ak, [cH]: al }, [ct]: n }], [ct]: o }], [ct]: o }], [ct]: o }, { [cv]: bF, [cu]: [{ [cv]: bG, [cu]: [{ [cv]: bD, [cu]: [{ [cv]: bL, [cu]: bM, [ct]: o }, { [cv]: bN, [cu]: bM, [ct]: o }, { [cv]: bO, [cu]: bM, [ct]: o }, { [cv]: bP, [cu]: bM, [ct]: o }, { [cv]: bQ, [cu]: bM, [ct]: o }, at], [ct]: o }, { [cv]: bL, [cu]: bR, [ct]: o }, { [cv]: bN, [cu]: bR, [ct]: o }, { [cv]: bO, [cu]: bR, [ct]: o }, { [cv]: bP, [cu]: bR, [ct]: o }, { [cv]: bQ, [cu]: bR, [ct]: o }, at], [ct]: o }], [ct]: o }, an], [ct]: o }, { [cv]: [ac, { [cw]: k, [cx]: bS, [cz]: s }, { [cw]: h, [cx]: [{ [cy]: s }, \"--xa-s3\"] }], [cu]: [ae, af, { [cv]: bF, [cu]: [{ [cv]: bG, [cu]: [{ [cv]: bD, [cu]: [{ [cv]: bT, [cu]: bM, [ct]: o }, { [cv]: bU, [cu]: bM, [ct]: o }, { [cv]: bV, [cu]: bM, [ct]: o }, { [cv]: bW, [cu]: bM, [ct]: o }, { [cv]: bX, [cu]: bM, [ct]: o }, at], [ct]: o }, { [cv]: bT, [cu]: bR, [ct]: o }, { [cv]: bU, [cu]: bR, [ct]: o }, { [cv]: bV, [cu]: bR, [ct]: o }, { [cv]: bW, [cu]: bR, [ct]: o }, { [cv]: bX, [cu]: bR, [ct]: o }, at], [ct]: o }], [ct]: o }, an], [ct]: o }, { [cv]: [au, ao, ap], [cu]: [{ [cv]: bG, [cu]: [{ [cv]: bC, endpoint: { [cA]: t, [cB]: ak, [cH]: al }, [ct]: n }, { [cv]: bH, endpoint: { [cA]: \"https://s3express-control-fips.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: ak, [cH]: al }, [ct]: n }, { [cv]: bI, endpoint: { [cA]: \"https://s3express-control-fips.{Region}.{partitionResult#dnsSuffix}\", [cB]: ak, [cH]: al }, [ct]: n }, { [cv]: bJ, endpoint: { [cA]: \"https://s3express-control.dualstack.{Region}.{partitionResult#dnsSuffix}\", [cB]: ak, [cH]: al }, [ct]: n }, { [cv]: bK, endpoint: { [cA]: \"https://s3express-control.{Region}.{partitionResult#dnsSuffix}\", [cB]: ak, [cH]: al }, [ct]: n }], [ct]: o }], [ct]: o }, { [cv]: [ac, { [cw]: k, [cx]: [ad, 49, 50, c], [cz]: u }, { [cw]: k, [cx]: [ad, 8, 12, c], [cz]: v }, { [cw]: k, [cx]: bS, [cz]: w }, { [cw]: k, [cx]: [ad, 32, 49, c], [cz]: x }, { [cw]: g, [cx]: by, [cz]: \"regionPartition\" }, { [cw]: h, [cx]: [{ [cy]: w }, \"--op-s3\"] }], [cu]: [{ [cv]: bZ, [cu]: [{ [cv]: bF, [cu]: [{ [cv]: [{ [cw]: h, [cx]: [av, \"e\"] }], [cu]: [{ [cv]: ca, [cu]: [aw, { [cv]: bC, endpoint: { [cA]: \"https://{Bucket}.ec2.{url#authority}\", [cB]: ax, [cH]: al }, [ct]: n }], [ct]: o }, { endpoint: { [cA]: \"https://{Bucket}.ec2.s3-outposts.{Region}.{regionPartition#dnsSuffix}\", [cB]: ax, [cH]: al }, [ct]: n }], [ct]: o }, { [cv]: [{ [cw]: h, [cx]: [av, \"o\"] }], [cu]: [{ [cv]: ca, [cu]: [aw, { [cv]: bC, endpoint: { [cA]: \"https://{Bucket}.op-{outpostId}.{url#authority}\", [cB]: ax, [cH]: al }, [ct]: n }], [ct]: o }, { endpoint: { [cA]: \"https://{Bucket}.op-{outpostId}.s3-outposts.{Region}.{regionPartition#dnsSuffix}\", [cB]: ax, [cH]: al }, [ct]: n }], [ct]: o }, { error: \"Unrecognized hardware type: \\\"Expected hardware type o or e but got {hardwareType}\\\"\", [ct]: f }], [ct]: o }, { error: \"Invalid Outposts Bucket alias - it must be a valid bucket name.\", [ct]: f }], [ct]: o }, { error: \"Invalid ARN: The outpost Id must only contain a-z, A-Z, 0-9 and `-`.\", [ct]: f }], [ct]: o }, { [cv]: bY, [cu]: [{ [cv]: [Z, { [cw]: r, [cx]: [{ [cw]: d, [cx]: [{ [cw]: m, [cx]: bz }] }] }], error: \"Custom endpoint `{Endpoint}` was not a valid URI\", [ct]: f }, { [cv]: [ay, am], [cu]: [{ [cv]: bG, [cu]: [{ [cv]: cc, [cu]: [{ [cv]: [W, ab], error: \"S3 Accelerate cannot be used in this region\", [ct]: f }, { [cv]: [Y, X, aA, aq, aB], endpoint: { [cA]: \"https://{Bucket}.s3-fips.dualstack.us-east-1.{partitionResult#dnsSuffix}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [Y, X, aA, aq, aD, aE], [cu]: [{ endpoint: aF, [ct]: n }], [ct]: o }, { [cv]: [Y, X, aA, aq, aD, aH], endpoint: aF, [ct]: n }, { [cv]: [ar, X, aA, aq, aB], endpoint: { [cA]: \"https://{Bucket}.s3-fips.us-east-1.{partitionResult#dnsSuffix}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [ar, X, aA, aq, aD, aE], [cu]: [{ endpoint: aI, [ct]: n }], [ct]: o }, { [cv]: [ar, X, aA, aq, aD, aH], endpoint: aI, [ct]: n }, { [cv]: [Y, as, W, aq, aB], endpoint: { [cA]: \"https://{Bucket}.s3-accelerate.dualstack.us-east-1.{partitionResult#dnsSuffix}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [Y, as, W, aq, aD, aE], [cu]: [{ endpoint: aJ, [ct]: n }], [ct]: o }, { [cv]: [Y, as, W, aq, aD, aH], endpoint: aJ, [ct]: n }, { [cv]: [Y, as, aA, aq, aB], endpoint: { [cA]: \"https://{Bucket}.s3.dualstack.us-east-1.{partitionResult#dnsSuffix}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [Y, as, aA, aq, aD, aE], [cu]: [{ endpoint: aK, [ct]: n }], [ct]: o }, { [cv]: [Y, as, aA, aq, aD, aH], endpoint: aK, [ct]: n }, { [cv]: [ar, as, aA, Z, ag, ah, aB], endpoint: { [cA]: C, [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [ar, as, aA, Z, ag, aL, aB], endpoint: { [cA]: q, [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [ar, as, aA, Z, ag, ah, aD, aE], [cu]: [{ [cv]: cd, endpoint: aM, [ct]: n }, { endpoint: aM, [ct]: n }], [ct]: o }, { [cv]: [ar, as, aA, Z, ag, aL, aD, aE], [cu]: [{ [cv]: cd, endpoint: aN, [ct]: n }, aO], [ct]: o }, { [cv]: [ar, as, aA, Z, ag, ah, aD, aH], endpoint: aM, [ct]: n }, { [cv]: [ar, as, aA, Z, ag, aL, aD, aH], endpoint: aN, [ct]: n }, { [cv]: [ar, as, W, aq, aB], endpoint: { [cA]: D, [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [ar, as, W, aq, aD, aE], [cu]: [{ [cv]: cd, endpoint: aP, [ct]: n }, { endpoint: aP, [ct]: n }], [ct]: o }, { [cv]: [ar, as, W, aq, aD, aH], endpoint: aP, [ct]: n }, { [cv]: [ar, as, aA, aq, aB], endpoint: { [cA]: E, [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [ar, as, aA, aq, aD, aE], [cu]: [{ [cv]: cd, endpoint: { [cA]: E, [cB]: aG, [cH]: al }, [ct]: n }, { endpoint: aQ, [ct]: n }], [ct]: o }, { [cv]: [ar, as, aA, aq, aD, aH], endpoint: aQ, [ct]: n }], [ct]: o }, aR], [ct]: o }], [ct]: o }, { [cv]: [Z, ag, { [cw]: h, [cx]: [{ [cw]: i, [cx]: [ai, \"scheme\"] }, \"http\"] }, { [cw]: p, [cx]: [ad, c] }, ay, as, ar, aA], [cu]: [{ [cv]: bG, [cu]: [{ [cv]: cc, [cu]: [aO], [ct]: o }, aR], [ct]: o }], [ct]: o }, { [cv]: [ay, { [cw]: F, [cx]: bA, [cz]: G }], [cu]: [{ [cv]: [{ [cw]: i, [cx]: [aS, \"resourceId[0]\"], [cz]: H }, { [cw]: r, [cx]: [{ [cw]: h, [cx]: [aT, I] }] }], [cu]: [{ [cv]: [{ [cw]: h, [cx]: [aU, J] }], [cu]: [{ [cv]: ce, [cu]: [{ [cv]: cf, [cu]: [aW, aX, { [cv]: ci, [cu]: [aY, { [cv]: cj, [cu]: [aZ, { [cv]: cl, [cu]: [{ [cv]: bG, [cu]: [{ [cv]: cm, [cu]: [{ [cv]: cn, [cu]: [{ [cv]: [{ [cw]: h, [cx]: [bb, I] }], error: \"Invalid ARN: Missing account id\", [ct]: f }, { [cv]: co, [cu]: [{ [cv]: cp, [cu]: [{ [cv]: bC, endpoint: { [cA]: M, [cB]: bc, [cH]: al }, [ct]: n }, { [cv]: cq, endpoint: { [cA]: \"https://{accessPointName}-{bucketArn#accountId}.s3-object-lambda-fips.{bucketArn#region}.{bucketPartition#dnsSuffix}\", [cB]: bc, [cH]: al }, [ct]: n }, { endpoint: { [cA]: \"https://{accessPointName}-{bucketArn#accountId}.s3-object-lambda.{bucketArn#region}.{bucketPartition#dnsSuffix}\", [cB]: bc, [cH]: al }, [ct]: n }], [ct]: o }, bd], [ct]: o }, be], [ct]: o }, bf], [ct]: o }, bg], [ct]: o }], [ct]: o }], [ct]: o }, bh], [ct]: o }, { error: \"Invalid ARN: bucket ARN is missing a region\", [ct]: f }], [ct]: o }, bi], [ct]: o }, { error: \"Invalid ARN: Object Lambda ARNs only support `accesspoint` arn types, but found: `{arnType}`\", [ct]: f }], [ct]: o }, { [cv]: ce, [cu]: [{ [cv]: cf, [cu]: [{ [cv]: ci, [cu]: [{ [cv]: ce, [cu]: [{ [cv]: ci, [cu]: [aY, { [cv]: cj, [cu]: [aZ, { [cv]: cl, [cu]: [{ [cv]: bG, [cu]: [{ [cv]: [{ [cw]: h, [cx]: [ba, \"{partitionResult#name}\"] }], [cu]: [{ [cv]: cn, [cu]: [{ [cv]: [{ [cw]: h, [cx]: [aU, B] }], [cu]: [{ [cv]: co, [cu]: [{ [cv]: cp, [cu]: [{ [cv]: bB, error: \"Access Points do not support S3 Accelerate\", [ct]: f }, { [cv]: bH, endpoint: { [cA]: \"https://{accessPointName}-{bucketArn#accountId}.s3-accesspoint-fips.dualstack.{bucketArn#region}.{bucketPartition#dnsSuffix}\", [cB]: bj, [cH]: al }, [ct]: n }, { [cv]: bI, endpoint: { [cA]: \"https://{accessPointName}-{bucketArn#accountId}.s3-accesspoint-fips.{bucketArn#region}.{bucketPartition#dnsSuffix}\", [cB]: bj, [cH]: al }, [ct]: n }, { [cv]: bJ, endpoint: { [cA]: \"https://{accessPointName}-{bucketArn#accountId}.s3-accesspoint.dualstack.{bucketArn#region}.{bucketPartition#dnsSuffix}\", [cB]: bj, [cH]: al }, [ct]: n }, { [cv]: [as, ar, Z, ag], endpoint: { [cA]: M, [cB]: bj, [cH]: al }, [ct]: n }, { [cv]: bK, endpoint: { [cA]: \"https://{accessPointName}-{bucketArn#accountId}.s3-accesspoint.{bucketArn#region}.{bucketPartition#dnsSuffix}\", [cB]: bj, [cH]: al }, [ct]: n }], [ct]: o }, bd], [ct]: o }, be], [ct]: o }, { error: \"Invalid ARN: The ARN was not for the S3 service, found: {bucketArn#service}\", [ct]: f }], [ct]: o }, bf], [ct]: o }, bg], [ct]: o }], [ct]: o }], [ct]: o }, bh], [ct]: o }], [ct]: o }], [ct]: o }, { [cv]: [{ [cw]: y, [cx]: [aV, c] }], [cu]: [{ [cv]: ch, error: \"S3 MRAP does not support dual-stack\", [ct]: f }, { [cv]: cq, error: \"S3 MRAP does not support FIPS\", [ct]: f }, { [cv]: bB, error: \"S3 MRAP does not support S3 Accelerate\", [ct]: f }, { [cv]: [{ [cw]: e, [cx]: [{ [cy]: \"DisableMultiRegionAccessPoints\" }, c] }], error: \"Invalid configuration: Multi-Region Access Point ARNs are disabled.\", [ct]: f }, { [cv]: [{ [cw]: g, [cx]: by, [cz]: N }], [cu]: [{ [cv]: [{ [cw]: h, [cx]: [{ [cw]: i, [cx]: [{ [cy]: N }, j] }, { [cw]: i, [cx]: [aS, \"partition\"] }] }], [cu]: [{ endpoint: { [cA]: \"https://{accessPointName}.accesspoint.s3-global.{mrapPartition#dnsSuffix}\", [cB]: { [cD]: [{ [cE]: c, name: z, [cF]: B, [cI]: cb }] }, [cH]: al }, [ct]: n }], [ct]: o }, { error: \"Client was configured for partition `{mrapPartition#name}` but bucket referred to partition `{bucketArn#partition}`\", [ct]: f }], [ct]: o }], [ct]: o }, { error: \"Invalid Access Point Name\", [ct]: f }], [ct]: o }, bi], [ct]: o }, { [cv]: [{ [cw]: h, [cx]: [aU, A] }], [cu]: [{ [cv]: ch, error: \"S3 Outposts does not support Dual-stack\", [ct]: f }, { [cv]: cq, error: \"S3 Outposts does not support FIPS\", [ct]: f }, { [cv]: bB, error: \"S3 Outposts does not support S3 Accelerate\", [ct]: f }, { [cv]: [{ [cw]: d, [cx]: [{ [cw]: i, [cx]: [aS, \"resourceId[4]\"] }] }], error: \"Invalid Arn: Outpost Access Point ARN contains sub resources\", [ct]: f }, { [cv]: [{ [cw]: i, [cx]: cg, [cz]: x }], [cu]: [{ [cv]: bZ, [cu]: [aZ, { [cv]: cl, [cu]: [{ [cv]: bG, [cu]: [{ [cv]: cm, [cu]: [{ [cv]: cn, [cu]: [{ [cv]: co, [cu]: [{ [cv]: [{ [cw]: i, [cx]: ck, [cz]: O }], [cu]: [{ [cv]: [{ [cw]: i, [cx]: [aS, \"resourceId[3]\"], [cz]: L }], [cu]: [{ [cv]: [{ [cw]: h, [cx]: [{ [cy]: O }, K] }], [cu]: [{ [cv]: bC, endpoint: { [cA]: \"https://{accessPointName}-{bucketArn#accountId}.{outpostId}.{url#authority}\", [cB]: bk, [cH]: al }, [ct]: n }, { endpoint: { [cA]: \"https://{accessPointName}-{bucketArn#accountId}.{outpostId}.s3-outposts.{bucketArn#region}.{bucketPartition#dnsSuffix}\", [cB]: bk, [cH]: al }, [ct]: n }], [ct]: o }, { error: \"Expected an outpost type `accesspoint`, found {outpostType}\", [ct]: f }], [ct]: o }, { error: \"Invalid ARN: expected an access point name\", [ct]: f }], [ct]: o }, { error: \"Invalid ARN: Expected a 4-component resource\", [ct]: f }], [ct]: o }, be], [ct]: o }, bf], [ct]: o }, bg], [ct]: o }], [ct]: o }], [ct]: o }, { error: \"Invalid ARN: The outpost Id may only contain a-z, A-Z, 0-9 and `-`. Found: `{outpostId}`\", [ct]: f }], [ct]: o }, { error: \"Invalid ARN: The Outpost Id was not set\", [ct]: f }], [ct]: o }, { error: \"Invalid ARN: Unrecognized format: {Bucket} (type: {arnType})\", [ct]: f }], [ct]: o }, { error: \"Invalid ARN: No ARN type specified\", [ct]: f }], [ct]: o }, { [cv]: [{ [cw]: k, [cx]: [ad, 0, 4, b], [cz]: P }, { [cw]: h, [cx]: [{ [cy]: P }, \"arn:\"] }, { [cw]: r, [cx]: [{ [cw]: d, [cx]: [bl] }] }], error: \"Invalid ARN: `{Bucket}` was not a valid ARN\", [ct]: f }, { [cv]: [{ [cw]: e, [cx]: [az, c] }, bl], error: \"Path-style addressing cannot be used with ARN buckets\", [ct]: f }, { [cv]: bE, [cu]: [{ [cv]: bG, [cu]: [{ [cv]: [aA], [cu]: [{ [cv]: [Y, aq, X, aB], endpoint: { [cA]: \"https://s3-fips.dualstack.us-east-1.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [Y, aq, X, aD, aE], [cu]: [{ endpoint: bm, [ct]: n }], [ct]: o }, { [cv]: [Y, aq, X, aD, aH], endpoint: bm, [ct]: n }, { [cv]: [ar, aq, X, aB], endpoint: { [cA]: \"https://s3-fips.us-east-1.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [ar, aq, X, aD, aE], [cu]: [{ endpoint: bn, [ct]: n }], [ct]: o }, { [cv]: [ar, aq, X, aD, aH], endpoint: bn, [ct]: n }, { [cv]: [Y, aq, as, aB], endpoint: { [cA]: \"https://s3.dualstack.us-east-1.{partitionResult#dnsSuffix}/{uri_encoded_bucket}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [Y, aq, as, aD, aE], [cu]: [{ endpoint: bo, [ct]: n }], [ct]: o }, { [cv]: [Y, aq, as, aD, aH], endpoint: bo, [ct]: n }, { [cv]: [ar, Z, ag, as, aB], endpoint: { [cA]: Q, [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [ar, Z, ag, as, aD, aE], [cu]: [{ [cv]: cd, endpoint: bp, [ct]: n }, { endpoint: bp, [ct]: n }], [ct]: o }, { [cv]: [ar, Z, ag, as, aD, aH], endpoint: bp, [ct]: n }, { [cv]: [ar, aq, as, aB], endpoint: { [cA]: R, [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [ar, aq, as, aD, aE], [cu]: [{ [cv]: cd, endpoint: { [cA]: R, [cB]: aG, [cH]: al }, [ct]: n }, { endpoint: bq, [ct]: n }], [ct]: o }, { [cv]: [ar, aq, as, aD, aH], endpoint: bq, [ct]: n }], [ct]: o }, { error: \"Path-style addressing cannot be used with S3 Accelerate\", [ct]: f }], [ct]: o }], [ct]: o }], [ct]: o }, { [cv]: [{ [cw]: d, [cx]: [br] }, { [cw]: e, [cx]: [br, c] }], [cu]: [{ [cv]: bG, [cu]: [{ [cv]: cr, [cu]: [aW, aX, { [cv]: bC, endpoint: { [cA]: t, [cB]: bs, [cH]: al }, [ct]: n }, { [cv]: cq, endpoint: { [cA]: \"https://s3-object-lambda-fips.{Region}.{partitionResult#dnsSuffix}\", [cB]: bs, [cH]: al }, [ct]: n }, { endpoint: { [cA]: \"https://s3-object-lambda.{Region}.{partitionResult#dnsSuffix}\", [cB]: bs, [cH]: al }, [ct]: n }], [ct]: o }, aR], [ct]: o }], [ct]: o }, { [cv]: [au], [cu]: [{ [cv]: bG, [cu]: [{ [cv]: cr, [cu]: [{ [cv]: [X, Y, aq, aB], endpoint: { [cA]: \"https://s3-fips.dualstack.us-east-1.{partitionResult#dnsSuffix}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [X, Y, aq, aD, aE], [cu]: [{ endpoint: bt, [ct]: n }], [ct]: o }, { [cv]: [X, Y, aq, aD, aH], endpoint: bt, [ct]: n }, { [cv]: [X, ar, aq, aB], endpoint: { [cA]: \"https://s3-fips.us-east-1.{partitionResult#dnsSuffix}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [X, ar, aq, aD, aE], [cu]: [{ endpoint: bu, [ct]: n }], [ct]: o }, { [cv]: [X, ar, aq, aD, aH], endpoint: bu, [ct]: n }, { [cv]: [as, Y, aq, aB], endpoint: { [cA]: \"https://s3.dualstack.us-east-1.{partitionResult#dnsSuffix}\", [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [as, Y, aq, aD, aE], [cu]: [{ endpoint: bv, [ct]: n }], [ct]: o }, { [cv]: [as, Y, aq, aD, aH], endpoint: bv, [ct]: n }, { [cv]: [as, ar, Z, ag, aB], endpoint: { [cA]: t, [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [as, ar, Z, ag, aD, aE], [cu]: [{ [cv]: cd, endpoint: bw, [ct]: n }, { endpoint: bw, [ct]: n }], [ct]: o }, { [cv]: [as, ar, Z, ag, aD, aH], endpoint: bw, [ct]: n }, { [cv]: [as, ar, aq, aB], endpoint: { [cA]: S, [cB]: aC, [cH]: al }, [ct]: n }, { [cv]: [as, ar, aq, aD, aE], [cu]: [{ [cv]: cd, endpoint: { [cA]: S, [cB]: aG, [cH]: al }, [ct]: n }, { endpoint: bx, [ct]: n }], [ct]: o }, { [cv]: [as, ar, aq, aD, aH], endpoint: bx, [ct]: n }], [ct]: o }, aR], [ct]: o }], [ct]: o }], [ct]: o }, { error: \"A region must be set when sending requests to S3.\", [ct]: f }] };\nexports.ruleSet = _data;\n","'use strict';\n\nvar middlewareExpectContinue = require('@aws-sdk/middleware-expect-continue');\nvar middlewareFlexibleChecksums = require('@aws-sdk/middleware-flexible-checksums');\nvar middlewareHostHeader = require('@aws-sdk/middleware-host-header');\nvar middlewareLogger = require('@aws-sdk/middleware-logger');\nvar middlewareRecursionDetection = require('@aws-sdk/middleware-recursion-detection');\nvar middlewareSdkS3 = require('@aws-sdk/middleware-sdk-s3');\nvar middlewareUserAgent = require('@aws-sdk/middleware-user-agent');\nvar configResolver = require('@smithy/config-resolver');\nvar core = require('@smithy/core');\nvar schema = require('@smithy/core/schema');\nvar eventstreamSerdeConfigResolver = require('@smithy/eventstream-serde-config-resolver');\nvar middlewareContentLength = require('@smithy/middleware-content-length');\nvar middlewareEndpoint = require('@smithy/middleware-endpoint');\nvar middlewareRetry = require('@smithy/middleware-retry');\nvar smithyClient = require('@smithy/smithy-client');\nvar httpAuthSchemeProvider = require('./auth/httpAuthSchemeProvider');\nvar runtimeConfig = require('./runtimeConfig');\nvar regionConfigResolver = require('@aws-sdk/region-config-resolver');\nvar protocolHttp = require('@smithy/protocol-http');\nvar middlewareSsec = require('@aws-sdk/middleware-ssec');\nvar middlewareLocationConstraint = require('@aws-sdk/middleware-location-constraint');\nvar utilWaiter = require('@smithy/util-waiter');\n\nconst resolveClientEndpointParameters = (options) => {\n    return Object.assign(options, {\n        useFipsEndpoint: options.useFipsEndpoint ?? false,\n        useDualstackEndpoint: options.useDualstackEndpoint ?? false,\n        forcePathStyle: options.forcePathStyle ?? false,\n        useAccelerateEndpoint: options.useAccelerateEndpoint ?? false,\n        useGlobalEndpoint: options.useGlobalEndpoint ?? false,\n        disableMultiregionAccessPoints: options.disableMultiregionAccessPoints ?? false,\n        defaultSigningName: \"s3\",\n        clientContextParams: options.clientContextParams ?? {},\n    });\n};\nconst commonParams = {\n    ForcePathStyle: { type: \"clientContextParams\", name: \"forcePathStyle\" },\n    UseArnRegion: { type: \"clientContextParams\", name: \"useArnRegion\" },\n    DisableMultiRegionAccessPoints: { type: \"clientContextParams\", name: \"disableMultiregionAccessPoints\" },\n    Accelerate: { type: \"clientContextParams\", name: \"useAccelerateEndpoint\" },\n    DisableS3ExpressSessionAuth: { type: \"clientContextParams\", name: \"disableS3ExpressSessionAuth\" },\n    UseGlobalEndpoint: { type: \"builtInParams\", name: \"useGlobalEndpoint\" },\n    UseFIPS: { type: \"builtInParams\", name: \"useFipsEndpoint\" },\n    Endpoint: { type: \"builtInParams\", name: \"endpoint\" },\n    Region: { type: \"builtInParams\", name: \"region\" },\n    UseDualStack: { type: \"builtInParams\", name: \"useDualstackEndpoint\" },\n};\n\nclass S3ServiceException extends smithyClient.ServiceException {\n    constructor(options) {\n        super(options);\n        Object.setPrototypeOf(this, S3ServiceException.prototype);\n    }\n}\n\nclass NoSuchUpload extends S3ServiceException {\n    name = \"NoSuchUpload\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"NoSuchUpload\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, NoSuchUpload.prototype);\n    }\n}\nclass AccessDenied extends S3ServiceException {\n    name = \"AccessDenied\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"AccessDenied\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, AccessDenied.prototype);\n    }\n}\nclass ObjectNotInActiveTierError extends S3ServiceException {\n    name = \"ObjectNotInActiveTierError\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"ObjectNotInActiveTierError\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, ObjectNotInActiveTierError.prototype);\n    }\n}\nclass BucketAlreadyExists extends S3ServiceException {\n    name = \"BucketAlreadyExists\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"BucketAlreadyExists\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, BucketAlreadyExists.prototype);\n    }\n}\nclass BucketAlreadyOwnedByYou extends S3ServiceException {\n    name = \"BucketAlreadyOwnedByYou\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"BucketAlreadyOwnedByYou\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, BucketAlreadyOwnedByYou.prototype);\n    }\n}\nclass NoSuchBucket extends S3ServiceException {\n    name = \"NoSuchBucket\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"NoSuchBucket\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, NoSuchBucket.prototype);\n    }\n}\nclass InvalidObjectState extends S3ServiceException {\n    name = \"InvalidObjectState\";\n    $fault = \"client\";\n    StorageClass;\n    AccessTier;\n    constructor(opts) {\n        super({\n            name: \"InvalidObjectState\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, InvalidObjectState.prototype);\n        this.StorageClass = opts.StorageClass;\n        this.AccessTier = opts.AccessTier;\n    }\n}\nclass NoSuchKey extends S3ServiceException {\n    name = \"NoSuchKey\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"NoSuchKey\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, NoSuchKey.prototype);\n    }\n}\nclass NotFound extends S3ServiceException {\n    name = \"NotFound\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"NotFound\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, NotFound.prototype);\n    }\n}\nclass EncryptionTypeMismatch extends S3ServiceException {\n    name = \"EncryptionTypeMismatch\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"EncryptionTypeMismatch\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, EncryptionTypeMismatch.prototype);\n    }\n}\nclass InvalidRequest extends S3ServiceException {\n    name = \"InvalidRequest\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"InvalidRequest\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, InvalidRequest.prototype);\n    }\n}\nclass InvalidWriteOffset extends S3ServiceException {\n    name = \"InvalidWriteOffset\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"InvalidWriteOffset\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, InvalidWriteOffset.prototype);\n    }\n}\nclass TooManyParts extends S3ServiceException {\n    name = \"TooManyParts\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"TooManyParts\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, TooManyParts.prototype);\n    }\n}\nclass IdempotencyParameterMismatch extends S3ServiceException {\n    name = \"IdempotencyParameterMismatch\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"IdempotencyParameterMismatch\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, IdempotencyParameterMismatch.prototype);\n    }\n}\nclass ObjectAlreadyInActiveTierError extends S3ServiceException {\n    name = \"ObjectAlreadyInActiveTierError\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"ObjectAlreadyInActiveTierError\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, ObjectAlreadyInActiveTierError.prototype);\n    }\n}\n\nconst _A = \"Account\";\nconst _AAO = \"AnalyticsAndOperator\";\nconst _AC = \"AccelerateConfiguration\";\nconst _ACL = \"AccessControlList\";\nconst _ACL_ = \"ACL\";\nconst _ACLn = \"AnalyticsConfigurationList\";\nconst _ACP = \"AccessControlPolicy\";\nconst _ACT = \"AccessControlTranslation\";\nconst _ACn = \"AnalyticsConfiguration\";\nconst _AD = \"AccessDenied\";\nconst _ADb = \"AbortDate\";\nconst _AED = \"AnalyticsExportDestination\";\nconst _AF = \"AnalyticsFilter\";\nconst _AH = \"AllowedHeaders\";\nconst _AHl = \"AllowedHeader\";\nconst _AI = \"AccountId\";\nconst _AIMU = \"AbortIncompleteMultipartUpload\";\nconst _AKI = \"AccessKeyId\";\nconst _AM = \"AllowedMethods\";\nconst _AMU = \"AbortMultipartUpload\";\nconst _AMUO = \"AbortMultipartUploadOutput\";\nconst _AMUR = \"AbortMultipartUploadRequest\";\nconst _AMl = \"AllowedMethod\";\nconst _AO = \"AllowedOrigins\";\nconst _AOl = \"AllowedOrigin\";\nconst _APA = \"AccessPointAlias\";\nconst _APAc = \"AccessPointArn\";\nconst _AQRD = \"AllowQuotedRecordDelimiter\";\nconst _AR = \"AcceptRanges\";\nconst _ARI = \"AbortRuleId\";\nconst _AS = \"AbacStatus\";\nconst _ASBD = \"AnalyticsS3BucketDestination\";\nconst _ASSEBD = \"ApplyServerSideEncryptionByDefault\";\nconst _ASr = \"ArchiveStatus\";\nconst _AT = \"AccessTier\";\nconst _An = \"And\";\nconst _B = \"Bucket\";\nconst _BA = \"BucketArn\";\nconst _BAE = \"BucketAlreadyExists\";\nconst _BAI = \"BucketAccountId\";\nconst _BAOBY = \"BucketAlreadyOwnedByYou\";\nconst _BET = \"BlockedEncryptionTypes\";\nconst _BGR = \"BypassGovernanceRetention\";\nconst _BI = \"BucketInfo\";\nconst _BKE = \"BucketKeyEnabled\";\nconst _BLC = \"BucketLifecycleConfiguration\";\nconst _BLN = \"BucketLocationName\";\nconst _BLS = \"BucketLoggingStatus\";\nconst _BLT = \"BucketLocationType\";\nconst _BN = \"BucketName\";\nconst _BP = \"BytesProcessed\";\nconst _BPA = \"BlockPublicAcls\";\nconst _BPP = \"BlockPublicPolicy\";\nconst _BR = \"BucketRegion\";\nconst _BRy = \"BytesReturned\";\nconst _BS = \"BytesScanned\";\nconst _Bo = \"Body\";\nconst _Bu = \"Buckets\";\nconst _C = \"Checksum\";\nconst _CA = \"ChecksumAlgorithm\";\nconst _CACL = \"CannedACL\";\nconst _CB = \"CreateBucket\";\nconst _CBC = \"CreateBucketConfiguration\";\nconst _CBMC = \"CreateBucketMetadataConfiguration\";\nconst _CBMCR = \"CreateBucketMetadataConfigurationRequest\";\nconst _CBMTC = \"CreateBucketMetadataTableConfiguration\";\nconst _CBMTCR = \"CreateBucketMetadataTableConfigurationRequest\";\nconst _CBO = \"CreateBucketOutput\";\nconst _CBR = \"CreateBucketRequest\";\nconst _CC = \"CacheControl\";\nconst _CCRC = \"ChecksumCRC32\";\nconst _CCRCC = \"ChecksumCRC32C\";\nconst _CCRCNVME = \"ChecksumCRC64NVME\";\nconst _CC_ = \"Cache-Control\";\nconst _CD = \"CreationDate\";\nconst _CD_ = \"Content-Disposition\";\nconst _CDo = \"ContentDisposition\";\nconst _CE = \"ContinuationEvent\";\nconst _CE_ = \"Content-Encoding\";\nconst _CEo = \"ContentEncoding\";\nconst _CF = \"CloudFunction\";\nconst _CFC = \"CloudFunctionConfiguration\";\nconst _CL = \"ContentLanguage\";\nconst _CL_ = \"Content-Language\";\nconst _CL__ = \"Content-Length\";\nconst _CLo = \"ContentLength\";\nconst _CM = \"Content-MD5\";\nconst _CMD = \"ContentMD5\";\nconst _CMU = \"CompletedMultipartUpload\";\nconst _CMUO = \"CompleteMultipartUploadOutput\";\nconst _CMUOr = \"CreateMultipartUploadOutput\";\nconst _CMUR = \"CompleteMultipartUploadResult\";\nconst _CMURo = \"CompleteMultipartUploadRequest\";\nconst _CMURr = \"CreateMultipartUploadRequest\";\nconst _CMUo = \"CompleteMultipartUpload\";\nconst _CMUr = \"CreateMultipartUpload\";\nconst _CMh = \"ChecksumMode\";\nconst _CO = \"CopyObject\";\nconst _COO = \"CopyObjectOutput\";\nconst _COR = \"CopyObjectResult\";\nconst _CORSC = \"CORSConfiguration\";\nconst _CORSR = \"CORSRules\";\nconst _CORSRu = \"CORSRule\";\nconst _CORo = \"CopyObjectRequest\";\nconst _CP = \"CommonPrefix\";\nconst _CPL = \"CommonPrefixList\";\nconst _CPLo = \"CompletedPartList\";\nconst _CPR = \"CopyPartResult\";\nconst _CPo = \"CompletedPart\";\nconst _CPom = \"CommonPrefixes\";\nconst _CR = \"ContentRange\";\nconst _CRSBA = \"ConfirmRemoveSelfBucketAccess\";\nconst _CR_ = \"Content-Range\";\nconst _CS = \"CopySource\";\nconst _CSHA = \"ChecksumSHA1\";\nconst _CSHAh = \"ChecksumSHA256\";\nconst _CSIM = \"CopySourceIfMatch\";\nconst _CSIMS = \"CopySourceIfModifiedSince\";\nconst _CSINM = \"CopySourceIfNoneMatch\";\nconst _CSIUS = \"CopySourceIfUnmodifiedSince\";\nconst _CSO = \"CreateSessionOutput\";\nconst _CSR = \"CreateSessionResult\";\nconst _CSRo = \"CopySourceRange\";\nconst _CSRr = \"CreateSessionRequest\";\nconst _CSSSECA = \"CopySourceSSECustomerAlgorithm\";\nconst _CSSSECK = \"CopySourceSSECustomerKey\";\nconst _CSSSECKMD = \"CopySourceSSECustomerKeyMD5\";\nconst _CSV = \"CSV\";\nconst _CSVI = \"CopySourceVersionId\";\nconst _CSVIn = \"CSVInput\";\nconst _CSVO = \"CSVOutput\";\nconst _CSo = \"ConfigurationState\";\nconst _CSr = \"CreateSession\";\nconst _CT = \"ChecksumType\";\nconst _CT_ = \"Content-Type\";\nconst _CTl = \"ClientToken\";\nconst _CTo = \"ContentType\";\nconst _CTom = \"CompressionType\";\nconst _CTon = \"ContinuationToken\";\nconst _Co = \"Condition\";\nconst _Cod = \"Code\";\nconst _Com = \"Comments\";\nconst _Con = \"Contents\";\nconst _Cont = \"Cont\";\nconst _Cr = \"Credentials\";\nconst _D = \"Days\";\nconst _DAI = \"DaysAfterInitiation\";\nconst _DB = \"DeleteBucket\";\nconst _DBAC = \"DeleteBucketAnalyticsConfiguration\";\nconst _DBACR = \"DeleteBucketAnalyticsConfigurationRequest\";\nconst _DBC = \"DeleteBucketCors\";\nconst _DBCR = \"DeleteBucketCorsRequest\";\nconst _DBE = \"DeleteBucketEncryption\";\nconst _DBER = \"DeleteBucketEncryptionRequest\";\nconst _DBIC = \"DeleteBucketInventoryConfiguration\";\nconst _DBICR = \"DeleteBucketInventoryConfigurationRequest\";\nconst _DBITC = \"DeleteBucketIntelligentTieringConfiguration\";\nconst _DBITCR = \"DeleteBucketIntelligentTieringConfigurationRequest\";\nconst _DBL = \"DeleteBucketLifecycle\";\nconst _DBLR = \"DeleteBucketLifecycleRequest\";\nconst _DBMC = \"DeleteBucketMetadataConfiguration\";\nconst _DBMCR = \"DeleteBucketMetadataConfigurationRequest\";\nconst _DBMCRe = \"DeleteBucketMetricsConfigurationRequest\";\nconst _DBMCe = \"DeleteBucketMetricsConfiguration\";\nconst _DBMTC = \"DeleteBucketMetadataTableConfiguration\";\nconst _DBMTCR = \"DeleteBucketMetadataTableConfigurationRequest\";\nconst _DBOC = \"DeleteBucketOwnershipControls\";\nconst _DBOCR = \"DeleteBucketOwnershipControlsRequest\";\nconst _DBP = \"DeleteBucketPolicy\";\nconst _DBPR = \"DeleteBucketPolicyRequest\";\nconst _DBR = \"DeleteBucketRequest\";\nconst _DBRR = \"DeleteBucketReplicationRequest\";\nconst _DBRe = \"DeleteBucketReplication\";\nconst _DBT = \"DeleteBucketTagging\";\nconst _DBTR = \"DeleteBucketTaggingRequest\";\nconst _DBW = \"DeleteBucketWebsite\";\nconst _DBWR = \"DeleteBucketWebsiteRequest\";\nconst _DE = \"DataExport\";\nconst _DIM = \"DestinationIfMatch\";\nconst _DIMS = \"DestinationIfModifiedSince\";\nconst _DINM = \"DestinationIfNoneMatch\";\nconst _DIUS = \"DestinationIfUnmodifiedSince\";\nconst _DM = \"DeleteMarker\";\nconst _DME = \"DeleteMarkerEntry\";\nconst _DMR = \"DeleteMarkerReplication\";\nconst _DMVI = \"DeleteMarkerVersionId\";\nconst _DMe = \"DeleteMarkers\";\nconst _DN = \"DisplayName\";\nconst _DO = \"DeletedObject\";\nconst _DOO = \"DeleteObjectOutput\";\nconst _DOOe = \"DeleteObjectsOutput\";\nconst _DOR = \"DeleteObjectRequest\";\nconst _DORe = \"DeleteObjectsRequest\";\nconst _DOT = \"DeleteObjectTagging\";\nconst _DOTO = \"DeleteObjectTaggingOutput\";\nconst _DOTR = \"DeleteObjectTaggingRequest\";\nconst _DOe = \"DeletedObjects\";\nconst _DOel = \"DeleteObject\";\nconst _DOele = \"DeleteObjects\";\nconst _DPAB = \"DeletePublicAccessBlock\";\nconst _DPABR = \"DeletePublicAccessBlockRequest\";\nconst _DR = \"DataRedundancy\";\nconst _DRe = \"DefaultRetention\";\nconst _DRel = \"DeleteResult\";\nconst _DRes = \"DestinationResult\";\nconst _Da = \"Date\";\nconst _De = \"Delete\";\nconst _Del = \"Deleted\";\nconst _Deli = \"Delimiter\";\nconst _Des = \"Destination\";\nconst _Desc = \"Description\";\nconst _Det = \"Details\";\nconst _E = \"Expiration\";\nconst _EA = \"EmailAddress\";\nconst _EBC = \"EventBridgeConfiguration\";\nconst _EBO = \"ExpectedBucketOwner\";\nconst _EC = \"EncryptionConfiguration\";\nconst _ECr = \"ErrorCode\";\nconst _ED = \"ErrorDetails\";\nconst _EDr = \"ErrorDocument\";\nconst _EE = \"EndEvent\";\nconst _EH = \"ExposeHeaders\";\nconst _EHx = \"ExposeHeader\";\nconst _EM = \"ErrorMessage\";\nconst _EODM = \"ExpiredObjectDeleteMarker\";\nconst _EOR = \"ExistingObjectReplication\";\nconst _ES = \"ExpiresString\";\nconst _ESBO = \"ExpectedSourceBucketOwner\";\nconst _ET = \"EncryptionType\";\nconst _ETL = \"EncryptionTypeList\";\nconst _ETM = \"EncryptionTypeMismatch\";\nconst _ETa = \"ETag\";\nconst _ETn = \"EncodingType\";\nconst _ETv = \"EventThreshold\";\nconst _ETx = \"ExpressionType\";\nconst _En = \"Encryption\";\nconst _Ena = \"Enabled\";\nconst _End = \"End\";\nconst _Er = \"Errors\";\nconst _Err = \"Error\";\nconst _Ev = \"Events\";\nconst _Eve = \"Event\";\nconst _Ex = \"Expires\";\nconst _Exp = \"Expression\";\nconst _F = \"Filter\";\nconst _FD = \"FieldDelimiter\";\nconst _FHI = \"FileHeaderInfo\";\nconst _FO = \"FetchOwner\";\nconst _FR = \"FilterRule\";\nconst _FRL = \"FilterRuleList\";\nconst _FRi = \"FilterRules\";\nconst _Fi = \"Field\";\nconst _Fo = \"Format\";\nconst _Fr = \"Frequency\";\nconst _G = \"Grants\";\nconst _GBA = \"GetBucketAbac\";\nconst _GBAC = \"GetBucketAccelerateConfiguration\";\nconst _GBACO = \"GetBucketAccelerateConfigurationOutput\";\nconst _GBACOe = \"GetBucketAnalyticsConfigurationOutput\";\nconst _GBACR = \"GetBucketAccelerateConfigurationRequest\";\nconst _GBACRe = \"GetBucketAnalyticsConfigurationRequest\";\nconst _GBACe = \"GetBucketAnalyticsConfiguration\";\nconst _GBAO = \"GetBucketAbacOutput\";\nconst _GBAOe = \"GetBucketAclOutput\";\nconst _GBAR = \"GetBucketAbacRequest\";\nconst _GBARe = \"GetBucketAclRequest\";\nconst _GBAe = \"GetBucketAcl\";\nconst _GBC = \"GetBucketCors\";\nconst _GBCO = \"GetBucketCorsOutput\";\nconst _GBCR = \"GetBucketCorsRequest\";\nconst _GBE = \"GetBucketEncryption\";\nconst _GBEO = \"GetBucketEncryptionOutput\";\nconst _GBER = \"GetBucketEncryptionRequest\";\nconst _GBIC = \"GetBucketInventoryConfiguration\";\nconst _GBICO = \"GetBucketInventoryConfigurationOutput\";\nconst _GBICR = \"GetBucketInventoryConfigurationRequest\";\nconst _GBITC = \"GetBucketIntelligentTieringConfiguration\";\nconst _GBITCO = \"GetBucketIntelligentTieringConfigurationOutput\";\nconst _GBITCR = \"GetBucketIntelligentTieringConfigurationRequest\";\nconst _GBL = \"GetBucketLocation\";\nconst _GBLC = \"GetBucketLifecycleConfiguration\";\nconst _GBLCO = \"GetBucketLifecycleConfigurationOutput\";\nconst _GBLCR = \"GetBucketLifecycleConfigurationRequest\";\nconst _GBLO = \"GetBucketLocationOutput\";\nconst _GBLOe = \"GetBucketLoggingOutput\";\nconst _GBLR = \"GetBucketLocationRequest\";\nconst _GBLRe = \"GetBucketLoggingRequest\";\nconst _GBLe = \"GetBucketLogging\";\nconst _GBMC = \"GetBucketMetadataConfiguration\";\nconst _GBMCO = \"GetBucketMetadataConfigurationOutput\";\nconst _GBMCOe = \"GetBucketMetricsConfigurationOutput\";\nconst _GBMCR = \"GetBucketMetadataConfigurationResult\";\nconst _GBMCRe = \"GetBucketMetadataConfigurationRequest\";\nconst _GBMCRet = \"GetBucketMetricsConfigurationRequest\";\nconst _GBMCe = \"GetBucketMetricsConfiguration\";\nconst _GBMTC = \"GetBucketMetadataTableConfiguration\";\nconst _GBMTCO = \"GetBucketMetadataTableConfigurationOutput\";\nconst _GBMTCR = \"GetBucketMetadataTableConfigurationResult\";\nconst _GBMTCRe = \"GetBucketMetadataTableConfigurationRequest\";\nconst _GBNC = \"GetBucketNotificationConfiguration\";\nconst _GBNCR = \"GetBucketNotificationConfigurationRequest\";\nconst _GBOC = \"GetBucketOwnershipControls\";\nconst _GBOCO = \"GetBucketOwnershipControlsOutput\";\nconst _GBOCR = \"GetBucketOwnershipControlsRequest\";\nconst _GBP = \"GetBucketPolicy\";\nconst _GBPO = \"GetBucketPolicyOutput\";\nconst _GBPR = \"GetBucketPolicyRequest\";\nconst _GBPS = \"GetBucketPolicyStatus\";\nconst _GBPSO = \"GetBucketPolicyStatusOutput\";\nconst _GBPSR = \"GetBucketPolicyStatusRequest\";\nconst _GBR = \"GetBucketReplication\";\nconst _GBRO = \"GetBucketReplicationOutput\";\nconst _GBRP = \"GetBucketRequestPayment\";\nconst _GBRPO = \"GetBucketRequestPaymentOutput\";\nconst _GBRPR = \"GetBucketRequestPaymentRequest\";\nconst _GBRR = \"GetBucketReplicationRequest\";\nconst _GBT = \"GetBucketTagging\";\nconst _GBTO = \"GetBucketTaggingOutput\";\nconst _GBTR = \"GetBucketTaggingRequest\";\nconst _GBV = \"GetBucketVersioning\";\nconst _GBVO = \"GetBucketVersioningOutput\";\nconst _GBVR = \"GetBucketVersioningRequest\";\nconst _GBW = \"GetBucketWebsite\";\nconst _GBWO = \"GetBucketWebsiteOutput\";\nconst _GBWR = \"GetBucketWebsiteRequest\";\nconst _GFC = \"GrantFullControl\";\nconst _GJP = \"GlacierJobParameters\";\nconst _GO = \"GetObject\";\nconst _GOA = \"GetObjectAcl\";\nconst _GOAO = \"GetObjectAclOutput\";\nconst _GOAOe = \"GetObjectAttributesOutput\";\nconst _GOAP = \"GetObjectAttributesParts\";\nconst _GOAR = \"GetObjectAclRequest\";\nconst _GOARe = \"GetObjectAttributesResponse\";\nconst _GOARet = \"GetObjectAttributesRequest\";\nconst _GOAe = \"GetObjectAttributes\";\nconst _GOLC = \"GetObjectLockConfiguration\";\nconst _GOLCO = \"GetObjectLockConfigurationOutput\";\nconst _GOLCR = \"GetObjectLockConfigurationRequest\";\nconst _GOLH = \"GetObjectLegalHold\";\nconst _GOLHO = \"GetObjectLegalHoldOutput\";\nconst _GOLHR = \"GetObjectLegalHoldRequest\";\nconst _GOO = \"GetObjectOutput\";\nconst _GOR = \"GetObjectRequest\";\nconst _GORO = \"GetObjectRetentionOutput\";\nconst _GORR = \"GetObjectRetentionRequest\";\nconst _GORe = \"GetObjectRetention\";\nconst _GOT = \"GetObjectTagging\";\nconst _GOTO = \"GetObjectTaggingOutput\";\nconst _GOTOe = \"GetObjectTorrentOutput\";\nconst _GOTR = \"GetObjectTaggingRequest\";\nconst _GOTRe = \"GetObjectTorrentRequest\";\nconst _GOTe = \"GetObjectTorrent\";\nconst _GPAB = \"GetPublicAccessBlock\";\nconst _GPABO = \"GetPublicAccessBlockOutput\";\nconst _GPABR = \"GetPublicAccessBlockRequest\";\nconst _GR = \"GrantRead\";\nconst _GRACP = \"GrantReadACP\";\nconst _GW = \"GrantWrite\";\nconst _GWACP = \"GrantWriteACP\";\nconst _Gr = \"Grant\";\nconst _Gra = \"Grantee\";\nconst _HB = \"HeadBucket\";\nconst _HBO = \"HeadBucketOutput\";\nconst _HBR = \"HeadBucketRequest\";\nconst _HECRE = \"HttpErrorCodeReturnedEquals\";\nconst _HN = \"HostName\";\nconst _HO = \"HeadObject\";\nconst _HOO = \"HeadObjectOutput\";\nconst _HOR = \"HeadObjectRequest\";\nconst _HRC = \"HttpRedirectCode\";\nconst _I = \"Id\";\nconst _IC = \"InventoryConfiguration\";\nconst _ICL = \"InventoryConfigurationList\";\nconst _ID = \"ID\";\nconst _IDn = \"IndexDocument\";\nconst _IDnv = \"InventoryDestination\";\nconst _IE = \"IsEnabled\";\nconst _IEn = \"InventoryEncryption\";\nconst _IF = \"InventoryFilter\";\nconst _IL = \"IsLatest\";\nconst _IM = \"IfMatch\";\nconst _IMIT = \"IfMatchInitiatedTime\";\nconst _IMLMT = \"IfMatchLastModifiedTime\";\nconst _IMS = \"IfMatchSize\";\nconst _IMS_ = \"If-Modified-Since\";\nconst _IMSf = \"IfModifiedSince\";\nconst _IMUR = \"InitiateMultipartUploadResult\";\nconst _IM_ = \"If-Match\";\nconst _INM = \"IfNoneMatch\";\nconst _INM_ = \"If-None-Match\";\nconst _IOF = \"InventoryOptionalFields\";\nconst _IOS = \"InvalidObjectState\";\nconst _IOV = \"IncludedObjectVersions\";\nconst _IP = \"IsPublic\";\nconst _IPA = \"IgnorePublicAcls\";\nconst _IPM = \"IdempotencyParameterMismatch\";\nconst _IR = \"InvalidRequest\";\nconst _IRIP = \"IsRestoreInProgress\";\nconst _IS = \"InputSerialization\";\nconst _ISBD = \"InventoryS3BucketDestination\";\nconst _ISn = \"InventorySchedule\";\nconst _IT = \"IsTruncated\";\nconst _ITAO = \"IntelligentTieringAndOperator\";\nconst _ITC = \"IntelligentTieringConfiguration\";\nconst _ITCL = \"IntelligentTieringConfigurationList\";\nconst _ITCR = \"InventoryTableConfigurationResult\";\nconst _ITCU = \"InventoryTableConfigurationUpdates\";\nconst _ITCn = \"InventoryTableConfiguration\";\nconst _ITF = \"IntelligentTieringFilter\";\nconst _IUS = \"IfUnmodifiedSince\";\nconst _IUS_ = \"If-Unmodified-Since\";\nconst _IWO = \"InvalidWriteOffset\";\nconst _In = \"Initiator\";\nconst _Ini = \"Initiated\";\nconst _JSON = \"JSON\";\nconst _JSONI = \"JSONInput\";\nconst _JSONO = \"JSONOutput\";\nconst _JTC = \"JournalTableConfiguration\";\nconst _JTCR = \"JournalTableConfigurationResult\";\nconst _JTCU = \"JournalTableConfigurationUpdates\";\nconst _K = \"Key\";\nconst _KC = \"KeyCount\";\nconst _KI = \"KeyId\";\nconst _KKA = \"KmsKeyArn\";\nconst _KM = \"KeyMarker\";\nconst _KMSC = \"KMSContext\";\nconst _KMSKA = \"KMSKeyArn\";\nconst _KMSKI = \"KMSKeyId\";\nconst _KMSMKID = \"KMSMasterKeyID\";\nconst _KPE = \"KeyPrefixEquals\";\nconst _L = \"Location\";\nconst _LAMBR = \"ListAllMyBucketsResult\";\nconst _LAMDBR = \"ListAllMyDirectoryBucketsResult\";\nconst _LB = \"ListBuckets\";\nconst _LBAC = \"ListBucketAnalyticsConfigurations\";\nconst _LBACO = \"ListBucketAnalyticsConfigurationsOutput\";\nconst _LBACR = \"ListBucketAnalyticsConfigurationResult\";\nconst _LBACRi = \"ListBucketAnalyticsConfigurationsRequest\";\nconst _LBIC = \"ListBucketInventoryConfigurations\";\nconst _LBICO = \"ListBucketInventoryConfigurationsOutput\";\nconst _LBICR = \"ListBucketInventoryConfigurationsRequest\";\nconst _LBITC = \"ListBucketIntelligentTieringConfigurations\";\nconst _LBITCO = \"ListBucketIntelligentTieringConfigurationsOutput\";\nconst _LBITCR = \"ListBucketIntelligentTieringConfigurationsRequest\";\nconst _LBMC = \"ListBucketMetricsConfigurations\";\nconst _LBMCO = \"ListBucketMetricsConfigurationsOutput\";\nconst _LBMCR = \"ListBucketMetricsConfigurationsRequest\";\nconst _LBO = \"ListBucketsOutput\";\nconst _LBR = \"ListBucketsRequest\";\nconst _LBRi = \"ListBucketResult\";\nconst _LC = \"LocationConstraint\";\nconst _LCi = \"LifecycleConfiguration\";\nconst _LDB = \"ListDirectoryBuckets\";\nconst _LDBO = \"ListDirectoryBucketsOutput\";\nconst _LDBR = \"ListDirectoryBucketsRequest\";\nconst _LE = \"LoggingEnabled\";\nconst _LEi = \"LifecycleExpiration\";\nconst _LFA = \"LambdaFunctionArn\";\nconst _LFC = \"LambdaFunctionConfiguration\";\nconst _LFCL = \"LambdaFunctionConfigurationList\";\nconst _LFCa = \"LambdaFunctionConfigurations\";\nconst _LH = \"LegalHold\";\nconst _LI = \"LocationInfo\";\nconst _LICR = \"ListInventoryConfigurationsResult\";\nconst _LM = \"LastModified\";\nconst _LMCR = \"ListMetricsConfigurationsResult\";\nconst _LMT = \"LastModifiedTime\";\nconst _LMU = \"ListMultipartUploads\";\nconst _LMUO = \"ListMultipartUploadsOutput\";\nconst _LMUR = \"ListMultipartUploadsResult\";\nconst _LMURi = \"ListMultipartUploadsRequest\";\nconst _LM_ = \"Last-Modified\";\nconst _LO = \"ListObjects\";\nconst _LOO = \"ListObjectsOutput\";\nconst _LOR = \"ListObjectsRequest\";\nconst _LOV = \"ListObjectsV2\";\nconst _LOVO = \"ListObjectsV2Output\";\nconst _LOVOi = \"ListObjectVersionsOutput\";\nconst _LOVR = \"ListObjectsV2Request\";\nconst _LOVRi = \"ListObjectVersionsRequest\";\nconst _LOVi = \"ListObjectVersions\";\nconst _LP = \"ListParts\";\nconst _LPO = \"ListPartsOutput\";\nconst _LPR = \"ListPartsResult\";\nconst _LPRi = \"ListPartsRequest\";\nconst _LR = \"LifecycleRule\";\nconst _LRAO = \"LifecycleRuleAndOperator\";\nconst _LRF = \"LifecycleRuleFilter\";\nconst _LRi = \"LifecycleRules\";\nconst _LVR = \"ListVersionsResult\";\nconst _M = \"Metadata\";\nconst _MAO = \"MetricsAndOperator\";\nconst _MAS = \"MaxAgeSeconds\";\nconst _MB = \"MaxBuckets\";\nconst _MC = \"MetadataConfiguration\";\nconst _MCL = \"MetricsConfigurationList\";\nconst _MCR = \"MetadataConfigurationResult\";\nconst _MCe = \"MetricsConfiguration\";\nconst _MD = \"MetadataDirective\";\nconst _MDB = \"MaxDirectoryBuckets\";\nconst _MDf = \"MfaDelete\";\nconst _ME = \"MetadataEntry\";\nconst _MF = \"MetricsFilter\";\nconst _MFA = \"MFA\";\nconst _MFAD = \"MFADelete\";\nconst _MK = \"MaxKeys\";\nconst _MM = \"MissingMeta\";\nconst _MOS = \"MpuObjectSize\";\nconst _MP = \"MaxParts\";\nconst _MTC = \"MetadataTableConfiguration\";\nconst _MTCR = \"MetadataTableConfigurationResult\";\nconst _MTEC = \"MetadataTableEncryptionConfiguration\";\nconst _MU = \"MultipartUpload\";\nconst _MUL = \"MultipartUploadList\";\nconst _MUa = \"MaxUploads\";\nconst _Ma = \"Marker\";\nconst _Me = \"Metrics\";\nconst _Mes = \"Message\";\nconst _Mi = \"Minutes\";\nconst _Mo = \"Mode\";\nconst _N = \"Name\";\nconst _NC = \"NotificationConfiguration\";\nconst _NCF = \"NotificationConfigurationFilter\";\nconst _NCT = \"NextContinuationToken\";\nconst _ND = \"NoncurrentDays\";\nconst _NEKKAS = \"NonEmptyKmsKeyArnString\";\nconst _NF = \"NotFound\";\nconst _NKM = \"NextKeyMarker\";\nconst _NM = \"NextMarker\";\nconst _NNV = \"NewerNoncurrentVersions\";\nconst _NPNM = \"NextPartNumberMarker\";\nconst _NSB = \"NoSuchBucket\";\nconst _NSK = \"NoSuchKey\";\nconst _NSU = \"NoSuchUpload\";\nconst _NUIM = \"NextUploadIdMarker\";\nconst _NVE = \"NoncurrentVersionExpiration\";\nconst _NVIM = \"NextVersionIdMarker\";\nconst _NVT = \"NoncurrentVersionTransitions\";\nconst _NVTL = \"NoncurrentVersionTransitionList\";\nconst _NVTo = \"NoncurrentVersionTransition\";\nconst _O = \"Owner\";\nconst _OA = \"ObjectAttributes\";\nconst _OAIATE = \"ObjectAlreadyInActiveTierError\";\nconst _OC = \"OwnershipControls\";\nconst _OCR = \"OwnershipControlsRule\";\nconst _OCRw = \"OwnershipControlsRules\";\nconst _OE = \"ObjectEncryption\";\nconst _OF = \"OptionalFields\";\nconst _OI = \"ObjectIdentifier\";\nconst _OIL = \"ObjectIdentifierList\";\nconst _OL = \"OutputLocation\";\nconst _OLC = \"ObjectLockConfiguration\";\nconst _OLE = \"ObjectLockEnabled\";\nconst _OLEFB = \"ObjectLockEnabledForBucket\";\nconst _OLLH = \"ObjectLockLegalHold\";\nconst _OLLHS = \"ObjectLockLegalHoldStatus\";\nconst _OLM = \"ObjectLockMode\";\nconst _OLR = \"ObjectLockRetention\";\nconst _OLRUD = \"ObjectLockRetainUntilDate\";\nconst _OLRb = \"ObjectLockRule\";\nconst _OLb = \"ObjectList\";\nconst _ONIATE = \"ObjectNotInActiveTierError\";\nconst _OO = \"ObjectOwnership\";\nconst _OOA = \"OptionalObjectAttributes\";\nconst _OP = \"ObjectParts\";\nconst _OPb = \"ObjectPart\";\nconst _OS = \"ObjectSize\";\nconst _OSGT = \"ObjectSizeGreaterThan\";\nconst _OSLT = \"ObjectSizeLessThan\";\nconst _OSV = \"OutputSchemaVersion\";\nconst _OSu = \"OutputSerialization\";\nconst _OV = \"ObjectVersion\";\nconst _OVL = \"ObjectVersionList\";\nconst _Ob = \"Objects\";\nconst _Obj = \"Object\";\nconst _P = \"Prefix\";\nconst _PABC = \"PublicAccessBlockConfiguration\";\nconst _PBA = \"PutBucketAbac\";\nconst _PBAC = \"PutBucketAccelerateConfiguration\";\nconst _PBACR = \"PutBucketAccelerateConfigurationRequest\";\nconst _PBACRu = \"PutBucketAnalyticsConfigurationRequest\";\nconst _PBACu = \"PutBucketAnalyticsConfiguration\";\nconst _PBAR = \"PutBucketAbacRequest\";\nconst _PBARu = \"PutBucketAclRequest\";\nconst _PBAu = \"PutBucketAcl\";\nconst _PBC = \"PutBucketCors\";\nconst _PBCR = \"PutBucketCorsRequest\";\nconst _PBE = \"PutBucketEncryption\";\nconst _PBER = \"PutBucketEncryptionRequest\";\nconst _PBIC = \"PutBucketInventoryConfiguration\";\nconst _PBICR = \"PutBucketInventoryConfigurationRequest\";\nconst _PBITC = \"PutBucketIntelligentTieringConfiguration\";\nconst _PBITCR = \"PutBucketIntelligentTieringConfigurationRequest\";\nconst _PBL = \"PutBucketLogging\";\nconst _PBLC = \"PutBucketLifecycleConfiguration\";\nconst _PBLCO = \"PutBucketLifecycleConfigurationOutput\";\nconst _PBLCR = \"PutBucketLifecycleConfigurationRequest\";\nconst _PBLR = \"PutBucketLoggingRequest\";\nconst _PBMC = \"PutBucketMetricsConfiguration\";\nconst _PBMCR = \"PutBucketMetricsConfigurationRequest\";\nconst _PBNC = \"PutBucketNotificationConfiguration\";\nconst _PBNCR = \"PutBucketNotificationConfigurationRequest\";\nconst _PBOC = \"PutBucketOwnershipControls\";\nconst _PBOCR = \"PutBucketOwnershipControlsRequest\";\nconst _PBP = \"PutBucketPolicy\";\nconst _PBPR = \"PutBucketPolicyRequest\";\nconst _PBR = \"PutBucketReplication\";\nconst _PBRP = \"PutBucketRequestPayment\";\nconst _PBRPR = \"PutBucketRequestPaymentRequest\";\nconst _PBRR = \"PutBucketReplicationRequest\";\nconst _PBT = \"PutBucketTagging\";\nconst _PBTR = \"PutBucketTaggingRequest\";\nconst _PBV = \"PutBucketVersioning\";\nconst _PBVR = \"PutBucketVersioningRequest\";\nconst _PBW = \"PutBucketWebsite\";\nconst _PBWR = \"PutBucketWebsiteRequest\";\nconst _PC = \"PartsCount\";\nconst _PDS = \"PartitionDateSource\";\nconst _PE = \"ProgressEvent\";\nconst _PI = \"ParquetInput\";\nconst _PL = \"PartsList\";\nconst _PN = \"PartNumber\";\nconst _PNM = \"PartNumberMarker\";\nconst _PO = \"PutObject\";\nconst _POA = \"PutObjectAcl\";\nconst _POAO = \"PutObjectAclOutput\";\nconst _POAR = \"PutObjectAclRequest\";\nconst _POLC = \"PutObjectLockConfiguration\";\nconst _POLCO = \"PutObjectLockConfigurationOutput\";\nconst _POLCR = \"PutObjectLockConfigurationRequest\";\nconst _POLH = \"PutObjectLegalHold\";\nconst _POLHO = \"PutObjectLegalHoldOutput\";\nconst _POLHR = \"PutObjectLegalHoldRequest\";\nconst _POO = \"PutObjectOutput\";\nconst _POR = \"PutObjectRequest\";\nconst _PORO = \"PutObjectRetentionOutput\";\nconst _PORR = \"PutObjectRetentionRequest\";\nconst _PORu = \"PutObjectRetention\";\nconst _POT = \"PutObjectTagging\";\nconst _POTO = \"PutObjectTaggingOutput\";\nconst _POTR = \"PutObjectTaggingRequest\";\nconst _PP = \"PartitionedPrefix\";\nconst _PPAB = \"PutPublicAccessBlock\";\nconst _PPABR = \"PutPublicAccessBlockRequest\";\nconst _PS = \"PolicyStatus\";\nconst _Pa = \"Parts\";\nconst _Par = \"Part\";\nconst _Parq = \"Parquet\";\nconst _Pay = \"Payer\";\nconst _Payl = \"Payload\";\nconst _Pe = \"Permission\";\nconst _Po = \"Policy\";\nconst _Pr = \"Progress\";\nconst _Pri = \"Priority\";\nconst _Pro = \"Protocol\";\nconst _Q = \"Quiet\";\nconst _QA = \"QueueArn\";\nconst _QC = \"QuoteCharacter\";\nconst _QCL = \"QueueConfigurationList\";\nconst _QCu = \"QueueConfigurations\";\nconst _QCue = \"QueueConfiguration\";\nconst _QEC = \"QuoteEscapeCharacter\";\nconst _QF = \"QuoteFields\";\nconst _Qu = \"Queue\";\nconst _R = \"Rules\";\nconst _RART = \"RedirectAllRequestsTo\";\nconst _RC = \"RequestCharged\";\nconst _RCC = \"ResponseCacheControl\";\nconst _RCD = \"ResponseContentDisposition\";\nconst _RCE = \"ResponseContentEncoding\";\nconst _RCL = \"ResponseContentLanguage\";\nconst _RCT = \"ResponseContentType\";\nconst _RCe = \"ReplicationConfiguration\";\nconst _RD = \"RecordDelimiter\";\nconst _RE = \"ResponseExpires\";\nconst _RED = \"RestoreExpiryDate\";\nconst _REe = \"RecordExpiration\";\nconst _REec = \"RecordsEvent\";\nconst _RKKID = \"ReplicaKmsKeyID\";\nconst _RKPW = \"ReplaceKeyPrefixWith\";\nconst _RKW = \"ReplaceKeyWith\";\nconst _RM = \"ReplicaModifications\";\nconst _RO = \"RenameObject\";\nconst _ROO = \"RenameObjectOutput\";\nconst _ROOe = \"RestoreObjectOutput\";\nconst _ROP = \"RestoreOutputPath\";\nconst _ROR = \"RenameObjectRequest\";\nconst _RORe = \"RestoreObjectRequest\";\nconst _ROe = \"RestoreObject\";\nconst _RP = \"RequestPayer\";\nconst _RPB = \"RestrictPublicBuckets\";\nconst _RPC = \"RequestPaymentConfiguration\";\nconst _RPe = \"RequestProgress\";\nconst _RR = \"RoutingRules\";\nconst _RRAO = \"ReplicationRuleAndOperator\";\nconst _RRF = \"ReplicationRuleFilter\";\nconst _RRe = \"ReplicationRule\";\nconst _RRep = \"ReplicationRules\";\nconst _RReq = \"RequestRoute\";\nconst _RRes = \"RestoreRequest\";\nconst _RRo = \"RoutingRule\";\nconst _RS = \"ReplicationStatus\";\nconst _RSe = \"RestoreStatus\";\nconst _RSen = \"RenameSource\";\nconst _RT = \"ReplicationTime\";\nconst _RTV = \"ReplicationTimeValue\";\nconst _RTe = \"RequestToken\";\nconst _RUD = \"RetainUntilDate\";\nconst _Ra = \"Range\";\nconst _Re = \"Restore\";\nconst _Rec = \"Records\";\nconst _Red = \"Redirect\";\nconst _Ret = \"Retention\";\nconst _Ro = \"Role\";\nconst _Ru = \"Rule\";\nconst _S = \"Status\";\nconst _SA = \"StartAfter\";\nconst _SAK = \"SecretAccessKey\";\nconst _SAs = \"SseAlgorithm\";\nconst _SB = \"StreamingBlob\";\nconst _SBD = \"S3BucketDestination\";\nconst _SC = \"StorageClass\";\nconst _SCA = \"StorageClassAnalysis\";\nconst _SCADE = \"StorageClassAnalysisDataExport\";\nconst _SCV = \"SessionCredentialValue\";\nconst _SCe = \"SessionCredentials\";\nconst _SCt = \"StatusCode\";\nconst _SDV = \"SkipDestinationValidation\";\nconst _SE = \"StatsEvent\";\nconst _SIM = \"SourceIfMatch\";\nconst _SIMS = \"SourceIfModifiedSince\";\nconst _SINM = \"SourceIfNoneMatch\";\nconst _SIUS = \"SourceIfUnmodifiedSince\";\nconst _SK = \"SSE-KMS\";\nconst _SKEO = \"SseKmsEncryptedObjects\";\nconst _SKF = \"S3KeyFilter\";\nconst _SKe = \"S3Key\";\nconst _SL = \"S3Location\";\nconst _SM = \"SessionMode\";\nconst _SOC = \"SelectObjectContent\";\nconst _SOCES = \"SelectObjectContentEventStream\";\nconst _SOCO = \"SelectObjectContentOutput\";\nconst _SOCR = \"SelectObjectContentRequest\";\nconst _SP = \"SelectParameters\";\nconst _SPi = \"SimplePrefix\";\nconst _SR = \"ScanRange\";\nconst _SS = \"SSE-S3\";\nconst _SSC = \"SourceSelectionCriteria\";\nconst _SSE = \"ServerSideEncryption\";\nconst _SSEA = \"SSEAlgorithm\";\nconst _SSEBD = \"ServerSideEncryptionByDefault\";\nconst _SSEC = \"ServerSideEncryptionConfiguration\";\nconst _SSECA = \"SSECustomerAlgorithm\";\nconst _SSECK = \"SSECustomerKey\";\nconst _SSECKMD = \"SSECustomerKeyMD5\";\nconst _SSEKMS = \"SSEKMS\";\nconst _SSEKMSE = \"SSEKMSEncryption\";\nconst _SSEKMSEC = \"SSEKMSEncryptionContext\";\nconst _SSEKMSKI = \"SSEKMSKeyId\";\nconst _SSER = \"ServerSideEncryptionRule\";\nconst _SSERe = \"ServerSideEncryptionRules\";\nconst _SSES = \"SSES3\";\nconst _ST = \"SessionToken\";\nconst _STD = \"S3TablesDestination\";\nconst _STDR = \"S3TablesDestinationResult\";\nconst _S_ = \"S3\";\nconst _Sc = \"Schedule\";\nconst _Si = \"Size\";\nconst _St = \"Start\";\nconst _Sta = \"Stats\";\nconst _Su = \"Suffix\";\nconst _T = \"Tags\";\nconst _TA = \"TableArn\";\nconst _TAo = \"TopicArn\";\nconst _TB = \"TargetBucket\";\nconst _TBA = \"TableBucketArn\";\nconst _TBT = \"TableBucketType\";\nconst _TC = \"TagCount\";\nconst _TCL = \"TopicConfigurationList\";\nconst _TCo = \"TopicConfigurations\";\nconst _TCop = \"TopicConfiguration\";\nconst _TD = \"TaggingDirective\";\nconst _TDMOS = \"TransitionDefaultMinimumObjectSize\";\nconst _TG = \"TargetGrants\";\nconst _TGa = \"TargetGrant\";\nconst _TL = \"TieringList\";\nconst _TLr = \"TransitionList\";\nconst _TMP = \"TooManyParts\";\nconst _TN = \"TableNamespace\";\nconst _TNa = \"TableName\";\nconst _TOKF = \"TargetObjectKeyFormat\";\nconst _TP = \"TargetPrefix\";\nconst _TPC = \"TotalPartsCount\";\nconst _TS = \"TagSet\";\nconst _TSa = \"TableStatus\";\nconst _Ta = \"Tag\";\nconst _Tag = \"Tagging\";\nconst _Ti = \"Tier\";\nconst _Tie = \"Tierings\";\nconst _Tier = \"Tiering\";\nconst _Tim = \"Time\";\nconst _To = \"Token\";\nconst _Top = \"Topic\";\nconst _Tr = \"Transitions\";\nconst _Tra = \"Transition\";\nconst _Ty = \"Type\";\nconst _U = \"Uploads\";\nconst _UBMITC = \"UpdateBucketMetadataInventoryTableConfiguration\";\nconst _UBMITCR = \"UpdateBucketMetadataInventoryTableConfigurationRequest\";\nconst _UBMJTC = \"UpdateBucketMetadataJournalTableConfiguration\";\nconst _UBMJTCR = \"UpdateBucketMetadataJournalTableConfigurationRequest\";\nconst _UI = \"UploadId\";\nconst _UIM = \"UploadIdMarker\";\nconst _UM = \"UserMetadata\";\nconst _UOE = \"UpdateObjectEncryption\";\nconst _UOER = \"UpdateObjectEncryptionRequest\";\nconst _UOERp = \"UpdateObjectEncryptionResponse\";\nconst _UP = \"UploadPart\";\nconst _UPC = \"UploadPartCopy\";\nconst _UPCO = \"UploadPartCopyOutput\";\nconst _UPCR = \"UploadPartCopyRequest\";\nconst _UPO = \"UploadPartOutput\";\nconst _UPR = \"UploadPartRequest\";\nconst _URI = \"URI\";\nconst _Up = \"Upload\";\nconst _V = \"Value\";\nconst _VC = \"VersioningConfiguration\";\nconst _VI = \"VersionId\";\nconst _VIM = \"VersionIdMarker\";\nconst _Ve = \"Versions\";\nconst _Ver = \"Version\";\nconst _WC = \"WebsiteConfiguration\";\nconst _WGOR = \"WriteGetObjectResponse\";\nconst _WGORR = \"WriteGetObjectResponseRequest\";\nconst _WOB = \"WriteOffsetBytes\";\nconst _WRL = \"WebsiteRedirectLocation\";\nconst _Y = \"Years\";\nconst _ar = \"accept-ranges\";\nconst _br = \"bucket-region\";\nconst _c = \"client\";\nconst _ct = \"continuation-token\";\nconst _d = \"delimiter\";\nconst _e = \"error\";\nconst _eP = \"eventPayload\";\nconst _en = \"endpoint\";\nconst _et = \"encoding-type\";\nconst _fo = \"fetch-owner\";\nconst _h = \"http\";\nconst _hC = \"httpChecksum\";\nconst _hE = \"httpError\";\nconst _hH = \"httpHeader\";\nconst _hL = \"hostLabel\";\nconst _hP = \"httpPayload\";\nconst _hPH = \"httpPrefixHeaders\";\nconst _hQ = \"httpQuery\";\nconst _hi = \"http://www.w3.org/2001/XMLSchema-instance\";\nconst _i = \"id\";\nconst _iT = \"idempotencyToken\";\nconst _km = \"key-marker\";\nconst _m = \"marker\";\nconst _mb = \"max-buckets\";\nconst _mdb = \"max-directory-buckets\";\nconst _mk = \"max-keys\";\nconst _mp = \"max-parts\";\nconst _mu = \"max-uploads\";\nconst _p = \"prefix\";\nconst _pN = \"partNumber\";\nconst _pnm = \"part-number-marker\";\nconst _rcc = \"response-cache-control\";\nconst _rcd = \"response-content-disposition\";\nconst _rce = \"response-content-encoding\";\nconst _rcl = \"response-content-language\";\nconst _rct = \"response-content-type\";\nconst _re = \"response-expires\";\nconst _s = \"streaming\";\nconst _sa = \"start-after\";\nconst _sm = \"smithy.ts.sdk.synthetic.com.amazonaws.s3\";\nconst _uI = \"uploadId\";\nconst _uim = \"upload-id-marker\";\nconst _vI = \"versionId\";\nconst _vim = \"version-id-marker\";\nconst _x = \"xsi\";\nconst _xA = \"xmlAttribute\";\nconst _xF = \"xmlFlattened\";\nconst _xN = \"xmlName\";\nconst _xNm = \"xmlNamespace\";\nconst _xaa = \"x-amz-acl\";\nconst _xaad = \"x-amz-abort-date\";\nconst _xaapa = \"x-amz-access-point-alias\";\nconst _xaari = \"x-amz-abort-rule-id\";\nconst _xaas = \"x-amz-archive-status\";\nconst _xaba = \"x-amz-bucket-arn\";\nconst _xabgr = \"x-amz-bypass-governance-retention\";\nconst _xabln = \"x-amz-bucket-location-name\";\nconst _xablt = \"x-amz-bucket-location-type\";\nconst _xabole = \"x-amz-bucket-object-lock-enabled\";\nconst _xabolt = \"x-amz-bucket-object-lock-token\";\nconst _xabr = \"x-amz-bucket-region\";\nconst _xaca = \"x-amz-checksum-algorithm\";\nconst _xacc = \"x-amz-checksum-crc32\";\nconst _xacc_ = \"x-amz-checksum-crc32c\";\nconst _xacc__ = \"x-amz-checksum-crc64nvme\";\nconst _xacm = \"x-amz-checksum-mode\";\nconst _xacrsba = \"x-amz-confirm-remove-self-bucket-access\";\nconst _xacs = \"x-amz-checksum-sha1\";\nconst _xacs_ = \"x-amz-checksum-sha256\";\nconst _xacs__ = \"x-amz-copy-source\";\nconst _xacsim = \"x-amz-copy-source-if-match\";\nconst _xacsims = \"x-amz-copy-source-if-modified-since\";\nconst _xacsinm = \"x-amz-copy-source-if-none-match\";\nconst _xacsius = \"x-amz-copy-source-if-unmodified-since\";\nconst _xacsm = \"x-amz-create-session-mode\";\nconst _xacsr = \"x-amz-copy-source-range\";\nconst _xacssseca = \"x-amz-copy-source-server-side-encryption-customer-algorithm\";\nconst _xacssseck = \"x-amz-copy-source-server-side-encryption-customer-key\";\nconst _xacssseckM = \"x-amz-copy-source-server-side-encryption-customer-key-MD5\";\nconst _xacsvi = \"x-amz-copy-source-version-id\";\nconst _xact = \"x-amz-checksum-type\";\nconst _xact_ = \"x-amz-client-token\";\nconst _xadm = \"x-amz-delete-marker\";\nconst _xae = \"x-amz-expiration\";\nconst _xaebo = \"x-amz-expected-bucket-owner\";\nconst _xafec = \"x-amz-fwd-error-code\";\nconst _xafem = \"x-amz-fwd-error-message\";\nconst _xafhCC = \"x-amz-fwd-header-Cache-Control\";\nconst _xafhCD = \"x-amz-fwd-header-Content-Disposition\";\nconst _xafhCE = \"x-amz-fwd-header-Content-Encoding\";\nconst _xafhCL = \"x-amz-fwd-header-Content-Language\";\nconst _xafhCR = \"x-amz-fwd-header-Content-Range\";\nconst _xafhCT = \"x-amz-fwd-header-Content-Type\";\nconst _xafhE = \"x-amz-fwd-header-ETag\";\nconst _xafhE_ = \"x-amz-fwd-header-Expires\";\nconst _xafhLM = \"x-amz-fwd-header-Last-Modified\";\nconst _xafhar = \"x-amz-fwd-header-accept-ranges\";\nconst _xafhxacc = \"x-amz-fwd-header-x-amz-checksum-crc32\";\nconst _xafhxacc_ = \"x-amz-fwd-header-x-amz-checksum-crc32c\";\nconst _xafhxacc__ = \"x-amz-fwd-header-x-amz-checksum-crc64nvme\";\nconst _xafhxacs = \"x-amz-fwd-header-x-amz-checksum-sha1\";\nconst _xafhxacs_ = \"x-amz-fwd-header-x-amz-checksum-sha256\";\nconst _xafhxadm = \"x-amz-fwd-header-x-amz-delete-marker\";\nconst _xafhxae = \"x-amz-fwd-header-x-amz-expiration\";\nconst _xafhxamm = \"x-amz-fwd-header-x-amz-missing-meta\";\nconst _xafhxampc = \"x-amz-fwd-header-x-amz-mp-parts-count\";\nconst _xafhxaollh = \"x-amz-fwd-header-x-amz-object-lock-legal-hold\";\nconst _xafhxaolm = \"x-amz-fwd-header-x-amz-object-lock-mode\";\nconst _xafhxaolrud = \"x-amz-fwd-header-x-amz-object-lock-retain-until-date\";\nconst _xafhxar = \"x-amz-fwd-header-x-amz-restore\";\nconst _xafhxarc = \"x-amz-fwd-header-x-amz-request-charged\";\nconst _xafhxars = \"x-amz-fwd-header-x-amz-replication-status\";\nconst _xafhxasc = \"x-amz-fwd-header-x-amz-storage-class\";\nconst _xafhxasse = \"x-amz-fwd-header-x-amz-server-side-encryption\";\nconst _xafhxasseakki = \"x-amz-fwd-header-x-amz-server-side-encryption-aws-kms-key-id\";\nconst _xafhxassebke = \"x-amz-fwd-header-x-amz-server-side-encryption-bucket-key-enabled\";\nconst _xafhxasseca = \"x-amz-fwd-header-x-amz-server-side-encryption-customer-algorithm\";\nconst _xafhxasseckM = \"x-amz-fwd-header-x-amz-server-side-encryption-customer-key-MD5\";\nconst _xafhxatc = \"x-amz-fwd-header-x-amz-tagging-count\";\nconst _xafhxavi = \"x-amz-fwd-header-x-amz-version-id\";\nconst _xafs = \"x-amz-fwd-status\";\nconst _xagfc = \"x-amz-grant-full-control\";\nconst _xagr = \"x-amz-grant-read\";\nconst _xagra = \"x-amz-grant-read-acp\";\nconst _xagw = \"x-amz-grant-write\";\nconst _xagwa = \"x-amz-grant-write-acp\";\nconst _xaimit = \"x-amz-if-match-initiated-time\";\nconst _xaimlmt = \"x-amz-if-match-last-modified-time\";\nconst _xaims = \"x-amz-if-match-size\";\nconst _xam = \"x-amz-meta-\";\nconst _xam_ = \"x-amz-mfa\";\nconst _xamd = \"x-amz-metadata-directive\";\nconst _xamm = \"x-amz-missing-meta\";\nconst _xamos = \"x-amz-mp-object-size\";\nconst _xamp = \"x-amz-max-parts\";\nconst _xampc = \"x-amz-mp-parts-count\";\nconst _xaoa = \"x-amz-object-attributes\";\nconst _xaollh = \"x-amz-object-lock-legal-hold\";\nconst _xaolm = \"x-amz-object-lock-mode\";\nconst _xaolrud = \"x-amz-object-lock-retain-until-date\";\nconst _xaoo = \"x-amz-object-ownership\";\nconst _xaooa = \"x-amz-optional-object-attributes\";\nconst _xaos = \"x-amz-object-size\";\nconst _xapnm = \"x-amz-part-number-marker\";\nconst _xar = \"x-amz-restore\";\nconst _xarc = \"x-amz-request-charged\";\nconst _xarop = \"x-amz-restore-output-path\";\nconst _xarp = \"x-amz-request-payer\";\nconst _xarr = \"x-amz-request-route\";\nconst _xars = \"x-amz-replication-status\";\nconst _xars_ = \"x-amz-rename-source\";\nconst _xarsim = \"x-amz-rename-source-if-match\";\nconst _xarsims = \"x-amz-rename-source-if-modified-since\";\nconst _xarsinm = \"x-amz-rename-source-if-none-match\";\nconst _xarsius = \"x-amz-rename-source-if-unmodified-since\";\nconst _xart = \"x-amz-request-token\";\nconst _xasc = \"x-amz-storage-class\";\nconst _xasca = \"x-amz-sdk-checksum-algorithm\";\nconst _xasdv = \"x-amz-skip-destination-validation\";\nconst _xasebo = \"x-amz-source-expected-bucket-owner\";\nconst _xasse = \"x-amz-server-side-encryption\";\nconst _xasseakki = \"x-amz-server-side-encryption-aws-kms-key-id\";\nconst _xassebke = \"x-amz-server-side-encryption-bucket-key-enabled\";\nconst _xassec = \"x-amz-server-side-encryption-context\";\nconst _xasseca = \"x-amz-server-side-encryption-customer-algorithm\";\nconst _xasseck = \"x-amz-server-side-encryption-customer-key\";\nconst _xasseckM = \"x-amz-server-side-encryption-customer-key-MD5\";\nconst _xat = \"x-amz-tagging\";\nconst _xatc = \"x-amz-tagging-count\";\nconst _xatd = \"x-amz-tagging-directive\";\nconst _xatdmos = \"x-amz-transition-default-minimum-object-size\";\nconst _xavi = \"x-amz-version-id\";\nconst _xawob = \"x-amz-write-offset-bytes\";\nconst _xawrl = \"x-amz-website-redirect-location\";\nconst _xs = \"xsi:type\";\nconst n0 = \"com.amazonaws.s3\";\nvar CopySourceSSECustomerKey = [0, n0, _CSSSECK, 8, 0];\nvar NonEmptyKmsKeyArnString = [0, n0, _NEKKAS, 8, 0];\nvar SessionCredentialValue = [0, n0, _SCV, 8, 0];\nvar SSECustomerKey = [0, n0, _SSECK, 8, 0];\nvar SSEKMSEncryptionContext = [0, n0, _SSEKMSEC, 8, 0];\nvar SSEKMSKeyId = [0, n0, _SSEKMSKI, 8, 0];\nvar StreamingBlob = [0, n0, _SB, { [_s]: 1 }, 42];\nvar AbacStatus$ = [3, n0, _AS,\n    0,\n    [_S],\n    [0]\n];\nvar AbortIncompleteMultipartUpload$ = [3, n0, _AIMU,\n    0,\n    [_DAI],\n    [1]\n];\nvar AbortMultipartUploadOutput$ = [3, n0, _AMUO,\n    0,\n    [_RC],\n    [[0, { [_hH]: _xarc }]]\n];\nvar AbortMultipartUploadRequest$ = [3, n0, _AMUR,\n    0,\n    [_B, _K, _UI, _RP, _EBO, _IMIT],\n    [[0, 1], [0, 1], [0, { [_hQ]: _uI }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }], [6, { [_hH]: _xaimit }]], 3\n];\nvar AccelerateConfiguration$ = [3, n0, _AC,\n    0,\n    [_S],\n    [0]\n];\nvar AccessControlPolicy$ = [3, n0, _ACP,\n    0,\n    [_G, _O],\n    [[() => Grants, { [_xN]: _ACL }], () => Owner$]\n];\nvar AccessControlTranslation$ = [3, n0, _ACT,\n    0,\n    [_O],\n    [0], 1\n];\nvar AccessDenied$ = [-3, n0, _AD,\n    { [_e]: _c, [_hE]: 403 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(AccessDenied$, AccessDenied);\nvar AnalyticsAndOperator$ = [3, n0, _AAO,\n    0,\n    [_P, _T],\n    [0, [() => TagSet, { [_xF]: 1, [_xN]: _Ta }]]\n];\nvar AnalyticsConfiguration$ = [3, n0, _ACn,\n    0,\n    [_I, _SCA, _F],\n    [0, () => StorageClassAnalysis$, [() => AnalyticsFilter$, 0]], 2\n];\nvar AnalyticsExportDestination$ = [3, n0, _AED,\n    0,\n    [_SBD],\n    [() => AnalyticsS3BucketDestination$], 1\n];\nvar AnalyticsS3BucketDestination$ = [3, n0, _ASBD,\n    0,\n    [_Fo, _B, _BAI, _P],\n    [0, 0, 0, 0], 2\n];\nvar BlockedEncryptionTypes$ = [3, n0, _BET,\n    0,\n    [_ET],\n    [[() => EncryptionTypeList, { [_xF]: 1 }]]\n];\nvar Bucket$ = [3, n0, _B,\n    0,\n    [_N, _CD, _BR, _BA],\n    [0, 4, 0, 0]\n];\nvar BucketAlreadyExists$ = [-3, n0, _BAE,\n    { [_e]: _c, [_hE]: 409 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(BucketAlreadyExists$, BucketAlreadyExists);\nvar BucketAlreadyOwnedByYou$ = [-3, n0, _BAOBY,\n    { [_e]: _c, [_hE]: 409 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(BucketAlreadyOwnedByYou$, BucketAlreadyOwnedByYou);\nvar BucketInfo$ = [3, n0, _BI,\n    0,\n    [_DR, _Ty],\n    [0, 0]\n];\nvar BucketLifecycleConfiguration$ = [3, n0, _BLC,\n    0,\n    [_R],\n    [[() => LifecycleRules, { [_xF]: 1, [_xN]: _Ru }]], 1\n];\nvar BucketLoggingStatus$ = [3, n0, _BLS,\n    0,\n    [_LE],\n    [[() => LoggingEnabled$, 0]]\n];\nvar Checksum$ = [3, n0, _C,\n    0,\n    [_CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _CT],\n    [0, 0, 0, 0, 0, 0]\n];\nvar CommonPrefix$ = [3, n0, _CP,\n    0,\n    [_P],\n    [0]\n];\nvar CompletedMultipartUpload$ = [3, n0, _CMU,\n    0,\n    [_Pa],\n    [[() => CompletedPartList, { [_xF]: 1, [_xN]: _Par }]]\n];\nvar CompletedPart$ = [3, n0, _CPo,\n    0,\n    [_ETa, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _PN],\n    [0, 0, 0, 0, 0, 0, 1]\n];\nvar CompleteMultipartUploadOutput$ = [3, n0, _CMUO,\n    { [_xN]: _CMUR },\n    [_L, _B, _K, _E, _ETa, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _CT, _SSE, _VI, _SSEKMSKI, _BKE, _RC],\n    [0, 0, 0, [0, { [_hH]: _xae }], 0, 0, 0, 0, 0, 0, 0, [0, { [_hH]: _xasse }], [0, { [_hH]: _xavi }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xarc }]]\n];\nvar CompleteMultipartUploadRequest$ = [3, n0, _CMURo,\n    0,\n    [_B, _K, _UI, _MU, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _CT, _MOS, _RP, _EBO, _IM, _INM, _SSECA, _SSECK, _SSECKMD],\n    [[0, 1], [0, 1], [0, { [_hQ]: _uI }], [() => CompletedMultipartUpload$, { [_hP]: 1, [_xN]: _CMUo }], [0, { [_hH]: _xacc }], [0, { [_hH]: _xacc_ }], [0, { [_hH]: _xacc__ }], [0, { [_hH]: _xacs }], [0, { [_hH]: _xacs_ }], [0, { [_hH]: _xact }], [1, { [_hH]: _xamos }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _IM_ }], [0, { [_hH]: _INM_ }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }]], 3\n];\nvar Condition$ = [3, n0, _Co,\n    0,\n    [_HECRE, _KPE],\n    [0, 0]\n];\nvar ContinuationEvent$ = [3, n0, _CE,\n    0,\n    [],\n    []\n];\nvar CopyObjectOutput$ = [3, n0, _COO,\n    0,\n    [_COR, _E, _CSVI, _VI, _SSE, _SSECA, _SSECKMD, _SSEKMSKI, _SSEKMSEC, _BKE, _RC],\n    [[() => CopyObjectResult$, 16], [0, { [_hH]: _xae }], [0, { [_hH]: _xacsvi }], [0, { [_hH]: _xavi }], [0, { [_hH]: _xasse }], [0, { [_hH]: _xasseca }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [() => SSEKMSEncryptionContext, { [_hH]: _xassec }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xarc }]]\n];\nvar CopyObjectRequest$ = [3, n0, _CORo,\n    0,\n    [_B, _CS, _K, _ACL_, _CC, _CA, _CDo, _CEo, _CL, _CTo, _CSIM, _CSIMS, _CSINM, _CSIUS, _Ex, _GFC, _GR, _GRACP, _GWACP, _IM, _INM, _M, _MD, _TD, _SSE, _SC, _WRL, _SSECA, _SSECK, _SSECKMD, _SSEKMSKI, _SSEKMSEC, _BKE, _CSSSECA, _CSSSECK, _CSSSECKMD, _RP, _Tag, _OLM, _OLRUD, _OLLHS, _EBO, _ESBO],\n    [[0, 1], [0, { [_hH]: _xacs__ }], [0, 1], [0, { [_hH]: _xaa }], [0, { [_hH]: _CC_ }], [0, { [_hH]: _xaca }], [0, { [_hH]: _CD_ }], [0, { [_hH]: _CE_ }], [0, { [_hH]: _CL_ }], [0, { [_hH]: _CT_ }], [0, { [_hH]: _xacsim }], [4, { [_hH]: _xacsims }], [0, { [_hH]: _xacsinm }], [4, { [_hH]: _xacsius }], [4, { [_hH]: _Ex }], [0, { [_hH]: _xagfc }], [0, { [_hH]: _xagr }], [0, { [_hH]: _xagra }], [0, { [_hH]: _xagwa }], [0, { [_hH]: _IM_ }], [0, { [_hH]: _INM_ }], [128 | 0, { [_hPH]: _xam }], [0, { [_hH]: _xamd }], [0, { [_hH]: _xatd }], [0, { [_hH]: _xasse }], [0, { [_hH]: _xasc }], [0, { [_hH]: _xawrl }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [() => SSEKMSEncryptionContext, { [_hH]: _xassec }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xacssseca }], [() => CopySourceSSECustomerKey, { [_hH]: _xacssseck }], [0, { [_hH]: _xacssseckM }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xat }], [0, { [_hH]: _xaolm }], [5, { [_hH]: _xaolrud }], [0, { [_hH]: _xaollh }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xasebo }]], 3\n];\nvar CopyObjectResult$ = [3, n0, _COR,\n    0,\n    [_ETa, _LM, _CT, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh],\n    [0, 4, 0, 0, 0, 0, 0, 0]\n];\nvar CopyPartResult$ = [3, n0, _CPR,\n    0,\n    [_ETa, _LM, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh],\n    [0, 4, 0, 0, 0, 0, 0]\n];\nvar CORSConfiguration$ = [3, n0, _CORSC,\n    0,\n    [_CORSR],\n    [[() => CORSRules, { [_xF]: 1, [_xN]: _CORSRu }]], 1\n];\nvar CORSRule$ = [3, n0, _CORSRu,\n    0,\n    [_AM, _AO, _ID, _AH, _EH, _MAS],\n    [[64 | 0, { [_xF]: 1, [_xN]: _AMl }], [64 | 0, { [_xF]: 1, [_xN]: _AOl }], 0, [64 | 0, { [_xF]: 1, [_xN]: _AHl }], [64 | 0, { [_xF]: 1, [_xN]: _EHx }], 1], 2\n];\nvar CreateBucketConfiguration$ = [3, n0, _CBC,\n    0,\n    [_LC, _L, _B, _T],\n    [0, () => LocationInfo$, () => BucketInfo$, [() => TagSet, 0]]\n];\nvar CreateBucketMetadataConfigurationRequest$ = [3, n0, _CBMCR,\n    0,\n    [_B, _MC, _CMD, _CA, _EBO],\n    [[0, 1], [() => MetadataConfiguration$, { [_hP]: 1, [_xN]: _MC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar CreateBucketMetadataTableConfigurationRequest$ = [3, n0, _CBMTCR,\n    0,\n    [_B, _MTC, _CMD, _CA, _EBO],\n    [[0, 1], [() => MetadataTableConfiguration$, { [_hP]: 1, [_xN]: _MTC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar CreateBucketOutput$ = [3, n0, _CBO,\n    0,\n    [_L, _BA],\n    [[0, { [_hH]: _L }], [0, { [_hH]: _xaba }]]\n];\nvar CreateBucketRequest$ = [3, n0, _CBR,\n    0,\n    [_B, _ACL_, _CBC, _GFC, _GR, _GRACP, _GW, _GWACP, _OLEFB, _OO],\n    [[0, 1], [0, { [_hH]: _xaa }], [() => CreateBucketConfiguration$, { [_hP]: 1, [_xN]: _CBC }], [0, { [_hH]: _xagfc }], [0, { [_hH]: _xagr }], [0, { [_hH]: _xagra }], [0, { [_hH]: _xagw }], [0, { [_hH]: _xagwa }], [2, { [_hH]: _xabole }], [0, { [_hH]: _xaoo }]], 1\n];\nvar CreateMultipartUploadOutput$ = [3, n0, _CMUOr,\n    { [_xN]: _IMUR },\n    [_ADb, _ARI, _B, _K, _UI, _SSE, _SSECA, _SSECKMD, _SSEKMSKI, _SSEKMSEC, _BKE, _RC, _CA, _CT],\n    [[4, { [_hH]: _xaad }], [0, { [_hH]: _xaari }], [0, { [_xN]: _B }], 0, 0, [0, { [_hH]: _xasse }], [0, { [_hH]: _xasseca }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [() => SSEKMSEncryptionContext, { [_hH]: _xassec }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xarc }], [0, { [_hH]: _xaca }], [0, { [_hH]: _xact }]]\n];\nvar CreateMultipartUploadRequest$ = [3, n0, _CMURr,\n    0,\n    [_B, _K, _ACL_, _CC, _CDo, _CEo, _CL, _CTo, _Ex, _GFC, _GR, _GRACP, _GWACP, _M, _SSE, _SC, _WRL, _SSECA, _SSECK, _SSECKMD, _SSEKMSKI, _SSEKMSEC, _BKE, _RP, _Tag, _OLM, _OLRUD, _OLLHS, _EBO, _CA, _CT],\n    [[0, 1], [0, 1], [0, { [_hH]: _xaa }], [0, { [_hH]: _CC_ }], [0, { [_hH]: _CD_ }], [0, { [_hH]: _CE_ }], [0, { [_hH]: _CL_ }], [0, { [_hH]: _CT_ }], [4, { [_hH]: _Ex }], [0, { [_hH]: _xagfc }], [0, { [_hH]: _xagr }], [0, { [_hH]: _xagra }], [0, { [_hH]: _xagwa }], [128 | 0, { [_hPH]: _xam }], [0, { [_hH]: _xasse }], [0, { [_hH]: _xasc }], [0, { [_hH]: _xawrl }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [() => SSEKMSEncryptionContext, { [_hH]: _xassec }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xat }], [0, { [_hH]: _xaolm }], [5, { [_hH]: _xaolrud }], [0, { [_hH]: _xaollh }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xaca }], [0, { [_hH]: _xact }]], 2\n];\nvar CreateSessionOutput$ = [3, n0, _CSO,\n    { [_xN]: _CSR },\n    [_Cr, _SSE, _SSEKMSKI, _SSEKMSEC, _BKE],\n    [[() => SessionCredentials$, { [_xN]: _Cr }], [0, { [_hH]: _xasse }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [() => SSEKMSEncryptionContext, { [_hH]: _xassec }], [2, { [_hH]: _xassebke }]], 1\n];\nvar CreateSessionRequest$ = [3, n0, _CSRr,\n    0,\n    [_B, _SM, _SSE, _SSEKMSKI, _SSEKMSEC, _BKE],\n    [[0, 1], [0, { [_hH]: _xacsm }], [0, { [_hH]: _xasse }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [() => SSEKMSEncryptionContext, { [_hH]: _xassec }], [2, { [_hH]: _xassebke }]], 1\n];\nvar CSVInput$ = [3, n0, _CSVIn,\n    0,\n    [_FHI, _Com, _QEC, _RD, _FD, _QC, _AQRD],\n    [0, 0, 0, 0, 0, 0, 2]\n];\nvar CSVOutput$ = [3, n0, _CSVO,\n    0,\n    [_QF, _QEC, _RD, _FD, _QC],\n    [0, 0, 0, 0, 0]\n];\nvar DefaultRetention$ = [3, n0, _DRe,\n    0,\n    [_Mo, _D, _Y],\n    [0, 1, 1]\n];\nvar Delete$ = [3, n0, _De,\n    0,\n    [_Ob, _Q],\n    [[() => ObjectIdentifierList, { [_xF]: 1, [_xN]: _Obj }], 2], 1\n];\nvar DeleteBucketAnalyticsConfigurationRequest$ = [3, n0, _DBACR,\n    0,\n    [_B, _I, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [0, { [_hH]: _xaebo }]], 2\n];\nvar DeleteBucketCorsRequest$ = [3, n0, _DBCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketEncryptionRequest$ = [3, n0, _DBER,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketIntelligentTieringConfigurationRequest$ = [3, n0, _DBITCR,\n    0,\n    [_B, _I, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [0, { [_hH]: _xaebo }]], 2\n];\nvar DeleteBucketInventoryConfigurationRequest$ = [3, n0, _DBICR,\n    0,\n    [_B, _I, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [0, { [_hH]: _xaebo }]], 2\n];\nvar DeleteBucketLifecycleRequest$ = [3, n0, _DBLR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketMetadataConfigurationRequest$ = [3, n0, _DBMCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketMetadataTableConfigurationRequest$ = [3, n0, _DBMTCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketMetricsConfigurationRequest$ = [3, n0, _DBMCRe,\n    0,\n    [_B, _I, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [0, { [_hH]: _xaebo }]], 2\n];\nvar DeleteBucketOwnershipControlsRequest$ = [3, n0, _DBOCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketPolicyRequest$ = [3, n0, _DBPR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketReplicationRequest$ = [3, n0, _DBRR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketRequest$ = [3, n0, _DBR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketTaggingRequest$ = [3, n0, _DBTR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeleteBucketWebsiteRequest$ = [3, n0, _DBWR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar DeletedObject$ = [3, n0, _DO,\n    0,\n    [_K, _VI, _DM, _DMVI],\n    [0, 0, 2, 0]\n];\nvar DeleteMarkerEntry$ = [3, n0, _DME,\n    0,\n    [_O, _K, _VI, _IL, _LM],\n    [() => Owner$, 0, 0, 2, 4]\n];\nvar DeleteMarkerReplication$ = [3, n0, _DMR,\n    0,\n    [_S],\n    [0]\n];\nvar DeleteObjectOutput$ = [3, n0, _DOO,\n    0,\n    [_DM, _VI, _RC],\n    [[2, { [_hH]: _xadm }], [0, { [_hH]: _xavi }], [0, { [_hH]: _xarc }]]\n];\nvar DeleteObjectRequest$ = [3, n0, _DOR,\n    0,\n    [_B, _K, _MFA, _VI, _RP, _BGR, _EBO, _IM, _IMLMT, _IMS],\n    [[0, 1], [0, 1], [0, { [_hH]: _xam_ }], [0, { [_hQ]: _vI }], [0, { [_hH]: _xarp }], [2, { [_hH]: _xabgr }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _IM_ }], [6, { [_hH]: _xaimlmt }], [1, { [_hH]: _xaims }]], 2\n];\nvar DeleteObjectsOutput$ = [3, n0, _DOOe,\n    { [_xN]: _DRel },\n    [_Del, _RC, _Er],\n    [[() => DeletedObjects, { [_xF]: 1 }], [0, { [_hH]: _xarc }], [() => Errors, { [_xF]: 1, [_xN]: _Err }]]\n];\nvar DeleteObjectsRequest$ = [3, n0, _DORe,\n    0,\n    [_B, _De, _MFA, _RP, _BGR, _EBO, _CA],\n    [[0, 1], [() => Delete$, { [_hP]: 1, [_xN]: _De }], [0, { [_hH]: _xam_ }], [0, { [_hH]: _xarp }], [2, { [_hH]: _xabgr }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xasca }]], 2\n];\nvar DeleteObjectTaggingOutput$ = [3, n0, _DOTO,\n    0,\n    [_VI],\n    [[0, { [_hH]: _xavi }]]\n];\nvar DeleteObjectTaggingRequest$ = [3, n0, _DOTR,\n    0,\n    [_B, _K, _VI, _EBO],\n    [[0, 1], [0, 1], [0, { [_hQ]: _vI }], [0, { [_hH]: _xaebo }]], 2\n];\nvar DeletePublicAccessBlockRequest$ = [3, n0, _DPABR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar Destination$ = [3, n0, _Des,\n    0,\n    [_B, _A, _SC, _ACT, _EC, _RT, _Me],\n    [0, 0, 0, () => AccessControlTranslation$, () => EncryptionConfiguration$, () => ReplicationTime$, () => Metrics$], 1\n];\nvar DestinationResult$ = [3, n0, _DRes,\n    0,\n    [_TBT, _TBA, _TN],\n    [0, 0, 0]\n];\nvar Encryption$ = [3, n0, _En,\n    0,\n    [_ET, _KMSKI, _KMSC],\n    [0, [() => SSEKMSKeyId, 0], 0], 1\n];\nvar EncryptionConfiguration$ = [3, n0, _EC,\n    0,\n    [_RKKID],\n    [0]\n];\nvar EncryptionTypeMismatch$ = [-3, n0, _ETM,\n    { [_e]: _c, [_hE]: 400 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(EncryptionTypeMismatch$, EncryptionTypeMismatch);\nvar EndEvent$ = [3, n0, _EE,\n    0,\n    [],\n    []\n];\nvar _Error$ = [3, n0, _Err,\n    0,\n    [_K, _VI, _Cod, _Mes],\n    [0, 0, 0, 0]\n];\nvar ErrorDetails$ = [3, n0, _ED,\n    0,\n    [_ECr, _EM],\n    [0, 0]\n];\nvar ErrorDocument$ = [3, n0, _EDr,\n    0,\n    [_K],\n    [0], 1\n];\nvar EventBridgeConfiguration$ = [3, n0, _EBC,\n    0,\n    [],\n    []\n];\nvar ExistingObjectReplication$ = [3, n0, _EOR,\n    0,\n    [_S],\n    [0], 1\n];\nvar FilterRule$ = [3, n0, _FR,\n    0,\n    [_N, _V],\n    [0, 0]\n];\nvar GetBucketAbacOutput$ = [3, n0, _GBAO,\n    0,\n    [_AS],\n    [[() => AbacStatus$, 16]]\n];\nvar GetBucketAbacRequest$ = [3, n0, _GBAR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketAccelerateConfigurationOutput$ = [3, n0, _GBACO,\n    { [_xN]: _AC },\n    [_S, _RC],\n    [0, [0, { [_hH]: _xarc }]]\n];\nvar GetBucketAccelerateConfigurationRequest$ = [3, n0, _GBACR,\n    0,\n    [_B, _EBO, _RP],\n    [[0, 1], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xarp }]], 1\n];\nvar GetBucketAclOutput$ = [3, n0, _GBAOe,\n    { [_xN]: _ACP },\n    [_O, _G],\n    [() => Owner$, [() => Grants, { [_xN]: _ACL }]]\n];\nvar GetBucketAclRequest$ = [3, n0, _GBARe,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketAnalyticsConfigurationOutput$ = [3, n0, _GBACOe,\n    0,\n    [_ACn],\n    [[() => AnalyticsConfiguration$, 16]]\n];\nvar GetBucketAnalyticsConfigurationRequest$ = [3, n0, _GBACRe,\n    0,\n    [_B, _I, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [0, { [_hH]: _xaebo }]], 2\n];\nvar GetBucketCorsOutput$ = [3, n0, _GBCO,\n    { [_xN]: _CORSC },\n    [_CORSR],\n    [[() => CORSRules, { [_xF]: 1, [_xN]: _CORSRu }]]\n];\nvar GetBucketCorsRequest$ = [3, n0, _GBCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketEncryptionOutput$ = [3, n0, _GBEO,\n    0,\n    [_SSEC],\n    [[() => ServerSideEncryptionConfiguration$, 16]]\n];\nvar GetBucketEncryptionRequest$ = [3, n0, _GBER,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketIntelligentTieringConfigurationOutput$ = [3, n0, _GBITCO,\n    0,\n    [_ITC],\n    [[() => IntelligentTieringConfiguration$, 16]]\n];\nvar GetBucketIntelligentTieringConfigurationRequest$ = [3, n0, _GBITCR,\n    0,\n    [_B, _I, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [0, { [_hH]: _xaebo }]], 2\n];\nvar GetBucketInventoryConfigurationOutput$ = [3, n0, _GBICO,\n    0,\n    [_IC],\n    [[() => InventoryConfiguration$, 16]]\n];\nvar GetBucketInventoryConfigurationRequest$ = [3, n0, _GBICR,\n    0,\n    [_B, _I, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [0, { [_hH]: _xaebo }]], 2\n];\nvar GetBucketLifecycleConfigurationOutput$ = [3, n0, _GBLCO,\n    { [_xN]: _LCi },\n    [_R, _TDMOS],\n    [[() => LifecycleRules, { [_xF]: 1, [_xN]: _Ru }], [0, { [_hH]: _xatdmos }]]\n];\nvar GetBucketLifecycleConfigurationRequest$ = [3, n0, _GBLCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketLocationOutput$ = [3, n0, _GBLO,\n    { [_xN]: _LC },\n    [_LC],\n    [0]\n];\nvar GetBucketLocationRequest$ = [3, n0, _GBLR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketLoggingOutput$ = [3, n0, _GBLOe,\n    { [_xN]: _BLS },\n    [_LE],\n    [[() => LoggingEnabled$, 0]]\n];\nvar GetBucketLoggingRequest$ = [3, n0, _GBLRe,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketMetadataConfigurationOutput$ = [3, n0, _GBMCO,\n    0,\n    [_GBMCR],\n    [[() => GetBucketMetadataConfigurationResult$, 16]]\n];\nvar GetBucketMetadataConfigurationRequest$ = [3, n0, _GBMCRe,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketMetadataConfigurationResult$ = [3, n0, _GBMCR,\n    0,\n    [_MCR],\n    [() => MetadataConfigurationResult$], 1\n];\nvar GetBucketMetadataTableConfigurationOutput$ = [3, n0, _GBMTCO,\n    0,\n    [_GBMTCR],\n    [[() => GetBucketMetadataTableConfigurationResult$, 16]]\n];\nvar GetBucketMetadataTableConfigurationRequest$ = [3, n0, _GBMTCRe,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketMetadataTableConfigurationResult$ = [3, n0, _GBMTCR,\n    0,\n    [_MTCR, _S, _Err],\n    [() => MetadataTableConfigurationResult$, 0, () => ErrorDetails$], 2\n];\nvar GetBucketMetricsConfigurationOutput$ = [3, n0, _GBMCOe,\n    0,\n    [_MCe],\n    [[() => MetricsConfiguration$, 16]]\n];\nvar GetBucketMetricsConfigurationRequest$ = [3, n0, _GBMCRet,\n    0,\n    [_B, _I, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [0, { [_hH]: _xaebo }]], 2\n];\nvar GetBucketNotificationConfigurationRequest$ = [3, n0, _GBNCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketOwnershipControlsOutput$ = [3, n0, _GBOCO,\n    0,\n    [_OC],\n    [[() => OwnershipControls$, 16]]\n];\nvar GetBucketOwnershipControlsRequest$ = [3, n0, _GBOCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketPolicyOutput$ = [3, n0, _GBPO,\n    0,\n    [_Po],\n    [[0, 16]]\n];\nvar GetBucketPolicyRequest$ = [3, n0, _GBPR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketPolicyStatusOutput$ = [3, n0, _GBPSO,\n    0,\n    [_PS],\n    [[() => PolicyStatus$, 16]]\n];\nvar GetBucketPolicyStatusRequest$ = [3, n0, _GBPSR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketReplicationOutput$ = [3, n0, _GBRO,\n    0,\n    [_RCe],\n    [[() => ReplicationConfiguration$, 16]]\n];\nvar GetBucketReplicationRequest$ = [3, n0, _GBRR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketRequestPaymentOutput$ = [3, n0, _GBRPO,\n    { [_xN]: _RPC },\n    [_Pay],\n    [0]\n];\nvar GetBucketRequestPaymentRequest$ = [3, n0, _GBRPR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketTaggingOutput$ = [3, n0, _GBTO,\n    { [_xN]: _Tag },\n    [_TS],\n    [[() => TagSet, 0]], 1\n];\nvar GetBucketTaggingRequest$ = [3, n0, _GBTR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketVersioningOutput$ = [3, n0, _GBVO,\n    { [_xN]: _VC },\n    [_S, _MFAD],\n    [0, [0, { [_xN]: _MDf }]]\n];\nvar GetBucketVersioningRequest$ = [3, n0, _GBVR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetBucketWebsiteOutput$ = [3, n0, _GBWO,\n    { [_xN]: _WC },\n    [_RART, _IDn, _EDr, _RR],\n    [() => RedirectAllRequestsTo$, () => IndexDocument$, () => ErrorDocument$, [() => RoutingRules, 0]]\n];\nvar GetBucketWebsiteRequest$ = [3, n0, _GBWR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetObjectAclOutput$ = [3, n0, _GOAO,\n    { [_xN]: _ACP },\n    [_O, _G, _RC],\n    [() => Owner$, [() => Grants, { [_xN]: _ACL }], [0, { [_hH]: _xarc }]]\n];\nvar GetObjectAclRequest$ = [3, n0, _GOAR,\n    0,\n    [_B, _K, _VI, _RP, _EBO],\n    [[0, 1], [0, 1], [0, { [_hQ]: _vI }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }]], 2\n];\nvar GetObjectAttributesOutput$ = [3, n0, _GOAOe,\n    { [_xN]: _GOARe },\n    [_DM, _LM, _VI, _RC, _ETa, _C, _OP, _SC, _OS],\n    [[2, { [_hH]: _xadm }], [4, { [_hH]: _LM_ }], [0, { [_hH]: _xavi }], [0, { [_hH]: _xarc }], 0, () => Checksum$, [() => GetObjectAttributesParts$, 0], 0, 1]\n];\nvar GetObjectAttributesParts$ = [3, n0, _GOAP,\n    0,\n    [_TPC, _PNM, _NPNM, _MP, _IT, _Pa],\n    [[1, { [_xN]: _PC }], 0, 0, 1, 2, [() => PartsList, { [_xF]: 1, [_xN]: _Par }]]\n];\nvar GetObjectAttributesRequest$ = [3, n0, _GOARet,\n    0,\n    [_B, _K, _OA, _VI, _MP, _PNM, _SSECA, _SSECK, _SSECKMD, _RP, _EBO],\n    [[0, 1], [0, 1], [64 | 0, { [_hH]: _xaoa }], [0, { [_hQ]: _vI }], [1, { [_hH]: _xamp }], [0, { [_hH]: _xapnm }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }]], 3\n];\nvar GetObjectLegalHoldOutput$ = [3, n0, _GOLHO,\n    0,\n    [_LH],\n    [[() => ObjectLockLegalHold$, { [_hP]: 1, [_xN]: _LH }]]\n];\nvar GetObjectLegalHoldRequest$ = [3, n0, _GOLHR,\n    0,\n    [_B, _K, _VI, _RP, _EBO],\n    [[0, 1], [0, 1], [0, { [_hQ]: _vI }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }]], 2\n];\nvar GetObjectLockConfigurationOutput$ = [3, n0, _GOLCO,\n    0,\n    [_OLC],\n    [[() => ObjectLockConfiguration$, 16]]\n];\nvar GetObjectLockConfigurationRequest$ = [3, n0, _GOLCR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GetObjectOutput$ = [3, n0, _GOO,\n    0,\n    [_Bo, _DM, _AR, _E, _Re, _LM, _CLo, _ETa, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _CT, _MM, _VI, _CC, _CDo, _CEo, _CL, _CR, _CTo, _Ex, _ES, _WRL, _SSE, _M, _SSECA, _SSECKMD, _SSEKMSKI, _BKE, _SC, _RC, _RS, _PC, _TC, _OLM, _OLRUD, _OLLHS],\n    [[() => StreamingBlob, 16], [2, { [_hH]: _xadm }], [0, { [_hH]: _ar }], [0, { [_hH]: _xae }], [0, { [_hH]: _xar }], [4, { [_hH]: _LM_ }], [1, { [_hH]: _CL__ }], [0, { [_hH]: _ETa }], [0, { [_hH]: _xacc }], [0, { [_hH]: _xacc_ }], [0, { [_hH]: _xacc__ }], [0, { [_hH]: _xacs }], [0, { [_hH]: _xacs_ }], [0, { [_hH]: _xact }], [1, { [_hH]: _xamm }], [0, { [_hH]: _xavi }], [0, { [_hH]: _CC_ }], [0, { [_hH]: _CD_ }], [0, { [_hH]: _CE_ }], [0, { [_hH]: _CL_ }], [0, { [_hH]: _CR_ }], [0, { [_hH]: _CT_ }], [4, { [_hH]: _Ex }], [0, { [_hH]: _ES }], [0, { [_hH]: _xawrl }], [0, { [_hH]: _xasse }], [128 | 0, { [_hPH]: _xam }], [0, { [_hH]: _xasseca }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xasc }], [0, { [_hH]: _xarc }], [0, { [_hH]: _xars }], [1, { [_hH]: _xampc }], [1, { [_hH]: _xatc }], [0, { [_hH]: _xaolm }], [5, { [_hH]: _xaolrud }], [0, { [_hH]: _xaollh }]]\n];\nvar GetObjectRequest$ = [3, n0, _GOR,\n    0,\n    [_B, _K, _IM, _IMSf, _INM, _IUS, _Ra, _RCC, _RCD, _RCE, _RCL, _RCT, _RE, _VI, _SSECA, _SSECK, _SSECKMD, _RP, _PN, _EBO, _CMh],\n    [[0, 1], [0, 1], [0, { [_hH]: _IM_ }], [4, { [_hH]: _IMS_ }], [0, { [_hH]: _INM_ }], [4, { [_hH]: _IUS_ }], [0, { [_hH]: _Ra }], [0, { [_hQ]: _rcc }], [0, { [_hQ]: _rcd }], [0, { [_hQ]: _rce }], [0, { [_hQ]: _rcl }], [0, { [_hQ]: _rct }], [6, { [_hQ]: _re }], [0, { [_hQ]: _vI }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], [0, { [_hH]: _xarp }], [1, { [_hQ]: _pN }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xacm }]], 2\n];\nvar GetObjectRetentionOutput$ = [3, n0, _GORO,\n    0,\n    [_Ret],\n    [[() => ObjectLockRetention$, { [_hP]: 1, [_xN]: _Ret }]]\n];\nvar GetObjectRetentionRequest$ = [3, n0, _GORR,\n    0,\n    [_B, _K, _VI, _RP, _EBO],\n    [[0, 1], [0, 1], [0, { [_hQ]: _vI }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }]], 2\n];\nvar GetObjectTaggingOutput$ = [3, n0, _GOTO,\n    { [_xN]: _Tag },\n    [_TS, _VI],\n    [[() => TagSet, 0], [0, { [_hH]: _xavi }]], 1\n];\nvar GetObjectTaggingRequest$ = [3, n0, _GOTR,\n    0,\n    [_B, _K, _VI, _EBO, _RP],\n    [[0, 1], [0, 1], [0, { [_hQ]: _vI }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xarp }]], 2\n];\nvar GetObjectTorrentOutput$ = [3, n0, _GOTOe,\n    0,\n    [_Bo, _RC],\n    [[() => StreamingBlob, 16], [0, { [_hH]: _xarc }]]\n];\nvar GetObjectTorrentRequest$ = [3, n0, _GOTRe,\n    0,\n    [_B, _K, _RP, _EBO],\n    [[0, 1], [0, 1], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }]], 2\n];\nvar GetPublicAccessBlockOutput$ = [3, n0, _GPABO,\n    0,\n    [_PABC],\n    [[() => PublicAccessBlockConfiguration$, 16]]\n];\nvar GetPublicAccessBlockRequest$ = [3, n0, _GPABR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar GlacierJobParameters$ = [3, n0, _GJP,\n    0,\n    [_Ti],\n    [0], 1\n];\nvar Grant$ = [3, n0, _Gr,\n    0,\n    [_Gra, _Pe],\n    [[() => Grantee$, { [_xNm]: [_x, _hi] }], 0]\n];\nvar Grantee$ = [3, n0, _Gra,\n    0,\n    [_Ty, _DN, _EA, _ID, _URI],\n    [[0, { [_xA]: 1, [_xN]: _xs }], 0, 0, 0, 0], 1\n];\nvar HeadBucketOutput$ = [3, n0, _HBO,\n    0,\n    [_BA, _BLT, _BLN, _BR, _APA],\n    [[0, { [_hH]: _xaba }], [0, { [_hH]: _xablt }], [0, { [_hH]: _xabln }], [0, { [_hH]: _xabr }], [2, { [_hH]: _xaapa }]]\n];\nvar HeadBucketRequest$ = [3, n0, _HBR,\n    0,\n    [_B, _EBO],\n    [[0, 1], [0, { [_hH]: _xaebo }]], 1\n];\nvar HeadObjectOutput$ = [3, n0, _HOO,\n    0,\n    [_DM, _AR, _E, _Re, _ASr, _LM, _CLo, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _CT, _ETa, _MM, _VI, _CC, _CDo, _CEo, _CL, _CTo, _CR, _Ex, _ES, _WRL, _SSE, _M, _SSECA, _SSECKMD, _SSEKMSKI, _BKE, _SC, _RC, _RS, _PC, _TC, _OLM, _OLRUD, _OLLHS],\n    [[2, { [_hH]: _xadm }], [0, { [_hH]: _ar }], [0, { [_hH]: _xae }], [0, { [_hH]: _xar }], [0, { [_hH]: _xaas }], [4, { [_hH]: _LM_ }], [1, { [_hH]: _CL__ }], [0, { [_hH]: _xacc }], [0, { [_hH]: _xacc_ }], [0, { [_hH]: _xacc__ }], [0, { [_hH]: _xacs }], [0, { [_hH]: _xacs_ }], [0, { [_hH]: _xact }], [0, { [_hH]: _ETa }], [1, { [_hH]: _xamm }], [0, { [_hH]: _xavi }], [0, { [_hH]: _CC_ }], [0, { [_hH]: _CD_ }], [0, { [_hH]: _CE_ }], [0, { [_hH]: _CL_ }], [0, { [_hH]: _CT_ }], [0, { [_hH]: _CR_ }], [4, { [_hH]: _Ex }], [0, { [_hH]: _ES }], [0, { [_hH]: _xawrl }], [0, { [_hH]: _xasse }], [128 | 0, { [_hPH]: _xam }], [0, { [_hH]: _xasseca }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xasc }], [0, { [_hH]: _xarc }], [0, { [_hH]: _xars }], [1, { [_hH]: _xampc }], [1, { [_hH]: _xatc }], [0, { [_hH]: _xaolm }], [5, { [_hH]: _xaolrud }], [0, { [_hH]: _xaollh }]]\n];\nvar HeadObjectRequest$ = [3, n0, _HOR,\n    0,\n    [_B, _K, _IM, _IMSf, _INM, _IUS, _Ra, _RCC, _RCD, _RCE, _RCL, _RCT, _RE, _VI, _SSECA, _SSECK, _SSECKMD, _RP, _PN, _EBO, _CMh],\n    [[0, 1], [0, 1], [0, { [_hH]: _IM_ }], [4, { [_hH]: _IMS_ }], [0, { [_hH]: _INM_ }], [4, { [_hH]: _IUS_ }], [0, { [_hH]: _Ra }], [0, { [_hQ]: _rcc }], [0, { [_hQ]: _rcd }], [0, { [_hQ]: _rce }], [0, { [_hQ]: _rcl }], [0, { [_hQ]: _rct }], [6, { [_hQ]: _re }], [0, { [_hQ]: _vI }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], [0, { [_hH]: _xarp }], [1, { [_hQ]: _pN }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xacm }]], 2\n];\nvar IdempotencyParameterMismatch$ = [-3, n0, _IPM,\n    { [_e]: _c, [_hE]: 400 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(IdempotencyParameterMismatch$, IdempotencyParameterMismatch);\nvar IndexDocument$ = [3, n0, _IDn,\n    0,\n    [_Su],\n    [0], 1\n];\nvar Initiator$ = [3, n0, _In,\n    0,\n    [_ID, _DN],\n    [0, 0]\n];\nvar InputSerialization$ = [3, n0, _IS,\n    0,\n    [_CSV, _CTom, _JSON, _Parq],\n    [() => CSVInput$, 0, () => JSONInput$, () => ParquetInput$]\n];\nvar IntelligentTieringAndOperator$ = [3, n0, _ITAO,\n    0,\n    [_P, _T],\n    [0, [() => TagSet, { [_xF]: 1, [_xN]: _Ta }]]\n];\nvar IntelligentTieringConfiguration$ = [3, n0, _ITC,\n    0,\n    [_I, _S, _Tie, _F],\n    [0, 0, [() => TieringList, { [_xF]: 1, [_xN]: _Tier }], [() => IntelligentTieringFilter$, 0]], 3\n];\nvar IntelligentTieringFilter$ = [3, n0, _ITF,\n    0,\n    [_P, _Ta, _An],\n    [0, () => Tag$, [() => IntelligentTieringAndOperator$, 0]]\n];\nvar InvalidObjectState$ = [-3, n0, _IOS,\n    { [_e]: _c, [_hE]: 403 },\n    [_SC, _AT],\n    [0, 0]\n];\nschema.TypeRegistry.for(n0).registerError(InvalidObjectState$, InvalidObjectState);\nvar InvalidRequest$ = [-3, n0, _IR,\n    { [_e]: _c, [_hE]: 400 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(InvalidRequest$, InvalidRequest);\nvar InvalidWriteOffset$ = [-3, n0, _IWO,\n    { [_e]: _c, [_hE]: 400 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(InvalidWriteOffset$, InvalidWriteOffset);\nvar InventoryConfiguration$ = [3, n0, _IC,\n    0,\n    [_Des, _IE, _I, _IOV, _Sc, _F, _OF],\n    [[() => InventoryDestination$, 0], 2, 0, 0, () => InventorySchedule$, () => InventoryFilter$, [() => InventoryOptionalFields, 0]], 5\n];\nvar InventoryDestination$ = [3, n0, _IDnv,\n    0,\n    [_SBD],\n    [[() => InventoryS3BucketDestination$, 0]], 1\n];\nvar InventoryEncryption$ = [3, n0, _IEn,\n    0,\n    [_SSES, _SSEKMS],\n    [[() => SSES3$, { [_xN]: _SS }], [() => SSEKMS$, { [_xN]: _SK }]]\n];\nvar InventoryFilter$ = [3, n0, _IF,\n    0,\n    [_P],\n    [0], 1\n];\nvar InventoryS3BucketDestination$ = [3, n0, _ISBD,\n    0,\n    [_B, _Fo, _AI, _P, _En],\n    [0, 0, 0, 0, [() => InventoryEncryption$, 0]], 2\n];\nvar InventorySchedule$ = [3, n0, _ISn,\n    0,\n    [_Fr],\n    [0], 1\n];\nvar InventoryTableConfiguration$ = [3, n0, _ITCn,\n    0,\n    [_CSo, _EC],\n    [0, () => MetadataTableEncryptionConfiguration$], 1\n];\nvar InventoryTableConfigurationResult$ = [3, n0, _ITCR,\n    0,\n    [_CSo, _TSa, _Err, _TNa, _TA],\n    [0, 0, () => ErrorDetails$, 0, 0], 1\n];\nvar InventoryTableConfigurationUpdates$ = [3, n0, _ITCU,\n    0,\n    [_CSo, _EC],\n    [0, () => MetadataTableEncryptionConfiguration$], 1\n];\nvar JournalTableConfiguration$ = [3, n0, _JTC,\n    0,\n    [_REe, _EC],\n    [() => RecordExpiration$, () => MetadataTableEncryptionConfiguration$], 1\n];\nvar JournalTableConfigurationResult$ = [3, n0, _JTCR,\n    0,\n    [_TSa, _TNa, _REe, _Err, _TA],\n    [0, 0, () => RecordExpiration$, () => ErrorDetails$, 0], 3\n];\nvar JournalTableConfigurationUpdates$ = [3, n0, _JTCU,\n    0,\n    [_REe],\n    [() => RecordExpiration$], 1\n];\nvar JSONInput$ = [3, n0, _JSONI,\n    0,\n    [_Ty],\n    [0]\n];\nvar JSONOutput$ = [3, n0, _JSONO,\n    0,\n    [_RD],\n    [0]\n];\nvar LambdaFunctionConfiguration$ = [3, n0, _LFC,\n    0,\n    [_LFA, _Ev, _I, _F],\n    [[0, { [_xN]: _CF }], [64 | 0, { [_xF]: 1, [_xN]: _Eve }], 0, [() => NotificationConfigurationFilter$, 0]], 2\n];\nvar LifecycleExpiration$ = [3, n0, _LEi,\n    0,\n    [_Da, _D, _EODM],\n    [5, 1, 2]\n];\nvar LifecycleRule$ = [3, n0, _LR,\n    0,\n    [_S, _E, _ID, _P, _F, _Tr, _NVT, _NVE, _AIMU],\n    [0, () => LifecycleExpiration$, 0, 0, [() => LifecycleRuleFilter$, 0], [() => TransitionList, { [_xF]: 1, [_xN]: _Tra }], [() => NoncurrentVersionTransitionList, { [_xF]: 1, [_xN]: _NVTo }], () => NoncurrentVersionExpiration$, () => AbortIncompleteMultipartUpload$], 1\n];\nvar LifecycleRuleAndOperator$ = [3, n0, _LRAO,\n    0,\n    [_P, _T, _OSGT, _OSLT],\n    [0, [() => TagSet, { [_xF]: 1, [_xN]: _Ta }], 1, 1]\n];\nvar LifecycleRuleFilter$ = [3, n0, _LRF,\n    0,\n    [_P, _Ta, _OSGT, _OSLT, _An],\n    [0, () => Tag$, 1, 1, [() => LifecycleRuleAndOperator$, 0]]\n];\nvar ListBucketAnalyticsConfigurationsOutput$ = [3, n0, _LBACO,\n    { [_xN]: _LBACR },\n    [_IT, _CTon, _NCT, _ACLn],\n    [2, 0, 0, [() => AnalyticsConfigurationList, { [_xF]: 1, [_xN]: _ACn }]]\n];\nvar ListBucketAnalyticsConfigurationsRequest$ = [3, n0, _LBACRi,\n    0,\n    [_B, _CTon, _EBO],\n    [[0, 1], [0, { [_hQ]: _ct }], [0, { [_hH]: _xaebo }]], 1\n];\nvar ListBucketIntelligentTieringConfigurationsOutput$ = [3, n0, _LBITCO,\n    0,\n    [_IT, _CTon, _NCT, _ITCL],\n    [2, 0, 0, [() => IntelligentTieringConfigurationList, { [_xF]: 1, [_xN]: _ITC }]]\n];\nvar ListBucketIntelligentTieringConfigurationsRequest$ = [3, n0, _LBITCR,\n    0,\n    [_B, _CTon, _EBO],\n    [[0, 1], [0, { [_hQ]: _ct }], [0, { [_hH]: _xaebo }]], 1\n];\nvar ListBucketInventoryConfigurationsOutput$ = [3, n0, _LBICO,\n    { [_xN]: _LICR },\n    [_CTon, _ICL, _IT, _NCT],\n    [0, [() => InventoryConfigurationList, { [_xF]: 1, [_xN]: _IC }], 2, 0]\n];\nvar ListBucketInventoryConfigurationsRequest$ = [3, n0, _LBICR,\n    0,\n    [_B, _CTon, _EBO],\n    [[0, 1], [0, { [_hQ]: _ct }], [0, { [_hH]: _xaebo }]], 1\n];\nvar ListBucketMetricsConfigurationsOutput$ = [3, n0, _LBMCO,\n    { [_xN]: _LMCR },\n    [_IT, _CTon, _NCT, _MCL],\n    [2, 0, 0, [() => MetricsConfigurationList, { [_xF]: 1, [_xN]: _MCe }]]\n];\nvar ListBucketMetricsConfigurationsRequest$ = [3, n0, _LBMCR,\n    0,\n    [_B, _CTon, _EBO],\n    [[0, 1], [0, { [_hQ]: _ct }], [0, { [_hH]: _xaebo }]], 1\n];\nvar ListBucketsOutput$ = [3, n0, _LBO,\n    { [_xN]: _LAMBR },\n    [_Bu, _O, _CTon, _P],\n    [[() => Buckets, 0], () => Owner$, 0, 0]\n];\nvar ListBucketsRequest$ = [3, n0, _LBR,\n    0,\n    [_MB, _CTon, _P, _BR],\n    [[1, { [_hQ]: _mb }], [0, { [_hQ]: _ct }], [0, { [_hQ]: _p }], [0, { [_hQ]: _br }]]\n];\nvar ListDirectoryBucketsOutput$ = [3, n0, _LDBO,\n    { [_xN]: _LAMDBR },\n    [_Bu, _CTon],\n    [[() => Buckets, 0], 0]\n];\nvar ListDirectoryBucketsRequest$ = [3, n0, _LDBR,\n    0,\n    [_CTon, _MDB],\n    [[0, { [_hQ]: _ct }], [1, { [_hQ]: _mdb }]]\n];\nvar ListMultipartUploadsOutput$ = [3, n0, _LMUO,\n    { [_xN]: _LMUR },\n    [_B, _KM, _UIM, _NKM, _P, _Deli, _NUIM, _MUa, _IT, _U, _CPom, _ETn, _RC],\n    [0, 0, 0, 0, 0, 0, 0, 1, 2, [() => MultipartUploadList, { [_xF]: 1, [_xN]: _Up }], [() => CommonPrefixList, { [_xF]: 1 }], 0, [0, { [_hH]: _xarc }]]\n];\nvar ListMultipartUploadsRequest$ = [3, n0, _LMURi,\n    0,\n    [_B, _Deli, _ETn, _KM, _MUa, _P, _UIM, _EBO, _RP],\n    [[0, 1], [0, { [_hQ]: _d }], [0, { [_hQ]: _et }], [0, { [_hQ]: _km }], [1, { [_hQ]: _mu }], [0, { [_hQ]: _p }], [0, { [_hQ]: _uim }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xarp }]], 1\n];\nvar ListObjectsOutput$ = [3, n0, _LOO,\n    { [_xN]: _LBRi },\n    [_IT, _Ma, _NM, _Con, _N, _P, _Deli, _MK, _CPom, _ETn, _RC],\n    [2, 0, 0, [() => ObjectList, { [_xF]: 1 }], 0, 0, 0, 1, [() => CommonPrefixList, { [_xF]: 1 }], 0, [0, { [_hH]: _xarc }]]\n];\nvar ListObjectsRequest$ = [3, n0, _LOR,\n    0,\n    [_B, _Deli, _ETn, _Ma, _MK, _P, _RP, _EBO, _OOA],\n    [[0, 1], [0, { [_hQ]: _d }], [0, { [_hQ]: _et }], [0, { [_hQ]: _m }], [1, { [_hQ]: _mk }], [0, { [_hQ]: _p }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }], [64 | 0, { [_hH]: _xaooa }]], 1\n];\nvar ListObjectsV2Output$ = [3, n0, _LOVO,\n    { [_xN]: _LBRi },\n    [_IT, _Con, _N, _P, _Deli, _MK, _CPom, _ETn, _KC, _CTon, _NCT, _SA, _RC],\n    [2, [() => ObjectList, { [_xF]: 1 }], 0, 0, 0, 1, [() => CommonPrefixList, { [_xF]: 1 }], 0, 1, 0, 0, 0, [0, { [_hH]: _xarc }]]\n];\nvar ListObjectsV2Request$ = [3, n0, _LOVR,\n    0,\n    [_B, _Deli, _ETn, _MK, _P, _CTon, _FO, _SA, _RP, _EBO, _OOA],\n    [[0, 1], [0, { [_hQ]: _d }], [0, { [_hQ]: _et }], [1, { [_hQ]: _mk }], [0, { [_hQ]: _p }], [0, { [_hQ]: _ct }], [2, { [_hQ]: _fo }], [0, { [_hQ]: _sa }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }], [64 | 0, { [_hH]: _xaooa }]], 1\n];\nvar ListObjectVersionsOutput$ = [3, n0, _LOVOi,\n    { [_xN]: _LVR },\n    [_IT, _KM, _VIM, _NKM, _NVIM, _Ve, _DMe, _N, _P, _Deli, _MK, _CPom, _ETn, _RC],\n    [2, 0, 0, 0, 0, [() => ObjectVersionList, { [_xF]: 1, [_xN]: _Ver }], [() => DeleteMarkers, { [_xF]: 1, [_xN]: _DM }], 0, 0, 0, 1, [() => CommonPrefixList, { [_xF]: 1 }], 0, [0, { [_hH]: _xarc }]]\n];\nvar ListObjectVersionsRequest$ = [3, n0, _LOVRi,\n    0,\n    [_B, _Deli, _ETn, _KM, _MK, _P, _VIM, _EBO, _RP, _OOA],\n    [[0, 1], [0, { [_hQ]: _d }], [0, { [_hQ]: _et }], [0, { [_hQ]: _km }], [1, { [_hQ]: _mk }], [0, { [_hQ]: _p }], [0, { [_hQ]: _vim }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xarp }], [64 | 0, { [_hH]: _xaooa }]], 1\n];\nvar ListPartsOutput$ = [3, n0, _LPO,\n    { [_xN]: _LPR },\n    [_ADb, _ARI, _B, _K, _UI, _PNM, _NPNM, _MP, _IT, _Pa, _In, _O, _SC, _RC, _CA, _CT],\n    [[4, { [_hH]: _xaad }], [0, { [_hH]: _xaari }], 0, 0, 0, 0, 0, 1, 2, [() => Parts, { [_xF]: 1, [_xN]: _Par }], () => Initiator$, () => Owner$, 0, [0, { [_hH]: _xarc }], 0, 0]\n];\nvar ListPartsRequest$ = [3, n0, _LPRi,\n    0,\n    [_B, _K, _UI, _MP, _PNM, _RP, _EBO, _SSECA, _SSECK, _SSECKMD],\n    [[0, 1], [0, 1], [0, { [_hQ]: _uI }], [1, { [_hQ]: _mp }], [0, { [_hQ]: _pnm }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }]], 3\n];\nvar LocationInfo$ = [3, n0, _LI,\n    0,\n    [_Ty, _N],\n    [0, 0]\n];\nvar LoggingEnabled$ = [3, n0, _LE,\n    0,\n    [_TB, _TP, _TG, _TOKF],\n    [0, 0, [() => TargetGrants, 0], [() => TargetObjectKeyFormat$, 0]], 2\n];\nvar MetadataConfiguration$ = [3, n0, _MC,\n    0,\n    [_JTC, _ITCn],\n    [() => JournalTableConfiguration$, () => InventoryTableConfiguration$], 1\n];\nvar MetadataConfigurationResult$ = [3, n0, _MCR,\n    0,\n    [_DRes, _JTCR, _ITCR],\n    [() => DestinationResult$, () => JournalTableConfigurationResult$, () => InventoryTableConfigurationResult$], 1\n];\nvar MetadataEntry$ = [3, n0, _ME,\n    0,\n    [_N, _V],\n    [0, 0]\n];\nvar MetadataTableConfiguration$ = [3, n0, _MTC,\n    0,\n    [_STD],\n    [() => S3TablesDestination$], 1\n];\nvar MetadataTableConfigurationResult$ = [3, n0, _MTCR,\n    0,\n    [_STDR],\n    [() => S3TablesDestinationResult$], 1\n];\nvar MetadataTableEncryptionConfiguration$ = [3, n0, _MTEC,\n    0,\n    [_SAs, _KKA],\n    [0, 0], 1\n];\nvar Metrics$ = [3, n0, _Me,\n    0,\n    [_S, _ETv],\n    [0, () => ReplicationTimeValue$], 1\n];\nvar MetricsAndOperator$ = [3, n0, _MAO,\n    0,\n    [_P, _T, _APAc],\n    [0, [() => TagSet, { [_xF]: 1, [_xN]: _Ta }], 0]\n];\nvar MetricsConfiguration$ = [3, n0, _MCe,\n    0,\n    [_I, _F],\n    [0, [() => MetricsFilter$, 0]], 1\n];\nvar MultipartUpload$ = [3, n0, _MU,\n    0,\n    [_UI, _K, _Ini, _SC, _O, _In, _CA, _CT],\n    [0, 0, 4, 0, () => Owner$, () => Initiator$, 0, 0]\n];\nvar NoncurrentVersionExpiration$ = [3, n0, _NVE,\n    0,\n    [_ND, _NNV],\n    [1, 1]\n];\nvar NoncurrentVersionTransition$ = [3, n0, _NVTo,\n    0,\n    [_ND, _SC, _NNV],\n    [1, 0, 1]\n];\nvar NoSuchBucket$ = [-3, n0, _NSB,\n    { [_e]: _c, [_hE]: 404 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(NoSuchBucket$, NoSuchBucket);\nvar NoSuchKey$ = [-3, n0, _NSK,\n    { [_e]: _c, [_hE]: 404 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(NoSuchKey$, NoSuchKey);\nvar NoSuchUpload$ = [-3, n0, _NSU,\n    { [_e]: _c, [_hE]: 404 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(NoSuchUpload$, NoSuchUpload);\nvar NotFound$ = [-3, n0, _NF,\n    { [_e]: _c },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(NotFound$, NotFound);\nvar NotificationConfiguration$ = [3, n0, _NC,\n    0,\n    [_TCo, _QCu, _LFCa, _EBC],\n    [[() => TopicConfigurationList, { [_xF]: 1, [_xN]: _TCop }], [() => QueueConfigurationList, { [_xF]: 1, [_xN]: _QCue }], [() => LambdaFunctionConfigurationList, { [_xF]: 1, [_xN]: _CFC }], () => EventBridgeConfiguration$]\n];\nvar NotificationConfigurationFilter$ = [3, n0, _NCF,\n    0,\n    [_K],\n    [[() => S3KeyFilter$, { [_xN]: _SKe }]]\n];\nvar _Object$ = [3, n0, _Obj,\n    0,\n    [_K, _LM, _ETa, _CA, _CT, _Si, _SC, _O, _RSe],\n    [0, 4, 0, [64 | 0, { [_xF]: 1 }], 0, 1, 0, () => Owner$, () => RestoreStatus$]\n];\nvar ObjectAlreadyInActiveTierError$ = [-3, n0, _OAIATE,\n    { [_e]: _c, [_hE]: 403 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(ObjectAlreadyInActiveTierError$, ObjectAlreadyInActiveTierError);\nvar ObjectIdentifier$ = [3, n0, _OI,\n    0,\n    [_K, _VI, _ETa, _LMT, _Si],\n    [0, 0, 0, 6, 1], 1\n];\nvar ObjectLockConfiguration$ = [3, n0, _OLC,\n    0,\n    [_OLE, _Ru],\n    [0, () => ObjectLockRule$]\n];\nvar ObjectLockLegalHold$ = [3, n0, _OLLH,\n    0,\n    [_S],\n    [0]\n];\nvar ObjectLockRetention$ = [3, n0, _OLR,\n    0,\n    [_Mo, _RUD],\n    [0, 5]\n];\nvar ObjectLockRule$ = [3, n0, _OLRb,\n    0,\n    [_DRe],\n    [() => DefaultRetention$]\n];\nvar ObjectNotInActiveTierError$ = [-3, n0, _ONIATE,\n    { [_e]: _c, [_hE]: 403 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(ObjectNotInActiveTierError$, ObjectNotInActiveTierError);\nvar ObjectPart$ = [3, n0, _OPb,\n    0,\n    [_PN, _Si, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh],\n    [1, 1, 0, 0, 0, 0, 0]\n];\nvar ObjectVersion$ = [3, n0, _OV,\n    0,\n    [_ETa, _CA, _CT, _Si, _SC, _K, _VI, _IL, _LM, _O, _RSe],\n    [0, [64 | 0, { [_xF]: 1 }], 0, 1, 0, 0, 0, 2, 4, () => Owner$, () => RestoreStatus$]\n];\nvar OutputLocation$ = [3, n0, _OL,\n    0,\n    [_S_],\n    [[() => S3Location$, 0]]\n];\nvar OutputSerialization$ = [3, n0, _OSu,\n    0,\n    [_CSV, _JSON],\n    [() => CSVOutput$, () => JSONOutput$]\n];\nvar Owner$ = [3, n0, _O,\n    0,\n    [_DN, _ID],\n    [0, 0]\n];\nvar OwnershipControls$ = [3, n0, _OC,\n    0,\n    [_R],\n    [[() => OwnershipControlsRules, { [_xF]: 1, [_xN]: _Ru }]], 1\n];\nvar OwnershipControlsRule$ = [3, n0, _OCR,\n    0,\n    [_OO],\n    [0], 1\n];\nvar ParquetInput$ = [3, n0, _PI,\n    0,\n    [],\n    []\n];\nvar Part$ = [3, n0, _Par,\n    0,\n    [_PN, _LM, _ETa, _Si, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh],\n    [1, 4, 0, 1, 0, 0, 0, 0, 0]\n];\nvar PartitionedPrefix$ = [3, n0, _PP,\n    { [_xN]: _PP },\n    [_PDS],\n    [0]\n];\nvar PolicyStatus$ = [3, n0, _PS,\n    0,\n    [_IP],\n    [[2, { [_xN]: _IP }]]\n];\nvar Progress$ = [3, n0, _Pr,\n    0,\n    [_BS, _BP, _BRy],\n    [1, 1, 1]\n];\nvar ProgressEvent$ = [3, n0, _PE,\n    0,\n    [_Det],\n    [[() => Progress$, { [_eP]: 1 }]]\n];\nvar PublicAccessBlockConfiguration$ = [3, n0, _PABC,\n    0,\n    [_BPA, _IPA, _BPP, _RPB],\n    [[2, { [_xN]: _BPA }], [2, { [_xN]: _IPA }], [2, { [_xN]: _BPP }], [2, { [_xN]: _RPB }]]\n];\nvar PutBucketAbacRequest$ = [3, n0, _PBAR,\n    0,\n    [_B, _AS, _CMD, _CA, _EBO],\n    [[0, 1], [() => AbacStatus$, { [_hP]: 1, [_xN]: _AS }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketAccelerateConfigurationRequest$ = [3, n0, _PBACR,\n    0,\n    [_B, _AC, _EBO, _CA],\n    [[0, 1], [() => AccelerateConfiguration$, { [_hP]: 1, [_xN]: _AC }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xasca }]], 2\n];\nvar PutBucketAclRequest$ = [3, n0, _PBARu,\n    0,\n    [_B, _ACL_, _ACP, _CMD, _CA, _GFC, _GR, _GRACP, _GW, _GWACP, _EBO],\n    [[0, 1], [0, { [_hH]: _xaa }], [() => AccessControlPolicy$, { [_hP]: 1, [_xN]: _ACP }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xagfc }], [0, { [_hH]: _xagr }], [0, { [_hH]: _xagra }], [0, { [_hH]: _xagw }], [0, { [_hH]: _xagwa }], [0, { [_hH]: _xaebo }]], 1\n];\nvar PutBucketAnalyticsConfigurationRequest$ = [3, n0, _PBACRu,\n    0,\n    [_B, _I, _ACn, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [() => AnalyticsConfiguration$, { [_hP]: 1, [_xN]: _ACn }], [0, { [_hH]: _xaebo }]], 3\n];\nvar PutBucketCorsRequest$ = [3, n0, _PBCR,\n    0,\n    [_B, _CORSC, _CMD, _CA, _EBO],\n    [[0, 1], [() => CORSConfiguration$, { [_hP]: 1, [_xN]: _CORSC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketEncryptionRequest$ = [3, n0, _PBER,\n    0,\n    [_B, _SSEC, _CMD, _CA, _EBO],\n    [[0, 1], [() => ServerSideEncryptionConfiguration$, { [_hP]: 1, [_xN]: _SSEC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketIntelligentTieringConfigurationRequest$ = [3, n0, _PBITCR,\n    0,\n    [_B, _I, _ITC, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [() => IntelligentTieringConfiguration$, { [_hP]: 1, [_xN]: _ITC }], [0, { [_hH]: _xaebo }]], 3\n];\nvar PutBucketInventoryConfigurationRequest$ = [3, n0, _PBICR,\n    0,\n    [_B, _I, _IC, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [() => InventoryConfiguration$, { [_hP]: 1, [_xN]: _IC }], [0, { [_hH]: _xaebo }]], 3\n];\nvar PutBucketLifecycleConfigurationOutput$ = [3, n0, _PBLCO,\n    0,\n    [_TDMOS],\n    [[0, { [_hH]: _xatdmos }]]\n];\nvar PutBucketLifecycleConfigurationRequest$ = [3, n0, _PBLCR,\n    0,\n    [_B, _CA, _LCi, _EBO, _TDMOS],\n    [[0, 1], [0, { [_hH]: _xasca }], [() => BucketLifecycleConfiguration$, { [_hP]: 1, [_xN]: _LCi }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xatdmos }]], 1\n];\nvar PutBucketLoggingRequest$ = [3, n0, _PBLR,\n    0,\n    [_B, _BLS, _CMD, _CA, _EBO],\n    [[0, 1], [() => BucketLoggingStatus$, { [_hP]: 1, [_xN]: _BLS }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketMetricsConfigurationRequest$ = [3, n0, _PBMCR,\n    0,\n    [_B, _I, _MCe, _EBO],\n    [[0, 1], [0, { [_hQ]: _i }], [() => MetricsConfiguration$, { [_hP]: 1, [_xN]: _MCe }], [0, { [_hH]: _xaebo }]], 3\n];\nvar PutBucketNotificationConfigurationRequest$ = [3, n0, _PBNCR,\n    0,\n    [_B, _NC, _EBO, _SDV],\n    [[0, 1], [() => NotificationConfiguration$, { [_hP]: 1, [_xN]: _NC }], [0, { [_hH]: _xaebo }], [2, { [_hH]: _xasdv }]], 2\n];\nvar PutBucketOwnershipControlsRequest$ = [3, n0, _PBOCR,\n    0,\n    [_B, _OC, _CMD, _EBO, _CA],\n    [[0, 1], [() => OwnershipControls$, { [_hP]: 1, [_xN]: _OC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xasca }]], 2\n];\nvar PutBucketPolicyRequest$ = [3, n0, _PBPR,\n    0,\n    [_B, _Po, _CMD, _CA, _CRSBA, _EBO],\n    [[0, 1], [0, 16], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [2, { [_hH]: _xacrsba }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketReplicationRequest$ = [3, n0, _PBRR,\n    0,\n    [_B, _RCe, _CMD, _CA, _To, _EBO],\n    [[0, 1], [() => ReplicationConfiguration$, { [_hP]: 1, [_xN]: _RCe }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xabolt }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketRequestPaymentRequest$ = [3, n0, _PBRPR,\n    0,\n    [_B, _RPC, _CMD, _CA, _EBO],\n    [[0, 1], [() => RequestPaymentConfiguration$, { [_hP]: 1, [_xN]: _RPC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketTaggingRequest$ = [3, n0, _PBTR,\n    0,\n    [_B, _Tag, _CMD, _CA, _EBO],\n    [[0, 1], [() => Tagging$, { [_hP]: 1, [_xN]: _Tag }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketVersioningRequest$ = [3, n0, _PBVR,\n    0,\n    [_B, _VC, _CMD, _CA, _MFA, _EBO],\n    [[0, 1], [() => VersioningConfiguration$, { [_hP]: 1, [_xN]: _VC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xam_ }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutBucketWebsiteRequest$ = [3, n0, _PBWR,\n    0,\n    [_B, _WC, _CMD, _CA, _EBO],\n    [[0, 1], [() => WebsiteConfiguration$, { [_hP]: 1, [_xN]: _WC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutObjectAclOutput$ = [3, n0, _POAO,\n    0,\n    [_RC],\n    [[0, { [_hH]: _xarc }]]\n];\nvar PutObjectAclRequest$ = [3, n0, _POAR,\n    0,\n    [_B, _K, _ACL_, _ACP, _CMD, _CA, _GFC, _GR, _GRACP, _GW, _GWACP, _RP, _VI, _EBO],\n    [[0, 1], [0, 1], [0, { [_hH]: _xaa }], [() => AccessControlPolicy$, { [_hP]: 1, [_xN]: _ACP }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xagfc }], [0, { [_hH]: _xagr }], [0, { [_hH]: _xagra }], [0, { [_hH]: _xagw }], [0, { [_hH]: _xagwa }], [0, { [_hH]: _xarp }], [0, { [_hQ]: _vI }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutObjectLegalHoldOutput$ = [3, n0, _POLHO,\n    0,\n    [_RC],\n    [[0, { [_hH]: _xarc }]]\n];\nvar PutObjectLegalHoldRequest$ = [3, n0, _POLHR,\n    0,\n    [_B, _K, _LH, _RP, _VI, _CMD, _CA, _EBO],\n    [[0, 1], [0, 1], [() => ObjectLockLegalHold$, { [_hP]: 1, [_xN]: _LH }], [0, { [_hH]: _xarp }], [0, { [_hQ]: _vI }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutObjectLockConfigurationOutput$ = [3, n0, _POLCO,\n    0,\n    [_RC],\n    [[0, { [_hH]: _xarc }]]\n];\nvar PutObjectLockConfigurationRequest$ = [3, n0, _POLCR,\n    0,\n    [_B, _OLC, _RP, _To, _CMD, _CA, _EBO],\n    [[0, 1], [() => ObjectLockConfiguration$, { [_hP]: 1, [_xN]: _OLC }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xabolt }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 1\n];\nvar PutObjectOutput$ = [3, n0, _POO,\n    0,\n    [_E, _ETa, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _CT, _SSE, _VI, _SSECA, _SSECKMD, _SSEKMSKI, _SSEKMSEC, _BKE, _Si, _RC],\n    [[0, { [_hH]: _xae }], [0, { [_hH]: _ETa }], [0, { [_hH]: _xacc }], [0, { [_hH]: _xacc_ }], [0, { [_hH]: _xacc__ }], [0, { [_hH]: _xacs }], [0, { [_hH]: _xacs_ }], [0, { [_hH]: _xact }], [0, { [_hH]: _xasse }], [0, { [_hH]: _xavi }], [0, { [_hH]: _xasseca }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [() => SSEKMSEncryptionContext, { [_hH]: _xassec }], [2, { [_hH]: _xassebke }], [1, { [_hH]: _xaos }], [0, { [_hH]: _xarc }]]\n];\nvar PutObjectRequest$ = [3, n0, _POR,\n    0,\n    [_B, _K, _ACL_, _Bo, _CC, _CDo, _CEo, _CL, _CLo, _CMD, _CTo, _CA, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _Ex, _IM, _INM, _GFC, _GR, _GRACP, _GWACP, _WOB, _M, _SSE, _SC, _WRL, _SSECA, _SSECK, _SSECKMD, _SSEKMSKI, _SSEKMSEC, _BKE, _RP, _Tag, _OLM, _OLRUD, _OLLHS, _EBO],\n    [[0, 1], [0, 1], [0, { [_hH]: _xaa }], [() => StreamingBlob, 16], [0, { [_hH]: _CC_ }], [0, { [_hH]: _CD_ }], [0, { [_hH]: _CE_ }], [0, { [_hH]: _CL_ }], [1, { [_hH]: _CL__ }], [0, { [_hH]: _CM }], [0, { [_hH]: _CT_ }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xacc }], [0, { [_hH]: _xacc_ }], [0, { [_hH]: _xacc__ }], [0, { [_hH]: _xacs }], [0, { [_hH]: _xacs_ }], [4, { [_hH]: _Ex }], [0, { [_hH]: _IM_ }], [0, { [_hH]: _INM_ }], [0, { [_hH]: _xagfc }], [0, { [_hH]: _xagr }], [0, { [_hH]: _xagra }], [0, { [_hH]: _xagwa }], [1, { [_hH]: _xawob }], [128 | 0, { [_hPH]: _xam }], [0, { [_hH]: _xasse }], [0, { [_hH]: _xasc }], [0, { [_hH]: _xawrl }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [() => SSEKMSEncryptionContext, { [_hH]: _xassec }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xat }], [0, { [_hH]: _xaolm }], [5, { [_hH]: _xaolrud }], [0, { [_hH]: _xaollh }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutObjectRetentionOutput$ = [3, n0, _PORO,\n    0,\n    [_RC],\n    [[0, { [_hH]: _xarc }]]\n];\nvar PutObjectRetentionRequest$ = [3, n0, _PORR,\n    0,\n    [_B, _K, _Ret, _RP, _VI, _BGR, _CMD, _CA, _EBO],\n    [[0, 1], [0, 1], [() => ObjectLockRetention$, { [_hP]: 1, [_xN]: _Ret }], [0, { [_hH]: _xarp }], [0, { [_hQ]: _vI }], [2, { [_hH]: _xabgr }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar PutObjectTaggingOutput$ = [3, n0, _POTO,\n    0,\n    [_VI],\n    [[0, { [_hH]: _xavi }]]\n];\nvar PutObjectTaggingRequest$ = [3, n0, _POTR,\n    0,\n    [_B, _K, _Tag, _VI, _CMD, _CA, _EBO, _RP],\n    [[0, 1], [0, 1], [() => Tagging$, { [_hP]: 1, [_xN]: _Tag }], [0, { [_hQ]: _vI }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xarp }]], 3\n];\nvar PutPublicAccessBlockRequest$ = [3, n0, _PPABR,\n    0,\n    [_B, _PABC, _CMD, _CA, _EBO],\n    [[0, 1], [() => PublicAccessBlockConfiguration$, { [_hP]: 1, [_xN]: _PABC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar QueueConfiguration$ = [3, n0, _QCue,\n    0,\n    [_QA, _Ev, _I, _F],\n    [[0, { [_xN]: _Qu }], [64 | 0, { [_xF]: 1, [_xN]: _Eve }], 0, [() => NotificationConfigurationFilter$, 0]], 2\n];\nvar RecordExpiration$ = [3, n0, _REe,\n    0,\n    [_E, _D],\n    [0, 1], 1\n];\nvar RecordsEvent$ = [3, n0, _REec,\n    0,\n    [_Payl],\n    [[21, { [_eP]: 1 }]]\n];\nvar Redirect$ = [3, n0, _Red,\n    0,\n    [_HN, _HRC, _Pro, _RKPW, _RKW],\n    [0, 0, 0, 0, 0]\n];\nvar RedirectAllRequestsTo$ = [3, n0, _RART,\n    0,\n    [_HN, _Pro],\n    [0, 0], 1\n];\nvar RenameObjectOutput$ = [3, n0, _ROO,\n    0,\n    [],\n    []\n];\nvar RenameObjectRequest$ = [3, n0, _ROR,\n    0,\n    [_B, _K, _RSen, _DIM, _DINM, _DIMS, _DIUS, _SIM, _SINM, _SIMS, _SIUS, _CTl],\n    [[0, 1], [0, 1], [0, { [_hH]: _xars_ }], [0, { [_hH]: _IM_ }], [0, { [_hH]: _INM_ }], [4, { [_hH]: _IMS_ }], [4, { [_hH]: _IUS_ }], [0, { [_hH]: _xarsim }], [0, { [_hH]: _xarsinm }], [6, { [_hH]: _xarsims }], [6, { [_hH]: _xarsius }], [0, { [_hH]: _xact_, [_iT]: 1 }]], 3\n];\nvar ReplicaModifications$ = [3, n0, _RM,\n    0,\n    [_S],\n    [0], 1\n];\nvar ReplicationConfiguration$ = [3, n0, _RCe,\n    0,\n    [_Ro, _R],\n    [0, [() => ReplicationRules, { [_xF]: 1, [_xN]: _Ru }]], 2\n];\nvar ReplicationRule$ = [3, n0, _RRe,\n    0,\n    [_S, _Des, _ID, _Pri, _P, _F, _SSC, _EOR, _DMR],\n    [0, () => Destination$, 0, 1, 0, [() => ReplicationRuleFilter$, 0], () => SourceSelectionCriteria$, () => ExistingObjectReplication$, () => DeleteMarkerReplication$], 2\n];\nvar ReplicationRuleAndOperator$ = [3, n0, _RRAO,\n    0,\n    [_P, _T],\n    [0, [() => TagSet, { [_xF]: 1, [_xN]: _Ta }]]\n];\nvar ReplicationRuleFilter$ = [3, n0, _RRF,\n    0,\n    [_P, _Ta, _An],\n    [0, () => Tag$, [() => ReplicationRuleAndOperator$, 0]]\n];\nvar ReplicationTime$ = [3, n0, _RT,\n    0,\n    [_S, _Tim],\n    [0, () => ReplicationTimeValue$], 2\n];\nvar ReplicationTimeValue$ = [3, n0, _RTV,\n    0,\n    [_Mi],\n    [1]\n];\nvar RequestPaymentConfiguration$ = [3, n0, _RPC,\n    0,\n    [_Pay],\n    [0], 1\n];\nvar RequestProgress$ = [3, n0, _RPe,\n    0,\n    [_Ena],\n    [2]\n];\nvar RestoreObjectOutput$ = [3, n0, _ROOe,\n    0,\n    [_RC, _ROP],\n    [[0, { [_hH]: _xarc }], [0, { [_hH]: _xarop }]]\n];\nvar RestoreObjectRequest$ = [3, n0, _RORe,\n    0,\n    [_B, _K, _VI, _RRes, _RP, _CA, _EBO],\n    [[0, 1], [0, 1], [0, { [_hQ]: _vI }], [() => RestoreRequest$, { [_hP]: 1, [_xN]: _RRes }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar RestoreRequest$ = [3, n0, _RRes,\n    0,\n    [_D, _GJP, _Ty, _Ti, _Desc, _SP, _OL],\n    [1, () => GlacierJobParameters$, 0, 0, 0, () => SelectParameters$, [() => OutputLocation$, 0]]\n];\nvar RestoreStatus$ = [3, n0, _RSe,\n    0,\n    [_IRIP, _RED],\n    [2, 4]\n];\nvar RoutingRule$ = [3, n0, _RRo,\n    0,\n    [_Red, _Co],\n    [() => Redirect$, () => Condition$], 1\n];\nvar S3KeyFilter$ = [3, n0, _SKF,\n    0,\n    [_FRi],\n    [[() => FilterRuleList, { [_xF]: 1, [_xN]: _FR }]]\n];\nvar S3Location$ = [3, n0, _SL,\n    0,\n    [_BN, _P, _En, _CACL, _ACL, _Tag, _UM, _SC],\n    [0, 0, [() => Encryption$, 0], 0, [() => Grants, 0], [() => Tagging$, 0], [() => UserMetadata, 0], 0], 2\n];\nvar S3TablesDestination$ = [3, n0, _STD,\n    0,\n    [_TBA, _TNa],\n    [0, 0], 2\n];\nvar S3TablesDestinationResult$ = [3, n0, _STDR,\n    0,\n    [_TBA, _TNa, _TA, _TN],\n    [0, 0, 0, 0], 4\n];\nvar ScanRange$ = [3, n0, _SR,\n    0,\n    [_St, _End],\n    [1, 1]\n];\nvar SelectObjectContentOutput$ = [3, n0, _SOCO,\n    0,\n    [_Payl],\n    [[() => SelectObjectContentEventStream$, 16]]\n];\nvar SelectObjectContentRequest$ = [3, n0, _SOCR,\n    0,\n    [_B, _K, _Exp, _ETx, _IS, _OSu, _SSECA, _SSECK, _SSECKMD, _RPe, _SR, _EBO],\n    [[0, 1], [0, 1], 0, 0, () => InputSerialization$, () => OutputSerialization$, [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], () => RequestProgress$, () => ScanRange$, [0, { [_hH]: _xaebo }]], 6\n];\nvar SelectParameters$ = [3, n0, _SP,\n    0,\n    [_IS, _ETx, _Exp, _OSu],\n    [() => InputSerialization$, 0, 0, () => OutputSerialization$], 4\n];\nvar ServerSideEncryptionByDefault$ = [3, n0, _SSEBD,\n    0,\n    [_SSEA, _KMSMKID],\n    [0, [() => SSEKMSKeyId, 0]], 1\n];\nvar ServerSideEncryptionConfiguration$ = [3, n0, _SSEC,\n    0,\n    [_R],\n    [[() => ServerSideEncryptionRules, { [_xF]: 1, [_xN]: _Ru }]], 1\n];\nvar ServerSideEncryptionRule$ = [3, n0, _SSER,\n    0,\n    [_ASSEBD, _BKE, _BET],\n    [[() => ServerSideEncryptionByDefault$, 0], 2, [() => BlockedEncryptionTypes$, 0]]\n];\nvar SessionCredentials$ = [3, n0, _SCe,\n    0,\n    [_AKI, _SAK, _ST, _E],\n    [[0, { [_xN]: _AKI }], [() => SessionCredentialValue, { [_xN]: _SAK }], [() => SessionCredentialValue, { [_xN]: _ST }], [4, { [_xN]: _E }]], 4\n];\nvar SimplePrefix$ = [3, n0, _SPi,\n    { [_xN]: _SPi },\n    [],\n    []\n];\nvar SourceSelectionCriteria$ = [3, n0, _SSC,\n    0,\n    [_SKEO, _RM],\n    [() => SseKmsEncryptedObjects$, () => ReplicaModifications$]\n];\nvar SSEKMS$ = [3, n0, _SSEKMS,\n    { [_xN]: _SK },\n    [_KI],\n    [[() => SSEKMSKeyId, 0]], 1\n];\nvar SseKmsEncryptedObjects$ = [3, n0, _SKEO,\n    0,\n    [_S],\n    [0], 1\n];\nvar SSEKMSEncryption$ = [3, n0, _SSEKMSE,\n    { [_xN]: _SK },\n    [_KMSKA, _BKE],\n    [[() => NonEmptyKmsKeyArnString, 0], 2], 1\n];\nvar SSES3$ = [3, n0, _SSES,\n    { [_xN]: _SS },\n    [],\n    []\n];\nvar Stats$ = [3, n0, _Sta,\n    0,\n    [_BS, _BP, _BRy],\n    [1, 1, 1]\n];\nvar StatsEvent$ = [3, n0, _SE,\n    0,\n    [_Det],\n    [[() => Stats$, { [_eP]: 1 }]]\n];\nvar StorageClassAnalysis$ = [3, n0, _SCA,\n    0,\n    [_DE],\n    [() => StorageClassAnalysisDataExport$]\n];\nvar StorageClassAnalysisDataExport$ = [3, n0, _SCADE,\n    0,\n    [_OSV, _Des],\n    [0, () => AnalyticsExportDestination$], 2\n];\nvar Tag$ = [3, n0, _Ta,\n    0,\n    [_K, _V],\n    [0, 0], 2\n];\nvar Tagging$ = [3, n0, _Tag,\n    0,\n    [_TS],\n    [[() => TagSet, 0]], 1\n];\nvar TargetGrant$ = [3, n0, _TGa,\n    0,\n    [_Gra, _Pe],\n    [[() => Grantee$, { [_xNm]: [_x, _hi] }], 0]\n];\nvar TargetObjectKeyFormat$ = [3, n0, _TOKF,\n    0,\n    [_SPi, _PP],\n    [[() => SimplePrefix$, { [_xN]: _SPi }], [() => PartitionedPrefix$, { [_xN]: _PP }]]\n];\nvar Tiering$ = [3, n0, _Tier,\n    0,\n    [_D, _AT],\n    [1, 0], 2\n];\nvar TooManyParts$ = [-3, n0, _TMP,\n    { [_e]: _c, [_hE]: 400 },\n    [],\n    []\n];\nschema.TypeRegistry.for(n0).registerError(TooManyParts$, TooManyParts);\nvar TopicConfiguration$ = [3, n0, _TCop,\n    0,\n    [_TAo, _Ev, _I, _F],\n    [[0, { [_xN]: _Top }], [64 | 0, { [_xF]: 1, [_xN]: _Eve }], 0, [() => NotificationConfigurationFilter$, 0]], 2\n];\nvar Transition$ = [3, n0, _Tra,\n    0,\n    [_Da, _D, _SC],\n    [5, 1, 0]\n];\nvar UpdateBucketMetadataInventoryTableConfigurationRequest$ = [3, n0, _UBMITCR,\n    0,\n    [_B, _ITCn, _CMD, _CA, _EBO],\n    [[0, 1], [() => InventoryTableConfigurationUpdates$, { [_hP]: 1, [_xN]: _ITCn }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar UpdateBucketMetadataJournalTableConfigurationRequest$ = [3, n0, _UBMJTCR,\n    0,\n    [_B, _JTC, _CMD, _CA, _EBO],\n    [[0, 1], [() => JournalTableConfigurationUpdates$, { [_hP]: 1, [_xN]: _JTC }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xaebo }]], 2\n];\nvar UpdateObjectEncryptionRequest$ = [3, n0, _UOER,\n    0,\n    [_B, _K, _OE, _VI, _RP, _EBO, _CMD, _CA],\n    [[0, 1], [0, 1], [() => ObjectEncryption$, 16], [0, { [_hQ]: _vI }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }]], 3\n];\nvar UpdateObjectEncryptionResponse$ = [3, n0, _UOERp,\n    0,\n    [_RC],\n    [[0, { [_hH]: _xarc }]]\n];\nvar UploadPartCopyOutput$ = [3, n0, _UPCO,\n    0,\n    [_CSVI, _CPR, _SSE, _SSECA, _SSECKMD, _SSEKMSKI, _BKE, _RC],\n    [[0, { [_hH]: _xacsvi }], [() => CopyPartResult$, 16], [0, { [_hH]: _xasse }], [0, { [_hH]: _xasseca }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xarc }]]\n];\nvar UploadPartCopyRequest$ = [3, n0, _UPCR,\n    0,\n    [_B, _CS, _K, _PN, _UI, _CSIM, _CSIMS, _CSINM, _CSIUS, _CSRo, _SSECA, _SSECK, _SSECKMD, _CSSSECA, _CSSSECK, _CSSSECKMD, _RP, _EBO, _ESBO],\n    [[0, 1], [0, { [_hH]: _xacs__ }], [0, 1], [1, { [_hQ]: _pN }], [0, { [_hQ]: _uI }], [0, { [_hH]: _xacsim }], [4, { [_hH]: _xacsims }], [0, { [_hH]: _xacsinm }], [4, { [_hH]: _xacsius }], [0, { [_hH]: _xacsr }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], [0, { [_hH]: _xacssseca }], [() => CopySourceSSECustomerKey, { [_hH]: _xacssseck }], [0, { [_hH]: _xacssseckM }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }], [0, { [_hH]: _xasebo }]], 5\n];\nvar UploadPartOutput$ = [3, n0, _UPO,\n    0,\n    [_SSE, _ETa, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _SSECA, _SSECKMD, _SSEKMSKI, _BKE, _RC],\n    [[0, { [_hH]: _xasse }], [0, { [_hH]: _ETa }], [0, { [_hH]: _xacc }], [0, { [_hH]: _xacc_ }], [0, { [_hH]: _xacc__ }], [0, { [_hH]: _xacs }], [0, { [_hH]: _xacs_ }], [0, { [_hH]: _xasseca }], [0, { [_hH]: _xasseckM }], [() => SSEKMSKeyId, { [_hH]: _xasseakki }], [2, { [_hH]: _xassebke }], [0, { [_hH]: _xarc }]]\n];\nvar UploadPartRequest$ = [3, n0, _UPR,\n    0,\n    [_B, _K, _PN, _UI, _Bo, _CLo, _CMD, _CA, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _SSECA, _SSECK, _SSECKMD, _RP, _EBO],\n    [[0, 1], [0, 1], [1, { [_hQ]: _pN }], [0, { [_hQ]: _uI }], [() => StreamingBlob, 16], [1, { [_hH]: _CL__ }], [0, { [_hH]: _CM }], [0, { [_hH]: _xasca }], [0, { [_hH]: _xacc }], [0, { [_hH]: _xacc_ }], [0, { [_hH]: _xacc__ }], [0, { [_hH]: _xacs }], [0, { [_hH]: _xacs_ }], [0, { [_hH]: _xasseca }], [() => SSECustomerKey, { [_hH]: _xasseck }], [0, { [_hH]: _xasseckM }], [0, { [_hH]: _xarp }], [0, { [_hH]: _xaebo }]], 4\n];\nvar VersioningConfiguration$ = [3, n0, _VC,\n    0,\n    [_MFAD, _S],\n    [[0, { [_xN]: _MDf }], 0]\n];\nvar WebsiteConfiguration$ = [3, n0, _WC,\n    0,\n    [_EDr, _IDn, _RART, _RR],\n    [() => ErrorDocument$, () => IndexDocument$, () => RedirectAllRequestsTo$, [() => RoutingRules, 0]]\n];\nvar WriteGetObjectResponseRequest$ = [3, n0, _WGORR,\n    0,\n    [_RReq, _RTe, _Bo, _SCt, _ECr, _EM, _AR, _CC, _CDo, _CEo, _CL, _CLo, _CR, _CTo, _CCRC, _CCRCC, _CCRCNVME, _CSHA, _CSHAh, _DM, _ETa, _Ex, _E, _LM, _MM, _M, _OLM, _OLLHS, _OLRUD, _PC, _RS, _RC, _Re, _SSE, _SSECA, _SSEKMSKI, _SSECKMD, _SC, _TC, _VI, _BKE],\n    [[0, { [_hL]: 1, [_hH]: _xarr }], [0, { [_hH]: _xart }], [() => StreamingBlob, 16], [1, { [_hH]: _xafs }], [0, { [_hH]: _xafec }], [0, { [_hH]: _xafem }], [0, { [_hH]: _xafhar }], [0, { [_hH]: _xafhCC }], [0, { [_hH]: _xafhCD }], [0, { [_hH]: _xafhCE }], [0, { [_hH]: _xafhCL }], [1, { [_hH]: _CL__ }], [0, { [_hH]: _xafhCR }], [0, { [_hH]: _xafhCT }], [0, { [_hH]: _xafhxacc }], [0, { [_hH]: _xafhxacc_ }], [0, { [_hH]: _xafhxacc__ }], [0, { [_hH]: _xafhxacs }], [0, { [_hH]: _xafhxacs_ }], [2, { [_hH]: _xafhxadm }], [0, { [_hH]: _xafhE }], [4, { [_hH]: _xafhE_ }], [0, { [_hH]: _xafhxae }], [4, { [_hH]: _xafhLM }], [1, { [_hH]: _xafhxamm }], [128 | 0, { [_hPH]: _xam }], [0, { [_hH]: _xafhxaolm }], [0, { [_hH]: _xafhxaollh }], [5, { [_hH]: _xafhxaolrud }], [1, { [_hH]: _xafhxampc }], [0, { [_hH]: _xafhxars }], [0, { [_hH]: _xafhxarc }], [0, { [_hH]: _xafhxar }], [0, { [_hH]: _xafhxasse }], [0, { [_hH]: _xafhxasseca }], [() => SSEKMSKeyId, { [_hH]: _xafhxasseakki }], [0, { [_hH]: _xafhxasseckM }], [0, { [_hH]: _xafhxasc }], [1, { [_hH]: _xafhxatc }], [0, { [_hH]: _xafhxavi }], [2, { [_hH]: _xafhxassebke }]], 2\n];\nvar __Unit = \"unit\";\nvar S3ServiceException$ = [-3, _sm, \"S3ServiceException\", 0, [], []];\nschema.TypeRegistry.for(_sm).registerError(S3ServiceException$, S3ServiceException);\nvar AnalyticsConfigurationList = [1, n0, _ACLn,\n    0, [() => AnalyticsConfiguration$,\n        0]\n];\nvar Buckets = [1, n0, _Bu,\n    0, [() => Bucket$,\n        { [_xN]: _B }]\n];\nvar CommonPrefixList = [1, n0, _CPL,\n    0, () => CommonPrefix$\n];\nvar CompletedPartList = [1, n0, _CPLo,\n    0, () => CompletedPart$\n];\nvar CORSRules = [1, n0, _CORSR,\n    0, [() => CORSRule$,\n        0]\n];\nvar DeletedObjects = [1, n0, _DOe,\n    0, () => DeletedObject$\n];\nvar DeleteMarkers = [1, n0, _DMe,\n    0, () => DeleteMarkerEntry$\n];\nvar EncryptionTypeList = [1, n0, _ETL,\n    0, [0,\n        { [_xN]: _ET }]\n];\nvar Errors = [1, n0, _Er,\n    0, () => _Error$\n];\nvar FilterRuleList = [1, n0, _FRL,\n    0, () => FilterRule$\n];\nvar Grants = [1, n0, _G,\n    0, [() => Grant$,\n        { [_xN]: _Gr }]\n];\nvar IntelligentTieringConfigurationList = [1, n0, _ITCL,\n    0, [() => IntelligentTieringConfiguration$,\n        0]\n];\nvar InventoryConfigurationList = [1, n0, _ICL,\n    0, [() => InventoryConfiguration$,\n        0]\n];\nvar InventoryOptionalFields = [1, n0, _IOF,\n    0, [0,\n        { [_xN]: _Fi }]\n];\nvar LambdaFunctionConfigurationList = [1, n0, _LFCL,\n    0, [() => LambdaFunctionConfiguration$,\n        0]\n];\nvar LifecycleRules = [1, n0, _LRi,\n    0, [() => LifecycleRule$,\n        0]\n];\nvar MetricsConfigurationList = [1, n0, _MCL,\n    0, [() => MetricsConfiguration$,\n        0]\n];\nvar MultipartUploadList = [1, n0, _MUL,\n    0, () => MultipartUpload$\n];\nvar NoncurrentVersionTransitionList = [1, n0, _NVTL,\n    0, () => NoncurrentVersionTransition$\n];\nvar ObjectIdentifierList = [1, n0, _OIL,\n    0, () => ObjectIdentifier$\n];\nvar ObjectList = [1, n0, _OLb,\n    0, [() => _Object$,\n        0]\n];\nvar ObjectVersionList = [1, n0, _OVL,\n    0, [() => ObjectVersion$,\n        0]\n];\nvar OwnershipControlsRules = [1, n0, _OCRw,\n    0, () => OwnershipControlsRule$\n];\nvar Parts = [1, n0, _Pa,\n    0, () => Part$\n];\nvar PartsList = [1, n0, _PL,\n    0, () => ObjectPart$\n];\nvar QueueConfigurationList = [1, n0, _QCL,\n    0, [() => QueueConfiguration$,\n        0]\n];\nvar ReplicationRules = [1, n0, _RRep,\n    0, [() => ReplicationRule$,\n        0]\n];\nvar RoutingRules = [1, n0, _RR,\n    0, [() => RoutingRule$,\n        { [_xN]: _RRo }]\n];\nvar ServerSideEncryptionRules = [1, n0, _SSERe,\n    0, [() => ServerSideEncryptionRule$,\n        0]\n];\nvar TagSet = [1, n0, _TS,\n    0, [() => Tag$,\n        { [_xN]: _Ta }]\n];\nvar TargetGrants = [1, n0, _TG,\n    0, [() => TargetGrant$,\n        { [_xN]: _Gr }]\n];\nvar TieringList = [1, n0, _TL,\n    0, () => Tiering$\n];\nvar TopicConfigurationList = [1, n0, _TCL,\n    0, [() => TopicConfiguration$,\n        0]\n];\nvar TransitionList = [1, n0, _TLr,\n    0, () => Transition$\n];\nvar UserMetadata = [1, n0, _UM,\n    0, [() => MetadataEntry$,\n        { [_xN]: _ME }]\n];\nvar AnalyticsFilter$ = [4, n0, _AF,\n    0,\n    [_P, _Ta, _An],\n    [0, () => Tag$, [() => AnalyticsAndOperator$, 0]]\n];\nvar MetricsFilter$ = [4, n0, _MF,\n    0,\n    [_P, _Ta, _APAc, _An],\n    [0, () => Tag$, 0, [() => MetricsAndOperator$, 0]]\n];\nvar ObjectEncryption$ = [4, n0, _OE,\n    0,\n    [_SSEKMS],\n    [[() => SSEKMSEncryption$, { [_xN]: _SK }]]\n];\nvar SelectObjectContentEventStream$ = [4, n0, _SOCES,\n    { [_s]: 1 },\n    [_Rec, _Sta, _Pr, _Cont, _End],\n    [[() => RecordsEvent$, 0], [() => StatsEvent$, 0], [() => ProgressEvent$, 0], () => ContinuationEvent$, () => EndEvent$]\n];\nvar AbortMultipartUpload$ = [9, n0, _AMU,\n    { [_h]: [\"DELETE\", \"/{Key+}?x-id=AbortMultipartUpload\", 204] }, () => AbortMultipartUploadRequest$, () => AbortMultipartUploadOutput$\n];\nvar CompleteMultipartUpload$ = [9, n0, _CMUo,\n    { [_h]: [\"POST\", \"/{Key+}\", 200] }, () => CompleteMultipartUploadRequest$, () => CompleteMultipartUploadOutput$\n];\nvar CopyObject$ = [9, n0, _CO,\n    { [_h]: [\"PUT\", \"/{Key+}?x-id=CopyObject\", 200] }, () => CopyObjectRequest$, () => CopyObjectOutput$\n];\nvar CreateBucket$ = [9, n0, _CB,\n    { [_h]: [\"PUT\", \"/\", 200] }, () => CreateBucketRequest$, () => CreateBucketOutput$\n];\nvar CreateBucketMetadataConfiguration$ = [9, n0, _CBMC,\n    { [_hC]: \"-\", [_h]: [\"POST\", \"/?metadataConfiguration\", 200] }, () => CreateBucketMetadataConfigurationRequest$, () => __Unit\n];\nvar CreateBucketMetadataTableConfiguration$ = [9, n0, _CBMTC,\n    { [_hC]: \"-\", [_h]: [\"POST\", \"/?metadataTable\", 200] }, () => CreateBucketMetadataTableConfigurationRequest$, () => __Unit\n];\nvar CreateMultipartUpload$ = [9, n0, _CMUr,\n    { [_h]: [\"POST\", \"/{Key+}?uploads\", 200] }, () => CreateMultipartUploadRequest$, () => CreateMultipartUploadOutput$\n];\nvar CreateSession$ = [9, n0, _CSr,\n    { [_h]: [\"GET\", \"/?session\", 200] }, () => CreateSessionRequest$, () => CreateSessionOutput$\n];\nvar DeleteBucket$ = [9, n0, _DB,\n    { [_h]: [\"DELETE\", \"/\", 204] }, () => DeleteBucketRequest$, () => __Unit\n];\nvar DeleteBucketAnalyticsConfiguration$ = [9, n0, _DBAC,\n    { [_h]: [\"DELETE\", \"/?analytics\", 204] }, () => DeleteBucketAnalyticsConfigurationRequest$, () => __Unit\n];\nvar DeleteBucketCors$ = [9, n0, _DBC,\n    { [_h]: [\"DELETE\", \"/?cors\", 204] }, () => DeleteBucketCorsRequest$, () => __Unit\n];\nvar DeleteBucketEncryption$ = [9, n0, _DBE,\n    { [_h]: [\"DELETE\", \"/?encryption\", 204] }, () => DeleteBucketEncryptionRequest$, () => __Unit\n];\nvar DeleteBucketIntelligentTieringConfiguration$ = [9, n0, _DBITC,\n    { [_h]: [\"DELETE\", \"/?intelligent-tiering\", 204] }, () => DeleteBucketIntelligentTieringConfigurationRequest$, () => __Unit\n];\nvar DeleteBucketInventoryConfiguration$ = [9, n0, _DBIC,\n    { [_h]: [\"DELETE\", \"/?inventory\", 204] }, () => DeleteBucketInventoryConfigurationRequest$, () => __Unit\n];\nvar DeleteBucketLifecycle$ = [9, n0, _DBL,\n    { [_h]: [\"DELETE\", \"/?lifecycle\", 204] }, () => DeleteBucketLifecycleRequest$, () => __Unit\n];\nvar DeleteBucketMetadataConfiguration$ = [9, n0, _DBMC,\n    { [_h]: [\"DELETE\", \"/?metadataConfiguration\", 204] }, () => DeleteBucketMetadataConfigurationRequest$, () => __Unit\n];\nvar DeleteBucketMetadataTableConfiguration$ = [9, n0, _DBMTC,\n    { [_h]: [\"DELETE\", \"/?metadataTable\", 204] }, () => DeleteBucketMetadataTableConfigurationRequest$, () => __Unit\n];\nvar DeleteBucketMetricsConfiguration$ = [9, n0, _DBMCe,\n    { [_h]: [\"DELETE\", \"/?metrics\", 204] }, () => DeleteBucketMetricsConfigurationRequest$, () => __Unit\n];\nvar DeleteBucketOwnershipControls$ = [9, n0, _DBOC,\n    { [_h]: [\"DELETE\", \"/?ownershipControls\", 204] }, () => DeleteBucketOwnershipControlsRequest$, () => __Unit\n];\nvar DeleteBucketPolicy$ = [9, n0, _DBP,\n    { [_h]: [\"DELETE\", \"/?policy\", 204] }, () => DeleteBucketPolicyRequest$, () => __Unit\n];\nvar DeleteBucketReplication$ = [9, n0, _DBRe,\n    { [_h]: [\"DELETE\", \"/?replication\", 204] }, () => DeleteBucketReplicationRequest$, () => __Unit\n];\nvar DeleteBucketTagging$ = [9, n0, _DBT,\n    { [_h]: [\"DELETE\", \"/?tagging\", 204] }, () => DeleteBucketTaggingRequest$, () => __Unit\n];\nvar DeleteBucketWebsite$ = [9, n0, _DBW,\n    { [_h]: [\"DELETE\", \"/?website\", 204] }, () => DeleteBucketWebsiteRequest$, () => __Unit\n];\nvar DeleteObject$ = [9, n0, _DOel,\n    { [_h]: [\"DELETE\", \"/{Key+}?x-id=DeleteObject\", 204] }, () => DeleteObjectRequest$, () => DeleteObjectOutput$\n];\nvar DeleteObjects$ = [9, n0, _DOele,\n    { [_hC]: \"-\", [_h]: [\"POST\", \"/?delete\", 200] }, () => DeleteObjectsRequest$, () => DeleteObjectsOutput$\n];\nvar DeleteObjectTagging$ = [9, n0, _DOT,\n    { [_h]: [\"DELETE\", \"/{Key+}?tagging\", 204] }, () => DeleteObjectTaggingRequest$, () => DeleteObjectTaggingOutput$\n];\nvar DeletePublicAccessBlock$ = [9, n0, _DPAB,\n    { [_h]: [\"DELETE\", \"/?publicAccessBlock\", 204] }, () => DeletePublicAccessBlockRequest$, () => __Unit\n];\nvar GetBucketAbac$ = [9, n0, _GBA,\n    { [_h]: [\"GET\", \"/?abac\", 200] }, () => GetBucketAbacRequest$, () => GetBucketAbacOutput$\n];\nvar GetBucketAccelerateConfiguration$ = [9, n0, _GBAC,\n    { [_h]: [\"GET\", \"/?accelerate\", 200] }, () => GetBucketAccelerateConfigurationRequest$, () => GetBucketAccelerateConfigurationOutput$\n];\nvar GetBucketAcl$ = [9, n0, _GBAe,\n    { [_h]: [\"GET\", \"/?acl\", 200] }, () => GetBucketAclRequest$, () => GetBucketAclOutput$\n];\nvar GetBucketAnalyticsConfiguration$ = [9, n0, _GBACe,\n    { [_h]: [\"GET\", \"/?analytics&x-id=GetBucketAnalyticsConfiguration\", 200] }, () => GetBucketAnalyticsConfigurationRequest$, () => GetBucketAnalyticsConfigurationOutput$\n];\nvar GetBucketCors$ = [9, n0, _GBC,\n    { [_h]: [\"GET\", \"/?cors\", 200] }, () => GetBucketCorsRequest$, () => GetBucketCorsOutput$\n];\nvar GetBucketEncryption$ = [9, n0, _GBE,\n    { [_h]: [\"GET\", \"/?encryption\", 200] }, () => GetBucketEncryptionRequest$, () => GetBucketEncryptionOutput$\n];\nvar GetBucketIntelligentTieringConfiguration$ = [9, n0, _GBITC,\n    { [_h]: [\"GET\", \"/?intelligent-tiering&x-id=GetBucketIntelligentTieringConfiguration\", 200] }, () => GetBucketIntelligentTieringConfigurationRequest$, () => GetBucketIntelligentTieringConfigurationOutput$\n];\nvar GetBucketInventoryConfiguration$ = [9, n0, _GBIC,\n    { [_h]: [\"GET\", \"/?inventory&x-id=GetBucketInventoryConfiguration\", 200] }, () => GetBucketInventoryConfigurationRequest$, () => GetBucketInventoryConfigurationOutput$\n];\nvar GetBucketLifecycleConfiguration$ = [9, n0, _GBLC,\n    { [_h]: [\"GET\", \"/?lifecycle\", 200] }, () => GetBucketLifecycleConfigurationRequest$, () => GetBucketLifecycleConfigurationOutput$\n];\nvar GetBucketLocation$ = [9, n0, _GBL,\n    { [_h]: [\"GET\", \"/?location\", 200] }, () => GetBucketLocationRequest$, () => GetBucketLocationOutput$\n];\nvar GetBucketLogging$ = [9, n0, _GBLe,\n    { [_h]: [\"GET\", \"/?logging\", 200] }, () => GetBucketLoggingRequest$, () => GetBucketLoggingOutput$\n];\nvar GetBucketMetadataConfiguration$ = [9, n0, _GBMC,\n    { [_h]: [\"GET\", \"/?metadataConfiguration\", 200] }, () => GetBucketMetadataConfigurationRequest$, () => GetBucketMetadataConfigurationOutput$\n];\nvar GetBucketMetadataTableConfiguration$ = [9, n0, _GBMTC,\n    { [_h]: [\"GET\", \"/?metadataTable\", 200] }, () => GetBucketMetadataTableConfigurationRequest$, () => GetBucketMetadataTableConfigurationOutput$\n];\nvar GetBucketMetricsConfiguration$ = [9, n0, _GBMCe,\n    { [_h]: [\"GET\", \"/?metrics&x-id=GetBucketMetricsConfiguration\", 200] }, () => GetBucketMetricsConfigurationRequest$, () => GetBucketMetricsConfigurationOutput$\n];\nvar GetBucketNotificationConfiguration$ = [9, n0, _GBNC,\n    { [_h]: [\"GET\", \"/?notification\", 200] }, () => GetBucketNotificationConfigurationRequest$, () => NotificationConfiguration$\n];\nvar GetBucketOwnershipControls$ = [9, n0, _GBOC,\n    { [_h]: [\"GET\", \"/?ownershipControls\", 200] }, () => GetBucketOwnershipControlsRequest$, () => GetBucketOwnershipControlsOutput$\n];\nvar GetBucketPolicy$ = [9, n0, _GBP,\n    { [_h]: [\"GET\", \"/?policy\", 200] }, () => GetBucketPolicyRequest$, () => GetBucketPolicyOutput$\n];\nvar GetBucketPolicyStatus$ = [9, n0, _GBPS,\n    { [_h]: [\"GET\", \"/?policyStatus\", 200] }, () => GetBucketPolicyStatusRequest$, () => GetBucketPolicyStatusOutput$\n];\nvar GetBucketReplication$ = [9, n0, _GBR,\n    { [_h]: [\"GET\", \"/?replication\", 200] }, () => GetBucketReplicationRequest$, () => GetBucketReplicationOutput$\n];\nvar GetBucketRequestPayment$ = [9, n0, _GBRP,\n    { [_h]: [\"GET\", \"/?requestPayment\", 200] }, () => GetBucketRequestPaymentRequest$, () => GetBucketRequestPaymentOutput$\n];\nvar GetBucketTagging$ = [9, n0, _GBT,\n    { [_h]: [\"GET\", \"/?tagging\", 200] }, () => GetBucketTaggingRequest$, () => GetBucketTaggingOutput$\n];\nvar GetBucketVersioning$ = [9, n0, _GBV,\n    { [_h]: [\"GET\", \"/?versioning\", 200] }, () => GetBucketVersioningRequest$, () => GetBucketVersioningOutput$\n];\nvar GetBucketWebsite$ = [9, n0, _GBW,\n    { [_h]: [\"GET\", \"/?website\", 200] }, () => GetBucketWebsiteRequest$, () => GetBucketWebsiteOutput$\n];\nvar GetObject$ = [9, n0, _GO,\n    { [_hC]: \"-\", [_h]: [\"GET\", \"/{Key+}?x-id=GetObject\", 200] }, () => GetObjectRequest$, () => GetObjectOutput$\n];\nvar GetObjectAcl$ = [9, n0, _GOA,\n    { [_h]: [\"GET\", \"/{Key+}?acl\", 200] }, () => GetObjectAclRequest$, () => GetObjectAclOutput$\n];\nvar GetObjectAttributes$ = [9, n0, _GOAe,\n    { [_h]: [\"GET\", \"/{Key+}?attributes\", 200] }, () => GetObjectAttributesRequest$, () => GetObjectAttributesOutput$\n];\nvar GetObjectLegalHold$ = [9, n0, _GOLH,\n    { [_h]: [\"GET\", \"/{Key+}?legal-hold\", 200] }, () => GetObjectLegalHoldRequest$, () => GetObjectLegalHoldOutput$\n];\nvar GetObjectLockConfiguration$ = [9, n0, _GOLC,\n    { [_h]: [\"GET\", \"/?object-lock\", 200] }, () => GetObjectLockConfigurationRequest$, () => GetObjectLockConfigurationOutput$\n];\nvar GetObjectRetention$ = [9, n0, _GORe,\n    { [_h]: [\"GET\", \"/{Key+}?retention\", 200] }, () => GetObjectRetentionRequest$, () => GetObjectRetentionOutput$\n];\nvar GetObjectTagging$ = [9, n0, _GOT,\n    { [_h]: [\"GET\", \"/{Key+}?tagging\", 200] }, () => GetObjectTaggingRequest$, () => GetObjectTaggingOutput$\n];\nvar GetObjectTorrent$ = [9, n0, _GOTe,\n    { [_h]: [\"GET\", \"/{Key+}?torrent\", 200] }, () => GetObjectTorrentRequest$, () => GetObjectTorrentOutput$\n];\nvar GetPublicAccessBlock$ = [9, n0, _GPAB,\n    { [_h]: [\"GET\", \"/?publicAccessBlock\", 200] }, () => GetPublicAccessBlockRequest$, () => GetPublicAccessBlockOutput$\n];\nvar HeadBucket$ = [9, n0, _HB,\n    { [_h]: [\"HEAD\", \"/\", 200] }, () => HeadBucketRequest$, () => HeadBucketOutput$\n];\nvar HeadObject$ = [9, n0, _HO,\n    { [_h]: [\"HEAD\", \"/{Key+}\", 200] }, () => HeadObjectRequest$, () => HeadObjectOutput$\n];\nvar ListBucketAnalyticsConfigurations$ = [9, n0, _LBAC,\n    { [_h]: [\"GET\", \"/?analytics&x-id=ListBucketAnalyticsConfigurations\", 200] }, () => ListBucketAnalyticsConfigurationsRequest$, () => ListBucketAnalyticsConfigurationsOutput$\n];\nvar ListBucketIntelligentTieringConfigurations$ = [9, n0, _LBITC,\n    { [_h]: [\"GET\", \"/?intelligent-tiering&x-id=ListBucketIntelligentTieringConfigurations\", 200] }, () => ListBucketIntelligentTieringConfigurationsRequest$, () => ListBucketIntelligentTieringConfigurationsOutput$\n];\nvar ListBucketInventoryConfigurations$ = [9, n0, _LBIC,\n    { [_h]: [\"GET\", \"/?inventory&x-id=ListBucketInventoryConfigurations\", 200] }, () => ListBucketInventoryConfigurationsRequest$, () => ListBucketInventoryConfigurationsOutput$\n];\nvar ListBucketMetricsConfigurations$ = [9, n0, _LBMC,\n    { [_h]: [\"GET\", \"/?metrics&x-id=ListBucketMetricsConfigurations\", 200] }, () => ListBucketMetricsConfigurationsRequest$, () => ListBucketMetricsConfigurationsOutput$\n];\nvar ListBuckets$ = [9, n0, _LB,\n    { [_h]: [\"GET\", \"/?x-id=ListBuckets\", 200] }, () => ListBucketsRequest$, () => ListBucketsOutput$\n];\nvar ListDirectoryBuckets$ = [9, n0, _LDB,\n    { [_h]: [\"GET\", \"/?x-id=ListDirectoryBuckets\", 200] }, () => ListDirectoryBucketsRequest$, () => ListDirectoryBucketsOutput$\n];\nvar ListMultipartUploads$ = [9, n0, _LMU,\n    { [_h]: [\"GET\", \"/?uploads\", 200] }, () => ListMultipartUploadsRequest$, () => ListMultipartUploadsOutput$\n];\nvar ListObjects$ = [9, n0, _LO,\n    { [_h]: [\"GET\", \"/\", 200] }, () => ListObjectsRequest$, () => ListObjectsOutput$\n];\nvar ListObjectsV2$ = [9, n0, _LOV,\n    { [_h]: [\"GET\", \"/?list-type=2\", 200] }, () => ListObjectsV2Request$, () => ListObjectsV2Output$\n];\nvar ListObjectVersions$ = [9, n0, _LOVi,\n    { [_h]: [\"GET\", \"/?versions\", 200] }, () => ListObjectVersionsRequest$, () => ListObjectVersionsOutput$\n];\nvar ListParts$ = [9, n0, _LP,\n    { [_h]: [\"GET\", \"/{Key+}?x-id=ListParts\", 200] }, () => ListPartsRequest$, () => ListPartsOutput$\n];\nvar PutBucketAbac$ = [9, n0, _PBA,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?abac\", 200] }, () => PutBucketAbacRequest$, () => __Unit\n];\nvar PutBucketAccelerateConfiguration$ = [9, n0, _PBAC,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?accelerate\", 200] }, () => PutBucketAccelerateConfigurationRequest$, () => __Unit\n];\nvar PutBucketAcl$ = [9, n0, _PBAu,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?acl\", 200] }, () => PutBucketAclRequest$, () => __Unit\n];\nvar PutBucketAnalyticsConfiguration$ = [9, n0, _PBACu,\n    { [_h]: [\"PUT\", \"/?analytics\", 200] }, () => PutBucketAnalyticsConfigurationRequest$, () => __Unit\n];\nvar PutBucketCors$ = [9, n0, _PBC,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?cors\", 200] }, () => PutBucketCorsRequest$, () => __Unit\n];\nvar PutBucketEncryption$ = [9, n0, _PBE,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?encryption\", 200] }, () => PutBucketEncryptionRequest$, () => __Unit\n];\nvar PutBucketIntelligentTieringConfiguration$ = [9, n0, _PBITC,\n    { [_h]: [\"PUT\", \"/?intelligent-tiering\", 200] }, () => PutBucketIntelligentTieringConfigurationRequest$, () => __Unit\n];\nvar PutBucketInventoryConfiguration$ = [9, n0, _PBIC,\n    { [_h]: [\"PUT\", \"/?inventory\", 200] }, () => PutBucketInventoryConfigurationRequest$, () => __Unit\n];\nvar PutBucketLifecycleConfiguration$ = [9, n0, _PBLC,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?lifecycle\", 200] }, () => PutBucketLifecycleConfigurationRequest$, () => PutBucketLifecycleConfigurationOutput$\n];\nvar PutBucketLogging$ = [9, n0, _PBL,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?logging\", 200] }, () => PutBucketLoggingRequest$, () => __Unit\n];\nvar PutBucketMetricsConfiguration$ = [9, n0, _PBMC,\n    { [_h]: [\"PUT\", \"/?metrics\", 200] }, () => PutBucketMetricsConfigurationRequest$, () => __Unit\n];\nvar PutBucketNotificationConfiguration$ = [9, n0, _PBNC,\n    { [_h]: [\"PUT\", \"/?notification\", 200] }, () => PutBucketNotificationConfigurationRequest$, () => __Unit\n];\nvar PutBucketOwnershipControls$ = [9, n0, _PBOC,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?ownershipControls\", 200] }, () => PutBucketOwnershipControlsRequest$, () => __Unit\n];\nvar PutBucketPolicy$ = [9, n0, _PBP,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?policy\", 200] }, () => PutBucketPolicyRequest$, () => __Unit\n];\nvar PutBucketReplication$ = [9, n0, _PBR,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?replication\", 200] }, () => PutBucketReplicationRequest$, () => __Unit\n];\nvar PutBucketRequestPayment$ = [9, n0, _PBRP,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?requestPayment\", 200] }, () => PutBucketRequestPaymentRequest$, () => __Unit\n];\nvar PutBucketTagging$ = [9, n0, _PBT,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?tagging\", 200] }, () => PutBucketTaggingRequest$, () => __Unit\n];\nvar PutBucketVersioning$ = [9, n0, _PBV,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?versioning\", 200] }, () => PutBucketVersioningRequest$, () => __Unit\n];\nvar PutBucketWebsite$ = [9, n0, _PBW,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?website\", 200] }, () => PutBucketWebsiteRequest$, () => __Unit\n];\nvar PutObject$ = [9, n0, _PO,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/{Key+}?x-id=PutObject\", 200] }, () => PutObjectRequest$, () => PutObjectOutput$\n];\nvar PutObjectAcl$ = [9, n0, _POA,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/{Key+}?acl\", 200] }, () => PutObjectAclRequest$, () => PutObjectAclOutput$\n];\nvar PutObjectLegalHold$ = [9, n0, _POLH,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/{Key+}?legal-hold\", 200] }, () => PutObjectLegalHoldRequest$, () => PutObjectLegalHoldOutput$\n];\nvar PutObjectLockConfiguration$ = [9, n0, _POLC,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?object-lock\", 200] }, () => PutObjectLockConfigurationRequest$, () => PutObjectLockConfigurationOutput$\n];\nvar PutObjectRetention$ = [9, n0, _PORu,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/{Key+}?retention\", 200] }, () => PutObjectRetentionRequest$, () => PutObjectRetentionOutput$\n];\nvar PutObjectTagging$ = [9, n0, _POT,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/{Key+}?tagging\", 200] }, () => PutObjectTaggingRequest$, () => PutObjectTaggingOutput$\n];\nvar PutPublicAccessBlock$ = [9, n0, _PPAB,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?publicAccessBlock\", 200] }, () => PutPublicAccessBlockRequest$, () => __Unit\n];\nvar RenameObject$ = [9, n0, _RO,\n    { [_h]: [\"PUT\", \"/{Key+}?renameObject\", 200] }, () => RenameObjectRequest$, () => RenameObjectOutput$\n];\nvar RestoreObject$ = [9, n0, _ROe,\n    { [_hC]: \"-\", [_h]: [\"POST\", \"/{Key+}?restore\", 200] }, () => RestoreObjectRequest$, () => RestoreObjectOutput$\n];\nvar SelectObjectContent$ = [9, n0, _SOC,\n    { [_h]: [\"POST\", \"/{Key+}?select&select-type=2\", 200] }, () => SelectObjectContentRequest$, () => SelectObjectContentOutput$\n];\nvar UpdateBucketMetadataInventoryTableConfiguration$ = [9, n0, _UBMITC,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?metadataInventoryTable\", 200] }, () => UpdateBucketMetadataInventoryTableConfigurationRequest$, () => __Unit\n];\nvar UpdateBucketMetadataJournalTableConfiguration$ = [9, n0, _UBMJTC,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/?metadataJournalTable\", 200] }, () => UpdateBucketMetadataJournalTableConfigurationRequest$, () => __Unit\n];\nvar UpdateObjectEncryption$ = [9, n0, _UOE,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/{Key+}?encryption\", 200] }, () => UpdateObjectEncryptionRequest$, () => UpdateObjectEncryptionResponse$\n];\nvar UploadPart$ = [9, n0, _UP,\n    { [_hC]: \"-\", [_h]: [\"PUT\", \"/{Key+}?x-id=UploadPart\", 200] }, () => UploadPartRequest$, () => UploadPartOutput$\n];\nvar UploadPartCopy$ = [9, n0, _UPC,\n    { [_h]: [\"PUT\", \"/{Key+}?x-id=UploadPartCopy\", 200] }, () => UploadPartCopyRequest$, () => UploadPartCopyOutput$\n];\nvar WriteGetObjectResponse$ = [9, n0, _WGOR,\n    { [_en]: [\"{RequestRoute}.\"], [_h]: [\"POST\", \"/WriteGetObjectResponse\", 200] }, () => WriteGetObjectResponseRequest$, () => __Unit\n];\n\nclass CreateSessionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    DisableS3ExpressSessionAuth: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"CreateSession\", {})\n    .n(\"S3Client\", \"CreateSessionCommand\")\n    .sc(CreateSession$)\n    .build() {\n}\n\nconst getHttpAuthExtensionConfiguration = (runtimeConfig) => {\n    const _httpAuthSchemes = runtimeConfig.httpAuthSchemes;\n    let _httpAuthSchemeProvider = runtimeConfig.httpAuthSchemeProvider;\n    let _credentials = runtimeConfig.credentials;\n    return {\n        setHttpAuthScheme(httpAuthScheme) {\n            const index = _httpAuthSchemes.findIndex((scheme) => scheme.schemeId === httpAuthScheme.schemeId);\n            if (index === -1) {\n                _httpAuthSchemes.push(httpAuthScheme);\n            }\n            else {\n                _httpAuthSchemes.splice(index, 1, httpAuthScheme);\n            }\n        },\n        httpAuthSchemes() {\n            return _httpAuthSchemes;\n        },\n        setHttpAuthSchemeProvider(httpAuthSchemeProvider) {\n            _httpAuthSchemeProvider = httpAuthSchemeProvider;\n        },\n        httpAuthSchemeProvider() {\n            return _httpAuthSchemeProvider;\n        },\n        setCredentials(credentials) {\n            _credentials = credentials;\n        },\n        credentials() {\n            return _credentials;\n        },\n    };\n};\nconst resolveHttpAuthRuntimeConfig = (config) => {\n    return {\n        httpAuthSchemes: config.httpAuthSchemes(),\n        httpAuthSchemeProvider: config.httpAuthSchemeProvider(),\n        credentials: config.credentials(),\n    };\n};\n\nconst resolveRuntimeExtensions = (runtimeConfig, extensions) => {\n    const extensionConfiguration = Object.assign(regionConfigResolver.getAwsRegionExtensionConfiguration(runtimeConfig), smithyClient.getDefaultExtensionConfiguration(runtimeConfig), protocolHttp.getHttpHandlerExtensionConfiguration(runtimeConfig), getHttpAuthExtensionConfiguration(runtimeConfig));\n    extensions.forEach((extension) => extension.configure(extensionConfiguration));\n    return Object.assign(runtimeConfig, regionConfigResolver.resolveAwsRegionExtensionConfiguration(extensionConfiguration), smithyClient.resolveDefaultRuntimeConfig(extensionConfiguration), protocolHttp.resolveHttpHandlerRuntimeConfig(extensionConfiguration), resolveHttpAuthRuntimeConfig(extensionConfiguration));\n};\n\nclass S3Client extends smithyClient.Client {\n    config;\n    constructor(...[configuration]) {\n        const _config_0 = runtimeConfig.getRuntimeConfig(configuration || {});\n        super(_config_0);\n        this.initConfig = _config_0;\n        const _config_1 = resolveClientEndpointParameters(_config_0);\n        const _config_2 = middlewareUserAgent.resolveUserAgentConfig(_config_1);\n        const _config_3 = middlewareFlexibleChecksums.resolveFlexibleChecksumsConfig(_config_2);\n        const _config_4 = middlewareRetry.resolveRetryConfig(_config_3);\n        const _config_5 = configResolver.resolveRegionConfig(_config_4);\n        const _config_6 = middlewareHostHeader.resolveHostHeaderConfig(_config_5);\n        const _config_7 = middlewareEndpoint.resolveEndpointConfig(_config_6);\n        const _config_8 = eventstreamSerdeConfigResolver.resolveEventStreamSerdeConfig(_config_7);\n        const _config_9 = httpAuthSchemeProvider.resolveHttpAuthSchemeConfig(_config_8);\n        const _config_10 = middlewareSdkS3.resolveS3Config(_config_9, { session: [() => this, CreateSessionCommand] });\n        const _config_11 = resolveRuntimeExtensions(_config_10, configuration?.extensions || []);\n        this.config = _config_11;\n        this.middlewareStack.use(schema.getSchemaSerdePlugin(this.config));\n        this.middlewareStack.use(middlewareUserAgent.getUserAgentPlugin(this.config));\n        this.middlewareStack.use(middlewareRetry.getRetryPlugin(this.config));\n        this.middlewareStack.use(middlewareContentLength.getContentLengthPlugin(this.config));\n        this.middlewareStack.use(middlewareHostHeader.getHostHeaderPlugin(this.config));\n        this.middlewareStack.use(middlewareLogger.getLoggerPlugin(this.config));\n        this.middlewareStack.use(middlewareRecursionDetection.getRecursionDetectionPlugin(this.config));\n        this.middlewareStack.use(core.getHttpAuthSchemeEndpointRuleSetPlugin(this.config, {\n            httpAuthSchemeParametersProvider: httpAuthSchemeProvider.defaultS3HttpAuthSchemeParametersProvider,\n            identityProviderConfigProvider: async (config) => new core.DefaultIdentityProviderConfig({\n                \"aws.auth#sigv4\": config.credentials,\n                \"aws.auth#sigv4a\": config.credentials,\n            }),\n        }));\n        this.middlewareStack.use(core.getHttpSigningPlugin(this.config));\n        this.middlewareStack.use(middlewareSdkS3.getValidateBucketNamePlugin(this.config));\n        this.middlewareStack.use(middlewareExpectContinue.getAddExpectContinuePlugin(this.config));\n        this.middlewareStack.use(middlewareSdkS3.getRegionRedirectMiddlewarePlugin(this.config));\n        this.middlewareStack.use(middlewareSdkS3.getS3ExpressPlugin(this.config));\n        this.middlewareStack.use(middlewareSdkS3.getS3ExpressHttpSigningPlugin(this.config));\n    }\n    destroy() {\n        super.destroy();\n    }\n}\n\nclass AbortMultipartUploadCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"AbortMultipartUpload\", {})\n    .n(\"S3Client\", \"AbortMultipartUploadCommand\")\n    .sc(AbortMultipartUpload$)\n    .build() {\n}\n\nclass CompleteMultipartUploadCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"CompleteMultipartUpload\", {})\n    .n(\"S3Client\", \"CompleteMultipartUploadCommand\")\n    .sc(CompleteMultipartUpload$)\n    .build() {\n}\n\nclass CopyObjectCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    DisableS3ExpressSessionAuth: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n    CopySource: { type: \"contextParams\", name: \"CopySource\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"CopyObject\", {})\n    .n(\"S3Client\", \"CopyObjectCommand\")\n    .sc(CopyObject$)\n    .build() {\n}\n\nclass CreateBucketCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    DisableAccessPoints: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareLocationConstraint.getLocationConstraintPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"CreateBucket\", {})\n    .n(\"S3Client\", \"CreateBucketCommand\")\n    .sc(CreateBucket$)\n    .build() {\n}\n\nclass CreateBucketMetadataConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"CreateBucketMetadataConfiguration\", {})\n    .n(\"S3Client\", \"CreateBucketMetadataConfigurationCommand\")\n    .sc(CreateBucketMetadataConfiguration$)\n    .build() {\n}\n\nclass CreateBucketMetadataTableConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"CreateBucketMetadataTableConfiguration\", {})\n    .n(\"S3Client\", \"CreateBucketMetadataTableConfigurationCommand\")\n    .sc(CreateBucketMetadataTableConfiguration$)\n    .build() {\n}\n\nclass CreateMultipartUploadCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"CreateMultipartUpload\", {})\n    .n(\"S3Client\", \"CreateMultipartUploadCommand\")\n    .sc(CreateMultipartUpload$)\n    .build() {\n}\n\nclass DeleteBucketAnalyticsConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketAnalyticsConfiguration\", {})\n    .n(\"S3Client\", \"DeleteBucketAnalyticsConfigurationCommand\")\n    .sc(DeleteBucketAnalyticsConfiguration$)\n    .build() {\n}\n\nclass DeleteBucketCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucket\", {})\n    .n(\"S3Client\", \"DeleteBucketCommand\")\n    .sc(DeleteBucket$)\n    .build() {\n}\n\nclass DeleteBucketCorsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketCors\", {})\n    .n(\"S3Client\", \"DeleteBucketCorsCommand\")\n    .sc(DeleteBucketCors$)\n    .build() {\n}\n\nclass DeleteBucketEncryptionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketEncryption\", {})\n    .n(\"S3Client\", \"DeleteBucketEncryptionCommand\")\n    .sc(DeleteBucketEncryption$)\n    .build() {\n}\n\nclass DeleteBucketIntelligentTieringConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketIntelligentTieringConfiguration\", {})\n    .n(\"S3Client\", \"DeleteBucketIntelligentTieringConfigurationCommand\")\n    .sc(DeleteBucketIntelligentTieringConfiguration$)\n    .build() {\n}\n\nclass DeleteBucketInventoryConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketInventoryConfiguration\", {})\n    .n(\"S3Client\", \"DeleteBucketInventoryConfigurationCommand\")\n    .sc(DeleteBucketInventoryConfiguration$)\n    .build() {\n}\n\nclass DeleteBucketLifecycleCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketLifecycle\", {})\n    .n(\"S3Client\", \"DeleteBucketLifecycleCommand\")\n    .sc(DeleteBucketLifecycle$)\n    .build() {\n}\n\nclass DeleteBucketMetadataConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketMetadataConfiguration\", {})\n    .n(\"S3Client\", \"DeleteBucketMetadataConfigurationCommand\")\n    .sc(DeleteBucketMetadataConfiguration$)\n    .build() {\n}\n\nclass DeleteBucketMetadataTableConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketMetadataTableConfiguration\", {})\n    .n(\"S3Client\", \"DeleteBucketMetadataTableConfigurationCommand\")\n    .sc(DeleteBucketMetadataTableConfiguration$)\n    .build() {\n}\n\nclass DeleteBucketMetricsConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketMetricsConfiguration\", {})\n    .n(\"S3Client\", \"DeleteBucketMetricsConfigurationCommand\")\n    .sc(DeleteBucketMetricsConfiguration$)\n    .build() {\n}\n\nclass DeleteBucketOwnershipControlsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketOwnershipControls\", {})\n    .n(\"S3Client\", \"DeleteBucketOwnershipControlsCommand\")\n    .sc(DeleteBucketOwnershipControls$)\n    .build() {\n}\n\nclass DeleteBucketPolicyCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketPolicy\", {})\n    .n(\"S3Client\", \"DeleteBucketPolicyCommand\")\n    .sc(DeleteBucketPolicy$)\n    .build() {\n}\n\nclass DeleteBucketReplicationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketReplication\", {})\n    .n(\"S3Client\", \"DeleteBucketReplicationCommand\")\n    .sc(DeleteBucketReplication$)\n    .build() {\n}\n\nclass DeleteBucketTaggingCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketTagging\", {})\n    .n(\"S3Client\", \"DeleteBucketTaggingCommand\")\n    .sc(DeleteBucketTagging$)\n    .build() {\n}\n\nclass DeleteBucketWebsiteCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeleteBucketWebsite\", {})\n    .n(\"S3Client\", \"DeleteBucketWebsiteCommand\")\n    .sc(DeleteBucketWebsite$)\n    .build() {\n}\n\nclass DeleteObjectCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"DeleteObject\", {})\n    .n(\"S3Client\", \"DeleteObjectCommand\")\n    .sc(DeleteObject$)\n    .build() {\n}\n\nclass DeleteObjectsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"DeleteObjects\", {})\n    .n(\"S3Client\", \"DeleteObjectsCommand\")\n    .sc(DeleteObjects$)\n    .build() {\n}\n\nclass DeleteObjectTaggingCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"DeleteObjectTagging\", {})\n    .n(\"S3Client\", \"DeleteObjectTaggingCommand\")\n    .sc(DeleteObjectTagging$)\n    .build() {\n}\n\nclass DeletePublicAccessBlockCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"DeletePublicAccessBlock\", {})\n    .n(\"S3Client\", \"DeletePublicAccessBlockCommand\")\n    .sc(DeletePublicAccessBlock$)\n    .build() {\n}\n\nclass GetBucketAbacCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketAbac\", {})\n    .n(\"S3Client\", \"GetBucketAbacCommand\")\n    .sc(GetBucketAbac$)\n    .build() {\n}\n\nclass GetBucketAccelerateConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketAccelerateConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketAccelerateConfigurationCommand\")\n    .sc(GetBucketAccelerateConfiguration$)\n    .build() {\n}\n\nclass GetBucketAclCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketAcl\", {})\n    .n(\"S3Client\", \"GetBucketAclCommand\")\n    .sc(GetBucketAcl$)\n    .build() {\n}\n\nclass GetBucketAnalyticsConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketAnalyticsConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketAnalyticsConfigurationCommand\")\n    .sc(GetBucketAnalyticsConfiguration$)\n    .build() {\n}\n\nclass GetBucketCorsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketCors\", {})\n    .n(\"S3Client\", \"GetBucketCorsCommand\")\n    .sc(GetBucketCors$)\n    .build() {\n}\n\nclass GetBucketEncryptionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketEncryption\", {})\n    .n(\"S3Client\", \"GetBucketEncryptionCommand\")\n    .sc(GetBucketEncryption$)\n    .build() {\n}\n\nclass GetBucketIntelligentTieringConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketIntelligentTieringConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketIntelligentTieringConfigurationCommand\")\n    .sc(GetBucketIntelligentTieringConfiguration$)\n    .build() {\n}\n\nclass GetBucketInventoryConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketInventoryConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketInventoryConfigurationCommand\")\n    .sc(GetBucketInventoryConfiguration$)\n    .build() {\n}\n\nclass GetBucketLifecycleConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketLifecycleConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketLifecycleConfigurationCommand\")\n    .sc(GetBucketLifecycleConfiguration$)\n    .build() {\n}\n\nclass GetBucketLocationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketLocation\", {})\n    .n(\"S3Client\", \"GetBucketLocationCommand\")\n    .sc(GetBucketLocation$)\n    .build() {\n}\n\nclass GetBucketLoggingCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketLogging\", {})\n    .n(\"S3Client\", \"GetBucketLoggingCommand\")\n    .sc(GetBucketLogging$)\n    .build() {\n}\n\nclass GetBucketMetadataConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketMetadataConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketMetadataConfigurationCommand\")\n    .sc(GetBucketMetadataConfiguration$)\n    .build() {\n}\n\nclass GetBucketMetadataTableConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketMetadataTableConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketMetadataTableConfigurationCommand\")\n    .sc(GetBucketMetadataTableConfiguration$)\n    .build() {\n}\n\nclass GetBucketMetricsConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketMetricsConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketMetricsConfigurationCommand\")\n    .sc(GetBucketMetricsConfiguration$)\n    .build() {\n}\n\nclass GetBucketNotificationConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketNotificationConfiguration\", {})\n    .n(\"S3Client\", \"GetBucketNotificationConfigurationCommand\")\n    .sc(GetBucketNotificationConfiguration$)\n    .build() {\n}\n\nclass GetBucketOwnershipControlsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketOwnershipControls\", {})\n    .n(\"S3Client\", \"GetBucketOwnershipControlsCommand\")\n    .sc(GetBucketOwnershipControls$)\n    .build() {\n}\n\nclass GetBucketPolicyCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketPolicy\", {})\n    .n(\"S3Client\", \"GetBucketPolicyCommand\")\n    .sc(GetBucketPolicy$)\n    .build() {\n}\n\nclass GetBucketPolicyStatusCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketPolicyStatus\", {})\n    .n(\"S3Client\", \"GetBucketPolicyStatusCommand\")\n    .sc(GetBucketPolicyStatus$)\n    .build() {\n}\n\nclass GetBucketReplicationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketReplication\", {})\n    .n(\"S3Client\", \"GetBucketReplicationCommand\")\n    .sc(GetBucketReplication$)\n    .build() {\n}\n\nclass GetBucketRequestPaymentCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketRequestPayment\", {})\n    .n(\"S3Client\", \"GetBucketRequestPaymentCommand\")\n    .sc(GetBucketRequestPayment$)\n    .build() {\n}\n\nclass GetBucketTaggingCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketTagging\", {})\n    .n(\"S3Client\", \"GetBucketTaggingCommand\")\n    .sc(GetBucketTagging$)\n    .build() {\n}\n\nclass GetBucketVersioningCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketVersioning\", {})\n    .n(\"S3Client\", \"GetBucketVersioningCommand\")\n    .sc(GetBucketVersioning$)\n    .build() {\n}\n\nclass GetBucketWebsiteCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetBucketWebsite\", {})\n    .n(\"S3Client\", \"GetBucketWebsiteCommand\")\n    .sc(GetBucketWebsite$)\n    .build() {\n}\n\nclass GetObjectAclCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetObjectAcl\", {})\n    .n(\"S3Client\", \"GetObjectAclCommand\")\n    .sc(GetObjectAcl$)\n    .build() {\n}\n\nclass GetObjectAttributesCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetObjectAttributes\", {})\n    .n(\"S3Client\", \"GetObjectAttributesCommand\")\n    .sc(GetObjectAttributes$)\n    .build() {\n}\n\nclass GetObjectCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestChecksumRequired: false,\n            requestValidationModeMember: 'ChecksumMode',\n            'responseAlgorithms': ['CRC64NVME', 'CRC32', 'CRC32C', 'SHA256', 'SHA1'],\n        }),\n        middlewareSsec.getSsecPlugin(config),\n        middlewareSdkS3.getS3ExpiresMiddlewarePlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetObject\", {})\n    .n(\"S3Client\", \"GetObjectCommand\")\n    .sc(GetObject$)\n    .build() {\n}\n\nclass GetObjectLegalHoldCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetObjectLegalHold\", {})\n    .n(\"S3Client\", \"GetObjectLegalHoldCommand\")\n    .sc(GetObjectLegalHold$)\n    .build() {\n}\n\nclass GetObjectLockConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetObjectLockConfiguration\", {})\n    .n(\"S3Client\", \"GetObjectLockConfigurationCommand\")\n    .sc(GetObjectLockConfiguration$)\n    .build() {\n}\n\nclass GetObjectRetentionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetObjectRetention\", {})\n    .n(\"S3Client\", \"GetObjectRetentionCommand\")\n    .sc(GetObjectRetention$)\n    .build() {\n}\n\nclass GetObjectTaggingCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetObjectTagging\", {})\n    .n(\"S3Client\", \"GetObjectTaggingCommand\")\n    .sc(GetObjectTagging$)\n    .build() {\n}\n\nclass GetObjectTorrentCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"GetObjectTorrent\", {})\n    .n(\"S3Client\", \"GetObjectTorrentCommand\")\n    .sc(GetObjectTorrent$)\n    .build() {\n}\n\nclass GetPublicAccessBlockCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"GetPublicAccessBlock\", {})\n    .n(\"S3Client\", \"GetPublicAccessBlockCommand\")\n    .sc(GetPublicAccessBlock$)\n    .build() {\n}\n\nclass HeadBucketCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"HeadBucket\", {})\n    .n(\"S3Client\", \"HeadBucketCommand\")\n    .sc(HeadBucket$)\n    .build() {\n}\n\nclass HeadObjectCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n        middlewareSdkS3.getS3ExpiresMiddlewarePlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"HeadObject\", {})\n    .n(\"S3Client\", \"HeadObjectCommand\")\n    .sc(HeadObject$)\n    .build() {\n}\n\nclass ListBucketAnalyticsConfigurationsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListBucketAnalyticsConfigurations\", {})\n    .n(\"S3Client\", \"ListBucketAnalyticsConfigurationsCommand\")\n    .sc(ListBucketAnalyticsConfigurations$)\n    .build() {\n}\n\nclass ListBucketIntelligentTieringConfigurationsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListBucketIntelligentTieringConfigurations\", {})\n    .n(\"S3Client\", \"ListBucketIntelligentTieringConfigurationsCommand\")\n    .sc(ListBucketIntelligentTieringConfigurations$)\n    .build() {\n}\n\nclass ListBucketInventoryConfigurationsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListBucketInventoryConfigurations\", {})\n    .n(\"S3Client\", \"ListBucketInventoryConfigurationsCommand\")\n    .sc(ListBucketInventoryConfigurations$)\n    .build() {\n}\n\nclass ListBucketMetricsConfigurationsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListBucketMetricsConfigurations\", {})\n    .n(\"S3Client\", \"ListBucketMetricsConfigurationsCommand\")\n    .sc(ListBucketMetricsConfigurations$)\n    .build() {\n}\n\nclass ListBucketsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(commonParams)\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListBuckets\", {})\n    .n(\"S3Client\", \"ListBucketsCommand\")\n    .sc(ListBuckets$)\n    .build() {\n}\n\nclass ListDirectoryBucketsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListDirectoryBuckets\", {})\n    .n(\"S3Client\", \"ListDirectoryBucketsCommand\")\n    .sc(ListDirectoryBuckets$)\n    .build() {\n}\n\nclass ListMultipartUploadsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Prefix: { type: \"contextParams\", name: \"Prefix\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListMultipartUploads\", {})\n    .n(\"S3Client\", \"ListMultipartUploadsCommand\")\n    .sc(ListMultipartUploads$)\n    .build() {\n}\n\nclass ListObjectsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Prefix: { type: \"contextParams\", name: \"Prefix\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListObjects\", {})\n    .n(\"S3Client\", \"ListObjectsCommand\")\n    .sc(ListObjects$)\n    .build() {\n}\n\nclass ListObjectsV2Command extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Prefix: { type: \"contextParams\", name: \"Prefix\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListObjectsV2\", {})\n    .n(\"S3Client\", \"ListObjectsV2Command\")\n    .sc(ListObjectsV2$)\n    .build() {\n}\n\nclass ListObjectVersionsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Prefix: { type: \"contextParams\", name: \"Prefix\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListObjectVersions\", {})\n    .n(\"S3Client\", \"ListObjectVersionsCommand\")\n    .sc(ListObjectVersions$)\n    .build() {\n}\n\nclass ListPartsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"ListParts\", {})\n    .n(\"S3Client\", \"ListPartsCommand\")\n    .sc(ListParts$)\n    .build() {\n}\n\nclass PutBucketAbacCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: false,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketAbac\", {})\n    .n(\"S3Client\", \"PutBucketAbacCommand\")\n    .sc(PutBucketAbac$)\n    .build() {\n}\n\nclass PutBucketAccelerateConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: false,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketAccelerateConfiguration\", {})\n    .n(\"S3Client\", \"PutBucketAccelerateConfigurationCommand\")\n    .sc(PutBucketAccelerateConfiguration$)\n    .build() {\n}\n\nclass PutBucketAclCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketAcl\", {})\n    .n(\"S3Client\", \"PutBucketAclCommand\")\n    .sc(PutBucketAcl$)\n    .build() {\n}\n\nclass PutBucketAnalyticsConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"PutBucketAnalyticsConfiguration\", {})\n    .n(\"S3Client\", \"PutBucketAnalyticsConfigurationCommand\")\n    .sc(PutBucketAnalyticsConfiguration$)\n    .build() {\n}\n\nclass PutBucketCorsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketCors\", {})\n    .n(\"S3Client\", \"PutBucketCorsCommand\")\n    .sc(PutBucketCors$)\n    .build() {\n}\n\nclass PutBucketEncryptionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketEncryption\", {})\n    .n(\"S3Client\", \"PutBucketEncryptionCommand\")\n    .sc(PutBucketEncryption$)\n    .build() {\n}\n\nclass PutBucketIntelligentTieringConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"PutBucketIntelligentTieringConfiguration\", {})\n    .n(\"S3Client\", \"PutBucketIntelligentTieringConfigurationCommand\")\n    .sc(PutBucketIntelligentTieringConfiguration$)\n    .build() {\n}\n\nclass PutBucketInventoryConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"PutBucketInventoryConfiguration\", {})\n    .n(\"S3Client\", \"PutBucketInventoryConfigurationCommand\")\n    .sc(PutBucketInventoryConfiguration$)\n    .build() {\n}\n\nclass PutBucketLifecycleConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketLifecycleConfiguration\", {})\n    .n(\"S3Client\", \"PutBucketLifecycleConfigurationCommand\")\n    .sc(PutBucketLifecycleConfiguration$)\n    .build() {\n}\n\nclass PutBucketLoggingCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketLogging\", {})\n    .n(\"S3Client\", \"PutBucketLoggingCommand\")\n    .sc(PutBucketLogging$)\n    .build() {\n}\n\nclass PutBucketMetricsConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"PutBucketMetricsConfiguration\", {})\n    .n(\"S3Client\", \"PutBucketMetricsConfigurationCommand\")\n    .sc(PutBucketMetricsConfiguration$)\n    .build() {\n}\n\nclass PutBucketNotificationConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"PutBucketNotificationConfiguration\", {})\n    .n(\"S3Client\", \"PutBucketNotificationConfigurationCommand\")\n    .sc(PutBucketNotificationConfiguration$)\n    .build() {\n}\n\nclass PutBucketOwnershipControlsCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketOwnershipControls\", {})\n    .n(\"S3Client\", \"PutBucketOwnershipControlsCommand\")\n    .sc(PutBucketOwnershipControls$)\n    .build() {\n}\n\nclass PutBucketPolicyCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketPolicy\", {})\n    .n(\"S3Client\", \"PutBucketPolicyCommand\")\n    .sc(PutBucketPolicy$)\n    .build() {\n}\n\nclass PutBucketReplicationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketReplication\", {})\n    .n(\"S3Client\", \"PutBucketReplicationCommand\")\n    .sc(PutBucketReplication$)\n    .build() {\n}\n\nclass PutBucketRequestPaymentCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketRequestPayment\", {})\n    .n(\"S3Client\", \"PutBucketRequestPaymentCommand\")\n    .sc(PutBucketRequestPayment$)\n    .build() {\n}\n\nclass PutBucketTaggingCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketTagging\", {})\n    .n(\"S3Client\", \"PutBucketTaggingCommand\")\n    .sc(PutBucketTagging$)\n    .build() {\n}\n\nclass PutBucketVersioningCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketVersioning\", {})\n    .n(\"S3Client\", \"PutBucketVersioningCommand\")\n    .sc(PutBucketVersioning$)\n    .build() {\n}\n\nclass PutBucketWebsiteCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutBucketWebsite\", {})\n    .n(\"S3Client\", \"PutBucketWebsiteCommand\")\n    .sc(PutBucketWebsite$)\n    .build() {\n}\n\nclass PutObjectAclCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"PutObjectAcl\", {})\n    .n(\"S3Client\", \"PutObjectAclCommand\")\n    .sc(PutObjectAcl$)\n    .build() {\n}\n\nclass PutObjectCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: false,\n        }),\n        middlewareSdkS3.getCheckContentLengthHeaderPlugin(config),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"PutObject\", {})\n    .n(\"S3Client\", \"PutObjectCommand\")\n    .sc(PutObject$)\n    .build() {\n}\n\nclass PutObjectLegalHoldCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"PutObjectLegalHold\", {})\n    .n(\"S3Client\", \"PutObjectLegalHoldCommand\")\n    .sc(PutObjectLegalHold$)\n    .build() {\n}\n\nclass PutObjectLockConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"PutObjectLockConfiguration\", {})\n    .n(\"S3Client\", \"PutObjectLockConfigurationCommand\")\n    .sc(PutObjectLockConfiguration$)\n    .build() {\n}\n\nclass PutObjectRetentionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"PutObjectRetention\", {})\n    .n(\"S3Client\", \"PutObjectRetentionCommand\")\n    .sc(PutObjectRetention$)\n    .build() {\n}\n\nclass PutObjectTaggingCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"PutObjectTagging\", {})\n    .n(\"S3Client\", \"PutObjectTaggingCommand\")\n    .sc(PutObjectTagging$)\n    .build() {\n}\n\nclass PutPublicAccessBlockCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"PutPublicAccessBlock\", {})\n    .n(\"S3Client\", \"PutPublicAccessBlockCommand\")\n    .sc(PutPublicAccessBlock$)\n    .build() {\n}\n\nclass RenameObjectCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"RenameObject\", {})\n    .n(\"S3Client\", \"RenameObjectCommand\")\n    .sc(RenameObject$)\n    .build() {\n}\n\nclass RestoreObjectCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: false,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"RestoreObject\", {})\n    .n(\"S3Client\", \"RestoreObjectCommand\")\n    .sc(RestoreObject$)\n    .build() {\n}\n\nclass SelectObjectContentCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"SelectObjectContent\", {\n    eventStream: {\n        output: true,\n    },\n})\n    .n(\"S3Client\", \"SelectObjectContentCommand\")\n    .sc(SelectObjectContent$)\n    .build() {\n}\n\nclass UpdateBucketMetadataInventoryTableConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"UpdateBucketMetadataInventoryTableConfiguration\", {})\n    .n(\"S3Client\", \"UpdateBucketMetadataInventoryTableConfigurationCommand\")\n    .sc(UpdateBucketMetadataInventoryTableConfiguration$)\n    .build() {\n}\n\nclass UpdateBucketMetadataJournalTableConfigurationCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseS3ExpressControlEndpoint: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n    ];\n})\n    .s(\"AmazonS3\", \"UpdateBucketMetadataJournalTableConfiguration\", {})\n    .n(\"S3Client\", \"UpdateBucketMetadataJournalTableConfigurationCommand\")\n    .sc(UpdateBucketMetadataJournalTableConfiguration$)\n    .build() {\n}\n\nclass UpdateObjectEncryptionCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: true,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"UpdateObjectEncryption\", {})\n    .n(\"S3Client\", \"UpdateObjectEncryptionCommand\")\n    .sc(UpdateObjectEncryption$)\n    .build() {\n}\n\nclass UploadPartCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n    Key: { type: \"contextParams\", name: \"Key\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareFlexibleChecksums.getFlexibleChecksumsPlugin(config, {\n            requestAlgorithmMember: { 'httpHeader': 'x-amz-sdk-checksum-algorithm', 'name': 'ChecksumAlgorithm' },\n            requestChecksumRequired: false,\n        }),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"UploadPart\", {})\n    .n(\"S3Client\", \"UploadPartCommand\")\n    .sc(UploadPart$)\n    .build() {\n}\n\nclass UploadPartCopyCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    DisableS3ExpressSessionAuth: { type: \"staticContextParams\", value: true },\n    Bucket: { type: \"contextParams\", name: \"Bucket\" },\n})\n    .m(function (Command, cs, config, o) {\n    return [\n        middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions()),\n        middlewareSdkS3.getThrow200ExceptionsPlugin(config),\n        middlewareSsec.getSsecPlugin(config),\n    ];\n})\n    .s(\"AmazonS3\", \"UploadPartCopy\", {})\n    .n(\"S3Client\", \"UploadPartCopyCommand\")\n    .sc(UploadPartCopy$)\n    .build() {\n}\n\nclass WriteGetObjectResponseCommand extends smithyClient.Command\n    .classBuilder()\n    .ep({\n    ...commonParams,\n    UseObjectLambdaEndpoint: { type: \"staticContextParams\", value: true },\n})\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AmazonS3\", \"WriteGetObjectResponse\", {})\n    .n(\"S3Client\", \"WriteGetObjectResponseCommand\")\n    .sc(WriteGetObjectResponse$)\n    .build() {\n}\n\nconst paginateListBuckets = core.createPaginator(S3Client, ListBucketsCommand, \"ContinuationToken\", \"ContinuationToken\", \"MaxBuckets\");\n\nconst paginateListDirectoryBuckets = core.createPaginator(S3Client, ListDirectoryBucketsCommand, \"ContinuationToken\", \"ContinuationToken\", \"MaxDirectoryBuckets\");\n\nconst paginateListObjectsV2 = core.createPaginator(S3Client, ListObjectsV2Command, \"ContinuationToken\", \"NextContinuationToken\", \"MaxKeys\");\n\nconst paginateListParts = core.createPaginator(S3Client, ListPartsCommand, \"PartNumberMarker\", \"NextPartNumberMarker\", \"MaxParts\");\n\nconst checkState$3 = async (client, input) => {\n    let reason;\n    try {\n        let result = await client.send(new HeadBucketCommand(input));\n        reason = result;\n        return { state: utilWaiter.WaiterState.SUCCESS, reason };\n    }\n    catch (exception) {\n        reason = exception;\n        if (exception.name && exception.name == \"NotFound\") {\n            return { state: utilWaiter.WaiterState.RETRY, reason };\n        }\n    }\n    return { state: utilWaiter.WaiterState.RETRY, reason };\n};\nconst waitForBucketExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 5, maxDelay: 120 };\n    return utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$3);\n};\nconst waitUntilBucketExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 5, maxDelay: 120 };\n    const result = await utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$3);\n    return utilWaiter.checkExceptions(result);\n};\n\nconst checkState$2 = async (client, input) => {\n    let reason;\n    try {\n        let result = await client.send(new HeadBucketCommand(input));\n        reason = result;\n    }\n    catch (exception) {\n        reason = exception;\n        if (exception.name && exception.name == \"NotFound\") {\n            return { state: utilWaiter.WaiterState.SUCCESS, reason };\n        }\n    }\n    return { state: utilWaiter.WaiterState.RETRY, reason };\n};\nconst waitForBucketNotExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 5, maxDelay: 120 };\n    return utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$2);\n};\nconst waitUntilBucketNotExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 5, maxDelay: 120 };\n    const result = await utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$2);\n    return utilWaiter.checkExceptions(result);\n};\n\nconst checkState$1 = async (client, input) => {\n    let reason;\n    try {\n        let result = await client.send(new HeadObjectCommand(input));\n        reason = result;\n        return { state: utilWaiter.WaiterState.SUCCESS, reason };\n    }\n    catch (exception) {\n        reason = exception;\n        if (exception.name && exception.name == \"NotFound\") {\n            return { state: utilWaiter.WaiterState.RETRY, reason };\n        }\n    }\n    return { state: utilWaiter.WaiterState.RETRY, reason };\n};\nconst waitForObjectExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 5, maxDelay: 120 };\n    return utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$1);\n};\nconst waitUntilObjectExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 5, maxDelay: 120 };\n    const result = await utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState$1);\n    return utilWaiter.checkExceptions(result);\n};\n\nconst checkState = async (client, input) => {\n    let reason;\n    try {\n        let result = await client.send(new HeadObjectCommand(input));\n        reason = result;\n    }\n    catch (exception) {\n        reason = exception;\n        if (exception.name && exception.name == \"NotFound\") {\n            return { state: utilWaiter.WaiterState.SUCCESS, reason };\n        }\n    }\n    return { state: utilWaiter.WaiterState.RETRY, reason };\n};\nconst waitForObjectNotExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 5, maxDelay: 120 };\n    return utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState);\n};\nconst waitUntilObjectNotExists = async (params, input) => {\n    const serviceDefaults = { minDelay: 5, maxDelay: 120 };\n    const result = await utilWaiter.createWaiter({ ...serviceDefaults, ...params }, input, checkState);\n    return utilWaiter.checkExceptions(result);\n};\n\nconst commands = {\n    AbortMultipartUploadCommand,\n    CompleteMultipartUploadCommand,\n    CopyObjectCommand,\n    CreateBucketCommand,\n    CreateBucketMetadataConfigurationCommand,\n    CreateBucketMetadataTableConfigurationCommand,\n    CreateMultipartUploadCommand,\n    CreateSessionCommand,\n    DeleteBucketCommand,\n    DeleteBucketAnalyticsConfigurationCommand,\n    DeleteBucketCorsCommand,\n    DeleteBucketEncryptionCommand,\n    DeleteBucketIntelligentTieringConfigurationCommand,\n    DeleteBucketInventoryConfigurationCommand,\n    DeleteBucketLifecycleCommand,\n    DeleteBucketMetadataConfigurationCommand,\n    DeleteBucketMetadataTableConfigurationCommand,\n    DeleteBucketMetricsConfigurationCommand,\n    DeleteBucketOwnershipControlsCommand,\n    DeleteBucketPolicyCommand,\n    DeleteBucketReplicationCommand,\n    DeleteBucketTaggingCommand,\n    DeleteBucketWebsiteCommand,\n    DeleteObjectCommand,\n    DeleteObjectsCommand,\n    DeleteObjectTaggingCommand,\n    DeletePublicAccessBlockCommand,\n    GetBucketAbacCommand,\n    GetBucketAccelerateConfigurationCommand,\n    GetBucketAclCommand,\n    GetBucketAnalyticsConfigurationCommand,\n    GetBucketCorsCommand,\n    GetBucketEncryptionCommand,\n    GetBucketIntelligentTieringConfigurationCommand,\n    GetBucketInventoryConfigurationCommand,\n    GetBucketLifecycleConfigurationCommand,\n    GetBucketLocationCommand,\n    GetBucketLoggingCommand,\n    GetBucketMetadataConfigurationCommand,\n    GetBucketMetadataTableConfigurationCommand,\n    GetBucketMetricsConfigurationCommand,\n    GetBucketNotificationConfigurationCommand,\n    GetBucketOwnershipControlsCommand,\n    GetBucketPolicyCommand,\n    GetBucketPolicyStatusCommand,\n    GetBucketReplicationCommand,\n    GetBucketRequestPaymentCommand,\n    GetBucketTaggingCommand,\n    GetBucketVersioningCommand,\n    GetBucketWebsiteCommand,\n    GetObjectCommand,\n    GetObjectAclCommand,\n    GetObjectAttributesCommand,\n    GetObjectLegalHoldCommand,\n    GetObjectLockConfigurationCommand,\n    GetObjectRetentionCommand,\n    GetObjectTaggingCommand,\n    GetObjectTorrentCommand,\n    GetPublicAccessBlockCommand,\n    HeadBucketCommand,\n    HeadObjectCommand,\n    ListBucketAnalyticsConfigurationsCommand,\n    ListBucketIntelligentTieringConfigurationsCommand,\n    ListBucketInventoryConfigurationsCommand,\n    ListBucketMetricsConfigurationsCommand,\n    ListBucketsCommand,\n    ListDirectoryBucketsCommand,\n    ListMultipartUploadsCommand,\n    ListObjectsCommand,\n    ListObjectsV2Command,\n    ListObjectVersionsCommand,\n    ListPartsCommand,\n    PutBucketAbacCommand,\n    PutBucketAccelerateConfigurationCommand,\n    PutBucketAclCommand,\n    PutBucketAnalyticsConfigurationCommand,\n    PutBucketCorsCommand,\n    PutBucketEncryptionCommand,\n    PutBucketIntelligentTieringConfigurationCommand,\n    PutBucketInventoryConfigurationCommand,\n    PutBucketLifecycleConfigurationCommand,\n    PutBucketLoggingCommand,\n    PutBucketMetricsConfigurationCommand,\n    PutBucketNotificationConfigurationCommand,\n    PutBucketOwnershipControlsCommand,\n    PutBucketPolicyCommand,\n    PutBucketReplicationCommand,\n    PutBucketRequestPaymentCommand,\n    PutBucketTaggingCommand,\n    PutBucketVersioningCommand,\n    PutBucketWebsiteCommand,\n    PutObjectCommand,\n    PutObjectAclCommand,\n    PutObjectLegalHoldCommand,\n    PutObjectLockConfigurationCommand,\n    PutObjectRetentionCommand,\n    PutObjectTaggingCommand,\n    PutPublicAccessBlockCommand,\n    RenameObjectCommand,\n    RestoreObjectCommand,\n    SelectObjectContentCommand,\n    UpdateBucketMetadataInventoryTableConfigurationCommand,\n    UpdateBucketMetadataJournalTableConfigurationCommand,\n    UpdateObjectEncryptionCommand,\n    UploadPartCommand,\n    UploadPartCopyCommand,\n    WriteGetObjectResponseCommand,\n};\nconst paginators = {\n    paginateListBuckets,\n    paginateListDirectoryBuckets,\n    paginateListObjectsV2,\n    paginateListParts,\n};\nconst waiters = {\n    waitUntilBucketExists,\n    waitUntilBucketNotExists,\n    waitUntilObjectExists,\n    waitUntilObjectNotExists,\n};\nclass S3 extends S3Client {\n}\nsmithyClient.createAggregatedClient(commands, S3, { paginators, waiters });\n\nconst BucketAbacStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst RequestCharged = {\n    requester: \"requester\",\n};\nconst RequestPayer = {\n    requester: \"requester\",\n};\nconst BucketAccelerateStatus = {\n    Enabled: \"Enabled\",\n    Suspended: \"Suspended\",\n};\nconst Type = {\n    AmazonCustomerByEmail: \"AmazonCustomerByEmail\",\n    CanonicalUser: \"CanonicalUser\",\n    Group: \"Group\",\n};\nconst Permission = {\n    FULL_CONTROL: \"FULL_CONTROL\",\n    READ: \"READ\",\n    READ_ACP: \"READ_ACP\",\n    WRITE: \"WRITE\",\n    WRITE_ACP: \"WRITE_ACP\",\n};\nconst OwnerOverride = {\n    Destination: \"Destination\",\n};\nconst ChecksumType = {\n    COMPOSITE: \"COMPOSITE\",\n    FULL_OBJECT: \"FULL_OBJECT\",\n};\nconst ServerSideEncryption = {\n    AES256: \"AES256\",\n    aws_fsx: \"aws:fsx\",\n    aws_kms: \"aws:kms\",\n    aws_kms_dsse: \"aws:kms:dsse\",\n};\nconst ObjectCannedACL = {\n    authenticated_read: \"authenticated-read\",\n    aws_exec_read: \"aws-exec-read\",\n    bucket_owner_full_control: \"bucket-owner-full-control\",\n    bucket_owner_read: \"bucket-owner-read\",\n    private: \"private\",\n    public_read: \"public-read\",\n    public_read_write: \"public-read-write\",\n};\nconst ChecksumAlgorithm = {\n    CRC32: \"CRC32\",\n    CRC32C: \"CRC32C\",\n    CRC64NVME: \"CRC64NVME\",\n    SHA1: \"SHA1\",\n    SHA256: \"SHA256\",\n};\nconst MetadataDirective = {\n    COPY: \"COPY\",\n    REPLACE: \"REPLACE\",\n};\nconst ObjectLockLegalHoldStatus = {\n    OFF: \"OFF\",\n    ON: \"ON\",\n};\nconst ObjectLockMode = {\n    COMPLIANCE: \"COMPLIANCE\",\n    GOVERNANCE: \"GOVERNANCE\",\n};\nconst StorageClass = {\n    DEEP_ARCHIVE: \"DEEP_ARCHIVE\",\n    EXPRESS_ONEZONE: \"EXPRESS_ONEZONE\",\n    FSX_ONTAP: \"FSX_ONTAP\",\n    FSX_OPENZFS: \"FSX_OPENZFS\",\n    GLACIER: \"GLACIER\",\n    GLACIER_IR: \"GLACIER_IR\",\n    INTELLIGENT_TIERING: \"INTELLIGENT_TIERING\",\n    ONEZONE_IA: \"ONEZONE_IA\",\n    OUTPOSTS: \"OUTPOSTS\",\n    REDUCED_REDUNDANCY: \"REDUCED_REDUNDANCY\",\n    SNOW: \"SNOW\",\n    STANDARD: \"STANDARD\",\n    STANDARD_IA: \"STANDARD_IA\",\n};\nconst TaggingDirective = {\n    COPY: \"COPY\",\n    REPLACE: \"REPLACE\",\n};\nconst BucketCannedACL = {\n    authenticated_read: \"authenticated-read\",\n    private: \"private\",\n    public_read: \"public-read\",\n    public_read_write: \"public-read-write\",\n};\nconst DataRedundancy = {\n    SingleAvailabilityZone: \"SingleAvailabilityZone\",\n    SingleLocalZone: \"SingleLocalZone\",\n};\nconst BucketType = {\n    Directory: \"Directory\",\n};\nconst LocationType = {\n    AvailabilityZone: \"AvailabilityZone\",\n    LocalZone: \"LocalZone\",\n};\nconst BucketLocationConstraint = {\n    EU: \"EU\",\n    af_south_1: \"af-south-1\",\n    ap_east_1: \"ap-east-1\",\n    ap_northeast_1: \"ap-northeast-1\",\n    ap_northeast_2: \"ap-northeast-2\",\n    ap_northeast_3: \"ap-northeast-3\",\n    ap_south_1: \"ap-south-1\",\n    ap_south_2: \"ap-south-2\",\n    ap_southeast_1: \"ap-southeast-1\",\n    ap_southeast_2: \"ap-southeast-2\",\n    ap_southeast_3: \"ap-southeast-3\",\n    ap_southeast_4: \"ap-southeast-4\",\n    ap_southeast_5: \"ap-southeast-5\",\n    ca_central_1: \"ca-central-1\",\n    cn_north_1: \"cn-north-1\",\n    cn_northwest_1: \"cn-northwest-1\",\n    eu_central_1: \"eu-central-1\",\n    eu_central_2: \"eu-central-2\",\n    eu_north_1: \"eu-north-1\",\n    eu_south_1: \"eu-south-1\",\n    eu_south_2: \"eu-south-2\",\n    eu_west_1: \"eu-west-1\",\n    eu_west_2: \"eu-west-2\",\n    eu_west_3: \"eu-west-3\",\n    il_central_1: \"il-central-1\",\n    me_central_1: \"me-central-1\",\n    me_south_1: \"me-south-1\",\n    sa_east_1: \"sa-east-1\",\n    us_east_2: \"us-east-2\",\n    us_gov_east_1: \"us-gov-east-1\",\n    us_gov_west_1: \"us-gov-west-1\",\n    us_west_1: \"us-west-1\",\n    us_west_2: \"us-west-2\",\n};\nconst ObjectOwnership = {\n    BucketOwnerEnforced: \"BucketOwnerEnforced\",\n    BucketOwnerPreferred: \"BucketOwnerPreferred\",\n    ObjectWriter: \"ObjectWriter\",\n};\nconst InventoryConfigurationState = {\n    DISABLED: \"DISABLED\",\n    ENABLED: \"ENABLED\",\n};\nconst TableSseAlgorithm = {\n    AES256: \"AES256\",\n    aws_kms: \"aws:kms\",\n};\nconst ExpirationState = {\n    DISABLED: \"DISABLED\",\n    ENABLED: \"ENABLED\",\n};\nconst SessionMode = {\n    ReadOnly: \"ReadOnly\",\n    ReadWrite: \"ReadWrite\",\n};\nconst AnalyticsS3ExportFileFormat = {\n    CSV: \"CSV\",\n};\nconst StorageClassAnalysisSchemaVersion = {\n    V_1: \"V_1\",\n};\nconst EncryptionType = {\n    NONE: \"NONE\",\n    SSE_C: \"SSE-C\",\n};\nconst IntelligentTieringStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst IntelligentTieringAccessTier = {\n    ARCHIVE_ACCESS: \"ARCHIVE_ACCESS\",\n    DEEP_ARCHIVE_ACCESS: \"DEEP_ARCHIVE_ACCESS\",\n};\nconst InventoryFormat = {\n    CSV: \"CSV\",\n    ORC: \"ORC\",\n    Parquet: \"Parquet\",\n};\nconst InventoryIncludedObjectVersions = {\n    All: \"All\",\n    Current: \"Current\",\n};\nconst InventoryOptionalField = {\n    BucketKeyStatus: \"BucketKeyStatus\",\n    ChecksumAlgorithm: \"ChecksumAlgorithm\",\n    ETag: \"ETag\",\n    EncryptionStatus: \"EncryptionStatus\",\n    IntelligentTieringAccessTier: \"IntelligentTieringAccessTier\",\n    IsMultipartUploaded: \"IsMultipartUploaded\",\n    LastModifiedDate: \"LastModifiedDate\",\n    LifecycleExpirationDate: \"LifecycleExpirationDate\",\n    ObjectAccessControlList: \"ObjectAccessControlList\",\n    ObjectLockLegalHoldStatus: \"ObjectLockLegalHoldStatus\",\n    ObjectLockMode: \"ObjectLockMode\",\n    ObjectLockRetainUntilDate: \"ObjectLockRetainUntilDate\",\n    ObjectOwner: \"ObjectOwner\",\n    ReplicationStatus: \"ReplicationStatus\",\n    Size: \"Size\",\n    StorageClass: \"StorageClass\",\n};\nconst InventoryFrequency = {\n    Daily: \"Daily\",\n    Weekly: \"Weekly\",\n};\nconst TransitionStorageClass = {\n    DEEP_ARCHIVE: \"DEEP_ARCHIVE\",\n    GLACIER: \"GLACIER\",\n    GLACIER_IR: \"GLACIER_IR\",\n    INTELLIGENT_TIERING: \"INTELLIGENT_TIERING\",\n    ONEZONE_IA: \"ONEZONE_IA\",\n    STANDARD_IA: \"STANDARD_IA\",\n};\nconst ExpirationStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst TransitionDefaultMinimumObjectSize = {\n    all_storage_classes_128K: \"all_storage_classes_128K\",\n    varies_by_storage_class: \"varies_by_storage_class\",\n};\nconst BucketLogsPermission = {\n    FULL_CONTROL: \"FULL_CONTROL\",\n    READ: \"READ\",\n    WRITE: \"WRITE\",\n};\nconst PartitionDateSource = {\n    DeliveryTime: \"DeliveryTime\",\n    EventTime: \"EventTime\",\n};\nconst S3TablesBucketType = {\n    aws: \"aws\",\n    customer: \"customer\",\n};\nconst Event = {\n    s3_IntelligentTiering: \"s3:IntelligentTiering\",\n    s3_LifecycleExpiration_: \"s3:LifecycleExpiration:*\",\n    s3_LifecycleExpiration_Delete: \"s3:LifecycleExpiration:Delete\",\n    s3_LifecycleExpiration_DeleteMarkerCreated: \"s3:LifecycleExpiration:DeleteMarkerCreated\",\n    s3_LifecycleTransition: \"s3:LifecycleTransition\",\n    s3_ObjectAcl_Put: \"s3:ObjectAcl:Put\",\n    s3_ObjectCreated_: \"s3:ObjectCreated:*\",\n    s3_ObjectCreated_CompleteMultipartUpload: \"s3:ObjectCreated:CompleteMultipartUpload\",\n    s3_ObjectCreated_Copy: \"s3:ObjectCreated:Copy\",\n    s3_ObjectCreated_Post: \"s3:ObjectCreated:Post\",\n    s3_ObjectCreated_Put: \"s3:ObjectCreated:Put\",\n    s3_ObjectRemoved_: \"s3:ObjectRemoved:*\",\n    s3_ObjectRemoved_Delete: \"s3:ObjectRemoved:Delete\",\n    s3_ObjectRemoved_DeleteMarkerCreated: \"s3:ObjectRemoved:DeleteMarkerCreated\",\n    s3_ObjectRestore_: \"s3:ObjectRestore:*\",\n    s3_ObjectRestore_Completed: \"s3:ObjectRestore:Completed\",\n    s3_ObjectRestore_Delete: \"s3:ObjectRestore:Delete\",\n    s3_ObjectRestore_Post: \"s3:ObjectRestore:Post\",\n    s3_ObjectTagging_: \"s3:ObjectTagging:*\",\n    s3_ObjectTagging_Delete: \"s3:ObjectTagging:Delete\",\n    s3_ObjectTagging_Put: \"s3:ObjectTagging:Put\",\n    s3_ReducedRedundancyLostObject: \"s3:ReducedRedundancyLostObject\",\n    s3_Replication_: \"s3:Replication:*\",\n    s3_Replication_OperationFailedReplication: \"s3:Replication:OperationFailedReplication\",\n    s3_Replication_OperationMissedThreshold: \"s3:Replication:OperationMissedThreshold\",\n    s3_Replication_OperationNotTracked: \"s3:Replication:OperationNotTracked\",\n    s3_Replication_OperationReplicatedAfterThreshold: \"s3:Replication:OperationReplicatedAfterThreshold\",\n};\nconst FilterRuleName = {\n    prefix: \"prefix\",\n    suffix: \"suffix\",\n};\nconst DeleteMarkerReplicationStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst MetricsStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst ReplicationTimeStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst ExistingObjectReplicationStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst ReplicaModificationsStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst SseKmsEncryptedObjectsStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst ReplicationRuleStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst Payer = {\n    BucketOwner: \"BucketOwner\",\n    Requester: \"Requester\",\n};\nconst MFADeleteStatus = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst BucketVersioningStatus = {\n    Enabled: \"Enabled\",\n    Suspended: \"Suspended\",\n};\nconst Protocol = {\n    http: \"http\",\n    https: \"https\",\n};\nconst ReplicationStatus = {\n    COMPLETE: \"COMPLETE\",\n    COMPLETED: \"COMPLETED\",\n    FAILED: \"FAILED\",\n    PENDING: \"PENDING\",\n    REPLICA: \"REPLICA\",\n};\nconst ChecksumMode = {\n    ENABLED: \"ENABLED\",\n};\nconst ObjectAttributes = {\n    CHECKSUM: \"Checksum\",\n    ETAG: \"ETag\",\n    OBJECT_PARTS: \"ObjectParts\",\n    OBJECT_SIZE: \"ObjectSize\",\n    STORAGE_CLASS: \"StorageClass\",\n};\nconst ObjectLockEnabled = {\n    Enabled: \"Enabled\",\n};\nconst ObjectLockRetentionMode = {\n    COMPLIANCE: \"COMPLIANCE\",\n    GOVERNANCE: \"GOVERNANCE\",\n};\nconst ArchiveStatus = {\n    ARCHIVE_ACCESS: \"ARCHIVE_ACCESS\",\n    DEEP_ARCHIVE_ACCESS: \"DEEP_ARCHIVE_ACCESS\",\n};\nconst EncodingType = {\n    url: \"url\",\n};\nconst ObjectStorageClass = {\n    DEEP_ARCHIVE: \"DEEP_ARCHIVE\",\n    EXPRESS_ONEZONE: \"EXPRESS_ONEZONE\",\n    FSX_ONTAP: \"FSX_ONTAP\",\n    FSX_OPENZFS: \"FSX_OPENZFS\",\n    GLACIER: \"GLACIER\",\n    GLACIER_IR: \"GLACIER_IR\",\n    INTELLIGENT_TIERING: \"INTELLIGENT_TIERING\",\n    ONEZONE_IA: \"ONEZONE_IA\",\n    OUTPOSTS: \"OUTPOSTS\",\n    REDUCED_REDUNDANCY: \"REDUCED_REDUNDANCY\",\n    SNOW: \"SNOW\",\n    STANDARD: \"STANDARD\",\n    STANDARD_IA: \"STANDARD_IA\",\n};\nconst OptionalObjectAttributes = {\n    RESTORE_STATUS: \"RestoreStatus\",\n};\nconst ObjectVersionStorageClass = {\n    STANDARD: \"STANDARD\",\n};\nconst MFADelete = {\n    Disabled: \"Disabled\",\n    Enabled: \"Enabled\",\n};\nconst Tier = {\n    Bulk: \"Bulk\",\n    Expedited: \"Expedited\",\n    Standard: \"Standard\",\n};\nconst ExpressionType = {\n    SQL: \"SQL\",\n};\nconst CompressionType = {\n    BZIP2: \"BZIP2\",\n    GZIP: \"GZIP\",\n    NONE: \"NONE\",\n};\nconst FileHeaderInfo = {\n    IGNORE: \"IGNORE\",\n    NONE: \"NONE\",\n    USE: \"USE\",\n};\nconst JSONType = {\n    DOCUMENT: \"DOCUMENT\",\n    LINES: \"LINES\",\n};\nconst QuoteFields = {\n    ALWAYS: \"ALWAYS\",\n    ASNEEDED: \"ASNEEDED\",\n};\nconst RestoreRequestType = {\n    SELECT: \"SELECT\",\n};\n\nObject.defineProperty(exports, \"$Command\", {\n    enumerable: true,\n    get: function () { return smithyClient.Command; }\n});\nObject.defineProperty(exports, \"__Client\", {\n    enumerable: true,\n    get: function () { return smithyClient.Client; }\n});\nexports.AbacStatus$ = AbacStatus$;\nexports.AbortIncompleteMultipartUpload$ = AbortIncompleteMultipartUpload$;\nexports.AbortMultipartUpload$ = AbortMultipartUpload$;\nexports.AbortMultipartUploadCommand = AbortMultipartUploadCommand;\nexports.AbortMultipartUploadOutput$ = AbortMultipartUploadOutput$;\nexports.AbortMultipartUploadRequest$ = AbortMultipartUploadRequest$;\nexports.AccelerateConfiguration$ = AccelerateConfiguration$;\nexports.AccessControlPolicy$ = AccessControlPolicy$;\nexports.AccessControlTranslation$ = AccessControlTranslation$;\nexports.AccessDenied = AccessDenied;\nexports.AccessDenied$ = AccessDenied$;\nexports.AnalyticsAndOperator$ = AnalyticsAndOperator$;\nexports.AnalyticsConfiguration$ = AnalyticsConfiguration$;\nexports.AnalyticsExportDestination$ = AnalyticsExportDestination$;\nexports.AnalyticsFilter$ = AnalyticsFilter$;\nexports.AnalyticsS3BucketDestination$ = AnalyticsS3BucketDestination$;\nexports.AnalyticsS3ExportFileFormat = AnalyticsS3ExportFileFormat;\nexports.ArchiveStatus = ArchiveStatus;\nexports.BlockedEncryptionTypes$ = BlockedEncryptionTypes$;\nexports.Bucket$ = Bucket$;\nexports.BucketAbacStatus = BucketAbacStatus;\nexports.BucketAccelerateStatus = BucketAccelerateStatus;\nexports.BucketAlreadyExists = BucketAlreadyExists;\nexports.BucketAlreadyExists$ = BucketAlreadyExists$;\nexports.BucketAlreadyOwnedByYou = BucketAlreadyOwnedByYou;\nexports.BucketAlreadyOwnedByYou$ = BucketAlreadyOwnedByYou$;\nexports.BucketCannedACL = BucketCannedACL;\nexports.BucketInfo$ = BucketInfo$;\nexports.BucketLifecycleConfiguration$ = BucketLifecycleConfiguration$;\nexports.BucketLocationConstraint = BucketLocationConstraint;\nexports.BucketLoggingStatus$ = BucketLoggingStatus$;\nexports.BucketLogsPermission = BucketLogsPermission;\nexports.BucketType = BucketType;\nexports.BucketVersioningStatus = BucketVersioningStatus;\nexports.CORSConfiguration$ = CORSConfiguration$;\nexports.CORSRule$ = CORSRule$;\nexports.CSVInput$ = CSVInput$;\nexports.CSVOutput$ = CSVOutput$;\nexports.Checksum$ = Checksum$;\nexports.ChecksumAlgorithm = ChecksumAlgorithm;\nexports.ChecksumMode = ChecksumMode;\nexports.ChecksumType = ChecksumType;\nexports.CommonPrefix$ = CommonPrefix$;\nexports.CompleteMultipartUpload$ = CompleteMultipartUpload$;\nexports.CompleteMultipartUploadCommand = CompleteMultipartUploadCommand;\nexports.CompleteMultipartUploadOutput$ = CompleteMultipartUploadOutput$;\nexports.CompleteMultipartUploadRequest$ = CompleteMultipartUploadRequest$;\nexports.CompletedMultipartUpload$ = CompletedMultipartUpload$;\nexports.CompletedPart$ = CompletedPart$;\nexports.CompressionType = CompressionType;\nexports.Condition$ = Condition$;\nexports.ContinuationEvent$ = ContinuationEvent$;\nexports.CopyObject$ = CopyObject$;\nexports.CopyObjectCommand = CopyObjectCommand;\nexports.CopyObjectOutput$ = CopyObjectOutput$;\nexports.CopyObjectRequest$ = CopyObjectRequest$;\nexports.CopyObjectResult$ = CopyObjectResult$;\nexports.CopyPartResult$ = CopyPartResult$;\nexports.CreateBucket$ = CreateBucket$;\nexports.CreateBucketCommand = CreateBucketCommand;\nexports.CreateBucketConfiguration$ = CreateBucketConfiguration$;\nexports.CreateBucketMetadataConfiguration$ = CreateBucketMetadataConfiguration$;\nexports.CreateBucketMetadataConfigurationCommand = CreateBucketMetadataConfigurationCommand;\nexports.CreateBucketMetadataConfigurationRequest$ = CreateBucketMetadataConfigurationRequest$;\nexports.CreateBucketMetadataTableConfiguration$ = CreateBucketMetadataTableConfiguration$;\nexports.CreateBucketMetadataTableConfigurationCommand = CreateBucketMetadataTableConfigurationCommand;\nexports.CreateBucketMetadataTableConfigurationRequest$ = CreateBucketMetadataTableConfigurationRequest$;\nexports.CreateBucketOutput$ = CreateBucketOutput$;\nexports.CreateBucketRequest$ = CreateBucketRequest$;\nexports.CreateMultipartUpload$ = CreateMultipartUpload$;\nexports.CreateMultipartUploadCommand = CreateMultipartUploadCommand;\nexports.CreateMultipartUploadOutput$ = CreateMultipartUploadOutput$;\nexports.CreateMultipartUploadRequest$ = CreateMultipartUploadRequest$;\nexports.CreateSession$ = CreateSession$;\nexports.CreateSessionCommand = CreateSessionCommand;\nexports.CreateSessionOutput$ = CreateSessionOutput$;\nexports.CreateSessionRequest$ = CreateSessionRequest$;\nexports.DataRedundancy = DataRedundancy;\nexports.DefaultRetention$ = DefaultRetention$;\nexports.Delete$ = Delete$;\nexports.DeleteBucket$ = DeleteBucket$;\nexports.DeleteBucketAnalyticsConfiguration$ = DeleteBucketAnalyticsConfiguration$;\nexports.DeleteBucketAnalyticsConfigurationCommand = DeleteBucketAnalyticsConfigurationCommand;\nexports.DeleteBucketAnalyticsConfigurationRequest$ = DeleteBucketAnalyticsConfigurationRequest$;\nexports.DeleteBucketCommand = DeleteBucketCommand;\nexports.DeleteBucketCors$ = DeleteBucketCors$;\nexports.DeleteBucketCorsCommand = DeleteBucketCorsCommand;\nexports.DeleteBucketCorsRequest$ = DeleteBucketCorsRequest$;\nexports.DeleteBucketEncryption$ = DeleteBucketEncryption$;\nexports.DeleteBucketEncryptionCommand = DeleteBucketEncryptionCommand;\nexports.DeleteBucketEncryptionRequest$ = DeleteBucketEncryptionRequest$;\nexports.DeleteBucketIntelligentTieringConfiguration$ = DeleteBucketIntelligentTieringConfiguration$;\nexports.DeleteBucketIntelligentTieringConfigurationCommand = DeleteBucketIntelligentTieringConfigurationCommand;\nexports.DeleteBucketIntelligentTieringConfigurationRequest$ = DeleteBucketIntelligentTieringConfigurationRequest$;\nexports.DeleteBucketInventoryConfiguration$ = DeleteBucketInventoryConfiguration$;\nexports.DeleteBucketInventoryConfigurationCommand = DeleteBucketInventoryConfigurationCommand;\nexports.DeleteBucketInventoryConfigurationRequest$ = DeleteBucketInventoryConfigurationRequest$;\nexports.DeleteBucketLifecycle$ = DeleteBucketLifecycle$;\nexports.DeleteBucketLifecycleCommand = DeleteBucketLifecycleCommand;\nexports.DeleteBucketLifecycleRequest$ = DeleteBucketLifecycleRequest$;\nexports.DeleteBucketMetadataConfiguration$ = DeleteBucketMetadataConfiguration$;\nexports.DeleteBucketMetadataConfigurationCommand = DeleteBucketMetadataConfigurationCommand;\nexports.DeleteBucketMetadataConfigurationRequest$ = DeleteBucketMetadataConfigurationRequest$;\nexports.DeleteBucketMetadataTableConfiguration$ = DeleteBucketMetadataTableConfiguration$;\nexports.DeleteBucketMetadataTableConfigurationCommand = DeleteBucketMetadataTableConfigurationCommand;\nexports.DeleteBucketMetadataTableConfigurationRequest$ = DeleteBucketMetadataTableConfigurationRequest$;\nexports.DeleteBucketMetricsConfiguration$ = DeleteBucketMetricsConfiguration$;\nexports.DeleteBucketMetricsConfigurationCommand = DeleteBucketMetricsConfigurationCommand;\nexports.DeleteBucketMetricsConfigurationRequest$ = DeleteBucketMetricsConfigurationRequest$;\nexports.DeleteBucketOwnershipControls$ = DeleteBucketOwnershipControls$;\nexports.DeleteBucketOwnershipControlsCommand = DeleteBucketOwnershipControlsCommand;\nexports.DeleteBucketOwnershipControlsRequest$ = DeleteBucketOwnershipControlsRequest$;\nexports.DeleteBucketPolicy$ = DeleteBucketPolicy$;\nexports.DeleteBucketPolicyCommand = DeleteBucketPolicyCommand;\nexports.DeleteBucketPolicyRequest$ = DeleteBucketPolicyRequest$;\nexports.DeleteBucketReplication$ = DeleteBucketReplication$;\nexports.DeleteBucketReplicationCommand = DeleteBucketReplicationCommand;\nexports.DeleteBucketReplicationRequest$ = DeleteBucketReplicationRequest$;\nexports.DeleteBucketRequest$ = DeleteBucketRequest$;\nexports.DeleteBucketTagging$ = DeleteBucketTagging$;\nexports.DeleteBucketTaggingCommand = DeleteBucketTaggingCommand;\nexports.DeleteBucketTaggingRequest$ = DeleteBucketTaggingRequest$;\nexports.DeleteBucketWebsite$ = DeleteBucketWebsite$;\nexports.DeleteBucketWebsiteCommand = DeleteBucketWebsiteCommand;\nexports.DeleteBucketWebsiteRequest$ = DeleteBucketWebsiteRequest$;\nexports.DeleteMarkerEntry$ = DeleteMarkerEntry$;\nexports.DeleteMarkerReplication$ = DeleteMarkerReplication$;\nexports.DeleteMarkerReplicationStatus = DeleteMarkerReplicationStatus;\nexports.DeleteObject$ = DeleteObject$;\nexports.DeleteObjectCommand = DeleteObjectCommand;\nexports.DeleteObjectOutput$ = DeleteObjectOutput$;\nexports.DeleteObjectRequest$ = DeleteObjectRequest$;\nexports.DeleteObjectTagging$ = DeleteObjectTagging$;\nexports.DeleteObjectTaggingCommand = DeleteObjectTaggingCommand;\nexports.DeleteObjectTaggingOutput$ = DeleteObjectTaggingOutput$;\nexports.DeleteObjectTaggingRequest$ = DeleteObjectTaggingRequest$;\nexports.DeleteObjects$ = DeleteObjects$;\nexports.DeleteObjectsCommand = DeleteObjectsCommand;\nexports.DeleteObjectsOutput$ = DeleteObjectsOutput$;\nexports.DeleteObjectsRequest$ = DeleteObjectsRequest$;\nexports.DeletePublicAccessBlock$ = DeletePublicAccessBlock$;\nexports.DeletePublicAccessBlockCommand = DeletePublicAccessBlockCommand;\nexports.DeletePublicAccessBlockRequest$ = DeletePublicAccessBlockRequest$;\nexports.DeletedObject$ = DeletedObject$;\nexports.Destination$ = Destination$;\nexports.DestinationResult$ = DestinationResult$;\nexports.EncodingType = EncodingType;\nexports.Encryption$ = Encryption$;\nexports.EncryptionConfiguration$ = EncryptionConfiguration$;\nexports.EncryptionType = EncryptionType;\nexports.EncryptionTypeMismatch = EncryptionTypeMismatch;\nexports.EncryptionTypeMismatch$ = EncryptionTypeMismatch$;\nexports.EndEvent$ = EndEvent$;\nexports.ErrorDetails$ = ErrorDetails$;\nexports.ErrorDocument$ = ErrorDocument$;\nexports.Event = Event;\nexports.EventBridgeConfiguration$ = EventBridgeConfiguration$;\nexports.ExistingObjectReplication$ = ExistingObjectReplication$;\nexports.ExistingObjectReplicationStatus = ExistingObjectReplicationStatus;\nexports.ExpirationState = ExpirationState;\nexports.ExpirationStatus = ExpirationStatus;\nexports.ExpressionType = ExpressionType;\nexports.FileHeaderInfo = FileHeaderInfo;\nexports.FilterRule$ = FilterRule$;\nexports.FilterRuleName = FilterRuleName;\nexports.GetBucketAbac$ = GetBucketAbac$;\nexports.GetBucketAbacCommand = GetBucketAbacCommand;\nexports.GetBucketAbacOutput$ = GetBucketAbacOutput$;\nexports.GetBucketAbacRequest$ = GetBucketAbacRequest$;\nexports.GetBucketAccelerateConfiguration$ = GetBucketAccelerateConfiguration$;\nexports.GetBucketAccelerateConfigurationCommand = GetBucketAccelerateConfigurationCommand;\nexports.GetBucketAccelerateConfigurationOutput$ = GetBucketAccelerateConfigurationOutput$;\nexports.GetBucketAccelerateConfigurationRequest$ = GetBucketAccelerateConfigurationRequest$;\nexports.GetBucketAcl$ = GetBucketAcl$;\nexports.GetBucketAclCommand = GetBucketAclCommand;\nexports.GetBucketAclOutput$ = GetBucketAclOutput$;\nexports.GetBucketAclRequest$ = GetBucketAclRequest$;\nexports.GetBucketAnalyticsConfiguration$ = GetBucketAnalyticsConfiguration$;\nexports.GetBucketAnalyticsConfigurationCommand = GetBucketAnalyticsConfigurationCommand;\nexports.GetBucketAnalyticsConfigurationOutput$ = GetBucketAnalyticsConfigurationOutput$;\nexports.GetBucketAnalyticsConfigurationRequest$ = GetBucketAnalyticsConfigurationRequest$;\nexports.GetBucketCors$ = GetBucketCors$;\nexports.GetBucketCorsCommand = GetBucketCorsCommand;\nexports.GetBucketCorsOutput$ = GetBucketCorsOutput$;\nexports.GetBucketCorsRequest$ = GetBucketCorsRequest$;\nexports.GetBucketEncryption$ = GetBucketEncryption$;\nexports.GetBucketEncryptionCommand = GetBucketEncryptionCommand;\nexports.GetBucketEncryptionOutput$ = GetBucketEncryptionOutput$;\nexports.GetBucketEncryptionRequest$ = GetBucketEncryptionRequest$;\nexports.GetBucketIntelligentTieringConfiguration$ = GetBucketIntelligentTieringConfiguration$;\nexports.GetBucketIntelligentTieringConfigurationCommand = GetBucketIntelligentTieringConfigurationCommand;\nexports.GetBucketIntelligentTieringConfigurationOutput$ = GetBucketIntelligentTieringConfigurationOutput$;\nexports.GetBucketIntelligentTieringConfigurationRequest$ = GetBucketIntelligentTieringConfigurationRequest$;\nexports.GetBucketInventoryConfiguration$ = GetBucketInventoryConfiguration$;\nexports.GetBucketInventoryConfigurationCommand = GetBucketInventoryConfigurationCommand;\nexports.GetBucketInventoryConfigurationOutput$ = GetBucketInventoryConfigurationOutput$;\nexports.GetBucketInventoryConfigurationRequest$ = GetBucketInventoryConfigurationRequest$;\nexports.GetBucketLifecycleConfiguration$ = GetBucketLifecycleConfiguration$;\nexports.GetBucketLifecycleConfigurationCommand = GetBucketLifecycleConfigurationCommand;\nexports.GetBucketLifecycleConfigurationOutput$ = GetBucketLifecycleConfigurationOutput$;\nexports.GetBucketLifecycleConfigurationRequest$ = GetBucketLifecycleConfigurationRequest$;\nexports.GetBucketLocation$ = GetBucketLocation$;\nexports.GetBucketLocationCommand = GetBucketLocationCommand;\nexports.GetBucketLocationOutput$ = GetBucketLocationOutput$;\nexports.GetBucketLocationRequest$ = GetBucketLocationRequest$;\nexports.GetBucketLogging$ = GetBucketLogging$;\nexports.GetBucketLoggingCommand = GetBucketLoggingCommand;\nexports.GetBucketLoggingOutput$ = GetBucketLoggingOutput$;\nexports.GetBucketLoggingRequest$ = GetBucketLoggingRequest$;\nexports.GetBucketMetadataConfiguration$ = GetBucketMetadataConfiguration$;\nexports.GetBucketMetadataConfigurationCommand = GetBucketMetadataConfigurationCommand;\nexports.GetBucketMetadataConfigurationOutput$ = GetBucketMetadataConfigurationOutput$;\nexports.GetBucketMetadataConfigurationRequest$ = GetBucketMetadataConfigurationRequest$;\nexports.GetBucketMetadataConfigurationResult$ = GetBucketMetadataConfigurationResult$;\nexports.GetBucketMetadataTableConfiguration$ = GetBucketMetadataTableConfiguration$;\nexports.GetBucketMetadataTableConfigurationCommand = GetBucketMetadataTableConfigurationCommand;\nexports.GetBucketMetadataTableConfigurationOutput$ = GetBucketMetadataTableConfigurationOutput$;\nexports.GetBucketMetadataTableConfigurationRequest$ = GetBucketMetadataTableConfigurationRequest$;\nexports.GetBucketMetadataTableConfigurationResult$ = GetBucketMetadataTableConfigurationResult$;\nexports.GetBucketMetricsConfiguration$ = GetBucketMetricsConfiguration$;\nexports.GetBucketMetricsConfigurationCommand = GetBucketMetricsConfigurationCommand;\nexports.GetBucketMetricsConfigurationOutput$ = GetBucketMetricsConfigurationOutput$;\nexports.GetBucketMetricsConfigurationRequest$ = GetBucketMetricsConfigurationRequest$;\nexports.GetBucketNotificationConfiguration$ = GetBucketNotificationConfiguration$;\nexports.GetBucketNotificationConfigurationCommand = GetBucketNotificationConfigurationCommand;\nexports.GetBucketNotificationConfigurationRequest$ = GetBucketNotificationConfigurationRequest$;\nexports.GetBucketOwnershipControls$ = GetBucketOwnershipControls$;\nexports.GetBucketOwnershipControlsCommand = GetBucketOwnershipControlsCommand;\nexports.GetBucketOwnershipControlsOutput$ = GetBucketOwnershipControlsOutput$;\nexports.GetBucketOwnershipControlsRequest$ = GetBucketOwnershipControlsRequest$;\nexports.GetBucketPolicy$ = GetBucketPolicy$;\nexports.GetBucketPolicyCommand = GetBucketPolicyCommand;\nexports.GetBucketPolicyOutput$ = GetBucketPolicyOutput$;\nexports.GetBucketPolicyRequest$ = GetBucketPolicyRequest$;\nexports.GetBucketPolicyStatus$ = GetBucketPolicyStatus$;\nexports.GetBucketPolicyStatusCommand = GetBucketPolicyStatusCommand;\nexports.GetBucketPolicyStatusOutput$ = GetBucketPolicyStatusOutput$;\nexports.GetBucketPolicyStatusRequest$ = GetBucketPolicyStatusRequest$;\nexports.GetBucketReplication$ = GetBucketReplication$;\nexports.GetBucketReplicationCommand = GetBucketReplicationCommand;\nexports.GetBucketReplicationOutput$ = GetBucketReplicationOutput$;\nexports.GetBucketReplicationRequest$ = GetBucketReplicationRequest$;\nexports.GetBucketRequestPayment$ = GetBucketRequestPayment$;\nexports.GetBucketRequestPaymentCommand = GetBucketRequestPaymentCommand;\nexports.GetBucketRequestPaymentOutput$ = GetBucketRequestPaymentOutput$;\nexports.GetBucketRequestPaymentRequest$ = GetBucketRequestPaymentRequest$;\nexports.GetBucketTagging$ = GetBucketTagging$;\nexports.GetBucketTaggingCommand = GetBucketTaggingCommand;\nexports.GetBucketTaggingOutput$ = GetBucketTaggingOutput$;\nexports.GetBucketTaggingRequest$ = GetBucketTaggingRequest$;\nexports.GetBucketVersioning$ = GetBucketVersioning$;\nexports.GetBucketVersioningCommand = GetBucketVersioningCommand;\nexports.GetBucketVersioningOutput$ = GetBucketVersioningOutput$;\nexports.GetBucketVersioningRequest$ = GetBucketVersioningRequest$;\nexports.GetBucketWebsite$ = GetBucketWebsite$;\nexports.GetBucketWebsiteCommand = GetBucketWebsiteCommand;\nexports.GetBucketWebsiteOutput$ = GetBucketWebsiteOutput$;\nexports.GetBucketWebsiteRequest$ = GetBucketWebsiteRequest$;\nexports.GetObject$ = GetObject$;\nexports.GetObjectAcl$ = GetObjectAcl$;\nexports.GetObjectAclCommand = GetObjectAclCommand;\nexports.GetObjectAclOutput$ = GetObjectAclOutput$;\nexports.GetObjectAclRequest$ = GetObjectAclRequest$;\nexports.GetObjectAttributes$ = GetObjectAttributes$;\nexports.GetObjectAttributesCommand = GetObjectAttributesCommand;\nexports.GetObjectAttributesOutput$ = GetObjectAttributesOutput$;\nexports.GetObjectAttributesParts$ = GetObjectAttributesParts$;\nexports.GetObjectAttributesRequest$ = GetObjectAttributesRequest$;\nexports.GetObjectCommand = GetObjectCommand;\nexports.GetObjectLegalHold$ = GetObjectLegalHold$;\nexports.GetObjectLegalHoldCommand = GetObjectLegalHoldCommand;\nexports.GetObjectLegalHoldOutput$ = GetObjectLegalHoldOutput$;\nexports.GetObjectLegalHoldRequest$ = GetObjectLegalHoldRequest$;\nexports.GetObjectLockConfiguration$ = GetObjectLockConfiguration$;\nexports.GetObjectLockConfigurationCommand = GetObjectLockConfigurationCommand;\nexports.GetObjectLockConfigurationOutput$ = GetObjectLockConfigurationOutput$;\nexports.GetObjectLockConfigurationRequest$ = GetObjectLockConfigurationRequest$;\nexports.GetObjectOutput$ = GetObjectOutput$;\nexports.GetObjectRequest$ = GetObjectRequest$;\nexports.GetObjectRetention$ = GetObjectRetention$;\nexports.GetObjectRetentionCommand = GetObjectRetentionCommand;\nexports.GetObjectRetentionOutput$ = GetObjectRetentionOutput$;\nexports.GetObjectRetentionRequest$ = GetObjectRetentionRequest$;\nexports.GetObjectTagging$ = GetObjectTagging$;\nexports.GetObjectTaggingCommand = GetObjectTaggingCommand;\nexports.GetObjectTaggingOutput$ = GetObjectTaggingOutput$;\nexports.GetObjectTaggingRequest$ = GetObjectTaggingRequest$;\nexports.GetObjectTorrent$ = GetObjectTorrent$;\nexports.GetObjectTorrentCommand = GetObjectTorrentCommand;\nexports.GetObjectTorrentOutput$ = GetObjectTorrentOutput$;\nexports.GetObjectTorrentRequest$ = GetObjectTorrentRequest$;\nexports.GetPublicAccessBlock$ = GetPublicAccessBlock$;\nexports.GetPublicAccessBlockCommand = GetPublicAccessBlockCommand;\nexports.GetPublicAccessBlockOutput$ = GetPublicAccessBlockOutput$;\nexports.GetPublicAccessBlockRequest$ = GetPublicAccessBlockRequest$;\nexports.GlacierJobParameters$ = GlacierJobParameters$;\nexports.Grant$ = Grant$;\nexports.Grantee$ = Grantee$;\nexports.HeadBucket$ = HeadBucket$;\nexports.HeadBucketCommand = HeadBucketCommand;\nexports.HeadBucketOutput$ = HeadBucketOutput$;\nexports.HeadBucketRequest$ = HeadBucketRequest$;\nexports.HeadObject$ = HeadObject$;\nexports.HeadObjectCommand = HeadObjectCommand;\nexports.HeadObjectOutput$ = HeadObjectOutput$;\nexports.HeadObjectRequest$ = HeadObjectRequest$;\nexports.IdempotencyParameterMismatch = IdempotencyParameterMismatch;\nexports.IdempotencyParameterMismatch$ = IdempotencyParameterMismatch$;\nexports.IndexDocument$ = IndexDocument$;\nexports.Initiator$ = Initiator$;\nexports.InputSerialization$ = InputSerialization$;\nexports.IntelligentTieringAccessTier = IntelligentTieringAccessTier;\nexports.IntelligentTieringAndOperator$ = IntelligentTieringAndOperator$;\nexports.IntelligentTieringConfiguration$ = IntelligentTieringConfiguration$;\nexports.IntelligentTieringFilter$ = IntelligentTieringFilter$;\nexports.IntelligentTieringStatus = IntelligentTieringStatus;\nexports.InvalidObjectState = InvalidObjectState;\nexports.InvalidObjectState$ = InvalidObjectState$;\nexports.InvalidRequest = InvalidRequest;\nexports.InvalidRequest$ = InvalidRequest$;\nexports.InvalidWriteOffset = InvalidWriteOffset;\nexports.InvalidWriteOffset$ = InvalidWriteOffset$;\nexports.InventoryConfiguration$ = InventoryConfiguration$;\nexports.InventoryConfigurationState = InventoryConfigurationState;\nexports.InventoryDestination$ = InventoryDestination$;\nexports.InventoryEncryption$ = InventoryEncryption$;\nexports.InventoryFilter$ = InventoryFilter$;\nexports.InventoryFormat = InventoryFormat;\nexports.InventoryFrequency = InventoryFrequency;\nexports.InventoryIncludedObjectVersions = InventoryIncludedObjectVersions;\nexports.InventoryOptionalField = InventoryOptionalField;\nexports.InventoryS3BucketDestination$ = InventoryS3BucketDestination$;\nexports.InventorySchedule$ = InventorySchedule$;\nexports.InventoryTableConfiguration$ = InventoryTableConfiguration$;\nexports.InventoryTableConfigurationResult$ = InventoryTableConfigurationResult$;\nexports.InventoryTableConfigurationUpdates$ = InventoryTableConfigurationUpdates$;\nexports.JSONInput$ = JSONInput$;\nexports.JSONOutput$ = JSONOutput$;\nexports.JSONType = JSONType;\nexports.JournalTableConfiguration$ = JournalTableConfiguration$;\nexports.JournalTableConfigurationResult$ = JournalTableConfigurationResult$;\nexports.JournalTableConfigurationUpdates$ = JournalTableConfigurationUpdates$;\nexports.LambdaFunctionConfiguration$ = LambdaFunctionConfiguration$;\nexports.LifecycleExpiration$ = LifecycleExpiration$;\nexports.LifecycleRule$ = LifecycleRule$;\nexports.LifecycleRuleAndOperator$ = LifecycleRuleAndOperator$;\nexports.LifecycleRuleFilter$ = LifecycleRuleFilter$;\nexports.ListBucketAnalyticsConfigurations$ = ListBucketAnalyticsConfigurations$;\nexports.ListBucketAnalyticsConfigurationsCommand = ListBucketAnalyticsConfigurationsCommand;\nexports.ListBucketAnalyticsConfigurationsOutput$ = ListBucketAnalyticsConfigurationsOutput$;\nexports.ListBucketAnalyticsConfigurationsRequest$ = ListBucketAnalyticsConfigurationsRequest$;\nexports.ListBucketIntelligentTieringConfigurations$ = ListBucketIntelligentTieringConfigurations$;\nexports.ListBucketIntelligentTieringConfigurationsCommand = ListBucketIntelligentTieringConfigurationsCommand;\nexports.ListBucketIntelligentTieringConfigurationsOutput$ = ListBucketIntelligentTieringConfigurationsOutput$;\nexports.ListBucketIntelligentTieringConfigurationsRequest$ = ListBucketIntelligentTieringConfigurationsRequest$;\nexports.ListBucketInventoryConfigurations$ = ListBucketInventoryConfigurations$;\nexports.ListBucketInventoryConfigurationsCommand = ListBucketInventoryConfigurationsCommand;\nexports.ListBucketInventoryConfigurationsOutput$ = ListBucketInventoryConfigurationsOutput$;\nexports.ListBucketInventoryConfigurationsRequest$ = ListBucketInventoryConfigurationsRequest$;\nexports.ListBucketMetricsConfigurations$ = ListBucketMetricsConfigurations$;\nexports.ListBucketMetricsConfigurationsCommand = ListBucketMetricsConfigurationsCommand;\nexports.ListBucketMetricsConfigurationsOutput$ = ListBucketMetricsConfigurationsOutput$;\nexports.ListBucketMetricsConfigurationsRequest$ = ListBucketMetricsConfigurationsRequest$;\nexports.ListBuckets$ = ListBuckets$;\nexports.ListBucketsCommand = ListBucketsCommand;\nexports.ListBucketsOutput$ = ListBucketsOutput$;\nexports.ListBucketsRequest$ = ListBucketsRequest$;\nexports.ListDirectoryBuckets$ = ListDirectoryBuckets$;\nexports.ListDirectoryBucketsCommand = ListDirectoryBucketsCommand;\nexports.ListDirectoryBucketsOutput$ = ListDirectoryBucketsOutput$;\nexports.ListDirectoryBucketsRequest$ = ListDirectoryBucketsRequest$;\nexports.ListMultipartUploads$ = ListMultipartUploads$;\nexports.ListMultipartUploadsCommand = ListMultipartUploadsCommand;\nexports.ListMultipartUploadsOutput$ = ListMultipartUploadsOutput$;\nexports.ListMultipartUploadsRequest$ = ListMultipartUploadsRequest$;\nexports.ListObjectVersions$ = ListObjectVersions$;\nexports.ListObjectVersionsCommand = ListObjectVersionsCommand;\nexports.ListObjectVersionsOutput$ = ListObjectVersionsOutput$;\nexports.ListObjectVersionsRequest$ = ListObjectVersionsRequest$;\nexports.ListObjects$ = ListObjects$;\nexports.ListObjectsCommand = ListObjectsCommand;\nexports.ListObjectsOutput$ = ListObjectsOutput$;\nexports.ListObjectsRequest$ = ListObjectsRequest$;\nexports.ListObjectsV2$ = ListObjectsV2$;\nexports.ListObjectsV2Command = ListObjectsV2Command;\nexports.ListObjectsV2Output$ = ListObjectsV2Output$;\nexports.ListObjectsV2Request$ = ListObjectsV2Request$;\nexports.ListParts$ = ListParts$;\nexports.ListPartsCommand = ListPartsCommand;\nexports.ListPartsOutput$ = ListPartsOutput$;\nexports.ListPartsRequest$ = ListPartsRequest$;\nexports.LocationInfo$ = LocationInfo$;\nexports.LocationType = LocationType;\nexports.LoggingEnabled$ = LoggingEnabled$;\nexports.MFADelete = MFADelete;\nexports.MFADeleteStatus = MFADeleteStatus;\nexports.MetadataConfiguration$ = MetadataConfiguration$;\nexports.MetadataConfigurationResult$ = MetadataConfigurationResult$;\nexports.MetadataDirective = MetadataDirective;\nexports.MetadataEntry$ = MetadataEntry$;\nexports.MetadataTableConfiguration$ = MetadataTableConfiguration$;\nexports.MetadataTableConfigurationResult$ = MetadataTableConfigurationResult$;\nexports.MetadataTableEncryptionConfiguration$ = MetadataTableEncryptionConfiguration$;\nexports.Metrics$ = Metrics$;\nexports.MetricsAndOperator$ = MetricsAndOperator$;\nexports.MetricsConfiguration$ = MetricsConfiguration$;\nexports.MetricsFilter$ = MetricsFilter$;\nexports.MetricsStatus = MetricsStatus;\nexports.MultipartUpload$ = MultipartUpload$;\nexports.NoSuchBucket = NoSuchBucket;\nexports.NoSuchBucket$ = NoSuchBucket$;\nexports.NoSuchKey = NoSuchKey;\nexports.NoSuchKey$ = NoSuchKey$;\nexports.NoSuchUpload = NoSuchUpload;\nexports.NoSuchUpload$ = NoSuchUpload$;\nexports.NoncurrentVersionExpiration$ = NoncurrentVersionExpiration$;\nexports.NoncurrentVersionTransition$ = NoncurrentVersionTransition$;\nexports.NotFound = NotFound;\nexports.NotFound$ = NotFound$;\nexports.NotificationConfiguration$ = NotificationConfiguration$;\nexports.NotificationConfigurationFilter$ = NotificationConfigurationFilter$;\nexports.ObjectAlreadyInActiveTierError = ObjectAlreadyInActiveTierError;\nexports.ObjectAlreadyInActiveTierError$ = ObjectAlreadyInActiveTierError$;\nexports.ObjectAttributes = ObjectAttributes;\nexports.ObjectCannedACL = ObjectCannedACL;\nexports.ObjectEncryption$ = ObjectEncryption$;\nexports.ObjectIdentifier$ = ObjectIdentifier$;\nexports.ObjectLockConfiguration$ = ObjectLockConfiguration$;\nexports.ObjectLockEnabled = ObjectLockEnabled;\nexports.ObjectLockLegalHold$ = ObjectLockLegalHold$;\nexports.ObjectLockLegalHoldStatus = ObjectLockLegalHoldStatus;\nexports.ObjectLockMode = ObjectLockMode;\nexports.ObjectLockRetention$ = ObjectLockRetention$;\nexports.ObjectLockRetentionMode = ObjectLockRetentionMode;\nexports.ObjectLockRule$ = ObjectLockRule$;\nexports.ObjectNotInActiveTierError = ObjectNotInActiveTierError;\nexports.ObjectNotInActiveTierError$ = ObjectNotInActiveTierError$;\nexports.ObjectOwnership = ObjectOwnership;\nexports.ObjectPart$ = ObjectPart$;\nexports.ObjectStorageClass = ObjectStorageClass;\nexports.ObjectVersion$ = ObjectVersion$;\nexports.ObjectVersionStorageClass = ObjectVersionStorageClass;\nexports.OptionalObjectAttributes = OptionalObjectAttributes;\nexports.OutputLocation$ = OutputLocation$;\nexports.OutputSerialization$ = OutputSerialization$;\nexports.Owner$ = Owner$;\nexports.OwnerOverride = OwnerOverride;\nexports.OwnershipControls$ = OwnershipControls$;\nexports.OwnershipControlsRule$ = OwnershipControlsRule$;\nexports.ParquetInput$ = ParquetInput$;\nexports.Part$ = Part$;\nexports.PartitionDateSource = PartitionDateSource;\nexports.PartitionedPrefix$ = PartitionedPrefix$;\nexports.Payer = Payer;\nexports.Permission = Permission;\nexports.PolicyStatus$ = PolicyStatus$;\nexports.Progress$ = Progress$;\nexports.ProgressEvent$ = ProgressEvent$;\nexports.Protocol = Protocol;\nexports.PublicAccessBlockConfiguration$ = PublicAccessBlockConfiguration$;\nexports.PutBucketAbac$ = PutBucketAbac$;\nexports.PutBucketAbacCommand = PutBucketAbacCommand;\nexports.PutBucketAbacRequest$ = PutBucketAbacRequest$;\nexports.PutBucketAccelerateConfiguration$ = PutBucketAccelerateConfiguration$;\nexports.PutBucketAccelerateConfigurationCommand = PutBucketAccelerateConfigurationCommand;\nexports.PutBucketAccelerateConfigurationRequest$ = PutBucketAccelerateConfigurationRequest$;\nexports.PutBucketAcl$ = PutBucketAcl$;\nexports.PutBucketAclCommand = PutBucketAclCommand;\nexports.PutBucketAclRequest$ = PutBucketAclRequest$;\nexports.PutBucketAnalyticsConfiguration$ = PutBucketAnalyticsConfiguration$;\nexports.PutBucketAnalyticsConfigurationCommand = PutBucketAnalyticsConfigurationCommand;\nexports.PutBucketAnalyticsConfigurationRequest$ = PutBucketAnalyticsConfigurationRequest$;\nexports.PutBucketCors$ = PutBucketCors$;\nexports.PutBucketCorsCommand = PutBucketCorsCommand;\nexports.PutBucketCorsRequest$ = PutBucketCorsRequest$;\nexports.PutBucketEncryption$ = PutBucketEncryption$;\nexports.PutBucketEncryptionCommand = PutBucketEncryptionCommand;\nexports.PutBucketEncryptionRequest$ = PutBucketEncryptionRequest$;\nexports.PutBucketIntelligentTieringConfiguration$ = PutBucketIntelligentTieringConfiguration$;\nexports.PutBucketIntelligentTieringConfigurationCommand = PutBucketIntelligentTieringConfigurationCommand;\nexports.PutBucketIntelligentTieringConfigurationRequest$ = PutBucketIntelligentTieringConfigurationRequest$;\nexports.PutBucketInventoryConfiguration$ = PutBucketInventoryConfiguration$;\nexports.PutBucketInventoryConfigurationCommand = PutBucketInventoryConfigurationCommand;\nexports.PutBucketInventoryConfigurationRequest$ = PutBucketInventoryConfigurationRequest$;\nexports.PutBucketLifecycleConfiguration$ = PutBucketLifecycleConfiguration$;\nexports.PutBucketLifecycleConfigurationCommand = PutBucketLifecycleConfigurationCommand;\nexports.PutBucketLifecycleConfigurationOutput$ = PutBucketLifecycleConfigurationOutput$;\nexports.PutBucketLifecycleConfigurationRequest$ = PutBucketLifecycleConfigurationRequest$;\nexports.PutBucketLogging$ = PutBucketLogging$;\nexports.PutBucketLoggingCommand = PutBucketLoggingCommand;\nexports.PutBucketLoggingRequest$ = PutBucketLoggingRequest$;\nexports.PutBucketMetricsConfiguration$ = PutBucketMetricsConfiguration$;\nexports.PutBucketMetricsConfigurationCommand = PutBucketMetricsConfigurationCommand;\nexports.PutBucketMetricsConfigurationRequest$ = PutBucketMetricsConfigurationRequest$;\nexports.PutBucketNotificationConfiguration$ = PutBucketNotificationConfiguration$;\nexports.PutBucketNotificationConfigurationCommand = PutBucketNotificationConfigurationCommand;\nexports.PutBucketNotificationConfigurationRequest$ = PutBucketNotificationConfigurationRequest$;\nexports.PutBucketOwnershipControls$ = PutBucketOwnershipControls$;\nexports.PutBucketOwnershipControlsCommand = PutBucketOwnershipControlsCommand;\nexports.PutBucketOwnershipControlsRequest$ = PutBucketOwnershipControlsRequest$;\nexports.PutBucketPolicy$ = PutBucketPolicy$;\nexports.PutBucketPolicyCommand = PutBucketPolicyCommand;\nexports.PutBucketPolicyRequest$ = PutBucketPolicyRequest$;\nexports.PutBucketReplication$ = PutBucketReplication$;\nexports.PutBucketReplicationCommand = PutBucketReplicationCommand;\nexports.PutBucketReplicationRequest$ = PutBucketReplicationRequest$;\nexports.PutBucketRequestPayment$ = PutBucketRequestPayment$;\nexports.PutBucketRequestPaymentCommand = PutBucketRequestPaymentCommand;\nexports.PutBucketRequestPaymentRequest$ = PutBucketRequestPaymentRequest$;\nexports.PutBucketTagging$ = PutBucketTagging$;\nexports.PutBucketTaggingCommand = PutBucketTaggingCommand;\nexports.PutBucketTaggingRequest$ = PutBucketTaggingRequest$;\nexports.PutBucketVersioning$ = PutBucketVersioning$;\nexports.PutBucketVersioningCommand = PutBucketVersioningCommand;\nexports.PutBucketVersioningRequest$ = PutBucketVersioningRequest$;\nexports.PutBucketWebsite$ = PutBucketWebsite$;\nexports.PutBucketWebsiteCommand = PutBucketWebsiteCommand;\nexports.PutBucketWebsiteRequest$ = PutBucketWebsiteRequest$;\nexports.PutObject$ = PutObject$;\nexports.PutObjectAcl$ = PutObjectAcl$;\nexports.PutObjectAclCommand = PutObjectAclCommand;\nexports.PutObjectAclOutput$ = PutObjectAclOutput$;\nexports.PutObjectAclRequest$ = PutObjectAclRequest$;\nexports.PutObjectCommand = PutObjectCommand;\nexports.PutObjectLegalHold$ = PutObjectLegalHold$;\nexports.PutObjectLegalHoldCommand = PutObjectLegalHoldCommand;\nexports.PutObjectLegalHoldOutput$ = PutObjectLegalHoldOutput$;\nexports.PutObjectLegalHoldRequest$ = PutObjectLegalHoldRequest$;\nexports.PutObjectLockConfiguration$ = PutObjectLockConfiguration$;\nexports.PutObjectLockConfigurationCommand = PutObjectLockConfigurationCommand;\nexports.PutObjectLockConfigurationOutput$ = PutObjectLockConfigurationOutput$;\nexports.PutObjectLockConfigurationRequest$ = PutObjectLockConfigurationRequest$;\nexports.PutObjectOutput$ = PutObjectOutput$;\nexports.PutObjectRequest$ = PutObjectRequest$;\nexports.PutObjectRetention$ = PutObjectRetention$;\nexports.PutObjectRetentionCommand = PutObjectRetentionCommand;\nexports.PutObjectRetentionOutput$ = PutObjectRetentionOutput$;\nexports.PutObjectRetentionRequest$ = PutObjectRetentionRequest$;\nexports.PutObjectTagging$ = PutObjectTagging$;\nexports.PutObjectTaggingCommand = PutObjectTaggingCommand;\nexports.PutObjectTaggingOutput$ = PutObjectTaggingOutput$;\nexports.PutObjectTaggingRequest$ = PutObjectTaggingRequest$;\nexports.PutPublicAccessBlock$ = PutPublicAccessBlock$;\nexports.PutPublicAccessBlockCommand = PutPublicAccessBlockCommand;\nexports.PutPublicAccessBlockRequest$ = PutPublicAccessBlockRequest$;\nexports.QueueConfiguration$ = QueueConfiguration$;\nexports.QuoteFields = QuoteFields;\nexports.RecordExpiration$ = RecordExpiration$;\nexports.RecordsEvent$ = RecordsEvent$;\nexports.Redirect$ = Redirect$;\nexports.RedirectAllRequestsTo$ = RedirectAllRequestsTo$;\nexports.RenameObject$ = RenameObject$;\nexports.RenameObjectCommand = RenameObjectCommand;\nexports.RenameObjectOutput$ = RenameObjectOutput$;\nexports.RenameObjectRequest$ = RenameObjectRequest$;\nexports.ReplicaModifications$ = ReplicaModifications$;\nexports.ReplicaModificationsStatus = ReplicaModificationsStatus;\nexports.ReplicationConfiguration$ = ReplicationConfiguration$;\nexports.ReplicationRule$ = ReplicationRule$;\nexports.ReplicationRuleAndOperator$ = ReplicationRuleAndOperator$;\nexports.ReplicationRuleFilter$ = ReplicationRuleFilter$;\nexports.ReplicationRuleStatus = ReplicationRuleStatus;\nexports.ReplicationStatus = ReplicationStatus;\nexports.ReplicationTime$ = ReplicationTime$;\nexports.ReplicationTimeStatus = ReplicationTimeStatus;\nexports.ReplicationTimeValue$ = ReplicationTimeValue$;\nexports.RequestCharged = RequestCharged;\nexports.RequestPayer = RequestPayer;\nexports.RequestPaymentConfiguration$ = RequestPaymentConfiguration$;\nexports.RequestProgress$ = RequestProgress$;\nexports.RestoreObject$ = RestoreObject$;\nexports.RestoreObjectCommand = RestoreObjectCommand;\nexports.RestoreObjectOutput$ = RestoreObjectOutput$;\nexports.RestoreObjectRequest$ = RestoreObjectRequest$;\nexports.RestoreRequest$ = RestoreRequest$;\nexports.RestoreRequestType = RestoreRequestType;\nexports.RestoreStatus$ = RestoreStatus$;\nexports.RoutingRule$ = RoutingRule$;\nexports.S3 = S3;\nexports.S3Client = S3Client;\nexports.S3KeyFilter$ = S3KeyFilter$;\nexports.S3Location$ = S3Location$;\nexports.S3ServiceException = S3ServiceException;\nexports.S3ServiceException$ = S3ServiceException$;\nexports.S3TablesBucketType = S3TablesBucketType;\nexports.S3TablesDestination$ = S3TablesDestination$;\nexports.S3TablesDestinationResult$ = S3TablesDestinationResult$;\nexports.SSEKMS$ = SSEKMS$;\nexports.SSEKMSEncryption$ = SSEKMSEncryption$;\nexports.SSES3$ = SSES3$;\nexports.ScanRange$ = ScanRange$;\nexports.SelectObjectContent$ = SelectObjectContent$;\nexports.SelectObjectContentCommand = SelectObjectContentCommand;\nexports.SelectObjectContentEventStream$ = SelectObjectContentEventStream$;\nexports.SelectObjectContentOutput$ = SelectObjectContentOutput$;\nexports.SelectObjectContentRequest$ = SelectObjectContentRequest$;\nexports.SelectParameters$ = SelectParameters$;\nexports.ServerSideEncryption = ServerSideEncryption;\nexports.ServerSideEncryptionByDefault$ = ServerSideEncryptionByDefault$;\nexports.ServerSideEncryptionConfiguration$ = ServerSideEncryptionConfiguration$;\nexports.ServerSideEncryptionRule$ = ServerSideEncryptionRule$;\nexports.SessionCredentials$ = SessionCredentials$;\nexports.SessionMode = SessionMode;\nexports.SimplePrefix$ = SimplePrefix$;\nexports.SourceSelectionCriteria$ = SourceSelectionCriteria$;\nexports.SseKmsEncryptedObjects$ = SseKmsEncryptedObjects$;\nexports.SseKmsEncryptedObjectsStatus = SseKmsEncryptedObjectsStatus;\nexports.Stats$ = Stats$;\nexports.StatsEvent$ = StatsEvent$;\nexports.StorageClass = StorageClass;\nexports.StorageClassAnalysis$ = StorageClassAnalysis$;\nexports.StorageClassAnalysisDataExport$ = StorageClassAnalysisDataExport$;\nexports.StorageClassAnalysisSchemaVersion = StorageClassAnalysisSchemaVersion;\nexports.TableSseAlgorithm = TableSseAlgorithm;\nexports.Tag$ = Tag$;\nexports.Tagging$ = Tagging$;\nexports.TaggingDirective = TaggingDirective;\nexports.TargetGrant$ = TargetGrant$;\nexports.TargetObjectKeyFormat$ = TargetObjectKeyFormat$;\nexports.Tier = Tier;\nexports.Tiering$ = Tiering$;\nexports.TooManyParts = TooManyParts;\nexports.TooManyParts$ = TooManyParts$;\nexports.TopicConfiguration$ = TopicConfiguration$;\nexports.Transition$ = Transition$;\nexports.TransitionDefaultMinimumObjectSize = TransitionDefaultMinimumObjectSize;\nexports.TransitionStorageClass = TransitionStorageClass;\nexports.Type = Type;\nexports.UpdateBucketMetadataInventoryTableConfiguration$ = UpdateBucketMetadataInventoryTableConfiguration$;\nexports.UpdateBucketMetadataInventoryTableConfigurationCommand = UpdateBucketMetadataInventoryTableConfigurationCommand;\nexports.UpdateBucketMetadataInventoryTableConfigurationRequest$ = UpdateBucketMetadataInventoryTableConfigurationRequest$;\nexports.UpdateBucketMetadataJournalTableConfiguration$ = UpdateBucketMetadataJournalTableConfiguration$;\nexports.UpdateBucketMetadataJournalTableConfigurationCommand = UpdateBucketMetadataJournalTableConfigurationCommand;\nexports.UpdateBucketMetadataJournalTableConfigurationRequest$ = UpdateBucketMetadataJournalTableConfigurationRequest$;\nexports.UpdateObjectEncryption$ = UpdateObjectEncryption$;\nexports.UpdateObjectEncryptionCommand = UpdateObjectEncryptionCommand;\nexports.UpdateObjectEncryptionRequest$ = UpdateObjectEncryptionRequest$;\nexports.UpdateObjectEncryptionResponse$ = UpdateObjectEncryptionResponse$;\nexports.UploadPart$ = UploadPart$;\nexports.UploadPartCommand = UploadPartCommand;\nexports.UploadPartCopy$ = UploadPartCopy$;\nexports.UploadPartCopyCommand = UploadPartCopyCommand;\nexports.UploadPartCopyOutput$ = UploadPartCopyOutput$;\nexports.UploadPartCopyRequest$ = UploadPartCopyRequest$;\nexports.UploadPartOutput$ = UploadPartOutput$;\nexports.UploadPartRequest$ = UploadPartRequest$;\nexports.VersioningConfiguration$ = VersioningConfiguration$;\nexports.WebsiteConfiguration$ = WebsiteConfiguration$;\nexports.WriteGetObjectResponse$ = WriteGetObjectResponse$;\nexports.WriteGetObjectResponseCommand = WriteGetObjectResponseCommand;\nexports.WriteGetObjectResponseRequest$ = WriteGetObjectResponseRequest$;\nexports._Error$ = _Error$;\nexports._Object$ = _Object$;\nexports.paginateListBuckets = paginateListBuckets;\nexports.paginateListDirectoryBuckets = paginateListDirectoryBuckets;\nexports.paginateListObjectsV2 = paginateListObjectsV2;\nexports.paginateListParts = paginateListParts;\nexports.waitForBucketExists = waitForBucketExists;\nexports.waitForBucketNotExists = waitForBucketNotExists;\nexports.waitForObjectExists = waitForObjectExists;\nexports.waitForObjectNotExists = waitForObjectNotExists;\nexports.waitUntilBucketExists = waitUntilBucketExists;\nexports.waitUntilBucketNotExists = waitUntilBucketNotExists;\nexports.waitUntilObjectExists = waitUntilObjectExists;\nexports.waitUntilObjectNotExists = waitUntilObjectNotExists;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getRuntimeConfig = void 0;\nconst tslib_1 = require(\"tslib\");\nconst package_json_1 = tslib_1.__importDefault(require(\"../package.json\"));\nconst core_1 = require(\"@aws-sdk/core\");\nconst credential_provider_node_1 = require(\"@aws-sdk/credential-provider-node\");\nconst middleware_bucket_endpoint_1 = require(\"@aws-sdk/middleware-bucket-endpoint\");\nconst middleware_flexible_checksums_1 = require(\"@aws-sdk/middleware-flexible-checksums\");\nconst middleware_sdk_s3_1 = require(\"@aws-sdk/middleware-sdk-s3\");\nconst util_user_agent_node_1 = require(\"@aws-sdk/util-user-agent-node\");\nconst config_resolver_1 = require(\"@smithy/config-resolver\");\nconst eventstream_serde_node_1 = require(\"@smithy/eventstream-serde-node\");\nconst hash_node_1 = require(\"@smithy/hash-node\");\nconst hash_stream_node_1 = require(\"@smithy/hash-stream-node\");\nconst middleware_retry_1 = require(\"@smithy/middleware-retry\");\nconst node_config_provider_1 = require(\"@smithy/node-config-provider\");\nconst node_http_handler_1 = require(\"@smithy/node-http-handler\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nconst util_body_length_node_1 = require(\"@smithy/util-body-length-node\");\nconst util_defaults_mode_node_1 = require(\"@smithy/util-defaults-mode-node\");\nconst util_retry_1 = require(\"@smithy/util-retry\");\nconst runtimeConfig_shared_1 = require(\"./runtimeConfig.shared\");\nconst getRuntimeConfig = (config) => {\n    (0, smithy_client_1.emitWarningIfUnsupportedVersion)(process.version);\n    const defaultsMode = (0, util_defaults_mode_node_1.resolveDefaultsModeConfig)(config);\n    const defaultConfigProvider = () => defaultsMode().then(smithy_client_1.loadConfigsForDefaultMode);\n    const clientSharedValues = (0, runtimeConfig_shared_1.getRuntimeConfig)(config);\n    (0, core_1.emitWarningIfUnsupportedVersion)(process.version);\n    const loaderConfig = {\n        profile: config?.profile,\n        logger: clientSharedValues.logger,\n    };\n    return {\n        ...clientSharedValues,\n        ...config,\n        runtime: \"node\",\n        defaultsMode,\n        authSchemePreference: config?.authSchemePreference ?? (0, node_config_provider_1.loadConfig)(core_1.NODE_AUTH_SCHEME_PREFERENCE_OPTIONS, loaderConfig),\n        bodyLengthChecker: config?.bodyLengthChecker ?? util_body_length_node_1.calculateBodyLength,\n        credentialDefaultProvider: config?.credentialDefaultProvider ?? credential_provider_node_1.defaultProvider,\n        defaultUserAgentProvider: config?.defaultUserAgentProvider ?? (0, util_user_agent_node_1.createDefaultUserAgentProvider)({ serviceId: clientSharedValues.serviceId, clientVersion: package_json_1.default.version }),\n        disableS3ExpressSessionAuth: config?.disableS3ExpressSessionAuth ?? (0, node_config_provider_1.loadConfig)(middleware_sdk_s3_1.NODE_DISABLE_S3_EXPRESS_SESSION_AUTH_OPTIONS, loaderConfig),\n        eventStreamSerdeProvider: config?.eventStreamSerdeProvider ?? eventstream_serde_node_1.eventStreamSerdeProvider,\n        maxAttempts: config?.maxAttempts ?? (0, node_config_provider_1.loadConfig)(middleware_retry_1.NODE_MAX_ATTEMPT_CONFIG_OPTIONS, config),\n        md5: config?.md5 ?? hash_node_1.Hash.bind(null, \"md5\"),\n        region: config?.region ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_REGION_CONFIG_OPTIONS, { ...config_resolver_1.NODE_REGION_CONFIG_FILE_OPTIONS, ...loaderConfig }),\n        requestChecksumCalculation: config?.requestChecksumCalculation ?? (0, node_config_provider_1.loadConfig)(middleware_flexible_checksums_1.NODE_REQUEST_CHECKSUM_CALCULATION_CONFIG_OPTIONS, loaderConfig),\n        requestHandler: node_http_handler_1.NodeHttpHandler.create(config?.requestHandler ?? defaultConfigProvider),\n        responseChecksumValidation: config?.responseChecksumValidation ?? (0, node_config_provider_1.loadConfig)(middleware_flexible_checksums_1.NODE_RESPONSE_CHECKSUM_VALIDATION_CONFIG_OPTIONS, loaderConfig),\n        retryMode: config?.retryMode ??\n            (0, node_config_provider_1.loadConfig)({\n                ...middleware_retry_1.NODE_RETRY_MODE_CONFIG_OPTIONS,\n                default: async () => (await defaultConfigProvider()).retryMode || util_retry_1.DEFAULT_RETRY_MODE,\n            }, config),\n        sha1: config?.sha1 ?? hash_node_1.Hash.bind(null, \"sha1\"),\n        sha256: config?.sha256 ?? hash_node_1.Hash.bind(null, \"sha256\"),\n        sigv4aSigningRegionSet: config?.sigv4aSigningRegionSet ?? (0, node_config_provider_1.loadConfig)(core_1.NODE_SIGV4A_CONFIG_OPTIONS, loaderConfig),\n        streamCollector: config?.streamCollector ?? node_http_handler_1.streamCollector,\n        streamHasher: config?.streamHasher ?? hash_stream_node_1.readableStreamHasher,\n        useArnRegion: config?.useArnRegion ?? (0, node_config_provider_1.loadConfig)(middleware_bucket_endpoint_1.NODE_USE_ARN_REGION_CONFIG_OPTIONS, loaderConfig),\n        useDualstackEndpoint: config?.useDualstackEndpoint ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_USE_DUALSTACK_ENDPOINT_CONFIG_OPTIONS, loaderConfig),\n        useFipsEndpoint: config?.useFipsEndpoint ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_USE_FIPS_ENDPOINT_CONFIG_OPTIONS, loaderConfig),\n        userAgentAppId: config?.userAgentAppId ?? (0, node_config_provider_1.loadConfig)(util_user_agent_node_1.NODE_APP_ID_CONFIG_OPTIONS, loaderConfig),\n    };\n};\nexports.getRuntimeConfig = getRuntimeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getRuntimeConfig = void 0;\nconst core_1 = require(\"@aws-sdk/core\");\nconst protocols_1 = require(\"@aws-sdk/core/protocols\");\nconst signature_v4_multi_region_1 = require(\"@aws-sdk/signature-v4-multi-region\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nconst url_parser_1 = require(\"@smithy/url-parser\");\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst util_stream_1 = require(\"@smithy/util-stream\");\nconst util_utf8_1 = require(\"@smithy/util-utf8\");\nconst httpAuthSchemeProvider_1 = require(\"./auth/httpAuthSchemeProvider\");\nconst endpointResolver_1 = require(\"./endpoint/endpointResolver\");\nconst getRuntimeConfig = (config) => {\n    return {\n        apiVersion: \"2006-03-01\",\n        base64Decoder: config?.base64Decoder ?? util_base64_1.fromBase64,\n        base64Encoder: config?.base64Encoder ?? util_base64_1.toBase64,\n        disableHostPrefix: config?.disableHostPrefix ?? false,\n        endpointProvider: config?.endpointProvider ?? endpointResolver_1.defaultEndpointResolver,\n        extensions: config?.extensions ?? [],\n        getAwsChunkedEncodingStream: config?.getAwsChunkedEncodingStream ?? util_stream_1.getAwsChunkedEncodingStream,\n        httpAuthSchemeProvider: config?.httpAuthSchemeProvider ?? httpAuthSchemeProvider_1.defaultS3HttpAuthSchemeProvider,\n        httpAuthSchemes: config?.httpAuthSchemes ?? [\n            {\n                schemeId: \"aws.auth#sigv4\",\n                identityProvider: (ipc) => ipc.getIdentityProvider(\"aws.auth#sigv4\"),\n                signer: new core_1.AwsSdkSigV4Signer(),\n            },\n            {\n                schemeId: \"aws.auth#sigv4a\",\n                identityProvider: (ipc) => ipc.getIdentityProvider(\"aws.auth#sigv4a\"),\n                signer: new core_1.AwsSdkSigV4ASigner(),\n            },\n        ],\n        logger: config?.logger ?? new smithy_client_1.NoOpLogger(),\n        protocol: config?.protocol ?? protocols_1.AwsRestXmlProtocol,\n        protocolSettings: config?.protocolSettings ?? {\n            defaultNamespace: \"com.amazonaws.s3\",\n            xmlNamespace: \"http://s3.amazonaws.com/doc/2006-03-01/\",\n            version: \"2006-03-01\",\n            serviceTarget: \"AmazonS3\",\n        },\n        sdkStreamMixin: config?.sdkStreamMixin ?? util_stream_1.sdkStreamMixin,\n        serviceId: config?.serviceId ?? \"S3\",\n        signerConstructor: config?.signerConstructor ?? signature_v4_multi_region_1.SignatureV4MultiRegion,\n        signingEscapePath: config?.signingEscapePath ?? false,\n        urlParser: config?.urlParser ?? url_parser_1.parseUrl,\n        useArnRegion: config?.useArnRegion ?? undefined,\n        utf8Decoder: config?.utf8Decoder ?? util_utf8_1.fromUtf8,\n        utf8Encoder: config?.utf8Encoder ?? util_utf8_1.toUtf8,\n    };\n};\nexports.getRuntimeConfig = getRuntimeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.STSClient = exports.__Client = void 0;\nconst middleware_host_header_1 = require(\"@aws-sdk/middleware-host-header\");\nconst middleware_logger_1 = require(\"@aws-sdk/middleware-logger\");\nconst middleware_recursion_detection_1 = require(\"@aws-sdk/middleware-recursion-detection\");\nconst middleware_user_agent_1 = require(\"@aws-sdk/middleware-user-agent\");\nconst config_resolver_1 = require(\"@smithy/config-resolver\");\nconst core_1 = require(\"@smithy/core\");\nconst schema_1 = require(\"@smithy/core/schema\");\nconst middleware_content_length_1 = require(\"@smithy/middleware-content-length\");\nconst middleware_endpoint_1 = require(\"@smithy/middleware-endpoint\");\nconst middleware_retry_1 = require(\"@smithy/middleware-retry\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nObject.defineProperty(exports, \"__Client\", { enumerable: true, get: function () { return smithy_client_1.Client; } });\nconst httpAuthSchemeProvider_1 = require(\"./auth/httpAuthSchemeProvider\");\nconst EndpointParameters_1 = require(\"./endpoint/EndpointParameters\");\nconst runtimeConfig_1 = require(\"./runtimeConfig\");\nconst runtimeExtensions_1 = require(\"./runtimeExtensions\");\nclass STSClient extends smithy_client_1.Client {\n    config;\n    constructor(...[configuration]) {\n        const _config_0 = (0, runtimeConfig_1.getRuntimeConfig)(configuration || {});\n        super(_config_0);\n        this.initConfig = _config_0;\n        const _config_1 = (0, EndpointParameters_1.resolveClientEndpointParameters)(_config_0);\n        const _config_2 = (0, middleware_user_agent_1.resolveUserAgentConfig)(_config_1);\n        const _config_3 = (0, middleware_retry_1.resolveRetryConfig)(_config_2);\n        const _config_4 = (0, config_resolver_1.resolveRegionConfig)(_config_3);\n        const _config_5 = (0, middleware_host_header_1.resolveHostHeaderConfig)(_config_4);\n        const _config_6 = (0, middleware_endpoint_1.resolveEndpointConfig)(_config_5);\n        const _config_7 = (0, httpAuthSchemeProvider_1.resolveHttpAuthSchemeConfig)(_config_6);\n        const _config_8 = (0, runtimeExtensions_1.resolveRuntimeExtensions)(_config_7, configuration?.extensions || []);\n        this.config = _config_8;\n        this.middlewareStack.use((0, schema_1.getSchemaSerdePlugin)(this.config));\n        this.middlewareStack.use((0, middleware_user_agent_1.getUserAgentPlugin)(this.config));\n        this.middlewareStack.use((0, middleware_retry_1.getRetryPlugin)(this.config));\n        this.middlewareStack.use((0, middleware_content_length_1.getContentLengthPlugin)(this.config));\n        this.middlewareStack.use((0, middleware_host_header_1.getHostHeaderPlugin)(this.config));\n        this.middlewareStack.use((0, middleware_logger_1.getLoggerPlugin)(this.config));\n        this.middlewareStack.use((0, middleware_recursion_detection_1.getRecursionDetectionPlugin)(this.config));\n        this.middlewareStack.use((0, core_1.getHttpAuthSchemeEndpointRuleSetPlugin)(this.config, {\n            httpAuthSchemeParametersProvider: httpAuthSchemeProvider_1.defaultSTSHttpAuthSchemeParametersProvider,\n            identityProviderConfigProvider: async (config) => new core_1.DefaultIdentityProviderConfig({\n                \"aws.auth#sigv4\": config.credentials,\n            }),\n        }));\n        this.middlewareStack.use((0, core_1.getHttpSigningPlugin)(this.config));\n    }\n    destroy() {\n        super.destroy();\n    }\n}\nexports.STSClient = STSClient;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.resolveHttpAuthRuntimeConfig = exports.getHttpAuthExtensionConfiguration = void 0;\nconst getHttpAuthExtensionConfiguration = (runtimeConfig) => {\n    const _httpAuthSchemes = runtimeConfig.httpAuthSchemes;\n    let _httpAuthSchemeProvider = runtimeConfig.httpAuthSchemeProvider;\n    let _credentials = runtimeConfig.credentials;\n    return {\n        setHttpAuthScheme(httpAuthScheme) {\n            const index = _httpAuthSchemes.findIndex((scheme) => scheme.schemeId === httpAuthScheme.schemeId);\n            if (index === -1) {\n                _httpAuthSchemes.push(httpAuthScheme);\n            }\n            else {\n                _httpAuthSchemes.splice(index, 1, httpAuthScheme);\n            }\n        },\n        httpAuthSchemes() {\n            return _httpAuthSchemes;\n        },\n        setHttpAuthSchemeProvider(httpAuthSchemeProvider) {\n            _httpAuthSchemeProvider = httpAuthSchemeProvider;\n        },\n        httpAuthSchemeProvider() {\n            return _httpAuthSchemeProvider;\n        },\n        setCredentials(credentials) {\n            _credentials = credentials;\n        },\n        credentials() {\n            return _credentials;\n        },\n    };\n};\nexports.getHttpAuthExtensionConfiguration = getHttpAuthExtensionConfiguration;\nconst resolveHttpAuthRuntimeConfig = (config) => {\n    return {\n        httpAuthSchemes: config.httpAuthSchemes(),\n        httpAuthSchemeProvider: config.httpAuthSchemeProvider(),\n        credentials: config.credentials(),\n    };\n};\nexports.resolveHttpAuthRuntimeConfig = resolveHttpAuthRuntimeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.resolveHttpAuthSchemeConfig = exports.resolveStsAuthConfig = exports.defaultSTSHttpAuthSchemeProvider = exports.defaultSTSHttpAuthSchemeParametersProvider = void 0;\nconst core_1 = require(\"@aws-sdk/core\");\nconst util_middleware_1 = require(\"@smithy/util-middleware\");\nconst STSClient_1 = require(\"../STSClient\");\nconst defaultSTSHttpAuthSchemeParametersProvider = async (config, context, input) => {\n    return {\n        operation: (0, util_middleware_1.getSmithyContext)(context).operation,\n        region: await (0, util_middleware_1.normalizeProvider)(config.region)() || (() => {\n            throw new Error(\"expected `region` to be configured for `aws.auth#sigv4`\");\n        })(),\n    };\n};\nexports.defaultSTSHttpAuthSchemeParametersProvider = defaultSTSHttpAuthSchemeParametersProvider;\nfunction createAwsAuthSigv4HttpAuthOption(authParameters) {\n    return {\n        schemeId: \"aws.auth#sigv4\",\n        signingProperties: {\n            name: \"sts\",\n            region: authParameters.region,\n        },\n        propertiesExtractor: (config, context) => ({\n            signingProperties: {\n                config,\n                context,\n            },\n        }),\n    };\n}\nfunction createSmithyApiNoAuthHttpAuthOption(authParameters) {\n    return {\n        schemeId: \"smithy.api#noAuth\",\n    };\n}\nconst defaultSTSHttpAuthSchemeProvider = (authParameters) => {\n    const options = [];\n    switch (authParameters.operation) {\n        case \"AssumeRoleWithSAML\":\n            {\n                options.push(createSmithyApiNoAuthHttpAuthOption(authParameters));\n                break;\n            }\n            ;\n        case \"AssumeRoleWithWebIdentity\":\n            {\n                options.push(createSmithyApiNoAuthHttpAuthOption(authParameters));\n                break;\n            }\n            ;\n        default: {\n            options.push(createAwsAuthSigv4HttpAuthOption(authParameters));\n        }\n    }\n    return options;\n};\nexports.defaultSTSHttpAuthSchemeProvider = defaultSTSHttpAuthSchemeProvider;\nconst resolveStsAuthConfig = (input) => Object.assign(input, {\n    stsClientCtor: STSClient_1.STSClient,\n});\nexports.resolveStsAuthConfig = resolveStsAuthConfig;\nconst resolveHttpAuthSchemeConfig = (config) => {\n    const config_0 = (0, exports.resolveStsAuthConfig)(config);\n    const config_1 = (0, core_1.resolveAwsSdkSigV4Config)(config_0);\n    return Object.assign(config_1, {\n        authSchemePreference: (0, util_middleware_1.normalizeProvider)(config.authSchemePreference ?? []),\n    });\n};\nexports.resolveHttpAuthSchemeConfig = resolveHttpAuthSchemeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.commonParams = exports.resolveClientEndpointParameters = void 0;\nconst resolveClientEndpointParameters = (options) => {\n    return Object.assign(options, {\n        useDualstackEndpoint: options.useDualstackEndpoint ?? false,\n        useFipsEndpoint: options.useFipsEndpoint ?? false,\n        useGlobalEndpoint: options.useGlobalEndpoint ?? false,\n        defaultSigningName: \"sts\",\n    });\n};\nexports.resolveClientEndpointParameters = resolveClientEndpointParameters;\nexports.commonParams = {\n    UseGlobalEndpoint: { type: \"builtInParams\", name: \"useGlobalEndpoint\" },\n    UseFIPS: { type: \"builtInParams\", name: \"useFipsEndpoint\" },\n    Endpoint: { type: \"builtInParams\", name: \"endpoint\" },\n    Region: { type: \"builtInParams\", name: \"region\" },\n    UseDualStack: { type: \"builtInParams\", name: \"useDualstackEndpoint\" },\n};\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.defaultEndpointResolver = void 0;\nconst util_endpoints_1 = require(\"@aws-sdk/util-endpoints\");\nconst util_endpoints_2 = require(\"@smithy/util-endpoints\");\nconst ruleset_1 = require(\"./ruleset\");\nconst cache = new util_endpoints_2.EndpointCache({\n    size: 50,\n    params: [\"Endpoint\", \"Region\", \"UseDualStack\", \"UseFIPS\", \"UseGlobalEndpoint\"],\n});\nconst defaultEndpointResolver = (endpointParams, context = {}) => {\n    return cache.get(endpointParams, () => (0, util_endpoints_2.resolveEndpoint)(ruleset_1.ruleSet, {\n        endpointParams: endpointParams,\n        logger: context.logger,\n    }));\n};\nexports.defaultEndpointResolver = defaultEndpointResolver;\nutil_endpoints_2.customEndpointFunctions.aws = util_endpoints_1.awsEndpointFunctions;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ruleSet = void 0;\nconst F = \"required\", G = \"type\", H = \"fn\", I = \"argv\", J = \"ref\";\nconst a = false, b = true, c = \"booleanEquals\", d = \"stringEquals\", e = \"sigv4\", f = \"sts\", g = \"us-east-1\", h = \"endpoint\", i = \"https://sts.{Region}.{PartitionResult#dnsSuffix}\", j = \"tree\", k = \"error\", l = \"getAttr\", m = { [F]: false, [G]: \"string\" }, n = { [F]: true, \"default\": false, [G]: \"boolean\" }, o = { [J]: \"Endpoint\" }, p = { [H]: \"isSet\", [I]: [{ [J]: \"Region\" }] }, q = { [J]: \"Region\" }, r = { [H]: \"aws.partition\", [I]: [q], \"assign\": \"PartitionResult\" }, s = { [J]: \"UseFIPS\" }, t = { [J]: \"UseDualStack\" }, u = { \"url\": \"https://sts.amazonaws.com\", \"properties\": { \"authSchemes\": [{ \"name\": e, \"signingName\": f, \"signingRegion\": g }] }, \"headers\": {} }, v = {}, w = { \"conditions\": [{ [H]: d, [I]: [q, \"aws-global\"] }], [h]: u, [G]: h }, x = { [H]: c, [I]: [s, true] }, y = { [H]: c, [I]: [t, true] }, z = { [H]: l, [I]: [{ [J]: \"PartitionResult\" }, \"supportsFIPS\"] }, A = { [J]: \"PartitionResult\" }, B = { [H]: c, [I]: [true, { [H]: l, [I]: [A, \"supportsDualStack\"] }] }, C = [{ [H]: \"isSet\", [I]: [o] }], D = [x], E = [y];\nconst _data = { version: \"1.0\", parameters: { Region: m, UseDualStack: n, UseFIPS: n, Endpoint: m, UseGlobalEndpoint: n }, rules: [{ conditions: [{ [H]: c, [I]: [{ [J]: \"UseGlobalEndpoint\" }, b] }, { [H]: \"not\", [I]: C }, p, r, { [H]: c, [I]: [s, a] }, { [H]: c, [I]: [t, a] }], rules: [{ conditions: [{ [H]: d, [I]: [q, \"ap-northeast-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"ap-south-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"ap-southeast-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"ap-southeast-2\"] }], endpoint: u, [G]: h }, w, { conditions: [{ [H]: d, [I]: [q, \"ca-central-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"eu-central-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"eu-north-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"eu-west-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"eu-west-2\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"eu-west-3\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"sa-east-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, g] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"us-east-2\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"us-west-1\"] }], endpoint: u, [G]: h }, { conditions: [{ [H]: d, [I]: [q, \"us-west-2\"] }], endpoint: u, [G]: h }, { endpoint: { url: i, properties: { authSchemes: [{ name: e, signingName: f, signingRegion: \"{Region}\" }] }, headers: v }, [G]: h }], [G]: j }, { conditions: C, rules: [{ conditions: D, error: \"Invalid Configuration: FIPS and custom endpoint are not supported\", [G]: k }, { conditions: E, error: \"Invalid Configuration: Dualstack and custom endpoint are not supported\", [G]: k }, { endpoint: { url: o, properties: v, headers: v }, [G]: h }], [G]: j }, { conditions: [p], rules: [{ conditions: [r], rules: [{ conditions: [x, y], rules: [{ conditions: [{ [H]: c, [I]: [b, z] }, B], rules: [{ endpoint: { url: \"https://sts-fips.{Region}.{PartitionResult#dualStackDnsSuffix}\", properties: v, headers: v }, [G]: h }], [G]: j }, { error: \"FIPS and DualStack are enabled, but this partition does not support one or both\", [G]: k }], [G]: j }, { conditions: D, rules: [{ conditions: [{ [H]: c, [I]: [z, b] }], rules: [{ conditions: [{ [H]: d, [I]: [{ [H]: l, [I]: [A, \"name\"] }, \"aws-us-gov\"] }], endpoint: { url: \"https://sts.{Region}.amazonaws.com\", properties: v, headers: v }, [G]: h }, { endpoint: { url: \"https://sts-fips.{Region}.{PartitionResult#dnsSuffix}\", properties: v, headers: v }, [G]: h }], [G]: j }, { error: \"FIPS is enabled but this partition does not support FIPS\", [G]: k }], [G]: j }, { conditions: E, rules: [{ conditions: [B], rules: [{ endpoint: { url: \"https://sts.{Region}.{PartitionResult#dualStackDnsSuffix}\", properties: v, headers: v }, [G]: h }], [G]: j }, { error: \"DualStack is enabled but this partition does not support DualStack\", [G]: k }], [G]: j }, w, { endpoint: { url: i, properties: v, headers: v }, [G]: h }], [G]: j }], [G]: j }, { error: \"Invalid Configuration: Missing Region\", [G]: k }] };\nexports.ruleSet = _data;\n","'use strict';\n\nvar STSClient = require('./STSClient');\nvar smithyClient = require('@smithy/smithy-client');\nvar middlewareEndpoint = require('@smithy/middleware-endpoint');\nvar EndpointParameters = require('./endpoint/EndpointParameters');\nvar schema = require('@smithy/core/schema');\nvar client = require('@aws-sdk/core/client');\nvar regionConfigResolver = require('@aws-sdk/region-config-resolver');\n\nclass STSServiceException extends smithyClient.ServiceException {\n    constructor(options) {\n        super(options);\n        Object.setPrototypeOf(this, STSServiceException.prototype);\n    }\n}\n\nclass ExpiredTokenException extends STSServiceException {\n    name = \"ExpiredTokenException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"ExpiredTokenException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, ExpiredTokenException.prototype);\n    }\n}\nclass MalformedPolicyDocumentException extends STSServiceException {\n    name = \"MalformedPolicyDocumentException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"MalformedPolicyDocumentException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, MalformedPolicyDocumentException.prototype);\n    }\n}\nclass PackedPolicyTooLargeException extends STSServiceException {\n    name = \"PackedPolicyTooLargeException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"PackedPolicyTooLargeException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, PackedPolicyTooLargeException.prototype);\n    }\n}\nclass RegionDisabledException extends STSServiceException {\n    name = \"RegionDisabledException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"RegionDisabledException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, RegionDisabledException.prototype);\n    }\n}\nclass IDPRejectedClaimException extends STSServiceException {\n    name = \"IDPRejectedClaimException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"IDPRejectedClaimException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, IDPRejectedClaimException.prototype);\n    }\n}\nclass InvalidIdentityTokenException extends STSServiceException {\n    name = \"InvalidIdentityTokenException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"InvalidIdentityTokenException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, InvalidIdentityTokenException.prototype);\n    }\n}\nclass IDPCommunicationErrorException extends STSServiceException {\n    name = \"IDPCommunicationErrorException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"IDPCommunicationErrorException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, IDPCommunicationErrorException.prototype);\n    }\n}\nclass InvalidAuthorizationMessageException extends STSServiceException {\n    name = \"InvalidAuthorizationMessageException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"InvalidAuthorizationMessageException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, InvalidAuthorizationMessageException.prototype);\n    }\n}\nclass ExpiredTradeInTokenException extends STSServiceException {\n    name = \"ExpiredTradeInTokenException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"ExpiredTradeInTokenException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, ExpiredTradeInTokenException.prototype);\n    }\n}\nclass JWTPayloadSizeExceededException extends STSServiceException {\n    name = \"JWTPayloadSizeExceededException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"JWTPayloadSizeExceededException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, JWTPayloadSizeExceededException.prototype);\n    }\n}\nclass OutboundWebIdentityFederationDisabledException extends STSServiceException {\n    name = \"OutboundWebIdentityFederationDisabledException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"OutboundWebIdentityFederationDisabledException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, OutboundWebIdentityFederationDisabledException.prototype);\n    }\n}\nclass SessionDurationEscalationException extends STSServiceException {\n    name = \"SessionDurationEscalationException\";\n    $fault = \"client\";\n    constructor(opts) {\n        super({\n            name: \"SessionDurationEscalationException\",\n            $fault: \"client\",\n            ...opts,\n        });\n        Object.setPrototypeOf(this, SessionDurationEscalationException.prototype);\n    }\n}\n\nconst _A = \"Arn\";\nconst _AKI = \"AccessKeyId\";\nconst _AP = \"AssumedPrincipal\";\nconst _AR = \"AssumeRole\";\nconst _ARI = \"AssumedRoleId\";\nconst _ARR = \"AssumeRoleRequest\";\nconst _ARRs = \"AssumeRoleResponse\";\nconst _ARRss = \"AssumeRootRequest\";\nconst _ARRssu = \"AssumeRootResponse\";\nconst _ARU = \"AssumedRoleUser\";\nconst _ARWSAML = \"AssumeRoleWithSAML\";\nconst _ARWSAMLR = \"AssumeRoleWithSAMLRequest\";\nconst _ARWSAMLRs = \"AssumeRoleWithSAMLResponse\";\nconst _ARWWI = \"AssumeRoleWithWebIdentity\";\nconst _ARWWIR = \"AssumeRoleWithWebIdentityRequest\";\nconst _ARWWIRs = \"AssumeRoleWithWebIdentityResponse\";\nconst _ARs = \"AssumeRoot\";\nconst _Ac = \"Account\";\nconst _Au = \"Audience\";\nconst _C = \"Credentials\";\nconst _CA = \"ContextAssertion\";\nconst _DAM = \"DecodeAuthorizationMessage\";\nconst _DAMR = \"DecodeAuthorizationMessageRequest\";\nconst _DAMRe = \"DecodeAuthorizationMessageResponse\";\nconst _DM = \"DecodedMessage\";\nconst _DS = \"DurationSeconds\";\nconst _E = \"Expiration\";\nconst _EI = \"ExternalId\";\nconst _EM = \"EncodedMessage\";\nconst _ETE = \"ExpiredTokenException\";\nconst _ETITE = \"ExpiredTradeInTokenException\";\nconst _FU = \"FederatedUser\";\nconst _FUI = \"FederatedUserId\";\nconst _GAKI = \"GetAccessKeyInfo\";\nconst _GAKIR = \"GetAccessKeyInfoRequest\";\nconst _GAKIRe = \"GetAccessKeyInfoResponse\";\nconst _GCI = \"GetCallerIdentity\";\nconst _GCIR = \"GetCallerIdentityRequest\";\nconst _GCIRe = \"GetCallerIdentityResponse\";\nconst _GDAT = \"GetDelegatedAccessToken\";\nconst _GDATR = \"GetDelegatedAccessTokenRequest\";\nconst _GDATRe = \"GetDelegatedAccessTokenResponse\";\nconst _GFT = \"GetFederationToken\";\nconst _GFTR = \"GetFederationTokenRequest\";\nconst _GFTRe = \"GetFederationTokenResponse\";\nconst _GST = \"GetSessionToken\";\nconst _GSTR = \"GetSessionTokenRequest\";\nconst _GSTRe = \"GetSessionTokenResponse\";\nconst _GWIT = \"GetWebIdentityToken\";\nconst _GWITR = \"GetWebIdentityTokenRequest\";\nconst _GWITRe = \"GetWebIdentityTokenResponse\";\nconst _I = \"Issuer\";\nconst _IAME = \"InvalidAuthorizationMessageException\";\nconst _IDPCEE = \"IDPCommunicationErrorException\";\nconst _IDPRCE = \"IDPRejectedClaimException\";\nconst _IITE = \"InvalidIdentityTokenException\";\nconst _JWTPSEE = \"JWTPayloadSizeExceededException\";\nconst _K = \"Key\";\nconst _MPDE = \"MalformedPolicyDocumentException\";\nconst _N = \"Name\";\nconst _NQ = \"NameQualifier\";\nconst _OWIFDE = \"OutboundWebIdentityFederationDisabledException\";\nconst _P = \"Policy\";\nconst _PA = \"PolicyArns\";\nconst _PAr = \"PrincipalArn\";\nconst _PAro = \"ProviderArn\";\nconst _PC = \"ProvidedContexts\";\nconst _PCLT = \"ProvidedContextsListType\";\nconst _PCr = \"ProvidedContext\";\nconst _PDT = \"PolicyDescriptorType\";\nconst _PI = \"ProviderId\";\nconst _PPS = \"PackedPolicySize\";\nconst _PPTLE = \"PackedPolicyTooLargeException\";\nconst _Pr = \"Provider\";\nconst _RA = \"RoleArn\";\nconst _RDE = \"RegionDisabledException\";\nconst _RSN = \"RoleSessionName\";\nconst _S = \"Subject\";\nconst _SA = \"SigningAlgorithm\";\nconst _SAK = \"SecretAccessKey\";\nconst _SAMLA = \"SAMLAssertion\";\nconst _SAMLAT = \"SAMLAssertionType\";\nconst _SDEE = \"SessionDurationEscalationException\";\nconst _SFWIT = \"SubjectFromWebIdentityToken\";\nconst _SI = \"SourceIdentity\";\nconst _SN = \"SerialNumber\";\nconst _ST = \"SubjectType\";\nconst _STe = \"SessionToken\";\nconst _T = \"Tags\";\nconst _TC = \"TokenCode\";\nconst _TIT = \"TradeInToken\";\nconst _TP = \"TargetPrincipal\";\nconst _TPA = \"TaskPolicyArn\";\nconst _TTK = \"TransitiveTagKeys\";\nconst _Ta = \"Tag\";\nconst _UI = \"UserId\";\nconst _V = \"Value\";\nconst _WIT = \"WebIdentityToken\";\nconst _a = \"arn\";\nconst _aKST = \"accessKeySecretType\";\nconst _aQE = \"awsQueryError\";\nconst _c = \"client\";\nconst _cTT = \"clientTokenType\";\nconst _e = \"error\";\nconst _hE = \"httpError\";\nconst _m = \"message\";\nconst _pDLT = \"policyDescriptorListType\";\nconst _s = \"smithy.ts.sdk.synthetic.com.amazonaws.sts\";\nconst _tITT = \"tradeInTokenType\";\nconst _tLT = \"tagListType\";\nconst _wITT = \"webIdentityTokenType\";\nconst n0 = \"com.amazonaws.sts\";\nvar accessKeySecretType = [0, n0, _aKST, 8, 0];\nvar clientTokenType = [0, n0, _cTT, 8, 0];\nvar SAMLAssertionType = [0, n0, _SAMLAT, 8, 0];\nvar tradeInTokenType = [0, n0, _tITT, 8, 0];\nvar webIdentityTokenType = [0, n0, _wITT, 8, 0];\nvar AssumedRoleUser$ = [3, n0, _ARU,\n    0,\n    [_ARI, _A],\n    [0, 0], 2\n];\nvar AssumeRoleRequest$ = [3, n0, _ARR,\n    0,\n    [_RA, _RSN, _PA, _P, _DS, _T, _TTK, _EI, _SN, _TC, _SI, _PC],\n    [0, 0, () => policyDescriptorListType, 0, 1, () => tagListType, 64 | 0, 0, 0, 0, 0, () => ProvidedContextsListType], 2\n];\nvar AssumeRoleResponse$ = [3, n0, _ARRs,\n    0,\n    [_C, _ARU, _PPS, _SI],\n    [[() => Credentials$, 0], () => AssumedRoleUser$, 1, 0]\n];\nvar AssumeRoleWithSAMLRequest$ = [3, n0, _ARWSAMLR,\n    0,\n    [_RA, _PAr, _SAMLA, _PA, _P, _DS],\n    [0, 0, [() => SAMLAssertionType, 0], () => policyDescriptorListType, 0, 1], 3\n];\nvar AssumeRoleWithSAMLResponse$ = [3, n0, _ARWSAMLRs,\n    0,\n    [_C, _ARU, _PPS, _S, _ST, _I, _Au, _NQ, _SI],\n    [[() => Credentials$, 0], () => AssumedRoleUser$, 1, 0, 0, 0, 0, 0, 0]\n];\nvar AssumeRoleWithWebIdentityRequest$ = [3, n0, _ARWWIR,\n    0,\n    [_RA, _RSN, _WIT, _PI, _PA, _P, _DS],\n    [0, 0, [() => clientTokenType, 0], 0, () => policyDescriptorListType, 0, 1], 3\n];\nvar AssumeRoleWithWebIdentityResponse$ = [3, n0, _ARWWIRs,\n    0,\n    [_C, _SFWIT, _ARU, _PPS, _Pr, _Au, _SI],\n    [[() => Credentials$, 0], 0, () => AssumedRoleUser$, 1, 0, 0, 0]\n];\nvar AssumeRootRequest$ = [3, n0, _ARRss,\n    0,\n    [_TP, _TPA, _DS],\n    [0, () => PolicyDescriptorType$, 1], 2\n];\nvar AssumeRootResponse$ = [3, n0, _ARRssu,\n    0,\n    [_C, _SI],\n    [[() => Credentials$, 0], 0]\n];\nvar Credentials$ = [3, n0, _C,\n    0,\n    [_AKI, _SAK, _STe, _E],\n    [0, [() => accessKeySecretType, 0], 0, 4], 4\n];\nvar DecodeAuthorizationMessageRequest$ = [3, n0, _DAMR,\n    0,\n    [_EM],\n    [0], 1\n];\nvar DecodeAuthorizationMessageResponse$ = [3, n0, _DAMRe,\n    0,\n    [_DM],\n    [0]\n];\nvar ExpiredTokenException$ = [-3, n0, _ETE,\n    { [_aQE]: [`ExpiredTokenException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(ExpiredTokenException$, ExpiredTokenException);\nvar ExpiredTradeInTokenException$ = [-3, n0, _ETITE,\n    { [_aQE]: [`ExpiredTradeInTokenException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(ExpiredTradeInTokenException$, ExpiredTradeInTokenException);\nvar FederatedUser$ = [3, n0, _FU,\n    0,\n    [_FUI, _A],\n    [0, 0], 2\n];\nvar GetAccessKeyInfoRequest$ = [3, n0, _GAKIR,\n    0,\n    [_AKI],\n    [0], 1\n];\nvar GetAccessKeyInfoResponse$ = [3, n0, _GAKIRe,\n    0,\n    [_Ac],\n    [0]\n];\nvar GetCallerIdentityRequest$ = [3, n0, _GCIR,\n    0,\n    [],\n    []\n];\nvar GetCallerIdentityResponse$ = [3, n0, _GCIRe,\n    0,\n    [_UI, _Ac, _A],\n    [0, 0, 0]\n];\nvar GetDelegatedAccessTokenRequest$ = [3, n0, _GDATR,\n    0,\n    [_TIT],\n    [[() => tradeInTokenType, 0]], 1\n];\nvar GetDelegatedAccessTokenResponse$ = [3, n0, _GDATRe,\n    0,\n    [_C, _PPS, _AP],\n    [[() => Credentials$, 0], 1, 0]\n];\nvar GetFederationTokenRequest$ = [3, n0, _GFTR,\n    0,\n    [_N, _P, _PA, _DS, _T],\n    [0, 0, () => policyDescriptorListType, 1, () => tagListType], 1\n];\nvar GetFederationTokenResponse$ = [3, n0, _GFTRe,\n    0,\n    [_C, _FU, _PPS],\n    [[() => Credentials$, 0], () => FederatedUser$, 1]\n];\nvar GetSessionTokenRequest$ = [3, n0, _GSTR,\n    0,\n    [_DS, _SN, _TC],\n    [1, 0, 0]\n];\nvar GetSessionTokenResponse$ = [3, n0, _GSTRe,\n    0,\n    [_C],\n    [[() => Credentials$, 0]]\n];\nvar GetWebIdentityTokenRequest$ = [3, n0, _GWITR,\n    0,\n    [_Au, _SA, _DS, _T],\n    [64 | 0, 0, 1, () => tagListType], 2\n];\nvar GetWebIdentityTokenResponse$ = [3, n0, _GWITRe,\n    0,\n    [_WIT, _E],\n    [[() => webIdentityTokenType, 0], 4]\n];\nvar IDPCommunicationErrorException$ = [-3, n0, _IDPCEE,\n    { [_aQE]: [`IDPCommunicationError`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(IDPCommunicationErrorException$, IDPCommunicationErrorException);\nvar IDPRejectedClaimException$ = [-3, n0, _IDPRCE,\n    { [_aQE]: [`IDPRejectedClaim`, 403], [_e]: _c, [_hE]: 403 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(IDPRejectedClaimException$, IDPRejectedClaimException);\nvar InvalidAuthorizationMessageException$ = [-3, n0, _IAME,\n    { [_aQE]: [`InvalidAuthorizationMessageException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(InvalidAuthorizationMessageException$, InvalidAuthorizationMessageException);\nvar InvalidIdentityTokenException$ = [-3, n0, _IITE,\n    { [_aQE]: [`InvalidIdentityToken`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(InvalidIdentityTokenException$, InvalidIdentityTokenException);\nvar JWTPayloadSizeExceededException$ = [-3, n0, _JWTPSEE,\n    { [_aQE]: [`JWTPayloadSizeExceededException`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(JWTPayloadSizeExceededException$, JWTPayloadSizeExceededException);\nvar MalformedPolicyDocumentException$ = [-3, n0, _MPDE,\n    { [_aQE]: [`MalformedPolicyDocument`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(MalformedPolicyDocumentException$, MalformedPolicyDocumentException);\nvar OutboundWebIdentityFederationDisabledException$ = [-3, n0, _OWIFDE,\n    { [_aQE]: [`OutboundWebIdentityFederationDisabledException`, 403], [_e]: _c, [_hE]: 403 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(OutboundWebIdentityFederationDisabledException$, OutboundWebIdentityFederationDisabledException);\nvar PackedPolicyTooLargeException$ = [-3, n0, _PPTLE,\n    { [_aQE]: [`PackedPolicyTooLarge`, 400], [_e]: _c, [_hE]: 400 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(PackedPolicyTooLargeException$, PackedPolicyTooLargeException);\nvar PolicyDescriptorType$ = [3, n0, _PDT,\n    0,\n    [_a],\n    [0]\n];\nvar ProvidedContext$ = [3, n0, _PCr,\n    0,\n    [_PAro, _CA],\n    [0, 0]\n];\nvar RegionDisabledException$ = [-3, n0, _RDE,\n    { [_aQE]: [`RegionDisabledException`, 403], [_e]: _c, [_hE]: 403 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(RegionDisabledException$, RegionDisabledException);\nvar SessionDurationEscalationException$ = [-3, n0, _SDEE,\n    { [_aQE]: [`SessionDurationEscalationException`, 403], [_e]: _c, [_hE]: 403 },\n    [_m],\n    [0]\n];\nschema.TypeRegistry.for(n0).registerError(SessionDurationEscalationException$, SessionDurationEscalationException);\nvar Tag$ = [3, n0, _Ta,\n    0,\n    [_K, _V],\n    [0, 0], 2\n];\nvar STSServiceException$ = [-3, _s, \"STSServiceException\", 0, [], []];\nschema.TypeRegistry.for(_s).registerError(STSServiceException$, STSServiceException);\nvar policyDescriptorListType = [1, n0, _pDLT,\n    0, () => PolicyDescriptorType$\n];\nvar ProvidedContextsListType = [1, n0, _PCLT,\n    0, () => ProvidedContext$\n];\nvar tagListType = [1, n0, _tLT,\n    0, () => Tag$\n];\nvar AssumeRole$ = [9, n0, _AR,\n    0, () => AssumeRoleRequest$, () => AssumeRoleResponse$\n];\nvar AssumeRoleWithSAML$ = [9, n0, _ARWSAML,\n    0, () => AssumeRoleWithSAMLRequest$, () => AssumeRoleWithSAMLResponse$\n];\nvar AssumeRoleWithWebIdentity$ = [9, n0, _ARWWI,\n    0, () => AssumeRoleWithWebIdentityRequest$, () => AssumeRoleWithWebIdentityResponse$\n];\nvar AssumeRoot$ = [9, n0, _ARs,\n    0, () => AssumeRootRequest$, () => AssumeRootResponse$\n];\nvar DecodeAuthorizationMessage$ = [9, n0, _DAM,\n    0, () => DecodeAuthorizationMessageRequest$, () => DecodeAuthorizationMessageResponse$\n];\nvar GetAccessKeyInfo$ = [9, n0, _GAKI,\n    0, () => GetAccessKeyInfoRequest$, () => GetAccessKeyInfoResponse$\n];\nvar GetCallerIdentity$ = [9, n0, _GCI,\n    0, () => GetCallerIdentityRequest$, () => GetCallerIdentityResponse$\n];\nvar GetDelegatedAccessToken$ = [9, n0, _GDAT,\n    0, () => GetDelegatedAccessTokenRequest$, () => GetDelegatedAccessTokenResponse$\n];\nvar GetFederationToken$ = [9, n0, _GFT,\n    0, () => GetFederationTokenRequest$, () => GetFederationTokenResponse$\n];\nvar GetSessionToken$ = [9, n0, _GST,\n    0, () => GetSessionTokenRequest$, () => GetSessionTokenResponse$\n];\nvar GetWebIdentityToken$ = [9, n0, _GWIT,\n    0, () => GetWebIdentityTokenRequest$, () => GetWebIdentityTokenResponse$\n];\n\nclass AssumeRoleCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"AssumeRole\", {})\n    .n(\"STSClient\", \"AssumeRoleCommand\")\n    .sc(AssumeRole$)\n    .build() {\n}\n\nclass AssumeRoleWithSAMLCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"AssumeRoleWithSAML\", {})\n    .n(\"STSClient\", \"AssumeRoleWithSAMLCommand\")\n    .sc(AssumeRoleWithSAML$)\n    .build() {\n}\n\nclass AssumeRoleWithWebIdentityCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"AssumeRoleWithWebIdentity\", {})\n    .n(\"STSClient\", \"AssumeRoleWithWebIdentityCommand\")\n    .sc(AssumeRoleWithWebIdentity$)\n    .build() {\n}\n\nclass AssumeRootCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"AssumeRoot\", {})\n    .n(\"STSClient\", \"AssumeRootCommand\")\n    .sc(AssumeRoot$)\n    .build() {\n}\n\nclass DecodeAuthorizationMessageCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"DecodeAuthorizationMessage\", {})\n    .n(\"STSClient\", \"DecodeAuthorizationMessageCommand\")\n    .sc(DecodeAuthorizationMessage$)\n    .build() {\n}\n\nclass GetAccessKeyInfoCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"GetAccessKeyInfo\", {})\n    .n(\"STSClient\", \"GetAccessKeyInfoCommand\")\n    .sc(GetAccessKeyInfo$)\n    .build() {\n}\n\nclass GetCallerIdentityCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"GetCallerIdentity\", {})\n    .n(\"STSClient\", \"GetCallerIdentityCommand\")\n    .sc(GetCallerIdentity$)\n    .build() {\n}\n\nclass GetDelegatedAccessTokenCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"GetDelegatedAccessToken\", {})\n    .n(\"STSClient\", \"GetDelegatedAccessTokenCommand\")\n    .sc(GetDelegatedAccessToken$)\n    .build() {\n}\n\nclass GetFederationTokenCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"GetFederationToken\", {})\n    .n(\"STSClient\", \"GetFederationTokenCommand\")\n    .sc(GetFederationToken$)\n    .build() {\n}\n\nclass GetSessionTokenCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"GetSessionToken\", {})\n    .n(\"STSClient\", \"GetSessionTokenCommand\")\n    .sc(GetSessionToken$)\n    .build() {\n}\n\nclass GetWebIdentityTokenCommand extends smithyClient.Command\n    .classBuilder()\n    .ep(EndpointParameters.commonParams)\n    .m(function (Command, cs, config, o) {\n    return [middlewareEndpoint.getEndpointPlugin(config, Command.getEndpointParameterInstructions())];\n})\n    .s(\"AWSSecurityTokenServiceV20110615\", \"GetWebIdentityToken\", {})\n    .n(\"STSClient\", \"GetWebIdentityTokenCommand\")\n    .sc(GetWebIdentityToken$)\n    .build() {\n}\n\nconst commands = {\n    AssumeRoleCommand,\n    AssumeRoleWithSAMLCommand,\n    AssumeRoleWithWebIdentityCommand,\n    AssumeRootCommand,\n    DecodeAuthorizationMessageCommand,\n    GetAccessKeyInfoCommand,\n    GetCallerIdentityCommand,\n    GetDelegatedAccessTokenCommand,\n    GetFederationTokenCommand,\n    GetSessionTokenCommand,\n    GetWebIdentityTokenCommand,\n};\nclass STS extends STSClient.STSClient {\n}\nsmithyClient.createAggregatedClient(commands, STS);\n\nconst getAccountIdFromAssumedRoleUser = (assumedRoleUser) => {\n    if (typeof assumedRoleUser?.Arn === \"string\") {\n        const arnComponents = assumedRoleUser.Arn.split(\":\");\n        if (arnComponents.length > 4 && arnComponents[4] !== \"\") {\n            return arnComponents[4];\n        }\n    }\n    return undefined;\n};\nconst resolveRegion = async (_region, _parentRegion, credentialProviderLogger, loaderConfig = {}) => {\n    const region = typeof _region === \"function\" ? await _region() : _region;\n    const parentRegion = typeof _parentRegion === \"function\" ? await _parentRegion() : _parentRegion;\n    let stsDefaultRegion = \"\";\n    const resolvedRegion = region ?? parentRegion ?? (stsDefaultRegion = await regionConfigResolver.stsRegionDefaultResolver(loaderConfig)());\n    credentialProviderLogger?.debug?.(\"@aws-sdk/client-sts::resolveRegion\", \"accepting first of:\", `${region} (credential provider clientConfig)`, `${parentRegion} (contextual client)`, `${stsDefaultRegion} (STS default: AWS_REGION, profile region, or us-east-1)`);\n    return resolvedRegion;\n};\nconst getDefaultRoleAssumer$1 = (stsOptions, STSClient) => {\n    let stsClient;\n    let closureSourceCreds;\n    return async (sourceCreds, params) => {\n        closureSourceCreds = sourceCreds;\n        if (!stsClient) {\n            const { logger = stsOptions?.parentClientConfig?.logger, profile = stsOptions?.parentClientConfig?.profile, region, requestHandler = stsOptions?.parentClientConfig?.requestHandler, credentialProviderLogger, userAgentAppId = stsOptions?.parentClientConfig?.userAgentAppId, } = stsOptions;\n            const resolvedRegion = await resolveRegion(region, stsOptions?.parentClientConfig?.region, credentialProviderLogger, {\n                logger,\n                profile,\n            });\n            const isCompatibleRequestHandler = !isH2(requestHandler);\n            stsClient = new STSClient({\n                ...stsOptions,\n                userAgentAppId,\n                profile,\n                credentialDefaultProvider: () => async () => closureSourceCreds,\n                region: resolvedRegion,\n                requestHandler: isCompatibleRequestHandler ? requestHandler : undefined,\n                logger: logger,\n            });\n        }\n        const { Credentials, AssumedRoleUser } = await stsClient.send(new AssumeRoleCommand(params));\n        if (!Credentials || !Credentials.AccessKeyId || !Credentials.SecretAccessKey) {\n            throw new Error(`Invalid response from STS.assumeRole call with role ${params.RoleArn}`);\n        }\n        const accountId = getAccountIdFromAssumedRoleUser(AssumedRoleUser);\n        const credentials = {\n            accessKeyId: Credentials.AccessKeyId,\n            secretAccessKey: Credentials.SecretAccessKey,\n            sessionToken: Credentials.SessionToken,\n            expiration: Credentials.Expiration,\n            ...(Credentials.CredentialScope && { credentialScope: Credentials.CredentialScope }),\n            ...(accountId && { accountId }),\n        };\n        client.setCredentialFeature(credentials, \"CREDENTIALS_STS_ASSUME_ROLE\", \"i\");\n        return credentials;\n    };\n};\nconst getDefaultRoleAssumerWithWebIdentity$1 = (stsOptions, STSClient) => {\n    let stsClient;\n    return async (params) => {\n        if (!stsClient) {\n            const { logger = stsOptions?.parentClientConfig?.logger, profile = stsOptions?.parentClientConfig?.profile, region, requestHandler = stsOptions?.parentClientConfig?.requestHandler, credentialProviderLogger, userAgentAppId = stsOptions?.parentClientConfig?.userAgentAppId, } = stsOptions;\n            const resolvedRegion = await resolveRegion(region, stsOptions?.parentClientConfig?.region, credentialProviderLogger, {\n                logger,\n                profile,\n            });\n            const isCompatibleRequestHandler = !isH2(requestHandler);\n            stsClient = new STSClient({\n                ...stsOptions,\n                userAgentAppId,\n                profile,\n                region: resolvedRegion,\n                requestHandler: isCompatibleRequestHandler ? requestHandler : undefined,\n                logger: logger,\n            });\n        }\n        const { Credentials, AssumedRoleUser } = await stsClient.send(new AssumeRoleWithWebIdentityCommand(params));\n        if (!Credentials || !Credentials.AccessKeyId || !Credentials.SecretAccessKey) {\n            throw new Error(`Invalid response from STS.assumeRoleWithWebIdentity call with role ${params.RoleArn}`);\n        }\n        const accountId = getAccountIdFromAssumedRoleUser(AssumedRoleUser);\n        const credentials = {\n            accessKeyId: Credentials.AccessKeyId,\n            secretAccessKey: Credentials.SecretAccessKey,\n            sessionToken: Credentials.SessionToken,\n            expiration: Credentials.Expiration,\n            ...(Credentials.CredentialScope && { credentialScope: Credentials.CredentialScope }),\n            ...(accountId && { accountId }),\n        };\n        if (accountId) {\n            client.setCredentialFeature(credentials, \"RESOLVED_ACCOUNT_ID\", \"T\");\n        }\n        client.setCredentialFeature(credentials, \"CREDENTIALS_STS_ASSUME_ROLE_WEB_ID\", \"k\");\n        return credentials;\n    };\n};\nconst isH2 = (requestHandler) => {\n    return requestHandler?.metadata?.handlerProtocol === \"h2\";\n};\n\nconst getCustomizableStsClientCtor = (baseCtor, customizations) => {\n    if (!customizations)\n        return baseCtor;\n    else\n        return class CustomizableSTSClient extends baseCtor {\n            constructor(config) {\n                super(config);\n                for (const customization of customizations) {\n                    this.middlewareStack.use(customization);\n                }\n            }\n        };\n};\nconst getDefaultRoleAssumer = (stsOptions = {}, stsPlugins) => getDefaultRoleAssumer$1(stsOptions, getCustomizableStsClientCtor(STSClient.STSClient, stsPlugins));\nconst getDefaultRoleAssumerWithWebIdentity = (stsOptions = {}, stsPlugins) => getDefaultRoleAssumerWithWebIdentity$1(stsOptions, getCustomizableStsClientCtor(STSClient.STSClient, stsPlugins));\nconst decorateDefaultCredentialProvider = (provider) => (input) => provider({\n    roleAssumer: getDefaultRoleAssumer(input),\n    roleAssumerWithWebIdentity: getDefaultRoleAssumerWithWebIdentity(input),\n    ...input,\n});\n\nObject.defineProperty(exports, \"$Command\", {\n    enumerable: true,\n    get: function () { return smithyClient.Command; }\n});\nexports.AssumeRole$ = AssumeRole$;\nexports.AssumeRoleCommand = AssumeRoleCommand;\nexports.AssumeRoleRequest$ = AssumeRoleRequest$;\nexports.AssumeRoleResponse$ = AssumeRoleResponse$;\nexports.AssumeRoleWithSAML$ = AssumeRoleWithSAML$;\nexports.AssumeRoleWithSAMLCommand = AssumeRoleWithSAMLCommand;\nexports.AssumeRoleWithSAMLRequest$ = AssumeRoleWithSAMLRequest$;\nexports.AssumeRoleWithSAMLResponse$ = AssumeRoleWithSAMLResponse$;\nexports.AssumeRoleWithWebIdentity$ = AssumeRoleWithWebIdentity$;\nexports.AssumeRoleWithWebIdentityCommand = AssumeRoleWithWebIdentityCommand;\nexports.AssumeRoleWithWebIdentityRequest$ = AssumeRoleWithWebIdentityRequest$;\nexports.AssumeRoleWithWebIdentityResponse$ = AssumeRoleWithWebIdentityResponse$;\nexports.AssumeRoot$ = AssumeRoot$;\nexports.AssumeRootCommand = AssumeRootCommand;\nexports.AssumeRootRequest$ = AssumeRootRequest$;\nexports.AssumeRootResponse$ = AssumeRootResponse$;\nexports.AssumedRoleUser$ = AssumedRoleUser$;\nexports.Credentials$ = Credentials$;\nexports.DecodeAuthorizationMessage$ = DecodeAuthorizationMessage$;\nexports.DecodeAuthorizationMessageCommand = DecodeAuthorizationMessageCommand;\nexports.DecodeAuthorizationMessageRequest$ = DecodeAuthorizationMessageRequest$;\nexports.DecodeAuthorizationMessageResponse$ = DecodeAuthorizationMessageResponse$;\nexports.ExpiredTokenException = ExpiredTokenException;\nexports.ExpiredTokenException$ = ExpiredTokenException$;\nexports.ExpiredTradeInTokenException = ExpiredTradeInTokenException;\nexports.ExpiredTradeInTokenException$ = ExpiredTradeInTokenException$;\nexports.FederatedUser$ = FederatedUser$;\nexports.GetAccessKeyInfo$ = GetAccessKeyInfo$;\nexports.GetAccessKeyInfoCommand = GetAccessKeyInfoCommand;\nexports.GetAccessKeyInfoRequest$ = GetAccessKeyInfoRequest$;\nexports.GetAccessKeyInfoResponse$ = GetAccessKeyInfoResponse$;\nexports.GetCallerIdentity$ = GetCallerIdentity$;\nexports.GetCallerIdentityCommand = GetCallerIdentityCommand;\nexports.GetCallerIdentityRequest$ = GetCallerIdentityRequest$;\nexports.GetCallerIdentityResponse$ = GetCallerIdentityResponse$;\nexports.GetDelegatedAccessToken$ = GetDelegatedAccessToken$;\nexports.GetDelegatedAccessTokenCommand = GetDelegatedAccessTokenCommand;\nexports.GetDelegatedAccessTokenRequest$ = GetDelegatedAccessTokenRequest$;\nexports.GetDelegatedAccessTokenResponse$ = GetDelegatedAccessTokenResponse$;\nexports.GetFederationToken$ = GetFederationToken$;\nexports.GetFederationTokenCommand = GetFederationTokenCommand;\nexports.GetFederationTokenRequest$ = GetFederationTokenRequest$;\nexports.GetFederationTokenResponse$ = GetFederationTokenResponse$;\nexports.GetSessionToken$ = GetSessionToken$;\nexports.GetSessionTokenCommand = GetSessionTokenCommand;\nexports.GetSessionTokenRequest$ = GetSessionTokenRequest$;\nexports.GetSessionTokenResponse$ = GetSessionTokenResponse$;\nexports.GetWebIdentityToken$ = GetWebIdentityToken$;\nexports.GetWebIdentityTokenCommand = GetWebIdentityTokenCommand;\nexports.GetWebIdentityTokenRequest$ = GetWebIdentityTokenRequest$;\nexports.GetWebIdentityTokenResponse$ = GetWebIdentityTokenResponse$;\nexports.IDPCommunicationErrorException = IDPCommunicationErrorException;\nexports.IDPCommunicationErrorException$ = IDPCommunicationErrorException$;\nexports.IDPRejectedClaimException = IDPRejectedClaimException;\nexports.IDPRejectedClaimException$ = IDPRejectedClaimException$;\nexports.InvalidAuthorizationMessageException = InvalidAuthorizationMessageException;\nexports.InvalidAuthorizationMessageException$ = InvalidAuthorizationMessageException$;\nexports.InvalidIdentityTokenException = InvalidIdentityTokenException;\nexports.InvalidIdentityTokenException$ = InvalidIdentityTokenException$;\nexports.JWTPayloadSizeExceededException = JWTPayloadSizeExceededException;\nexports.JWTPayloadSizeExceededException$ = JWTPayloadSizeExceededException$;\nexports.MalformedPolicyDocumentException = MalformedPolicyDocumentException;\nexports.MalformedPolicyDocumentException$ = MalformedPolicyDocumentException$;\nexports.OutboundWebIdentityFederationDisabledException = OutboundWebIdentityFederationDisabledException;\nexports.OutboundWebIdentityFederationDisabledException$ = OutboundWebIdentityFederationDisabledException$;\nexports.PackedPolicyTooLargeException = PackedPolicyTooLargeException;\nexports.PackedPolicyTooLargeException$ = PackedPolicyTooLargeException$;\nexports.PolicyDescriptorType$ = PolicyDescriptorType$;\nexports.ProvidedContext$ = ProvidedContext$;\nexports.RegionDisabledException = RegionDisabledException;\nexports.RegionDisabledException$ = RegionDisabledException$;\nexports.STS = STS;\nexports.STSServiceException = STSServiceException;\nexports.STSServiceException$ = STSServiceException$;\nexports.SessionDurationEscalationException = SessionDurationEscalationException;\nexports.SessionDurationEscalationException$ = SessionDurationEscalationException$;\nexports.Tag$ = Tag$;\nexports.decorateDefaultCredentialProvider = decorateDefaultCredentialProvider;\nexports.getDefaultRoleAssumer = getDefaultRoleAssumer;\nexports.getDefaultRoleAssumerWithWebIdentity = getDefaultRoleAssumerWithWebIdentity;\nObject.keys(STSClient).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return STSClient[k]; }\n    });\n});\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getRuntimeConfig = void 0;\nconst tslib_1 = require(\"tslib\");\nconst package_json_1 = tslib_1.__importDefault(require(\"../package.json\"));\nconst core_1 = require(\"@aws-sdk/core\");\nconst credential_provider_node_1 = require(\"@aws-sdk/credential-provider-node\");\nconst util_user_agent_node_1 = require(\"@aws-sdk/util-user-agent-node\");\nconst config_resolver_1 = require(\"@smithy/config-resolver\");\nconst core_2 = require(\"@smithy/core\");\nconst hash_node_1 = require(\"@smithy/hash-node\");\nconst middleware_retry_1 = require(\"@smithy/middleware-retry\");\nconst node_config_provider_1 = require(\"@smithy/node-config-provider\");\nconst node_http_handler_1 = require(\"@smithy/node-http-handler\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nconst util_body_length_node_1 = require(\"@smithy/util-body-length-node\");\nconst util_defaults_mode_node_1 = require(\"@smithy/util-defaults-mode-node\");\nconst util_retry_1 = require(\"@smithy/util-retry\");\nconst runtimeConfig_shared_1 = require(\"./runtimeConfig.shared\");\nconst getRuntimeConfig = (config) => {\n    (0, smithy_client_1.emitWarningIfUnsupportedVersion)(process.version);\n    const defaultsMode = (0, util_defaults_mode_node_1.resolveDefaultsModeConfig)(config);\n    const defaultConfigProvider = () => defaultsMode().then(smithy_client_1.loadConfigsForDefaultMode);\n    const clientSharedValues = (0, runtimeConfig_shared_1.getRuntimeConfig)(config);\n    (0, core_1.emitWarningIfUnsupportedVersion)(process.version);\n    const loaderConfig = {\n        profile: config?.profile,\n        logger: clientSharedValues.logger,\n    };\n    return {\n        ...clientSharedValues,\n        ...config,\n        runtime: \"node\",\n        defaultsMode,\n        authSchemePreference: config?.authSchemePreference ?? (0, node_config_provider_1.loadConfig)(core_1.NODE_AUTH_SCHEME_PREFERENCE_OPTIONS, loaderConfig),\n        bodyLengthChecker: config?.bodyLengthChecker ?? util_body_length_node_1.calculateBodyLength,\n        credentialDefaultProvider: config?.credentialDefaultProvider ?? credential_provider_node_1.defaultProvider,\n        defaultUserAgentProvider: config?.defaultUserAgentProvider ?? (0, util_user_agent_node_1.createDefaultUserAgentProvider)({ serviceId: clientSharedValues.serviceId, clientVersion: package_json_1.default.version }),\n        httpAuthSchemes: config?.httpAuthSchemes ?? [\n            {\n                schemeId: \"aws.auth#sigv4\",\n                identityProvider: (ipc) => ipc.getIdentityProvider(\"aws.auth#sigv4\") || (async (idProps) => await (0, credential_provider_node_1.defaultProvider)(idProps?.__config || {})()),\n                signer: new core_1.AwsSdkSigV4Signer(),\n            },\n            {\n                schemeId: \"smithy.api#noAuth\",\n                identityProvider: (ipc) => ipc.getIdentityProvider(\"smithy.api#noAuth\") || (async () => ({})),\n                signer: new core_2.NoAuthSigner(),\n            },\n        ],\n        maxAttempts: config?.maxAttempts ?? (0, node_config_provider_1.loadConfig)(middleware_retry_1.NODE_MAX_ATTEMPT_CONFIG_OPTIONS, config),\n        region: config?.region ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_REGION_CONFIG_OPTIONS, { ...config_resolver_1.NODE_REGION_CONFIG_FILE_OPTIONS, ...loaderConfig }),\n        requestHandler: node_http_handler_1.NodeHttpHandler.create(config?.requestHandler ?? defaultConfigProvider),\n        retryMode: config?.retryMode ??\n            (0, node_config_provider_1.loadConfig)({\n                ...middleware_retry_1.NODE_RETRY_MODE_CONFIG_OPTIONS,\n                default: async () => (await defaultConfigProvider()).retryMode || util_retry_1.DEFAULT_RETRY_MODE,\n            }, config),\n        sha256: config?.sha256 ?? hash_node_1.Hash.bind(null, \"sha256\"),\n        streamCollector: config?.streamCollector ?? node_http_handler_1.streamCollector,\n        useDualstackEndpoint: config?.useDualstackEndpoint ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_USE_DUALSTACK_ENDPOINT_CONFIG_OPTIONS, loaderConfig),\n        useFipsEndpoint: config?.useFipsEndpoint ?? (0, node_config_provider_1.loadConfig)(config_resolver_1.NODE_USE_FIPS_ENDPOINT_CONFIG_OPTIONS, loaderConfig),\n        userAgentAppId: config?.userAgentAppId ?? (0, node_config_provider_1.loadConfig)(util_user_agent_node_1.NODE_APP_ID_CONFIG_OPTIONS, loaderConfig),\n    };\n};\nexports.getRuntimeConfig = getRuntimeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getRuntimeConfig = void 0;\nconst core_1 = require(\"@aws-sdk/core\");\nconst protocols_1 = require(\"@aws-sdk/core/protocols\");\nconst core_2 = require(\"@smithy/core\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nconst url_parser_1 = require(\"@smithy/url-parser\");\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst util_utf8_1 = require(\"@smithy/util-utf8\");\nconst httpAuthSchemeProvider_1 = require(\"./auth/httpAuthSchemeProvider\");\nconst endpointResolver_1 = require(\"./endpoint/endpointResolver\");\nconst getRuntimeConfig = (config) => {\n    return {\n        apiVersion: \"2011-06-15\",\n        base64Decoder: config?.base64Decoder ?? util_base64_1.fromBase64,\n        base64Encoder: config?.base64Encoder ?? util_base64_1.toBase64,\n        disableHostPrefix: config?.disableHostPrefix ?? false,\n        endpointProvider: config?.endpointProvider ?? endpointResolver_1.defaultEndpointResolver,\n        extensions: config?.extensions ?? [],\n        httpAuthSchemeProvider: config?.httpAuthSchemeProvider ?? httpAuthSchemeProvider_1.defaultSTSHttpAuthSchemeProvider,\n        httpAuthSchemes: config?.httpAuthSchemes ?? [\n            {\n                schemeId: \"aws.auth#sigv4\",\n                identityProvider: (ipc) => ipc.getIdentityProvider(\"aws.auth#sigv4\"),\n                signer: new core_1.AwsSdkSigV4Signer(),\n            },\n            {\n                schemeId: \"smithy.api#noAuth\",\n                identityProvider: (ipc) => ipc.getIdentityProvider(\"smithy.api#noAuth\") || (async () => ({})),\n                signer: new core_2.NoAuthSigner(),\n            },\n        ],\n        logger: config?.logger ?? new smithy_client_1.NoOpLogger(),\n        protocol: config?.protocol ?? protocols_1.AwsQueryProtocol,\n        protocolSettings: config?.protocolSettings ?? {\n            defaultNamespace: \"com.amazonaws.sts\",\n            xmlNamespace: \"https://sts.amazonaws.com/doc/2011-06-15/\",\n            version: \"2011-06-15\",\n            serviceTarget: \"AWSSecurityTokenServiceV20110615\",\n        },\n        serviceId: config?.serviceId ?? \"STS\",\n        urlParser: config?.urlParser ?? url_parser_1.parseUrl,\n        utf8Decoder: config?.utf8Decoder ?? util_utf8_1.fromUtf8,\n        utf8Encoder: config?.utf8Encoder ?? util_utf8_1.toUtf8,\n    };\n};\nexports.getRuntimeConfig = getRuntimeConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.resolveRuntimeExtensions = void 0;\nconst region_config_resolver_1 = require(\"@aws-sdk/region-config-resolver\");\nconst protocol_http_1 = require(\"@smithy/protocol-http\");\nconst smithy_client_1 = require(\"@smithy/smithy-client\");\nconst httpAuthExtensionConfiguration_1 = require(\"./auth/httpAuthExtensionConfiguration\");\nconst resolveRuntimeExtensions = (runtimeConfig, extensions) => {\n    const extensionConfiguration = Object.assign((0, region_config_resolver_1.getAwsRegionExtensionConfiguration)(runtimeConfig), (0, smithy_client_1.getDefaultExtensionConfiguration)(runtimeConfig), (0, protocol_http_1.getHttpHandlerExtensionConfiguration)(runtimeConfig), (0, httpAuthExtensionConfiguration_1.getHttpAuthExtensionConfiguration)(runtimeConfig));\n    extensions.forEach((extension) => extension.configure(extensionConfiguration));\n    return Object.assign(runtimeConfig, (0, region_config_resolver_1.resolveAwsRegionExtensionConfiguration)(extensionConfiguration), (0, smithy_client_1.resolveDefaultRuntimeConfig)(extensionConfiguration), (0, protocol_http_1.resolveHttpHandlerRuntimeConfig)(extensionConfiguration), (0, httpAuthExtensionConfiguration_1.resolveHttpAuthRuntimeConfig)(extensionConfiguration));\n};\nexports.resolveRuntimeExtensions = resolveRuntimeExtensions;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\nvar core = require('@smithy/core');\nvar propertyProvider = require('@smithy/property-provider');\nvar client = require('@aws-sdk/core/client');\nvar signatureV4 = require('@smithy/signature-v4');\nvar cbor = require('@smithy/core/cbor');\nvar schema = require('@smithy/core/schema');\nvar smithyClient = require('@smithy/smithy-client');\nvar protocols = require('@smithy/core/protocols');\nvar serde = require('@smithy/core/serde');\nvar utilBase64 = require('@smithy/util-base64');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar xmlBuilder = require('@aws-sdk/xml-builder');\n\nconst state = {\n    warningEmitted: false,\n};\nconst emitWarningIfUnsupportedVersion = (version) => {\n    if (version && !state.warningEmitted && parseInt(version.substring(1, version.indexOf(\".\"))) < 20) {\n        state.warningEmitted = true;\n        process.emitWarning(`NodeDeprecationWarning: The AWS SDK for JavaScript (v3) will\nno longer support Node.js ${version} in January 2026.\n\nTo continue receiving updates to AWS services, bug fixes, and security\nupdates please upgrade to a supported Node.js LTS version.\n\nMore information can be found at: https://a.co/c895JFp`);\n    }\n};\n\nfunction setCredentialFeature(credentials, feature, value) {\n    if (!credentials.$source) {\n        credentials.$source = {};\n    }\n    credentials.$source[feature] = value;\n    return credentials;\n}\n\nfunction setFeature(context, feature, value) {\n    if (!context.__aws_sdk_context) {\n        context.__aws_sdk_context = {\n            features: {},\n        };\n    }\n    else if (!context.__aws_sdk_context.features) {\n        context.__aws_sdk_context.features = {};\n    }\n    context.__aws_sdk_context.features[feature] = value;\n}\n\nfunction setTokenFeature(token, feature, value) {\n    if (!token.$source) {\n        token.$source = {};\n    }\n    token.$source[feature] = value;\n    return token;\n}\n\nconst getDateHeader = (response) => protocolHttp.HttpResponse.isInstance(response) ? response.headers?.date ?? response.headers?.Date : undefined;\n\nconst getSkewCorrectedDate = (systemClockOffset) => new Date(Date.now() + systemClockOffset);\n\nconst isClockSkewed = (clockTime, systemClockOffset) => Math.abs(getSkewCorrectedDate(systemClockOffset).getTime() - clockTime) >= 300000;\n\nconst getUpdatedSystemClockOffset = (clockTime, currentSystemClockOffset) => {\n    const clockTimeInMs = Date.parse(clockTime);\n    if (isClockSkewed(clockTimeInMs, currentSystemClockOffset)) {\n        return clockTimeInMs - Date.now();\n    }\n    return currentSystemClockOffset;\n};\n\nconst throwSigningPropertyError = (name, property) => {\n    if (!property) {\n        throw new Error(`Property \\`${name}\\` is not resolved for AWS SDK SigV4Auth`);\n    }\n    return property;\n};\nconst validateSigningProperties = async (signingProperties) => {\n    const context = throwSigningPropertyError(\"context\", signingProperties.context);\n    const config = throwSigningPropertyError(\"config\", signingProperties.config);\n    const authScheme = context.endpointV2?.properties?.authSchemes?.[0];\n    const signerFunction = throwSigningPropertyError(\"signer\", config.signer);\n    const signer = await signerFunction(authScheme);\n    const signingRegion = signingProperties?.signingRegion;\n    const signingRegionSet = signingProperties?.signingRegionSet;\n    const signingName = signingProperties?.signingName;\n    return {\n        config,\n        signer,\n        signingRegion,\n        signingRegionSet,\n        signingName,\n    };\n};\nclass AwsSdkSigV4Signer {\n    async sign(httpRequest, identity, signingProperties) {\n        if (!protocolHttp.HttpRequest.isInstance(httpRequest)) {\n            throw new Error(\"The request is not an instance of `HttpRequest` and cannot be signed\");\n        }\n        const validatedProps = await validateSigningProperties(signingProperties);\n        const { config, signer } = validatedProps;\n        let { signingRegion, signingName } = validatedProps;\n        const handlerExecutionContext = signingProperties.context;\n        if (handlerExecutionContext?.authSchemes?.length ?? 0 > 1) {\n            const [first, second] = handlerExecutionContext.authSchemes;\n            if (first?.name === \"sigv4a\" && second?.name === \"sigv4\") {\n                signingRegion = second?.signingRegion ?? signingRegion;\n                signingName = second?.signingName ?? signingName;\n            }\n        }\n        const signedRequest = await signer.sign(httpRequest, {\n            signingDate: getSkewCorrectedDate(config.systemClockOffset),\n            signingRegion: signingRegion,\n            signingService: signingName,\n        });\n        return signedRequest;\n    }\n    errorHandler(signingProperties) {\n        return (error) => {\n            const serverTime = error.ServerTime ?? getDateHeader(error.$response);\n            if (serverTime) {\n                const config = throwSigningPropertyError(\"config\", signingProperties.config);\n                const initialSystemClockOffset = config.systemClockOffset;\n                config.systemClockOffset = getUpdatedSystemClockOffset(serverTime, config.systemClockOffset);\n                const clockSkewCorrected = config.systemClockOffset !== initialSystemClockOffset;\n                if (clockSkewCorrected && error.$metadata) {\n                    error.$metadata.clockSkewCorrected = true;\n                }\n            }\n            throw error;\n        };\n    }\n    successHandler(httpResponse, signingProperties) {\n        const dateHeader = getDateHeader(httpResponse);\n        if (dateHeader) {\n            const config = throwSigningPropertyError(\"config\", signingProperties.config);\n            config.systemClockOffset = getUpdatedSystemClockOffset(dateHeader, config.systemClockOffset);\n        }\n    }\n}\nconst AWSSDKSigV4Signer = AwsSdkSigV4Signer;\n\nclass AwsSdkSigV4ASigner extends AwsSdkSigV4Signer {\n    async sign(httpRequest, identity, signingProperties) {\n        if (!protocolHttp.HttpRequest.isInstance(httpRequest)) {\n            throw new Error(\"The request is not an instance of `HttpRequest` and cannot be signed\");\n        }\n        const { config, signer, signingRegion, signingRegionSet, signingName } = await validateSigningProperties(signingProperties);\n        const configResolvedSigningRegionSet = await config.sigv4aSigningRegionSet?.();\n        const multiRegionOverride = (configResolvedSigningRegionSet ??\n            signingRegionSet ?? [signingRegion]).join(\",\");\n        const signedRequest = await signer.sign(httpRequest, {\n            signingDate: getSkewCorrectedDate(config.systemClockOffset),\n            signingRegion: multiRegionOverride,\n            signingService: signingName,\n        });\n        return signedRequest;\n    }\n}\n\nconst getArrayForCommaSeparatedString = (str) => typeof str === \"string\" && str.length > 0 ? str.split(\",\").map((item) => item.trim()) : [];\n\nconst getBearerTokenEnvKey = (signingName) => `AWS_BEARER_TOKEN_${signingName.replace(/[\\s-]/g, \"_\").toUpperCase()}`;\n\nconst NODE_AUTH_SCHEME_PREFERENCE_ENV_KEY = \"AWS_AUTH_SCHEME_PREFERENCE\";\nconst NODE_AUTH_SCHEME_PREFERENCE_CONFIG_KEY = \"auth_scheme_preference\";\nconst NODE_AUTH_SCHEME_PREFERENCE_OPTIONS = {\n    environmentVariableSelector: (env, options) => {\n        if (options?.signingName) {\n            const bearerTokenKey = getBearerTokenEnvKey(options.signingName);\n            if (bearerTokenKey in env)\n                return [\"httpBearerAuth\"];\n        }\n        if (!(NODE_AUTH_SCHEME_PREFERENCE_ENV_KEY in env))\n            return undefined;\n        return getArrayForCommaSeparatedString(env[NODE_AUTH_SCHEME_PREFERENCE_ENV_KEY]);\n    },\n    configFileSelector: (profile) => {\n        if (!(NODE_AUTH_SCHEME_PREFERENCE_CONFIG_KEY in profile))\n            return undefined;\n        return getArrayForCommaSeparatedString(profile[NODE_AUTH_SCHEME_PREFERENCE_CONFIG_KEY]);\n    },\n    default: [],\n};\n\nconst resolveAwsSdkSigV4AConfig = (config) => {\n    config.sigv4aSigningRegionSet = core.normalizeProvider(config.sigv4aSigningRegionSet);\n    return config;\n};\nconst NODE_SIGV4A_CONFIG_OPTIONS = {\n    environmentVariableSelector(env) {\n        if (env.AWS_SIGV4A_SIGNING_REGION_SET) {\n            return env.AWS_SIGV4A_SIGNING_REGION_SET.split(\",\").map((_) => _.trim());\n        }\n        throw new propertyProvider.ProviderError(\"AWS_SIGV4A_SIGNING_REGION_SET not set in env.\", {\n            tryNextLink: true,\n        });\n    },\n    configFileSelector(profile) {\n        if (profile.sigv4a_signing_region_set) {\n            return (profile.sigv4a_signing_region_set ?? \"\").split(\",\").map((_) => _.trim());\n        }\n        throw new propertyProvider.ProviderError(\"sigv4a_signing_region_set not set in profile.\", {\n            tryNextLink: true,\n        });\n    },\n    default: undefined,\n};\n\nconst resolveAwsSdkSigV4Config = (config) => {\n    let inputCredentials = config.credentials;\n    let isUserSupplied = !!config.credentials;\n    let resolvedCredentials = undefined;\n    Object.defineProperty(config, \"credentials\", {\n        set(credentials) {\n            if (credentials && credentials !== inputCredentials && credentials !== resolvedCredentials) {\n                isUserSupplied = true;\n            }\n            inputCredentials = credentials;\n            const memoizedProvider = normalizeCredentialProvider(config, {\n                credentials: inputCredentials,\n                credentialDefaultProvider: config.credentialDefaultProvider,\n            });\n            const boundProvider = bindCallerConfig(config, memoizedProvider);\n            if (isUserSupplied && !boundProvider.attributed) {\n                const isCredentialObject = typeof inputCredentials === \"object\" && inputCredentials !== null;\n                resolvedCredentials = async (options) => {\n                    const creds = await boundProvider(options);\n                    const attributedCreds = creds;\n                    if (isCredentialObject && (!attributedCreds.$source || Object.keys(attributedCreds.$source).length === 0)) {\n                        return client.setCredentialFeature(attributedCreds, \"CREDENTIALS_CODE\", \"e\");\n                    }\n                    return attributedCreds;\n                };\n                resolvedCredentials.memoized = boundProvider.memoized;\n                resolvedCredentials.configBound = boundProvider.configBound;\n                resolvedCredentials.attributed = true;\n            }\n            else {\n                resolvedCredentials = boundProvider;\n            }\n        },\n        get() {\n            return resolvedCredentials;\n        },\n        enumerable: true,\n        configurable: true,\n    });\n    config.credentials = inputCredentials;\n    const { signingEscapePath = true, systemClockOffset = config.systemClockOffset || 0, sha256, } = config;\n    let signer;\n    if (config.signer) {\n        signer = core.normalizeProvider(config.signer);\n    }\n    else if (config.regionInfoProvider) {\n        signer = () => core.normalizeProvider(config.region)()\n            .then(async (region) => [\n            (await config.regionInfoProvider(region, {\n                useFipsEndpoint: await config.useFipsEndpoint(),\n                useDualstackEndpoint: await config.useDualstackEndpoint(),\n            })) || {},\n            region,\n        ])\n            .then(([regionInfo, region]) => {\n            const { signingRegion, signingService } = regionInfo;\n            config.signingRegion = config.signingRegion || signingRegion || region;\n            config.signingName = config.signingName || signingService || config.serviceId;\n            const params = {\n                ...config,\n                credentials: config.credentials,\n                region: config.signingRegion,\n                service: config.signingName,\n                sha256,\n                uriEscapePath: signingEscapePath,\n            };\n            const SignerCtor = config.signerConstructor || signatureV4.SignatureV4;\n            return new SignerCtor(params);\n        });\n    }\n    else {\n        signer = async (authScheme) => {\n            authScheme = Object.assign({}, {\n                name: \"sigv4\",\n                signingName: config.signingName || config.defaultSigningName,\n                signingRegion: await core.normalizeProvider(config.region)(),\n                properties: {},\n            }, authScheme);\n            const signingRegion = authScheme.signingRegion;\n            const signingService = authScheme.signingName;\n            config.signingRegion = config.signingRegion || signingRegion;\n            config.signingName = config.signingName || signingService || config.serviceId;\n            const params = {\n                ...config,\n                credentials: config.credentials,\n                region: config.signingRegion,\n                service: config.signingName,\n                sha256,\n                uriEscapePath: signingEscapePath,\n            };\n            const SignerCtor = config.signerConstructor || signatureV4.SignatureV4;\n            return new SignerCtor(params);\n        };\n    }\n    const resolvedConfig = Object.assign(config, {\n        systemClockOffset,\n        signingEscapePath,\n        signer,\n    });\n    return resolvedConfig;\n};\nconst resolveAWSSDKSigV4Config = resolveAwsSdkSigV4Config;\nfunction normalizeCredentialProvider(config, { credentials, credentialDefaultProvider, }) {\n    let credentialsProvider;\n    if (credentials) {\n        if (!credentials?.memoized) {\n            credentialsProvider = core.memoizeIdentityProvider(credentials, core.isIdentityExpired, core.doesIdentityRequireRefresh);\n        }\n        else {\n            credentialsProvider = credentials;\n        }\n    }\n    else {\n        if (credentialDefaultProvider) {\n            credentialsProvider = core.normalizeProvider(credentialDefaultProvider(Object.assign({}, config, {\n                parentClientConfig: config,\n            })));\n        }\n        else {\n            credentialsProvider = async () => {\n                throw new Error(\"@aws-sdk/core::resolveAwsSdkSigV4Config - `credentials` not provided and no credentialDefaultProvider was configured.\");\n            };\n        }\n    }\n    credentialsProvider.memoized = true;\n    return credentialsProvider;\n}\nfunction bindCallerConfig(config, credentialsProvider) {\n    if (credentialsProvider.configBound) {\n        return credentialsProvider;\n    }\n    const fn = async (options) => credentialsProvider({ ...options, callerClientConfig: config });\n    fn.memoized = credentialsProvider.memoized;\n    fn.configBound = true;\n    return fn;\n}\n\nclass ProtocolLib {\n    queryCompat;\n    constructor(queryCompat = false) {\n        this.queryCompat = queryCompat;\n    }\n    resolveRestContentType(defaultContentType, inputSchema) {\n        const members = inputSchema.getMemberSchemas();\n        const httpPayloadMember = Object.values(members).find((m) => {\n            return !!m.getMergedTraits().httpPayload;\n        });\n        if (httpPayloadMember) {\n            const mediaType = httpPayloadMember.getMergedTraits().mediaType;\n            if (mediaType) {\n                return mediaType;\n            }\n            else if (httpPayloadMember.isStringSchema()) {\n                return \"text/plain\";\n            }\n            else if (httpPayloadMember.isBlobSchema()) {\n                return \"application/octet-stream\";\n            }\n            else {\n                return defaultContentType;\n            }\n        }\n        else if (!inputSchema.isUnitSchema()) {\n            const hasBody = Object.values(members).find((m) => {\n                const { httpQuery, httpQueryParams, httpHeader, httpLabel, httpPrefixHeaders } = m.getMergedTraits();\n                const noPrefixHeaders = httpPrefixHeaders === void 0;\n                return !httpQuery && !httpQueryParams && !httpHeader && !httpLabel && noPrefixHeaders;\n            });\n            if (hasBody) {\n                return defaultContentType;\n            }\n        }\n    }\n    async getErrorSchemaOrThrowBaseException(errorIdentifier, defaultNamespace, response, dataObject, metadata, getErrorSchema) {\n        let namespace = defaultNamespace;\n        let errorName = errorIdentifier;\n        if (errorIdentifier.includes(\"#\")) {\n            [namespace, errorName] = errorIdentifier.split(\"#\");\n        }\n        const errorMetadata = {\n            $metadata: metadata,\n            $fault: response.statusCode < 500 ? \"client\" : \"server\",\n        };\n        const registry = schema.TypeRegistry.for(namespace);\n        try {\n            const errorSchema = getErrorSchema?.(registry, errorName) ?? registry.getSchema(errorIdentifier);\n            return { errorSchema, errorMetadata };\n        }\n        catch (e) {\n            dataObject.message = dataObject.message ?? dataObject.Message ?? \"UnknownError\";\n            const synthetic = schema.TypeRegistry.for(\"smithy.ts.sdk.synthetic.\" + namespace);\n            const baseExceptionSchema = synthetic.getBaseException();\n            if (baseExceptionSchema) {\n                const ErrorCtor = synthetic.getErrorCtor(baseExceptionSchema) ?? Error;\n                throw this.decorateServiceException(Object.assign(new ErrorCtor({ name: errorName }), errorMetadata), dataObject);\n            }\n            throw this.decorateServiceException(Object.assign(new Error(errorName), errorMetadata), dataObject);\n        }\n    }\n    decorateServiceException(exception, additions = {}) {\n        if (this.queryCompat) {\n            const msg = exception.Message ?? additions.Message;\n            const error = smithyClient.decorateServiceException(exception, additions);\n            if (msg) {\n                error.message = msg;\n            }\n            error.Error = {\n                ...error.Error,\n                Type: error.Error.Type,\n                Code: error.Error.Code,\n                Message: error.Error.message ?? error.Error.Message ?? msg,\n            };\n            const reqId = error.$metadata.requestId;\n            if (reqId) {\n                error.RequestId = reqId;\n            }\n            return error;\n        }\n        return smithyClient.decorateServiceException(exception, additions);\n    }\n    setQueryCompatError(output, response) {\n        const queryErrorHeader = response.headers?.[\"x-amzn-query-error\"];\n        if (output !== undefined && queryErrorHeader != null) {\n            const [Code, Type] = queryErrorHeader.split(\";\");\n            const entries = Object.entries(output);\n            const Error = {\n                Code,\n                Type,\n            };\n            Object.assign(output, Error);\n            for (const [k, v] of entries) {\n                Error[k === \"message\" ? \"Message\" : k] = v;\n            }\n            delete Error.__type;\n            output.Error = Error;\n        }\n    }\n    queryCompatOutput(queryCompatErrorData, errorData) {\n        if (queryCompatErrorData.Error) {\n            errorData.Error = queryCompatErrorData.Error;\n        }\n        if (queryCompatErrorData.Type) {\n            errorData.Type = queryCompatErrorData.Type;\n        }\n        if (queryCompatErrorData.Code) {\n            errorData.Code = queryCompatErrorData.Code;\n        }\n    }\n    findQueryCompatibleError(registry, errorName) {\n        try {\n            return registry.getSchema(errorName);\n        }\n        catch (e) {\n            return registry.find((schema$1) => schema.NormalizedSchema.of(schema$1).getMergedTraits().awsQueryError?.[0] === errorName);\n        }\n    }\n}\n\nclass AwsSmithyRpcV2CborProtocol extends cbor.SmithyRpcV2CborProtocol {\n    awsQueryCompatible;\n    mixin;\n    constructor({ defaultNamespace, awsQueryCompatible, }) {\n        super({ defaultNamespace });\n        this.awsQueryCompatible = !!awsQueryCompatible;\n        this.mixin = new ProtocolLib(this.awsQueryCompatible);\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        if (this.awsQueryCompatible) {\n            request.headers[\"x-amzn-query-mode\"] = \"true\";\n        }\n        return request;\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        if (this.awsQueryCompatible) {\n            this.mixin.setQueryCompatError(dataObject, response);\n        }\n        const errorName = (() => {\n            const compatHeader = response.headers[\"x-amzn-query-error\"];\n            if (compatHeader && this.awsQueryCompatible) {\n                return compatHeader.split(\";\")[0];\n            }\n            return cbor.loadSmithyRpcV2CborErrorCode(response, dataObject) ?? \"Unknown\";\n        })();\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorName, this.options.defaultNamespace, response, dataObject, metadata, this.awsQueryCompatible ? this.mixin.findQueryCompatibleError : undefined);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const message = dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            if (dataObject[name] != null) {\n                output[name] = this.deserializer.readValue(member, dataObject[name]);\n            }\n        }\n        if (this.awsQueryCompatible) {\n            this.mixin.queryCompatOutput(dataObject, output);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n}\n\nconst _toStr = (val) => {\n    if (val == null) {\n        return val;\n    }\n    if (typeof val === \"number\" || typeof val === \"bigint\") {\n        const warning = new Error(`Received number ${val} where a string was expected.`);\n        warning.name = \"Warning\";\n        console.warn(warning);\n        return String(val);\n    }\n    if (typeof val === \"boolean\") {\n        const warning = new Error(`Received boolean ${val} where a string was expected.`);\n        warning.name = \"Warning\";\n        console.warn(warning);\n        return String(val);\n    }\n    return val;\n};\nconst _toBool = (val) => {\n    if (val == null) {\n        return val;\n    }\n    if (typeof val === \"string\") {\n        const lowercase = val.toLowerCase();\n        if (val !== \"\" && lowercase !== \"false\" && lowercase !== \"true\") {\n            const warning = new Error(`Received string \"${val}\" where a boolean was expected.`);\n            warning.name = \"Warning\";\n            console.warn(warning);\n        }\n        return val !== \"\" && lowercase !== \"false\";\n    }\n    return val;\n};\nconst _toNum = (val) => {\n    if (val == null) {\n        return val;\n    }\n    if (typeof val === \"string\") {\n        const num = Number(val);\n        if (num.toString() !== val) {\n            const warning = new Error(`Received string \"${val}\" where a number was expected.`);\n            warning.name = \"Warning\";\n            console.warn(warning);\n            return val;\n        }\n        return num;\n    }\n    return val;\n};\n\nclass SerdeContextConfig {\n    serdeContext;\n    setSerdeContext(serdeContext) {\n        this.serdeContext = serdeContext;\n    }\n}\n\nclass UnionSerde {\n    from;\n    to;\n    keys;\n    constructor(from, to) {\n        this.from = from;\n        this.to = to;\n        this.keys = new Set(Object.keys(this.from).filter((k) => k !== \"__type\"));\n    }\n    mark(key) {\n        this.keys.delete(key);\n    }\n    hasUnknown() {\n        return this.keys.size === 1 && Object.keys(this.to).length === 0;\n    }\n    writeUnknown() {\n        if (this.hasUnknown()) {\n            const k = this.keys.values().next().value;\n            const v = this.from[k];\n            this.to.$unknown = [k, v];\n        }\n    }\n}\n\nfunction jsonReviver(key, value, context) {\n    if (context?.source) {\n        const numericString = context.source;\n        if (typeof value === \"number\") {\n            if (value > Number.MAX_SAFE_INTEGER || value < Number.MIN_SAFE_INTEGER || numericString !== String(value)) {\n                const isFractional = numericString.includes(\".\");\n                if (isFractional) {\n                    return new serde.NumericValue(numericString, \"bigDecimal\");\n                }\n                else {\n                    return BigInt(numericString);\n                }\n            }\n        }\n    }\n    return value;\n}\n\nconst collectBodyString = (streamBody, context) => smithyClient.collectBody(streamBody, context).then((body) => (context?.utf8Encoder ?? utilUtf8.toUtf8)(body));\n\nconst parseJsonBody = (streamBody, context) => collectBodyString(streamBody, context).then((encoded) => {\n    if (encoded.length) {\n        try {\n            return JSON.parse(encoded);\n        }\n        catch (e) {\n            if (e?.name === \"SyntaxError\") {\n                Object.defineProperty(e, \"$responseBodyText\", {\n                    value: encoded,\n                });\n            }\n            throw e;\n        }\n    }\n    return {};\n});\nconst parseJsonErrorBody = async (errorBody, context) => {\n    const value = await parseJsonBody(errorBody, context);\n    value.message = value.message ?? value.Message;\n    return value;\n};\nconst loadRestJsonErrorCode = (output, data) => {\n    const findKey = (object, key) => Object.keys(object).find((k) => k.toLowerCase() === key.toLowerCase());\n    const sanitizeErrorCode = (rawValue) => {\n        let cleanValue = rawValue;\n        if (typeof cleanValue === \"number\") {\n            cleanValue = cleanValue.toString();\n        }\n        if (cleanValue.indexOf(\",\") >= 0) {\n            cleanValue = cleanValue.split(\",\")[0];\n        }\n        if (cleanValue.indexOf(\":\") >= 0) {\n            cleanValue = cleanValue.split(\":\")[0];\n        }\n        if (cleanValue.indexOf(\"#\") >= 0) {\n            cleanValue = cleanValue.split(\"#\")[1];\n        }\n        return cleanValue;\n    };\n    const headerKey = findKey(output.headers, \"x-amzn-errortype\");\n    if (headerKey !== undefined) {\n        return sanitizeErrorCode(output.headers[headerKey]);\n    }\n    if (data && typeof data === \"object\") {\n        const codeKey = findKey(data, \"code\");\n        if (codeKey && data[codeKey] !== undefined) {\n            return sanitizeErrorCode(data[codeKey]);\n        }\n        if (data[\"__type\"] !== undefined) {\n            return sanitizeErrorCode(data[\"__type\"]);\n        }\n    }\n};\n\nclass JsonShapeDeserializer extends SerdeContextConfig {\n    settings;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    async read(schema, data) {\n        return this._read(schema, typeof data === \"string\" ? JSON.parse(data, jsonReviver) : await parseJsonBody(data, this.serdeContext));\n    }\n    readObject(schema, data) {\n        return this._read(schema, data);\n    }\n    _read(schema$1, value) {\n        const isObject = value !== null && typeof value === \"object\";\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (isObject) {\n            if (ns.isStructSchema()) {\n                const record = value;\n                const union = ns.isUnionSchema();\n                const out = {};\n                let nameMap = void 0;\n                const { jsonName } = this.settings;\n                if (jsonName) {\n                    nameMap = {};\n                }\n                let unionSerde;\n                if (union) {\n                    unionSerde = new UnionSerde(record, out);\n                }\n                for (const [memberName, memberSchema] of ns.structIterator()) {\n                    let fromKey = memberName;\n                    if (jsonName) {\n                        fromKey = memberSchema.getMergedTraits().jsonName ?? fromKey;\n                        nameMap[fromKey] = memberName;\n                    }\n                    if (union) {\n                        unionSerde.mark(fromKey);\n                    }\n                    if (record[fromKey] != null) {\n                        out[memberName] = this._read(memberSchema, record[fromKey]);\n                    }\n                }\n                if (union) {\n                    unionSerde.writeUnknown();\n                }\n                else if (typeof record.__type === \"string\") {\n                    for (const [k, v] of Object.entries(record)) {\n                        const t = jsonName ? nameMap[k] ?? k : k;\n                        if (!(t in out)) {\n                            out[t] = v;\n                        }\n                    }\n                }\n                return out;\n            }\n            if (Array.isArray(value) && ns.isListSchema()) {\n                const listMember = ns.getValueSchema();\n                const out = [];\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const item of value) {\n                    if (sparse || item != null) {\n                        out.push(this._read(listMember, item));\n                    }\n                }\n                return out;\n            }\n            if (ns.isMapSchema()) {\n                const mapMember = ns.getValueSchema();\n                const out = {};\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const [_k, _v] of Object.entries(value)) {\n                    if (sparse || _v != null) {\n                        out[_k] = this._read(mapMember, _v);\n                    }\n                }\n                return out;\n            }\n        }\n        if (ns.isBlobSchema() && typeof value === \"string\") {\n            return utilBase64.fromBase64(value);\n        }\n        const mediaType = ns.getMergedTraits().mediaType;\n        if (ns.isStringSchema() && typeof value === \"string\" && mediaType) {\n            const isJson = mediaType === \"application/json\" || mediaType.endsWith(\"+json\");\n            if (isJson) {\n                return serde.LazyJsonString.from(value);\n            }\n            return value;\n        }\n        if (ns.isTimestampSchema() && value != null) {\n            const format = protocols.determineTimestampFormat(ns, this.settings);\n            switch (format) {\n                case 5:\n                    return serde.parseRfc3339DateTimeWithOffset(value);\n                case 6:\n                    return serde.parseRfc7231DateTime(value);\n                case 7:\n                    return serde.parseEpochTimestamp(value);\n                default:\n                    console.warn(\"Missing timestamp format, parsing value with Date constructor:\", value);\n                    return new Date(value);\n            }\n        }\n        if (ns.isBigIntegerSchema() && (typeof value === \"number\" || typeof value === \"string\")) {\n            return BigInt(value);\n        }\n        if (ns.isBigDecimalSchema() && value != undefined) {\n            if (value instanceof serde.NumericValue) {\n                return value;\n            }\n            const untyped = value;\n            if (untyped.type === \"bigDecimal\" && \"string\" in untyped) {\n                return new serde.NumericValue(untyped.string, untyped.type);\n            }\n            return new serde.NumericValue(String(value), \"bigDecimal\");\n        }\n        if (ns.isNumericSchema() && typeof value === \"string\") {\n            switch (value) {\n                case \"Infinity\":\n                    return Infinity;\n                case \"-Infinity\":\n                    return -Infinity;\n                case \"NaN\":\n                    return NaN;\n            }\n            return value;\n        }\n        if (ns.isDocumentSchema()) {\n            if (isObject) {\n                const out = Array.isArray(value) ? [] : {};\n                for (const [k, v] of Object.entries(value)) {\n                    if (v instanceof serde.NumericValue) {\n                        out[k] = v;\n                    }\n                    else {\n                        out[k] = this._read(ns, v);\n                    }\n                }\n                return out;\n            }\n            else {\n                return structuredClone(value);\n            }\n        }\n        return value;\n    }\n}\n\nconst NUMERIC_CONTROL_CHAR = String.fromCharCode(925);\nclass JsonReplacer {\n    values = new Map();\n    counter = 0;\n    stage = 0;\n    createReplacer() {\n        if (this.stage === 1) {\n            throw new Error(\"@aws-sdk/core/protocols - JsonReplacer already created.\");\n        }\n        if (this.stage === 2) {\n            throw new Error(\"@aws-sdk/core/protocols - JsonReplacer exhausted.\");\n        }\n        this.stage = 1;\n        return (key, value) => {\n            if (value instanceof serde.NumericValue) {\n                const v = `${NUMERIC_CONTROL_CHAR + \"nv\" + this.counter++}_` + value.string;\n                this.values.set(`\"${v}\"`, value.string);\n                return v;\n            }\n            if (typeof value === \"bigint\") {\n                const s = value.toString();\n                const v = `${NUMERIC_CONTROL_CHAR + \"b\" + this.counter++}_` + s;\n                this.values.set(`\"${v}\"`, s);\n                return v;\n            }\n            return value;\n        };\n    }\n    replaceInJson(json) {\n        if (this.stage === 0) {\n            throw new Error(\"@aws-sdk/core/protocols - JsonReplacer not created yet.\");\n        }\n        if (this.stage === 2) {\n            throw new Error(\"@aws-sdk/core/protocols - JsonReplacer exhausted.\");\n        }\n        this.stage = 2;\n        if (this.counter === 0) {\n            return json;\n        }\n        for (const [key, value] of this.values) {\n            json = json.replace(key, value);\n        }\n        return json;\n    }\n}\n\nclass JsonShapeSerializer extends SerdeContextConfig {\n    settings;\n    buffer;\n    useReplacer = false;\n    rootSchema;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    write(schema$1, value) {\n        this.rootSchema = schema.NormalizedSchema.of(schema$1);\n        this.buffer = this._write(this.rootSchema, value);\n    }\n    writeDiscriminatedDocument(schema$1, value) {\n        this.write(schema$1, value);\n        if (typeof this.buffer === \"object\") {\n            this.buffer.__type = schema.NormalizedSchema.of(schema$1).getName(true);\n        }\n    }\n    flush() {\n        const { rootSchema, useReplacer } = this;\n        this.rootSchema = undefined;\n        this.useReplacer = false;\n        if (rootSchema?.isStructSchema() || rootSchema?.isDocumentSchema()) {\n            if (!useReplacer) {\n                return JSON.stringify(this.buffer);\n            }\n            const replacer = new JsonReplacer();\n            return replacer.replaceInJson(JSON.stringify(this.buffer, replacer.createReplacer(), 0));\n        }\n        return this.buffer;\n    }\n    _write(schema$1, value, container) {\n        const isObject = value !== null && typeof value === \"object\";\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (isObject) {\n            if (ns.isStructSchema()) {\n                const record = value;\n                const out = {};\n                const { jsonName } = this.settings;\n                let nameMap = void 0;\n                if (jsonName) {\n                    nameMap = {};\n                }\n                for (const [memberName, memberSchema] of ns.structIterator()) {\n                    const serializableValue = this._write(memberSchema, record[memberName], ns);\n                    if (serializableValue !== undefined) {\n                        let targetKey = memberName;\n                        if (jsonName) {\n                            targetKey = memberSchema.getMergedTraits().jsonName ?? memberName;\n                            nameMap[memberName] = targetKey;\n                        }\n                        out[targetKey] = serializableValue;\n                    }\n                }\n                if (ns.isUnionSchema() && Object.keys(out).length === 0) {\n                    const { $unknown } = record;\n                    if (Array.isArray($unknown)) {\n                        const [k, v] = $unknown;\n                        out[k] = this._write(15, v);\n                    }\n                }\n                else if (typeof record.__type === \"string\") {\n                    for (const [k, v] of Object.entries(record)) {\n                        const targetKey = jsonName ? nameMap[k] ?? k : k;\n                        if (!(targetKey in out)) {\n                            out[targetKey] = this._write(15, v);\n                        }\n                    }\n                }\n                return out;\n            }\n            if (Array.isArray(value) && ns.isListSchema()) {\n                const listMember = ns.getValueSchema();\n                const out = [];\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const item of value) {\n                    if (sparse || item != null) {\n                        out.push(this._write(listMember, item));\n                    }\n                }\n                return out;\n            }\n            if (ns.isMapSchema()) {\n                const mapMember = ns.getValueSchema();\n                const out = {};\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const [_k, _v] of Object.entries(value)) {\n                    if (sparse || _v != null) {\n                        out[_k] = this._write(mapMember, _v);\n                    }\n                }\n                return out;\n            }\n            if (value instanceof Uint8Array && (ns.isBlobSchema() || ns.isDocumentSchema())) {\n                if (ns === this.rootSchema) {\n                    return value;\n                }\n                return (this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value);\n            }\n            if (value instanceof Date && (ns.isTimestampSchema() || ns.isDocumentSchema())) {\n                const format = protocols.determineTimestampFormat(ns, this.settings);\n                switch (format) {\n                    case 5:\n                        return value.toISOString().replace(\".000Z\", \"Z\");\n                    case 6:\n                        return serde.dateToUtcString(value);\n                    case 7:\n                        return value.getTime() / 1000;\n                    default:\n                        console.warn(\"Missing timestamp format, using epoch seconds\", value);\n                        return value.getTime() / 1000;\n                }\n            }\n            if (value instanceof serde.NumericValue) {\n                this.useReplacer = true;\n            }\n        }\n        if (value === null && container?.isStructSchema()) {\n            return void 0;\n        }\n        if (ns.isStringSchema()) {\n            if (typeof value === \"undefined\" && ns.isIdempotencyToken()) {\n                return serde.generateIdempotencyToken();\n            }\n            const mediaType = ns.getMergedTraits().mediaType;\n            if (value != null && mediaType) {\n                const isJson = mediaType === \"application/json\" || mediaType.endsWith(\"+json\");\n                if (isJson) {\n                    return serde.LazyJsonString.from(value);\n                }\n            }\n            return value;\n        }\n        if (typeof value === \"number\" && ns.isNumericSchema()) {\n            if (Math.abs(value) === Infinity || isNaN(value)) {\n                return String(value);\n            }\n            return value;\n        }\n        if (typeof value === \"string\" && ns.isBlobSchema()) {\n            if (ns === this.rootSchema) {\n                return value;\n            }\n            return (this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value);\n        }\n        if (typeof value === \"bigint\") {\n            this.useReplacer = true;\n        }\n        if (ns.isDocumentSchema()) {\n            if (isObject) {\n                const out = Array.isArray(value) ? [] : {};\n                for (const [k, v] of Object.entries(value)) {\n                    if (v instanceof serde.NumericValue) {\n                        this.useReplacer = true;\n                        out[k] = v;\n                    }\n                    else {\n                        out[k] = this._write(ns, v);\n                    }\n                }\n                return out;\n            }\n            else {\n                return structuredClone(value);\n            }\n        }\n        return value;\n    }\n}\n\nclass JsonCodec extends SerdeContextConfig {\n    settings;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    createSerializer() {\n        const serializer = new JsonShapeSerializer(this.settings);\n        serializer.setSerdeContext(this.serdeContext);\n        return serializer;\n    }\n    createDeserializer() {\n        const deserializer = new JsonShapeDeserializer(this.settings);\n        deserializer.setSerdeContext(this.serdeContext);\n        return deserializer;\n    }\n}\n\nclass AwsJsonRpcProtocol extends protocols.RpcProtocol {\n    serializer;\n    deserializer;\n    serviceTarget;\n    codec;\n    mixin;\n    awsQueryCompatible;\n    constructor({ defaultNamespace, serviceTarget, awsQueryCompatible, jsonCodec, }) {\n        super({\n            defaultNamespace,\n        });\n        this.serviceTarget = serviceTarget;\n        this.codec =\n            jsonCodec ??\n                new JsonCodec({\n                    timestampFormat: {\n                        useTrait: true,\n                        default: 7,\n                    },\n                    jsonName: false,\n                });\n        this.serializer = this.codec.createSerializer();\n        this.deserializer = this.codec.createDeserializer();\n        this.awsQueryCompatible = !!awsQueryCompatible;\n        this.mixin = new ProtocolLib(this.awsQueryCompatible);\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        if (!request.path.endsWith(\"/\")) {\n            request.path += \"/\";\n        }\n        Object.assign(request.headers, {\n            \"content-type\": `application/x-amz-json-${this.getJsonRpcVersion()}`,\n            \"x-amz-target\": `${this.serviceTarget}.${operationSchema.name}`,\n        });\n        if (this.awsQueryCompatible) {\n            request.headers[\"x-amzn-query-mode\"] = \"true\";\n        }\n        if (schema.deref(operationSchema.input) === \"unit\" || !request.body) {\n            request.body = \"{}\";\n        }\n        return request;\n    }\n    getPayloadCodec() {\n        return this.codec;\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        if (this.awsQueryCompatible) {\n            this.mixin.setQueryCompatError(dataObject, response);\n        }\n        const errorIdentifier = loadRestJsonErrorCode(response, dataObject) ?? \"Unknown\";\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorIdentifier, this.options.defaultNamespace, response, dataObject, metadata, this.awsQueryCompatible ? this.mixin.findQueryCompatibleError : undefined);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const message = dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            if (dataObject[name] != null) {\n                output[name] = this.codec.createDeserializer().readObject(member, dataObject[name]);\n            }\n        }\n        if (this.awsQueryCompatible) {\n            this.mixin.queryCompatOutput(dataObject, output);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n}\n\nclass AwsJson1_0Protocol extends AwsJsonRpcProtocol {\n    constructor({ defaultNamespace, serviceTarget, awsQueryCompatible, jsonCodec, }) {\n        super({\n            defaultNamespace,\n            serviceTarget,\n            awsQueryCompatible,\n            jsonCodec,\n        });\n    }\n    getShapeId() {\n        return \"aws.protocols#awsJson1_0\";\n    }\n    getJsonRpcVersion() {\n        return \"1.0\";\n    }\n    getDefaultContentType() {\n        return \"application/x-amz-json-1.0\";\n    }\n}\n\nclass AwsJson1_1Protocol extends AwsJsonRpcProtocol {\n    constructor({ defaultNamespace, serviceTarget, awsQueryCompatible, jsonCodec, }) {\n        super({\n            defaultNamespace,\n            serviceTarget,\n            awsQueryCompatible,\n            jsonCodec,\n        });\n    }\n    getShapeId() {\n        return \"aws.protocols#awsJson1_1\";\n    }\n    getJsonRpcVersion() {\n        return \"1.1\";\n    }\n    getDefaultContentType() {\n        return \"application/x-amz-json-1.1\";\n    }\n}\n\nclass AwsRestJsonProtocol extends protocols.HttpBindingProtocol {\n    serializer;\n    deserializer;\n    codec;\n    mixin = new ProtocolLib();\n    constructor({ defaultNamespace }) {\n        super({\n            defaultNamespace,\n        });\n        const settings = {\n            timestampFormat: {\n                useTrait: true,\n                default: 7,\n            },\n            httpBindings: true,\n            jsonName: true,\n        };\n        this.codec = new JsonCodec(settings);\n        this.serializer = new protocols.HttpInterceptingShapeSerializer(this.codec.createSerializer(), settings);\n        this.deserializer = new protocols.HttpInterceptingShapeDeserializer(this.codec.createDeserializer(), settings);\n    }\n    getShapeId() {\n        return \"aws.protocols#restJson1\";\n    }\n    getPayloadCodec() {\n        return this.codec;\n    }\n    setSerdeContext(serdeContext) {\n        this.codec.setSerdeContext(serdeContext);\n        super.setSerdeContext(serdeContext);\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        const inputSchema = schema.NormalizedSchema.of(operationSchema.input);\n        if (!request.headers[\"content-type\"]) {\n            const contentType = this.mixin.resolveRestContentType(this.getDefaultContentType(), inputSchema);\n            if (contentType) {\n                request.headers[\"content-type\"] = contentType;\n            }\n        }\n        if (request.body == null && request.headers[\"content-type\"] === this.getDefaultContentType()) {\n            request.body = \"{}\";\n        }\n        return request;\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        const output = await super.deserializeResponse(operationSchema, context, response);\n        const outputSchema = schema.NormalizedSchema.of(operationSchema.output);\n        for (const [name, member] of outputSchema.structIterator()) {\n            if (member.getMemberTraits().httpPayload && !(name in output)) {\n                output[name] = null;\n            }\n        }\n        return output;\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        const errorIdentifier = loadRestJsonErrorCode(response, dataObject) ?? \"Unknown\";\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorIdentifier, this.options.defaultNamespace, response, dataObject, metadata);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const message = dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        await this.deserializeHttpMessage(errorSchema, context, response, dataObject);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            const target = member.getMergedTraits().jsonName ?? name;\n            output[name] = this.codec.createDeserializer().readObject(member, dataObject[target]);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n    getDefaultContentType() {\n        return \"application/json\";\n    }\n}\n\nconst awsExpectUnion = (value) => {\n    if (value == null) {\n        return undefined;\n    }\n    if (typeof value === \"object\" && \"__type\" in value) {\n        delete value.__type;\n    }\n    return smithyClient.expectUnion(value);\n};\n\nclass XmlShapeDeserializer extends SerdeContextConfig {\n    settings;\n    stringDeserializer;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n        this.stringDeserializer = new protocols.FromStringShapeDeserializer(settings);\n    }\n    setSerdeContext(serdeContext) {\n        this.serdeContext = serdeContext;\n        this.stringDeserializer.setSerdeContext(serdeContext);\n    }\n    read(schema$1, bytes, key) {\n        const ns = schema.NormalizedSchema.of(schema$1);\n        const memberSchemas = ns.getMemberSchemas();\n        const isEventPayload = ns.isStructSchema() &&\n            ns.isMemberSchema() &&\n            !!Object.values(memberSchemas).find((memberNs) => {\n                return !!memberNs.getMemberTraits().eventPayload;\n            });\n        if (isEventPayload) {\n            const output = {};\n            const memberName = Object.keys(memberSchemas)[0];\n            const eventMemberSchema = memberSchemas[memberName];\n            if (eventMemberSchema.isBlobSchema()) {\n                output[memberName] = bytes;\n            }\n            else {\n                output[memberName] = this.read(memberSchemas[memberName], bytes);\n            }\n            return output;\n        }\n        const xmlString = (this.serdeContext?.utf8Encoder ?? utilUtf8.toUtf8)(bytes);\n        const parsedObject = this.parseXml(xmlString);\n        return this.readSchema(schema$1, key ? parsedObject[key] : parsedObject);\n    }\n    readSchema(_schema, value) {\n        const ns = schema.NormalizedSchema.of(_schema);\n        if (ns.isUnitSchema()) {\n            return;\n        }\n        const traits = ns.getMergedTraits();\n        if (ns.isListSchema() && !Array.isArray(value)) {\n            return this.readSchema(ns, [value]);\n        }\n        if (value == null) {\n            return value;\n        }\n        if (typeof value === \"object\") {\n            const sparse = !!traits.sparse;\n            const flat = !!traits.xmlFlattened;\n            if (ns.isListSchema()) {\n                const listValue = ns.getValueSchema();\n                const buffer = [];\n                const sourceKey = listValue.getMergedTraits().xmlName ?? \"member\";\n                const source = flat ? value : (value[0] ?? value)[sourceKey];\n                const sourceArray = Array.isArray(source) ? source : [source];\n                for (const v of sourceArray) {\n                    if (v != null || sparse) {\n                        buffer.push(this.readSchema(listValue, v));\n                    }\n                }\n                return buffer;\n            }\n            const buffer = {};\n            if (ns.isMapSchema()) {\n                const keyNs = ns.getKeySchema();\n                const memberNs = ns.getValueSchema();\n                let entries;\n                if (flat) {\n                    entries = Array.isArray(value) ? value : [value];\n                }\n                else {\n                    entries = Array.isArray(value.entry) ? value.entry : [value.entry];\n                }\n                const keyProperty = keyNs.getMergedTraits().xmlName ?? \"key\";\n                const valueProperty = memberNs.getMergedTraits().xmlName ?? \"value\";\n                for (const entry of entries) {\n                    const key = entry[keyProperty];\n                    const value = entry[valueProperty];\n                    if (value != null || sparse) {\n                        buffer[key] = this.readSchema(memberNs, value);\n                    }\n                }\n                return buffer;\n            }\n            if (ns.isStructSchema()) {\n                const union = ns.isUnionSchema();\n                let unionSerde;\n                if (union) {\n                    unionSerde = new UnionSerde(value, buffer);\n                }\n                for (const [memberName, memberSchema] of ns.structIterator()) {\n                    const memberTraits = memberSchema.getMergedTraits();\n                    const xmlObjectKey = !memberTraits.httpPayload\n                        ? memberSchema.getMemberTraits().xmlName ?? memberName\n                        : memberTraits.xmlName ?? memberSchema.getName();\n                    if (union) {\n                        unionSerde.mark(xmlObjectKey);\n                    }\n                    if (value[xmlObjectKey] != null) {\n                        buffer[memberName] = this.readSchema(memberSchema, value[xmlObjectKey]);\n                    }\n                }\n                if (union) {\n                    unionSerde.writeUnknown();\n                }\n                return buffer;\n            }\n            if (ns.isDocumentSchema()) {\n                return value;\n            }\n            throw new Error(`@aws-sdk/core/protocols - xml deserializer unhandled schema type for ${ns.getName(true)}`);\n        }\n        if (ns.isListSchema()) {\n            return [];\n        }\n        if (ns.isMapSchema() || ns.isStructSchema()) {\n            return {};\n        }\n        return this.stringDeserializer.read(ns, value);\n    }\n    parseXml(xml) {\n        if (xml.length) {\n            let parsedObj;\n            try {\n                parsedObj = xmlBuilder.parseXML(xml);\n            }\n            catch (e) {\n                if (e && typeof e === \"object\") {\n                    Object.defineProperty(e, \"$responseBodyText\", {\n                        value: xml,\n                    });\n                }\n                throw e;\n            }\n            const textNodeName = \"#text\";\n            const key = Object.keys(parsedObj)[0];\n            const parsedObjToReturn = parsedObj[key];\n            if (parsedObjToReturn[textNodeName]) {\n                parsedObjToReturn[key] = parsedObjToReturn[textNodeName];\n                delete parsedObjToReturn[textNodeName];\n            }\n            return smithyClient.getValueFromTextNode(parsedObjToReturn);\n        }\n        return {};\n    }\n}\n\nclass QueryShapeSerializer extends SerdeContextConfig {\n    settings;\n    buffer;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    write(schema$1, value, prefix = \"\") {\n        if (this.buffer === undefined) {\n            this.buffer = \"\";\n        }\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (prefix && !prefix.endsWith(\".\")) {\n            prefix += \".\";\n        }\n        if (ns.isBlobSchema()) {\n            if (typeof value === \"string\" || value instanceof Uint8Array) {\n                this.writeKey(prefix);\n                this.writeValue((this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value));\n            }\n        }\n        else if (ns.isBooleanSchema() || ns.isNumericSchema() || ns.isStringSchema()) {\n            if (value != null) {\n                this.writeKey(prefix);\n                this.writeValue(String(value));\n            }\n            else if (ns.isIdempotencyToken()) {\n                this.writeKey(prefix);\n                this.writeValue(serde.generateIdempotencyToken());\n            }\n        }\n        else if (ns.isBigIntegerSchema()) {\n            if (value != null) {\n                this.writeKey(prefix);\n                this.writeValue(String(value));\n            }\n        }\n        else if (ns.isBigDecimalSchema()) {\n            if (value != null) {\n                this.writeKey(prefix);\n                this.writeValue(value instanceof serde.NumericValue ? value.string : String(value));\n            }\n        }\n        else if (ns.isTimestampSchema()) {\n            if (value instanceof Date) {\n                this.writeKey(prefix);\n                const format = protocols.determineTimestampFormat(ns, this.settings);\n                switch (format) {\n                    case 5:\n                        this.writeValue(value.toISOString().replace(\".000Z\", \"Z\"));\n                        break;\n                    case 6:\n                        this.writeValue(smithyClient.dateToUtcString(value));\n                        break;\n                    case 7:\n                        this.writeValue(String(value.getTime() / 1000));\n                        break;\n                }\n            }\n        }\n        else if (ns.isDocumentSchema()) {\n            if (Array.isArray(value)) {\n                this.write(64 | 15, value, prefix);\n            }\n            else if (value instanceof Date) {\n                this.write(4, value, prefix);\n            }\n            else if (value instanceof Uint8Array) {\n                this.write(21, value, prefix);\n            }\n            else if (value && typeof value === \"object\") {\n                this.write(128 | 15, value, prefix);\n            }\n            else {\n                this.writeKey(prefix);\n                this.writeValue(String(value));\n            }\n        }\n        else if (ns.isListSchema()) {\n            if (Array.isArray(value)) {\n                if (value.length === 0) {\n                    if (this.settings.serializeEmptyLists) {\n                        this.writeKey(prefix);\n                        this.writeValue(\"\");\n                    }\n                }\n                else {\n                    const member = ns.getValueSchema();\n                    const flat = this.settings.flattenLists || ns.getMergedTraits().xmlFlattened;\n                    let i = 1;\n                    for (const item of value) {\n                        if (item == null) {\n                            continue;\n                        }\n                        const suffix = this.getKey(\"member\", member.getMergedTraits().xmlName);\n                        const key = flat ? `${prefix}${i}` : `${prefix}${suffix}.${i}`;\n                        this.write(member, item, key);\n                        ++i;\n                    }\n                }\n            }\n        }\n        else if (ns.isMapSchema()) {\n            if (value && typeof value === \"object\") {\n                const keySchema = ns.getKeySchema();\n                const memberSchema = ns.getValueSchema();\n                const flat = ns.getMergedTraits().xmlFlattened;\n                let i = 1;\n                for (const [k, v] of Object.entries(value)) {\n                    if (v == null) {\n                        continue;\n                    }\n                    const keySuffix = this.getKey(\"key\", keySchema.getMergedTraits().xmlName);\n                    const key = flat ? `${prefix}${i}.${keySuffix}` : `${prefix}entry.${i}.${keySuffix}`;\n                    const valueSuffix = this.getKey(\"value\", memberSchema.getMergedTraits().xmlName);\n                    const valueKey = flat ? `${prefix}${i}.${valueSuffix}` : `${prefix}entry.${i}.${valueSuffix}`;\n                    this.write(keySchema, k, key);\n                    this.write(memberSchema, v, valueKey);\n                    ++i;\n                }\n            }\n        }\n        else if (ns.isStructSchema()) {\n            if (value && typeof value === \"object\") {\n                let didWriteMember = false;\n                for (const [memberName, member] of ns.structIterator()) {\n                    if (value[memberName] == null && !member.isIdempotencyToken()) {\n                        continue;\n                    }\n                    const suffix = this.getKey(memberName, member.getMergedTraits().xmlName);\n                    const key = `${prefix}${suffix}`;\n                    this.write(member, value[memberName], key);\n                    didWriteMember = true;\n                }\n                if (!didWriteMember && ns.isUnionSchema()) {\n                    const { $unknown } = value;\n                    if (Array.isArray($unknown)) {\n                        const [k, v] = $unknown;\n                        const key = `${prefix}${k}`;\n                        this.write(15, v, key);\n                    }\n                }\n            }\n        }\n        else if (ns.isUnitSchema()) ;\n        else {\n            throw new Error(`@aws-sdk/core/protocols - QuerySerializer unrecognized schema type ${ns.getName(true)}`);\n        }\n    }\n    flush() {\n        if (this.buffer === undefined) {\n            throw new Error(\"@aws-sdk/core/protocols - QuerySerializer cannot flush with nothing written to buffer.\");\n        }\n        const str = this.buffer;\n        delete this.buffer;\n        return str;\n    }\n    getKey(memberName, xmlName) {\n        const key = xmlName ?? memberName;\n        if (this.settings.capitalizeKeys) {\n            return key[0].toUpperCase() + key.slice(1);\n        }\n        return key;\n    }\n    writeKey(key) {\n        if (key.endsWith(\".\")) {\n            key = key.slice(0, key.length - 1);\n        }\n        this.buffer += `&${protocols.extendedEncodeURIComponent(key)}=`;\n    }\n    writeValue(value) {\n        this.buffer += protocols.extendedEncodeURIComponent(value);\n    }\n}\n\nclass AwsQueryProtocol extends protocols.RpcProtocol {\n    options;\n    serializer;\n    deserializer;\n    mixin = new ProtocolLib();\n    constructor(options) {\n        super({\n            defaultNamespace: options.defaultNamespace,\n        });\n        this.options = options;\n        const settings = {\n            timestampFormat: {\n                useTrait: true,\n                default: 5,\n            },\n            httpBindings: false,\n            xmlNamespace: options.xmlNamespace,\n            serviceNamespace: options.defaultNamespace,\n            serializeEmptyLists: true,\n        };\n        this.serializer = new QueryShapeSerializer(settings);\n        this.deserializer = new XmlShapeDeserializer(settings);\n    }\n    getShapeId() {\n        return \"aws.protocols#awsQuery\";\n    }\n    setSerdeContext(serdeContext) {\n        this.serializer.setSerdeContext(serdeContext);\n        this.deserializer.setSerdeContext(serdeContext);\n    }\n    getPayloadCodec() {\n        throw new Error(\"AWSQuery protocol has no payload codec.\");\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        if (!request.path.endsWith(\"/\")) {\n            request.path += \"/\";\n        }\n        Object.assign(request.headers, {\n            \"content-type\": `application/x-www-form-urlencoded`,\n        });\n        if (schema.deref(operationSchema.input) === \"unit\" || !request.body) {\n            request.body = \"\";\n        }\n        const action = operationSchema.name.split(\"#\")[1] ?? operationSchema.name;\n        request.body = `Action=${action}&Version=${this.options.version}` + request.body;\n        if (request.body.endsWith(\"&\")) {\n            request.body = request.body.slice(-1);\n        }\n        return request;\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        const deserializer = this.deserializer;\n        const ns = schema.NormalizedSchema.of(operationSchema.output);\n        const dataObject = {};\n        if (response.statusCode >= 300) {\n            const bytes = await protocols.collectBody(response.body, context);\n            if (bytes.byteLength > 0) {\n                Object.assign(dataObject, await deserializer.read(15, bytes));\n            }\n            await this.handleError(operationSchema, context, response, dataObject, this.deserializeMetadata(response));\n        }\n        for (const header in response.headers) {\n            const value = response.headers[header];\n            delete response.headers[header];\n            response.headers[header.toLowerCase()] = value;\n        }\n        const shortName = operationSchema.name.split(\"#\")[1] ?? operationSchema.name;\n        const awsQueryResultKey = ns.isStructSchema() && this.useNestedResult() ? shortName + \"Result\" : undefined;\n        const bytes = await protocols.collectBody(response.body, context);\n        if (bytes.byteLength > 0) {\n            Object.assign(dataObject, await deserializer.read(ns, bytes, awsQueryResultKey));\n        }\n        const output = {\n            $metadata: this.deserializeMetadata(response),\n            ...dataObject,\n        };\n        return output;\n    }\n    useNestedResult() {\n        return true;\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        const errorIdentifier = this.loadQueryErrorCode(response, dataObject) ?? \"Unknown\";\n        const errorData = this.loadQueryError(dataObject);\n        const message = this.loadQueryErrorMessage(dataObject);\n        errorData.message = message;\n        errorData.Error = {\n            Type: errorData.Type,\n            Code: errorData.Code,\n            Message: message,\n        };\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorIdentifier, this.options.defaultNamespace, response, errorData, metadata, this.mixin.findQueryCompatibleError);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        const output = {\n            Type: errorData.Error.Type,\n            Code: errorData.Error.Code,\n            Error: errorData.Error,\n        };\n        for (const [name, member] of ns.structIterator()) {\n            const target = member.getMergedTraits().xmlName ?? name;\n            const value = errorData[target] ?? dataObject[target];\n            output[name] = this.deserializer.readSchema(member, value);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n    loadQueryErrorCode(output, data) {\n        const code = (data.Errors?.[0]?.Error ?? data.Errors?.Error ?? data.Error)?.Code;\n        if (code !== undefined) {\n            return code;\n        }\n        if (output.statusCode == 404) {\n            return \"NotFound\";\n        }\n    }\n    loadQueryError(data) {\n        return data.Errors?.[0]?.Error ?? data.Errors?.Error ?? data.Error;\n    }\n    loadQueryErrorMessage(data) {\n        const errorData = this.loadQueryError(data);\n        return errorData?.message ?? errorData?.Message ?? data.message ?? data.Message ?? \"Unknown\";\n    }\n    getDefaultContentType() {\n        return \"application/x-www-form-urlencoded\";\n    }\n}\n\nclass AwsEc2QueryProtocol extends AwsQueryProtocol {\n    options;\n    constructor(options) {\n        super(options);\n        this.options = options;\n        const ec2Settings = {\n            capitalizeKeys: true,\n            flattenLists: true,\n            serializeEmptyLists: false,\n        };\n        Object.assign(this.serializer.settings, ec2Settings);\n    }\n    useNestedResult() {\n        return false;\n    }\n}\n\nconst parseXmlBody = (streamBody, context) => collectBodyString(streamBody, context).then((encoded) => {\n    if (encoded.length) {\n        let parsedObj;\n        try {\n            parsedObj = xmlBuilder.parseXML(encoded);\n        }\n        catch (e) {\n            if (e && typeof e === \"object\") {\n                Object.defineProperty(e, \"$responseBodyText\", {\n                    value: encoded,\n                });\n            }\n            throw e;\n        }\n        const textNodeName = \"#text\";\n        const key = Object.keys(parsedObj)[0];\n        const parsedObjToReturn = parsedObj[key];\n        if (parsedObjToReturn[textNodeName]) {\n            parsedObjToReturn[key] = parsedObjToReturn[textNodeName];\n            delete parsedObjToReturn[textNodeName];\n        }\n        return smithyClient.getValueFromTextNode(parsedObjToReturn);\n    }\n    return {};\n});\nconst parseXmlErrorBody = async (errorBody, context) => {\n    const value = await parseXmlBody(errorBody, context);\n    if (value.Error) {\n        value.Error.message = value.Error.message ?? value.Error.Message;\n    }\n    return value;\n};\nconst loadRestXmlErrorCode = (output, data) => {\n    if (data?.Error?.Code !== undefined) {\n        return data.Error.Code;\n    }\n    if (data?.Code !== undefined) {\n        return data.Code;\n    }\n    if (output.statusCode == 404) {\n        return \"NotFound\";\n    }\n};\n\nclass XmlShapeSerializer extends SerdeContextConfig {\n    settings;\n    stringBuffer;\n    byteBuffer;\n    buffer;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    write(schema$1, value) {\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (ns.isStringSchema() && typeof value === \"string\") {\n            this.stringBuffer = value;\n        }\n        else if (ns.isBlobSchema()) {\n            this.byteBuffer =\n                \"byteLength\" in value\n                    ? value\n                    : (this.serdeContext?.base64Decoder ?? utilBase64.fromBase64)(value);\n        }\n        else {\n            this.buffer = this.writeStruct(ns, value, undefined);\n            const traits = ns.getMergedTraits();\n            if (traits.httpPayload && !traits.xmlName) {\n                this.buffer.withName(ns.getName());\n            }\n        }\n    }\n    flush() {\n        if (this.byteBuffer !== undefined) {\n            const bytes = this.byteBuffer;\n            delete this.byteBuffer;\n            return bytes;\n        }\n        if (this.stringBuffer !== undefined) {\n            const str = this.stringBuffer;\n            delete this.stringBuffer;\n            return str;\n        }\n        const buffer = this.buffer;\n        if (this.settings.xmlNamespace) {\n            if (!buffer?.attributes?.[\"xmlns\"]) {\n                buffer.addAttribute(\"xmlns\", this.settings.xmlNamespace);\n            }\n        }\n        delete this.buffer;\n        return buffer.toString();\n    }\n    writeStruct(ns, value, parentXmlns) {\n        const traits = ns.getMergedTraits();\n        const name = ns.isMemberSchema() && !traits.httpPayload\n            ? ns.getMemberTraits().xmlName ?? ns.getMemberName()\n            : traits.xmlName ?? ns.getName();\n        if (!name || !ns.isStructSchema()) {\n            throw new Error(`@aws-sdk/core/protocols - xml serializer, cannot write struct with empty name or non-struct, schema=${ns.getName(true)}.`);\n        }\n        const structXmlNode = xmlBuilder.XmlNode.of(name);\n        const [xmlnsAttr, xmlns] = this.getXmlnsAttribute(ns, parentXmlns);\n        for (const [memberName, memberSchema] of ns.structIterator()) {\n            const val = value[memberName];\n            if (val != null || memberSchema.isIdempotencyToken()) {\n                if (memberSchema.getMergedTraits().xmlAttribute) {\n                    structXmlNode.addAttribute(memberSchema.getMergedTraits().xmlName ?? memberName, this.writeSimple(memberSchema, val));\n                    continue;\n                }\n                if (memberSchema.isListSchema()) {\n                    this.writeList(memberSchema, val, structXmlNode, xmlns);\n                }\n                else if (memberSchema.isMapSchema()) {\n                    this.writeMap(memberSchema, val, structXmlNode, xmlns);\n                }\n                else if (memberSchema.isStructSchema()) {\n                    structXmlNode.addChildNode(this.writeStruct(memberSchema, val, xmlns));\n                }\n                else {\n                    const memberNode = xmlBuilder.XmlNode.of(memberSchema.getMergedTraits().xmlName ?? memberSchema.getMemberName());\n                    this.writeSimpleInto(memberSchema, val, memberNode, xmlns);\n                    structXmlNode.addChildNode(memberNode);\n                }\n            }\n        }\n        const { $unknown } = value;\n        if ($unknown && ns.isUnionSchema() && Array.isArray($unknown) && Object.keys(value).length === 1) {\n            const [k, v] = $unknown;\n            const node = xmlBuilder.XmlNode.of(k);\n            if (typeof v !== \"string\") {\n                if (value instanceof xmlBuilder.XmlNode || value instanceof xmlBuilder.XmlText) {\n                    structXmlNode.addChildNode(value);\n                }\n                else {\n                    throw new Error(`@aws-sdk - $unknown union member in XML requires ` +\n                        `value of type string, @aws-sdk/xml-builder::XmlNode or XmlText.`);\n                }\n            }\n            this.writeSimpleInto(0, v, node, xmlns);\n            structXmlNode.addChildNode(node);\n        }\n        if (xmlns) {\n            structXmlNode.addAttribute(xmlnsAttr, xmlns);\n        }\n        return structXmlNode;\n    }\n    writeList(listMember, array, container, parentXmlns) {\n        if (!listMember.isMemberSchema()) {\n            throw new Error(`@aws-sdk/core/protocols - xml serializer, cannot write non-member list: ${listMember.getName(true)}`);\n        }\n        const listTraits = listMember.getMergedTraits();\n        const listValueSchema = listMember.getValueSchema();\n        const listValueTraits = listValueSchema.getMergedTraits();\n        const sparse = !!listValueTraits.sparse;\n        const flat = !!listTraits.xmlFlattened;\n        const [xmlnsAttr, xmlns] = this.getXmlnsAttribute(listMember, parentXmlns);\n        const writeItem = (container, value) => {\n            if (listValueSchema.isListSchema()) {\n                this.writeList(listValueSchema, Array.isArray(value) ? value : [value], container, xmlns);\n            }\n            else if (listValueSchema.isMapSchema()) {\n                this.writeMap(listValueSchema, value, container, xmlns);\n            }\n            else if (listValueSchema.isStructSchema()) {\n                const struct = this.writeStruct(listValueSchema, value, xmlns);\n                container.addChildNode(struct.withName(flat ? listTraits.xmlName ?? listMember.getMemberName() : listValueTraits.xmlName ?? \"member\"));\n            }\n            else {\n                const listItemNode = xmlBuilder.XmlNode.of(flat ? listTraits.xmlName ?? listMember.getMemberName() : listValueTraits.xmlName ?? \"member\");\n                this.writeSimpleInto(listValueSchema, value, listItemNode, xmlns);\n                container.addChildNode(listItemNode);\n            }\n        };\n        if (flat) {\n            for (const value of array) {\n                if (sparse || value != null) {\n                    writeItem(container, value);\n                }\n            }\n        }\n        else {\n            const listNode = xmlBuilder.XmlNode.of(listTraits.xmlName ?? listMember.getMemberName());\n            if (xmlns) {\n                listNode.addAttribute(xmlnsAttr, xmlns);\n            }\n            for (const value of array) {\n                if (sparse || value != null) {\n                    writeItem(listNode, value);\n                }\n            }\n            container.addChildNode(listNode);\n        }\n    }\n    writeMap(mapMember, map, container, parentXmlns, containerIsMap = false) {\n        if (!mapMember.isMemberSchema()) {\n            throw new Error(`@aws-sdk/core/protocols - xml serializer, cannot write non-member map: ${mapMember.getName(true)}`);\n        }\n        const mapTraits = mapMember.getMergedTraits();\n        const mapKeySchema = mapMember.getKeySchema();\n        const mapKeyTraits = mapKeySchema.getMergedTraits();\n        const keyTag = mapKeyTraits.xmlName ?? \"key\";\n        const mapValueSchema = mapMember.getValueSchema();\n        const mapValueTraits = mapValueSchema.getMergedTraits();\n        const valueTag = mapValueTraits.xmlName ?? \"value\";\n        const sparse = !!mapValueTraits.sparse;\n        const flat = !!mapTraits.xmlFlattened;\n        const [xmlnsAttr, xmlns] = this.getXmlnsAttribute(mapMember, parentXmlns);\n        const addKeyValue = (entry, key, val) => {\n            const keyNode = xmlBuilder.XmlNode.of(keyTag, key);\n            const [keyXmlnsAttr, keyXmlns] = this.getXmlnsAttribute(mapKeySchema, xmlns);\n            if (keyXmlns) {\n                keyNode.addAttribute(keyXmlnsAttr, keyXmlns);\n            }\n            entry.addChildNode(keyNode);\n            let valueNode = xmlBuilder.XmlNode.of(valueTag);\n            if (mapValueSchema.isListSchema()) {\n                this.writeList(mapValueSchema, val, valueNode, xmlns);\n            }\n            else if (mapValueSchema.isMapSchema()) {\n                this.writeMap(mapValueSchema, val, valueNode, xmlns, true);\n            }\n            else if (mapValueSchema.isStructSchema()) {\n                valueNode = this.writeStruct(mapValueSchema, val, xmlns);\n            }\n            else {\n                this.writeSimpleInto(mapValueSchema, val, valueNode, xmlns);\n            }\n            entry.addChildNode(valueNode);\n        };\n        if (flat) {\n            for (const [key, val] of Object.entries(map)) {\n                if (sparse || val != null) {\n                    const entry = xmlBuilder.XmlNode.of(mapTraits.xmlName ?? mapMember.getMemberName());\n                    addKeyValue(entry, key, val);\n                    container.addChildNode(entry);\n                }\n            }\n        }\n        else {\n            let mapNode;\n            if (!containerIsMap) {\n                mapNode = xmlBuilder.XmlNode.of(mapTraits.xmlName ?? mapMember.getMemberName());\n                if (xmlns) {\n                    mapNode.addAttribute(xmlnsAttr, xmlns);\n                }\n                container.addChildNode(mapNode);\n            }\n            for (const [key, val] of Object.entries(map)) {\n                if (sparse || val != null) {\n                    const entry = xmlBuilder.XmlNode.of(\"entry\");\n                    addKeyValue(entry, key, val);\n                    (containerIsMap ? container : mapNode).addChildNode(entry);\n                }\n            }\n        }\n    }\n    writeSimple(_schema, value) {\n        if (null === value) {\n            throw new Error(\"@aws-sdk/core/protocols - (XML serializer) cannot write null value.\");\n        }\n        const ns = schema.NormalizedSchema.of(_schema);\n        let nodeContents = null;\n        if (value && typeof value === \"object\") {\n            if (ns.isBlobSchema()) {\n                nodeContents = (this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value);\n            }\n            else if (ns.isTimestampSchema() && value instanceof Date) {\n                const format = protocols.determineTimestampFormat(ns, this.settings);\n                switch (format) {\n                    case 5:\n                        nodeContents = value.toISOString().replace(\".000Z\", \"Z\");\n                        break;\n                    case 6:\n                        nodeContents = smithyClient.dateToUtcString(value);\n                        break;\n                    case 7:\n                        nodeContents = String(value.getTime() / 1000);\n                        break;\n                    default:\n                        console.warn(\"Missing timestamp format, using http date\", value);\n                        nodeContents = smithyClient.dateToUtcString(value);\n                        break;\n                }\n            }\n            else if (ns.isBigDecimalSchema() && value) {\n                if (value instanceof serde.NumericValue) {\n                    return value.string;\n                }\n                return String(value);\n            }\n            else if (ns.isMapSchema() || ns.isListSchema()) {\n                throw new Error(\"@aws-sdk/core/protocols - xml serializer, cannot call _write() on List/Map schema, call writeList or writeMap() instead.\");\n            }\n            else {\n                throw new Error(`@aws-sdk/core/protocols - xml serializer, unhandled schema type for object value and schema: ${ns.getName(true)}`);\n            }\n        }\n        if (ns.isBooleanSchema() || ns.isNumericSchema() || ns.isBigIntegerSchema() || ns.isBigDecimalSchema()) {\n            nodeContents = String(value);\n        }\n        if (ns.isStringSchema()) {\n            if (value === undefined && ns.isIdempotencyToken()) {\n                nodeContents = serde.generateIdempotencyToken();\n            }\n            else {\n                nodeContents = String(value);\n            }\n        }\n        if (nodeContents === null) {\n            throw new Error(`Unhandled schema-value pair ${ns.getName(true)}=${value}`);\n        }\n        return nodeContents;\n    }\n    writeSimpleInto(_schema, value, into, parentXmlns) {\n        const nodeContents = this.writeSimple(_schema, value);\n        const ns = schema.NormalizedSchema.of(_schema);\n        const content = new xmlBuilder.XmlText(nodeContents);\n        const [xmlnsAttr, xmlns] = this.getXmlnsAttribute(ns, parentXmlns);\n        if (xmlns) {\n            into.addAttribute(xmlnsAttr, xmlns);\n        }\n        into.addChildNode(content);\n    }\n    getXmlnsAttribute(ns, parentXmlns) {\n        const traits = ns.getMergedTraits();\n        const [prefix, xmlns] = traits.xmlNamespace ?? [];\n        if (xmlns && xmlns !== parentXmlns) {\n            return [prefix ? `xmlns:${prefix}` : \"xmlns\", xmlns];\n        }\n        return [void 0, void 0];\n    }\n}\n\nclass XmlCodec extends SerdeContextConfig {\n    settings;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    createSerializer() {\n        const serializer = new XmlShapeSerializer(this.settings);\n        serializer.setSerdeContext(this.serdeContext);\n        return serializer;\n    }\n    createDeserializer() {\n        const deserializer = new XmlShapeDeserializer(this.settings);\n        deserializer.setSerdeContext(this.serdeContext);\n        return deserializer;\n    }\n}\n\nclass AwsRestXmlProtocol extends protocols.HttpBindingProtocol {\n    codec;\n    serializer;\n    deserializer;\n    mixin = new ProtocolLib();\n    constructor(options) {\n        super(options);\n        const settings = {\n            timestampFormat: {\n                useTrait: true,\n                default: 5,\n            },\n            httpBindings: true,\n            xmlNamespace: options.xmlNamespace,\n            serviceNamespace: options.defaultNamespace,\n        };\n        this.codec = new XmlCodec(settings);\n        this.serializer = new protocols.HttpInterceptingShapeSerializer(this.codec.createSerializer(), settings);\n        this.deserializer = new protocols.HttpInterceptingShapeDeserializer(this.codec.createDeserializer(), settings);\n    }\n    getPayloadCodec() {\n        return this.codec;\n    }\n    getShapeId() {\n        return \"aws.protocols#restXml\";\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        const inputSchema = schema.NormalizedSchema.of(operationSchema.input);\n        if (!request.headers[\"content-type\"]) {\n            const contentType = this.mixin.resolveRestContentType(this.getDefaultContentType(), inputSchema);\n            if (contentType) {\n                request.headers[\"content-type\"] = contentType;\n            }\n        }\n        if (typeof request.body === \"string\" &&\n            request.headers[\"content-type\"] === this.getDefaultContentType() &&\n            !request.body.startsWith(\"<?xml \") &&\n            !this.hasUnstructuredPayloadBinding(inputSchema)) {\n            request.body = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' + request.body;\n        }\n        return request;\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        return super.deserializeResponse(operationSchema, context, response);\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        const errorIdentifier = loadRestXmlErrorCode(response, dataObject) ?? \"Unknown\";\n        if (dataObject.Error && typeof dataObject.Error === \"object\") {\n            for (const key of Object.keys(dataObject.Error)) {\n                dataObject[key] = dataObject.Error[key];\n                if (key.toLowerCase() === \"message\") {\n                    dataObject.message = dataObject.Error[key];\n                }\n            }\n        }\n        if (dataObject.RequestId && !metadata.requestId) {\n            metadata.requestId = dataObject.RequestId;\n        }\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorIdentifier, this.options.defaultNamespace, response, dataObject, metadata);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const message = dataObject.Error?.message ?? dataObject.Error?.Message ?? dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        await this.deserializeHttpMessage(errorSchema, context, response, dataObject);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            const target = member.getMergedTraits().xmlName ?? name;\n            const value = dataObject.Error?.[target] ?? dataObject[target];\n            output[name] = this.codec.createDeserializer().readSchema(member, value);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n    getDefaultContentType() {\n        return \"application/xml\";\n    }\n    hasUnstructuredPayloadBinding(ns) {\n        for (const [, member] of ns.structIterator()) {\n            if (member.getMergedTraits().httpPayload) {\n                return !(member.isStructSchema() || member.isMapSchema() || member.isListSchema());\n            }\n        }\n        return false;\n    }\n}\n\nexports.AWSSDKSigV4Signer = AWSSDKSigV4Signer;\nexports.AwsEc2QueryProtocol = AwsEc2QueryProtocol;\nexports.AwsJson1_0Protocol = AwsJson1_0Protocol;\nexports.AwsJson1_1Protocol = AwsJson1_1Protocol;\nexports.AwsJsonRpcProtocol = AwsJsonRpcProtocol;\nexports.AwsQueryProtocol = AwsQueryProtocol;\nexports.AwsRestJsonProtocol = AwsRestJsonProtocol;\nexports.AwsRestXmlProtocol = AwsRestXmlProtocol;\nexports.AwsSdkSigV4ASigner = AwsSdkSigV4ASigner;\nexports.AwsSdkSigV4Signer = AwsSdkSigV4Signer;\nexports.AwsSmithyRpcV2CborProtocol = AwsSmithyRpcV2CborProtocol;\nexports.JsonCodec = JsonCodec;\nexports.JsonShapeDeserializer = JsonShapeDeserializer;\nexports.JsonShapeSerializer = JsonShapeSerializer;\nexports.NODE_AUTH_SCHEME_PREFERENCE_OPTIONS = NODE_AUTH_SCHEME_PREFERENCE_OPTIONS;\nexports.NODE_SIGV4A_CONFIG_OPTIONS = NODE_SIGV4A_CONFIG_OPTIONS;\nexports.XmlCodec = XmlCodec;\nexports.XmlShapeDeserializer = XmlShapeDeserializer;\nexports.XmlShapeSerializer = XmlShapeSerializer;\nexports._toBool = _toBool;\nexports._toNum = _toNum;\nexports._toStr = _toStr;\nexports.awsExpectUnion = awsExpectUnion;\nexports.emitWarningIfUnsupportedVersion = emitWarningIfUnsupportedVersion;\nexports.getBearerTokenEnvKey = getBearerTokenEnvKey;\nexports.loadRestJsonErrorCode = loadRestJsonErrorCode;\nexports.loadRestXmlErrorCode = loadRestXmlErrorCode;\nexports.parseJsonBody = parseJsonBody;\nexports.parseJsonErrorBody = parseJsonErrorBody;\nexports.parseXmlBody = parseXmlBody;\nexports.parseXmlErrorBody = parseXmlErrorBody;\nexports.resolveAWSSDKSigV4Config = resolveAWSSDKSigV4Config;\nexports.resolveAwsSdkSigV4AConfig = resolveAwsSdkSigV4AConfig;\nexports.resolveAwsSdkSigV4Config = resolveAwsSdkSigV4Config;\nexports.setCredentialFeature = setCredentialFeature;\nexports.setFeature = setFeature;\nexports.setTokenFeature = setTokenFeature;\nexports.state = state;\nexports.validateSigningProperties = validateSigningProperties;\n","'use strict';\n\nconst state = {\n    warningEmitted: false,\n};\nconst emitWarningIfUnsupportedVersion = (version) => {\n    if (version && !state.warningEmitted && parseInt(version.substring(1, version.indexOf(\".\"))) < 20) {\n        state.warningEmitted = true;\n        process.emitWarning(`NodeDeprecationWarning: The AWS SDK for JavaScript (v3) will\nno longer support Node.js ${version} in January 2026.\n\nTo continue receiving updates to AWS services, bug fixes, and security\nupdates please upgrade to a supported Node.js LTS version.\n\nMore information can be found at: https://a.co/c895JFp`);\n    }\n};\n\nfunction setCredentialFeature(credentials, feature, value) {\n    if (!credentials.$source) {\n        credentials.$source = {};\n    }\n    credentials.$source[feature] = value;\n    return credentials;\n}\n\nfunction setFeature(context, feature, value) {\n    if (!context.__aws_sdk_context) {\n        context.__aws_sdk_context = {\n            features: {},\n        };\n    }\n    else if (!context.__aws_sdk_context.features) {\n        context.__aws_sdk_context.features = {};\n    }\n    context.__aws_sdk_context.features[feature] = value;\n}\n\nfunction setTokenFeature(token, feature, value) {\n    if (!token.$source) {\n        token.$source = {};\n    }\n    token.$source[feature] = value;\n    return token;\n}\n\nexports.emitWarningIfUnsupportedVersion = emitWarningIfUnsupportedVersion;\nexports.setCredentialFeature = setCredentialFeature;\nexports.setFeature = setFeature;\nexports.setTokenFeature = setTokenFeature;\nexports.state = state;\n","'use strict';\n\nvar cbor = require('@smithy/core/cbor');\nvar schema = require('@smithy/core/schema');\nvar smithyClient = require('@smithy/smithy-client');\nvar protocols = require('@smithy/core/protocols');\nvar serde = require('@smithy/core/serde');\nvar utilBase64 = require('@smithy/util-base64');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar xmlBuilder = require('@aws-sdk/xml-builder');\n\nclass ProtocolLib {\n    queryCompat;\n    constructor(queryCompat = false) {\n        this.queryCompat = queryCompat;\n    }\n    resolveRestContentType(defaultContentType, inputSchema) {\n        const members = inputSchema.getMemberSchemas();\n        const httpPayloadMember = Object.values(members).find((m) => {\n            return !!m.getMergedTraits().httpPayload;\n        });\n        if (httpPayloadMember) {\n            const mediaType = httpPayloadMember.getMergedTraits().mediaType;\n            if (mediaType) {\n                return mediaType;\n            }\n            else if (httpPayloadMember.isStringSchema()) {\n                return \"text/plain\";\n            }\n            else if (httpPayloadMember.isBlobSchema()) {\n                return \"application/octet-stream\";\n            }\n            else {\n                return defaultContentType;\n            }\n        }\n        else if (!inputSchema.isUnitSchema()) {\n            const hasBody = Object.values(members).find((m) => {\n                const { httpQuery, httpQueryParams, httpHeader, httpLabel, httpPrefixHeaders } = m.getMergedTraits();\n                const noPrefixHeaders = httpPrefixHeaders === void 0;\n                return !httpQuery && !httpQueryParams && !httpHeader && !httpLabel && noPrefixHeaders;\n            });\n            if (hasBody) {\n                return defaultContentType;\n            }\n        }\n    }\n    async getErrorSchemaOrThrowBaseException(errorIdentifier, defaultNamespace, response, dataObject, metadata, getErrorSchema) {\n        let namespace = defaultNamespace;\n        let errorName = errorIdentifier;\n        if (errorIdentifier.includes(\"#\")) {\n            [namespace, errorName] = errorIdentifier.split(\"#\");\n        }\n        const errorMetadata = {\n            $metadata: metadata,\n            $fault: response.statusCode < 500 ? \"client\" : \"server\",\n        };\n        const registry = schema.TypeRegistry.for(namespace);\n        try {\n            const errorSchema = getErrorSchema?.(registry, errorName) ?? registry.getSchema(errorIdentifier);\n            return { errorSchema, errorMetadata };\n        }\n        catch (e) {\n            dataObject.message = dataObject.message ?? dataObject.Message ?? \"UnknownError\";\n            const synthetic = schema.TypeRegistry.for(\"smithy.ts.sdk.synthetic.\" + namespace);\n            const baseExceptionSchema = synthetic.getBaseException();\n            if (baseExceptionSchema) {\n                const ErrorCtor = synthetic.getErrorCtor(baseExceptionSchema) ?? Error;\n                throw this.decorateServiceException(Object.assign(new ErrorCtor({ name: errorName }), errorMetadata), dataObject);\n            }\n            throw this.decorateServiceException(Object.assign(new Error(errorName), errorMetadata), dataObject);\n        }\n    }\n    decorateServiceException(exception, additions = {}) {\n        if (this.queryCompat) {\n            const msg = exception.Message ?? additions.Message;\n            const error = smithyClient.decorateServiceException(exception, additions);\n            if (msg) {\n                error.message = msg;\n            }\n            error.Error = {\n                ...error.Error,\n                Type: error.Error.Type,\n                Code: error.Error.Code,\n                Message: error.Error.message ?? error.Error.Message ?? msg,\n            };\n            const reqId = error.$metadata.requestId;\n            if (reqId) {\n                error.RequestId = reqId;\n            }\n            return error;\n        }\n        return smithyClient.decorateServiceException(exception, additions);\n    }\n    setQueryCompatError(output, response) {\n        const queryErrorHeader = response.headers?.[\"x-amzn-query-error\"];\n        if (output !== undefined && queryErrorHeader != null) {\n            const [Code, Type] = queryErrorHeader.split(\";\");\n            const entries = Object.entries(output);\n            const Error = {\n                Code,\n                Type,\n            };\n            Object.assign(output, Error);\n            for (const [k, v] of entries) {\n                Error[k === \"message\" ? \"Message\" : k] = v;\n            }\n            delete Error.__type;\n            output.Error = Error;\n        }\n    }\n    queryCompatOutput(queryCompatErrorData, errorData) {\n        if (queryCompatErrorData.Error) {\n            errorData.Error = queryCompatErrorData.Error;\n        }\n        if (queryCompatErrorData.Type) {\n            errorData.Type = queryCompatErrorData.Type;\n        }\n        if (queryCompatErrorData.Code) {\n            errorData.Code = queryCompatErrorData.Code;\n        }\n    }\n    findQueryCompatibleError(registry, errorName) {\n        try {\n            return registry.getSchema(errorName);\n        }\n        catch (e) {\n            return registry.find((schema$1) => schema.NormalizedSchema.of(schema$1).getMergedTraits().awsQueryError?.[0] === errorName);\n        }\n    }\n}\n\nclass AwsSmithyRpcV2CborProtocol extends cbor.SmithyRpcV2CborProtocol {\n    awsQueryCompatible;\n    mixin;\n    constructor({ defaultNamespace, awsQueryCompatible, }) {\n        super({ defaultNamespace });\n        this.awsQueryCompatible = !!awsQueryCompatible;\n        this.mixin = new ProtocolLib(this.awsQueryCompatible);\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        if (this.awsQueryCompatible) {\n            request.headers[\"x-amzn-query-mode\"] = \"true\";\n        }\n        return request;\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        if (this.awsQueryCompatible) {\n            this.mixin.setQueryCompatError(dataObject, response);\n        }\n        const errorName = (() => {\n            const compatHeader = response.headers[\"x-amzn-query-error\"];\n            if (compatHeader && this.awsQueryCompatible) {\n                return compatHeader.split(\";\")[0];\n            }\n            return cbor.loadSmithyRpcV2CborErrorCode(response, dataObject) ?? \"Unknown\";\n        })();\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorName, this.options.defaultNamespace, response, dataObject, metadata, this.awsQueryCompatible ? this.mixin.findQueryCompatibleError : undefined);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const message = dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            if (dataObject[name] != null) {\n                output[name] = this.deserializer.readValue(member, dataObject[name]);\n            }\n        }\n        if (this.awsQueryCompatible) {\n            this.mixin.queryCompatOutput(dataObject, output);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n}\n\nconst _toStr = (val) => {\n    if (val == null) {\n        return val;\n    }\n    if (typeof val === \"number\" || typeof val === \"bigint\") {\n        const warning = new Error(`Received number ${val} where a string was expected.`);\n        warning.name = \"Warning\";\n        console.warn(warning);\n        return String(val);\n    }\n    if (typeof val === \"boolean\") {\n        const warning = new Error(`Received boolean ${val} where a string was expected.`);\n        warning.name = \"Warning\";\n        console.warn(warning);\n        return String(val);\n    }\n    return val;\n};\nconst _toBool = (val) => {\n    if (val == null) {\n        return val;\n    }\n    if (typeof val === \"string\") {\n        const lowercase = val.toLowerCase();\n        if (val !== \"\" && lowercase !== \"false\" && lowercase !== \"true\") {\n            const warning = new Error(`Received string \"${val}\" where a boolean was expected.`);\n            warning.name = \"Warning\";\n            console.warn(warning);\n        }\n        return val !== \"\" && lowercase !== \"false\";\n    }\n    return val;\n};\nconst _toNum = (val) => {\n    if (val == null) {\n        return val;\n    }\n    if (typeof val === \"string\") {\n        const num = Number(val);\n        if (num.toString() !== val) {\n            const warning = new Error(`Received string \"${val}\" where a number was expected.`);\n            warning.name = \"Warning\";\n            console.warn(warning);\n            return val;\n        }\n        return num;\n    }\n    return val;\n};\n\nclass SerdeContextConfig {\n    serdeContext;\n    setSerdeContext(serdeContext) {\n        this.serdeContext = serdeContext;\n    }\n}\n\nclass UnionSerde {\n    from;\n    to;\n    keys;\n    constructor(from, to) {\n        this.from = from;\n        this.to = to;\n        this.keys = new Set(Object.keys(this.from).filter((k) => k !== \"__type\"));\n    }\n    mark(key) {\n        this.keys.delete(key);\n    }\n    hasUnknown() {\n        return this.keys.size === 1 && Object.keys(this.to).length === 0;\n    }\n    writeUnknown() {\n        if (this.hasUnknown()) {\n            const k = this.keys.values().next().value;\n            const v = this.from[k];\n            this.to.$unknown = [k, v];\n        }\n    }\n}\n\nfunction jsonReviver(key, value, context) {\n    if (context?.source) {\n        const numericString = context.source;\n        if (typeof value === \"number\") {\n            if (value > Number.MAX_SAFE_INTEGER || value < Number.MIN_SAFE_INTEGER || numericString !== String(value)) {\n                const isFractional = numericString.includes(\".\");\n                if (isFractional) {\n                    return new serde.NumericValue(numericString, \"bigDecimal\");\n                }\n                else {\n                    return BigInt(numericString);\n                }\n            }\n        }\n    }\n    return value;\n}\n\nconst collectBodyString = (streamBody, context) => smithyClient.collectBody(streamBody, context).then((body) => (context?.utf8Encoder ?? utilUtf8.toUtf8)(body));\n\nconst parseJsonBody = (streamBody, context) => collectBodyString(streamBody, context).then((encoded) => {\n    if (encoded.length) {\n        try {\n            return JSON.parse(encoded);\n        }\n        catch (e) {\n            if (e?.name === \"SyntaxError\") {\n                Object.defineProperty(e, \"$responseBodyText\", {\n                    value: encoded,\n                });\n            }\n            throw e;\n        }\n    }\n    return {};\n});\nconst parseJsonErrorBody = async (errorBody, context) => {\n    const value = await parseJsonBody(errorBody, context);\n    value.message = value.message ?? value.Message;\n    return value;\n};\nconst loadRestJsonErrorCode = (output, data) => {\n    const findKey = (object, key) => Object.keys(object).find((k) => k.toLowerCase() === key.toLowerCase());\n    const sanitizeErrorCode = (rawValue) => {\n        let cleanValue = rawValue;\n        if (typeof cleanValue === \"number\") {\n            cleanValue = cleanValue.toString();\n        }\n        if (cleanValue.indexOf(\",\") >= 0) {\n            cleanValue = cleanValue.split(\",\")[0];\n        }\n        if (cleanValue.indexOf(\":\") >= 0) {\n            cleanValue = cleanValue.split(\":\")[0];\n        }\n        if (cleanValue.indexOf(\"#\") >= 0) {\n            cleanValue = cleanValue.split(\"#\")[1];\n        }\n        return cleanValue;\n    };\n    const headerKey = findKey(output.headers, \"x-amzn-errortype\");\n    if (headerKey !== undefined) {\n        return sanitizeErrorCode(output.headers[headerKey]);\n    }\n    if (data && typeof data === \"object\") {\n        const codeKey = findKey(data, \"code\");\n        if (codeKey && data[codeKey] !== undefined) {\n            return sanitizeErrorCode(data[codeKey]);\n        }\n        if (data[\"__type\"] !== undefined) {\n            return sanitizeErrorCode(data[\"__type\"]);\n        }\n    }\n};\n\nclass JsonShapeDeserializer extends SerdeContextConfig {\n    settings;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    async read(schema, data) {\n        return this._read(schema, typeof data === \"string\" ? JSON.parse(data, jsonReviver) : await parseJsonBody(data, this.serdeContext));\n    }\n    readObject(schema, data) {\n        return this._read(schema, data);\n    }\n    _read(schema$1, value) {\n        const isObject = value !== null && typeof value === \"object\";\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (isObject) {\n            if (ns.isStructSchema()) {\n                const record = value;\n                const union = ns.isUnionSchema();\n                const out = {};\n                let nameMap = void 0;\n                const { jsonName } = this.settings;\n                if (jsonName) {\n                    nameMap = {};\n                }\n                let unionSerde;\n                if (union) {\n                    unionSerde = new UnionSerde(record, out);\n                }\n                for (const [memberName, memberSchema] of ns.structIterator()) {\n                    let fromKey = memberName;\n                    if (jsonName) {\n                        fromKey = memberSchema.getMergedTraits().jsonName ?? fromKey;\n                        nameMap[fromKey] = memberName;\n                    }\n                    if (union) {\n                        unionSerde.mark(fromKey);\n                    }\n                    if (record[fromKey] != null) {\n                        out[memberName] = this._read(memberSchema, record[fromKey]);\n                    }\n                }\n                if (union) {\n                    unionSerde.writeUnknown();\n                }\n                else if (typeof record.__type === \"string\") {\n                    for (const [k, v] of Object.entries(record)) {\n                        const t = jsonName ? nameMap[k] ?? k : k;\n                        if (!(t in out)) {\n                            out[t] = v;\n                        }\n                    }\n                }\n                return out;\n            }\n            if (Array.isArray(value) && ns.isListSchema()) {\n                const listMember = ns.getValueSchema();\n                const out = [];\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const item of value) {\n                    if (sparse || item != null) {\n                        out.push(this._read(listMember, item));\n                    }\n                }\n                return out;\n            }\n            if (ns.isMapSchema()) {\n                const mapMember = ns.getValueSchema();\n                const out = {};\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const [_k, _v] of Object.entries(value)) {\n                    if (sparse || _v != null) {\n                        out[_k] = this._read(mapMember, _v);\n                    }\n                }\n                return out;\n            }\n        }\n        if (ns.isBlobSchema() && typeof value === \"string\") {\n            return utilBase64.fromBase64(value);\n        }\n        const mediaType = ns.getMergedTraits().mediaType;\n        if (ns.isStringSchema() && typeof value === \"string\" && mediaType) {\n            const isJson = mediaType === \"application/json\" || mediaType.endsWith(\"+json\");\n            if (isJson) {\n                return serde.LazyJsonString.from(value);\n            }\n            return value;\n        }\n        if (ns.isTimestampSchema() && value != null) {\n            const format = protocols.determineTimestampFormat(ns, this.settings);\n            switch (format) {\n                case 5:\n                    return serde.parseRfc3339DateTimeWithOffset(value);\n                case 6:\n                    return serde.parseRfc7231DateTime(value);\n                case 7:\n                    return serde.parseEpochTimestamp(value);\n                default:\n                    console.warn(\"Missing timestamp format, parsing value with Date constructor:\", value);\n                    return new Date(value);\n            }\n        }\n        if (ns.isBigIntegerSchema() && (typeof value === \"number\" || typeof value === \"string\")) {\n            return BigInt(value);\n        }\n        if (ns.isBigDecimalSchema() && value != undefined) {\n            if (value instanceof serde.NumericValue) {\n                return value;\n            }\n            const untyped = value;\n            if (untyped.type === \"bigDecimal\" && \"string\" in untyped) {\n                return new serde.NumericValue(untyped.string, untyped.type);\n            }\n            return new serde.NumericValue(String(value), \"bigDecimal\");\n        }\n        if (ns.isNumericSchema() && typeof value === \"string\") {\n            switch (value) {\n                case \"Infinity\":\n                    return Infinity;\n                case \"-Infinity\":\n                    return -Infinity;\n                case \"NaN\":\n                    return NaN;\n            }\n            return value;\n        }\n        if (ns.isDocumentSchema()) {\n            if (isObject) {\n                const out = Array.isArray(value) ? [] : {};\n                for (const [k, v] of Object.entries(value)) {\n                    if (v instanceof serde.NumericValue) {\n                        out[k] = v;\n                    }\n                    else {\n                        out[k] = this._read(ns, v);\n                    }\n                }\n                return out;\n            }\n            else {\n                return structuredClone(value);\n            }\n        }\n        return value;\n    }\n}\n\nconst NUMERIC_CONTROL_CHAR = String.fromCharCode(925);\nclass JsonReplacer {\n    values = new Map();\n    counter = 0;\n    stage = 0;\n    createReplacer() {\n        if (this.stage === 1) {\n            throw new Error(\"@aws-sdk/core/protocols - JsonReplacer already created.\");\n        }\n        if (this.stage === 2) {\n            throw new Error(\"@aws-sdk/core/protocols - JsonReplacer exhausted.\");\n        }\n        this.stage = 1;\n        return (key, value) => {\n            if (value instanceof serde.NumericValue) {\n                const v = `${NUMERIC_CONTROL_CHAR + \"nv\" + this.counter++}_` + value.string;\n                this.values.set(`\"${v}\"`, value.string);\n                return v;\n            }\n            if (typeof value === \"bigint\") {\n                const s = value.toString();\n                const v = `${NUMERIC_CONTROL_CHAR + \"b\" + this.counter++}_` + s;\n                this.values.set(`\"${v}\"`, s);\n                return v;\n            }\n            return value;\n        };\n    }\n    replaceInJson(json) {\n        if (this.stage === 0) {\n            throw new Error(\"@aws-sdk/core/protocols - JsonReplacer not created yet.\");\n        }\n        if (this.stage === 2) {\n            throw new Error(\"@aws-sdk/core/protocols - JsonReplacer exhausted.\");\n        }\n        this.stage = 2;\n        if (this.counter === 0) {\n            return json;\n        }\n        for (const [key, value] of this.values) {\n            json = json.replace(key, value);\n        }\n        return json;\n    }\n}\n\nclass JsonShapeSerializer extends SerdeContextConfig {\n    settings;\n    buffer;\n    useReplacer = false;\n    rootSchema;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    write(schema$1, value) {\n        this.rootSchema = schema.NormalizedSchema.of(schema$1);\n        this.buffer = this._write(this.rootSchema, value);\n    }\n    writeDiscriminatedDocument(schema$1, value) {\n        this.write(schema$1, value);\n        if (typeof this.buffer === \"object\") {\n            this.buffer.__type = schema.NormalizedSchema.of(schema$1).getName(true);\n        }\n    }\n    flush() {\n        const { rootSchema, useReplacer } = this;\n        this.rootSchema = undefined;\n        this.useReplacer = false;\n        if (rootSchema?.isStructSchema() || rootSchema?.isDocumentSchema()) {\n            if (!useReplacer) {\n                return JSON.stringify(this.buffer);\n            }\n            const replacer = new JsonReplacer();\n            return replacer.replaceInJson(JSON.stringify(this.buffer, replacer.createReplacer(), 0));\n        }\n        return this.buffer;\n    }\n    _write(schema$1, value, container) {\n        const isObject = value !== null && typeof value === \"object\";\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (isObject) {\n            if (ns.isStructSchema()) {\n                const record = value;\n                const out = {};\n                const { jsonName } = this.settings;\n                let nameMap = void 0;\n                if (jsonName) {\n                    nameMap = {};\n                }\n                for (const [memberName, memberSchema] of ns.structIterator()) {\n                    const serializableValue = this._write(memberSchema, record[memberName], ns);\n                    if (serializableValue !== undefined) {\n                        let targetKey = memberName;\n                        if (jsonName) {\n                            targetKey = memberSchema.getMergedTraits().jsonName ?? memberName;\n                            nameMap[memberName] = targetKey;\n                        }\n                        out[targetKey] = serializableValue;\n                    }\n                }\n                if (ns.isUnionSchema() && Object.keys(out).length === 0) {\n                    const { $unknown } = record;\n                    if (Array.isArray($unknown)) {\n                        const [k, v] = $unknown;\n                        out[k] = this._write(15, v);\n                    }\n                }\n                else if (typeof record.__type === \"string\") {\n                    for (const [k, v] of Object.entries(record)) {\n                        const targetKey = jsonName ? nameMap[k] ?? k : k;\n                        if (!(targetKey in out)) {\n                            out[targetKey] = this._write(15, v);\n                        }\n                    }\n                }\n                return out;\n            }\n            if (Array.isArray(value) && ns.isListSchema()) {\n                const listMember = ns.getValueSchema();\n                const out = [];\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const item of value) {\n                    if (sparse || item != null) {\n                        out.push(this._write(listMember, item));\n                    }\n                }\n                return out;\n            }\n            if (ns.isMapSchema()) {\n                const mapMember = ns.getValueSchema();\n                const out = {};\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const [_k, _v] of Object.entries(value)) {\n                    if (sparse || _v != null) {\n                        out[_k] = this._write(mapMember, _v);\n                    }\n                }\n                return out;\n            }\n            if (value instanceof Uint8Array && (ns.isBlobSchema() || ns.isDocumentSchema())) {\n                if (ns === this.rootSchema) {\n                    return value;\n                }\n                return (this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value);\n            }\n            if (value instanceof Date && (ns.isTimestampSchema() || ns.isDocumentSchema())) {\n                const format = protocols.determineTimestampFormat(ns, this.settings);\n                switch (format) {\n                    case 5:\n                        return value.toISOString().replace(\".000Z\", \"Z\");\n                    case 6:\n                        return serde.dateToUtcString(value);\n                    case 7:\n                        return value.getTime() / 1000;\n                    default:\n                        console.warn(\"Missing timestamp format, using epoch seconds\", value);\n                        return value.getTime() / 1000;\n                }\n            }\n            if (value instanceof serde.NumericValue) {\n                this.useReplacer = true;\n            }\n        }\n        if (value === null && container?.isStructSchema()) {\n            return void 0;\n        }\n        if (ns.isStringSchema()) {\n            if (typeof value === \"undefined\" && ns.isIdempotencyToken()) {\n                return serde.generateIdempotencyToken();\n            }\n            const mediaType = ns.getMergedTraits().mediaType;\n            if (value != null && mediaType) {\n                const isJson = mediaType === \"application/json\" || mediaType.endsWith(\"+json\");\n                if (isJson) {\n                    return serde.LazyJsonString.from(value);\n                }\n            }\n            return value;\n        }\n        if (typeof value === \"number\" && ns.isNumericSchema()) {\n            if (Math.abs(value) === Infinity || isNaN(value)) {\n                return String(value);\n            }\n            return value;\n        }\n        if (typeof value === \"string\" && ns.isBlobSchema()) {\n            if (ns === this.rootSchema) {\n                return value;\n            }\n            return (this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value);\n        }\n        if (typeof value === \"bigint\") {\n            this.useReplacer = true;\n        }\n        if (ns.isDocumentSchema()) {\n            if (isObject) {\n                const out = Array.isArray(value) ? [] : {};\n                for (const [k, v] of Object.entries(value)) {\n                    if (v instanceof serde.NumericValue) {\n                        this.useReplacer = true;\n                        out[k] = v;\n                    }\n                    else {\n                        out[k] = this._write(ns, v);\n                    }\n                }\n                return out;\n            }\n            else {\n                return structuredClone(value);\n            }\n        }\n        return value;\n    }\n}\n\nclass JsonCodec extends SerdeContextConfig {\n    settings;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    createSerializer() {\n        const serializer = new JsonShapeSerializer(this.settings);\n        serializer.setSerdeContext(this.serdeContext);\n        return serializer;\n    }\n    createDeserializer() {\n        const deserializer = new JsonShapeDeserializer(this.settings);\n        deserializer.setSerdeContext(this.serdeContext);\n        return deserializer;\n    }\n}\n\nclass AwsJsonRpcProtocol extends protocols.RpcProtocol {\n    serializer;\n    deserializer;\n    serviceTarget;\n    codec;\n    mixin;\n    awsQueryCompatible;\n    constructor({ defaultNamespace, serviceTarget, awsQueryCompatible, jsonCodec, }) {\n        super({\n            defaultNamespace,\n        });\n        this.serviceTarget = serviceTarget;\n        this.codec =\n            jsonCodec ??\n                new JsonCodec({\n                    timestampFormat: {\n                        useTrait: true,\n                        default: 7,\n                    },\n                    jsonName: false,\n                });\n        this.serializer = this.codec.createSerializer();\n        this.deserializer = this.codec.createDeserializer();\n        this.awsQueryCompatible = !!awsQueryCompatible;\n        this.mixin = new ProtocolLib(this.awsQueryCompatible);\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        if (!request.path.endsWith(\"/\")) {\n            request.path += \"/\";\n        }\n        Object.assign(request.headers, {\n            \"content-type\": `application/x-amz-json-${this.getJsonRpcVersion()}`,\n            \"x-amz-target\": `${this.serviceTarget}.${operationSchema.name}`,\n        });\n        if (this.awsQueryCompatible) {\n            request.headers[\"x-amzn-query-mode\"] = \"true\";\n        }\n        if (schema.deref(operationSchema.input) === \"unit\" || !request.body) {\n            request.body = \"{}\";\n        }\n        return request;\n    }\n    getPayloadCodec() {\n        return this.codec;\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        if (this.awsQueryCompatible) {\n            this.mixin.setQueryCompatError(dataObject, response);\n        }\n        const errorIdentifier = loadRestJsonErrorCode(response, dataObject) ?? \"Unknown\";\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorIdentifier, this.options.defaultNamespace, response, dataObject, metadata, this.awsQueryCompatible ? this.mixin.findQueryCompatibleError : undefined);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const message = dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            if (dataObject[name] != null) {\n                output[name] = this.codec.createDeserializer().readObject(member, dataObject[name]);\n            }\n        }\n        if (this.awsQueryCompatible) {\n            this.mixin.queryCompatOutput(dataObject, output);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n}\n\nclass AwsJson1_0Protocol extends AwsJsonRpcProtocol {\n    constructor({ defaultNamespace, serviceTarget, awsQueryCompatible, jsonCodec, }) {\n        super({\n            defaultNamespace,\n            serviceTarget,\n            awsQueryCompatible,\n            jsonCodec,\n        });\n    }\n    getShapeId() {\n        return \"aws.protocols#awsJson1_0\";\n    }\n    getJsonRpcVersion() {\n        return \"1.0\";\n    }\n    getDefaultContentType() {\n        return \"application/x-amz-json-1.0\";\n    }\n}\n\nclass AwsJson1_1Protocol extends AwsJsonRpcProtocol {\n    constructor({ defaultNamespace, serviceTarget, awsQueryCompatible, jsonCodec, }) {\n        super({\n            defaultNamespace,\n            serviceTarget,\n            awsQueryCompatible,\n            jsonCodec,\n        });\n    }\n    getShapeId() {\n        return \"aws.protocols#awsJson1_1\";\n    }\n    getJsonRpcVersion() {\n        return \"1.1\";\n    }\n    getDefaultContentType() {\n        return \"application/x-amz-json-1.1\";\n    }\n}\n\nclass AwsRestJsonProtocol extends protocols.HttpBindingProtocol {\n    serializer;\n    deserializer;\n    codec;\n    mixin = new ProtocolLib();\n    constructor({ defaultNamespace }) {\n        super({\n            defaultNamespace,\n        });\n        const settings = {\n            timestampFormat: {\n                useTrait: true,\n                default: 7,\n            },\n            httpBindings: true,\n            jsonName: true,\n        };\n        this.codec = new JsonCodec(settings);\n        this.serializer = new protocols.HttpInterceptingShapeSerializer(this.codec.createSerializer(), settings);\n        this.deserializer = new protocols.HttpInterceptingShapeDeserializer(this.codec.createDeserializer(), settings);\n    }\n    getShapeId() {\n        return \"aws.protocols#restJson1\";\n    }\n    getPayloadCodec() {\n        return this.codec;\n    }\n    setSerdeContext(serdeContext) {\n        this.codec.setSerdeContext(serdeContext);\n        super.setSerdeContext(serdeContext);\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        const inputSchema = schema.NormalizedSchema.of(operationSchema.input);\n        if (!request.headers[\"content-type\"]) {\n            const contentType = this.mixin.resolveRestContentType(this.getDefaultContentType(), inputSchema);\n            if (contentType) {\n                request.headers[\"content-type\"] = contentType;\n            }\n        }\n        if (request.body == null && request.headers[\"content-type\"] === this.getDefaultContentType()) {\n            request.body = \"{}\";\n        }\n        return request;\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        const output = await super.deserializeResponse(operationSchema, context, response);\n        const outputSchema = schema.NormalizedSchema.of(operationSchema.output);\n        for (const [name, member] of outputSchema.structIterator()) {\n            if (member.getMemberTraits().httpPayload && !(name in output)) {\n                output[name] = null;\n            }\n        }\n        return output;\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        const errorIdentifier = loadRestJsonErrorCode(response, dataObject) ?? \"Unknown\";\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorIdentifier, this.options.defaultNamespace, response, dataObject, metadata);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const message = dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        await this.deserializeHttpMessage(errorSchema, context, response, dataObject);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            const target = member.getMergedTraits().jsonName ?? name;\n            output[name] = this.codec.createDeserializer().readObject(member, dataObject[target]);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n    getDefaultContentType() {\n        return \"application/json\";\n    }\n}\n\nconst awsExpectUnion = (value) => {\n    if (value == null) {\n        return undefined;\n    }\n    if (typeof value === \"object\" && \"__type\" in value) {\n        delete value.__type;\n    }\n    return smithyClient.expectUnion(value);\n};\n\nclass XmlShapeDeserializer extends SerdeContextConfig {\n    settings;\n    stringDeserializer;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n        this.stringDeserializer = new protocols.FromStringShapeDeserializer(settings);\n    }\n    setSerdeContext(serdeContext) {\n        this.serdeContext = serdeContext;\n        this.stringDeserializer.setSerdeContext(serdeContext);\n    }\n    read(schema$1, bytes, key) {\n        const ns = schema.NormalizedSchema.of(schema$1);\n        const memberSchemas = ns.getMemberSchemas();\n        const isEventPayload = ns.isStructSchema() &&\n            ns.isMemberSchema() &&\n            !!Object.values(memberSchemas).find((memberNs) => {\n                return !!memberNs.getMemberTraits().eventPayload;\n            });\n        if (isEventPayload) {\n            const output = {};\n            const memberName = Object.keys(memberSchemas)[0];\n            const eventMemberSchema = memberSchemas[memberName];\n            if (eventMemberSchema.isBlobSchema()) {\n                output[memberName] = bytes;\n            }\n            else {\n                output[memberName] = this.read(memberSchemas[memberName], bytes);\n            }\n            return output;\n        }\n        const xmlString = (this.serdeContext?.utf8Encoder ?? utilUtf8.toUtf8)(bytes);\n        const parsedObject = this.parseXml(xmlString);\n        return this.readSchema(schema$1, key ? parsedObject[key] : parsedObject);\n    }\n    readSchema(_schema, value) {\n        const ns = schema.NormalizedSchema.of(_schema);\n        if (ns.isUnitSchema()) {\n            return;\n        }\n        const traits = ns.getMergedTraits();\n        if (ns.isListSchema() && !Array.isArray(value)) {\n            return this.readSchema(ns, [value]);\n        }\n        if (value == null) {\n            return value;\n        }\n        if (typeof value === \"object\") {\n            const sparse = !!traits.sparse;\n            const flat = !!traits.xmlFlattened;\n            if (ns.isListSchema()) {\n                const listValue = ns.getValueSchema();\n                const buffer = [];\n                const sourceKey = listValue.getMergedTraits().xmlName ?? \"member\";\n                const source = flat ? value : (value[0] ?? value)[sourceKey];\n                const sourceArray = Array.isArray(source) ? source : [source];\n                for (const v of sourceArray) {\n                    if (v != null || sparse) {\n                        buffer.push(this.readSchema(listValue, v));\n                    }\n                }\n                return buffer;\n            }\n            const buffer = {};\n            if (ns.isMapSchema()) {\n                const keyNs = ns.getKeySchema();\n                const memberNs = ns.getValueSchema();\n                let entries;\n                if (flat) {\n                    entries = Array.isArray(value) ? value : [value];\n                }\n                else {\n                    entries = Array.isArray(value.entry) ? value.entry : [value.entry];\n                }\n                const keyProperty = keyNs.getMergedTraits().xmlName ?? \"key\";\n                const valueProperty = memberNs.getMergedTraits().xmlName ?? \"value\";\n                for (const entry of entries) {\n                    const key = entry[keyProperty];\n                    const value = entry[valueProperty];\n                    if (value != null || sparse) {\n                        buffer[key] = this.readSchema(memberNs, value);\n                    }\n                }\n                return buffer;\n            }\n            if (ns.isStructSchema()) {\n                const union = ns.isUnionSchema();\n                let unionSerde;\n                if (union) {\n                    unionSerde = new UnionSerde(value, buffer);\n                }\n                for (const [memberName, memberSchema] of ns.structIterator()) {\n                    const memberTraits = memberSchema.getMergedTraits();\n                    const xmlObjectKey = !memberTraits.httpPayload\n                        ? memberSchema.getMemberTraits().xmlName ?? memberName\n                        : memberTraits.xmlName ?? memberSchema.getName();\n                    if (union) {\n                        unionSerde.mark(xmlObjectKey);\n                    }\n                    if (value[xmlObjectKey] != null) {\n                        buffer[memberName] = this.readSchema(memberSchema, value[xmlObjectKey]);\n                    }\n                }\n                if (union) {\n                    unionSerde.writeUnknown();\n                }\n                return buffer;\n            }\n            if (ns.isDocumentSchema()) {\n                return value;\n            }\n            throw new Error(`@aws-sdk/core/protocols - xml deserializer unhandled schema type for ${ns.getName(true)}`);\n        }\n        if (ns.isListSchema()) {\n            return [];\n        }\n        if (ns.isMapSchema() || ns.isStructSchema()) {\n            return {};\n        }\n        return this.stringDeserializer.read(ns, value);\n    }\n    parseXml(xml) {\n        if (xml.length) {\n            let parsedObj;\n            try {\n                parsedObj = xmlBuilder.parseXML(xml);\n            }\n            catch (e) {\n                if (e && typeof e === \"object\") {\n                    Object.defineProperty(e, \"$responseBodyText\", {\n                        value: xml,\n                    });\n                }\n                throw e;\n            }\n            const textNodeName = \"#text\";\n            const key = Object.keys(parsedObj)[0];\n            const parsedObjToReturn = parsedObj[key];\n            if (parsedObjToReturn[textNodeName]) {\n                parsedObjToReturn[key] = parsedObjToReturn[textNodeName];\n                delete parsedObjToReturn[textNodeName];\n            }\n            return smithyClient.getValueFromTextNode(parsedObjToReturn);\n        }\n        return {};\n    }\n}\n\nclass QueryShapeSerializer extends SerdeContextConfig {\n    settings;\n    buffer;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    write(schema$1, value, prefix = \"\") {\n        if (this.buffer === undefined) {\n            this.buffer = \"\";\n        }\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (prefix && !prefix.endsWith(\".\")) {\n            prefix += \".\";\n        }\n        if (ns.isBlobSchema()) {\n            if (typeof value === \"string\" || value instanceof Uint8Array) {\n                this.writeKey(prefix);\n                this.writeValue((this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value));\n            }\n        }\n        else if (ns.isBooleanSchema() || ns.isNumericSchema() || ns.isStringSchema()) {\n            if (value != null) {\n                this.writeKey(prefix);\n                this.writeValue(String(value));\n            }\n            else if (ns.isIdempotencyToken()) {\n                this.writeKey(prefix);\n                this.writeValue(serde.generateIdempotencyToken());\n            }\n        }\n        else if (ns.isBigIntegerSchema()) {\n            if (value != null) {\n                this.writeKey(prefix);\n                this.writeValue(String(value));\n            }\n        }\n        else if (ns.isBigDecimalSchema()) {\n            if (value != null) {\n                this.writeKey(prefix);\n                this.writeValue(value instanceof serde.NumericValue ? value.string : String(value));\n            }\n        }\n        else if (ns.isTimestampSchema()) {\n            if (value instanceof Date) {\n                this.writeKey(prefix);\n                const format = protocols.determineTimestampFormat(ns, this.settings);\n                switch (format) {\n                    case 5:\n                        this.writeValue(value.toISOString().replace(\".000Z\", \"Z\"));\n                        break;\n                    case 6:\n                        this.writeValue(smithyClient.dateToUtcString(value));\n                        break;\n                    case 7:\n                        this.writeValue(String(value.getTime() / 1000));\n                        break;\n                }\n            }\n        }\n        else if (ns.isDocumentSchema()) {\n            if (Array.isArray(value)) {\n                this.write(64 | 15, value, prefix);\n            }\n            else if (value instanceof Date) {\n                this.write(4, value, prefix);\n            }\n            else if (value instanceof Uint8Array) {\n                this.write(21, value, prefix);\n            }\n            else if (value && typeof value === \"object\") {\n                this.write(128 | 15, value, prefix);\n            }\n            else {\n                this.writeKey(prefix);\n                this.writeValue(String(value));\n            }\n        }\n        else if (ns.isListSchema()) {\n            if (Array.isArray(value)) {\n                if (value.length === 0) {\n                    if (this.settings.serializeEmptyLists) {\n                        this.writeKey(prefix);\n                        this.writeValue(\"\");\n                    }\n                }\n                else {\n                    const member = ns.getValueSchema();\n                    const flat = this.settings.flattenLists || ns.getMergedTraits().xmlFlattened;\n                    let i = 1;\n                    for (const item of value) {\n                        if (item == null) {\n                            continue;\n                        }\n                        const suffix = this.getKey(\"member\", member.getMergedTraits().xmlName);\n                        const key = flat ? `${prefix}${i}` : `${prefix}${suffix}.${i}`;\n                        this.write(member, item, key);\n                        ++i;\n                    }\n                }\n            }\n        }\n        else if (ns.isMapSchema()) {\n            if (value && typeof value === \"object\") {\n                const keySchema = ns.getKeySchema();\n                const memberSchema = ns.getValueSchema();\n                const flat = ns.getMergedTraits().xmlFlattened;\n                let i = 1;\n                for (const [k, v] of Object.entries(value)) {\n                    if (v == null) {\n                        continue;\n                    }\n                    const keySuffix = this.getKey(\"key\", keySchema.getMergedTraits().xmlName);\n                    const key = flat ? `${prefix}${i}.${keySuffix}` : `${prefix}entry.${i}.${keySuffix}`;\n                    const valueSuffix = this.getKey(\"value\", memberSchema.getMergedTraits().xmlName);\n                    const valueKey = flat ? `${prefix}${i}.${valueSuffix}` : `${prefix}entry.${i}.${valueSuffix}`;\n                    this.write(keySchema, k, key);\n                    this.write(memberSchema, v, valueKey);\n                    ++i;\n                }\n            }\n        }\n        else if (ns.isStructSchema()) {\n            if (value && typeof value === \"object\") {\n                let didWriteMember = false;\n                for (const [memberName, member] of ns.structIterator()) {\n                    if (value[memberName] == null && !member.isIdempotencyToken()) {\n                        continue;\n                    }\n                    const suffix = this.getKey(memberName, member.getMergedTraits().xmlName);\n                    const key = `${prefix}${suffix}`;\n                    this.write(member, value[memberName], key);\n                    didWriteMember = true;\n                }\n                if (!didWriteMember && ns.isUnionSchema()) {\n                    const { $unknown } = value;\n                    if (Array.isArray($unknown)) {\n                        const [k, v] = $unknown;\n                        const key = `${prefix}${k}`;\n                        this.write(15, v, key);\n                    }\n                }\n            }\n        }\n        else if (ns.isUnitSchema()) ;\n        else {\n            throw new Error(`@aws-sdk/core/protocols - QuerySerializer unrecognized schema type ${ns.getName(true)}`);\n        }\n    }\n    flush() {\n        if (this.buffer === undefined) {\n            throw new Error(\"@aws-sdk/core/protocols - QuerySerializer cannot flush with nothing written to buffer.\");\n        }\n        const str = this.buffer;\n        delete this.buffer;\n        return str;\n    }\n    getKey(memberName, xmlName) {\n        const key = xmlName ?? memberName;\n        if (this.settings.capitalizeKeys) {\n            return key[0].toUpperCase() + key.slice(1);\n        }\n        return key;\n    }\n    writeKey(key) {\n        if (key.endsWith(\".\")) {\n            key = key.slice(0, key.length - 1);\n        }\n        this.buffer += `&${protocols.extendedEncodeURIComponent(key)}=`;\n    }\n    writeValue(value) {\n        this.buffer += protocols.extendedEncodeURIComponent(value);\n    }\n}\n\nclass AwsQueryProtocol extends protocols.RpcProtocol {\n    options;\n    serializer;\n    deserializer;\n    mixin = new ProtocolLib();\n    constructor(options) {\n        super({\n            defaultNamespace: options.defaultNamespace,\n        });\n        this.options = options;\n        const settings = {\n            timestampFormat: {\n                useTrait: true,\n                default: 5,\n            },\n            httpBindings: false,\n            xmlNamespace: options.xmlNamespace,\n            serviceNamespace: options.defaultNamespace,\n            serializeEmptyLists: true,\n        };\n        this.serializer = new QueryShapeSerializer(settings);\n        this.deserializer = new XmlShapeDeserializer(settings);\n    }\n    getShapeId() {\n        return \"aws.protocols#awsQuery\";\n    }\n    setSerdeContext(serdeContext) {\n        this.serializer.setSerdeContext(serdeContext);\n        this.deserializer.setSerdeContext(serdeContext);\n    }\n    getPayloadCodec() {\n        throw new Error(\"AWSQuery protocol has no payload codec.\");\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        if (!request.path.endsWith(\"/\")) {\n            request.path += \"/\";\n        }\n        Object.assign(request.headers, {\n            \"content-type\": `application/x-www-form-urlencoded`,\n        });\n        if (schema.deref(operationSchema.input) === \"unit\" || !request.body) {\n            request.body = \"\";\n        }\n        const action = operationSchema.name.split(\"#\")[1] ?? operationSchema.name;\n        request.body = `Action=${action}&Version=${this.options.version}` + request.body;\n        if (request.body.endsWith(\"&\")) {\n            request.body = request.body.slice(-1);\n        }\n        return request;\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        const deserializer = this.deserializer;\n        const ns = schema.NormalizedSchema.of(operationSchema.output);\n        const dataObject = {};\n        if (response.statusCode >= 300) {\n            const bytes = await protocols.collectBody(response.body, context);\n            if (bytes.byteLength > 0) {\n                Object.assign(dataObject, await deserializer.read(15, bytes));\n            }\n            await this.handleError(operationSchema, context, response, dataObject, this.deserializeMetadata(response));\n        }\n        for (const header in response.headers) {\n            const value = response.headers[header];\n            delete response.headers[header];\n            response.headers[header.toLowerCase()] = value;\n        }\n        const shortName = operationSchema.name.split(\"#\")[1] ?? operationSchema.name;\n        const awsQueryResultKey = ns.isStructSchema() && this.useNestedResult() ? shortName + \"Result\" : undefined;\n        const bytes = await protocols.collectBody(response.body, context);\n        if (bytes.byteLength > 0) {\n            Object.assign(dataObject, await deserializer.read(ns, bytes, awsQueryResultKey));\n        }\n        const output = {\n            $metadata: this.deserializeMetadata(response),\n            ...dataObject,\n        };\n        return output;\n    }\n    useNestedResult() {\n        return true;\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        const errorIdentifier = this.loadQueryErrorCode(response, dataObject) ?? \"Unknown\";\n        const errorData = this.loadQueryError(dataObject);\n        const message = this.loadQueryErrorMessage(dataObject);\n        errorData.message = message;\n        errorData.Error = {\n            Type: errorData.Type,\n            Code: errorData.Code,\n            Message: message,\n        };\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorIdentifier, this.options.defaultNamespace, response, errorData, metadata, this.mixin.findQueryCompatibleError);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        const output = {\n            Type: errorData.Error.Type,\n            Code: errorData.Error.Code,\n            Error: errorData.Error,\n        };\n        for (const [name, member] of ns.structIterator()) {\n            const target = member.getMergedTraits().xmlName ?? name;\n            const value = errorData[target] ?? dataObject[target];\n            output[name] = this.deserializer.readSchema(member, value);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n    loadQueryErrorCode(output, data) {\n        const code = (data.Errors?.[0]?.Error ?? data.Errors?.Error ?? data.Error)?.Code;\n        if (code !== undefined) {\n            return code;\n        }\n        if (output.statusCode == 404) {\n            return \"NotFound\";\n        }\n    }\n    loadQueryError(data) {\n        return data.Errors?.[0]?.Error ?? data.Errors?.Error ?? data.Error;\n    }\n    loadQueryErrorMessage(data) {\n        const errorData = this.loadQueryError(data);\n        return errorData?.message ?? errorData?.Message ?? data.message ?? data.Message ?? \"Unknown\";\n    }\n    getDefaultContentType() {\n        return \"application/x-www-form-urlencoded\";\n    }\n}\n\nclass AwsEc2QueryProtocol extends AwsQueryProtocol {\n    options;\n    constructor(options) {\n        super(options);\n        this.options = options;\n        const ec2Settings = {\n            capitalizeKeys: true,\n            flattenLists: true,\n            serializeEmptyLists: false,\n        };\n        Object.assign(this.serializer.settings, ec2Settings);\n    }\n    useNestedResult() {\n        return false;\n    }\n}\n\nconst parseXmlBody = (streamBody, context) => collectBodyString(streamBody, context).then((encoded) => {\n    if (encoded.length) {\n        let parsedObj;\n        try {\n            parsedObj = xmlBuilder.parseXML(encoded);\n        }\n        catch (e) {\n            if (e && typeof e === \"object\") {\n                Object.defineProperty(e, \"$responseBodyText\", {\n                    value: encoded,\n                });\n            }\n            throw e;\n        }\n        const textNodeName = \"#text\";\n        const key = Object.keys(parsedObj)[0];\n        const parsedObjToReturn = parsedObj[key];\n        if (parsedObjToReturn[textNodeName]) {\n            parsedObjToReturn[key] = parsedObjToReturn[textNodeName];\n            delete parsedObjToReturn[textNodeName];\n        }\n        return smithyClient.getValueFromTextNode(parsedObjToReturn);\n    }\n    return {};\n});\nconst parseXmlErrorBody = async (errorBody, context) => {\n    const value = await parseXmlBody(errorBody, context);\n    if (value.Error) {\n        value.Error.message = value.Error.message ?? value.Error.Message;\n    }\n    return value;\n};\nconst loadRestXmlErrorCode = (output, data) => {\n    if (data?.Error?.Code !== undefined) {\n        return data.Error.Code;\n    }\n    if (data?.Code !== undefined) {\n        return data.Code;\n    }\n    if (output.statusCode == 404) {\n        return \"NotFound\";\n    }\n};\n\nclass XmlShapeSerializer extends SerdeContextConfig {\n    settings;\n    stringBuffer;\n    byteBuffer;\n    buffer;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    write(schema$1, value) {\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (ns.isStringSchema() && typeof value === \"string\") {\n            this.stringBuffer = value;\n        }\n        else if (ns.isBlobSchema()) {\n            this.byteBuffer =\n                \"byteLength\" in value\n                    ? value\n                    : (this.serdeContext?.base64Decoder ?? utilBase64.fromBase64)(value);\n        }\n        else {\n            this.buffer = this.writeStruct(ns, value, undefined);\n            const traits = ns.getMergedTraits();\n            if (traits.httpPayload && !traits.xmlName) {\n                this.buffer.withName(ns.getName());\n            }\n        }\n    }\n    flush() {\n        if (this.byteBuffer !== undefined) {\n            const bytes = this.byteBuffer;\n            delete this.byteBuffer;\n            return bytes;\n        }\n        if (this.stringBuffer !== undefined) {\n            const str = this.stringBuffer;\n            delete this.stringBuffer;\n            return str;\n        }\n        const buffer = this.buffer;\n        if (this.settings.xmlNamespace) {\n            if (!buffer?.attributes?.[\"xmlns\"]) {\n                buffer.addAttribute(\"xmlns\", this.settings.xmlNamespace);\n            }\n        }\n        delete this.buffer;\n        return buffer.toString();\n    }\n    writeStruct(ns, value, parentXmlns) {\n        const traits = ns.getMergedTraits();\n        const name = ns.isMemberSchema() && !traits.httpPayload\n            ? ns.getMemberTraits().xmlName ?? ns.getMemberName()\n            : traits.xmlName ?? ns.getName();\n        if (!name || !ns.isStructSchema()) {\n            throw new Error(`@aws-sdk/core/protocols - xml serializer, cannot write struct with empty name or non-struct, schema=${ns.getName(true)}.`);\n        }\n        const structXmlNode = xmlBuilder.XmlNode.of(name);\n        const [xmlnsAttr, xmlns] = this.getXmlnsAttribute(ns, parentXmlns);\n        for (const [memberName, memberSchema] of ns.structIterator()) {\n            const val = value[memberName];\n            if (val != null || memberSchema.isIdempotencyToken()) {\n                if (memberSchema.getMergedTraits().xmlAttribute) {\n                    structXmlNode.addAttribute(memberSchema.getMergedTraits().xmlName ?? memberName, this.writeSimple(memberSchema, val));\n                    continue;\n                }\n                if (memberSchema.isListSchema()) {\n                    this.writeList(memberSchema, val, structXmlNode, xmlns);\n                }\n                else if (memberSchema.isMapSchema()) {\n                    this.writeMap(memberSchema, val, structXmlNode, xmlns);\n                }\n                else if (memberSchema.isStructSchema()) {\n                    structXmlNode.addChildNode(this.writeStruct(memberSchema, val, xmlns));\n                }\n                else {\n                    const memberNode = xmlBuilder.XmlNode.of(memberSchema.getMergedTraits().xmlName ?? memberSchema.getMemberName());\n                    this.writeSimpleInto(memberSchema, val, memberNode, xmlns);\n                    structXmlNode.addChildNode(memberNode);\n                }\n            }\n        }\n        const { $unknown } = value;\n        if ($unknown && ns.isUnionSchema() && Array.isArray($unknown) && Object.keys(value).length === 1) {\n            const [k, v] = $unknown;\n            const node = xmlBuilder.XmlNode.of(k);\n            if (typeof v !== \"string\") {\n                if (value instanceof xmlBuilder.XmlNode || value instanceof xmlBuilder.XmlText) {\n                    structXmlNode.addChildNode(value);\n                }\n                else {\n                    throw new Error(`@aws-sdk - $unknown union member in XML requires ` +\n                        `value of type string, @aws-sdk/xml-builder::XmlNode or XmlText.`);\n                }\n            }\n            this.writeSimpleInto(0, v, node, xmlns);\n            structXmlNode.addChildNode(node);\n        }\n        if (xmlns) {\n            structXmlNode.addAttribute(xmlnsAttr, xmlns);\n        }\n        return structXmlNode;\n    }\n    writeList(listMember, array, container, parentXmlns) {\n        if (!listMember.isMemberSchema()) {\n            throw new Error(`@aws-sdk/core/protocols - xml serializer, cannot write non-member list: ${listMember.getName(true)}`);\n        }\n        const listTraits = listMember.getMergedTraits();\n        const listValueSchema = listMember.getValueSchema();\n        const listValueTraits = listValueSchema.getMergedTraits();\n        const sparse = !!listValueTraits.sparse;\n        const flat = !!listTraits.xmlFlattened;\n        const [xmlnsAttr, xmlns] = this.getXmlnsAttribute(listMember, parentXmlns);\n        const writeItem = (container, value) => {\n            if (listValueSchema.isListSchema()) {\n                this.writeList(listValueSchema, Array.isArray(value) ? value : [value], container, xmlns);\n            }\n            else if (listValueSchema.isMapSchema()) {\n                this.writeMap(listValueSchema, value, container, xmlns);\n            }\n            else if (listValueSchema.isStructSchema()) {\n                const struct = this.writeStruct(listValueSchema, value, xmlns);\n                container.addChildNode(struct.withName(flat ? listTraits.xmlName ?? listMember.getMemberName() : listValueTraits.xmlName ?? \"member\"));\n            }\n            else {\n                const listItemNode = xmlBuilder.XmlNode.of(flat ? listTraits.xmlName ?? listMember.getMemberName() : listValueTraits.xmlName ?? \"member\");\n                this.writeSimpleInto(listValueSchema, value, listItemNode, xmlns);\n                container.addChildNode(listItemNode);\n            }\n        };\n        if (flat) {\n            for (const value of array) {\n                if (sparse || value != null) {\n                    writeItem(container, value);\n                }\n            }\n        }\n        else {\n            const listNode = xmlBuilder.XmlNode.of(listTraits.xmlName ?? listMember.getMemberName());\n            if (xmlns) {\n                listNode.addAttribute(xmlnsAttr, xmlns);\n            }\n            for (const value of array) {\n                if (sparse || value != null) {\n                    writeItem(listNode, value);\n                }\n            }\n            container.addChildNode(listNode);\n        }\n    }\n    writeMap(mapMember, map, container, parentXmlns, containerIsMap = false) {\n        if (!mapMember.isMemberSchema()) {\n            throw new Error(`@aws-sdk/core/protocols - xml serializer, cannot write non-member map: ${mapMember.getName(true)}`);\n        }\n        const mapTraits = mapMember.getMergedTraits();\n        const mapKeySchema = mapMember.getKeySchema();\n        const mapKeyTraits = mapKeySchema.getMergedTraits();\n        const keyTag = mapKeyTraits.xmlName ?? \"key\";\n        const mapValueSchema = mapMember.getValueSchema();\n        const mapValueTraits = mapValueSchema.getMergedTraits();\n        const valueTag = mapValueTraits.xmlName ?? \"value\";\n        const sparse = !!mapValueTraits.sparse;\n        const flat = !!mapTraits.xmlFlattened;\n        const [xmlnsAttr, xmlns] = this.getXmlnsAttribute(mapMember, parentXmlns);\n        const addKeyValue = (entry, key, val) => {\n            const keyNode = xmlBuilder.XmlNode.of(keyTag, key);\n            const [keyXmlnsAttr, keyXmlns] = this.getXmlnsAttribute(mapKeySchema, xmlns);\n            if (keyXmlns) {\n                keyNode.addAttribute(keyXmlnsAttr, keyXmlns);\n            }\n            entry.addChildNode(keyNode);\n            let valueNode = xmlBuilder.XmlNode.of(valueTag);\n            if (mapValueSchema.isListSchema()) {\n                this.writeList(mapValueSchema, val, valueNode, xmlns);\n            }\n            else if (mapValueSchema.isMapSchema()) {\n                this.writeMap(mapValueSchema, val, valueNode, xmlns, true);\n            }\n            else if (mapValueSchema.isStructSchema()) {\n                valueNode = this.writeStruct(mapValueSchema, val, xmlns);\n            }\n            else {\n                this.writeSimpleInto(mapValueSchema, val, valueNode, xmlns);\n            }\n            entry.addChildNode(valueNode);\n        };\n        if (flat) {\n            for (const [key, val] of Object.entries(map)) {\n                if (sparse || val != null) {\n                    const entry = xmlBuilder.XmlNode.of(mapTraits.xmlName ?? mapMember.getMemberName());\n                    addKeyValue(entry, key, val);\n                    container.addChildNode(entry);\n                }\n            }\n        }\n        else {\n            let mapNode;\n            if (!containerIsMap) {\n                mapNode = xmlBuilder.XmlNode.of(mapTraits.xmlName ?? mapMember.getMemberName());\n                if (xmlns) {\n                    mapNode.addAttribute(xmlnsAttr, xmlns);\n                }\n                container.addChildNode(mapNode);\n            }\n            for (const [key, val] of Object.entries(map)) {\n                if (sparse || val != null) {\n                    const entry = xmlBuilder.XmlNode.of(\"entry\");\n                    addKeyValue(entry, key, val);\n                    (containerIsMap ? container : mapNode).addChildNode(entry);\n                }\n            }\n        }\n    }\n    writeSimple(_schema, value) {\n        if (null === value) {\n            throw new Error(\"@aws-sdk/core/protocols - (XML serializer) cannot write null value.\");\n        }\n        const ns = schema.NormalizedSchema.of(_schema);\n        let nodeContents = null;\n        if (value && typeof value === \"object\") {\n            if (ns.isBlobSchema()) {\n                nodeContents = (this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value);\n            }\n            else if (ns.isTimestampSchema() && value instanceof Date) {\n                const format = protocols.determineTimestampFormat(ns, this.settings);\n                switch (format) {\n                    case 5:\n                        nodeContents = value.toISOString().replace(\".000Z\", \"Z\");\n                        break;\n                    case 6:\n                        nodeContents = smithyClient.dateToUtcString(value);\n                        break;\n                    case 7:\n                        nodeContents = String(value.getTime() / 1000);\n                        break;\n                    default:\n                        console.warn(\"Missing timestamp format, using http date\", value);\n                        nodeContents = smithyClient.dateToUtcString(value);\n                        break;\n                }\n            }\n            else if (ns.isBigDecimalSchema() && value) {\n                if (value instanceof serde.NumericValue) {\n                    return value.string;\n                }\n                return String(value);\n            }\n            else if (ns.isMapSchema() || ns.isListSchema()) {\n                throw new Error(\"@aws-sdk/core/protocols - xml serializer, cannot call _write() on List/Map schema, call writeList or writeMap() instead.\");\n            }\n            else {\n                throw new Error(`@aws-sdk/core/protocols - xml serializer, unhandled schema type for object value and schema: ${ns.getName(true)}`);\n            }\n        }\n        if (ns.isBooleanSchema() || ns.isNumericSchema() || ns.isBigIntegerSchema() || ns.isBigDecimalSchema()) {\n            nodeContents = String(value);\n        }\n        if (ns.isStringSchema()) {\n            if (value === undefined && ns.isIdempotencyToken()) {\n                nodeContents = serde.generateIdempotencyToken();\n            }\n            else {\n                nodeContents = String(value);\n            }\n        }\n        if (nodeContents === null) {\n            throw new Error(`Unhandled schema-value pair ${ns.getName(true)}=${value}`);\n        }\n        return nodeContents;\n    }\n    writeSimpleInto(_schema, value, into, parentXmlns) {\n        const nodeContents = this.writeSimple(_schema, value);\n        const ns = schema.NormalizedSchema.of(_schema);\n        const content = new xmlBuilder.XmlText(nodeContents);\n        const [xmlnsAttr, xmlns] = this.getXmlnsAttribute(ns, parentXmlns);\n        if (xmlns) {\n            into.addAttribute(xmlnsAttr, xmlns);\n        }\n        into.addChildNode(content);\n    }\n    getXmlnsAttribute(ns, parentXmlns) {\n        const traits = ns.getMergedTraits();\n        const [prefix, xmlns] = traits.xmlNamespace ?? [];\n        if (xmlns && xmlns !== parentXmlns) {\n            return [prefix ? `xmlns:${prefix}` : \"xmlns\", xmlns];\n        }\n        return [void 0, void 0];\n    }\n}\n\nclass XmlCodec extends SerdeContextConfig {\n    settings;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    createSerializer() {\n        const serializer = new XmlShapeSerializer(this.settings);\n        serializer.setSerdeContext(this.serdeContext);\n        return serializer;\n    }\n    createDeserializer() {\n        const deserializer = new XmlShapeDeserializer(this.settings);\n        deserializer.setSerdeContext(this.serdeContext);\n        return deserializer;\n    }\n}\n\nclass AwsRestXmlProtocol extends protocols.HttpBindingProtocol {\n    codec;\n    serializer;\n    deserializer;\n    mixin = new ProtocolLib();\n    constructor(options) {\n        super(options);\n        const settings = {\n            timestampFormat: {\n                useTrait: true,\n                default: 5,\n            },\n            httpBindings: true,\n            xmlNamespace: options.xmlNamespace,\n            serviceNamespace: options.defaultNamespace,\n        };\n        this.codec = new XmlCodec(settings);\n        this.serializer = new protocols.HttpInterceptingShapeSerializer(this.codec.createSerializer(), settings);\n        this.deserializer = new protocols.HttpInterceptingShapeDeserializer(this.codec.createDeserializer(), settings);\n    }\n    getPayloadCodec() {\n        return this.codec;\n    }\n    getShapeId() {\n        return \"aws.protocols#restXml\";\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        const inputSchema = schema.NormalizedSchema.of(operationSchema.input);\n        if (!request.headers[\"content-type\"]) {\n            const contentType = this.mixin.resolveRestContentType(this.getDefaultContentType(), inputSchema);\n            if (contentType) {\n                request.headers[\"content-type\"] = contentType;\n            }\n        }\n        if (typeof request.body === \"string\" &&\n            request.headers[\"content-type\"] === this.getDefaultContentType() &&\n            !request.body.startsWith(\"<?xml \") &&\n            !this.hasUnstructuredPayloadBinding(inputSchema)) {\n            request.body = '<?xml version=\"1.0\" encoding=\"UTF-8\"?>' + request.body;\n        }\n        return request;\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        return super.deserializeResponse(operationSchema, context, response);\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        const errorIdentifier = loadRestXmlErrorCode(response, dataObject) ?? \"Unknown\";\n        if (dataObject.Error && typeof dataObject.Error === \"object\") {\n            for (const key of Object.keys(dataObject.Error)) {\n                dataObject[key] = dataObject.Error[key];\n                if (key.toLowerCase() === \"message\") {\n                    dataObject.message = dataObject.Error[key];\n                }\n            }\n        }\n        if (dataObject.RequestId && !metadata.requestId) {\n            metadata.requestId = dataObject.RequestId;\n        }\n        const { errorSchema, errorMetadata } = await this.mixin.getErrorSchemaOrThrowBaseException(errorIdentifier, this.options.defaultNamespace, response, dataObject, metadata);\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const message = dataObject.Error?.message ?? dataObject.Error?.Message ?? dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const ErrorCtor = schema.TypeRegistry.for(errorSchema[1]).getErrorCtor(errorSchema) ?? Error;\n        const exception = new ErrorCtor(message);\n        await this.deserializeHttpMessage(errorSchema, context, response, dataObject);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            const target = member.getMergedTraits().xmlName ?? name;\n            const value = dataObject.Error?.[target] ?? dataObject[target];\n            output[name] = this.codec.createDeserializer().readSchema(member, value);\n        }\n        throw this.mixin.decorateServiceException(Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output), dataObject);\n    }\n    getDefaultContentType() {\n        return \"application/xml\";\n    }\n    hasUnstructuredPayloadBinding(ns) {\n        for (const [, member] of ns.structIterator()) {\n            if (member.getMergedTraits().httpPayload) {\n                return !(member.isStructSchema() || member.isMapSchema() || member.isListSchema());\n            }\n        }\n        return false;\n    }\n}\n\nexports.AwsEc2QueryProtocol = AwsEc2QueryProtocol;\nexports.AwsJson1_0Protocol = AwsJson1_0Protocol;\nexports.AwsJson1_1Protocol = AwsJson1_1Protocol;\nexports.AwsJsonRpcProtocol = AwsJsonRpcProtocol;\nexports.AwsQueryProtocol = AwsQueryProtocol;\nexports.AwsRestJsonProtocol = AwsRestJsonProtocol;\nexports.AwsRestXmlProtocol = AwsRestXmlProtocol;\nexports.AwsSmithyRpcV2CborProtocol = AwsSmithyRpcV2CborProtocol;\nexports.JsonCodec = JsonCodec;\nexports.JsonShapeDeserializer = JsonShapeDeserializer;\nexports.JsonShapeSerializer = JsonShapeSerializer;\nexports.XmlCodec = XmlCodec;\nexports.XmlShapeDeserializer = XmlShapeDeserializer;\nexports.XmlShapeSerializer = XmlShapeSerializer;\nexports._toBool = _toBool;\nexports._toNum = _toNum;\nexports._toStr = _toStr;\nexports.awsExpectUnion = awsExpectUnion;\nexports.loadRestJsonErrorCode = loadRestJsonErrorCode;\nexports.loadRestXmlErrorCode = loadRestXmlErrorCode;\nexports.parseJsonBody = parseJsonBody;\nexports.parseJsonErrorBody = parseJsonErrorBody;\nexports.parseXmlBody = parseXmlBody;\nexports.parseXmlErrorBody = parseXmlErrorBody;\n","'use strict';\n\nconst generateCRC64NVMETable = () => {\n    const sliceLength = 8;\n    const tables = new Array(sliceLength);\n    for (let slice = 0; slice < sliceLength; slice++) {\n        const table = new Array(512);\n        for (let i = 0; i < 256; i++) {\n            let crc = BigInt(i);\n            for (let j = 0; j < 8 * (slice + 1); j++) {\n                if (crc & 1n) {\n                    crc = (crc >> 1n) ^ 0x9a6c9329ac4bc9b5n;\n                }\n                else {\n                    crc = crc >> 1n;\n                }\n            }\n            table[i * 2] = Number((crc >> 32n) & 0xffffffffn);\n            table[i * 2 + 1] = Number(crc & 0xffffffffn);\n        }\n        tables[slice] = new Uint32Array(table);\n    }\n    return tables;\n};\nlet CRC64_NVME_REVERSED_TABLE;\nlet t0, t1, t2, t3;\nlet t4, t5, t6, t7;\nconst ensureTablesInitialized = () => {\n    if (!CRC64_NVME_REVERSED_TABLE) {\n        CRC64_NVME_REVERSED_TABLE = generateCRC64NVMETable();\n        [t0, t1, t2, t3, t4, t5, t6, t7] = CRC64_NVME_REVERSED_TABLE;\n    }\n};\nclass Crc64Nvme {\n    c1 = 0;\n    c2 = 0;\n    constructor() {\n        ensureTablesInitialized();\n        this.reset();\n    }\n    update(data) {\n        const len = data.length;\n        let i = 0;\n        let crc1 = this.c1;\n        let crc2 = this.c2;\n        while (i + 8 <= len) {\n            const idx0 = ((crc2 ^ data[i++]) & 255) << 1;\n            const idx1 = (((crc2 >>> 8) ^ data[i++]) & 255) << 1;\n            const idx2 = (((crc2 >>> 16) ^ data[i++]) & 255) << 1;\n            const idx3 = (((crc2 >>> 24) ^ data[i++]) & 255) << 1;\n            const idx4 = ((crc1 ^ data[i++]) & 255) << 1;\n            const idx5 = (((crc1 >>> 8) ^ data[i++]) & 255) << 1;\n            const idx6 = (((crc1 >>> 16) ^ data[i++]) & 255) << 1;\n            const idx7 = (((crc1 >>> 24) ^ data[i++]) & 255) << 1;\n            crc1 = t7[idx0] ^ t6[idx1] ^ t5[idx2] ^ t4[idx3] ^ t3[idx4] ^ t2[idx5] ^ t1[idx6] ^ t0[idx7];\n            crc2 =\n                t7[idx0 + 1] ^\n                    t6[idx1 + 1] ^\n                    t5[idx2 + 1] ^\n                    t4[idx3 + 1] ^\n                    t3[idx4 + 1] ^\n                    t2[idx5 + 1] ^\n                    t1[idx6 + 1] ^\n                    t0[idx7 + 1];\n        }\n        while (i < len) {\n            const idx = ((crc2 ^ data[i]) & 255) << 1;\n            crc2 = ((crc2 >>> 8) | ((crc1 & 255) << 24)) >>> 0;\n            crc1 = (crc1 >>> 8) ^ t0[idx];\n            crc2 ^= t0[idx + 1];\n            i++;\n        }\n        this.c1 = crc1;\n        this.c2 = crc2;\n    }\n    async digest() {\n        const c1 = this.c1 ^ 4294967295;\n        const c2 = this.c2 ^ 4294967295;\n        return new Uint8Array([\n            c1 >>> 24,\n            (c1 >>> 16) & 255,\n            (c1 >>> 8) & 255,\n            c1 & 255,\n            c2 >>> 24,\n            (c2 >>> 16) & 255,\n            (c2 >>> 8) & 255,\n            c2 & 255,\n        ]);\n    }\n    reset() {\n        this.c1 = 4294967295;\n        this.c2 = 4294967295;\n    }\n}\n\nconst crc64NvmeCrtContainer = {\n    CrtCrc64Nvme: null,\n};\n\nexports.Crc64Nvme = Crc64Nvme;\nexports.crc64NvmeCrtContainer = crc64NvmeCrtContainer;\n","'use strict';\n\nvar client = require('@aws-sdk/core/client');\nvar propertyProvider = require('@smithy/property-provider');\n\nconst ENV_KEY = \"AWS_ACCESS_KEY_ID\";\nconst ENV_SECRET = \"AWS_SECRET_ACCESS_KEY\";\nconst ENV_SESSION = \"AWS_SESSION_TOKEN\";\nconst ENV_EXPIRATION = \"AWS_CREDENTIAL_EXPIRATION\";\nconst ENV_CREDENTIAL_SCOPE = \"AWS_CREDENTIAL_SCOPE\";\nconst ENV_ACCOUNT_ID = \"AWS_ACCOUNT_ID\";\nconst fromEnv = (init) => async () => {\n    init?.logger?.debug(\"@aws-sdk/credential-provider-env - fromEnv\");\n    const accessKeyId = process.env[ENV_KEY];\n    const secretAccessKey = process.env[ENV_SECRET];\n    const sessionToken = process.env[ENV_SESSION];\n    const expiry = process.env[ENV_EXPIRATION];\n    const credentialScope = process.env[ENV_CREDENTIAL_SCOPE];\n    const accountId = process.env[ENV_ACCOUNT_ID];\n    if (accessKeyId && secretAccessKey) {\n        const credentials = {\n            accessKeyId,\n            secretAccessKey,\n            ...(sessionToken && { sessionToken }),\n            ...(expiry && { expiration: new Date(expiry) }),\n            ...(credentialScope && { credentialScope }),\n            ...(accountId && { accountId }),\n        };\n        client.setCredentialFeature(credentials, \"CREDENTIALS_ENV_VARS\", \"g\");\n        return credentials;\n    }\n    throw new propertyProvider.CredentialsProviderError(\"Unable to find environment variable credentials.\", { logger: init?.logger });\n};\n\nexports.ENV_ACCOUNT_ID = ENV_ACCOUNT_ID;\nexports.ENV_CREDENTIAL_SCOPE = ENV_CREDENTIAL_SCOPE;\nexports.ENV_EXPIRATION = ENV_EXPIRATION;\nexports.ENV_KEY = ENV_KEY;\nexports.ENV_SECRET = ENV_SECRET;\nexports.ENV_SESSION = ENV_SESSION;\nexports.fromEnv = fromEnv;\n","'use strict';\n\nvar credentialProviderEnv = require('@aws-sdk/credential-provider-env');\nvar propertyProvider = require('@smithy/property-provider');\nvar sharedIniFileLoader = require('@smithy/shared-ini-file-loader');\n\nconst ENV_IMDS_DISABLED = \"AWS_EC2_METADATA_DISABLED\";\nconst remoteProvider = async (init) => {\n    const { ENV_CMDS_FULL_URI, ENV_CMDS_RELATIVE_URI, fromContainerMetadata, fromInstanceMetadata } = await import('@smithy/credential-provider-imds');\n    if (process.env[ENV_CMDS_RELATIVE_URI] || process.env[ENV_CMDS_FULL_URI]) {\n        init.logger?.debug(\"@aws-sdk/credential-provider-node - remoteProvider::fromHttp/fromContainerMetadata\");\n        const { fromHttp } = await import('@aws-sdk/credential-provider-http');\n        return propertyProvider.chain(fromHttp(init), fromContainerMetadata(init));\n    }\n    if (process.env[ENV_IMDS_DISABLED] && process.env[ENV_IMDS_DISABLED] !== \"false\") {\n        return async () => {\n            throw new propertyProvider.CredentialsProviderError(\"EC2 Instance Metadata Service access disabled\", { logger: init.logger });\n        };\n    }\n    init.logger?.debug(\"@aws-sdk/credential-provider-node - remoteProvider::fromInstanceMetadata\");\n    return fromInstanceMetadata(init);\n};\n\nfunction memoizeChain(providers, treatAsExpired) {\n    const chain = internalCreateChain(providers);\n    let activeLock;\n    let passiveLock;\n    let credentials;\n    const provider = async (options) => {\n        if (options?.forceRefresh) {\n            return await chain(options);\n        }\n        if (credentials?.expiration) {\n            if (credentials?.expiration?.getTime() < Date.now()) {\n                credentials = undefined;\n            }\n        }\n        if (activeLock) {\n            await activeLock;\n        }\n        else if (!credentials || treatAsExpired?.(credentials)) {\n            if (credentials) {\n                if (!passiveLock) {\n                    passiveLock = chain(options)\n                        .then((c) => {\n                        credentials = c;\n                    })\n                        .finally(() => {\n                        passiveLock = undefined;\n                    });\n                }\n            }\n            else {\n                activeLock = chain(options)\n                    .then((c) => {\n                    credentials = c;\n                })\n                    .finally(() => {\n                    activeLock = undefined;\n                });\n                return provider(options);\n            }\n        }\n        return credentials;\n    };\n    return provider;\n}\nconst internalCreateChain = (providers) => async (awsIdentityProperties) => {\n    let lastProviderError;\n    for (const provider of providers) {\n        try {\n            return await provider(awsIdentityProperties);\n        }\n        catch (err) {\n            lastProviderError = err;\n            if (err?.tryNextLink) {\n                continue;\n            }\n            throw err;\n        }\n    }\n    throw lastProviderError;\n};\n\nlet multipleCredentialSourceWarningEmitted = false;\nconst defaultProvider = (init = {}) => memoizeChain([\n    async () => {\n        const profile = init.profile ?? process.env[sharedIniFileLoader.ENV_PROFILE];\n        if (profile) {\n            const envStaticCredentialsAreSet = process.env[credentialProviderEnv.ENV_KEY] && process.env[credentialProviderEnv.ENV_SECRET];\n            if (envStaticCredentialsAreSet) {\n                if (!multipleCredentialSourceWarningEmitted) {\n                    const warnFn = init.logger?.warn && init.logger?.constructor?.name !== \"NoOpLogger\"\n                        ? init.logger.warn.bind(init.logger)\n                        : console.warn;\n                    warnFn(`@aws-sdk/credential-provider-node - defaultProvider::fromEnv WARNING:\n    Multiple credential sources detected: \n    Both AWS_PROFILE and the pair AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY static credentials are set.\n    This SDK will proceed with the AWS_PROFILE value.\n    \n    However, a future version may change this behavior to prefer the ENV static credentials.\n    Please ensure that your environment only sets either the AWS_PROFILE or the\n    AWS_ACCESS_KEY_ID/AWS_SECRET_ACCESS_KEY pair.\n`);\n                    multipleCredentialSourceWarningEmitted = true;\n                }\n            }\n            throw new propertyProvider.CredentialsProviderError(\"AWS_PROFILE is set, skipping fromEnv provider.\", {\n                logger: init.logger,\n                tryNextLink: true,\n            });\n        }\n        init.logger?.debug(\"@aws-sdk/credential-provider-node - defaultProvider::fromEnv\");\n        return credentialProviderEnv.fromEnv(init)();\n    },\n    async (awsIdentityProperties) => {\n        init.logger?.debug(\"@aws-sdk/credential-provider-node - defaultProvider::fromSSO\");\n        const { ssoStartUrl, ssoAccountId, ssoRegion, ssoRoleName, ssoSession } = init;\n        if (!ssoStartUrl && !ssoAccountId && !ssoRegion && !ssoRoleName && !ssoSession) {\n            throw new propertyProvider.CredentialsProviderError(\"Skipping SSO provider in default chain (inputs do not include SSO fields).\", { logger: init.logger });\n        }\n        const { fromSSO } = await import('@aws-sdk/credential-provider-sso');\n        return fromSSO(init)(awsIdentityProperties);\n    },\n    async (awsIdentityProperties) => {\n        init.logger?.debug(\"@aws-sdk/credential-provider-node - defaultProvider::fromIni\");\n        const { fromIni } = await import('@aws-sdk/credential-provider-ini');\n        return fromIni(init)(awsIdentityProperties);\n    },\n    async (awsIdentityProperties) => {\n        init.logger?.debug(\"@aws-sdk/credential-provider-node - defaultProvider::fromProcess\");\n        const { fromProcess } = await import('@aws-sdk/credential-provider-process');\n        return fromProcess(init)(awsIdentityProperties);\n    },\n    async (awsIdentityProperties) => {\n        init.logger?.debug(\"@aws-sdk/credential-provider-node - defaultProvider::fromTokenFile\");\n        const { fromTokenFile } = await import('@aws-sdk/credential-provider-web-identity');\n        return fromTokenFile(init)(awsIdentityProperties);\n    },\n    async () => {\n        init.logger?.debug(\"@aws-sdk/credential-provider-node - defaultProvider::remoteProvider\");\n        return (await remoteProvider(init))();\n    },\n    async () => {\n        throw new propertyProvider.CredentialsProviderError(\"Could not load credentials from any providers\", {\n            tryNextLink: false,\n            logger: init.logger,\n        });\n    },\n], credentialsTreatedAsExpired);\nconst credentialsWillNeedRefresh = (credentials) => credentials?.expiration !== undefined;\nconst credentialsTreatedAsExpired = (credentials) => credentials?.expiration !== undefined && credentials.expiration.getTime() - Date.now() < 300000;\n\nexports.credentialsTreatedAsExpired = credentialsTreatedAsExpired;\nexports.credentialsWillNeedRefresh = credentialsWillNeedRefresh;\nexports.defaultProvider = defaultProvider;\n","'use strict';\n\nvar utilConfigProvider = require('@smithy/util-config-provider');\nvar utilArnParser = require('@aws-sdk/util-arn-parser');\nvar protocolHttp = require('@smithy/protocol-http');\n\nconst NODE_DISABLE_MULTIREGION_ACCESS_POINT_ENV_NAME = \"AWS_S3_DISABLE_MULTIREGION_ACCESS_POINTS\";\nconst NODE_DISABLE_MULTIREGION_ACCESS_POINT_INI_NAME = \"s3_disable_multiregion_access_points\";\nconst NODE_DISABLE_MULTIREGION_ACCESS_POINT_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => utilConfigProvider.booleanSelector(env, NODE_DISABLE_MULTIREGION_ACCESS_POINT_ENV_NAME, utilConfigProvider.SelectorType.ENV),\n    configFileSelector: (profile) => utilConfigProvider.booleanSelector(profile, NODE_DISABLE_MULTIREGION_ACCESS_POINT_INI_NAME, utilConfigProvider.SelectorType.CONFIG),\n    default: false,\n};\n\nconst NODE_USE_ARN_REGION_ENV_NAME = \"AWS_S3_USE_ARN_REGION\";\nconst NODE_USE_ARN_REGION_INI_NAME = \"s3_use_arn_region\";\nconst NODE_USE_ARN_REGION_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => utilConfigProvider.booleanSelector(env, NODE_USE_ARN_REGION_ENV_NAME, utilConfigProvider.SelectorType.ENV),\n    configFileSelector: (profile) => utilConfigProvider.booleanSelector(profile, NODE_USE_ARN_REGION_INI_NAME, utilConfigProvider.SelectorType.CONFIG),\n    default: undefined,\n};\n\nconst DOMAIN_PATTERN = /^[a-z0-9][a-z0-9\\.\\-]{1,61}[a-z0-9]$/;\nconst IP_ADDRESS_PATTERN = /(\\d+\\.){3}\\d+/;\nconst DOTS_PATTERN = /\\.\\./;\nconst DOT_PATTERN = /\\./;\nconst S3_HOSTNAME_PATTERN = /^(.+\\.)?s3(-fips)?(\\.dualstack)?[.-]([a-z0-9-]+)\\./;\nconst S3_US_EAST_1_ALTNAME_PATTERN = /^s3(-external-1)?\\.amazonaws\\.com$/;\nconst AWS_PARTITION_SUFFIX = \"amazonaws.com\";\nconst isBucketNameOptions = (options) => typeof options.bucketName === \"string\";\nconst isDnsCompatibleBucketName = (bucketName) => DOMAIN_PATTERN.test(bucketName) && !IP_ADDRESS_PATTERN.test(bucketName) && !DOTS_PATTERN.test(bucketName);\nconst getRegionalSuffix = (hostname) => {\n    const parts = hostname.match(S3_HOSTNAME_PATTERN);\n    return [parts[4], hostname.replace(new RegExp(`^${parts[0]}`), \"\")];\n};\nconst getSuffix = (hostname) => S3_US_EAST_1_ALTNAME_PATTERN.test(hostname) ? [\"us-east-1\", AWS_PARTITION_SUFFIX] : getRegionalSuffix(hostname);\nconst getSuffixForArnEndpoint = (hostname) => S3_US_EAST_1_ALTNAME_PATTERN.test(hostname)\n    ? [hostname.replace(`.${AWS_PARTITION_SUFFIX}`, \"\"), AWS_PARTITION_SUFFIX]\n    : getRegionalSuffix(hostname);\nconst validateArnEndpointOptions = (options) => {\n    if (options.pathStyleEndpoint) {\n        throw new Error(\"Path-style S3 endpoint is not supported when bucket is an ARN\");\n    }\n    if (options.accelerateEndpoint) {\n        throw new Error(\"Accelerate endpoint is not supported when bucket is an ARN\");\n    }\n    if (!options.tlsCompatible) {\n        throw new Error(\"HTTPS is required when bucket is an ARN\");\n    }\n};\nconst validateService = (service) => {\n    if (service !== \"s3\" && service !== \"s3-outposts\" && service !== \"s3-object-lambda\") {\n        throw new Error(\"Expect 's3' or 's3-outposts' or 's3-object-lambda' in ARN service component\");\n    }\n};\nconst validateS3Service = (service) => {\n    if (service !== \"s3\") {\n        throw new Error(\"Expect 's3' in Accesspoint ARN service component\");\n    }\n};\nconst validateOutpostService = (service) => {\n    if (service !== \"s3-outposts\") {\n        throw new Error(\"Expect 's3-posts' in Outpost ARN service component\");\n    }\n};\nconst validatePartition = (partition, options) => {\n    if (partition !== options.clientPartition) {\n        throw new Error(`Partition in ARN is incompatible, got \"${partition}\" but expected \"${options.clientPartition}\"`);\n    }\n};\nconst validateRegion = (region, options) => { };\nconst validateRegionalClient = (region) => {\n    if ([\"s3-external-1\", \"aws-global\"].includes(region)) {\n        throw new Error(`Client region ${region} is not regional`);\n    }\n};\nconst validateAccountId = (accountId) => {\n    if (!/[0-9]{12}/.exec(accountId)) {\n        throw new Error(\"Access point ARN accountID does not match regex '[0-9]{12}'\");\n    }\n};\nconst validateDNSHostLabel = (label, options = { tlsCompatible: true }) => {\n    if (label.length >= 64 ||\n        !/^[a-z0-9][a-z0-9.-]*[a-z0-9]$/.test(label) ||\n        /(\\d+\\.){3}\\d+/.test(label) ||\n        /[.-]{2}/.test(label) ||\n        (options?.tlsCompatible && DOT_PATTERN.test(label))) {\n        throw new Error(`Invalid DNS label ${label}`);\n    }\n};\nconst validateCustomEndpoint = (options) => {\n    if (options.isCustomEndpoint) {\n        if (options.dualstackEndpoint)\n            throw new Error(\"Dualstack endpoint is not supported with custom endpoint\");\n        if (options.accelerateEndpoint)\n            throw new Error(\"Accelerate endpoint is not supported with custom endpoint\");\n    }\n};\nconst getArnResources = (resource) => {\n    const delimiter = resource.includes(\":\") ? \":\" : \"/\";\n    const [resourceType, ...rest] = resource.split(delimiter);\n    if (resourceType === \"accesspoint\") {\n        if (rest.length !== 1 || rest[0] === \"\") {\n            throw new Error(`Access Point ARN should have one resource accesspoint${delimiter}{accesspointname}`);\n        }\n        return { accesspointName: rest[0] };\n    }\n    else if (resourceType === \"outpost\") {\n        if (!rest[0] || rest[1] !== \"accesspoint\" || !rest[2] || rest.length !== 3) {\n            throw new Error(`Outpost ARN should have resource outpost${delimiter}{outpostId}${delimiter}accesspoint${delimiter}{accesspointName}`);\n        }\n        const [outpostId, _, accesspointName] = rest;\n        return { outpostId, accesspointName };\n    }\n    else {\n        throw new Error(`ARN resource should begin with 'accesspoint${delimiter}' or 'outpost${delimiter}'`);\n    }\n};\nconst validateNoDualstack = (dualstackEndpoint) => { };\nconst validateNoFIPS = (useFipsEndpoint) => {\n    if (useFipsEndpoint)\n        throw new Error(`FIPS region is not supported with Outpost.`);\n};\nconst validateMrapAlias = (name) => {\n    try {\n        name.split(\".\").forEach((label) => {\n            validateDNSHostLabel(label);\n        });\n    }\n    catch (e) {\n        throw new Error(`\"${name}\" is not a DNS compatible name.`);\n    }\n};\n\nconst bucketHostname = (options) => {\n    validateCustomEndpoint(options);\n    return isBucketNameOptions(options)\n        ?\n            getEndpointFromBucketName(options)\n        :\n            getEndpointFromArn(options);\n};\nconst getEndpointFromBucketName = ({ accelerateEndpoint = false, clientRegion: region, baseHostname, bucketName, dualstackEndpoint = false, fipsEndpoint = false, pathStyleEndpoint = false, tlsCompatible = true, isCustomEndpoint = false, }) => {\n    const [clientRegion, hostnameSuffix] = isCustomEndpoint ? [region, baseHostname] : getSuffix(baseHostname);\n    if (pathStyleEndpoint || !isDnsCompatibleBucketName(bucketName) || (tlsCompatible && DOT_PATTERN.test(bucketName))) {\n        return {\n            bucketEndpoint: false,\n            hostname: dualstackEndpoint ? `s3.dualstack.${clientRegion}.${hostnameSuffix}` : baseHostname,\n        };\n    }\n    if (accelerateEndpoint) {\n        baseHostname = `s3-accelerate${dualstackEndpoint ? \".dualstack\" : \"\"}.${hostnameSuffix}`;\n    }\n    else if (dualstackEndpoint) {\n        baseHostname = `s3.dualstack.${clientRegion}.${hostnameSuffix}`;\n    }\n    return {\n        bucketEndpoint: true,\n        hostname: `${bucketName}.${baseHostname}`,\n    };\n};\nconst getEndpointFromArn = (options) => {\n    const { isCustomEndpoint, baseHostname, clientRegion } = options;\n    const hostnameSuffix = isCustomEndpoint ? baseHostname : getSuffixForArnEndpoint(baseHostname)[1];\n    const { pathStyleEndpoint, accelerateEndpoint = false, fipsEndpoint = false, tlsCompatible = true, bucketName, clientPartition = \"aws\", } = options;\n    validateArnEndpointOptions({ pathStyleEndpoint, accelerateEndpoint, tlsCompatible });\n    const { service, partition, accountId, region, resource } = bucketName;\n    validateService(service);\n    validatePartition(partition, { clientPartition });\n    validateAccountId(accountId);\n    const { accesspointName, outpostId } = getArnResources(resource);\n    if (service === \"s3-object-lambda\") {\n        return getEndpointFromObjectLambdaArn({ ...options, tlsCompatible, bucketName, accesspointName, hostnameSuffix });\n    }\n    if (region === \"\") {\n        return getEndpointFromMRAPArn({ ...options, mrapAlias: accesspointName, hostnameSuffix });\n    }\n    if (outpostId) {\n        return getEndpointFromOutpostArn({ ...options, clientRegion, outpostId, accesspointName, hostnameSuffix });\n    }\n    return getEndpointFromAccessPointArn({ ...options, clientRegion, accesspointName, hostnameSuffix });\n};\nconst getEndpointFromObjectLambdaArn = ({ dualstackEndpoint = false, fipsEndpoint = false, tlsCompatible = true, useArnRegion, clientRegion, clientSigningRegion = clientRegion, accesspointName, bucketName, hostnameSuffix, }) => {\n    const { accountId, region, service } = bucketName;\n    validateRegionalClient(clientRegion);\n    const DNSHostLabel = `${accesspointName}-${accountId}`;\n    validateDNSHostLabel(DNSHostLabel, { tlsCompatible });\n    const endpointRegion = useArnRegion ? region : clientRegion;\n    const signingRegion = useArnRegion ? region : clientSigningRegion;\n    return {\n        bucketEndpoint: true,\n        hostname: `${DNSHostLabel}.${service}${fipsEndpoint ? \"-fips\" : \"\"}.${endpointRegion}.${hostnameSuffix}`,\n        signingRegion,\n        signingService: service,\n    };\n};\nconst getEndpointFromMRAPArn = ({ disableMultiregionAccessPoints, dualstackEndpoint = false, isCustomEndpoint, mrapAlias, hostnameSuffix, }) => {\n    if (disableMultiregionAccessPoints === true) {\n        throw new Error(\"SDK is attempting to use a MRAP ARN. Please enable to feature.\");\n    }\n    validateMrapAlias(mrapAlias);\n    return {\n        bucketEndpoint: true,\n        hostname: `${mrapAlias}${isCustomEndpoint ? \"\" : `.accesspoint.s3-global`}.${hostnameSuffix}`,\n        signingRegion: \"*\",\n    };\n};\nconst getEndpointFromOutpostArn = ({ useArnRegion, clientRegion, clientSigningRegion = clientRegion, bucketName, outpostId, dualstackEndpoint = false, fipsEndpoint = false, tlsCompatible = true, accesspointName, isCustomEndpoint, hostnameSuffix, }) => {\n    validateRegionalClient(clientRegion);\n    const DNSHostLabel = `${accesspointName}-${bucketName.accountId}`;\n    validateDNSHostLabel(DNSHostLabel, { tlsCompatible });\n    const endpointRegion = useArnRegion ? bucketName.region : clientRegion;\n    const signingRegion = useArnRegion ? bucketName.region : clientSigningRegion;\n    validateOutpostService(bucketName.service);\n    validateDNSHostLabel(outpostId, { tlsCompatible });\n    validateNoFIPS(fipsEndpoint);\n    const hostnamePrefix = `${DNSHostLabel}.${outpostId}`;\n    return {\n        bucketEndpoint: true,\n        hostname: `${hostnamePrefix}${isCustomEndpoint ? \"\" : `.s3-outposts.${endpointRegion}`}.${hostnameSuffix}`,\n        signingRegion,\n        signingService: \"s3-outposts\",\n    };\n};\nconst getEndpointFromAccessPointArn = ({ useArnRegion, clientRegion, clientSigningRegion = clientRegion, bucketName, dualstackEndpoint = false, fipsEndpoint = false, tlsCompatible = true, accesspointName, isCustomEndpoint, hostnameSuffix, }) => {\n    validateRegionalClient(clientRegion);\n    const hostnamePrefix = `${accesspointName}-${bucketName.accountId}`;\n    validateDNSHostLabel(hostnamePrefix, { tlsCompatible });\n    const endpointRegion = useArnRegion ? bucketName.region : clientRegion;\n    const signingRegion = useArnRegion ? bucketName.region : clientSigningRegion;\n    validateS3Service(bucketName.service);\n    return {\n        bucketEndpoint: true,\n        hostname: `${hostnamePrefix}${isCustomEndpoint\n            ? \"\"\n            : `.s3-accesspoint${fipsEndpoint ? \"-fips\" : \"\"}${dualstackEndpoint ? \".dualstack\" : \"\"}.${endpointRegion}`}.${hostnameSuffix}`,\n        signingRegion,\n    };\n};\n\nconst bucketEndpointMiddleware = (options) => (next, context) => async (args) => {\n    const { Bucket: bucketName } = args.input;\n    let replaceBucketInPath = options.bucketEndpoint;\n    const request = args.request;\n    if (protocolHttp.HttpRequest.isInstance(request)) {\n        if (options.bucketEndpoint) {\n            request.hostname = bucketName;\n        }\n        else if (utilArnParser.validate(bucketName)) {\n            const bucketArn = utilArnParser.parse(bucketName);\n            const clientRegion = await options.region();\n            const useDualstackEndpoint = await options.useDualstackEndpoint();\n            const useFipsEndpoint = await options.useFipsEndpoint();\n            const { partition, signingRegion = clientRegion } = (await options.regionInfoProvider(clientRegion, { useDualstackEndpoint, useFipsEndpoint })) || {};\n            const useArnRegion = await options.useArnRegion();\n            const { hostname, bucketEndpoint, signingRegion: modifiedSigningRegion, signingService, } = bucketHostname({\n                bucketName: bucketArn,\n                baseHostname: request.hostname,\n                accelerateEndpoint: options.useAccelerateEndpoint,\n                dualstackEndpoint: useDualstackEndpoint,\n                fipsEndpoint: useFipsEndpoint,\n                pathStyleEndpoint: options.forcePathStyle,\n                tlsCompatible: request.protocol === \"https:\",\n                useArnRegion,\n                clientPartition: partition,\n                clientSigningRegion: signingRegion,\n                clientRegion: clientRegion,\n                isCustomEndpoint: options.isCustomEndpoint,\n                disableMultiregionAccessPoints: await options.disableMultiregionAccessPoints(),\n            });\n            if (modifiedSigningRegion && modifiedSigningRegion !== signingRegion) {\n                context[\"signing_region\"] = modifiedSigningRegion;\n            }\n            if (signingService && signingService !== \"s3\") {\n                context[\"signing_service\"] = signingService;\n            }\n            request.hostname = hostname;\n            replaceBucketInPath = bucketEndpoint;\n        }\n        else {\n            const clientRegion = await options.region();\n            const dualstackEndpoint = await options.useDualstackEndpoint();\n            const fipsEndpoint = await options.useFipsEndpoint();\n            const { hostname, bucketEndpoint } = bucketHostname({\n                bucketName,\n                clientRegion,\n                baseHostname: request.hostname,\n                accelerateEndpoint: options.useAccelerateEndpoint,\n                dualstackEndpoint,\n                fipsEndpoint,\n                pathStyleEndpoint: options.forcePathStyle,\n                tlsCompatible: request.protocol === \"https:\",\n                isCustomEndpoint: options.isCustomEndpoint,\n            });\n            request.hostname = hostname;\n            replaceBucketInPath = bucketEndpoint;\n        }\n        if (replaceBucketInPath) {\n            request.path = request.path.replace(/^(\\/)?[^\\/]+/, \"\");\n            if (request.path === \"\") {\n                request.path = \"/\";\n            }\n        }\n    }\n    return next({ ...args, request });\n};\nconst bucketEndpointMiddlewareOptions = {\n    tags: [\"BUCKET_ENDPOINT\"],\n    name: \"bucketEndpointMiddleware\",\n    relation: \"before\",\n    toMiddleware: \"hostHeaderMiddleware\",\n    override: true,\n};\nconst getBucketEndpointPlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(bucketEndpointMiddleware(options), bucketEndpointMiddlewareOptions);\n    },\n});\n\nfunction resolveBucketEndpointConfig(input) {\n    const { bucketEndpoint = false, forcePathStyle = false, useAccelerateEndpoint = false, useArnRegion, disableMultiregionAccessPoints = false, } = input;\n    return Object.assign(input, {\n        bucketEndpoint,\n        forcePathStyle,\n        useAccelerateEndpoint,\n        useArnRegion: typeof useArnRegion === \"function\" ? useArnRegion : () => Promise.resolve(useArnRegion),\n        disableMultiregionAccessPoints: typeof disableMultiregionAccessPoints === \"function\"\n            ? disableMultiregionAccessPoints\n            : () => Promise.resolve(disableMultiregionAccessPoints),\n    });\n}\n\nexports.NODE_DISABLE_MULTIREGION_ACCESS_POINT_CONFIG_OPTIONS = NODE_DISABLE_MULTIREGION_ACCESS_POINT_CONFIG_OPTIONS;\nexports.NODE_DISABLE_MULTIREGION_ACCESS_POINT_ENV_NAME = NODE_DISABLE_MULTIREGION_ACCESS_POINT_ENV_NAME;\nexports.NODE_DISABLE_MULTIREGION_ACCESS_POINT_INI_NAME = NODE_DISABLE_MULTIREGION_ACCESS_POINT_INI_NAME;\nexports.NODE_USE_ARN_REGION_CONFIG_OPTIONS = NODE_USE_ARN_REGION_CONFIG_OPTIONS;\nexports.NODE_USE_ARN_REGION_ENV_NAME = NODE_USE_ARN_REGION_ENV_NAME;\nexports.NODE_USE_ARN_REGION_INI_NAME = NODE_USE_ARN_REGION_INI_NAME;\nexports.bucketEndpointMiddleware = bucketEndpointMiddleware;\nexports.bucketEndpointMiddlewareOptions = bucketEndpointMiddlewareOptions;\nexports.bucketHostname = bucketHostname;\nexports.getArnResources = getArnResources;\nexports.getBucketEndpointPlugin = getBucketEndpointPlugin;\nexports.getSuffixForArnEndpoint = getSuffixForArnEndpoint;\nexports.resolveBucketEndpointConfig = resolveBucketEndpointConfig;\nexports.validateAccountId = validateAccountId;\nexports.validateDNSHostLabel = validateDNSHostLabel;\nexports.validateNoDualstack = validateNoDualstack;\nexports.validateNoFIPS = validateNoFIPS;\nexports.validateOutpostService = validateOutpostService;\nexports.validatePartition = validatePartition;\nexports.validateRegion = validateRegion;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\n\nfunction addExpectContinueMiddleware(options) {\n    return (next) => async (args) => {\n        const { request } = args;\n        if (options.expectContinueHeader !== false &&\n            protocolHttp.HttpRequest.isInstance(request) &&\n            request.body &&\n            options.runtime === \"node\" &&\n            options.requestHandler?.constructor?.name !== \"FetchHttpHandler\") {\n            let sendHeader = true;\n            if (typeof options.expectContinueHeader === \"number\") {\n                try {\n                    const bodyLength = Number(request.headers?.[\"content-length\"]) ?? options.bodyLengthChecker?.(request.body) ?? Infinity;\n                    sendHeader = bodyLength >= options.expectContinueHeader;\n                }\n                catch (e) { }\n            }\n            else {\n                sendHeader = !!options.expectContinueHeader;\n            }\n            if (sendHeader) {\n                request.headers.Expect = \"100-continue\";\n            }\n        }\n        return next({\n            ...args,\n            request,\n        });\n    };\n}\nconst addExpectContinueMiddlewareOptions = {\n    step: \"build\",\n    tags: [\"SET_EXPECT_HEADER\", \"EXPECT_HEADER\"],\n    name: \"addExpectContinueMiddleware\",\n    override: true,\n};\nconst getAddExpectContinuePlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(addExpectContinueMiddleware(options), addExpectContinueMiddlewareOptions);\n    },\n});\n\nexports.addExpectContinueMiddleware = addExpectContinueMiddleware;\nexports.addExpectContinueMiddlewareOptions = addExpectContinueMiddlewareOptions;\nexports.getAddExpectContinuePlugin = getAddExpectContinuePlugin;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getCrc32ChecksumAlgorithmFunction = void 0;\nconst tslib_1 = require(\"tslib\");\nconst crc32_1 = require(\"@aws-crypto/crc32\");\nconst util_1 = require(\"@aws-crypto/util\");\nconst zlib = tslib_1.__importStar(require(\"zlib\"));\nclass NodeCrc32 {\n    checksum = 0;\n    update(data) {\n        this.checksum = zlib.crc32(data, this.checksum);\n    }\n    async digest() {\n        return (0, util_1.numToUint8)(this.checksum);\n    }\n    reset() {\n        this.checksum = 0;\n    }\n}\nconst getCrc32ChecksumAlgorithmFunction = () => {\n    if (typeof zlib.crc32 === \"undefined\") {\n        return crc32_1.AwsCrc32;\n    }\n    return NodeCrc32;\n};\nexports.getCrc32ChecksumAlgorithmFunction = getCrc32ChecksumAlgorithmFunction;\n","'use strict';\n\nvar core = require('@aws-sdk/core');\nvar protocolHttp = require('@smithy/protocol-http');\nvar utilStream = require('@smithy/util-stream');\nvar isArrayBuffer = require('@smithy/is-array-buffer');\nvar crc32c = require('@aws-crypto/crc32c');\nvar crc64Nvme = require('@aws-sdk/crc64-nvme');\nvar getCrc32ChecksumAlgorithmFunction = require('./getCrc32ChecksumAlgorithmFunction');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar utilMiddleware = require('@smithy/util-middleware');\n\nconst RequestChecksumCalculation = {\n    WHEN_SUPPORTED: \"WHEN_SUPPORTED\",\n    WHEN_REQUIRED: \"WHEN_REQUIRED\",\n};\nconst DEFAULT_REQUEST_CHECKSUM_CALCULATION = RequestChecksumCalculation.WHEN_SUPPORTED;\nconst ResponseChecksumValidation = {\n    WHEN_SUPPORTED: \"WHEN_SUPPORTED\",\n    WHEN_REQUIRED: \"WHEN_REQUIRED\",\n};\nconst DEFAULT_RESPONSE_CHECKSUM_VALIDATION = RequestChecksumCalculation.WHEN_SUPPORTED;\nexports.ChecksumAlgorithm = void 0;\n(function (ChecksumAlgorithm) {\n    ChecksumAlgorithm[\"MD5\"] = \"MD5\";\n    ChecksumAlgorithm[\"CRC32\"] = \"CRC32\";\n    ChecksumAlgorithm[\"CRC32C\"] = \"CRC32C\";\n    ChecksumAlgorithm[\"CRC64NVME\"] = \"CRC64NVME\";\n    ChecksumAlgorithm[\"SHA1\"] = \"SHA1\";\n    ChecksumAlgorithm[\"SHA256\"] = \"SHA256\";\n})(exports.ChecksumAlgorithm || (exports.ChecksumAlgorithm = {}));\nexports.ChecksumLocation = void 0;\n(function (ChecksumLocation) {\n    ChecksumLocation[\"HEADER\"] = \"header\";\n    ChecksumLocation[\"TRAILER\"] = \"trailer\";\n})(exports.ChecksumLocation || (exports.ChecksumLocation = {}));\nconst DEFAULT_CHECKSUM_ALGORITHM = exports.ChecksumAlgorithm.CRC32;\n\nvar SelectorType;\n(function (SelectorType) {\n    SelectorType[\"ENV\"] = \"env\";\n    SelectorType[\"CONFIG\"] = \"shared config entry\";\n})(SelectorType || (SelectorType = {}));\nconst stringUnionSelector = (obj, key, union, type) => {\n    if (!(key in obj))\n        return undefined;\n    const value = obj[key].toUpperCase();\n    if (!Object.values(union).includes(value)) {\n        throw new TypeError(`Cannot load ${type} '${key}'. Expected one of ${Object.values(union)}, got '${obj[key]}'.`);\n    }\n    return value;\n};\n\nconst ENV_REQUEST_CHECKSUM_CALCULATION = \"AWS_REQUEST_CHECKSUM_CALCULATION\";\nconst CONFIG_REQUEST_CHECKSUM_CALCULATION = \"request_checksum_calculation\";\nconst NODE_REQUEST_CHECKSUM_CALCULATION_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => stringUnionSelector(env, ENV_REQUEST_CHECKSUM_CALCULATION, RequestChecksumCalculation, SelectorType.ENV),\n    configFileSelector: (profile) => stringUnionSelector(profile, CONFIG_REQUEST_CHECKSUM_CALCULATION, RequestChecksumCalculation, SelectorType.CONFIG),\n    default: DEFAULT_REQUEST_CHECKSUM_CALCULATION,\n};\n\nconst ENV_RESPONSE_CHECKSUM_VALIDATION = \"AWS_RESPONSE_CHECKSUM_VALIDATION\";\nconst CONFIG_RESPONSE_CHECKSUM_VALIDATION = \"response_checksum_validation\";\nconst NODE_RESPONSE_CHECKSUM_VALIDATION_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => stringUnionSelector(env, ENV_RESPONSE_CHECKSUM_VALIDATION, ResponseChecksumValidation, SelectorType.ENV),\n    configFileSelector: (profile) => stringUnionSelector(profile, CONFIG_RESPONSE_CHECKSUM_VALIDATION, ResponseChecksumValidation, SelectorType.CONFIG),\n    default: DEFAULT_RESPONSE_CHECKSUM_VALIDATION,\n};\n\nconst CLIENT_SUPPORTED_ALGORITHMS = [\n    exports.ChecksumAlgorithm.CRC32,\n    exports.ChecksumAlgorithm.CRC32C,\n    exports.ChecksumAlgorithm.CRC64NVME,\n    exports.ChecksumAlgorithm.SHA1,\n    exports.ChecksumAlgorithm.SHA256,\n];\nconst PRIORITY_ORDER_ALGORITHMS = [\n    exports.ChecksumAlgorithm.SHA256,\n    exports.ChecksumAlgorithm.SHA1,\n    exports.ChecksumAlgorithm.CRC32,\n    exports.ChecksumAlgorithm.CRC32C,\n    exports.ChecksumAlgorithm.CRC64NVME,\n];\n\nconst getChecksumAlgorithmForRequest = (input, { requestChecksumRequired, requestAlgorithmMember, requestChecksumCalculation }) => {\n    if (!requestAlgorithmMember) {\n        return requestChecksumCalculation === RequestChecksumCalculation.WHEN_SUPPORTED || requestChecksumRequired\n            ? DEFAULT_CHECKSUM_ALGORITHM\n            : undefined;\n    }\n    if (!input[requestAlgorithmMember]) {\n        return undefined;\n    }\n    const checksumAlgorithm = input[requestAlgorithmMember];\n    if (!CLIENT_SUPPORTED_ALGORITHMS.includes(checksumAlgorithm)) {\n        throw new Error(`The checksum algorithm \"${checksumAlgorithm}\" is not supported by the client.` +\n            ` Select one of ${CLIENT_SUPPORTED_ALGORITHMS}.`);\n    }\n    return checksumAlgorithm;\n};\n\nconst getChecksumLocationName = (algorithm) => algorithm === exports.ChecksumAlgorithm.MD5 ? \"content-md5\" : `x-amz-checksum-${algorithm.toLowerCase()}`;\n\nconst hasHeader = (header, headers) => {\n    const soughtHeader = header.toLowerCase();\n    for (const headerName of Object.keys(headers)) {\n        if (soughtHeader === headerName.toLowerCase()) {\n            return true;\n        }\n    }\n    return false;\n};\n\nconst hasHeaderWithPrefix = (headerPrefix, headers) => {\n    const soughtHeaderPrefix = headerPrefix.toLowerCase();\n    for (const headerName of Object.keys(headers)) {\n        if (headerName.toLowerCase().startsWith(soughtHeaderPrefix)) {\n            return true;\n        }\n    }\n    return false;\n};\n\nconst isStreaming = (body) => body !== undefined && typeof body !== \"string\" && !ArrayBuffer.isView(body) && !isArrayBuffer.isArrayBuffer(body);\n\nconst selectChecksumAlgorithmFunction = (checksumAlgorithm, config) => {\n    switch (checksumAlgorithm) {\n        case exports.ChecksumAlgorithm.MD5:\n            return config.md5;\n        case exports.ChecksumAlgorithm.CRC32:\n            return getCrc32ChecksumAlgorithmFunction.getCrc32ChecksumAlgorithmFunction();\n        case exports.ChecksumAlgorithm.CRC32C:\n            return crc32c.AwsCrc32c;\n        case exports.ChecksumAlgorithm.CRC64NVME:\n            if (typeof crc64Nvme.crc64NvmeCrtContainer.CrtCrc64Nvme !== \"function\") {\n                return crc64Nvme.Crc64Nvme;\n            }\n            return crc64Nvme.crc64NvmeCrtContainer.CrtCrc64Nvme;\n        case exports.ChecksumAlgorithm.SHA1:\n            return config.sha1;\n        case exports.ChecksumAlgorithm.SHA256:\n            return config.sha256;\n        default:\n            throw new Error(`Unsupported checksum algorithm: ${checksumAlgorithm}`);\n    }\n};\n\nconst stringHasher = (checksumAlgorithmFn, body) => {\n    const hash = new checksumAlgorithmFn();\n    hash.update(utilUtf8.toUint8Array(body || \"\"));\n    return hash.digest();\n};\n\nconst flexibleChecksumsMiddlewareOptions = {\n    name: \"flexibleChecksumsMiddleware\",\n    step: \"build\",\n    tags: [\"BODY_CHECKSUM\"],\n    override: true,\n};\nconst flexibleChecksumsMiddleware = (config, middlewareConfig) => (next, context) => async (args) => {\n    if (!protocolHttp.HttpRequest.isInstance(args.request)) {\n        return next(args);\n    }\n    if (hasHeaderWithPrefix(\"x-amz-checksum-\", args.request.headers)) {\n        return next(args);\n    }\n    const { request, input } = args;\n    const { body: requestBody, headers } = request;\n    const { base64Encoder, streamHasher } = config;\n    const { requestChecksumRequired, requestAlgorithmMember } = middlewareConfig;\n    const requestChecksumCalculation = await config.requestChecksumCalculation();\n    const requestAlgorithmMemberName = requestAlgorithmMember?.name;\n    const requestAlgorithmMemberHttpHeader = requestAlgorithmMember?.httpHeader;\n    if (requestAlgorithmMemberName && !input[requestAlgorithmMemberName]) {\n        if (requestChecksumCalculation === RequestChecksumCalculation.WHEN_SUPPORTED || requestChecksumRequired) {\n            input[requestAlgorithmMemberName] = DEFAULT_CHECKSUM_ALGORITHM;\n            if (requestAlgorithmMemberHttpHeader) {\n                headers[requestAlgorithmMemberHttpHeader] = DEFAULT_CHECKSUM_ALGORITHM;\n            }\n        }\n    }\n    const checksumAlgorithm = getChecksumAlgorithmForRequest(input, {\n        requestChecksumRequired,\n        requestAlgorithmMember: requestAlgorithmMember?.name,\n        requestChecksumCalculation,\n    });\n    let updatedBody = requestBody;\n    let updatedHeaders = headers;\n    if (checksumAlgorithm) {\n        switch (checksumAlgorithm) {\n            case exports.ChecksumAlgorithm.CRC32:\n                core.setFeature(context, \"FLEXIBLE_CHECKSUMS_REQ_CRC32\", \"U\");\n                break;\n            case exports.ChecksumAlgorithm.CRC32C:\n                core.setFeature(context, \"FLEXIBLE_CHECKSUMS_REQ_CRC32C\", \"V\");\n                break;\n            case exports.ChecksumAlgorithm.CRC64NVME:\n                core.setFeature(context, \"FLEXIBLE_CHECKSUMS_REQ_CRC64\", \"W\");\n                break;\n            case exports.ChecksumAlgorithm.SHA1:\n                core.setFeature(context, \"FLEXIBLE_CHECKSUMS_REQ_SHA1\", \"X\");\n                break;\n            case exports.ChecksumAlgorithm.SHA256:\n                core.setFeature(context, \"FLEXIBLE_CHECKSUMS_REQ_SHA256\", \"Y\");\n                break;\n        }\n        const checksumLocationName = getChecksumLocationName(checksumAlgorithm);\n        const checksumAlgorithmFn = selectChecksumAlgorithmFunction(checksumAlgorithm, config);\n        if (isStreaming(requestBody)) {\n            const { getAwsChunkedEncodingStream, bodyLengthChecker } = config;\n            updatedBody = getAwsChunkedEncodingStream(typeof config.requestStreamBufferSize === \"number\" && config.requestStreamBufferSize >= 8 * 1024\n                ? utilStream.createBufferedReadable(requestBody, config.requestStreamBufferSize, context.logger)\n                : requestBody, {\n                base64Encoder,\n                bodyLengthChecker,\n                checksumLocationName,\n                checksumAlgorithmFn,\n                streamHasher,\n            });\n            updatedHeaders = {\n                ...headers,\n                \"content-encoding\": headers[\"content-encoding\"]\n                    ? `${headers[\"content-encoding\"]},aws-chunked`\n                    : \"aws-chunked\",\n                \"transfer-encoding\": \"chunked\",\n                \"x-amz-decoded-content-length\": headers[\"content-length\"],\n                \"x-amz-content-sha256\": \"STREAMING-UNSIGNED-PAYLOAD-TRAILER\",\n                \"x-amz-trailer\": checksumLocationName,\n            };\n            delete updatedHeaders[\"content-length\"];\n        }\n        else if (!hasHeader(checksumLocationName, headers)) {\n            const rawChecksum = await stringHasher(checksumAlgorithmFn, requestBody);\n            updatedHeaders = {\n                ...headers,\n                [checksumLocationName]: base64Encoder(rawChecksum),\n            };\n        }\n    }\n    try {\n        const result = await next({\n            ...args,\n            request: {\n                ...request,\n                headers: updatedHeaders,\n                body: updatedBody,\n            },\n        });\n        return result;\n    }\n    catch (e) {\n        if (e instanceof Error && e.name === \"InvalidChunkSizeError\") {\n            try {\n                if (!e.message.endsWith(\".\")) {\n                    e.message += \".\";\n                }\n                e.message +=\n                    \" Set [requestStreamBufferSize=number e.g. 65_536] in client constructor to instruct AWS SDK to buffer your input stream.\";\n            }\n            catch (ignored) {\n            }\n        }\n        throw e;\n    }\n};\n\nconst flexibleChecksumsInputMiddlewareOptions = {\n    name: \"flexibleChecksumsInputMiddleware\",\n    toMiddleware: \"serializerMiddleware\",\n    relation: \"before\",\n    tags: [\"BODY_CHECKSUM\"],\n    override: true,\n};\nconst flexibleChecksumsInputMiddleware = (config, middlewareConfig) => (next, context) => async (args) => {\n    const input = args.input;\n    const { requestValidationModeMember } = middlewareConfig;\n    const requestChecksumCalculation = await config.requestChecksumCalculation();\n    const responseChecksumValidation = await config.responseChecksumValidation();\n    switch (requestChecksumCalculation) {\n        case RequestChecksumCalculation.WHEN_REQUIRED:\n            core.setFeature(context, \"FLEXIBLE_CHECKSUMS_REQ_WHEN_REQUIRED\", \"a\");\n            break;\n        case RequestChecksumCalculation.WHEN_SUPPORTED:\n            core.setFeature(context, \"FLEXIBLE_CHECKSUMS_REQ_WHEN_SUPPORTED\", \"Z\");\n            break;\n    }\n    switch (responseChecksumValidation) {\n        case ResponseChecksumValidation.WHEN_REQUIRED:\n            core.setFeature(context, \"FLEXIBLE_CHECKSUMS_RES_WHEN_REQUIRED\", \"c\");\n            break;\n        case ResponseChecksumValidation.WHEN_SUPPORTED:\n            core.setFeature(context, \"FLEXIBLE_CHECKSUMS_RES_WHEN_SUPPORTED\", \"b\");\n            break;\n    }\n    if (requestValidationModeMember && !input[requestValidationModeMember]) {\n        if (responseChecksumValidation === ResponseChecksumValidation.WHEN_SUPPORTED) {\n            input[requestValidationModeMember] = \"ENABLED\";\n        }\n    }\n    return next(args);\n};\n\nconst getChecksumAlgorithmListForResponse = (responseAlgorithms = []) => {\n    const validChecksumAlgorithms = [];\n    for (const algorithm of PRIORITY_ORDER_ALGORITHMS) {\n        if (!responseAlgorithms.includes(algorithm) || !CLIENT_SUPPORTED_ALGORITHMS.includes(algorithm)) {\n            continue;\n        }\n        validChecksumAlgorithms.push(algorithm);\n    }\n    return validChecksumAlgorithms;\n};\n\nconst isChecksumWithPartNumber = (checksum) => {\n    const lastHyphenIndex = checksum.lastIndexOf(\"-\");\n    if (lastHyphenIndex !== -1) {\n        const numberPart = checksum.slice(lastHyphenIndex + 1);\n        if (!numberPart.startsWith(\"0\")) {\n            const number = parseInt(numberPart, 10);\n            if (!isNaN(number) && number >= 1 && number <= 10000) {\n                return true;\n            }\n        }\n    }\n    return false;\n};\n\nconst getChecksum = async (body, { checksumAlgorithmFn, base64Encoder }) => base64Encoder(await stringHasher(checksumAlgorithmFn, body));\n\nconst validateChecksumFromResponse = async (response, { config, responseAlgorithms, logger }) => {\n    const checksumAlgorithms = getChecksumAlgorithmListForResponse(responseAlgorithms);\n    const { body: responseBody, headers: responseHeaders } = response;\n    for (const algorithm of checksumAlgorithms) {\n        const responseHeader = getChecksumLocationName(algorithm);\n        const checksumFromResponse = responseHeaders[responseHeader];\n        if (checksumFromResponse) {\n            let checksumAlgorithmFn;\n            try {\n                checksumAlgorithmFn = selectChecksumAlgorithmFunction(algorithm, config);\n            }\n            catch (error) {\n                if (algorithm === exports.ChecksumAlgorithm.CRC64NVME) {\n                    logger?.warn(`Skipping ${exports.ChecksumAlgorithm.CRC64NVME} checksum validation: ${error.message}`);\n                    continue;\n                }\n                throw error;\n            }\n            const { base64Encoder } = config;\n            if (isStreaming(responseBody)) {\n                response.body = utilStream.createChecksumStream({\n                    expectedChecksum: checksumFromResponse,\n                    checksumSourceLocation: responseHeader,\n                    checksum: new checksumAlgorithmFn(),\n                    source: responseBody,\n                    base64Encoder,\n                });\n                return;\n            }\n            const checksum = await getChecksum(responseBody, { checksumAlgorithmFn, base64Encoder });\n            if (checksum === checksumFromResponse) {\n                break;\n            }\n            throw new Error(`Checksum mismatch: expected \"${checksum}\" but received \"${checksumFromResponse}\"` +\n                ` in response header \"${responseHeader}\".`);\n        }\n    }\n};\n\nconst flexibleChecksumsResponseMiddlewareOptions = {\n    name: \"flexibleChecksumsResponseMiddleware\",\n    toMiddleware: \"deserializerMiddleware\",\n    relation: \"after\",\n    tags: [\"BODY_CHECKSUM\"],\n    override: true,\n};\nconst flexibleChecksumsResponseMiddleware = (config, middlewareConfig) => (next, context) => async (args) => {\n    if (!protocolHttp.HttpRequest.isInstance(args.request)) {\n        return next(args);\n    }\n    const input = args.input;\n    const result = await next(args);\n    const response = result.response;\n    const { requestValidationModeMember, responseAlgorithms } = middlewareConfig;\n    if (requestValidationModeMember && input[requestValidationModeMember] === \"ENABLED\") {\n        const { clientName, commandName } = context;\n        const isS3WholeObjectMultipartGetResponseChecksum = clientName === \"S3Client\" &&\n            commandName === \"GetObjectCommand\" &&\n            getChecksumAlgorithmListForResponse(responseAlgorithms).every((algorithm) => {\n                const responseHeader = getChecksumLocationName(algorithm);\n                const checksumFromResponse = response.headers[responseHeader];\n                return !checksumFromResponse || isChecksumWithPartNumber(checksumFromResponse);\n            });\n        if (isS3WholeObjectMultipartGetResponseChecksum) {\n            return result;\n        }\n        await validateChecksumFromResponse(response, {\n            config,\n            responseAlgorithms,\n            logger: context.logger,\n        });\n    }\n    return result;\n};\n\nconst getFlexibleChecksumsPlugin = (config, middlewareConfig) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(flexibleChecksumsMiddleware(config, middlewareConfig), flexibleChecksumsMiddlewareOptions);\n        clientStack.addRelativeTo(flexibleChecksumsInputMiddleware(config, middlewareConfig), flexibleChecksumsInputMiddlewareOptions);\n        clientStack.addRelativeTo(flexibleChecksumsResponseMiddleware(config, middlewareConfig), flexibleChecksumsResponseMiddlewareOptions);\n    },\n});\n\nconst resolveFlexibleChecksumsConfig = (input) => {\n    const { requestChecksumCalculation, responseChecksumValidation, requestStreamBufferSize } = input;\n    return Object.assign(input, {\n        requestChecksumCalculation: utilMiddleware.normalizeProvider(requestChecksumCalculation ?? DEFAULT_REQUEST_CHECKSUM_CALCULATION),\n        responseChecksumValidation: utilMiddleware.normalizeProvider(responseChecksumValidation ?? DEFAULT_RESPONSE_CHECKSUM_VALIDATION),\n        requestStreamBufferSize: Number(requestStreamBufferSize ?? 0),\n    });\n};\n\nexports.CONFIG_REQUEST_CHECKSUM_CALCULATION = CONFIG_REQUEST_CHECKSUM_CALCULATION;\nexports.CONFIG_RESPONSE_CHECKSUM_VALIDATION = CONFIG_RESPONSE_CHECKSUM_VALIDATION;\nexports.DEFAULT_CHECKSUM_ALGORITHM = DEFAULT_CHECKSUM_ALGORITHM;\nexports.DEFAULT_REQUEST_CHECKSUM_CALCULATION = DEFAULT_REQUEST_CHECKSUM_CALCULATION;\nexports.DEFAULT_RESPONSE_CHECKSUM_VALIDATION = DEFAULT_RESPONSE_CHECKSUM_VALIDATION;\nexports.ENV_REQUEST_CHECKSUM_CALCULATION = ENV_REQUEST_CHECKSUM_CALCULATION;\nexports.ENV_RESPONSE_CHECKSUM_VALIDATION = ENV_RESPONSE_CHECKSUM_VALIDATION;\nexports.NODE_REQUEST_CHECKSUM_CALCULATION_CONFIG_OPTIONS = NODE_REQUEST_CHECKSUM_CALCULATION_CONFIG_OPTIONS;\nexports.NODE_RESPONSE_CHECKSUM_VALIDATION_CONFIG_OPTIONS = NODE_RESPONSE_CHECKSUM_VALIDATION_CONFIG_OPTIONS;\nexports.RequestChecksumCalculation = RequestChecksumCalculation;\nexports.ResponseChecksumValidation = ResponseChecksumValidation;\nexports.flexibleChecksumsMiddleware = flexibleChecksumsMiddleware;\nexports.flexibleChecksumsMiddlewareOptions = flexibleChecksumsMiddlewareOptions;\nexports.getFlexibleChecksumsPlugin = getFlexibleChecksumsPlugin;\nexports.resolveFlexibleChecksumsConfig = resolveFlexibleChecksumsConfig;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\n\nfunction resolveHostHeaderConfig(input) {\n    return input;\n}\nconst hostHeaderMiddleware = (options) => (next) => async (args) => {\n    if (!protocolHttp.HttpRequest.isInstance(args.request))\n        return next(args);\n    const { request } = args;\n    const { handlerProtocol = \"\" } = options.requestHandler.metadata || {};\n    if (handlerProtocol.indexOf(\"h2\") >= 0 && !request.headers[\":authority\"]) {\n        delete request.headers[\"host\"];\n        request.headers[\":authority\"] = request.hostname + (request.port ? \":\" + request.port : \"\");\n    }\n    else if (!request.headers[\"host\"]) {\n        let host = request.hostname;\n        if (request.port != null)\n            host += `:${request.port}`;\n        request.headers[\"host\"] = host;\n    }\n    return next(args);\n};\nconst hostHeaderMiddlewareOptions = {\n    name: \"hostHeaderMiddleware\",\n    step: \"build\",\n    priority: \"low\",\n    tags: [\"HOST\"],\n    override: true,\n};\nconst getHostHeaderPlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(hostHeaderMiddleware(options), hostHeaderMiddlewareOptions);\n    },\n});\n\nexports.getHostHeaderPlugin = getHostHeaderPlugin;\nexports.hostHeaderMiddleware = hostHeaderMiddleware;\nexports.hostHeaderMiddlewareOptions = hostHeaderMiddlewareOptions;\nexports.resolveHostHeaderConfig = resolveHostHeaderConfig;\n","'use strict';\n\nfunction locationConstraintMiddleware(options) {\n    return (next) => async (args) => {\n        const { CreateBucketConfiguration } = args.input;\n        const region = await options.region();\n        if (!CreateBucketConfiguration?.LocationConstraint && !CreateBucketConfiguration?.Location) {\n            if (region !== \"us-east-1\") {\n                args.input.CreateBucketConfiguration = args.input.CreateBucketConfiguration ?? {};\n                args.input.CreateBucketConfiguration.LocationConstraint = region;\n            }\n        }\n        return next(args);\n    };\n}\nconst locationConstraintMiddlewareOptions = {\n    step: \"initialize\",\n    tags: [\"LOCATION_CONSTRAINT\", \"CREATE_BUCKET_CONFIGURATION\"],\n    name: \"locationConstraintMiddleware\",\n    override: true,\n};\nconst getLocationConstraintPlugin = (config) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(locationConstraintMiddleware(config), locationConstraintMiddlewareOptions);\n    },\n});\n\nexports.getLocationConstraintPlugin = getLocationConstraintPlugin;\nexports.locationConstraintMiddleware = locationConstraintMiddleware;\nexports.locationConstraintMiddlewareOptions = locationConstraintMiddlewareOptions;\n","'use strict';\n\nconst loggerMiddleware = () => (next, context) => async (args) => {\n    try {\n        const response = await next(args);\n        const { clientName, commandName, logger, dynamoDbDocumentClientOptions = {} } = context;\n        const { overrideInputFilterSensitiveLog, overrideOutputFilterSensitiveLog } = dynamoDbDocumentClientOptions;\n        const inputFilterSensitiveLog = overrideInputFilterSensitiveLog ?? context.inputFilterSensitiveLog;\n        const outputFilterSensitiveLog = overrideOutputFilterSensitiveLog ?? context.outputFilterSensitiveLog;\n        const { $metadata, ...outputWithoutMetadata } = response.output;\n        logger?.info?.({\n            clientName,\n            commandName,\n            input: inputFilterSensitiveLog(args.input),\n            output: outputFilterSensitiveLog(outputWithoutMetadata),\n            metadata: $metadata,\n        });\n        return response;\n    }\n    catch (error) {\n        const { clientName, commandName, logger, dynamoDbDocumentClientOptions = {} } = context;\n        const { overrideInputFilterSensitiveLog } = dynamoDbDocumentClientOptions;\n        const inputFilterSensitiveLog = overrideInputFilterSensitiveLog ?? context.inputFilterSensitiveLog;\n        logger?.error?.({\n            clientName,\n            commandName,\n            input: inputFilterSensitiveLog(args.input),\n            error,\n            metadata: error.$metadata,\n        });\n        throw error;\n    }\n};\nconst loggerMiddlewareOptions = {\n    name: \"loggerMiddleware\",\n    tags: [\"LOGGER\"],\n    step: \"initialize\",\n    override: true,\n};\nconst getLoggerPlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(loggerMiddleware(), loggerMiddlewareOptions);\n    },\n});\n\nexports.getLoggerPlugin = getLoggerPlugin;\nexports.loggerMiddleware = loggerMiddleware;\nexports.loggerMiddlewareOptions = loggerMiddlewareOptions;\n","'use strict';\n\nvar recursionDetectionMiddleware = require('./recursionDetectionMiddleware');\n\nconst recursionDetectionMiddlewareOptions = {\n    step: \"build\",\n    tags: [\"RECURSION_DETECTION\"],\n    name: \"recursionDetectionMiddleware\",\n    override: true,\n    priority: \"low\",\n};\n\nconst getRecursionDetectionPlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(recursionDetectionMiddleware.recursionDetectionMiddleware(), recursionDetectionMiddlewareOptions);\n    },\n});\n\nexports.getRecursionDetectionPlugin = getRecursionDetectionPlugin;\nObject.keys(recursionDetectionMiddleware).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return recursionDetectionMiddleware[k]; }\n    });\n});\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.recursionDetectionMiddleware = void 0;\nconst lambda_invoke_store_1 = require(\"@aws/lambda-invoke-store\");\nconst protocol_http_1 = require(\"@smithy/protocol-http\");\nconst TRACE_ID_HEADER_NAME = \"X-Amzn-Trace-Id\";\nconst ENV_LAMBDA_FUNCTION_NAME = \"AWS_LAMBDA_FUNCTION_NAME\";\nconst ENV_TRACE_ID = \"_X_AMZN_TRACE_ID\";\nconst recursionDetectionMiddleware = () => (next) => async (args) => {\n    const { request } = args;\n    if (!protocol_http_1.HttpRequest.isInstance(request)) {\n        return next(args);\n    }\n    const traceIdHeader = Object.keys(request.headers ?? {}).find((h) => h.toLowerCase() === TRACE_ID_HEADER_NAME.toLowerCase()) ??\n        TRACE_ID_HEADER_NAME;\n    if (request.headers.hasOwnProperty(traceIdHeader)) {\n        return next(args);\n    }\n    const functionName = process.env[ENV_LAMBDA_FUNCTION_NAME];\n    const traceIdFromEnv = process.env[ENV_TRACE_ID];\n    const invokeStore = await lambda_invoke_store_1.InvokeStore.getInstanceAsync();\n    const traceIdFromInvokeStore = invokeStore?.getXRayTraceId();\n    const traceId = traceIdFromInvokeStore ?? traceIdFromEnv;\n    const nonEmptyString = (str) => typeof str === \"string\" && str.length > 0;\n    if (nonEmptyString(functionName) && nonEmptyString(traceId)) {\n        request.headers[TRACE_ID_HEADER_NAME] = traceId;\n    }\n    return next({\n        ...args,\n        request,\n    });\n};\nexports.recursionDetectionMiddleware = recursionDetectionMiddleware;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\nvar smithyClient = require('@smithy/smithy-client');\nvar utilStream = require('@smithy/util-stream');\nvar utilArnParser = require('@aws-sdk/util-arn-parser');\nvar signatureV4 = require('@smithy/signature-v4');\nvar utilConfigProvider = require('@smithy/util-config-provider');\nvar core = require('@aws-sdk/core');\nvar core$1 = require('@smithy/core');\nrequire('@smithy/types');\nvar utilMiddleware = require('@smithy/util-middleware');\n\nconst CONTENT_LENGTH_HEADER = \"content-length\";\nconst DECODED_CONTENT_LENGTH_HEADER = \"x-amz-decoded-content-length\";\nfunction checkContentLengthHeader() {\n    return (next, context) => async (args) => {\n        const { request } = args;\n        if (protocolHttp.HttpRequest.isInstance(request)) {\n            if (!(CONTENT_LENGTH_HEADER in request.headers) && !(DECODED_CONTENT_LENGTH_HEADER in request.headers)) {\n                const message = `Are you using a Stream of unknown length as the Body of a PutObject request? Consider using Upload instead from @aws-sdk/lib-storage.`;\n                if (typeof context?.logger?.warn === \"function\" && !(context.logger instanceof smithyClient.NoOpLogger)) {\n                    context.logger.warn(message);\n                }\n                else {\n                    console.warn(message);\n                }\n            }\n        }\n        return next({ ...args });\n    };\n}\nconst checkContentLengthHeaderMiddlewareOptions = {\n    step: \"finalizeRequest\",\n    tags: [\"CHECK_CONTENT_LENGTH_HEADER\"],\n    name: \"getCheckContentLengthHeaderPlugin\",\n    override: true,\n};\nconst getCheckContentLengthHeaderPlugin = (unused) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(checkContentLengthHeader(), checkContentLengthHeaderMiddlewareOptions);\n    },\n});\n\nconst regionRedirectEndpointMiddleware = (config) => {\n    return (next, context) => async (args) => {\n        const originalRegion = await config.region();\n        const regionProviderRef = config.region;\n        let unlock = () => { };\n        if (context.__s3RegionRedirect) {\n            Object.defineProperty(config, \"region\", {\n                writable: false,\n                value: async () => {\n                    return context.__s3RegionRedirect;\n                },\n            });\n            unlock = () => Object.defineProperty(config, \"region\", {\n                writable: true,\n                value: regionProviderRef,\n            });\n        }\n        try {\n            const result = await next(args);\n            if (context.__s3RegionRedirect) {\n                unlock();\n                const region = await config.region();\n                if (originalRegion !== region) {\n                    throw new Error(\"Region was not restored following S3 region redirect.\");\n                }\n            }\n            return result;\n        }\n        catch (e) {\n            unlock();\n            throw e;\n        }\n    };\n};\nconst regionRedirectEndpointMiddlewareOptions = {\n    tags: [\"REGION_REDIRECT\", \"S3\"],\n    name: \"regionRedirectEndpointMiddleware\",\n    override: true,\n    relation: \"before\",\n    toMiddleware: \"endpointV2Middleware\",\n};\n\nfunction regionRedirectMiddleware(clientConfig) {\n    return (next, context) => async (args) => {\n        try {\n            return await next(args);\n        }\n        catch (err) {\n            if (clientConfig.followRegionRedirects) {\n                const statusCode = err?.$metadata?.httpStatusCode;\n                const isHeadBucket = context.commandName === \"HeadBucketCommand\";\n                const bucketRegionHeader = err?.$response?.headers?.[\"x-amz-bucket-region\"];\n                if (bucketRegionHeader) {\n                    if (statusCode === 301 ||\n                        (statusCode === 400 && (err?.name === \"IllegalLocationConstraintException\" || isHeadBucket))) {\n                        try {\n                            const actualRegion = bucketRegionHeader;\n                            context.logger?.debug(`Redirecting from ${await clientConfig.region()} to ${actualRegion}`);\n                            context.__s3RegionRedirect = actualRegion;\n                        }\n                        catch (e) {\n                            throw new Error(\"Region redirect failed: \" + e);\n                        }\n                        return next(args);\n                    }\n                }\n            }\n            throw err;\n        }\n    };\n}\nconst regionRedirectMiddlewareOptions = {\n    step: \"initialize\",\n    tags: [\"REGION_REDIRECT\", \"S3\"],\n    name: \"regionRedirectMiddleware\",\n    override: true,\n};\nconst getRegionRedirectMiddlewarePlugin = (clientConfig) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(regionRedirectMiddleware(clientConfig), regionRedirectMiddlewareOptions);\n        clientStack.addRelativeTo(regionRedirectEndpointMiddleware(clientConfig), regionRedirectEndpointMiddlewareOptions);\n    },\n});\n\nconst s3ExpiresMiddleware = (config) => {\n    return (next, context) => async (args) => {\n        const result = await next(args);\n        const { response } = result;\n        if (protocolHttp.HttpResponse.isInstance(response)) {\n            if (response.headers.expires) {\n                response.headers.expiresstring = response.headers.expires;\n                try {\n                    smithyClient.parseRfc7231DateTime(response.headers.expires);\n                }\n                catch (e) {\n                    context.logger?.warn(`AWS SDK Warning for ${context.clientName}::${context.commandName} response parsing (${response.headers.expires}): ${e}`);\n                    delete response.headers.expires;\n                }\n            }\n        }\n        return result;\n    };\n};\nconst s3ExpiresMiddlewareOptions = {\n    tags: [\"S3\"],\n    name: \"s3ExpiresMiddleware\",\n    override: true,\n    relation: \"after\",\n    toMiddleware: \"deserializerMiddleware\",\n};\nconst getS3ExpiresMiddlewarePlugin = (clientConfig) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(s3ExpiresMiddleware(), s3ExpiresMiddlewareOptions);\n    },\n});\n\nclass S3ExpressIdentityCache {\n    data;\n    lastPurgeTime = Date.now();\n    static EXPIRED_CREDENTIAL_PURGE_INTERVAL_MS = 30_000;\n    constructor(data = {}) {\n        this.data = data;\n    }\n    get(key) {\n        const entry = this.data[key];\n        if (!entry) {\n            return;\n        }\n        return entry;\n    }\n    set(key, entry) {\n        this.data[key] = entry;\n        return entry;\n    }\n    delete(key) {\n        delete this.data[key];\n    }\n    async purgeExpired() {\n        const now = Date.now();\n        if (this.lastPurgeTime + S3ExpressIdentityCache.EXPIRED_CREDENTIAL_PURGE_INTERVAL_MS > now) {\n            return;\n        }\n        for (const key in this.data) {\n            const entry = this.data[key];\n            if (!entry.isRefreshing) {\n                const credential = await entry.identity;\n                if (credential.expiration) {\n                    if (credential.expiration.getTime() < now) {\n                        delete this.data[key];\n                    }\n                }\n            }\n        }\n    }\n}\n\nclass S3ExpressIdentityCacheEntry {\n    _identity;\n    isRefreshing;\n    accessed;\n    constructor(_identity, isRefreshing = false, accessed = Date.now()) {\n        this._identity = _identity;\n        this.isRefreshing = isRefreshing;\n        this.accessed = accessed;\n    }\n    get identity() {\n        this.accessed = Date.now();\n        return this._identity;\n    }\n}\n\nclass S3ExpressIdentityProviderImpl {\n    createSessionFn;\n    cache;\n    static REFRESH_WINDOW_MS = 60_000;\n    constructor(createSessionFn, cache = new S3ExpressIdentityCache()) {\n        this.createSessionFn = createSessionFn;\n        this.cache = cache;\n    }\n    async getS3ExpressIdentity(awsIdentity, identityProperties) {\n        const key = identityProperties.Bucket;\n        const { cache } = this;\n        const entry = cache.get(key);\n        if (entry) {\n            return entry.identity.then((identity) => {\n                const isExpired = (identity.expiration?.getTime() ?? 0) < Date.now();\n                if (isExpired) {\n                    return cache.set(key, new S3ExpressIdentityCacheEntry(this.getIdentity(key))).identity;\n                }\n                const isExpiringSoon = (identity.expiration?.getTime() ?? 0) < Date.now() + S3ExpressIdentityProviderImpl.REFRESH_WINDOW_MS;\n                if (isExpiringSoon && !entry.isRefreshing) {\n                    entry.isRefreshing = true;\n                    this.getIdentity(key).then((id) => {\n                        cache.set(key, new S3ExpressIdentityCacheEntry(Promise.resolve(id)));\n                    });\n                }\n                return identity;\n            });\n        }\n        return cache.set(key, new S3ExpressIdentityCacheEntry(this.getIdentity(key))).identity;\n    }\n    async getIdentity(key) {\n        await this.cache.purgeExpired().catch((error) => {\n            console.warn(\"Error while clearing expired entries in S3ExpressIdentityCache: \\n\" + error);\n        });\n        const session = await this.createSessionFn(key);\n        if (!session.Credentials?.AccessKeyId || !session.Credentials?.SecretAccessKey) {\n            throw new Error(\"s3#createSession response credential missing AccessKeyId or SecretAccessKey.\");\n        }\n        const identity = {\n            accessKeyId: session.Credentials.AccessKeyId,\n            secretAccessKey: session.Credentials.SecretAccessKey,\n            sessionToken: session.Credentials.SessionToken,\n            expiration: session.Credentials.Expiration ? new Date(session.Credentials.Expiration) : undefined,\n        };\n        return identity;\n    }\n}\n\nconst S3_EXPRESS_BUCKET_TYPE = \"Directory\";\nconst S3_EXPRESS_BACKEND = \"S3Express\";\nconst S3_EXPRESS_AUTH_SCHEME = \"sigv4-s3express\";\nconst SESSION_TOKEN_QUERY_PARAM = \"X-Amz-S3session-Token\";\nconst SESSION_TOKEN_HEADER = SESSION_TOKEN_QUERY_PARAM.toLowerCase();\nconst NODE_DISABLE_S3_EXPRESS_SESSION_AUTH_ENV_NAME = \"AWS_S3_DISABLE_EXPRESS_SESSION_AUTH\";\nconst NODE_DISABLE_S3_EXPRESS_SESSION_AUTH_INI_NAME = \"s3_disable_express_session_auth\";\nconst NODE_DISABLE_S3_EXPRESS_SESSION_AUTH_OPTIONS = {\n    environmentVariableSelector: (env) => utilConfigProvider.booleanSelector(env, NODE_DISABLE_S3_EXPRESS_SESSION_AUTH_ENV_NAME, utilConfigProvider.SelectorType.ENV),\n    configFileSelector: (profile) => utilConfigProvider.booleanSelector(profile, NODE_DISABLE_S3_EXPRESS_SESSION_AUTH_INI_NAME, utilConfigProvider.SelectorType.CONFIG),\n    default: false,\n};\n\nclass SignatureV4S3Express extends signatureV4.SignatureV4 {\n    async signWithCredentials(requestToSign, credentials, options) {\n        const credentialsWithoutSessionToken = getCredentialsWithoutSessionToken(credentials);\n        requestToSign.headers[SESSION_TOKEN_HEADER] = credentials.sessionToken;\n        const privateAccess = this;\n        setSingleOverride(privateAccess, credentialsWithoutSessionToken);\n        return privateAccess.signRequest(requestToSign, options ?? {});\n    }\n    async presignWithCredentials(requestToSign, credentials, options) {\n        const credentialsWithoutSessionToken = getCredentialsWithoutSessionToken(credentials);\n        delete requestToSign.headers[SESSION_TOKEN_HEADER];\n        requestToSign.headers[SESSION_TOKEN_QUERY_PARAM] = credentials.sessionToken;\n        requestToSign.query = requestToSign.query ?? {};\n        requestToSign.query[SESSION_TOKEN_QUERY_PARAM] = credentials.sessionToken;\n        const privateAccess = this;\n        setSingleOverride(privateAccess, credentialsWithoutSessionToken);\n        return this.presign(requestToSign, options);\n    }\n}\nfunction getCredentialsWithoutSessionToken(credentials) {\n    const credentialsWithoutSessionToken = {\n        accessKeyId: credentials.accessKeyId,\n        secretAccessKey: credentials.secretAccessKey,\n        expiration: credentials.expiration,\n    };\n    return credentialsWithoutSessionToken;\n}\nfunction setSingleOverride(privateAccess, credentialsWithoutSessionToken) {\n    const id = setTimeout(() => {\n        throw new Error(\"SignatureV4S3Express credential override was created but not called.\");\n    }, 10);\n    const currentCredentialProvider = privateAccess.credentialProvider;\n    const overrideCredentialsProviderOnce = () => {\n        clearTimeout(id);\n        privateAccess.credentialProvider = currentCredentialProvider;\n        return Promise.resolve(credentialsWithoutSessionToken);\n    };\n    privateAccess.credentialProvider = overrideCredentialsProviderOnce;\n}\n\nconst s3ExpressMiddleware = (options) => {\n    return (next, context) => async (args) => {\n        if (context.endpointV2) {\n            const endpoint = context.endpointV2;\n            const isS3ExpressAuth = endpoint.properties?.authSchemes?.[0]?.name === S3_EXPRESS_AUTH_SCHEME;\n            const isS3ExpressBucket = endpoint.properties?.backend === S3_EXPRESS_BACKEND ||\n                endpoint.properties?.bucketType === S3_EXPRESS_BUCKET_TYPE;\n            if (isS3ExpressBucket) {\n                core.setFeature(context, \"S3_EXPRESS_BUCKET\", \"J\");\n                context.isS3ExpressBucket = true;\n            }\n            if (isS3ExpressAuth) {\n                const requestBucket = args.input.Bucket;\n                if (requestBucket) {\n                    const s3ExpressIdentity = await options.s3ExpressIdentityProvider.getS3ExpressIdentity(await options.credentials(), {\n                        Bucket: requestBucket,\n                    });\n                    context.s3ExpressIdentity = s3ExpressIdentity;\n                    if (protocolHttp.HttpRequest.isInstance(args.request) && s3ExpressIdentity.sessionToken) {\n                        args.request.headers[SESSION_TOKEN_HEADER] = s3ExpressIdentity.sessionToken;\n                    }\n                }\n            }\n        }\n        return next(args);\n    };\n};\nconst s3ExpressMiddlewareOptions = {\n    name: \"s3ExpressMiddleware\",\n    step: \"build\",\n    tags: [\"S3\", \"S3_EXPRESS\"],\n    override: true,\n};\nconst getS3ExpressPlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(s3ExpressMiddleware(options), s3ExpressMiddlewareOptions);\n    },\n});\n\nconst signS3Express = async (s3ExpressIdentity, signingOptions, request, sigV4MultiRegionSigner) => {\n    const signedRequest = await sigV4MultiRegionSigner.signWithCredentials(request, s3ExpressIdentity, {});\n    if (signedRequest.headers[\"X-Amz-Security-Token\"] || signedRequest.headers[\"x-amz-security-token\"]) {\n        throw new Error(\"X-Amz-Security-Token must not be set for s3-express requests.\");\n    }\n    return signedRequest;\n};\n\nconst defaultErrorHandler = (signingProperties) => (error) => {\n    throw error;\n};\nconst defaultSuccessHandler = (httpResponse, signingProperties) => { };\nconst s3ExpressHttpSigningMiddlewareOptions = core$1.httpSigningMiddlewareOptions;\nconst s3ExpressHttpSigningMiddleware = (config) => (next, context) => async (args) => {\n    if (!protocolHttp.HttpRequest.isInstance(args.request)) {\n        return next(args);\n    }\n    const smithyContext = utilMiddleware.getSmithyContext(context);\n    const scheme = smithyContext.selectedHttpAuthScheme;\n    if (!scheme) {\n        throw new Error(`No HttpAuthScheme was selected: unable to sign request`);\n    }\n    const { httpAuthOption: { signingProperties = {} }, identity, signer, } = scheme;\n    let request;\n    if (context.s3ExpressIdentity) {\n        request = await signS3Express(context.s3ExpressIdentity, signingProperties, args.request, await config.signer());\n    }\n    else {\n        request = await signer.sign(args.request, identity, signingProperties);\n    }\n    const output = await next({\n        ...args,\n        request,\n    }).catch((signer.errorHandler || defaultErrorHandler)(signingProperties));\n    (signer.successHandler || defaultSuccessHandler)(output.response, signingProperties);\n    return output;\n};\nconst getS3ExpressHttpSigningPlugin = (config) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(s3ExpressHttpSigningMiddleware(config), core$1.httpSigningMiddlewareOptions);\n    },\n});\n\nconst resolveS3Config = (input, { session, }) => {\n    const [s3ClientProvider, CreateSessionCommandCtor] = session;\n    const { forcePathStyle, useAccelerateEndpoint, disableMultiregionAccessPoints, followRegionRedirects, s3ExpressIdentityProvider, bucketEndpoint, expectContinueHeader, } = input;\n    return Object.assign(input, {\n        forcePathStyle: forcePathStyle ?? false,\n        useAccelerateEndpoint: useAccelerateEndpoint ?? false,\n        disableMultiregionAccessPoints: disableMultiregionAccessPoints ?? false,\n        followRegionRedirects: followRegionRedirects ?? false,\n        s3ExpressIdentityProvider: s3ExpressIdentityProvider ??\n            new S3ExpressIdentityProviderImpl(async (key) => s3ClientProvider().send(new CreateSessionCommandCtor({\n                Bucket: key,\n            }))),\n        bucketEndpoint: bucketEndpoint ?? false,\n        expectContinueHeader: expectContinueHeader ?? 2_097_152,\n    });\n};\n\nconst THROW_IF_EMPTY_BODY = {\n    CopyObjectCommand: true,\n    UploadPartCopyCommand: true,\n    CompleteMultipartUploadCommand: true,\n};\nconst MAX_BYTES_TO_INSPECT = 3000;\nconst throw200ExceptionsMiddleware = (config) => (next, context) => async (args) => {\n    const result = await next(args);\n    const { response } = result;\n    if (!protocolHttp.HttpResponse.isInstance(response)) {\n        return result;\n    }\n    const { statusCode, body: sourceBody } = response;\n    if (statusCode < 200 || statusCode >= 300) {\n        return result;\n    }\n    const isSplittableStream = typeof sourceBody?.stream === \"function\" ||\n        typeof sourceBody?.pipe === \"function\" ||\n        typeof sourceBody?.tee === \"function\";\n    if (!isSplittableStream) {\n        return result;\n    }\n    let bodyCopy = sourceBody;\n    let body = sourceBody;\n    if (sourceBody && typeof sourceBody === \"object\" && !(sourceBody instanceof Uint8Array)) {\n        [bodyCopy, body] = await utilStream.splitStream(sourceBody);\n    }\n    response.body = body;\n    const bodyBytes = await collectBody(bodyCopy, {\n        streamCollector: async (stream) => {\n            return utilStream.headStream(stream, MAX_BYTES_TO_INSPECT);\n        },\n    });\n    if (typeof bodyCopy?.destroy === \"function\") {\n        bodyCopy.destroy();\n    }\n    const bodyStringTail = config.utf8Encoder(bodyBytes.subarray(bodyBytes.length - 16));\n    if (bodyBytes.length === 0 && THROW_IF_EMPTY_BODY[context.commandName]) {\n        const err = new Error(\"S3 aborted request\");\n        err.name = \"InternalError\";\n        throw err;\n    }\n    if (bodyStringTail && bodyStringTail.endsWith(\"</Error>\")) {\n        response.statusCode = 400;\n    }\n    return result;\n};\nconst collectBody = (streamBody = new Uint8Array(), context) => {\n    if (streamBody instanceof Uint8Array) {\n        return Promise.resolve(streamBody);\n    }\n    return context.streamCollector(streamBody) || Promise.resolve(new Uint8Array());\n};\nconst throw200ExceptionsMiddlewareOptions = {\n    relation: \"after\",\n    toMiddleware: \"deserializerMiddleware\",\n    tags: [\"THROW_200_EXCEPTIONS\", \"S3\"],\n    name: \"throw200ExceptionsMiddleware\",\n    override: true,\n};\nconst getThrow200ExceptionsPlugin = (config) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(throw200ExceptionsMiddleware(config), throw200ExceptionsMiddlewareOptions);\n    },\n});\n\nfunction bucketEndpointMiddleware(options) {\n    return (next, context) => async (args) => {\n        if (options.bucketEndpoint) {\n            const endpoint = context.endpointV2;\n            if (endpoint) {\n                const bucket = args.input.Bucket;\n                if (typeof bucket === \"string\") {\n                    try {\n                        const bucketEndpointUrl = new URL(bucket);\n                        context.endpointV2 = {\n                            ...endpoint,\n                            url: bucketEndpointUrl,\n                        };\n                    }\n                    catch (e) {\n                        const warning = `@aws-sdk/middleware-sdk-s3: bucketEndpoint=true was set but Bucket=${bucket} could not be parsed as URL.`;\n                        if (context.logger?.constructor?.name === \"NoOpLogger\") {\n                            console.warn(warning);\n                        }\n                        else {\n                            context.logger?.warn?.(warning);\n                        }\n                        throw e;\n                    }\n                }\n            }\n        }\n        return next(args);\n    };\n}\nconst bucketEndpointMiddlewareOptions = {\n    name: \"bucketEndpointMiddleware\",\n    override: true,\n    relation: \"after\",\n    toMiddleware: \"endpointV2Middleware\",\n};\n\nfunction validateBucketNameMiddleware({ bucketEndpoint }) {\n    return (next) => async (args) => {\n        const { input: { Bucket }, } = args;\n        if (!bucketEndpoint && typeof Bucket === \"string\" && !utilArnParser.validate(Bucket) && Bucket.indexOf(\"/\") >= 0) {\n            const err = new Error(`Bucket name shouldn't contain '/', received '${Bucket}'`);\n            err.name = \"InvalidBucketName\";\n            throw err;\n        }\n        return next({ ...args });\n    };\n}\nconst validateBucketNameMiddlewareOptions = {\n    step: \"initialize\",\n    tags: [\"VALIDATE_BUCKET_NAME\"],\n    name: \"validateBucketNameMiddleware\",\n    override: true,\n};\nconst getValidateBucketNamePlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(validateBucketNameMiddleware(options), validateBucketNameMiddlewareOptions);\n        clientStack.addRelativeTo(bucketEndpointMiddleware(options), bucketEndpointMiddlewareOptions);\n    },\n});\n\nexports.NODE_DISABLE_S3_EXPRESS_SESSION_AUTH_OPTIONS = NODE_DISABLE_S3_EXPRESS_SESSION_AUTH_OPTIONS;\nexports.S3ExpressIdentityCache = S3ExpressIdentityCache;\nexports.S3ExpressIdentityCacheEntry = S3ExpressIdentityCacheEntry;\nexports.S3ExpressIdentityProviderImpl = S3ExpressIdentityProviderImpl;\nexports.SignatureV4S3Express = SignatureV4S3Express;\nexports.checkContentLengthHeader = checkContentLengthHeader;\nexports.checkContentLengthHeaderMiddlewareOptions = checkContentLengthHeaderMiddlewareOptions;\nexports.getCheckContentLengthHeaderPlugin = getCheckContentLengthHeaderPlugin;\nexports.getRegionRedirectMiddlewarePlugin = getRegionRedirectMiddlewarePlugin;\nexports.getS3ExpiresMiddlewarePlugin = getS3ExpiresMiddlewarePlugin;\nexports.getS3ExpressHttpSigningPlugin = getS3ExpressHttpSigningPlugin;\nexports.getS3ExpressPlugin = getS3ExpressPlugin;\nexports.getThrow200ExceptionsPlugin = getThrow200ExceptionsPlugin;\nexports.getValidateBucketNamePlugin = getValidateBucketNamePlugin;\nexports.regionRedirectEndpointMiddleware = regionRedirectEndpointMiddleware;\nexports.regionRedirectEndpointMiddlewareOptions = regionRedirectEndpointMiddlewareOptions;\nexports.regionRedirectMiddleware = regionRedirectMiddleware;\nexports.regionRedirectMiddlewareOptions = regionRedirectMiddlewareOptions;\nexports.resolveS3Config = resolveS3Config;\nexports.s3ExpiresMiddleware = s3ExpiresMiddleware;\nexports.s3ExpiresMiddlewareOptions = s3ExpiresMiddlewareOptions;\nexports.s3ExpressHttpSigningMiddleware = s3ExpressHttpSigningMiddleware;\nexports.s3ExpressHttpSigningMiddlewareOptions = s3ExpressHttpSigningMiddlewareOptions;\nexports.s3ExpressMiddleware = s3ExpressMiddleware;\nexports.s3ExpressMiddlewareOptions = s3ExpressMiddlewareOptions;\nexports.throw200ExceptionsMiddleware = throw200ExceptionsMiddleware;\nexports.throw200ExceptionsMiddlewareOptions = throw200ExceptionsMiddlewareOptions;\nexports.validateBucketNameMiddleware = validateBucketNameMiddleware;\nexports.validateBucketNameMiddlewareOptions = validateBucketNameMiddlewareOptions;\n","'use strict';\n\nfunction ssecMiddleware(options) {\n    return (next) => async (args) => {\n        const input = { ...args.input };\n        const properties = [\n            {\n                target: \"SSECustomerKey\",\n                hash: \"SSECustomerKeyMD5\",\n            },\n            {\n                target: \"CopySourceSSECustomerKey\",\n                hash: \"CopySourceSSECustomerKeyMD5\",\n            },\n        ];\n        for (const prop of properties) {\n            const value = input[prop.target];\n            if (value) {\n                let valueForHash;\n                if (typeof value === \"string\") {\n                    if (isValidBase64EncodedSSECustomerKey(value, options)) {\n                        valueForHash = options.base64Decoder(value);\n                    }\n                    else {\n                        valueForHash = options.utf8Decoder(value);\n                        input[prop.target] = options.base64Encoder(valueForHash);\n                    }\n                }\n                else {\n                    valueForHash = ArrayBuffer.isView(value)\n                        ? new Uint8Array(value.buffer, value.byteOffset, value.byteLength)\n                        : new Uint8Array(value);\n                    input[prop.target] = options.base64Encoder(valueForHash);\n                }\n                const hash = new options.md5();\n                hash.update(valueForHash);\n                input[prop.hash] = options.base64Encoder(await hash.digest());\n            }\n        }\n        return next({\n            ...args,\n            input,\n        });\n    };\n}\nconst ssecMiddlewareOptions = {\n    name: \"ssecMiddleware\",\n    step: \"initialize\",\n    tags: [\"SSE\"],\n    override: true,\n};\nconst getSsecPlugin = (config) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(ssecMiddleware(config), ssecMiddlewareOptions);\n    },\n});\nfunction isValidBase64EncodedSSECustomerKey(str, options) {\n    const base64Regex = /^(?:[A-Za-z0-9+/]{4})*([A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/;\n    if (!base64Regex.test(str))\n        return false;\n    try {\n        const decodedBytes = options.base64Decoder(str);\n        return decodedBytes.length === 32;\n    }\n    catch {\n        return false;\n    }\n}\n\nexports.getSsecPlugin = getSsecPlugin;\nexports.isValidBase64EncodedSSECustomerKey = isValidBase64EncodedSSECustomerKey;\nexports.ssecMiddleware = ssecMiddleware;\nexports.ssecMiddlewareOptions = ssecMiddlewareOptions;\n","'use strict';\n\nvar core = require('@smithy/core');\nvar utilEndpoints = require('@aws-sdk/util-endpoints');\nvar protocolHttp = require('@smithy/protocol-http');\nvar core$1 = require('@aws-sdk/core');\n\nconst DEFAULT_UA_APP_ID = undefined;\nfunction isValidUserAgentAppId(appId) {\n    if (appId === undefined) {\n        return true;\n    }\n    return typeof appId === \"string\" && appId.length <= 50;\n}\nfunction resolveUserAgentConfig(input) {\n    const normalizedAppIdProvider = core.normalizeProvider(input.userAgentAppId ?? DEFAULT_UA_APP_ID);\n    const { customUserAgent } = input;\n    return Object.assign(input, {\n        customUserAgent: typeof customUserAgent === \"string\" ? [[customUserAgent]] : customUserAgent,\n        userAgentAppId: async () => {\n            const appId = await normalizedAppIdProvider();\n            if (!isValidUserAgentAppId(appId)) {\n                const logger = input.logger?.constructor?.name === \"NoOpLogger\" || !input.logger ? console : input.logger;\n                if (typeof appId !== \"string\") {\n                    logger?.warn(\"userAgentAppId must be a string or undefined.\");\n                }\n                else if (appId.length > 50) {\n                    logger?.warn(\"The provided userAgentAppId exceeds the maximum length of 50 characters.\");\n                }\n            }\n            return appId;\n        },\n    });\n}\n\nconst ACCOUNT_ID_ENDPOINT_REGEX = /\\d{12}\\.ddb/;\nasync function checkFeatures(context, config, args) {\n    const request = args.request;\n    if (request?.headers?.[\"smithy-protocol\"] === \"rpc-v2-cbor\") {\n        core$1.setFeature(context, \"PROTOCOL_RPC_V2_CBOR\", \"M\");\n    }\n    if (typeof config.retryStrategy === \"function\") {\n        const retryStrategy = await config.retryStrategy();\n        if (typeof retryStrategy.acquireInitialRetryToken === \"function\") {\n            if (retryStrategy.constructor?.name?.includes(\"Adaptive\")) {\n                core$1.setFeature(context, \"RETRY_MODE_ADAPTIVE\", \"F\");\n            }\n            else {\n                core$1.setFeature(context, \"RETRY_MODE_STANDARD\", \"E\");\n            }\n        }\n        else {\n            core$1.setFeature(context, \"RETRY_MODE_LEGACY\", \"D\");\n        }\n    }\n    if (typeof config.accountIdEndpointMode === \"function\") {\n        const endpointV2 = context.endpointV2;\n        if (String(endpointV2?.url?.hostname).match(ACCOUNT_ID_ENDPOINT_REGEX)) {\n            core$1.setFeature(context, \"ACCOUNT_ID_ENDPOINT\", \"O\");\n        }\n        switch (await config.accountIdEndpointMode?.()) {\n            case \"disabled\":\n                core$1.setFeature(context, \"ACCOUNT_ID_MODE_DISABLED\", \"Q\");\n                break;\n            case \"preferred\":\n                core$1.setFeature(context, \"ACCOUNT_ID_MODE_PREFERRED\", \"P\");\n                break;\n            case \"required\":\n                core$1.setFeature(context, \"ACCOUNT_ID_MODE_REQUIRED\", \"R\");\n                break;\n        }\n    }\n    const identity = context.__smithy_context?.selectedHttpAuthScheme?.identity;\n    if (identity?.$source) {\n        const credentials = identity;\n        if (credentials.accountId) {\n            core$1.setFeature(context, \"RESOLVED_ACCOUNT_ID\", \"T\");\n        }\n        for (const [key, value] of Object.entries(credentials.$source ?? {})) {\n            core$1.setFeature(context, key, value);\n        }\n    }\n}\n\nconst USER_AGENT = \"user-agent\";\nconst X_AMZ_USER_AGENT = \"x-amz-user-agent\";\nconst SPACE = \" \";\nconst UA_NAME_SEPARATOR = \"/\";\nconst UA_NAME_ESCAPE_REGEX = /[^!$%&'*+\\-.^_`|~\\w]/g;\nconst UA_VALUE_ESCAPE_REGEX = /[^!$%&'*+\\-.^_`|~\\w#]/g;\nconst UA_ESCAPE_CHAR = \"-\";\n\nconst BYTE_LIMIT = 1024;\nfunction encodeFeatures(features) {\n    let buffer = \"\";\n    for (const key in features) {\n        const val = features[key];\n        if (buffer.length + val.length + 1 <= BYTE_LIMIT) {\n            if (buffer.length) {\n                buffer += \",\" + val;\n            }\n            else {\n                buffer += val;\n            }\n            continue;\n        }\n        break;\n    }\n    return buffer;\n}\n\nconst userAgentMiddleware = (options) => (next, context) => async (args) => {\n    const { request } = args;\n    if (!protocolHttp.HttpRequest.isInstance(request)) {\n        return next(args);\n    }\n    const { headers } = request;\n    const userAgent = context?.userAgent?.map(escapeUserAgent) || [];\n    const defaultUserAgent = (await options.defaultUserAgentProvider()).map(escapeUserAgent);\n    await checkFeatures(context, options, args);\n    const awsContext = context;\n    defaultUserAgent.push(`m/${encodeFeatures(Object.assign({}, context.__smithy_context?.features, awsContext.__aws_sdk_context?.features))}`);\n    const customUserAgent = options?.customUserAgent?.map(escapeUserAgent) || [];\n    const appId = await options.userAgentAppId();\n    if (appId) {\n        defaultUserAgent.push(escapeUserAgent([`app`, `${appId}`]));\n    }\n    const prefix = utilEndpoints.getUserAgentPrefix();\n    const sdkUserAgentValue = (prefix ? [prefix] : [])\n        .concat([...defaultUserAgent, ...userAgent, ...customUserAgent])\n        .join(SPACE);\n    const normalUAValue = [\n        ...defaultUserAgent.filter((section) => section.startsWith(\"aws-sdk-\")),\n        ...customUserAgent,\n    ].join(SPACE);\n    if (options.runtime !== \"browser\") {\n        if (normalUAValue) {\n            headers[X_AMZ_USER_AGENT] = headers[X_AMZ_USER_AGENT]\n                ? `${headers[USER_AGENT]} ${normalUAValue}`\n                : normalUAValue;\n        }\n        headers[USER_AGENT] = sdkUserAgentValue;\n    }\n    else {\n        headers[X_AMZ_USER_AGENT] = sdkUserAgentValue;\n    }\n    return next({\n        ...args,\n        request,\n    });\n};\nconst escapeUserAgent = (userAgentPair) => {\n    const name = userAgentPair[0]\n        .split(UA_NAME_SEPARATOR)\n        .map((part) => part.replace(UA_NAME_ESCAPE_REGEX, UA_ESCAPE_CHAR))\n        .join(UA_NAME_SEPARATOR);\n    const version = userAgentPair[1]?.replace(UA_VALUE_ESCAPE_REGEX, UA_ESCAPE_CHAR);\n    const prefixSeparatorIndex = name.indexOf(UA_NAME_SEPARATOR);\n    const prefix = name.substring(0, prefixSeparatorIndex);\n    let uaName = name.substring(prefixSeparatorIndex + 1);\n    if (prefix === \"api\") {\n        uaName = uaName.toLowerCase();\n    }\n    return [prefix, uaName, version]\n        .filter((item) => item && item.length > 0)\n        .reduce((acc, item, index) => {\n        switch (index) {\n            case 0:\n                return item;\n            case 1:\n                return `${acc}/${item}`;\n            default:\n                return `${acc}#${item}`;\n        }\n    }, \"\");\n};\nconst getUserAgentMiddlewareOptions = {\n    name: \"getUserAgentMiddleware\",\n    step: \"build\",\n    priority: \"low\",\n    tags: [\"SET_USER_AGENT\", \"USER_AGENT\"],\n    override: true,\n};\nconst getUserAgentPlugin = (config) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(userAgentMiddleware(config), getUserAgentMiddlewareOptions);\n    },\n});\n\nexports.DEFAULT_UA_APP_ID = DEFAULT_UA_APP_ID;\nexports.getUserAgentMiddlewareOptions = getUserAgentMiddlewareOptions;\nexports.getUserAgentPlugin = getUserAgentPlugin;\nexports.resolveUserAgentConfig = resolveUserAgentConfig;\nexports.userAgentMiddleware = userAgentMiddleware;\n","'use strict';\n\nvar stsRegionDefaultResolver = require('./regionConfig/stsRegionDefaultResolver');\nvar configResolver = require('@smithy/config-resolver');\n\nconst getAwsRegionExtensionConfiguration = (runtimeConfig) => {\n    return {\n        setRegion(region) {\n            runtimeConfig.region = region;\n        },\n        region() {\n            return runtimeConfig.region;\n        },\n    };\n};\nconst resolveAwsRegionExtensionConfiguration = (awsRegionExtensionConfiguration) => {\n    return {\n        region: awsRegionExtensionConfiguration.region(),\n    };\n};\n\nObject.defineProperty(exports, \"NODE_REGION_CONFIG_FILE_OPTIONS\", {\n    enumerable: true,\n    get: function () { return configResolver.NODE_REGION_CONFIG_FILE_OPTIONS; }\n});\nObject.defineProperty(exports, \"NODE_REGION_CONFIG_OPTIONS\", {\n    enumerable: true,\n    get: function () { return configResolver.NODE_REGION_CONFIG_OPTIONS; }\n});\nObject.defineProperty(exports, \"REGION_ENV_NAME\", {\n    enumerable: true,\n    get: function () { return configResolver.REGION_ENV_NAME; }\n});\nObject.defineProperty(exports, \"REGION_INI_NAME\", {\n    enumerable: true,\n    get: function () { return configResolver.REGION_INI_NAME; }\n});\nObject.defineProperty(exports, \"resolveRegionConfig\", {\n    enumerable: true,\n    get: function () { return configResolver.resolveRegionConfig; }\n});\nexports.getAwsRegionExtensionConfiguration = getAwsRegionExtensionConfiguration;\nexports.resolveAwsRegionExtensionConfiguration = resolveAwsRegionExtensionConfiguration;\nObject.keys(stsRegionDefaultResolver).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return stsRegionDefaultResolver[k]; }\n    });\n});\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.warning = void 0;\nexports.stsRegionDefaultResolver = stsRegionDefaultResolver;\nconst config_resolver_1 = require(\"@smithy/config-resolver\");\nconst node_config_provider_1 = require(\"@smithy/node-config-provider\");\nfunction stsRegionDefaultResolver(loaderConfig = {}) {\n    return (0, node_config_provider_1.loadConfig)({\n        ...config_resolver_1.NODE_REGION_CONFIG_OPTIONS,\n        async default() {\n            if (!exports.warning.silence) {\n                console.warn(\"@aws-sdk - WARN - default STS region of us-east-1 used. See @aws-sdk/credential-providers README and set a region explicitly.\");\n            }\n            return \"us-east-1\";\n        },\n    }, { ...config_resolver_1.NODE_REGION_CONFIG_FILE_OPTIONS, ...loaderConfig });\n}\nexports.warning = {\n    silence: false,\n};\n","'use strict';\n\nvar middlewareSdkS3 = require('@aws-sdk/middleware-sdk-s3');\nvar signatureV4 = require('@smithy/signature-v4');\n\nconst signatureV4CrtContainer = {\n    CrtSignerV4: null,\n};\n\nclass SignatureV4MultiRegion {\n    sigv4aSigner;\n    sigv4Signer;\n    signerOptions;\n    static sigv4aDependency() {\n        if (typeof signatureV4CrtContainer.CrtSignerV4 === \"function\") {\n            return \"crt\";\n        }\n        else if (typeof signatureV4.signatureV4aContainer.SignatureV4a === \"function\") {\n            return \"js\";\n        }\n        return \"none\";\n    }\n    constructor(options) {\n        this.sigv4Signer = new middlewareSdkS3.SignatureV4S3Express(options);\n        this.signerOptions = options;\n    }\n    async sign(requestToSign, options = {}) {\n        if (options.signingRegion === \"*\") {\n            return this.getSigv4aSigner().sign(requestToSign, options);\n        }\n        return this.sigv4Signer.sign(requestToSign, options);\n    }\n    async signWithCredentials(requestToSign, credentials, options = {}) {\n        if (options.signingRegion === \"*\") {\n            const signer = this.getSigv4aSigner();\n            const CrtSignerV4 = signatureV4CrtContainer.CrtSignerV4;\n            if (CrtSignerV4 && signer instanceof CrtSignerV4) {\n                return signer.signWithCredentials(requestToSign, credentials, options);\n            }\n            else {\n                throw new Error(`signWithCredentials with signingRegion '*' is only supported when using the CRT dependency @aws-sdk/signature-v4-crt. ` +\n                    `Please check whether you have installed the \"@aws-sdk/signature-v4-crt\" package explicitly. ` +\n                    `You must also register the package by calling [require(\"@aws-sdk/signature-v4-crt\");] ` +\n                    `or an ESM equivalent such as [import \"@aws-sdk/signature-v4-crt\";]. ` +\n                    `For more information please go to https://github.com/aws/aws-sdk-js-v3#functionality-requiring-aws-common-runtime-crt`);\n            }\n        }\n        return this.sigv4Signer.signWithCredentials(requestToSign, credentials, options);\n    }\n    async presign(originalRequest, options = {}) {\n        if (options.signingRegion === \"*\") {\n            const signer = this.getSigv4aSigner();\n            const CrtSignerV4 = signatureV4CrtContainer.CrtSignerV4;\n            if (CrtSignerV4 && signer instanceof CrtSignerV4) {\n                return signer.presign(originalRequest, options);\n            }\n            else {\n                throw new Error(`presign with signingRegion '*' is only supported when using the CRT dependency @aws-sdk/signature-v4-crt. ` +\n                    `Please check whether you have installed the \"@aws-sdk/signature-v4-crt\" package explicitly. ` +\n                    `You must also register the package by calling [require(\"@aws-sdk/signature-v4-crt\");] ` +\n                    `or an ESM equivalent such as [import \"@aws-sdk/signature-v4-crt\";]. ` +\n                    `For more information please go to https://github.com/aws/aws-sdk-js-v3#functionality-requiring-aws-common-runtime-crt`);\n            }\n        }\n        return this.sigv4Signer.presign(originalRequest, options);\n    }\n    async presignWithCredentials(originalRequest, credentials, options = {}) {\n        if (options.signingRegion === \"*\") {\n            throw new Error(\"Method presignWithCredentials is not supported for [signingRegion=*].\");\n        }\n        return this.sigv4Signer.presignWithCredentials(originalRequest, credentials, options);\n    }\n    getSigv4aSigner() {\n        if (!this.sigv4aSigner) {\n            const CrtSignerV4 = signatureV4CrtContainer.CrtSignerV4;\n            const JsSigV4aSigner = signatureV4.signatureV4aContainer.SignatureV4a;\n            if (this.signerOptions.runtime === \"node\") {\n                if (!CrtSignerV4 && !JsSigV4aSigner) {\n                    throw new Error(\"Neither CRT nor JS SigV4a implementation is available. \" +\n                        \"Please load either @aws-sdk/signature-v4-crt or @aws-sdk/signature-v4a. \" +\n                        \"For more information please go to \" +\n                        \"https://github.com/aws/aws-sdk-js-v3#functionality-requiring-aws-common-runtime-crt\");\n                }\n                if (CrtSignerV4 && typeof CrtSignerV4 === \"function\") {\n                    this.sigv4aSigner = new CrtSignerV4({\n                        ...this.signerOptions,\n                        signingAlgorithm: 1,\n                    });\n                }\n                else if (JsSigV4aSigner && typeof JsSigV4aSigner === \"function\") {\n                    this.sigv4aSigner = new JsSigV4aSigner({\n                        ...this.signerOptions,\n                    });\n                }\n                else {\n                    throw new Error(\"Available SigV4a implementation is not a valid constructor. \" +\n                        \"Please ensure you've properly imported @aws-sdk/signature-v4-crt or @aws-sdk/signature-v4a.\" +\n                        \"For more information please go to \" +\n                        \"https://github.com/aws/aws-sdk-js-v3#functionality-requiring-aws-common-runtime-crt\");\n                }\n            }\n            else {\n                if (!JsSigV4aSigner || typeof JsSigV4aSigner !== \"function\") {\n                    throw new Error(\"JS SigV4a implementation is not available or not a valid constructor. \" +\n                        \"Please check whether you have installed the @aws-sdk/signature-v4a package explicitly. The CRT implementation is not available for browsers. \" +\n                        \"You must also register the package by calling [require('@aws-sdk/signature-v4a');] \" +\n                        \"or an ESM equivalent such as [import '@aws-sdk/signature-v4a';]. \" +\n                        \"For more information please go to \" +\n                        \"https://github.com/aws/aws-sdk-js-v3#using-javascript-non-crt-implementation-of-sigv4a\");\n                }\n                this.sigv4aSigner = new JsSigV4aSigner({\n                    ...this.signerOptions,\n                });\n            }\n        }\n        return this.sigv4aSigner;\n    }\n}\n\nexports.SignatureV4MultiRegion = SignatureV4MultiRegion;\nexports.signatureV4CrtContainer = signatureV4CrtContainer;\n","'use strict';\n\nconst validate = (str) => typeof str === \"string\" && str.indexOf(\"arn:\") === 0 && str.split(\":\").length >= 6;\nconst parse = (arn) => {\n    const segments = arn.split(\":\");\n    if (segments.length < 6 || segments[0] !== \"arn\")\n        throw new Error(\"Malformed ARN\");\n    const [, partition, service, region, accountId, ...resource] = segments;\n    return {\n        partition,\n        service,\n        region,\n        accountId,\n        resource: resource.join(\":\"),\n    };\n};\nconst build = (arnObject) => {\n    const { partition = \"aws\", service, region, accountId, resource } = arnObject;\n    if ([service, region, accountId, resource].some((segment) => typeof segment !== \"string\")) {\n        throw new Error(\"Input ARN object is invalid\");\n    }\n    return `arn:${partition}:${service}:${region}:${accountId}:${resource}`;\n};\n\nexports.build = build;\nexports.parse = parse;\nexports.validate = validate;\n","'use strict';\n\nvar utilEndpoints = require('@smithy/util-endpoints');\nvar urlParser = require('@smithy/url-parser');\n\nconst isVirtualHostableS3Bucket = (value, allowSubDomains = false) => {\n    if (allowSubDomains) {\n        for (const label of value.split(\".\")) {\n            if (!isVirtualHostableS3Bucket(label)) {\n                return false;\n            }\n        }\n        return true;\n    }\n    if (!utilEndpoints.isValidHostLabel(value)) {\n        return false;\n    }\n    if (value.length < 3 || value.length > 63) {\n        return false;\n    }\n    if (value !== value.toLowerCase()) {\n        return false;\n    }\n    if (utilEndpoints.isIpAddress(value)) {\n        return false;\n    }\n    return true;\n};\n\nconst ARN_DELIMITER = \":\";\nconst RESOURCE_DELIMITER = \"/\";\nconst parseArn = (value) => {\n    const segments = value.split(ARN_DELIMITER);\n    if (segments.length < 6)\n        return null;\n    const [arn, partition, service, region, accountId, ...resourcePath] = segments;\n    if (arn !== \"arn\" || partition === \"\" || service === \"\" || resourcePath.join(ARN_DELIMITER) === \"\")\n        return null;\n    const resourceId = resourcePath.map((resource) => resource.split(RESOURCE_DELIMITER)).flat();\n    return {\n        partition,\n        service,\n        region,\n        accountId,\n        resourceId,\n    };\n};\n\nvar partitions = [\n\t{\n\t\tid: \"aws\",\n\t\toutputs: {\n\t\t\tdnsSuffix: \"amazonaws.com\",\n\t\t\tdualStackDnsSuffix: \"api.aws\",\n\t\t\timplicitGlobalRegion: \"us-east-1\",\n\t\t\tname: \"aws\",\n\t\t\tsupportsDualStack: true,\n\t\t\tsupportsFIPS: true\n\t\t},\n\t\tregionRegex: \"^(us|eu|ap|sa|ca|me|af|il|mx)\\\\-\\\\w+\\\\-\\\\d+$\",\n\t\tregions: {\n\t\t\t\"af-south-1\": {\n\t\t\t\tdescription: \"Africa (Cape Town)\"\n\t\t\t},\n\t\t\t\"ap-east-1\": {\n\t\t\t\tdescription: \"Asia Pacific (Hong Kong)\"\n\t\t\t},\n\t\t\t\"ap-east-2\": {\n\t\t\t\tdescription: \"Asia Pacific (Taipei)\"\n\t\t\t},\n\t\t\t\"ap-northeast-1\": {\n\t\t\t\tdescription: \"Asia Pacific (Tokyo)\"\n\t\t\t},\n\t\t\t\"ap-northeast-2\": {\n\t\t\t\tdescription: \"Asia Pacific (Seoul)\"\n\t\t\t},\n\t\t\t\"ap-northeast-3\": {\n\t\t\t\tdescription: \"Asia Pacific (Osaka)\"\n\t\t\t},\n\t\t\t\"ap-south-1\": {\n\t\t\t\tdescription: \"Asia Pacific (Mumbai)\"\n\t\t\t},\n\t\t\t\"ap-south-2\": {\n\t\t\t\tdescription: \"Asia Pacific (Hyderabad)\"\n\t\t\t},\n\t\t\t\"ap-southeast-1\": {\n\t\t\t\tdescription: \"Asia Pacific (Singapore)\"\n\t\t\t},\n\t\t\t\"ap-southeast-2\": {\n\t\t\t\tdescription: \"Asia Pacific (Sydney)\"\n\t\t\t},\n\t\t\t\"ap-southeast-3\": {\n\t\t\t\tdescription: \"Asia Pacific (Jakarta)\"\n\t\t\t},\n\t\t\t\"ap-southeast-4\": {\n\t\t\t\tdescription: \"Asia Pacific (Melbourne)\"\n\t\t\t},\n\t\t\t\"ap-southeast-5\": {\n\t\t\t\tdescription: \"Asia Pacific (Malaysia)\"\n\t\t\t},\n\t\t\t\"ap-southeast-6\": {\n\t\t\t\tdescription: \"Asia Pacific (New Zealand)\"\n\t\t\t},\n\t\t\t\"ap-southeast-7\": {\n\t\t\t\tdescription: \"Asia Pacific (Thailand)\"\n\t\t\t},\n\t\t\t\"aws-global\": {\n\t\t\t\tdescription: \"aws global region\"\n\t\t\t},\n\t\t\t\"ca-central-1\": {\n\t\t\t\tdescription: \"Canada (Central)\"\n\t\t\t},\n\t\t\t\"ca-west-1\": {\n\t\t\t\tdescription: \"Canada West (Calgary)\"\n\t\t\t},\n\t\t\t\"eu-central-1\": {\n\t\t\t\tdescription: \"Europe (Frankfurt)\"\n\t\t\t},\n\t\t\t\"eu-central-2\": {\n\t\t\t\tdescription: \"Europe (Zurich)\"\n\t\t\t},\n\t\t\t\"eu-north-1\": {\n\t\t\t\tdescription: \"Europe (Stockholm)\"\n\t\t\t},\n\t\t\t\"eu-south-1\": {\n\t\t\t\tdescription: \"Europe (Milan)\"\n\t\t\t},\n\t\t\t\"eu-south-2\": {\n\t\t\t\tdescription: \"Europe (Spain)\"\n\t\t\t},\n\t\t\t\"eu-west-1\": {\n\t\t\t\tdescription: \"Europe (Ireland)\"\n\t\t\t},\n\t\t\t\"eu-west-2\": {\n\t\t\t\tdescription: \"Europe (London)\"\n\t\t\t},\n\t\t\t\"eu-west-3\": {\n\t\t\t\tdescription: \"Europe (Paris)\"\n\t\t\t},\n\t\t\t\"il-central-1\": {\n\t\t\t\tdescription: \"Israel (Tel Aviv)\"\n\t\t\t},\n\t\t\t\"me-central-1\": {\n\t\t\t\tdescription: \"Middle East (UAE)\"\n\t\t\t},\n\t\t\t\"me-south-1\": {\n\t\t\t\tdescription: \"Middle East (Bahrain)\"\n\t\t\t},\n\t\t\t\"mx-central-1\": {\n\t\t\t\tdescription: \"Mexico (Central)\"\n\t\t\t},\n\t\t\t\"sa-east-1\": {\n\t\t\t\tdescription: \"South America (Sao Paulo)\"\n\t\t\t},\n\t\t\t\"us-east-1\": {\n\t\t\t\tdescription: \"US East (N. Virginia)\"\n\t\t\t},\n\t\t\t\"us-east-2\": {\n\t\t\t\tdescription: \"US East (Ohio)\"\n\t\t\t},\n\t\t\t\"us-west-1\": {\n\t\t\t\tdescription: \"US West (N. California)\"\n\t\t\t},\n\t\t\t\"us-west-2\": {\n\t\t\t\tdescription: \"US West (Oregon)\"\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\tid: \"aws-cn\",\n\t\toutputs: {\n\t\t\tdnsSuffix: \"amazonaws.com.cn\",\n\t\t\tdualStackDnsSuffix: \"api.amazonwebservices.com.cn\",\n\t\t\timplicitGlobalRegion: \"cn-northwest-1\",\n\t\t\tname: \"aws-cn\",\n\t\t\tsupportsDualStack: true,\n\t\t\tsupportsFIPS: true\n\t\t},\n\t\tregionRegex: \"^cn\\\\-\\\\w+\\\\-\\\\d+$\",\n\t\tregions: {\n\t\t\t\"aws-cn-global\": {\n\t\t\t\tdescription: \"aws-cn global region\"\n\t\t\t},\n\t\t\t\"cn-north-1\": {\n\t\t\t\tdescription: \"China (Beijing)\"\n\t\t\t},\n\t\t\t\"cn-northwest-1\": {\n\t\t\t\tdescription: \"China (Ningxia)\"\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\tid: \"aws-eusc\",\n\t\toutputs: {\n\t\t\tdnsSuffix: \"amazonaws.eu\",\n\t\t\tdualStackDnsSuffix: \"api.amazonwebservices.eu\",\n\t\t\timplicitGlobalRegion: \"eusc-de-east-1\",\n\t\t\tname: \"aws-eusc\",\n\t\t\tsupportsDualStack: true,\n\t\t\tsupportsFIPS: true\n\t\t},\n\t\tregionRegex: \"^eusc\\\\-(de)\\\\-\\\\w+\\\\-\\\\d+$\",\n\t\tregions: {\n\t\t\t\"eusc-de-east-1\": {\n\t\t\t\tdescription: \"AWS European Sovereign Cloud (Germany)\"\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\tid: \"aws-iso\",\n\t\toutputs: {\n\t\t\tdnsSuffix: \"c2s.ic.gov\",\n\t\t\tdualStackDnsSuffix: \"api.aws.ic.gov\",\n\t\t\timplicitGlobalRegion: \"us-iso-east-1\",\n\t\t\tname: \"aws-iso\",\n\t\t\tsupportsDualStack: true,\n\t\t\tsupportsFIPS: true\n\t\t},\n\t\tregionRegex: \"^us\\\\-iso\\\\-\\\\w+\\\\-\\\\d+$\",\n\t\tregions: {\n\t\t\t\"aws-iso-global\": {\n\t\t\t\tdescription: \"aws-iso global region\"\n\t\t\t},\n\t\t\t\"us-iso-east-1\": {\n\t\t\t\tdescription: \"US ISO East\"\n\t\t\t},\n\t\t\t\"us-iso-west-1\": {\n\t\t\t\tdescription: \"US ISO WEST\"\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\tid: \"aws-iso-b\",\n\t\toutputs: {\n\t\t\tdnsSuffix: \"sc2s.sgov.gov\",\n\t\t\tdualStackDnsSuffix: \"api.aws.scloud\",\n\t\t\timplicitGlobalRegion: \"us-isob-east-1\",\n\t\t\tname: \"aws-iso-b\",\n\t\t\tsupportsDualStack: true,\n\t\t\tsupportsFIPS: true\n\t\t},\n\t\tregionRegex: \"^us\\\\-isob\\\\-\\\\w+\\\\-\\\\d+$\",\n\t\tregions: {\n\t\t\t\"aws-iso-b-global\": {\n\t\t\t\tdescription: \"aws-iso-b global region\"\n\t\t\t},\n\t\t\t\"us-isob-east-1\": {\n\t\t\t\tdescription: \"US ISOB East (Ohio)\"\n\t\t\t},\n\t\t\t\"us-isob-west-1\": {\n\t\t\t\tdescription: \"US ISOB West\"\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\tid: \"aws-iso-e\",\n\t\toutputs: {\n\t\t\tdnsSuffix: \"cloud.adc-e.uk\",\n\t\t\tdualStackDnsSuffix: \"api.cloud-aws.adc-e.uk\",\n\t\t\timplicitGlobalRegion: \"eu-isoe-west-1\",\n\t\t\tname: \"aws-iso-e\",\n\t\t\tsupportsDualStack: true,\n\t\t\tsupportsFIPS: true\n\t\t},\n\t\tregionRegex: \"^eu\\\\-isoe\\\\-\\\\w+\\\\-\\\\d+$\",\n\t\tregions: {\n\t\t\t\"aws-iso-e-global\": {\n\t\t\t\tdescription: \"aws-iso-e global region\"\n\t\t\t},\n\t\t\t\"eu-isoe-west-1\": {\n\t\t\t\tdescription: \"EU ISOE West\"\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\tid: \"aws-iso-f\",\n\t\toutputs: {\n\t\t\tdnsSuffix: \"csp.hci.ic.gov\",\n\t\t\tdualStackDnsSuffix: \"api.aws.hci.ic.gov\",\n\t\t\timplicitGlobalRegion: \"us-isof-south-1\",\n\t\t\tname: \"aws-iso-f\",\n\t\t\tsupportsDualStack: true,\n\t\t\tsupportsFIPS: true\n\t\t},\n\t\tregionRegex: \"^us\\\\-isof\\\\-\\\\w+\\\\-\\\\d+$\",\n\t\tregions: {\n\t\t\t\"aws-iso-f-global\": {\n\t\t\t\tdescription: \"aws-iso-f global region\"\n\t\t\t},\n\t\t\t\"us-isof-east-1\": {\n\t\t\t\tdescription: \"US ISOF EAST\"\n\t\t\t},\n\t\t\t\"us-isof-south-1\": {\n\t\t\t\tdescription: \"US ISOF SOUTH\"\n\t\t\t}\n\t\t}\n\t},\n\t{\n\t\tid: \"aws-us-gov\",\n\t\toutputs: {\n\t\t\tdnsSuffix: \"amazonaws.com\",\n\t\t\tdualStackDnsSuffix: \"api.aws\",\n\t\t\timplicitGlobalRegion: \"us-gov-west-1\",\n\t\t\tname: \"aws-us-gov\",\n\t\t\tsupportsDualStack: true,\n\t\t\tsupportsFIPS: true\n\t\t},\n\t\tregionRegex: \"^us\\\\-gov\\\\-\\\\w+\\\\-\\\\d+$\",\n\t\tregions: {\n\t\t\t\"aws-us-gov-global\": {\n\t\t\t\tdescription: \"aws-us-gov global region\"\n\t\t\t},\n\t\t\t\"us-gov-east-1\": {\n\t\t\t\tdescription: \"AWS GovCloud (US-East)\"\n\t\t\t},\n\t\t\t\"us-gov-west-1\": {\n\t\t\t\tdescription: \"AWS GovCloud (US-West)\"\n\t\t\t}\n\t\t}\n\t}\n];\nvar version = \"1.1\";\nvar partitionsInfo = {\n\tpartitions: partitions,\n\tversion: version\n};\n\nlet selectedPartitionsInfo = partitionsInfo;\nlet selectedUserAgentPrefix = \"\";\nconst partition = (value) => {\n    const { partitions } = selectedPartitionsInfo;\n    for (const partition of partitions) {\n        const { regions, outputs } = partition;\n        for (const [region, regionData] of Object.entries(regions)) {\n            if (region === value) {\n                return {\n                    ...outputs,\n                    ...regionData,\n                };\n            }\n        }\n    }\n    for (const partition of partitions) {\n        const { regionRegex, outputs } = partition;\n        if (new RegExp(regionRegex).test(value)) {\n            return {\n                ...outputs,\n            };\n        }\n    }\n    const DEFAULT_PARTITION = partitions.find((partition) => partition.id === \"aws\");\n    if (!DEFAULT_PARTITION) {\n        throw new Error(\"Provided region was not found in the partition array or regex,\" +\n            \" and default partition with id 'aws' doesn't exist.\");\n    }\n    return {\n        ...DEFAULT_PARTITION.outputs,\n    };\n};\nconst setPartitionInfo = (partitionsInfo, userAgentPrefix = \"\") => {\n    selectedPartitionsInfo = partitionsInfo;\n    selectedUserAgentPrefix = userAgentPrefix;\n};\nconst useDefaultPartitionInfo = () => {\n    setPartitionInfo(partitionsInfo, \"\");\n};\nconst getUserAgentPrefix = () => selectedUserAgentPrefix;\n\nconst awsEndpointFunctions = {\n    isVirtualHostableS3Bucket: isVirtualHostableS3Bucket,\n    parseArn: parseArn,\n    partition: partition,\n};\nutilEndpoints.customEndpointFunctions.aws = awsEndpointFunctions;\n\nconst resolveDefaultAwsRegionalEndpointsConfig = (input) => {\n    if (typeof input.endpointProvider !== \"function\") {\n        throw new Error(\"@aws-sdk/util-endpoint - endpointProvider and endpoint missing in config for this client.\");\n    }\n    const { endpoint } = input;\n    if (endpoint === undefined) {\n        input.endpoint = async () => {\n            return toEndpointV1(input.endpointProvider({\n                Region: typeof input.region === \"function\" ? await input.region() : input.region,\n                UseDualStack: typeof input.useDualstackEndpoint === \"function\"\n                    ? await input.useDualstackEndpoint()\n                    : input.useDualstackEndpoint,\n                UseFIPS: typeof input.useFipsEndpoint === \"function\" ? await input.useFipsEndpoint() : input.useFipsEndpoint,\n                Endpoint: undefined,\n            }, { logger: input.logger }));\n        };\n    }\n    return input;\n};\nconst toEndpointV1 = (endpoint) => urlParser.parseUrl(endpoint.url);\n\nObject.defineProperty(exports, \"EndpointError\", {\n    enumerable: true,\n    get: function () { return utilEndpoints.EndpointError; }\n});\nObject.defineProperty(exports, \"isIpAddress\", {\n    enumerable: true,\n    get: function () { return utilEndpoints.isIpAddress; }\n});\nObject.defineProperty(exports, \"resolveEndpoint\", {\n    enumerable: true,\n    get: function () { return utilEndpoints.resolveEndpoint; }\n});\nexports.awsEndpointFunctions = awsEndpointFunctions;\nexports.getUserAgentPrefix = getUserAgentPrefix;\nexports.partition = partition;\nexports.resolveDefaultAwsRegionalEndpointsConfig = resolveDefaultAwsRegionalEndpointsConfig;\nexports.setPartitionInfo = setPartitionInfo;\nexports.toEndpointV1 = toEndpointV1;\nexports.useDefaultPartitionInfo = useDefaultPartitionInfo;\n","'use strict';\n\nvar os = require('os');\nvar process = require('process');\nvar middlewareUserAgent = require('@aws-sdk/middleware-user-agent');\n\nconst crtAvailability = {\n    isCrtAvailable: false,\n};\n\nconst isCrtAvailable = () => {\n    if (crtAvailability.isCrtAvailable) {\n        return [\"md/crt-avail\"];\n    }\n    return null;\n};\n\nconst createDefaultUserAgentProvider = ({ serviceId, clientVersion }) => {\n    return async (config) => {\n        const sections = [\n            [\"aws-sdk-js\", clientVersion],\n            [\"ua\", \"2.1\"],\n            [`os/${os.platform()}`, os.release()],\n            [\"lang/js\"],\n            [\"md/nodejs\", `${process.versions.node}`],\n        ];\n        const crtAvailable = isCrtAvailable();\n        if (crtAvailable) {\n            sections.push(crtAvailable);\n        }\n        if (serviceId) {\n            sections.push([`api/${serviceId}`, clientVersion]);\n        }\n        if (process.env.AWS_EXECUTION_ENV) {\n            sections.push([`exec-env/${process.env.AWS_EXECUTION_ENV}`]);\n        }\n        const appId = await config?.userAgentAppId?.();\n        const resolvedUserAgent = appId ? [...sections, [`app/${appId}`]] : [...sections];\n        return resolvedUserAgent;\n    };\n};\nconst defaultUserAgent = createDefaultUserAgentProvider;\n\nconst UA_APP_ID_ENV_NAME = \"AWS_SDK_UA_APP_ID\";\nconst UA_APP_ID_INI_NAME = \"sdk_ua_app_id\";\nconst UA_APP_ID_INI_NAME_DEPRECATED = \"sdk-ua-app-id\";\nconst NODE_APP_ID_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => env[UA_APP_ID_ENV_NAME],\n    configFileSelector: (profile) => profile[UA_APP_ID_INI_NAME] ?? profile[UA_APP_ID_INI_NAME_DEPRECATED],\n    default: middlewareUserAgent.DEFAULT_UA_APP_ID,\n};\n\nexports.NODE_APP_ID_CONFIG_OPTIONS = NODE_APP_ID_CONFIG_OPTIONS;\nexports.UA_APP_ID_ENV_NAME = UA_APP_ID_ENV_NAME;\nexports.UA_APP_ID_INI_NAME = UA_APP_ID_INI_NAME;\nexports.createDefaultUserAgentProvider = createDefaultUserAgentProvider;\nexports.crtAvailability = crtAvailability;\nexports.defaultUserAgent = defaultUserAgent;\n","'use strict';\n\nvar xmlParser = require('./xml-parser');\n\nfunction escapeAttribute(value) {\n    return value.replace(/&/g, \"&amp;\").replace(/</g, \"&lt;\").replace(/>/g, \"&gt;\").replace(/\"/g, \"&quot;\");\n}\n\nfunction escapeElement(value) {\n    return value\n        .replace(/&/g, \"&amp;\")\n        .replace(/\"/g, \"&quot;\")\n        .replace(/'/g, \"&apos;\")\n        .replace(/</g, \"&lt;\")\n        .replace(/>/g, \"&gt;\")\n        .replace(/\\r/g, \"&#x0D;\")\n        .replace(/\\n/g, \"&#x0A;\")\n        .replace(/\\u0085/g, \"&#x85;\")\n        .replace(/\\u2028/, \"&#x2028;\");\n}\n\nclass XmlText {\n    value;\n    constructor(value) {\n        this.value = value;\n    }\n    toString() {\n        return escapeElement(\"\" + this.value);\n    }\n}\n\nclass XmlNode {\n    name;\n    children;\n    attributes = {};\n    static of(name, childText, withName) {\n        const node = new XmlNode(name);\n        if (childText !== undefined) {\n            node.addChildNode(new XmlText(childText));\n        }\n        if (withName !== undefined) {\n            node.withName(withName);\n        }\n        return node;\n    }\n    constructor(name, children = []) {\n        this.name = name;\n        this.children = children;\n    }\n    withName(name) {\n        this.name = name;\n        return this;\n    }\n    addAttribute(name, value) {\n        this.attributes[name] = value;\n        return this;\n    }\n    addChildNode(child) {\n        this.children.push(child);\n        return this;\n    }\n    removeAttribute(name) {\n        delete this.attributes[name];\n        return this;\n    }\n    n(name) {\n        this.name = name;\n        return this;\n    }\n    c(child) {\n        this.children.push(child);\n        return this;\n    }\n    a(name, value) {\n        if (value != null) {\n            this.attributes[name] = value;\n        }\n        return this;\n    }\n    cc(input, field, withName = field) {\n        if (input[field] != null) {\n            const node = XmlNode.of(field, input[field]).withName(withName);\n            this.c(node);\n        }\n    }\n    l(input, listName, memberName, valueProvider) {\n        if (input[listName] != null) {\n            const nodes = valueProvider();\n            nodes.map((node) => {\n                node.withName(memberName);\n                this.c(node);\n            });\n        }\n    }\n    lc(input, listName, memberName, valueProvider) {\n        if (input[listName] != null) {\n            const nodes = valueProvider();\n            const containerNode = new XmlNode(memberName);\n            nodes.map((node) => {\n                containerNode.c(node);\n            });\n            this.c(containerNode);\n        }\n    }\n    toString() {\n        const hasChildren = Boolean(this.children.length);\n        let xmlText = `<${this.name}`;\n        const attributes = this.attributes;\n        for (const attributeName of Object.keys(attributes)) {\n            const attribute = attributes[attributeName];\n            if (attribute != null) {\n                xmlText += ` ${attributeName}=\"${escapeAttribute(\"\" + attribute)}\"`;\n            }\n        }\n        return (xmlText += !hasChildren ? \"/>\" : `>${this.children.map((c) => c.toString()).join(\"\")}</${this.name}>`);\n    }\n}\n\nObject.defineProperty(exports, \"parseXML\", {\n    enumerable: true,\n    get: function () { return xmlParser.parseXML; }\n});\nexports.XmlNode = XmlNode;\nexports.XmlText = XmlText;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.parseXML = parseXML;\nconst fast_xml_parser_1 = require(\"fast-xml-parser\");\nconst parser = new fast_xml_parser_1.XMLParser({\n    attributeNamePrefix: \"\",\n    htmlEntities: true,\n    ignoreAttributes: false,\n    ignoreDeclaration: true,\n    parseTagValue: false,\n    trimValues: false,\n    tagValueProcessor: (_, val) => (val.trim() === \"\" && val.includes(\"\\n\") ? \"\" : undefined),\n});\nparser.addEntity(\"#xD\", \"\\r\");\nparser.addEntity(\"#10\", \"\\n\");\nfunction parseXML(xmlString) {\n    return parser.parse(xmlString, true);\n}\n","'use strict';\n\nconst PROTECTED_KEYS = {\n    REQUEST_ID: Symbol.for(\"_AWS_LAMBDA_REQUEST_ID\"),\n    X_RAY_TRACE_ID: Symbol.for(\"_AWS_LAMBDA_X_RAY_TRACE_ID\"),\n    TENANT_ID: Symbol.for(\"_AWS_LAMBDA_TENANT_ID\"),\n};\nconst NO_GLOBAL_AWS_LAMBDA = [\"true\", \"1\"].includes(process.env?.AWS_LAMBDA_NODEJS_NO_GLOBAL_AWSLAMBDA ?? \"\");\nif (!NO_GLOBAL_AWS_LAMBDA) {\n    globalThis.awslambda = globalThis.awslambda || {};\n}\nclass InvokeStoreBase {\n    static PROTECTED_KEYS = PROTECTED_KEYS;\n    isProtectedKey(key) {\n        return Object.values(PROTECTED_KEYS).includes(key);\n    }\n    getRequestId() {\n        return this.get(PROTECTED_KEYS.REQUEST_ID) ?? \"-\";\n    }\n    getXRayTraceId() {\n        return this.get(PROTECTED_KEYS.X_RAY_TRACE_ID);\n    }\n    getTenantId() {\n        return this.get(PROTECTED_KEYS.TENANT_ID);\n    }\n}\nclass InvokeStoreSingle extends InvokeStoreBase {\n    currentContext;\n    getContext() {\n        return this.currentContext;\n    }\n    hasContext() {\n        return this.currentContext !== undefined;\n    }\n    get(key) {\n        return this.currentContext?.[key];\n    }\n    set(key, value) {\n        if (this.isProtectedKey(key)) {\n            throw new Error(`Cannot modify protected Lambda context field: ${String(key)}`);\n        }\n        this.currentContext = this.currentContext || {};\n        this.currentContext[key] = value;\n    }\n    run(context, fn) {\n        this.currentContext = context;\n        return fn();\n    }\n}\nclass InvokeStoreMulti extends InvokeStoreBase {\n    als;\n    static async create() {\n        const instance = new InvokeStoreMulti();\n        const asyncHooks = await import('node:async_hooks');\n        instance.als = new asyncHooks.AsyncLocalStorage();\n        return instance;\n    }\n    getContext() {\n        return this.als.getStore();\n    }\n    hasContext() {\n        return this.als.getStore() !== undefined;\n    }\n    get(key) {\n        return this.als.getStore()?.[key];\n    }\n    set(key, value) {\n        if (this.isProtectedKey(key)) {\n            throw new Error(`Cannot modify protected Lambda context field: ${String(key)}`);\n        }\n        const store = this.als.getStore();\n        if (!store) {\n            throw new Error(\"No context available\");\n        }\n        store[key] = value;\n    }\n    run(context, fn) {\n        return this.als.run(context, fn);\n    }\n}\nexports.InvokeStore = void 0;\n(function (InvokeStore) {\n    let instance = null;\n    async function getInstanceAsync() {\n        if (!instance) {\n            instance = (async () => {\n                const isMulti = \"AWS_LAMBDA_MAX_CONCURRENCY\" in process.env;\n                const newInstance = isMulti\n                    ? await InvokeStoreMulti.create()\n                    : new InvokeStoreSingle();\n                if (!NO_GLOBAL_AWS_LAMBDA && globalThis.awslambda?.InvokeStore) {\n                    return globalThis.awslambda.InvokeStore;\n                }\n                else if (!NO_GLOBAL_AWS_LAMBDA && globalThis.awslambda) {\n                    globalThis.awslambda.InvokeStore = newInstance;\n                    return newInstance;\n                }\n                else {\n                    return newInstance;\n                }\n            })();\n        }\n        return instance;\n    }\n    InvokeStore.getInstanceAsync = getInstanceAsync;\n    InvokeStore._testing = process.env.AWS_LAMBDA_BENCHMARK_MODE === \"1\"\n        ? {\n            reset: () => {\n                instance = null;\n                if (globalThis.awslambda?.InvokeStore) {\n                    delete globalThis.awslambda.InvokeStore;\n                }\n                globalThis.awslambda = { InvokeStore: undefined };\n            },\n        }\n        : undefined;\n})(exports.InvokeStore || (exports.InvokeStore = {}));\n\nexports.InvokeStoreBase = InvokeStoreBase;\n","'use strict';\n\nvar utilConfigProvider = require('@smithy/util-config-provider');\nvar utilMiddleware = require('@smithy/util-middleware');\nvar utilEndpoints = require('@smithy/util-endpoints');\n\nconst ENV_USE_DUALSTACK_ENDPOINT = \"AWS_USE_DUALSTACK_ENDPOINT\";\nconst CONFIG_USE_DUALSTACK_ENDPOINT = \"use_dualstack_endpoint\";\nconst DEFAULT_USE_DUALSTACK_ENDPOINT = false;\nconst NODE_USE_DUALSTACK_ENDPOINT_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => utilConfigProvider.booleanSelector(env, ENV_USE_DUALSTACK_ENDPOINT, utilConfigProvider.SelectorType.ENV),\n    configFileSelector: (profile) => utilConfigProvider.booleanSelector(profile, CONFIG_USE_DUALSTACK_ENDPOINT, utilConfigProvider.SelectorType.CONFIG),\n    default: false,\n};\n\nconst ENV_USE_FIPS_ENDPOINT = \"AWS_USE_FIPS_ENDPOINT\";\nconst CONFIG_USE_FIPS_ENDPOINT = \"use_fips_endpoint\";\nconst DEFAULT_USE_FIPS_ENDPOINT = false;\nconst NODE_USE_FIPS_ENDPOINT_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => utilConfigProvider.booleanSelector(env, ENV_USE_FIPS_ENDPOINT, utilConfigProvider.SelectorType.ENV),\n    configFileSelector: (profile) => utilConfigProvider.booleanSelector(profile, CONFIG_USE_FIPS_ENDPOINT, utilConfigProvider.SelectorType.CONFIG),\n    default: false,\n};\n\nconst resolveCustomEndpointsConfig = (input) => {\n    const { tls, endpoint, urlParser, useDualstackEndpoint } = input;\n    return Object.assign(input, {\n        tls: tls ?? true,\n        endpoint: utilMiddleware.normalizeProvider(typeof endpoint === \"string\" ? urlParser(endpoint) : endpoint),\n        isCustomEndpoint: true,\n        useDualstackEndpoint: utilMiddleware.normalizeProvider(useDualstackEndpoint ?? false),\n    });\n};\n\nconst getEndpointFromRegion = async (input) => {\n    const { tls = true } = input;\n    const region = await input.region();\n    const dnsHostRegex = new RegExp(/^([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9-]{0,61}[a-zA-Z0-9])$/);\n    if (!dnsHostRegex.test(region)) {\n        throw new Error(\"Invalid region in client config\");\n    }\n    const useDualstackEndpoint = await input.useDualstackEndpoint();\n    const useFipsEndpoint = await input.useFipsEndpoint();\n    const { hostname } = (await input.regionInfoProvider(region, { useDualstackEndpoint, useFipsEndpoint })) ?? {};\n    if (!hostname) {\n        throw new Error(\"Cannot resolve hostname from client config\");\n    }\n    return input.urlParser(`${tls ? \"https:\" : \"http:\"}//${hostname}`);\n};\n\nconst resolveEndpointsConfig = (input) => {\n    const useDualstackEndpoint = utilMiddleware.normalizeProvider(input.useDualstackEndpoint ?? false);\n    const { endpoint, useFipsEndpoint, urlParser, tls } = input;\n    return Object.assign(input, {\n        tls: tls ?? true,\n        endpoint: endpoint\n            ? utilMiddleware.normalizeProvider(typeof endpoint === \"string\" ? urlParser(endpoint) : endpoint)\n            : () => getEndpointFromRegion({ ...input, useDualstackEndpoint, useFipsEndpoint }),\n        isCustomEndpoint: !!endpoint,\n        useDualstackEndpoint,\n    });\n};\n\nconst REGION_ENV_NAME = \"AWS_REGION\";\nconst REGION_INI_NAME = \"region\";\nconst NODE_REGION_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => env[REGION_ENV_NAME],\n    configFileSelector: (profile) => profile[REGION_INI_NAME],\n    default: () => {\n        throw new Error(\"Region is missing\");\n    },\n};\nconst NODE_REGION_CONFIG_FILE_OPTIONS = {\n    preferredFile: \"credentials\",\n};\n\nconst validRegions = new Set();\nconst checkRegion = (region, check = utilEndpoints.isValidHostLabel) => {\n    if (!validRegions.has(region) && !check(region)) {\n        if (region === \"*\") {\n            console.warn(`@smithy/config-resolver WARN - Please use the caller region instead of \"*\". See \"sigv4a\" in https://github.com/aws/aws-sdk-js-v3/blob/main/supplemental-docs/CLIENTS.md.`);\n        }\n        else {\n            throw new Error(`Region not accepted: region=\"${region}\" is not a valid hostname component.`);\n        }\n    }\n    else {\n        validRegions.add(region);\n    }\n};\n\nconst isFipsRegion = (region) => typeof region === \"string\" && (region.startsWith(\"fips-\") || region.endsWith(\"-fips\"));\n\nconst getRealRegion = (region) => isFipsRegion(region)\n    ? [\"fips-aws-global\", \"aws-fips\"].includes(region)\n        ? \"us-east-1\"\n        : region.replace(/fips-(dkr-|prod-)?|-fips/, \"\")\n    : region;\n\nconst resolveRegionConfig = (input) => {\n    const { region, useFipsEndpoint } = input;\n    if (!region) {\n        throw new Error(\"Region is missing\");\n    }\n    return Object.assign(input, {\n        region: async () => {\n            const providedRegion = typeof region === \"function\" ? await region() : region;\n            const realRegion = getRealRegion(providedRegion);\n            checkRegion(realRegion);\n            return realRegion;\n        },\n        useFipsEndpoint: async () => {\n            const providedRegion = typeof region === \"string\" ? region : await region();\n            if (isFipsRegion(providedRegion)) {\n                return true;\n            }\n            return typeof useFipsEndpoint !== \"function\" ? Promise.resolve(!!useFipsEndpoint) : useFipsEndpoint();\n        },\n    });\n};\n\nconst getHostnameFromVariants = (variants = [], { useFipsEndpoint, useDualstackEndpoint }) => variants.find(({ tags }) => useFipsEndpoint === tags.includes(\"fips\") && useDualstackEndpoint === tags.includes(\"dualstack\"))?.hostname;\n\nconst getResolvedHostname = (resolvedRegion, { regionHostname, partitionHostname }) => regionHostname\n    ? regionHostname\n    : partitionHostname\n        ? partitionHostname.replace(\"{region}\", resolvedRegion)\n        : undefined;\n\nconst getResolvedPartition = (region, { partitionHash }) => Object.keys(partitionHash || {}).find((key) => partitionHash[key].regions.includes(region)) ?? \"aws\";\n\nconst getResolvedSigningRegion = (hostname, { signingRegion, regionRegex, useFipsEndpoint }) => {\n    if (signingRegion) {\n        return signingRegion;\n    }\n    else if (useFipsEndpoint) {\n        const regionRegexJs = regionRegex.replace(\"\\\\\\\\\", \"\\\\\").replace(/^\\^/g, \"\\\\.\").replace(/\\$$/g, \"\\\\.\");\n        const regionRegexmatchArray = hostname.match(regionRegexJs);\n        if (regionRegexmatchArray) {\n            return regionRegexmatchArray[0].slice(1, -1);\n        }\n    }\n};\n\nconst getRegionInfo = (region, { useFipsEndpoint = false, useDualstackEndpoint = false, signingService, regionHash, partitionHash, }) => {\n    const partition = getResolvedPartition(region, { partitionHash });\n    const resolvedRegion = region in regionHash ? region : partitionHash[partition]?.endpoint ?? region;\n    const hostnameOptions = { useFipsEndpoint, useDualstackEndpoint };\n    const regionHostname = getHostnameFromVariants(regionHash[resolvedRegion]?.variants, hostnameOptions);\n    const partitionHostname = getHostnameFromVariants(partitionHash[partition]?.variants, hostnameOptions);\n    const hostname = getResolvedHostname(resolvedRegion, { regionHostname, partitionHostname });\n    if (hostname === undefined) {\n        throw new Error(`Endpoint resolution failed for: ${{ resolvedRegion, useFipsEndpoint, useDualstackEndpoint }}`);\n    }\n    const signingRegion = getResolvedSigningRegion(hostname, {\n        signingRegion: regionHash[resolvedRegion]?.signingRegion,\n        regionRegex: partitionHash[partition].regionRegex,\n        useFipsEndpoint,\n    });\n    return {\n        partition,\n        signingService,\n        hostname,\n        ...(signingRegion && { signingRegion }),\n        ...(regionHash[resolvedRegion]?.signingService && {\n            signingService: regionHash[resolvedRegion].signingService,\n        }),\n    };\n};\n\nexports.CONFIG_USE_DUALSTACK_ENDPOINT = CONFIG_USE_DUALSTACK_ENDPOINT;\nexports.CONFIG_USE_FIPS_ENDPOINT = CONFIG_USE_FIPS_ENDPOINT;\nexports.DEFAULT_USE_DUALSTACK_ENDPOINT = DEFAULT_USE_DUALSTACK_ENDPOINT;\nexports.DEFAULT_USE_FIPS_ENDPOINT = DEFAULT_USE_FIPS_ENDPOINT;\nexports.ENV_USE_DUALSTACK_ENDPOINT = ENV_USE_DUALSTACK_ENDPOINT;\nexports.ENV_USE_FIPS_ENDPOINT = ENV_USE_FIPS_ENDPOINT;\nexports.NODE_REGION_CONFIG_FILE_OPTIONS = NODE_REGION_CONFIG_FILE_OPTIONS;\nexports.NODE_REGION_CONFIG_OPTIONS = NODE_REGION_CONFIG_OPTIONS;\nexports.NODE_USE_DUALSTACK_ENDPOINT_CONFIG_OPTIONS = NODE_USE_DUALSTACK_ENDPOINT_CONFIG_OPTIONS;\nexports.NODE_USE_FIPS_ENDPOINT_CONFIG_OPTIONS = NODE_USE_FIPS_ENDPOINT_CONFIG_OPTIONS;\nexports.REGION_ENV_NAME = REGION_ENV_NAME;\nexports.REGION_INI_NAME = REGION_INI_NAME;\nexports.getRegionInfo = getRegionInfo;\nexports.resolveCustomEndpointsConfig = resolveCustomEndpointsConfig;\nexports.resolveEndpointsConfig = resolveEndpointsConfig;\nexports.resolveRegionConfig = resolveRegionConfig;\n","'use strict';\n\nvar types = require('@smithy/types');\nvar utilMiddleware = require('@smithy/util-middleware');\nvar middlewareSerde = require('@smithy/middleware-serde');\nvar protocolHttp = require('@smithy/protocol-http');\nvar protocols = require('@smithy/core/protocols');\n\nconst getSmithyContext = (context) => context[types.SMITHY_CONTEXT_KEY] || (context[types.SMITHY_CONTEXT_KEY] = {});\n\nconst resolveAuthOptions = (candidateAuthOptions, authSchemePreference) => {\n    if (!authSchemePreference || authSchemePreference.length === 0) {\n        return candidateAuthOptions;\n    }\n    const preferredAuthOptions = [];\n    for (const preferredSchemeName of authSchemePreference) {\n        for (const candidateAuthOption of candidateAuthOptions) {\n            const candidateAuthSchemeName = candidateAuthOption.schemeId.split(\"#\")[1];\n            if (candidateAuthSchemeName === preferredSchemeName) {\n                preferredAuthOptions.push(candidateAuthOption);\n            }\n        }\n    }\n    for (const candidateAuthOption of candidateAuthOptions) {\n        if (!preferredAuthOptions.find(({ schemeId }) => schemeId === candidateAuthOption.schemeId)) {\n            preferredAuthOptions.push(candidateAuthOption);\n        }\n    }\n    return preferredAuthOptions;\n};\n\nfunction convertHttpAuthSchemesToMap(httpAuthSchemes) {\n    const map = new Map();\n    for (const scheme of httpAuthSchemes) {\n        map.set(scheme.schemeId, scheme);\n    }\n    return map;\n}\nconst httpAuthSchemeMiddleware = (config, mwOptions) => (next, context) => async (args) => {\n    const options = config.httpAuthSchemeProvider(await mwOptions.httpAuthSchemeParametersProvider(config, context, args.input));\n    const authSchemePreference = config.authSchemePreference ? await config.authSchemePreference() : [];\n    const resolvedOptions = resolveAuthOptions(options, authSchemePreference);\n    const authSchemes = convertHttpAuthSchemesToMap(config.httpAuthSchemes);\n    const smithyContext = utilMiddleware.getSmithyContext(context);\n    const failureReasons = [];\n    for (const option of resolvedOptions) {\n        const scheme = authSchemes.get(option.schemeId);\n        if (!scheme) {\n            failureReasons.push(`HttpAuthScheme \\`${option.schemeId}\\` was not enabled for this service.`);\n            continue;\n        }\n        const identityProvider = scheme.identityProvider(await mwOptions.identityProviderConfigProvider(config));\n        if (!identityProvider) {\n            failureReasons.push(`HttpAuthScheme \\`${option.schemeId}\\` did not have an IdentityProvider configured.`);\n            continue;\n        }\n        const { identityProperties = {}, signingProperties = {} } = option.propertiesExtractor?.(config, context) || {};\n        option.identityProperties = Object.assign(option.identityProperties || {}, identityProperties);\n        option.signingProperties = Object.assign(option.signingProperties || {}, signingProperties);\n        smithyContext.selectedHttpAuthScheme = {\n            httpAuthOption: option,\n            identity: await identityProvider(option.identityProperties),\n            signer: scheme.signer,\n        };\n        break;\n    }\n    if (!smithyContext.selectedHttpAuthScheme) {\n        throw new Error(failureReasons.join(\"\\n\"));\n    }\n    return next(args);\n};\n\nconst httpAuthSchemeEndpointRuleSetMiddlewareOptions = {\n    step: \"serialize\",\n    tags: [\"HTTP_AUTH_SCHEME\"],\n    name: \"httpAuthSchemeMiddleware\",\n    override: true,\n    relation: \"before\",\n    toMiddleware: \"endpointV2Middleware\",\n};\nconst getHttpAuthSchemeEndpointRuleSetPlugin = (config, { httpAuthSchemeParametersProvider, identityProviderConfigProvider, }) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(httpAuthSchemeMiddleware(config, {\n            httpAuthSchemeParametersProvider,\n            identityProviderConfigProvider,\n        }), httpAuthSchemeEndpointRuleSetMiddlewareOptions);\n    },\n});\n\nconst httpAuthSchemeMiddlewareOptions = {\n    step: \"serialize\",\n    tags: [\"HTTP_AUTH_SCHEME\"],\n    name: \"httpAuthSchemeMiddleware\",\n    override: true,\n    relation: \"before\",\n    toMiddleware: middlewareSerde.serializerMiddlewareOption.name,\n};\nconst getHttpAuthSchemePlugin = (config, { httpAuthSchemeParametersProvider, identityProviderConfigProvider, }) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(httpAuthSchemeMiddleware(config, {\n            httpAuthSchemeParametersProvider,\n            identityProviderConfigProvider,\n        }), httpAuthSchemeMiddlewareOptions);\n    },\n});\n\nconst defaultErrorHandler = (signingProperties) => (error) => {\n    throw error;\n};\nconst defaultSuccessHandler = (httpResponse, signingProperties) => { };\nconst httpSigningMiddleware = (config) => (next, context) => async (args) => {\n    if (!protocolHttp.HttpRequest.isInstance(args.request)) {\n        return next(args);\n    }\n    const smithyContext = utilMiddleware.getSmithyContext(context);\n    const scheme = smithyContext.selectedHttpAuthScheme;\n    if (!scheme) {\n        throw new Error(`No HttpAuthScheme was selected: unable to sign request`);\n    }\n    const { httpAuthOption: { signingProperties = {} }, identity, signer, } = scheme;\n    const output = await next({\n        ...args,\n        request: await signer.sign(args.request, identity, signingProperties),\n    }).catch((signer.errorHandler || defaultErrorHandler)(signingProperties));\n    (signer.successHandler || defaultSuccessHandler)(output.response, signingProperties);\n    return output;\n};\n\nconst httpSigningMiddlewareOptions = {\n    step: \"finalizeRequest\",\n    tags: [\"HTTP_SIGNING\"],\n    name: \"httpSigningMiddleware\",\n    aliases: [\"apiKeyMiddleware\", \"tokenMiddleware\", \"awsAuthMiddleware\"],\n    override: true,\n    relation: \"after\",\n    toMiddleware: \"retryMiddleware\",\n};\nconst getHttpSigningPlugin = (config) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(httpSigningMiddleware(), httpSigningMiddlewareOptions);\n    },\n});\n\nconst normalizeProvider = (input) => {\n    if (typeof input === \"function\")\n        return input;\n    const promisified = Promise.resolve(input);\n    return () => promisified;\n};\n\nconst makePagedClientRequest = async (CommandCtor, client, input, withCommand = (_) => _, ...args) => {\n    let command = new CommandCtor(input);\n    command = withCommand(command) ?? command;\n    return await client.send(command, ...args);\n};\nfunction createPaginator(ClientCtor, CommandCtor, inputTokenName, outputTokenName, pageSizeTokenName) {\n    return async function* paginateOperation(config, input, ...additionalArguments) {\n        const _input = input;\n        let token = config.startingToken ?? _input[inputTokenName];\n        let hasNext = true;\n        let page;\n        while (hasNext) {\n            _input[inputTokenName] = token;\n            if (pageSizeTokenName) {\n                _input[pageSizeTokenName] = _input[pageSizeTokenName] ?? config.pageSize;\n            }\n            if (config.client instanceof ClientCtor) {\n                page = await makePagedClientRequest(CommandCtor, config.client, input, config.withCommand, ...additionalArguments);\n            }\n            else {\n                throw new Error(`Invalid client, expected instance of ${ClientCtor.name}`);\n            }\n            yield page;\n            const prevToken = token;\n            token = get(page, outputTokenName);\n            hasNext = !!(token && (!config.stopOnSameToken || token !== prevToken));\n        }\n        return undefined;\n    };\n}\nconst get = (fromObject, path) => {\n    let cursor = fromObject;\n    const pathComponents = path.split(\".\");\n    for (const step of pathComponents) {\n        if (!cursor || typeof cursor !== \"object\") {\n            return undefined;\n        }\n        cursor = cursor[step];\n    }\n    return cursor;\n};\n\nfunction setFeature(context, feature, value) {\n    if (!context.__smithy_context) {\n        context.__smithy_context = {\n            features: {},\n        };\n    }\n    else if (!context.__smithy_context.features) {\n        context.__smithy_context.features = {};\n    }\n    context.__smithy_context.features[feature] = value;\n}\n\nclass DefaultIdentityProviderConfig {\n    authSchemes = new Map();\n    constructor(config) {\n        for (const [key, value] of Object.entries(config)) {\n            if (value !== undefined) {\n                this.authSchemes.set(key, value);\n            }\n        }\n    }\n    getIdentityProvider(schemeId) {\n        return this.authSchemes.get(schemeId);\n    }\n}\n\nclass HttpApiKeyAuthSigner {\n    async sign(httpRequest, identity, signingProperties) {\n        if (!signingProperties) {\n            throw new Error(\"request could not be signed with `apiKey` since the `name` and `in` signer properties are missing\");\n        }\n        if (!signingProperties.name) {\n            throw new Error(\"request could not be signed with `apiKey` since the `name` signer property is missing\");\n        }\n        if (!signingProperties.in) {\n            throw new Error(\"request could not be signed with `apiKey` since the `in` signer property is missing\");\n        }\n        if (!identity.apiKey) {\n            throw new Error(\"request could not be signed with `apiKey` since the `apiKey` is not defined\");\n        }\n        const clonedRequest = protocolHttp.HttpRequest.clone(httpRequest);\n        if (signingProperties.in === types.HttpApiKeyAuthLocation.QUERY) {\n            clonedRequest.query[signingProperties.name] = identity.apiKey;\n        }\n        else if (signingProperties.in === types.HttpApiKeyAuthLocation.HEADER) {\n            clonedRequest.headers[signingProperties.name] = signingProperties.scheme\n                ? `${signingProperties.scheme} ${identity.apiKey}`\n                : identity.apiKey;\n        }\n        else {\n            throw new Error(\"request can only be signed with `apiKey` locations `query` or `header`, \" +\n                \"but found: `\" +\n                signingProperties.in +\n                \"`\");\n        }\n        return clonedRequest;\n    }\n}\n\nclass HttpBearerAuthSigner {\n    async sign(httpRequest, identity, signingProperties) {\n        const clonedRequest = protocolHttp.HttpRequest.clone(httpRequest);\n        if (!identity.token) {\n            throw new Error(\"request could not be signed with `token` since the `token` is not defined\");\n        }\n        clonedRequest.headers[\"Authorization\"] = `Bearer ${identity.token}`;\n        return clonedRequest;\n    }\n}\n\nclass NoAuthSigner {\n    async sign(httpRequest, identity, signingProperties) {\n        return httpRequest;\n    }\n}\n\nconst createIsIdentityExpiredFunction = (expirationMs) => function isIdentityExpired(identity) {\n    return doesIdentityRequireRefresh(identity) && identity.expiration.getTime() - Date.now() < expirationMs;\n};\nconst EXPIRATION_MS = 300_000;\nconst isIdentityExpired = createIsIdentityExpiredFunction(EXPIRATION_MS);\nconst doesIdentityRequireRefresh = (identity) => identity.expiration !== undefined;\nconst memoizeIdentityProvider = (provider, isExpired, requiresRefresh) => {\n    if (provider === undefined) {\n        return undefined;\n    }\n    const normalizedProvider = typeof provider !== \"function\" ? async () => Promise.resolve(provider) : provider;\n    let resolved;\n    let pending;\n    let hasResult;\n    let isConstant = false;\n    const coalesceProvider = async (options) => {\n        if (!pending) {\n            pending = normalizedProvider(options);\n        }\n        try {\n            resolved = await pending;\n            hasResult = true;\n            isConstant = false;\n        }\n        finally {\n            pending = undefined;\n        }\n        return resolved;\n    };\n    if (isExpired === undefined) {\n        return async (options) => {\n            if (!hasResult || options?.forceRefresh) {\n                resolved = await coalesceProvider(options);\n            }\n            return resolved;\n        };\n    }\n    return async (options) => {\n        if (!hasResult || options?.forceRefresh) {\n            resolved = await coalesceProvider(options);\n        }\n        if (isConstant) {\n            return resolved;\n        }\n        if (!requiresRefresh(resolved)) {\n            isConstant = true;\n            return resolved;\n        }\n        if (isExpired(resolved)) {\n            await coalesceProvider(options);\n            return resolved;\n        }\n        return resolved;\n    };\n};\n\nObject.defineProperty(exports, \"requestBuilder\", {\n    enumerable: true,\n    get: function () { return protocols.requestBuilder; }\n});\nexports.DefaultIdentityProviderConfig = DefaultIdentityProviderConfig;\nexports.EXPIRATION_MS = EXPIRATION_MS;\nexports.HttpApiKeyAuthSigner = HttpApiKeyAuthSigner;\nexports.HttpBearerAuthSigner = HttpBearerAuthSigner;\nexports.NoAuthSigner = NoAuthSigner;\nexports.createIsIdentityExpiredFunction = createIsIdentityExpiredFunction;\nexports.createPaginator = createPaginator;\nexports.doesIdentityRequireRefresh = doesIdentityRequireRefresh;\nexports.getHttpAuthSchemeEndpointRuleSetPlugin = getHttpAuthSchemeEndpointRuleSetPlugin;\nexports.getHttpAuthSchemePlugin = getHttpAuthSchemePlugin;\nexports.getHttpSigningPlugin = getHttpSigningPlugin;\nexports.getSmithyContext = getSmithyContext;\nexports.httpAuthSchemeEndpointRuleSetMiddlewareOptions = httpAuthSchemeEndpointRuleSetMiddlewareOptions;\nexports.httpAuthSchemeMiddleware = httpAuthSchemeMiddleware;\nexports.httpAuthSchemeMiddlewareOptions = httpAuthSchemeMiddlewareOptions;\nexports.httpSigningMiddleware = httpSigningMiddleware;\nexports.httpSigningMiddlewareOptions = httpSigningMiddlewareOptions;\nexports.isIdentityExpired = isIdentityExpired;\nexports.memoizeIdentityProvider = memoizeIdentityProvider;\nexports.normalizeProvider = normalizeProvider;\nexports.setFeature = setFeature;\n","'use strict';\n\nvar serde = require('@smithy/core/serde');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar protocols = require('@smithy/core/protocols');\nvar protocolHttp = require('@smithy/protocol-http');\nvar utilBodyLengthBrowser = require('@smithy/util-body-length-browser');\nvar schema = require('@smithy/core/schema');\nvar utilMiddleware = require('@smithy/util-middleware');\nvar utilBase64 = require('@smithy/util-base64');\n\nconst majorUint64 = 0;\nconst majorNegativeInt64 = 1;\nconst majorUnstructuredByteString = 2;\nconst majorUtf8String = 3;\nconst majorList = 4;\nconst majorMap = 5;\nconst majorTag = 6;\nconst majorSpecial = 7;\nconst specialFalse = 20;\nconst specialTrue = 21;\nconst specialNull = 22;\nconst specialUndefined = 23;\nconst extendedOneByte = 24;\nconst extendedFloat16 = 25;\nconst extendedFloat32 = 26;\nconst extendedFloat64 = 27;\nconst minorIndefinite = 31;\nfunction alloc(size) {\n    return typeof Buffer !== \"undefined\" ? Buffer.alloc(size) : new Uint8Array(size);\n}\nconst tagSymbol = Symbol(\"@smithy/core/cbor::tagSymbol\");\nfunction tag(data) {\n    data[tagSymbol] = true;\n    return data;\n}\n\nconst USE_TEXT_DECODER = typeof TextDecoder !== \"undefined\";\nconst USE_BUFFER$1 = typeof Buffer !== \"undefined\";\nlet payload = alloc(0);\nlet dataView$1 = new DataView(payload.buffer, payload.byteOffset, payload.byteLength);\nconst textDecoder = USE_TEXT_DECODER ? new TextDecoder() : null;\nlet _offset = 0;\nfunction setPayload(bytes) {\n    payload = bytes;\n    dataView$1 = new DataView(payload.buffer, payload.byteOffset, payload.byteLength);\n}\nfunction decode(at, to) {\n    if (at >= to) {\n        throw new Error(\"unexpected end of (decode) payload.\");\n    }\n    const major = (payload[at] & 0b1110_0000) >> 5;\n    const minor = payload[at] & 0b0001_1111;\n    switch (major) {\n        case majorUint64:\n        case majorNegativeInt64:\n        case majorTag:\n            let unsignedInt;\n            let offset;\n            if (minor < 24) {\n                unsignedInt = minor;\n                offset = 1;\n            }\n            else {\n                switch (minor) {\n                    case extendedOneByte:\n                    case extendedFloat16:\n                    case extendedFloat32:\n                    case extendedFloat64:\n                        const countLength = minorValueToArgumentLength[minor];\n                        const countOffset = (countLength + 1);\n                        offset = countOffset;\n                        if (to - at < countOffset) {\n                            throw new Error(`countLength ${countLength} greater than remaining buf len.`);\n                        }\n                        const countIndex = at + 1;\n                        if (countLength === 1) {\n                            unsignedInt = payload[countIndex];\n                        }\n                        else if (countLength === 2) {\n                            unsignedInt = dataView$1.getUint16(countIndex);\n                        }\n                        else if (countLength === 4) {\n                            unsignedInt = dataView$1.getUint32(countIndex);\n                        }\n                        else {\n                            unsignedInt = dataView$1.getBigUint64(countIndex);\n                        }\n                        break;\n                    default:\n                        throw new Error(`unexpected minor value ${minor}.`);\n                }\n            }\n            if (major === majorUint64) {\n                _offset = offset;\n                return castBigInt(unsignedInt);\n            }\n            else if (major === majorNegativeInt64) {\n                let negativeInt;\n                if (typeof unsignedInt === \"bigint\") {\n                    negativeInt = BigInt(-1) - unsignedInt;\n                }\n                else {\n                    negativeInt = -1 - unsignedInt;\n                }\n                _offset = offset;\n                return castBigInt(negativeInt);\n            }\n            else {\n                if (minor === 2 || minor === 3) {\n                    const length = decodeCount(at + offset, to);\n                    let b = BigInt(0);\n                    const start = at + offset + _offset;\n                    for (let i = start; i < start + length; ++i) {\n                        b = (b << BigInt(8)) | BigInt(payload[i]);\n                    }\n                    _offset = offset + _offset + length;\n                    return minor === 3 ? -b - BigInt(1) : b;\n                }\n                else if (minor === 4) {\n                    const decimalFraction = decode(at + offset, to);\n                    const [exponent, mantissa] = decimalFraction;\n                    const normalizer = mantissa < 0 ? -1 : 1;\n                    const mantissaStr = \"0\".repeat(Math.abs(exponent) + 1) + String(BigInt(normalizer) * BigInt(mantissa));\n                    let numericString;\n                    const sign = mantissa < 0 ? \"-\" : \"\";\n                    numericString =\n                        exponent === 0\n                            ? mantissaStr\n                            : mantissaStr.slice(0, mantissaStr.length + exponent) + \".\" + mantissaStr.slice(exponent);\n                    numericString = numericString.replace(/^0+/g, \"\");\n                    if (numericString === \"\") {\n                        numericString = \"0\";\n                    }\n                    if (numericString[0] === \".\") {\n                        numericString = \"0\" + numericString;\n                    }\n                    numericString = sign + numericString;\n                    _offset = offset + _offset;\n                    return serde.nv(numericString);\n                }\n                else {\n                    const value = decode(at + offset, to);\n                    const valueOffset = _offset;\n                    _offset = offset + valueOffset;\n                    return tag({ tag: castBigInt(unsignedInt), value });\n                }\n            }\n        case majorUtf8String:\n        case majorMap:\n        case majorList:\n        case majorUnstructuredByteString:\n            if (minor === minorIndefinite) {\n                switch (major) {\n                    case majorUtf8String:\n                        return decodeUtf8StringIndefinite(at, to);\n                    case majorMap:\n                        return decodeMapIndefinite(at, to);\n                    case majorList:\n                        return decodeListIndefinite(at, to);\n                    case majorUnstructuredByteString:\n                        return decodeUnstructuredByteStringIndefinite(at, to);\n                }\n            }\n            else {\n                switch (major) {\n                    case majorUtf8String:\n                        return decodeUtf8String(at, to);\n                    case majorMap:\n                        return decodeMap(at, to);\n                    case majorList:\n                        return decodeList(at, to);\n                    case majorUnstructuredByteString:\n                        return decodeUnstructuredByteString(at, to);\n                }\n            }\n        default:\n            return decodeSpecial(at, to);\n    }\n}\nfunction bytesToUtf8(bytes, at, to) {\n    if (USE_BUFFER$1 && bytes.constructor?.name === \"Buffer\") {\n        return bytes.toString(\"utf-8\", at, to);\n    }\n    if (textDecoder) {\n        return textDecoder.decode(bytes.subarray(at, to));\n    }\n    return utilUtf8.toUtf8(bytes.subarray(at, to));\n}\nfunction demote(bigInteger) {\n    const num = Number(bigInteger);\n    if (num < Number.MIN_SAFE_INTEGER || Number.MAX_SAFE_INTEGER < num) {\n        console.warn(new Error(`@smithy/core/cbor - truncating BigInt(${bigInteger}) to ${num} with loss of precision.`));\n    }\n    return num;\n}\nconst minorValueToArgumentLength = {\n    [extendedOneByte]: 1,\n    [extendedFloat16]: 2,\n    [extendedFloat32]: 4,\n    [extendedFloat64]: 8,\n};\nfunction bytesToFloat16(a, b) {\n    const sign = a >> 7;\n    const exponent = (a & 0b0111_1100) >> 2;\n    const fraction = ((a & 0b0000_0011) << 8) | b;\n    const scalar = sign === 0 ? 1 : -1;\n    let exponentComponent;\n    let summation;\n    if (exponent === 0b00000) {\n        if (fraction === 0b00000_00000) {\n            return 0;\n        }\n        else {\n            exponentComponent = Math.pow(2, 1 - 15);\n            summation = 0;\n        }\n    }\n    else if (exponent === 0b11111) {\n        if (fraction === 0b00000_00000) {\n            return scalar * Infinity;\n        }\n        else {\n            return NaN;\n        }\n    }\n    else {\n        exponentComponent = Math.pow(2, exponent - 15);\n        summation = 1;\n    }\n    summation += fraction / 1024;\n    return scalar * (exponentComponent * summation);\n}\nfunction decodeCount(at, to) {\n    const minor = payload[at] & 0b0001_1111;\n    if (minor < 24) {\n        _offset = 1;\n        return minor;\n    }\n    if (minor === extendedOneByte ||\n        minor === extendedFloat16 ||\n        minor === extendedFloat32 ||\n        minor === extendedFloat64) {\n        const countLength = minorValueToArgumentLength[minor];\n        _offset = (countLength + 1);\n        if (to - at < _offset) {\n            throw new Error(`countLength ${countLength} greater than remaining buf len.`);\n        }\n        const countIndex = at + 1;\n        if (countLength === 1) {\n            return payload[countIndex];\n        }\n        else if (countLength === 2) {\n            return dataView$1.getUint16(countIndex);\n        }\n        else if (countLength === 4) {\n            return dataView$1.getUint32(countIndex);\n        }\n        return demote(dataView$1.getBigUint64(countIndex));\n    }\n    throw new Error(`unexpected minor value ${minor}.`);\n}\nfunction decodeUtf8String(at, to) {\n    const length = decodeCount(at, to);\n    const offset = _offset;\n    at += offset;\n    if (to - at < length) {\n        throw new Error(`string len ${length} greater than remaining buf len.`);\n    }\n    const value = bytesToUtf8(payload, at, at + length);\n    _offset = offset + length;\n    return value;\n}\nfunction decodeUtf8StringIndefinite(at, to) {\n    at += 1;\n    const vector = [];\n    for (const base = at; at < to;) {\n        if (payload[at] === 0b1111_1111) {\n            const data = alloc(vector.length);\n            data.set(vector, 0);\n            _offset = at - base + 2;\n            return bytesToUtf8(data, 0, data.length);\n        }\n        const major = (payload[at] & 0b1110_0000) >> 5;\n        const minor = payload[at] & 0b0001_1111;\n        if (major !== majorUtf8String) {\n            throw new Error(`unexpected major type ${major} in indefinite string.`);\n        }\n        if (minor === minorIndefinite) {\n            throw new Error(\"nested indefinite string.\");\n        }\n        const bytes = decodeUnstructuredByteString(at, to);\n        const length = _offset;\n        at += length;\n        for (let i = 0; i < bytes.length; ++i) {\n            vector.push(bytes[i]);\n        }\n    }\n    throw new Error(\"expected break marker.\");\n}\nfunction decodeUnstructuredByteString(at, to) {\n    const length = decodeCount(at, to);\n    const offset = _offset;\n    at += offset;\n    if (to - at < length) {\n        throw new Error(`unstructured byte string len ${length} greater than remaining buf len.`);\n    }\n    const value = payload.subarray(at, at + length);\n    _offset = offset + length;\n    return value;\n}\nfunction decodeUnstructuredByteStringIndefinite(at, to) {\n    at += 1;\n    const vector = [];\n    for (const base = at; at < to;) {\n        if (payload[at] === 0b1111_1111) {\n            const data = alloc(vector.length);\n            data.set(vector, 0);\n            _offset = at - base + 2;\n            return data;\n        }\n        const major = (payload[at] & 0b1110_0000) >> 5;\n        const minor = payload[at] & 0b0001_1111;\n        if (major !== majorUnstructuredByteString) {\n            throw new Error(`unexpected major type ${major} in indefinite string.`);\n        }\n        if (minor === minorIndefinite) {\n            throw new Error(\"nested indefinite string.\");\n        }\n        const bytes = decodeUnstructuredByteString(at, to);\n        const length = _offset;\n        at += length;\n        for (let i = 0; i < bytes.length; ++i) {\n            vector.push(bytes[i]);\n        }\n    }\n    throw new Error(\"expected break marker.\");\n}\nfunction decodeList(at, to) {\n    const listDataLength = decodeCount(at, to);\n    const offset = _offset;\n    at += offset;\n    const base = at;\n    const list = Array(listDataLength);\n    for (let i = 0; i < listDataLength; ++i) {\n        const item = decode(at, to);\n        const itemOffset = _offset;\n        list[i] = item;\n        at += itemOffset;\n    }\n    _offset = offset + (at - base);\n    return list;\n}\nfunction decodeListIndefinite(at, to) {\n    at += 1;\n    const list = [];\n    for (const base = at; at < to;) {\n        if (payload[at] === 0b1111_1111) {\n            _offset = at - base + 2;\n            return list;\n        }\n        const item = decode(at, to);\n        const n = _offset;\n        at += n;\n        list.push(item);\n    }\n    throw new Error(\"expected break marker.\");\n}\nfunction decodeMap(at, to) {\n    const mapDataLength = decodeCount(at, to);\n    const offset = _offset;\n    at += offset;\n    const base = at;\n    const map = {};\n    for (let i = 0; i < mapDataLength; ++i) {\n        if (at >= to) {\n            throw new Error(\"unexpected end of map payload.\");\n        }\n        const major = (payload[at] & 0b1110_0000) >> 5;\n        if (major !== majorUtf8String) {\n            throw new Error(`unexpected major type ${major} for map key at index ${at}.`);\n        }\n        const key = decode(at, to);\n        at += _offset;\n        const value = decode(at, to);\n        at += _offset;\n        map[key] = value;\n    }\n    _offset = offset + (at - base);\n    return map;\n}\nfunction decodeMapIndefinite(at, to) {\n    at += 1;\n    const base = at;\n    const map = {};\n    for (; at < to;) {\n        if (at >= to) {\n            throw new Error(\"unexpected end of map payload.\");\n        }\n        if (payload[at] === 0b1111_1111) {\n            _offset = at - base + 2;\n            return map;\n        }\n        const major = (payload[at] & 0b1110_0000) >> 5;\n        if (major !== majorUtf8String) {\n            throw new Error(`unexpected major type ${major} for map key.`);\n        }\n        const key = decode(at, to);\n        at += _offset;\n        const value = decode(at, to);\n        at += _offset;\n        map[key] = value;\n    }\n    throw new Error(\"expected break marker.\");\n}\nfunction decodeSpecial(at, to) {\n    const minor = payload[at] & 0b0001_1111;\n    switch (minor) {\n        case specialTrue:\n        case specialFalse:\n            _offset = 1;\n            return minor === specialTrue;\n        case specialNull:\n            _offset = 1;\n            return null;\n        case specialUndefined:\n            _offset = 1;\n            return null;\n        case extendedFloat16:\n            if (to - at < 3) {\n                throw new Error(\"incomplete float16 at end of buf.\");\n            }\n            _offset = 3;\n            return bytesToFloat16(payload[at + 1], payload[at + 2]);\n        case extendedFloat32:\n            if (to - at < 5) {\n                throw new Error(\"incomplete float32 at end of buf.\");\n            }\n            _offset = 5;\n            return dataView$1.getFloat32(at + 1);\n        case extendedFloat64:\n            if (to - at < 9) {\n                throw new Error(\"incomplete float64 at end of buf.\");\n            }\n            _offset = 9;\n            return dataView$1.getFloat64(at + 1);\n        default:\n            throw new Error(`unexpected minor value ${minor}.`);\n    }\n}\nfunction castBigInt(bigInt) {\n    if (typeof bigInt === \"number\") {\n        return bigInt;\n    }\n    const num = Number(bigInt);\n    if (Number.MIN_SAFE_INTEGER <= num && num <= Number.MAX_SAFE_INTEGER) {\n        return num;\n    }\n    return bigInt;\n}\n\nconst USE_BUFFER = typeof Buffer !== \"undefined\";\nconst initialSize = 2048;\nlet data = alloc(initialSize);\nlet dataView = new DataView(data.buffer, data.byteOffset, data.byteLength);\nlet cursor = 0;\nfunction ensureSpace(bytes) {\n    const remaining = data.byteLength - cursor;\n    if (remaining < bytes) {\n        if (cursor < 16_000_000) {\n            resize(Math.max(data.byteLength * 4, data.byteLength + bytes));\n        }\n        else {\n            resize(data.byteLength + bytes + 16_000_000);\n        }\n    }\n}\nfunction toUint8Array() {\n    const out = alloc(cursor);\n    out.set(data.subarray(0, cursor), 0);\n    cursor = 0;\n    return out;\n}\nfunction resize(size) {\n    const old = data;\n    data = alloc(size);\n    if (old) {\n        if (old.copy) {\n            old.copy(data, 0, 0, old.byteLength);\n        }\n        else {\n            data.set(old, 0);\n        }\n    }\n    dataView = new DataView(data.buffer, data.byteOffset, data.byteLength);\n}\nfunction encodeHeader(major, value) {\n    if (value < 24) {\n        data[cursor++] = (major << 5) | value;\n    }\n    else if (value < 1 << 8) {\n        data[cursor++] = (major << 5) | 24;\n        data[cursor++] = value;\n    }\n    else if (value < 1 << 16) {\n        data[cursor++] = (major << 5) | extendedFloat16;\n        dataView.setUint16(cursor, value);\n        cursor += 2;\n    }\n    else if (value < 2 ** 32) {\n        data[cursor++] = (major << 5) | extendedFloat32;\n        dataView.setUint32(cursor, value);\n        cursor += 4;\n    }\n    else {\n        data[cursor++] = (major << 5) | extendedFloat64;\n        dataView.setBigUint64(cursor, typeof value === \"bigint\" ? value : BigInt(value));\n        cursor += 8;\n    }\n}\nfunction encode(_input) {\n    const encodeStack = [_input];\n    while (encodeStack.length) {\n        const input = encodeStack.pop();\n        ensureSpace(typeof input === \"string\" ? input.length * 4 : 64);\n        if (typeof input === \"string\") {\n            if (USE_BUFFER) {\n                encodeHeader(majorUtf8String, Buffer.byteLength(input));\n                cursor += data.write(input, cursor);\n            }\n            else {\n                const bytes = utilUtf8.fromUtf8(input);\n                encodeHeader(majorUtf8String, bytes.byteLength);\n                data.set(bytes, cursor);\n                cursor += bytes.byteLength;\n            }\n            continue;\n        }\n        else if (typeof input === \"number\") {\n            if (Number.isInteger(input)) {\n                const nonNegative = input >= 0;\n                const major = nonNegative ? majorUint64 : majorNegativeInt64;\n                const value = nonNegative ? input : -input - 1;\n                if (value < 24) {\n                    data[cursor++] = (major << 5) | value;\n                }\n                else if (value < 256) {\n                    data[cursor++] = (major << 5) | 24;\n                    data[cursor++] = value;\n                }\n                else if (value < 65536) {\n                    data[cursor++] = (major << 5) | extendedFloat16;\n                    data[cursor++] = value >> 8;\n                    data[cursor++] = value;\n                }\n                else if (value < 4294967296) {\n                    data[cursor++] = (major << 5) | extendedFloat32;\n                    dataView.setUint32(cursor, value);\n                    cursor += 4;\n                }\n                else {\n                    data[cursor++] = (major << 5) | extendedFloat64;\n                    dataView.setBigUint64(cursor, BigInt(value));\n                    cursor += 8;\n                }\n                continue;\n            }\n            data[cursor++] = (majorSpecial << 5) | extendedFloat64;\n            dataView.setFloat64(cursor, input);\n            cursor += 8;\n            continue;\n        }\n        else if (typeof input === \"bigint\") {\n            const nonNegative = input >= 0;\n            const major = nonNegative ? majorUint64 : majorNegativeInt64;\n            const value = nonNegative ? input : -input - BigInt(1);\n            const n = Number(value);\n            if (n < 24) {\n                data[cursor++] = (major << 5) | n;\n            }\n            else if (n < 256) {\n                data[cursor++] = (major << 5) | 24;\n                data[cursor++] = n;\n            }\n            else if (n < 65536) {\n                data[cursor++] = (major << 5) | extendedFloat16;\n                data[cursor++] = n >> 8;\n                data[cursor++] = n & 0b1111_1111;\n            }\n            else if (n < 4294967296) {\n                data[cursor++] = (major << 5) | extendedFloat32;\n                dataView.setUint32(cursor, n);\n                cursor += 4;\n            }\n            else if (value < BigInt(\"18446744073709551616\")) {\n                data[cursor++] = (major << 5) | extendedFloat64;\n                dataView.setBigUint64(cursor, value);\n                cursor += 8;\n            }\n            else {\n                const binaryBigInt = value.toString(2);\n                const bigIntBytes = new Uint8Array(Math.ceil(binaryBigInt.length / 8));\n                let b = value;\n                let i = 0;\n                while (bigIntBytes.byteLength - ++i >= 0) {\n                    bigIntBytes[bigIntBytes.byteLength - i] = Number(b & BigInt(255));\n                    b >>= BigInt(8);\n                }\n                ensureSpace(bigIntBytes.byteLength * 2);\n                data[cursor++] = nonNegative ? 0b110_00010 : 0b110_00011;\n                if (USE_BUFFER) {\n                    encodeHeader(majorUnstructuredByteString, Buffer.byteLength(bigIntBytes));\n                }\n                else {\n                    encodeHeader(majorUnstructuredByteString, bigIntBytes.byteLength);\n                }\n                data.set(bigIntBytes, cursor);\n                cursor += bigIntBytes.byteLength;\n            }\n            continue;\n        }\n        else if (input === null) {\n            data[cursor++] = (majorSpecial << 5) | specialNull;\n            continue;\n        }\n        else if (typeof input === \"boolean\") {\n            data[cursor++] = (majorSpecial << 5) | (input ? specialTrue : specialFalse);\n            continue;\n        }\n        else if (typeof input === \"undefined\") {\n            throw new Error(\"@smithy/core/cbor: client may not serialize undefined value.\");\n        }\n        else if (Array.isArray(input)) {\n            for (let i = input.length - 1; i >= 0; --i) {\n                encodeStack.push(input[i]);\n            }\n            encodeHeader(majorList, input.length);\n            continue;\n        }\n        else if (typeof input.byteLength === \"number\") {\n            ensureSpace(input.length * 2);\n            encodeHeader(majorUnstructuredByteString, input.length);\n            data.set(input, cursor);\n            cursor += input.byteLength;\n            continue;\n        }\n        else if (typeof input === \"object\") {\n            if (input instanceof serde.NumericValue) {\n                const decimalIndex = input.string.indexOf(\".\");\n                const exponent = decimalIndex === -1 ? 0 : decimalIndex - input.string.length + 1;\n                const mantissa = BigInt(input.string.replace(\".\", \"\"));\n                data[cursor++] = 0b110_00100;\n                encodeStack.push(mantissa);\n                encodeStack.push(exponent);\n                encodeHeader(majorList, 2);\n                continue;\n            }\n            if (input[tagSymbol]) {\n                if (\"tag\" in input && \"value\" in input) {\n                    encodeStack.push(input.value);\n                    encodeHeader(majorTag, input.tag);\n                    continue;\n                }\n                else {\n                    throw new Error(\"tag encountered with missing fields, need 'tag' and 'value', found: \" + JSON.stringify(input));\n                }\n            }\n            const keys = Object.keys(input);\n            for (let i = keys.length - 1; i >= 0; --i) {\n                const key = keys[i];\n                encodeStack.push(input[key]);\n                encodeStack.push(key);\n            }\n            encodeHeader(majorMap, keys.length);\n            continue;\n        }\n        throw new Error(`data type ${input?.constructor?.name ?? typeof input} not compatible for encoding.`);\n    }\n}\n\nconst cbor = {\n    deserialize(payload) {\n        setPayload(payload);\n        return decode(0, payload.length);\n    },\n    serialize(input) {\n        try {\n            encode(input);\n            return toUint8Array();\n        }\n        catch (e) {\n            toUint8Array();\n            throw e;\n        }\n    },\n    resizeEncodingBuffer(size) {\n        resize(size);\n    },\n};\n\nconst parseCborBody = (streamBody, context) => {\n    return protocols.collectBody(streamBody, context).then(async (bytes) => {\n        if (bytes.length) {\n            try {\n                return cbor.deserialize(bytes);\n            }\n            catch (e) {\n                Object.defineProperty(e, \"$responseBodyText\", {\n                    value: context.utf8Encoder(bytes),\n                });\n                throw e;\n            }\n        }\n        return {};\n    });\n};\nconst dateToTag = (date) => {\n    return tag({\n        tag: 1,\n        value: date.getTime() / 1000,\n    });\n};\nconst parseCborErrorBody = async (errorBody, context) => {\n    const value = await parseCborBody(errorBody, context);\n    value.message = value.message ?? value.Message;\n    return value;\n};\nconst loadSmithyRpcV2CborErrorCode = (output, data) => {\n    const sanitizeErrorCode = (rawValue) => {\n        let cleanValue = rawValue;\n        if (typeof cleanValue === \"number\") {\n            cleanValue = cleanValue.toString();\n        }\n        if (cleanValue.indexOf(\",\") >= 0) {\n            cleanValue = cleanValue.split(\",\")[0];\n        }\n        if (cleanValue.indexOf(\":\") >= 0) {\n            cleanValue = cleanValue.split(\":\")[0];\n        }\n        if (cleanValue.indexOf(\"#\") >= 0) {\n            cleanValue = cleanValue.split(\"#\")[1];\n        }\n        return cleanValue;\n    };\n    if (data[\"__type\"] !== undefined) {\n        return sanitizeErrorCode(data[\"__type\"]);\n    }\n    const codeKey = Object.keys(data).find((key) => key.toLowerCase() === \"code\");\n    if (codeKey && data[codeKey] !== undefined) {\n        return sanitizeErrorCode(data[codeKey]);\n    }\n};\nconst checkCborResponse = (response) => {\n    if (String(response.headers[\"smithy-protocol\"]).toLowerCase() !== \"rpc-v2-cbor\") {\n        throw new Error(\"Malformed RPCv2 CBOR response, status: \" + response.statusCode);\n    }\n};\nconst buildHttpRpcRequest = async (context, headers, path, resolvedHostname, body) => {\n    const { hostname, protocol = \"https\", port, path: basePath } = await context.endpoint();\n    const contents = {\n        protocol,\n        hostname,\n        port,\n        method: \"POST\",\n        path: basePath.endsWith(\"/\") ? basePath.slice(0, -1) + path : basePath + path,\n        headers: {\n            ...headers,\n        },\n    };\n    if (resolvedHostname !== undefined) {\n        contents.hostname = resolvedHostname;\n    }\n    if (body !== undefined) {\n        contents.body = body;\n        try {\n            contents.headers[\"content-length\"] = String(utilBodyLengthBrowser.calculateBodyLength(body));\n        }\n        catch (e) { }\n    }\n    return new protocolHttp.HttpRequest(contents);\n};\n\nclass CborCodec extends protocols.SerdeContext {\n    createSerializer() {\n        const serializer = new CborShapeSerializer();\n        serializer.setSerdeContext(this.serdeContext);\n        return serializer;\n    }\n    createDeserializer() {\n        const deserializer = new CborShapeDeserializer();\n        deserializer.setSerdeContext(this.serdeContext);\n        return deserializer;\n    }\n}\nclass CborShapeSerializer extends protocols.SerdeContext {\n    value;\n    write(schema, value) {\n        this.value = this.serialize(schema, value);\n    }\n    serialize(schema$1, source) {\n        const ns = schema.NormalizedSchema.of(schema$1);\n        if (source == null) {\n            if (ns.isIdempotencyToken()) {\n                return serde.generateIdempotencyToken();\n            }\n            return source;\n        }\n        if (ns.isBlobSchema()) {\n            if (typeof source === \"string\") {\n                return (this.serdeContext?.base64Decoder ?? utilBase64.fromBase64)(source);\n            }\n            return source;\n        }\n        if (ns.isTimestampSchema()) {\n            if (typeof source === \"number\" || typeof source === \"bigint\") {\n                return dateToTag(new Date((Number(source) / 1000) | 0));\n            }\n            return dateToTag(source);\n        }\n        if (typeof source === \"function\" || typeof source === \"object\") {\n            const sourceObject = source;\n            if (ns.isListSchema() && Array.isArray(sourceObject)) {\n                const sparse = !!ns.getMergedTraits().sparse;\n                const newArray = [];\n                let i = 0;\n                for (const item of sourceObject) {\n                    const value = this.serialize(ns.getValueSchema(), item);\n                    if (value != null || sparse) {\n                        newArray[i++] = value;\n                    }\n                }\n                return newArray;\n            }\n            if (sourceObject instanceof Date) {\n                return dateToTag(sourceObject);\n            }\n            const newObject = {};\n            if (ns.isMapSchema()) {\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const key of Object.keys(sourceObject)) {\n                    const value = this.serialize(ns.getValueSchema(), sourceObject[key]);\n                    if (value != null || sparse) {\n                        newObject[key] = value;\n                    }\n                }\n            }\n            else if (ns.isStructSchema()) {\n                for (const [key, memberSchema] of ns.structIterator()) {\n                    const value = this.serialize(memberSchema, sourceObject[key]);\n                    if (value != null) {\n                        newObject[key] = value;\n                    }\n                }\n                const isUnion = ns.isUnionSchema();\n                if (isUnion && Array.isArray(sourceObject.$unknown)) {\n                    const [k, v] = sourceObject.$unknown;\n                    newObject[k] = v;\n                }\n                else if (typeof sourceObject.__type === \"string\") {\n                    for (const [k, v] of Object.entries(sourceObject)) {\n                        if (!(k in newObject)) {\n                            newObject[k] = this.serialize(15, v);\n                        }\n                    }\n                }\n            }\n            else if (ns.isDocumentSchema()) {\n                for (const key of Object.keys(sourceObject)) {\n                    newObject[key] = this.serialize(ns.getValueSchema(), sourceObject[key]);\n                }\n            }\n            else if (ns.isBigDecimalSchema()) {\n                return sourceObject;\n            }\n            return newObject;\n        }\n        return source;\n    }\n    flush() {\n        const buffer = cbor.serialize(this.value);\n        this.value = undefined;\n        return buffer;\n    }\n}\nclass CborShapeDeserializer extends protocols.SerdeContext {\n    read(schema, bytes) {\n        const data = cbor.deserialize(bytes);\n        return this.readValue(schema, data);\n    }\n    readValue(_schema, value) {\n        const ns = schema.NormalizedSchema.of(_schema);\n        if (ns.isTimestampSchema()) {\n            if (typeof value === \"number\") {\n                return serde._parseEpochTimestamp(value);\n            }\n            if (typeof value === \"object\") {\n                if (value.tag === 1 && \"value\" in value) {\n                    return serde._parseEpochTimestamp(value.value);\n                }\n            }\n        }\n        if (ns.isBlobSchema()) {\n            if (typeof value === \"string\") {\n                return (this.serdeContext?.base64Decoder ?? utilBase64.fromBase64)(value);\n            }\n            return value;\n        }\n        if (typeof value === \"undefined\" ||\n            typeof value === \"boolean\" ||\n            typeof value === \"number\" ||\n            typeof value === \"string\" ||\n            typeof value === \"bigint\" ||\n            typeof value === \"symbol\") {\n            return value;\n        }\n        else if (typeof value === \"object\") {\n            if (value === null) {\n                return null;\n            }\n            if (\"byteLength\" in value) {\n                return value;\n            }\n            if (value instanceof Date) {\n                return value;\n            }\n            if (ns.isDocumentSchema()) {\n                return value;\n            }\n            if (ns.isListSchema()) {\n                const newArray = [];\n                const memberSchema = ns.getValueSchema();\n                const sparse = !!ns.getMergedTraits().sparse;\n                for (const item of value) {\n                    const itemValue = this.readValue(memberSchema, item);\n                    if (itemValue != null || sparse) {\n                        newArray.push(itemValue);\n                    }\n                }\n                return newArray;\n            }\n            const newObject = {};\n            if (ns.isMapSchema()) {\n                const sparse = !!ns.getMergedTraits().sparse;\n                const targetSchema = ns.getValueSchema();\n                for (const key of Object.keys(value)) {\n                    const itemValue = this.readValue(targetSchema, value[key]);\n                    if (itemValue != null || sparse) {\n                        newObject[key] = itemValue;\n                    }\n                }\n            }\n            else if (ns.isStructSchema()) {\n                const isUnion = ns.isUnionSchema();\n                let keys;\n                if (isUnion) {\n                    keys = new Set(Object.keys(value).filter((k) => k !== \"__type\"));\n                }\n                for (const [key, memberSchema] of ns.structIterator()) {\n                    if (isUnion) {\n                        keys.delete(key);\n                    }\n                    if (value[key] != null) {\n                        newObject[key] = this.readValue(memberSchema, value[key]);\n                    }\n                }\n                if (isUnion && keys?.size === 1 && Object.keys(newObject).length === 0) {\n                    const k = keys.values().next().value;\n                    newObject.$unknown = [k, value[k]];\n                }\n                else if (typeof value.__type === \"string\") {\n                    for (const [k, v] of Object.entries(value)) {\n                        if (!(k in newObject)) {\n                            newObject[k] = v;\n                        }\n                    }\n                }\n            }\n            else if (value instanceof serde.NumericValue) {\n                return value;\n            }\n            return newObject;\n        }\n        else {\n            return value;\n        }\n    }\n}\n\nclass SmithyRpcV2CborProtocol extends protocols.RpcProtocol {\n    codec = new CborCodec();\n    serializer = this.codec.createSerializer();\n    deserializer = this.codec.createDeserializer();\n    constructor({ defaultNamespace }) {\n        super({ defaultNamespace });\n    }\n    getShapeId() {\n        return \"smithy.protocols#rpcv2Cbor\";\n    }\n    getPayloadCodec() {\n        return this.codec;\n    }\n    async serializeRequest(operationSchema, input, context) {\n        const request = await super.serializeRequest(operationSchema, input, context);\n        Object.assign(request.headers, {\n            \"content-type\": this.getDefaultContentType(),\n            \"smithy-protocol\": \"rpc-v2-cbor\",\n            accept: this.getDefaultContentType(),\n        });\n        if (schema.deref(operationSchema.input) === \"unit\") {\n            delete request.body;\n            delete request.headers[\"content-type\"];\n        }\n        else {\n            if (!request.body) {\n                this.serializer.write(15, {});\n                request.body = this.serializer.flush();\n            }\n            try {\n                request.headers[\"content-length\"] = String(request.body.byteLength);\n            }\n            catch (e) { }\n        }\n        const { service, operation } = utilMiddleware.getSmithyContext(context);\n        const path = `/service/${service}/operation/${operation}`;\n        if (request.path.endsWith(\"/\")) {\n            request.path += path.slice(1);\n        }\n        else {\n            request.path += path;\n        }\n        return request;\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        return super.deserializeResponse(operationSchema, context, response);\n    }\n    async handleError(operationSchema, context, response, dataObject, metadata) {\n        const errorName = loadSmithyRpcV2CborErrorCode(response, dataObject) ?? \"Unknown\";\n        let namespace = this.options.defaultNamespace;\n        if (errorName.includes(\"#\")) {\n            [namespace] = errorName.split(\"#\");\n        }\n        const errorMetadata = {\n            $metadata: metadata,\n            $fault: response.statusCode <= 500 ? \"client\" : \"server\",\n        };\n        const registry = schema.TypeRegistry.for(namespace);\n        let errorSchema;\n        try {\n            errorSchema = registry.getSchema(errorName);\n        }\n        catch (e) {\n            if (dataObject.Message) {\n                dataObject.message = dataObject.Message;\n            }\n            const synthetic = schema.TypeRegistry.for(\"smithy.ts.sdk.synthetic.\" + namespace);\n            const baseExceptionSchema = synthetic.getBaseException();\n            if (baseExceptionSchema) {\n                const ErrorCtor = synthetic.getErrorCtor(baseExceptionSchema);\n                throw Object.assign(new ErrorCtor({ name: errorName }), errorMetadata, dataObject);\n            }\n            throw Object.assign(new Error(errorName), errorMetadata, dataObject);\n        }\n        const ns = schema.NormalizedSchema.of(errorSchema);\n        const ErrorCtor = registry.getErrorCtor(errorSchema);\n        const message = dataObject.message ?? dataObject.Message ?? \"Unknown\";\n        const exception = new ErrorCtor(message);\n        const output = {};\n        for (const [name, member] of ns.structIterator()) {\n            output[name] = this.deserializer.readValue(member, dataObject[name]);\n        }\n        throw Object.assign(exception, errorMetadata, {\n            $fault: ns.getMergedTraits().error,\n            message,\n        }, output);\n    }\n    getDefaultContentType() {\n        return \"application/cbor\";\n    }\n}\n\nexports.CborCodec = CborCodec;\nexports.CborShapeDeserializer = CborShapeDeserializer;\nexports.CborShapeSerializer = CborShapeSerializer;\nexports.SmithyRpcV2CborProtocol = SmithyRpcV2CborProtocol;\nexports.buildHttpRpcRequest = buildHttpRpcRequest;\nexports.cbor = cbor;\nexports.checkCborResponse = checkCborResponse;\nexports.dateToTag = dateToTag;\nexports.loadSmithyRpcV2CborErrorCode = loadSmithyRpcV2CborErrorCode;\nexports.parseCborBody = parseCborBody;\nexports.parseCborErrorBody = parseCborErrorBody;\nexports.tag = tag;\nexports.tagSymbol = tagSymbol;\n","'use strict';\n\nvar utilStream = require('@smithy/util-stream');\nvar schema = require('@smithy/core/schema');\nvar serde = require('@smithy/core/serde');\nvar protocolHttp = require('@smithy/protocol-http');\nvar utilBase64 = require('@smithy/util-base64');\nvar utilUtf8 = require('@smithy/util-utf8');\n\nconst collectBody = async (streamBody = new Uint8Array(), context) => {\n    if (streamBody instanceof Uint8Array) {\n        return utilStream.Uint8ArrayBlobAdapter.mutate(streamBody);\n    }\n    if (!streamBody) {\n        return utilStream.Uint8ArrayBlobAdapter.mutate(new Uint8Array());\n    }\n    const fromContext = context.streamCollector(streamBody);\n    return utilStream.Uint8ArrayBlobAdapter.mutate(await fromContext);\n};\n\nfunction extendedEncodeURIComponent(str) {\n    return encodeURIComponent(str).replace(/[!'()*]/g, function (c) {\n        return \"%\" + c.charCodeAt(0).toString(16).toUpperCase();\n    });\n}\n\nclass SerdeContext {\n    serdeContext;\n    setSerdeContext(serdeContext) {\n        this.serdeContext = serdeContext;\n    }\n}\n\nclass HttpProtocol extends SerdeContext {\n    options;\n    constructor(options) {\n        super();\n        this.options = options;\n    }\n    getRequestType() {\n        return protocolHttp.HttpRequest;\n    }\n    getResponseType() {\n        return protocolHttp.HttpResponse;\n    }\n    setSerdeContext(serdeContext) {\n        this.serdeContext = serdeContext;\n        this.serializer.setSerdeContext(serdeContext);\n        this.deserializer.setSerdeContext(serdeContext);\n        if (this.getPayloadCodec()) {\n            this.getPayloadCodec().setSerdeContext(serdeContext);\n        }\n    }\n    updateServiceEndpoint(request, endpoint) {\n        if (\"url\" in endpoint) {\n            request.protocol = endpoint.url.protocol;\n            request.hostname = endpoint.url.hostname;\n            request.port = endpoint.url.port ? Number(endpoint.url.port) : undefined;\n            request.path = endpoint.url.pathname;\n            request.fragment = endpoint.url.hash || void 0;\n            request.username = endpoint.url.username || void 0;\n            request.password = endpoint.url.password || void 0;\n            if (!request.query) {\n                request.query = {};\n            }\n            for (const [k, v] of endpoint.url.searchParams.entries()) {\n                request.query[k] = v;\n            }\n            return request;\n        }\n        else {\n            request.protocol = endpoint.protocol;\n            request.hostname = endpoint.hostname;\n            request.port = endpoint.port ? Number(endpoint.port) : undefined;\n            request.path = endpoint.path;\n            request.query = {\n                ...endpoint.query,\n            };\n            return request;\n        }\n    }\n    setHostPrefix(request, operationSchema, input) {\n        if (this.serdeContext?.disableHostPrefix) {\n            return;\n        }\n        const inputNs = schema.NormalizedSchema.of(operationSchema.input);\n        const opTraits = schema.translateTraits(operationSchema.traits ?? {});\n        if (opTraits.endpoint) {\n            let hostPrefix = opTraits.endpoint?.[0];\n            if (typeof hostPrefix === \"string\") {\n                const hostLabelInputs = [...inputNs.structIterator()].filter(([, member]) => member.getMergedTraits().hostLabel);\n                for (const [name] of hostLabelInputs) {\n                    const replacement = input[name];\n                    if (typeof replacement !== \"string\") {\n                        throw new Error(`@smithy/core/schema - ${name} in input must be a string as hostLabel.`);\n                    }\n                    hostPrefix = hostPrefix.replace(`{${name}}`, replacement);\n                }\n                request.hostname = hostPrefix + request.hostname;\n            }\n        }\n    }\n    deserializeMetadata(output) {\n        return {\n            httpStatusCode: output.statusCode,\n            requestId: output.headers[\"x-amzn-requestid\"] ?? output.headers[\"x-amzn-request-id\"] ?? output.headers[\"x-amz-request-id\"],\n            extendedRequestId: output.headers[\"x-amz-id-2\"],\n            cfId: output.headers[\"x-amz-cf-id\"],\n        };\n    }\n    async serializeEventStream({ eventStream, requestSchema, initialRequest, }) {\n        const eventStreamSerde = await this.loadEventStreamCapability();\n        return eventStreamSerde.serializeEventStream({\n            eventStream,\n            requestSchema,\n            initialRequest,\n        });\n    }\n    async deserializeEventStream({ response, responseSchema, initialResponseContainer, }) {\n        const eventStreamSerde = await this.loadEventStreamCapability();\n        return eventStreamSerde.deserializeEventStream({\n            response,\n            responseSchema,\n            initialResponseContainer,\n        });\n    }\n    async loadEventStreamCapability() {\n        const { EventStreamSerde } = await import('@smithy/core/event-streams');\n        return new EventStreamSerde({\n            marshaller: this.getEventStreamMarshaller(),\n            serializer: this.serializer,\n            deserializer: this.deserializer,\n            serdeContext: this.serdeContext,\n            defaultContentType: this.getDefaultContentType(),\n        });\n    }\n    getDefaultContentType() {\n        throw new Error(`@smithy/core/protocols - ${this.constructor.name} getDefaultContentType() implementation missing.`);\n    }\n    async deserializeHttpMessage(schema, context, response, arg4, arg5) {\n        return [];\n    }\n    getEventStreamMarshaller() {\n        const context = this.serdeContext;\n        if (!context.eventStreamMarshaller) {\n            throw new Error(\"@smithy/core - HttpProtocol: eventStreamMarshaller missing in serdeContext.\");\n        }\n        return context.eventStreamMarshaller;\n    }\n}\n\nclass HttpBindingProtocol extends HttpProtocol {\n    async serializeRequest(operationSchema, _input, context) {\n        const input = {\n            ...(_input ?? {}),\n        };\n        const serializer = this.serializer;\n        const query = {};\n        const headers = {};\n        const endpoint = await context.endpoint();\n        const ns = schema.NormalizedSchema.of(operationSchema?.input);\n        const schema$1 = ns.getSchema();\n        let hasNonHttpBindingMember = false;\n        let payload;\n        const request = new protocolHttp.HttpRequest({\n            protocol: \"\",\n            hostname: \"\",\n            port: undefined,\n            path: \"\",\n            fragment: undefined,\n            query: query,\n            headers: headers,\n            body: undefined,\n        });\n        if (endpoint) {\n            this.updateServiceEndpoint(request, endpoint);\n            this.setHostPrefix(request, operationSchema, input);\n            const opTraits = schema.translateTraits(operationSchema.traits);\n            if (opTraits.http) {\n                request.method = opTraits.http[0];\n                const [path, search] = opTraits.http[1].split(\"?\");\n                if (request.path == \"/\") {\n                    request.path = path;\n                }\n                else {\n                    request.path += path;\n                }\n                const traitSearchParams = new URLSearchParams(search ?? \"\");\n                Object.assign(query, Object.fromEntries(traitSearchParams));\n            }\n        }\n        for (const [memberName, memberNs] of ns.structIterator()) {\n            const memberTraits = memberNs.getMergedTraits() ?? {};\n            const inputMemberValue = input[memberName];\n            if (inputMemberValue == null && !memberNs.isIdempotencyToken()) {\n                if (memberTraits.httpLabel) {\n                    if (request.path.includes(`{${memberName}+}`) || request.path.includes(`{${memberName}}`)) {\n                        throw new Error(`No value provided for input HTTP label: ${memberName}.`);\n                    }\n                }\n                continue;\n            }\n            if (memberTraits.httpPayload) {\n                const isStreaming = memberNs.isStreaming();\n                if (isStreaming) {\n                    const isEventStream = memberNs.isStructSchema();\n                    if (isEventStream) {\n                        if (input[memberName]) {\n                            payload = await this.serializeEventStream({\n                                eventStream: input[memberName],\n                                requestSchema: ns,\n                            });\n                        }\n                    }\n                    else {\n                        payload = inputMemberValue;\n                    }\n                }\n                else {\n                    serializer.write(memberNs, inputMemberValue);\n                    payload = serializer.flush();\n                }\n                delete input[memberName];\n            }\n            else if (memberTraits.httpLabel) {\n                serializer.write(memberNs, inputMemberValue);\n                const replacement = serializer.flush();\n                if (request.path.includes(`{${memberName}+}`)) {\n                    request.path = request.path.replace(`{${memberName}+}`, replacement.split(\"/\").map(extendedEncodeURIComponent).join(\"/\"));\n                }\n                else if (request.path.includes(`{${memberName}}`)) {\n                    request.path = request.path.replace(`{${memberName}}`, extendedEncodeURIComponent(replacement));\n                }\n                delete input[memberName];\n            }\n            else if (memberTraits.httpHeader) {\n                serializer.write(memberNs, inputMemberValue);\n                headers[memberTraits.httpHeader.toLowerCase()] = String(serializer.flush());\n                delete input[memberName];\n            }\n            else if (typeof memberTraits.httpPrefixHeaders === \"string\") {\n                for (const [key, val] of Object.entries(inputMemberValue)) {\n                    const amalgam = memberTraits.httpPrefixHeaders + key;\n                    serializer.write([memberNs.getValueSchema(), { httpHeader: amalgam }], val);\n                    headers[amalgam.toLowerCase()] = serializer.flush();\n                }\n                delete input[memberName];\n            }\n            else if (memberTraits.httpQuery || memberTraits.httpQueryParams) {\n                this.serializeQuery(memberNs, inputMemberValue, query);\n                delete input[memberName];\n            }\n            else {\n                hasNonHttpBindingMember = true;\n            }\n        }\n        if (hasNonHttpBindingMember && input) {\n            serializer.write(schema$1, input);\n            payload = serializer.flush();\n        }\n        request.headers = headers;\n        request.query = query;\n        request.body = payload;\n        return request;\n    }\n    serializeQuery(ns, data, query) {\n        const serializer = this.serializer;\n        const traits = ns.getMergedTraits();\n        if (traits.httpQueryParams) {\n            for (const [key, val] of Object.entries(data)) {\n                if (!(key in query)) {\n                    const valueSchema = ns.getValueSchema();\n                    Object.assign(valueSchema.getMergedTraits(), {\n                        ...traits,\n                        httpQuery: key,\n                        httpQueryParams: undefined,\n                    });\n                    this.serializeQuery(valueSchema, val, query);\n                }\n            }\n            return;\n        }\n        if (ns.isListSchema()) {\n            const sparse = !!ns.getMergedTraits().sparse;\n            const buffer = [];\n            for (const item of data) {\n                serializer.write([ns.getValueSchema(), traits], item);\n                const serializable = serializer.flush();\n                if (sparse || serializable !== undefined) {\n                    buffer.push(serializable);\n                }\n            }\n            query[traits.httpQuery] = buffer;\n        }\n        else {\n            serializer.write([ns, traits], data);\n            query[traits.httpQuery] = serializer.flush();\n        }\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        const deserializer = this.deserializer;\n        const ns = schema.NormalizedSchema.of(operationSchema.output);\n        const dataObject = {};\n        if (response.statusCode >= 300) {\n            const bytes = await collectBody(response.body, context);\n            if (bytes.byteLength > 0) {\n                Object.assign(dataObject, await deserializer.read(15, bytes));\n            }\n            await this.handleError(operationSchema, context, response, dataObject, this.deserializeMetadata(response));\n            throw new Error(\"@smithy/core/protocols - HTTP Protocol error handler failed to throw.\");\n        }\n        for (const header in response.headers) {\n            const value = response.headers[header];\n            delete response.headers[header];\n            response.headers[header.toLowerCase()] = value;\n        }\n        const nonHttpBindingMembers = await this.deserializeHttpMessage(ns, context, response, dataObject);\n        if (nonHttpBindingMembers.length) {\n            const bytes = await collectBody(response.body, context);\n            if (bytes.byteLength > 0) {\n                const dataFromBody = await deserializer.read(ns, bytes);\n                for (const member of nonHttpBindingMembers) {\n                    dataObject[member] = dataFromBody[member];\n                }\n            }\n        }\n        else if (nonHttpBindingMembers.discardResponseBody) {\n            await collectBody(response.body, context);\n        }\n        dataObject.$metadata = this.deserializeMetadata(response);\n        return dataObject;\n    }\n    async deserializeHttpMessage(schema$1, context, response, arg4, arg5) {\n        let dataObject;\n        if (arg4 instanceof Set) {\n            dataObject = arg5;\n        }\n        else {\n            dataObject = arg4;\n        }\n        let discardResponseBody = true;\n        const deserializer = this.deserializer;\n        const ns = schema.NormalizedSchema.of(schema$1);\n        const nonHttpBindingMembers = [];\n        for (const [memberName, memberSchema] of ns.structIterator()) {\n            const memberTraits = memberSchema.getMemberTraits();\n            if (memberTraits.httpPayload) {\n                discardResponseBody = false;\n                const isStreaming = memberSchema.isStreaming();\n                if (isStreaming) {\n                    const isEventStream = memberSchema.isStructSchema();\n                    if (isEventStream) {\n                        dataObject[memberName] = await this.deserializeEventStream({\n                            response,\n                            responseSchema: ns,\n                        });\n                    }\n                    else {\n                        dataObject[memberName] = utilStream.sdkStreamMixin(response.body);\n                    }\n                }\n                else if (response.body) {\n                    const bytes = await collectBody(response.body, context);\n                    if (bytes.byteLength > 0) {\n                        dataObject[memberName] = await deserializer.read(memberSchema, bytes);\n                    }\n                }\n            }\n            else if (memberTraits.httpHeader) {\n                const key = String(memberTraits.httpHeader).toLowerCase();\n                const value = response.headers[key];\n                if (null != value) {\n                    if (memberSchema.isListSchema()) {\n                        const headerListValueSchema = memberSchema.getValueSchema();\n                        headerListValueSchema.getMergedTraits().httpHeader = key;\n                        let sections;\n                        if (headerListValueSchema.isTimestampSchema() &&\n                            headerListValueSchema.getSchema() === 4) {\n                            sections = serde.splitEvery(value, \",\", 2);\n                        }\n                        else {\n                            sections = serde.splitHeader(value);\n                        }\n                        const list = [];\n                        for (const section of sections) {\n                            list.push(await deserializer.read(headerListValueSchema, section.trim()));\n                        }\n                        dataObject[memberName] = list;\n                    }\n                    else {\n                        dataObject[memberName] = await deserializer.read(memberSchema, value);\n                    }\n                }\n            }\n            else if (memberTraits.httpPrefixHeaders !== undefined) {\n                dataObject[memberName] = {};\n                for (const [header, value] of Object.entries(response.headers)) {\n                    if (header.startsWith(memberTraits.httpPrefixHeaders)) {\n                        const valueSchema = memberSchema.getValueSchema();\n                        valueSchema.getMergedTraits().httpHeader = header;\n                        dataObject[memberName][header.slice(memberTraits.httpPrefixHeaders.length)] = await deserializer.read(valueSchema, value);\n                    }\n                }\n            }\n            else if (memberTraits.httpResponseCode) {\n                dataObject[memberName] = response.statusCode;\n            }\n            else {\n                nonHttpBindingMembers.push(memberName);\n            }\n        }\n        nonHttpBindingMembers.discardResponseBody = discardResponseBody;\n        return nonHttpBindingMembers;\n    }\n}\n\nclass RpcProtocol extends HttpProtocol {\n    async serializeRequest(operationSchema, input, context) {\n        const serializer = this.serializer;\n        const query = {};\n        const headers = {};\n        const endpoint = await context.endpoint();\n        const ns = schema.NormalizedSchema.of(operationSchema?.input);\n        const schema$1 = ns.getSchema();\n        let payload;\n        const request = new protocolHttp.HttpRequest({\n            protocol: \"\",\n            hostname: \"\",\n            port: undefined,\n            path: \"/\",\n            fragment: undefined,\n            query: query,\n            headers: headers,\n            body: undefined,\n        });\n        if (endpoint) {\n            this.updateServiceEndpoint(request, endpoint);\n            this.setHostPrefix(request, operationSchema, input);\n        }\n        const _input = {\n            ...input,\n        };\n        if (input) {\n            const eventStreamMember = ns.getEventStreamMember();\n            if (eventStreamMember) {\n                if (_input[eventStreamMember]) {\n                    const initialRequest = {};\n                    for (const [memberName, memberSchema] of ns.structIterator()) {\n                        if (memberName !== eventStreamMember && _input[memberName]) {\n                            serializer.write(memberSchema, _input[memberName]);\n                            initialRequest[memberName] = serializer.flush();\n                        }\n                    }\n                    payload = await this.serializeEventStream({\n                        eventStream: _input[eventStreamMember],\n                        requestSchema: ns,\n                        initialRequest,\n                    });\n                }\n            }\n            else {\n                serializer.write(schema$1, _input);\n                payload = serializer.flush();\n            }\n        }\n        request.headers = headers;\n        request.query = query;\n        request.body = payload;\n        request.method = \"POST\";\n        return request;\n    }\n    async deserializeResponse(operationSchema, context, response) {\n        const deserializer = this.deserializer;\n        const ns = schema.NormalizedSchema.of(operationSchema.output);\n        const dataObject = {};\n        if (response.statusCode >= 300) {\n            const bytes = await collectBody(response.body, context);\n            if (bytes.byteLength > 0) {\n                Object.assign(dataObject, await deserializer.read(15, bytes));\n            }\n            await this.handleError(operationSchema, context, response, dataObject, this.deserializeMetadata(response));\n            throw new Error(\"@smithy/core/protocols - RPC Protocol error handler failed to throw.\");\n        }\n        for (const header in response.headers) {\n            const value = response.headers[header];\n            delete response.headers[header];\n            response.headers[header.toLowerCase()] = value;\n        }\n        const eventStreamMember = ns.getEventStreamMember();\n        if (eventStreamMember) {\n            dataObject[eventStreamMember] = await this.deserializeEventStream({\n                response,\n                responseSchema: ns,\n                initialResponseContainer: dataObject,\n            });\n        }\n        else {\n            const bytes = await collectBody(response.body, context);\n            if (bytes.byteLength > 0) {\n                Object.assign(dataObject, await deserializer.read(ns, bytes));\n            }\n        }\n        dataObject.$metadata = this.deserializeMetadata(response);\n        return dataObject;\n    }\n}\n\nconst resolvedPath = (resolvedPath, input, memberName, labelValueProvider, uriLabel, isGreedyLabel) => {\n    if (input != null && input[memberName] !== undefined) {\n        const labelValue = labelValueProvider();\n        if (labelValue.length <= 0) {\n            throw new Error(\"Empty value provided for input HTTP label: \" + memberName + \".\");\n        }\n        resolvedPath = resolvedPath.replace(uriLabel, isGreedyLabel\n            ? labelValue\n                .split(\"/\")\n                .map((segment) => extendedEncodeURIComponent(segment))\n                .join(\"/\")\n            : extendedEncodeURIComponent(labelValue));\n    }\n    else {\n        throw new Error(\"No value provided for input HTTP label: \" + memberName + \".\");\n    }\n    return resolvedPath;\n};\n\nfunction requestBuilder(input, context) {\n    return new RequestBuilder(input, context);\n}\nclass RequestBuilder {\n    input;\n    context;\n    query = {};\n    method = \"\";\n    headers = {};\n    path = \"\";\n    body = null;\n    hostname = \"\";\n    resolvePathStack = [];\n    constructor(input, context) {\n        this.input = input;\n        this.context = context;\n    }\n    async build() {\n        const { hostname, protocol = \"https\", port, path: basePath } = await this.context.endpoint();\n        this.path = basePath;\n        for (const resolvePath of this.resolvePathStack) {\n            resolvePath(this.path);\n        }\n        return new protocolHttp.HttpRequest({\n            protocol,\n            hostname: this.hostname || hostname,\n            port,\n            method: this.method,\n            path: this.path,\n            query: this.query,\n            body: this.body,\n            headers: this.headers,\n        });\n    }\n    hn(hostname) {\n        this.hostname = hostname;\n        return this;\n    }\n    bp(uriLabel) {\n        this.resolvePathStack.push((basePath) => {\n            this.path = `${basePath?.endsWith(\"/\") ? basePath.slice(0, -1) : basePath || \"\"}` + uriLabel;\n        });\n        return this;\n    }\n    p(memberName, labelValueProvider, uriLabel, isGreedyLabel) {\n        this.resolvePathStack.push((path) => {\n            this.path = resolvedPath(path, this.input, memberName, labelValueProvider, uriLabel, isGreedyLabel);\n        });\n        return this;\n    }\n    h(headers) {\n        this.headers = headers;\n        return this;\n    }\n    q(query) {\n        this.query = query;\n        return this;\n    }\n    b(body) {\n        this.body = body;\n        return this;\n    }\n    m(method) {\n        this.method = method;\n        return this;\n    }\n}\n\nfunction determineTimestampFormat(ns, settings) {\n    if (settings.timestampFormat.useTrait) {\n        if (ns.isTimestampSchema() &&\n            (ns.getSchema() === 5 ||\n                ns.getSchema() === 6 ||\n                ns.getSchema() === 7)) {\n            return ns.getSchema();\n        }\n    }\n    const { httpLabel, httpPrefixHeaders, httpHeader, httpQuery } = ns.getMergedTraits();\n    const bindingFormat = settings.httpBindings\n        ? typeof httpPrefixHeaders === \"string\" || Boolean(httpHeader)\n            ? 6\n            : Boolean(httpQuery) || Boolean(httpLabel)\n                ? 5\n                : undefined\n        : undefined;\n    return bindingFormat ?? settings.timestampFormat.default;\n}\n\nclass FromStringShapeDeserializer extends SerdeContext {\n    settings;\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    read(_schema, data) {\n        const ns = schema.NormalizedSchema.of(_schema);\n        if (ns.isListSchema()) {\n            return serde.splitHeader(data).map((item) => this.read(ns.getValueSchema(), item));\n        }\n        if (ns.isBlobSchema()) {\n            return (this.serdeContext?.base64Decoder ?? utilBase64.fromBase64)(data);\n        }\n        if (ns.isTimestampSchema()) {\n            const format = determineTimestampFormat(ns, this.settings);\n            switch (format) {\n                case 5:\n                    return serde._parseRfc3339DateTimeWithOffset(data);\n                case 6:\n                    return serde._parseRfc7231DateTime(data);\n                case 7:\n                    return serde._parseEpochTimestamp(data);\n                default:\n                    console.warn(\"Missing timestamp format, parsing value with Date constructor:\", data);\n                    return new Date(data);\n            }\n        }\n        if (ns.isStringSchema()) {\n            const mediaType = ns.getMergedTraits().mediaType;\n            let intermediateValue = data;\n            if (mediaType) {\n                if (ns.getMergedTraits().httpHeader) {\n                    intermediateValue = this.base64ToUtf8(intermediateValue);\n                }\n                const isJson = mediaType === \"application/json\" || mediaType.endsWith(\"+json\");\n                if (isJson) {\n                    intermediateValue = serde.LazyJsonString.from(intermediateValue);\n                }\n                return intermediateValue;\n            }\n        }\n        if (ns.isNumericSchema()) {\n            return Number(data);\n        }\n        if (ns.isBigIntegerSchema()) {\n            return BigInt(data);\n        }\n        if (ns.isBigDecimalSchema()) {\n            return new serde.NumericValue(data, \"bigDecimal\");\n        }\n        if (ns.isBooleanSchema()) {\n            return String(data).toLowerCase() === \"true\";\n        }\n        return data;\n    }\n    base64ToUtf8(base64String) {\n        return (this.serdeContext?.utf8Encoder ?? utilUtf8.toUtf8)((this.serdeContext?.base64Decoder ?? utilBase64.fromBase64)(base64String));\n    }\n}\n\nclass HttpInterceptingShapeDeserializer extends SerdeContext {\n    codecDeserializer;\n    stringDeserializer;\n    constructor(codecDeserializer, codecSettings) {\n        super();\n        this.codecDeserializer = codecDeserializer;\n        this.stringDeserializer = new FromStringShapeDeserializer(codecSettings);\n    }\n    setSerdeContext(serdeContext) {\n        this.stringDeserializer.setSerdeContext(serdeContext);\n        this.codecDeserializer.setSerdeContext(serdeContext);\n        this.serdeContext = serdeContext;\n    }\n    read(schema$1, data) {\n        const ns = schema.NormalizedSchema.of(schema$1);\n        const traits = ns.getMergedTraits();\n        const toString = this.serdeContext?.utf8Encoder ?? utilUtf8.toUtf8;\n        if (traits.httpHeader || traits.httpResponseCode) {\n            return this.stringDeserializer.read(ns, toString(data));\n        }\n        if (traits.httpPayload) {\n            if (ns.isBlobSchema()) {\n                const toBytes = this.serdeContext?.utf8Decoder ?? utilUtf8.fromUtf8;\n                if (typeof data === \"string\") {\n                    return toBytes(data);\n                }\n                return data;\n            }\n            else if (ns.isStringSchema()) {\n                if (\"byteLength\" in data) {\n                    return toString(data);\n                }\n                return data;\n            }\n        }\n        return this.codecDeserializer.read(ns, data);\n    }\n}\n\nclass ToStringShapeSerializer extends SerdeContext {\n    settings;\n    stringBuffer = \"\";\n    constructor(settings) {\n        super();\n        this.settings = settings;\n    }\n    write(schema$1, value) {\n        const ns = schema.NormalizedSchema.of(schema$1);\n        switch (typeof value) {\n            case \"object\":\n                if (value === null) {\n                    this.stringBuffer = \"null\";\n                    return;\n                }\n                if (ns.isTimestampSchema()) {\n                    if (!(value instanceof Date)) {\n                        throw new Error(`@smithy/core/protocols - received non-Date value ${value} when schema expected Date in ${ns.getName(true)}`);\n                    }\n                    const format = determineTimestampFormat(ns, this.settings);\n                    switch (format) {\n                        case 5:\n                            this.stringBuffer = value.toISOString().replace(\".000Z\", \"Z\");\n                            break;\n                        case 6:\n                            this.stringBuffer = serde.dateToUtcString(value);\n                            break;\n                        case 7:\n                            this.stringBuffer = String(value.getTime() / 1000);\n                            break;\n                        default:\n                            console.warn(\"Missing timestamp format, using epoch seconds\", value);\n                            this.stringBuffer = String(value.getTime() / 1000);\n                    }\n                    return;\n                }\n                if (ns.isBlobSchema() && \"byteLength\" in value) {\n                    this.stringBuffer = (this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(value);\n                    return;\n                }\n                if (ns.isListSchema() && Array.isArray(value)) {\n                    let buffer = \"\";\n                    for (const item of value) {\n                        this.write([ns.getValueSchema(), ns.getMergedTraits()], item);\n                        const headerItem = this.flush();\n                        const serialized = ns.getValueSchema().isTimestampSchema() ? headerItem : serde.quoteHeader(headerItem);\n                        if (buffer !== \"\") {\n                            buffer += \", \";\n                        }\n                        buffer += serialized;\n                    }\n                    this.stringBuffer = buffer;\n                    return;\n                }\n                this.stringBuffer = JSON.stringify(value, null, 2);\n                break;\n            case \"string\":\n                const mediaType = ns.getMergedTraits().mediaType;\n                let intermediateValue = value;\n                if (mediaType) {\n                    const isJson = mediaType === \"application/json\" || mediaType.endsWith(\"+json\");\n                    if (isJson) {\n                        intermediateValue = serde.LazyJsonString.from(intermediateValue);\n                    }\n                    if (ns.getMergedTraits().httpHeader) {\n                        this.stringBuffer = (this.serdeContext?.base64Encoder ?? utilBase64.toBase64)(intermediateValue.toString());\n                        return;\n                    }\n                }\n                this.stringBuffer = value;\n                break;\n            default:\n                if (ns.isIdempotencyToken()) {\n                    this.stringBuffer = serde.generateIdempotencyToken();\n                }\n                else {\n                    this.stringBuffer = String(value);\n                }\n        }\n    }\n    flush() {\n        const buffer = this.stringBuffer;\n        this.stringBuffer = \"\";\n        return buffer;\n    }\n}\n\nclass HttpInterceptingShapeSerializer {\n    codecSerializer;\n    stringSerializer;\n    buffer;\n    constructor(codecSerializer, codecSettings, stringSerializer = new ToStringShapeSerializer(codecSettings)) {\n        this.codecSerializer = codecSerializer;\n        this.stringSerializer = stringSerializer;\n    }\n    setSerdeContext(serdeContext) {\n        this.codecSerializer.setSerdeContext(serdeContext);\n        this.stringSerializer.setSerdeContext(serdeContext);\n    }\n    write(schema$1, value) {\n        const ns = schema.NormalizedSchema.of(schema$1);\n        const traits = ns.getMergedTraits();\n        if (traits.httpHeader || traits.httpLabel || traits.httpQuery) {\n            this.stringSerializer.write(ns, value);\n            this.buffer = this.stringSerializer.flush();\n            return;\n        }\n        return this.codecSerializer.write(ns, value);\n    }\n    flush() {\n        if (this.buffer !== undefined) {\n            const buffer = this.buffer;\n            this.buffer = undefined;\n            return buffer;\n        }\n        return this.codecSerializer.flush();\n    }\n}\n\nexports.FromStringShapeDeserializer = FromStringShapeDeserializer;\nexports.HttpBindingProtocol = HttpBindingProtocol;\nexports.HttpInterceptingShapeDeserializer = HttpInterceptingShapeDeserializer;\nexports.HttpInterceptingShapeSerializer = HttpInterceptingShapeSerializer;\nexports.HttpProtocol = HttpProtocol;\nexports.RequestBuilder = RequestBuilder;\nexports.RpcProtocol = RpcProtocol;\nexports.SerdeContext = SerdeContext;\nexports.ToStringShapeSerializer = ToStringShapeSerializer;\nexports.collectBody = collectBody;\nexports.determineTimestampFormat = determineTimestampFormat;\nexports.extendedEncodeURIComponent = extendedEncodeURIComponent;\nexports.requestBuilder = requestBuilder;\nexports.resolvedPath = resolvedPath;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\nvar utilMiddleware = require('@smithy/util-middleware');\n\nconst deref = (schemaRef) => {\n    if (typeof schemaRef === \"function\") {\n        return schemaRef();\n    }\n    return schemaRef;\n};\n\nconst operation = (namespace, name, traits, input, output) => ({\n    name,\n    namespace,\n    traits,\n    input,\n    output,\n});\n\nconst schemaDeserializationMiddleware = (config) => (next, context) => async (args) => {\n    const { response } = await next(args);\n    const { operationSchema } = utilMiddleware.getSmithyContext(context);\n    const [, ns, n, t, i, o] = operationSchema ?? [];\n    try {\n        const parsed = await config.protocol.deserializeResponse(operation(ns, n, t, i, o), {\n            ...config,\n            ...context,\n        }, response);\n        return {\n            response,\n            output: parsed,\n        };\n    }\n    catch (error) {\n        Object.defineProperty(error, \"$response\", {\n            value: response,\n            enumerable: false,\n            writable: false,\n            configurable: false,\n        });\n        if (!(\"$metadata\" in error)) {\n            const hint = `Deserialization error: to see the raw response, inspect the hidden field {error}.$response on this object.`;\n            try {\n                error.message += \"\\n  \" + hint;\n            }\n            catch (e) {\n                if (!context.logger || context.logger?.constructor?.name === \"NoOpLogger\") {\n                    console.warn(hint);\n                }\n                else {\n                    context.logger?.warn?.(hint);\n                }\n            }\n            if (typeof error.$responseBodyText !== \"undefined\") {\n                if (error.$response) {\n                    error.$response.body = error.$responseBodyText;\n                }\n            }\n            try {\n                if (protocolHttp.HttpResponse.isInstance(response)) {\n                    const { headers = {} } = response;\n                    const headerEntries = Object.entries(headers);\n                    error.$metadata = {\n                        httpStatusCode: response.statusCode,\n                        requestId: findHeader(/^x-[\\w-]+-request-?id$/, headerEntries),\n                        extendedRequestId: findHeader(/^x-[\\w-]+-id-2$/, headerEntries),\n                        cfId: findHeader(/^x-[\\w-]+-cf-id$/, headerEntries),\n                    };\n                }\n            }\n            catch (e) {\n            }\n        }\n        throw error;\n    }\n};\nconst findHeader = (pattern, headers) => {\n    return (headers.find(([k]) => {\n        return k.match(pattern);\n    }) || [void 0, void 0])[1];\n};\n\nconst schemaSerializationMiddleware = (config) => (next, context) => async (args) => {\n    const { operationSchema } = utilMiddleware.getSmithyContext(context);\n    const [, ns, n, t, i, o] = operationSchema ?? [];\n    const endpoint = context.endpointV2?.url && config.urlParser\n        ? async () => config.urlParser(context.endpointV2.url)\n        : config.endpoint;\n    const request = await config.protocol.serializeRequest(operation(ns, n, t, i, o), args.input, {\n        ...config,\n        ...context,\n        endpoint,\n    });\n    return next({\n        ...args,\n        request,\n    });\n};\n\nconst deserializerMiddlewareOption = {\n    name: \"deserializerMiddleware\",\n    step: \"deserialize\",\n    tags: [\"DESERIALIZER\"],\n    override: true,\n};\nconst serializerMiddlewareOption = {\n    name: \"serializerMiddleware\",\n    step: \"serialize\",\n    tags: [\"SERIALIZER\"],\n    override: true,\n};\nfunction getSchemaSerdePlugin(config) {\n    return {\n        applyToStack: (commandStack) => {\n            commandStack.add(schemaSerializationMiddleware(config), serializerMiddlewareOption);\n            commandStack.add(schemaDeserializationMiddleware(config), deserializerMiddlewareOption);\n            config.protocol.setSerdeContext(config);\n        },\n    };\n}\n\nclass Schema {\n    name;\n    namespace;\n    traits;\n    static assign(instance, values) {\n        const schema = Object.assign(instance, values);\n        return schema;\n    }\n    static [Symbol.hasInstance](lhs) {\n        const isPrototype = this.prototype.isPrototypeOf(lhs);\n        if (!isPrototype && typeof lhs === \"object\" && lhs !== null) {\n            const list = lhs;\n            return list.symbol === this.symbol;\n        }\n        return isPrototype;\n    }\n    getName() {\n        return this.namespace + \"#\" + this.name;\n    }\n}\n\nclass ListSchema extends Schema {\n    static symbol = Symbol.for(\"@smithy/lis\");\n    name;\n    traits;\n    valueSchema;\n    symbol = ListSchema.symbol;\n}\nconst list = (namespace, name, traits, valueSchema) => Schema.assign(new ListSchema(), {\n    name,\n    namespace,\n    traits,\n    valueSchema,\n});\n\nclass MapSchema extends Schema {\n    static symbol = Symbol.for(\"@smithy/map\");\n    name;\n    traits;\n    keySchema;\n    valueSchema;\n    symbol = MapSchema.symbol;\n}\nconst map = (namespace, name, traits, keySchema, valueSchema) => Schema.assign(new MapSchema(), {\n    name,\n    namespace,\n    traits,\n    keySchema,\n    valueSchema,\n});\n\nclass OperationSchema extends Schema {\n    static symbol = Symbol.for(\"@smithy/ope\");\n    name;\n    traits;\n    input;\n    output;\n    symbol = OperationSchema.symbol;\n}\nconst op = (namespace, name, traits, input, output) => Schema.assign(new OperationSchema(), {\n    name,\n    namespace,\n    traits,\n    input,\n    output,\n});\n\nclass StructureSchema extends Schema {\n    static symbol = Symbol.for(\"@smithy/str\");\n    name;\n    traits;\n    memberNames;\n    memberList;\n    symbol = StructureSchema.symbol;\n}\nconst struct = (namespace, name, traits, memberNames, memberList) => Schema.assign(new StructureSchema(), {\n    name,\n    namespace,\n    traits,\n    memberNames,\n    memberList,\n});\n\nclass ErrorSchema extends StructureSchema {\n    static symbol = Symbol.for(\"@smithy/err\");\n    ctor;\n    symbol = ErrorSchema.symbol;\n}\nconst error = (namespace, name, traits, memberNames, memberList, ctor) => Schema.assign(new ErrorSchema(), {\n    name,\n    namespace,\n    traits,\n    memberNames,\n    memberList,\n    ctor: null,\n});\n\nfunction translateTraits(indicator) {\n    if (typeof indicator === \"object\") {\n        return indicator;\n    }\n    indicator = indicator | 0;\n    const traits = {};\n    let i = 0;\n    for (const trait of [\n        \"httpLabel\",\n        \"idempotent\",\n        \"idempotencyToken\",\n        \"sensitive\",\n        \"httpPayload\",\n        \"httpResponseCode\",\n        \"httpQueryParams\",\n    ]) {\n        if (((indicator >> i++) & 1) === 1) {\n            traits[trait] = 1;\n        }\n    }\n    return traits;\n}\n\nconst anno = {\n    it: Symbol.for(\"@smithy/nor-struct-it\"),\n};\nclass NormalizedSchema {\n    ref;\n    memberName;\n    static symbol = Symbol.for(\"@smithy/nor\");\n    symbol = NormalizedSchema.symbol;\n    name;\n    schema;\n    _isMemberSchema;\n    traits;\n    memberTraits;\n    normalizedTraits;\n    constructor(ref, memberName) {\n        this.ref = ref;\n        this.memberName = memberName;\n        const traitStack = [];\n        let _ref = ref;\n        let schema = ref;\n        this._isMemberSchema = false;\n        while (isMemberSchema(_ref)) {\n            traitStack.push(_ref[1]);\n            _ref = _ref[0];\n            schema = deref(_ref);\n            this._isMemberSchema = true;\n        }\n        if (traitStack.length > 0) {\n            this.memberTraits = {};\n            for (let i = traitStack.length - 1; i >= 0; --i) {\n                const traitSet = traitStack[i];\n                Object.assign(this.memberTraits, translateTraits(traitSet));\n            }\n        }\n        else {\n            this.memberTraits = 0;\n        }\n        if (schema instanceof NormalizedSchema) {\n            const computedMemberTraits = this.memberTraits;\n            Object.assign(this, schema);\n            this.memberTraits = Object.assign({}, computedMemberTraits, schema.getMemberTraits(), this.getMemberTraits());\n            this.normalizedTraits = void 0;\n            this.memberName = memberName ?? schema.memberName;\n            return;\n        }\n        this.schema = deref(schema);\n        if (isStaticSchema(this.schema)) {\n            this.name = `${this.schema[1]}#${this.schema[2]}`;\n            this.traits = this.schema[3];\n        }\n        else {\n            this.name = this.memberName ?? String(schema);\n            this.traits = 0;\n        }\n        if (this._isMemberSchema && !memberName) {\n            throw new Error(`@smithy/core/schema - NormalizedSchema member init ${this.getName(true)} missing member name.`);\n        }\n    }\n    static [Symbol.hasInstance](lhs) {\n        const isPrototype = this.prototype.isPrototypeOf(lhs);\n        if (!isPrototype && typeof lhs === \"object\" && lhs !== null) {\n            const ns = lhs;\n            return ns.symbol === this.symbol;\n        }\n        return isPrototype;\n    }\n    static of(ref) {\n        const sc = deref(ref);\n        if (sc instanceof NormalizedSchema) {\n            return sc;\n        }\n        if (isMemberSchema(sc)) {\n            const [ns, traits] = sc;\n            if (ns instanceof NormalizedSchema) {\n                Object.assign(ns.getMergedTraits(), translateTraits(traits));\n                return ns;\n            }\n            throw new Error(`@smithy/core/schema - may not init unwrapped member schema=${JSON.stringify(ref, null, 2)}.`);\n        }\n        return new NormalizedSchema(sc);\n    }\n    getSchema() {\n        const sc = this.schema;\n        if (Array.isArray(sc) && sc[0] === 0) {\n            return sc[4];\n        }\n        return sc;\n    }\n    getName(withNamespace = false) {\n        const { name } = this;\n        const short = !withNamespace && name && name.includes(\"#\");\n        return short ? name.split(\"#\")[1] : name || undefined;\n    }\n    getMemberName() {\n        return this.memberName;\n    }\n    isMemberSchema() {\n        return this._isMemberSchema;\n    }\n    isListSchema() {\n        const sc = this.getSchema();\n        return typeof sc === \"number\"\n            ? sc >= 64 && sc < 128\n            : sc[0] === 1;\n    }\n    isMapSchema() {\n        const sc = this.getSchema();\n        return typeof sc === \"number\"\n            ? sc >= 128 && sc <= 0b1111_1111\n            : sc[0] === 2;\n    }\n    isStructSchema() {\n        const sc = this.getSchema();\n        if (typeof sc !== \"object\") {\n            return false;\n        }\n        const id = sc[0];\n        return (id === 3 ||\n            id === -3 ||\n            id === 4);\n    }\n    isUnionSchema() {\n        const sc = this.getSchema();\n        if (typeof sc !== \"object\") {\n            return false;\n        }\n        return sc[0] === 4;\n    }\n    isBlobSchema() {\n        const sc = this.getSchema();\n        return sc === 21 || sc === 42;\n    }\n    isTimestampSchema() {\n        const sc = this.getSchema();\n        return (typeof sc === \"number\" &&\n            sc >= 4 &&\n            sc <= 7);\n    }\n    isUnitSchema() {\n        return this.getSchema() === \"unit\";\n    }\n    isDocumentSchema() {\n        return this.getSchema() === 15;\n    }\n    isStringSchema() {\n        return this.getSchema() === 0;\n    }\n    isBooleanSchema() {\n        return this.getSchema() === 2;\n    }\n    isNumericSchema() {\n        return this.getSchema() === 1;\n    }\n    isBigIntegerSchema() {\n        return this.getSchema() === 17;\n    }\n    isBigDecimalSchema() {\n        return this.getSchema() === 19;\n    }\n    isStreaming() {\n        const { streaming } = this.getMergedTraits();\n        return !!streaming || this.getSchema() === 42;\n    }\n    isIdempotencyToken() {\n        return !!this.getMergedTraits().idempotencyToken;\n    }\n    getMergedTraits() {\n        return (this.normalizedTraits ??\n            (this.normalizedTraits = {\n                ...this.getOwnTraits(),\n                ...this.getMemberTraits(),\n            }));\n    }\n    getMemberTraits() {\n        return translateTraits(this.memberTraits);\n    }\n    getOwnTraits() {\n        return translateTraits(this.traits);\n    }\n    getKeySchema() {\n        const [isDoc, isMap] = [this.isDocumentSchema(), this.isMapSchema()];\n        if (!isDoc && !isMap) {\n            throw new Error(`@smithy/core/schema - cannot get key for non-map: ${this.getName(true)}`);\n        }\n        const schema = this.getSchema();\n        const memberSchema = isDoc\n            ? 15\n            : schema[4] ?? 0;\n        return member([memberSchema, 0], \"key\");\n    }\n    getValueSchema() {\n        const sc = this.getSchema();\n        const [isDoc, isMap, isList] = [this.isDocumentSchema(), this.isMapSchema(), this.isListSchema()];\n        const memberSchema = typeof sc === \"number\"\n            ? 0b0011_1111 & sc\n            : sc && typeof sc === \"object\" && (isMap || isList)\n                ? sc[3 + sc[0]]\n                : isDoc\n                    ? 15\n                    : void 0;\n        if (memberSchema != null) {\n            return member([memberSchema, 0], isMap ? \"value\" : \"member\");\n        }\n        throw new Error(`@smithy/core/schema - ${this.getName(true)} has no value member.`);\n    }\n    getMemberSchema(memberName) {\n        const struct = this.getSchema();\n        if (this.isStructSchema() && struct[4].includes(memberName)) {\n            const i = struct[4].indexOf(memberName);\n            const memberSchema = struct[5][i];\n            return member(isMemberSchema(memberSchema) ? memberSchema : [memberSchema, 0], memberName);\n        }\n        if (this.isDocumentSchema()) {\n            return member([15, 0], memberName);\n        }\n        throw new Error(`@smithy/core/schema - ${this.getName(true)} has no no member=${memberName}.`);\n    }\n    getMemberSchemas() {\n        const buffer = {};\n        try {\n            for (const [k, v] of this.structIterator()) {\n                buffer[k] = v;\n            }\n        }\n        catch (ignored) { }\n        return buffer;\n    }\n    getEventStreamMember() {\n        if (this.isStructSchema()) {\n            for (const [memberName, memberSchema] of this.structIterator()) {\n                if (memberSchema.isStreaming() && memberSchema.isStructSchema()) {\n                    return memberName;\n                }\n            }\n        }\n        return \"\";\n    }\n    *structIterator() {\n        if (this.isUnitSchema()) {\n            return;\n        }\n        if (!this.isStructSchema()) {\n            throw new Error(\"@smithy/core/schema - cannot iterate non-struct schema.\");\n        }\n        const struct = this.getSchema();\n        const z = struct[4].length;\n        let it = struct[anno.it];\n        if (it && z === it.length) {\n            yield* it;\n            return;\n        }\n        it = Array(z);\n        for (let i = 0; i < z; ++i) {\n            const k = struct[4][i];\n            const v = member([struct[5][i], 0], k);\n            yield (it[i] = [k, v]);\n        }\n        struct[anno.it] = it;\n    }\n}\nfunction member(memberSchema, memberName) {\n    if (memberSchema instanceof NormalizedSchema) {\n        return Object.assign(memberSchema, {\n            memberName,\n            _isMemberSchema: true,\n        });\n    }\n    const internalCtorAccess = NormalizedSchema;\n    return new internalCtorAccess(memberSchema, memberName);\n}\nconst isMemberSchema = (sc) => Array.isArray(sc) && sc.length === 2;\nconst isStaticSchema = (sc) => Array.isArray(sc) && sc.length >= 5;\n\nclass SimpleSchema extends Schema {\n    static symbol = Symbol.for(\"@smithy/sim\");\n    name;\n    schemaRef;\n    traits;\n    symbol = SimpleSchema.symbol;\n}\nconst sim = (namespace, name, schemaRef, traits) => Schema.assign(new SimpleSchema(), {\n    name,\n    namespace,\n    traits,\n    schemaRef,\n});\nconst simAdapter = (namespace, name, traits, schemaRef) => Schema.assign(new SimpleSchema(), {\n    name,\n    namespace,\n    traits,\n    schemaRef,\n});\n\nconst SCHEMA = {\n    BLOB: 0b0001_0101,\n    STREAMING_BLOB: 0b0010_1010,\n    BOOLEAN: 0b0000_0010,\n    STRING: 0b0000_0000,\n    NUMERIC: 0b0000_0001,\n    BIG_INTEGER: 0b0001_0001,\n    BIG_DECIMAL: 0b0001_0011,\n    DOCUMENT: 0b0000_1111,\n    TIMESTAMP_DEFAULT: 0b0000_0100,\n    TIMESTAMP_DATE_TIME: 0b0000_0101,\n    TIMESTAMP_HTTP_DATE: 0b0000_0110,\n    TIMESTAMP_EPOCH_SECONDS: 0b0000_0111,\n    LIST_MODIFIER: 0b0100_0000,\n    MAP_MODIFIER: 0b1000_0000,\n};\n\nclass TypeRegistry {\n    namespace;\n    schemas;\n    exceptions;\n    static registries = new Map();\n    constructor(namespace, schemas = new Map(), exceptions = new Map()) {\n        this.namespace = namespace;\n        this.schemas = schemas;\n        this.exceptions = exceptions;\n    }\n    static for(namespace) {\n        if (!TypeRegistry.registries.has(namespace)) {\n            TypeRegistry.registries.set(namespace, new TypeRegistry(namespace));\n        }\n        return TypeRegistry.registries.get(namespace);\n    }\n    register(shapeId, schema) {\n        const qualifiedName = this.normalizeShapeId(shapeId);\n        const registry = TypeRegistry.for(qualifiedName.split(\"#\")[0]);\n        registry.schemas.set(qualifiedName, schema);\n    }\n    getSchema(shapeId) {\n        const id = this.normalizeShapeId(shapeId);\n        if (!this.schemas.has(id)) {\n            throw new Error(`@smithy/core/schema - schema not found for ${id}`);\n        }\n        return this.schemas.get(id);\n    }\n    registerError(es, ctor) {\n        const $error = es;\n        const registry = TypeRegistry.for($error[1]);\n        registry.schemas.set($error[1] + \"#\" + $error[2], $error);\n        registry.exceptions.set($error, ctor);\n    }\n    getErrorCtor(es) {\n        const $error = es;\n        const registry = TypeRegistry.for($error[1]);\n        return registry.exceptions.get($error);\n    }\n    getBaseException() {\n        for (const exceptionKey of this.exceptions.keys()) {\n            if (Array.isArray(exceptionKey)) {\n                const [, ns, name] = exceptionKey;\n                const id = ns + \"#\" + name;\n                if (id.startsWith(\"smithy.ts.sdk.synthetic.\") && id.endsWith(\"ServiceException\")) {\n                    return exceptionKey;\n                }\n            }\n        }\n        return undefined;\n    }\n    find(predicate) {\n        return [...this.schemas.values()].find(predicate);\n    }\n    clear() {\n        this.schemas.clear();\n        this.exceptions.clear();\n    }\n    normalizeShapeId(shapeId) {\n        if (shapeId.includes(\"#\")) {\n            return shapeId;\n        }\n        return this.namespace + \"#\" + shapeId;\n    }\n}\n\nexports.ErrorSchema = ErrorSchema;\nexports.ListSchema = ListSchema;\nexports.MapSchema = MapSchema;\nexports.NormalizedSchema = NormalizedSchema;\nexports.OperationSchema = OperationSchema;\nexports.SCHEMA = SCHEMA;\nexports.Schema = Schema;\nexports.SimpleSchema = SimpleSchema;\nexports.StructureSchema = StructureSchema;\nexports.TypeRegistry = TypeRegistry;\nexports.deref = deref;\nexports.deserializerMiddlewareOption = deserializerMiddlewareOption;\nexports.error = error;\nexports.getSchemaSerdePlugin = getSchemaSerdePlugin;\nexports.isStaticSchema = isStaticSchema;\nexports.list = list;\nexports.map = map;\nexports.op = op;\nexports.operation = operation;\nexports.serializerMiddlewareOption = serializerMiddlewareOption;\nexports.sim = sim;\nexports.simAdapter = simAdapter;\nexports.struct = struct;\nexports.translateTraits = translateTraits;\n","'use strict';\n\nvar uuid = require('@smithy/uuid');\n\nconst copyDocumentWithTransform = (source, schemaRef, transform = (_) => _) => source;\n\nconst parseBoolean = (value) => {\n    switch (value) {\n        case \"true\":\n            return true;\n        case \"false\":\n            return false;\n        default:\n            throw new Error(`Unable to parse boolean value \"${value}\"`);\n    }\n};\nconst expectBoolean = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    if (typeof value === \"number\") {\n        if (value === 0 || value === 1) {\n            logger.warn(stackTraceWarning(`Expected boolean, got ${typeof value}: ${value}`));\n        }\n        if (value === 0) {\n            return false;\n        }\n        if (value === 1) {\n            return true;\n        }\n    }\n    if (typeof value === \"string\") {\n        const lower = value.toLowerCase();\n        if (lower === \"false\" || lower === \"true\") {\n            logger.warn(stackTraceWarning(`Expected boolean, got ${typeof value}: ${value}`));\n        }\n        if (lower === \"false\") {\n            return false;\n        }\n        if (lower === \"true\") {\n            return true;\n        }\n    }\n    if (typeof value === \"boolean\") {\n        return value;\n    }\n    throw new TypeError(`Expected boolean, got ${typeof value}: ${value}`);\n};\nconst expectNumber = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    if (typeof value === \"string\") {\n        const parsed = parseFloat(value);\n        if (!Number.isNaN(parsed)) {\n            if (String(parsed) !== String(value)) {\n                logger.warn(stackTraceWarning(`Expected number but observed string: ${value}`));\n            }\n            return parsed;\n        }\n    }\n    if (typeof value === \"number\") {\n        return value;\n    }\n    throw new TypeError(`Expected number, got ${typeof value}: ${value}`);\n};\nconst MAX_FLOAT = Math.ceil(2 ** 127 * (2 - 2 ** -23));\nconst expectFloat32 = (value) => {\n    const expected = expectNumber(value);\n    if (expected !== undefined && !Number.isNaN(expected) && expected !== Infinity && expected !== -Infinity) {\n        if (Math.abs(expected) > MAX_FLOAT) {\n            throw new TypeError(`Expected 32-bit float, got ${value}`);\n        }\n    }\n    return expected;\n};\nconst expectLong = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    if (Number.isInteger(value) && !Number.isNaN(value)) {\n        return value;\n    }\n    throw new TypeError(`Expected integer, got ${typeof value}: ${value}`);\n};\nconst expectInt = expectLong;\nconst expectInt32 = (value) => expectSizedInt(value, 32);\nconst expectShort = (value) => expectSizedInt(value, 16);\nconst expectByte = (value) => expectSizedInt(value, 8);\nconst expectSizedInt = (value, size) => {\n    const expected = expectLong(value);\n    if (expected !== undefined && castInt(expected, size) !== expected) {\n        throw new TypeError(`Expected ${size}-bit integer, got ${value}`);\n    }\n    return expected;\n};\nconst castInt = (value, size) => {\n    switch (size) {\n        case 32:\n            return Int32Array.of(value)[0];\n        case 16:\n            return Int16Array.of(value)[0];\n        case 8:\n            return Int8Array.of(value)[0];\n    }\n};\nconst expectNonNull = (value, location) => {\n    if (value === null || value === undefined) {\n        if (location) {\n            throw new TypeError(`Expected a non-null value for ${location}`);\n        }\n        throw new TypeError(\"Expected a non-null value\");\n    }\n    return value;\n};\nconst expectObject = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    if (typeof value === \"object\" && !Array.isArray(value)) {\n        return value;\n    }\n    const receivedType = Array.isArray(value) ? \"array\" : typeof value;\n    throw new TypeError(`Expected object, got ${receivedType}: ${value}`);\n};\nconst expectString = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    if (typeof value === \"string\") {\n        return value;\n    }\n    if ([\"boolean\", \"number\", \"bigint\"].includes(typeof value)) {\n        logger.warn(stackTraceWarning(`Expected string, got ${typeof value}: ${value}`));\n        return String(value);\n    }\n    throw new TypeError(`Expected string, got ${typeof value}: ${value}`);\n};\nconst expectUnion = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    const asObject = expectObject(value);\n    const setKeys = Object.entries(asObject)\n        .filter(([, v]) => v != null)\n        .map(([k]) => k);\n    if (setKeys.length === 0) {\n        throw new TypeError(`Unions must have exactly one non-null member. None were found.`);\n    }\n    if (setKeys.length > 1) {\n        throw new TypeError(`Unions must have exactly one non-null member. Keys ${setKeys} were not null.`);\n    }\n    return asObject;\n};\nconst strictParseDouble = (value) => {\n    if (typeof value == \"string\") {\n        return expectNumber(parseNumber(value));\n    }\n    return expectNumber(value);\n};\nconst strictParseFloat = strictParseDouble;\nconst strictParseFloat32 = (value) => {\n    if (typeof value == \"string\") {\n        return expectFloat32(parseNumber(value));\n    }\n    return expectFloat32(value);\n};\nconst NUMBER_REGEX = /(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)|(-?Infinity)|(NaN)/g;\nconst parseNumber = (value) => {\n    const matches = value.match(NUMBER_REGEX);\n    if (matches === null || matches[0].length !== value.length) {\n        throw new TypeError(`Expected real number, got implicit NaN`);\n    }\n    return parseFloat(value);\n};\nconst limitedParseDouble = (value) => {\n    if (typeof value == \"string\") {\n        return parseFloatString(value);\n    }\n    return expectNumber(value);\n};\nconst handleFloat = limitedParseDouble;\nconst limitedParseFloat = limitedParseDouble;\nconst limitedParseFloat32 = (value) => {\n    if (typeof value == \"string\") {\n        return parseFloatString(value);\n    }\n    return expectFloat32(value);\n};\nconst parseFloatString = (value) => {\n    switch (value) {\n        case \"NaN\":\n            return NaN;\n        case \"Infinity\":\n            return Infinity;\n        case \"-Infinity\":\n            return -Infinity;\n        default:\n            throw new Error(`Unable to parse float value: ${value}`);\n    }\n};\nconst strictParseLong = (value) => {\n    if (typeof value === \"string\") {\n        return expectLong(parseNumber(value));\n    }\n    return expectLong(value);\n};\nconst strictParseInt = strictParseLong;\nconst strictParseInt32 = (value) => {\n    if (typeof value === \"string\") {\n        return expectInt32(parseNumber(value));\n    }\n    return expectInt32(value);\n};\nconst strictParseShort = (value) => {\n    if (typeof value === \"string\") {\n        return expectShort(parseNumber(value));\n    }\n    return expectShort(value);\n};\nconst strictParseByte = (value) => {\n    if (typeof value === \"string\") {\n        return expectByte(parseNumber(value));\n    }\n    return expectByte(value);\n};\nconst stackTraceWarning = (message) => {\n    return String(new TypeError(message).stack || message)\n        .split(\"\\n\")\n        .slice(0, 5)\n        .filter((s) => !s.includes(\"stackTraceWarning\"))\n        .join(\"\\n\");\n};\nconst logger = {\n    warn: console.warn,\n};\n\nconst DAYS = [\"Sun\", \"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\"];\nconst MONTHS = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"];\nfunction dateToUtcString(date) {\n    const year = date.getUTCFullYear();\n    const month = date.getUTCMonth();\n    const dayOfWeek = date.getUTCDay();\n    const dayOfMonthInt = date.getUTCDate();\n    const hoursInt = date.getUTCHours();\n    const minutesInt = date.getUTCMinutes();\n    const secondsInt = date.getUTCSeconds();\n    const dayOfMonthString = dayOfMonthInt < 10 ? `0${dayOfMonthInt}` : `${dayOfMonthInt}`;\n    const hoursString = hoursInt < 10 ? `0${hoursInt}` : `${hoursInt}`;\n    const minutesString = minutesInt < 10 ? `0${minutesInt}` : `${minutesInt}`;\n    const secondsString = secondsInt < 10 ? `0${secondsInt}` : `${secondsInt}`;\n    return `${DAYS[dayOfWeek]}, ${dayOfMonthString} ${MONTHS[month]} ${year} ${hoursString}:${minutesString}:${secondsString} GMT`;\n}\nconst RFC3339 = new RegExp(/^(\\d{4})-(\\d{2})-(\\d{2})[tT](\\d{2}):(\\d{2}):(\\d{2})(?:\\.(\\d+))?[zZ]$/);\nconst parseRfc3339DateTime = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    if (typeof value !== \"string\") {\n        throw new TypeError(\"RFC-3339 date-times must be expressed as strings\");\n    }\n    const match = RFC3339.exec(value);\n    if (!match) {\n        throw new TypeError(\"Invalid RFC-3339 date-time value\");\n    }\n    const [_, yearStr, monthStr, dayStr, hours, minutes, seconds, fractionalMilliseconds] = match;\n    const year = strictParseShort(stripLeadingZeroes(yearStr));\n    const month = parseDateValue(monthStr, \"month\", 1, 12);\n    const day = parseDateValue(dayStr, \"day\", 1, 31);\n    return buildDate(year, month, day, { hours, minutes, seconds, fractionalMilliseconds });\n};\nconst RFC3339_WITH_OFFSET$1 = new RegExp(/^(\\d{4})-(\\d{2})-(\\d{2})[tT](\\d{2}):(\\d{2}):(\\d{2})(?:\\.(\\d+))?(([-+]\\d{2}\\:\\d{2})|[zZ])$/);\nconst parseRfc3339DateTimeWithOffset = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    if (typeof value !== \"string\") {\n        throw new TypeError(\"RFC-3339 date-times must be expressed as strings\");\n    }\n    const match = RFC3339_WITH_OFFSET$1.exec(value);\n    if (!match) {\n        throw new TypeError(\"Invalid RFC-3339 date-time value\");\n    }\n    const [_, yearStr, monthStr, dayStr, hours, minutes, seconds, fractionalMilliseconds, offsetStr] = match;\n    const year = strictParseShort(stripLeadingZeroes(yearStr));\n    const month = parseDateValue(monthStr, \"month\", 1, 12);\n    const day = parseDateValue(dayStr, \"day\", 1, 31);\n    const date = buildDate(year, month, day, { hours, minutes, seconds, fractionalMilliseconds });\n    if (offsetStr.toUpperCase() != \"Z\") {\n        date.setTime(date.getTime() - parseOffsetToMilliseconds(offsetStr));\n    }\n    return date;\n};\nconst IMF_FIXDATE$1 = new RegExp(/^(?:Mon|Tue|Wed|Thu|Fri|Sat|Sun), (\\d{2}) (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) (\\d{4}) (\\d{1,2}):(\\d{2}):(\\d{2})(?:\\.(\\d+))? GMT$/);\nconst RFC_850_DATE$1 = new RegExp(/^(?:Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday), (\\d{2})-(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)-(\\d{2}) (\\d{1,2}):(\\d{2}):(\\d{2})(?:\\.(\\d+))? GMT$/);\nconst ASC_TIME$1 = new RegExp(/^(?:Mon|Tue|Wed|Thu|Fri|Sat|Sun) (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) ( [1-9]|\\d{2}) (\\d{1,2}):(\\d{2}):(\\d{2})(?:\\.(\\d+))? (\\d{4})$/);\nconst parseRfc7231DateTime = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    if (typeof value !== \"string\") {\n        throw new TypeError(\"RFC-7231 date-times must be expressed as strings\");\n    }\n    let match = IMF_FIXDATE$1.exec(value);\n    if (match) {\n        const [_, dayStr, monthStr, yearStr, hours, minutes, seconds, fractionalMilliseconds] = match;\n        return buildDate(strictParseShort(stripLeadingZeroes(yearStr)), parseMonthByShortName(monthStr), parseDateValue(dayStr, \"day\", 1, 31), { hours, minutes, seconds, fractionalMilliseconds });\n    }\n    match = RFC_850_DATE$1.exec(value);\n    if (match) {\n        const [_, dayStr, monthStr, yearStr, hours, minutes, seconds, fractionalMilliseconds] = match;\n        return adjustRfc850Year(buildDate(parseTwoDigitYear(yearStr), parseMonthByShortName(monthStr), parseDateValue(dayStr, \"day\", 1, 31), {\n            hours,\n            minutes,\n            seconds,\n            fractionalMilliseconds,\n        }));\n    }\n    match = ASC_TIME$1.exec(value);\n    if (match) {\n        const [_, monthStr, dayStr, hours, minutes, seconds, fractionalMilliseconds, yearStr] = match;\n        return buildDate(strictParseShort(stripLeadingZeroes(yearStr)), parseMonthByShortName(monthStr), parseDateValue(dayStr.trimLeft(), \"day\", 1, 31), { hours, minutes, seconds, fractionalMilliseconds });\n    }\n    throw new TypeError(\"Invalid RFC-7231 date-time value\");\n};\nconst parseEpochTimestamp = (value) => {\n    if (value === null || value === undefined) {\n        return undefined;\n    }\n    let valueAsDouble;\n    if (typeof value === \"number\") {\n        valueAsDouble = value;\n    }\n    else if (typeof value === \"string\") {\n        valueAsDouble = strictParseDouble(value);\n    }\n    else if (typeof value === \"object\" && value.tag === 1) {\n        valueAsDouble = value.value;\n    }\n    else {\n        throw new TypeError(\"Epoch timestamps must be expressed as floating point numbers or their string representation\");\n    }\n    if (Number.isNaN(valueAsDouble) || valueAsDouble === Infinity || valueAsDouble === -Infinity) {\n        throw new TypeError(\"Epoch timestamps must be valid, non-Infinite, non-NaN numerics\");\n    }\n    return new Date(Math.round(valueAsDouble * 1000));\n};\nconst buildDate = (year, month, day, time) => {\n    const adjustedMonth = month - 1;\n    validateDayOfMonth(year, adjustedMonth, day);\n    return new Date(Date.UTC(year, adjustedMonth, day, parseDateValue(time.hours, \"hour\", 0, 23), parseDateValue(time.minutes, \"minute\", 0, 59), parseDateValue(time.seconds, \"seconds\", 0, 60), parseMilliseconds(time.fractionalMilliseconds)));\n};\nconst parseTwoDigitYear = (value) => {\n    const thisYear = new Date().getUTCFullYear();\n    const valueInThisCentury = Math.floor(thisYear / 100) * 100 + strictParseShort(stripLeadingZeroes(value));\n    if (valueInThisCentury < thisYear) {\n        return valueInThisCentury + 100;\n    }\n    return valueInThisCentury;\n};\nconst FIFTY_YEARS_IN_MILLIS = 50 * 365 * 24 * 60 * 60 * 1000;\nconst adjustRfc850Year = (input) => {\n    if (input.getTime() - new Date().getTime() > FIFTY_YEARS_IN_MILLIS) {\n        return new Date(Date.UTC(input.getUTCFullYear() - 100, input.getUTCMonth(), input.getUTCDate(), input.getUTCHours(), input.getUTCMinutes(), input.getUTCSeconds(), input.getUTCMilliseconds()));\n    }\n    return input;\n};\nconst parseMonthByShortName = (value) => {\n    const monthIdx = MONTHS.indexOf(value);\n    if (monthIdx < 0) {\n        throw new TypeError(`Invalid month: ${value}`);\n    }\n    return monthIdx + 1;\n};\nconst DAYS_IN_MONTH = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31];\nconst validateDayOfMonth = (year, month, day) => {\n    let maxDays = DAYS_IN_MONTH[month];\n    if (month === 1 && isLeapYear(year)) {\n        maxDays = 29;\n    }\n    if (day > maxDays) {\n        throw new TypeError(`Invalid day for ${MONTHS[month]} in ${year}: ${day}`);\n    }\n};\nconst isLeapYear = (year) => {\n    return year % 4 === 0 && (year % 100 !== 0 || year % 400 === 0);\n};\nconst parseDateValue = (value, type, lower, upper) => {\n    const dateVal = strictParseByte(stripLeadingZeroes(value));\n    if (dateVal < lower || dateVal > upper) {\n        throw new TypeError(`${type} must be between ${lower} and ${upper}, inclusive`);\n    }\n    return dateVal;\n};\nconst parseMilliseconds = (value) => {\n    if (value === null || value === undefined) {\n        return 0;\n    }\n    return strictParseFloat32(\"0.\" + value) * 1000;\n};\nconst parseOffsetToMilliseconds = (value) => {\n    const directionStr = value[0];\n    let direction = 1;\n    if (directionStr == \"+\") {\n        direction = 1;\n    }\n    else if (directionStr == \"-\") {\n        direction = -1;\n    }\n    else {\n        throw new TypeError(`Offset direction, ${directionStr}, must be \"+\" or \"-\"`);\n    }\n    const hour = Number(value.substring(1, 3));\n    const minute = Number(value.substring(4, 6));\n    return direction * (hour * 60 + minute) * 60 * 1000;\n};\nconst stripLeadingZeroes = (value) => {\n    let idx = 0;\n    while (idx < value.length - 1 && value.charAt(idx) === \"0\") {\n        idx++;\n    }\n    if (idx === 0) {\n        return value;\n    }\n    return value.slice(idx);\n};\n\nconst LazyJsonString = function LazyJsonString(val) {\n    const str = Object.assign(new String(val), {\n        deserializeJSON() {\n            return JSON.parse(String(val));\n        },\n        toString() {\n            return String(val);\n        },\n        toJSON() {\n            return String(val);\n        },\n    });\n    return str;\n};\nLazyJsonString.from = (object) => {\n    if (object && typeof object === \"object\" && (object instanceof LazyJsonString || \"deserializeJSON\" in object)) {\n        return object;\n    }\n    else if (typeof object === \"string\" || Object.getPrototypeOf(object) === String.prototype) {\n        return LazyJsonString(String(object));\n    }\n    return LazyJsonString(JSON.stringify(object));\n};\nLazyJsonString.fromObject = LazyJsonString.from;\n\nfunction quoteHeader(part) {\n    if (part.includes(\",\") || part.includes('\"')) {\n        part = `\"${part.replace(/\"/g, '\\\\\"')}\"`;\n    }\n    return part;\n}\n\nconst ddd = `(?:Mon|Tue|Wed|Thu|Fri|Sat|Sun)(?:[ne|u?r]?s?day)?`;\nconst mmm = `(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)`;\nconst time = `(\\\\d?\\\\d):(\\\\d{2}):(\\\\d{2})(?:\\\\.(\\\\d+))?`;\nconst date = `(\\\\d?\\\\d)`;\nconst year = `(\\\\d{4})`;\nconst RFC3339_WITH_OFFSET = new RegExp(/^(\\d{4})-(\\d\\d)-(\\d\\d)[tT](\\d\\d):(\\d\\d):(\\d\\d)(\\.(\\d+))?(([-+]\\d\\d:\\d\\d)|[zZ])$/);\nconst IMF_FIXDATE = new RegExp(`^${ddd}, ${date} ${mmm} ${year} ${time} GMT$`);\nconst RFC_850_DATE = new RegExp(`^${ddd}, ${date}-${mmm}-(\\\\d\\\\d) ${time} GMT$`);\nconst ASC_TIME = new RegExp(`^${ddd} ${mmm} ( [1-9]|\\\\d\\\\d) ${time} ${year}$`);\nconst months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"];\nconst _parseEpochTimestamp = (value) => {\n    if (value == null) {\n        return void 0;\n    }\n    let num = NaN;\n    if (typeof value === \"number\") {\n        num = value;\n    }\n    else if (typeof value === \"string\") {\n        if (!/^-?\\d*\\.?\\d+$/.test(value)) {\n            throw new TypeError(`parseEpochTimestamp - numeric string invalid.`);\n        }\n        num = Number.parseFloat(value);\n    }\n    else if (typeof value === \"object\" && value.tag === 1) {\n        num = value.value;\n    }\n    if (isNaN(num) || Math.abs(num) === Infinity) {\n        throw new TypeError(\"Epoch timestamps must be valid finite numbers.\");\n    }\n    return new Date(Math.round(num * 1000));\n};\nconst _parseRfc3339DateTimeWithOffset = (value) => {\n    if (value == null) {\n        return void 0;\n    }\n    if (typeof value !== \"string\") {\n        throw new TypeError(\"RFC3339 timestamps must be strings\");\n    }\n    const matches = RFC3339_WITH_OFFSET.exec(value);\n    if (!matches) {\n        throw new TypeError(`Invalid RFC3339 timestamp format ${value}`);\n    }\n    const [, yearStr, monthStr, dayStr, hours, minutes, seconds, , ms, offsetStr] = matches;\n    range(monthStr, 1, 12);\n    range(dayStr, 1, 31);\n    range(hours, 0, 23);\n    range(minutes, 0, 59);\n    range(seconds, 0, 60);\n    const date = new Date(Date.UTC(Number(yearStr), Number(monthStr) - 1, Number(dayStr), Number(hours), Number(minutes), Number(seconds), Number(ms) ? Math.round(parseFloat(`0.${ms}`) * 1000) : 0));\n    date.setUTCFullYear(Number(yearStr));\n    if (offsetStr.toUpperCase() != \"Z\") {\n        const [, sign, offsetH, offsetM] = /([+-])(\\d\\d):(\\d\\d)/.exec(offsetStr) || [void 0, \"+\", 0, 0];\n        const scalar = sign === \"-\" ? 1 : -1;\n        date.setTime(date.getTime() + scalar * (Number(offsetH) * 60 * 60 * 1000 + Number(offsetM) * 60 * 1000));\n    }\n    return date;\n};\nconst _parseRfc7231DateTime = (value) => {\n    if (value == null) {\n        return void 0;\n    }\n    if (typeof value !== \"string\") {\n        throw new TypeError(\"RFC7231 timestamps must be strings.\");\n    }\n    let day;\n    let month;\n    let year;\n    let hour;\n    let minute;\n    let second;\n    let fraction;\n    let matches;\n    if ((matches = IMF_FIXDATE.exec(value))) {\n        [, day, month, year, hour, minute, second, fraction] = matches;\n    }\n    else if ((matches = RFC_850_DATE.exec(value))) {\n        [, day, month, year, hour, minute, second, fraction] = matches;\n        year = (Number(year) + 1900).toString();\n    }\n    else if ((matches = ASC_TIME.exec(value))) {\n        [, month, day, hour, minute, second, fraction, year] = matches;\n    }\n    if (year && second) {\n        const timestamp = Date.UTC(Number(year), months.indexOf(month), Number(day), Number(hour), Number(minute), Number(second), fraction ? Math.round(parseFloat(`0.${fraction}`) * 1000) : 0);\n        range(day, 1, 31);\n        range(hour, 0, 23);\n        range(minute, 0, 59);\n        range(second, 0, 60);\n        const date = new Date(timestamp);\n        date.setUTCFullYear(Number(year));\n        return date;\n    }\n    throw new TypeError(`Invalid RFC7231 date-time value ${value}.`);\n};\nfunction range(v, min, max) {\n    const _v = Number(v);\n    if (_v < min || _v > max) {\n        throw new Error(`Value ${_v} out of range [${min}, ${max}]`);\n    }\n}\n\nfunction splitEvery(value, delimiter, numDelimiters) {\n    if (numDelimiters <= 0 || !Number.isInteger(numDelimiters)) {\n        throw new Error(\"Invalid number of delimiters (\" + numDelimiters + \") for splitEvery.\");\n    }\n    const segments = value.split(delimiter);\n    if (numDelimiters === 1) {\n        return segments;\n    }\n    const compoundSegments = [];\n    let currentSegment = \"\";\n    for (let i = 0; i < segments.length; i++) {\n        if (currentSegment === \"\") {\n            currentSegment = segments[i];\n        }\n        else {\n            currentSegment += delimiter + segments[i];\n        }\n        if ((i + 1) % numDelimiters === 0) {\n            compoundSegments.push(currentSegment);\n            currentSegment = \"\";\n        }\n    }\n    if (currentSegment !== \"\") {\n        compoundSegments.push(currentSegment);\n    }\n    return compoundSegments;\n}\n\nconst splitHeader = (value) => {\n    const z = value.length;\n    const values = [];\n    let withinQuotes = false;\n    let prevChar = undefined;\n    let anchor = 0;\n    for (let i = 0; i < z; ++i) {\n        const char = value[i];\n        switch (char) {\n            case `\"`:\n                if (prevChar !== \"\\\\\") {\n                    withinQuotes = !withinQuotes;\n                }\n                break;\n            case \",\":\n                if (!withinQuotes) {\n                    values.push(value.slice(anchor, i));\n                    anchor = i + 1;\n                }\n                break;\n        }\n        prevChar = char;\n    }\n    values.push(value.slice(anchor));\n    return values.map((v) => {\n        v = v.trim();\n        const z = v.length;\n        if (z < 2) {\n            return v;\n        }\n        if (v[0] === `\"` && v[z - 1] === `\"`) {\n            v = v.slice(1, z - 1);\n        }\n        return v.replace(/\\\\\"/g, '\"');\n    });\n};\n\nconst format = /^-?\\d*(\\.\\d+)?$/;\nclass NumericValue {\n    string;\n    type;\n    constructor(string, type) {\n        this.string = string;\n        this.type = type;\n        if (!format.test(string)) {\n            throw new Error(`@smithy/core/serde - NumericValue must only contain [0-9], at most one decimal point \".\", and an optional negation prefix \"-\".`);\n        }\n    }\n    toString() {\n        return this.string;\n    }\n    static [Symbol.hasInstance](object) {\n        if (!object || typeof object !== \"object\") {\n            return false;\n        }\n        const _nv = object;\n        return NumericValue.prototype.isPrototypeOf(object) || (_nv.type === \"bigDecimal\" && format.test(_nv.string));\n    }\n}\nfunction nv(input) {\n    return new NumericValue(String(input), \"bigDecimal\");\n}\n\nObject.defineProperty(exports, \"generateIdempotencyToken\", {\n    enumerable: true,\n    get: function () { return uuid.v4; }\n});\nexports.LazyJsonString = LazyJsonString;\nexports.NumericValue = NumericValue;\nexports._parseEpochTimestamp = _parseEpochTimestamp;\nexports._parseRfc3339DateTimeWithOffset = _parseRfc3339DateTimeWithOffset;\nexports._parseRfc7231DateTime = _parseRfc7231DateTime;\nexports.copyDocumentWithTransform = copyDocumentWithTransform;\nexports.dateToUtcString = dateToUtcString;\nexports.expectBoolean = expectBoolean;\nexports.expectByte = expectByte;\nexports.expectFloat32 = expectFloat32;\nexports.expectInt = expectInt;\nexports.expectInt32 = expectInt32;\nexports.expectLong = expectLong;\nexports.expectNonNull = expectNonNull;\nexports.expectNumber = expectNumber;\nexports.expectObject = expectObject;\nexports.expectShort = expectShort;\nexports.expectString = expectString;\nexports.expectUnion = expectUnion;\nexports.handleFloat = handleFloat;\nexports.limitedParseDouble = limitedParseDouble;\nexports.limitedParseFloat = limitedParseFloat;\nexports.limitedParseFloat32 = limitedParseFloat32;\nexports.logger = logger;\nexports.nv = nv;\nexports.parseBoolean = parseBoolean;\nexports.parseEpochTimestamp = parseEpochTimestamp;\nexports.parseRfc3339DateTime = parseRfc3339DateTime;\nexports.parseRfc3339DateTimeWithOffset = parseRfc3339DateTimeWithOffset;\nexports.parseRfc7231DateTime = parseRfc7231DateTime;\nexports.quoteHeader = quoteHeader;\nexports.splitEvery = splitEvery;\nexports.splitHeader = splitHeader;\nexports.strictParseByte = strictParseByte;\nexports.strictParseDouble = strictParseDouble;\nexports.strictParseFloat = strictParseFloat;\nexports.strictParseFloat32 = strictParseFloat32;\nexports.strictParseInt = strictParseInt;\nexports.strictParseInt32 = strictParseInt32;\nexports.strictParseLong = strictParseLong;\nexports.strictParseShort = strictParseShort;\n","'use strict';\n\nvar crc32 = require('@aws-crypto/crc32');\nvar utilHexEncoding = require('@smithy/util-hex-encoding');\n\nclass Int64 {\n    bytes;\n    constructor(bytes) {\n        this.bytes = bytes;\n        if (bytes.byteLength !== 8) {\n            throw new Error(\"Int64 buffers must be exactly 8 bytes\");\n        }\n    }\n    static fromNumber(number) {\n        if (number > 9_223_372_036_854_775_807 || number < -9223372036854776e3) {\n            throw new Error(`${number} is too large (or, if negative, too small) to represent as an Int64`);\n        }\n        const bytes = new Uint8Array(8);\n        for (let i = 7, remaining = Math.abs(Math.round(number)); i > -1 && remaining > 0; i--, remaining /= 256) {\n            bytes[i] = remaining;\n        }\n        if (number < 0) {\n            negate(bytes);\n        }\n        return new Int64(bytes);\n    }\n    valueOf() {\n        const bytes = this.bytes.slice(0);\n        const negative = bytes[0] & 0b10000000;\n        if (negative) {\n            negate(bytes);\n        }\n        return parseInt(utilHexEncoding.toHex(bytes), 16) * (negative ? -1 : 1);\n    }\n    toString() {\n        return String(this.valueOf());\n    }\n}\nfunction negate(bytes) {\n    for (let i = 0; i < 8; i++) {\n        bytes[i] ^= 0xff;\n    }\n    for (let i = 7; i > -1; i--) {\n        bytes[i]++;\n        if (bytes[i] !== 0)\n            break;\n    }\n}\n\nclass HeaderMarshaller {\n    toUtf8;\n    fromUtf8;\n    constructor(toUtf8, fromUtf8) {\n        this.toUtf8 = toUtf8;\n        this.fromUtf8 = fromUtf8;\n    }\n    format(headers) {\n        const chunks = [];\n        for (const headerName of Object.keys(headers)) {\n            const bytes = this.fromUtf8(headerName);\n            chunks.push(Uint8Array.from([bytes.byteLength]), bytes, this.formatHeaderValue(headers[headerName]));\n        }\n        const out = new Uint8Array(chunks.reduce((carry, bytes) => carry + bytes.byteLength, 0));\n        let position = 0;\n        for (const chunk of chunks) {\n            out.set(chunk, position);\n            position += chunk.byteLength;\n        }\n        return out;\n    }\n    formatHeaderValue(header) {\n        switch (header.type) {\n            case \"boolean\":\n                return Uint8Array.from([header.value ? 0 : 1]);\n            case \"byte\":\n                return Uint8Array.from([2, header.value]);\n            case \"short\":\n                const shortView = new DataView(new ArrayBuffer(3));\n                shortView.setUint8(0, 3);\n                shortView.setInt16(1, header.value, false);\n                return new Uint8Array(shortView.buffer);\n            case \"integer\":\n                const intView = new DataView(new ArrayBuffer(5));\n                intView.setUint8(0, 4);\n                intView.setInt32(1, header.value, false);\n                return new Uint8Array(intView.buffer);\n            case \"long\":\n                const longBytes = new Uint8Array(9);\n                longBytes[0] = 5;\n                longBytes.set(header.value.bytes, 1);\n                return longBytes;\n            case \"binary\":\n                const binView = new DataView(new ArrayBuffer(3 + header.value.byteLength));\n                binView.setUint8(0, 6);\n                binView.setUint16(1, header.value.byteLength, false);\n                const binBytes = new Uint8Array(binView.buffer);\n                binBytes.set(header.value, 3);\n                return binBytes;\n            case \"string\":\n                const utf8Bytes = this.fromUtf8(header.value);\n                const strView = new DataView(new ArrayBuffer(3 + utf8Bytes.byteLength));\n                strView.setUint8(0, 7);\n                strView.setUint16(1, utf8Bytes.byteLength, false);\n                const strBytes = new Uint8Array(strView.buffer);\n                strBytes.set(utf8Bytes, 3);\n                return strBytes;\n            case \"timestamp\":\n                const tsBytes = new Uint8Array(9);\n                tsBytes[0] = 8;\n                tsBytes.set(Int64.fromNumber(header.value.valueOf()).bytes, 1);\n                return tsBytes;\n            case \"uuid\":\n                if (!UUID_PATTERN.test(header.value)) {\n                    throw new Error(`Invalid UUID received: ${header.value}`);\n                }\n                const uuidBytes = new Uint8Array(17);\n                uuidBytes[0] = 9;\n                uuidBytes.set(utilHexEncoding.fromHex(header.value.replace(/\\-/g, \"\")), 1);\n                return uuidBytes;\n        }\n    }\n    parse(headers) {\n        const out = {};\n        let position = 0;\n        while (position < headers.byteLength) {\n            const nameLength = headers.getUint8(position++);\n            const name = this.toUtf8(new Uint8Array(headers.buffer, headers.byteOffset + position, nameLength));\n            position += nameLength;\n            switch (headers.getUint8(position++)) {\n                case 0:\n                    out[name] = {\n                        type: BOOLEAN_TAG,\n                        value: true,\n                    };\n                    break;\n                case 1:\n                    out[name] = {\n                        type: BOOLEAN_TAG,\n                        value: false,\n                    };\n                    break;\n                case 2:\n                    out[name] = {\n                        type: BYTE_TAG,\n                        value: headers.getInt8(position++),\n                    };\n                    break;\n                case 3:\n                    out[name] = {\n                        type: SHORT_TAG,\n                        value: headers.getInt16(position, false),\n                    };\n                    position += 2;\n                    break;\n                case 4:\n                    out[name] = {\n                        type: INT_TAG,\n                        value: headers.getInt32(position, false),\n                    };\n                    position += 4;\n                    break;\n                case 5:\n                    out[name] = {\n                        type: LONG_TAG,\n                        value: new Int64(new Uint8Array(headers.buffer, headers.byteOffset + position, 8)),\n                    };\n                    position += 8;\n                    break;\n                case 6:\n                    const binaryLength = headers.getUint16(position, false);\n                    position += 2;\n                    out[name] = {\n                        type: BINARY_TAG,\n                        value: new Uint8Array(headers.buffer, headers.byteOffset + position, binaryLength),\n                    };\n                    position += binaryLength;\n                    break;\n                case 7:\n                    const stringLength = headers.getUint16(position, false);\n                    position += 2;\n                    out[name] = {\n                        type: STRING_TAG,\n                        value: this.toUtf8(new Uint8Array(headers.buffer, headers.byteOffset + position, stringLength)),\n                    };\n                    position += stringLength;\n                    break;\n                case 8:\n                    out[name] = {\n                        type: TIMESTAMP_TAG,\n                        value: new Date(new Int64(new Uint8Array(headers.buffer, headers.byteOffset + position, 8)).valueOf()),\n                    };\n                    position += 8;\n                    break;\n                case 9:\n                    const uuidBytes = new Uint8Array(headers.buffer, headers.byteOffset + position, 16);\n                    position += 16;\n                    out[name] = {\n                        type: UUID_TAG,\n                        value: `${utilHexEncoding.toHex(uuidBytes.subarray(0, 4))}-${utilHexEncoding.toHex(uuidBytes.subarray(4, 6))}-${utilHexEncoding.toHex(uuidBytes.subarray(6, 8))}-${utilHexEncoding.toHex(uuidBytes.subarray(8, 10))}-${utilHexEncoding.toHex(uuidBytes.subarray(10))}`,\n                    };\n                    break;\n                default:\n                    throw new Error(`Unrecognized header type tag`);\n            }\n        }\n        return out;\n    }\n}\nconst BOOLEAN_TAG = \"boolean\";\nconst BYTE_TAG = \"byte\";\nconst SHORT_TAG = \"short\";\nconst INT_TAG = \"integer\";\nconst LONG_TAG = \"long\";\nconst BINARY_TAG = \"binary\";\nconst STRING_TAG = \"string\";\nconst TIMESTAMP_TAG = \"timestamp\";\nconst UUID_TAG = \"uuid\";\nconst UUID_PATTERN = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;\n\nconst PRELUDE_MEMBER_LENGTH = 4;\nconst PRELUDE_LENGTH = PRELUDE_MEMBER_LENGTH * 2;\nconst CHECKSUM_LENGTH = 4;\nconst MINIMUM_MESSAGE_LENGTH = PRELUDE_LENGTH + CHECKSUM_LENGTH * 2;\nfunction splitMessage({ byteLength, byteOffset, buffer }) {\n    if (byteLength < MINIMUM_MESSAGE_LENGTH) {\n        throw new Error(\"Provided message too short to accommodate event stream message overhead\");\n    }\n    const view = new DataView(buffer, byteOffset, byteLength);\n    const messageLength = view.getUint32(0, false);\n    if (byteLength !== messageLength) {\n        throw new Error(\"Reported message length does not match received message length\");\n    }\n    const headerLength = view.getUint32(PRELUDE_MEMBER_LENGTH, false);\n    const expectedPreludeChecksum = view.getUint32(PRELUDE_LENGTH, false);\n    const expectedMessageChecksum = view.getUint32(byteLength - CHECKSUM_LENGTH, false);\n    const checksummer = new crc32.Crc32().update(new Uint8Array(buffer, byteOffset, PRELUDE_LENGTH));\n    if (expectedPreludeChecksum !== checksummer.digest()) {\n        throw new Error(`The prelude checksum specified in the message (${expectedPreludeChecksum}) does not match the calculated CRC32 checksum (${checksummer.digest()})`);\n    }\n    checksummer.update(new Uint8Array(buffer, byteOffset + PRELUDE_LENGTH, byteLength - (PRELUDE_LENGTH + CHECKSUM_LENGTH)));\n    if (expectedMessageChecksum !== checksummer.digest()) {\n        throw new Error(`The message checksum (${checksummer.digest()}) did not match the expected value of ${expectedMessageChecksum}`);\n    }\n    return {\n        headers: new DataView(buffer, byteOffset + PRELUDE_LENGTH + CHECKSUM_LENGTH, headerLength),\n        body: new Uint8Array(buffer, byteOffset + PRELUDE_LENGTH + CHECKSUM_LENGTH + headerLength, messageLength - headerLength - (PRELUDE_LENGTH + CHECKSUM_LENGTH + CHECKSUM_LENGTH)),\n    };\n}\n\nclass EventStreamCodec {\n    headerMarshaller;\n    messageBuffer;\n    isEndOfStream;\n    constructor(toUtf8, fromUtf8) {\n        this.headerMarshaller = new HeaderMarshaller(toUtf8, fromUtf8);\n        this.messageBuffer = [];\n        this.isEndOfStream = false;\n    }\n    feed(message) {\n        this.messageBuffer.push(this.decode(message));\n    }\n    endOfStream() {\n        this.isEndOfStream = true;\n    }\n    getMessage() {\n        const message = this.messageBuffer.pop();\n        const isEndOfStream = this.isEndOfStream;\n        return {\n            getMessage() {\n                return message;\n            },\n            isEndOfStream() {\n                return isEndOfStream;\n            },\n        };\n    }\n    getAvailableMessages() {\n        const messages = this.messageBuffer;\n        this.messageBuffer = [];\n        const isEndOfStream = this.isEndOfStream;\n        return {\n            getMessages() {\n                return messages;\n            },\n            isEndOfStream() {\n                return isEndOfStream;\n            },\n        };\n    }\n    encode({ headers: rawHeaders, body }) {\n        const headers = this.headerMarshaller.format(rawHeaders);\n        const length = headers.byteLength + body.byteLength + 16;\n        const out = new Uint8Array(length);\n        const view = new DataView(out.buffer, out.byteOffset, out.byteLength);\n        const checksum = new crc32.Crc32();\n        view.setUint32(0, length, false);\n        view.setUint32(4, headers.byteLength, false);\n        view.setUint32(8, checksum.update(out.subarray(0, 8)).digest(), false);\n        out.set(headers, 12);\n        out.set(body, headers.byteLength + 12);\n        view.setUint32(length - 4, checksum.update(out.subarray(8, length - 4)).digest(), false);\n        return out;\n    }\n    decode(message) {\n        const { headers, body } = splitMessage(message);\n        return { headers: this.headerMarshaller.parse(headers), body };\n    }\n    formatHeaders(rawHeaders) {\n        return this.headerMarshaller.format(rawHeaders);\n    }\n}\n\nclass MessageDecoderStream {\n    options;\n    constructor(options) {\n        this.options = options;\n    }\n    [Symbol.asyncIterator]() {\n        return this.asyncIterator();\n    }\n    async *asyncIterator() {\n        for await (const bytes of this.options.inputStream) {\n            const decoded = this.options.decoder.decode(bytes);\n            yield decoded;\n        }\n    }\n}\n\nclass MessageEncoderStream {\n    options;\n    constructor(options) {\n        this.options = options;\n    }\n    [Symbol.asyncIterator]() {\n        return this.asyncIterator();\n    }\n    async *asyncIterator() {\n        for await (const msg of this.options.messageStream) {\n            const encoded = this.options.encoder.encode(msg);\n            yield encoded;\n        }\n        if (this.options.includeEndFrame) {\n            yield new Uint8Array(0);\n        }\n    }\n}\n\nclass SmithyMessageDecoderStream {\n    options;\n    constructor(options) {\n        this.options = options;\n    }\n    [Symbol.asyncIterator]() {\n        return this.asyncIterator();\n    }\n    async *asyncIterator() {\n        for await (const message of this.options.messageStream) {\n            const deserialized = await this.options.deserializer(message);\n            if (deserialized === undefined)\n                continue;\n            yield deserialized;\n        }\n    }\n}\n\nclass SmithyMessageEncoderStream {\n    options;\n    constructor(options) {\n        this.options = options;\n    }\n    [Symbol.asyncIterator]() {\n        return this.asyncIterator();\n    }\n    async *asyncIterator() {\n        for await (const chunk of this.options.inputStream) {\n            const payloadBuf = this.options.serializer(chunk);\n            yield payloadBuf;\n        }\n    }\n}\n\nexports.EventStreamCodec = EventStreamCodec;\nexports.HeaderMarshaller = HeaderMarshaller;\nexports.Int64 = Int64;\nexports.MessageDecoderStream = MessageDecoderStream;\nexports.MessageEncoderStream = MessageEncoderStream;\nexports.SmithyMessageDecoderStream = SmithyMessageDecoderStream;\nexports.SmithyMessageEncoderStream = SmithyMessageEncoderStream;\n","'use strict';\n\nconst resolveEventStreamSerdeConfig = (input) => Object.assign(input, {\n    eventStreamMarshaller: input.eventStreamSerdeProvider(input),\n});\n\nexports.resolveEventStreamSerdeConfig = resolveEventStreamSerdeConfig;\n","'use strict';\n\nvar eventstreamSerdeUniversal = require('@smithy/eventstream-serde-universal');\nvar stream = require('stream');\n\nasync function* readabletoIterable(readStream) {\n    let streamEnded = false;\n    let generationEnded = false;\n    const records = new Array();\n    readStream.on(\"error\", (err) => {\n        if (!streamEnded) {\n            streamEnded = true;\n        }\n        if (err) {\n            throw err;\n        }\n    });\n    readStream.on(\"data\", (data) => {\n        records.push(data);\n    });\n    readStream.on(\"end\", () => {\n        streamEnded = true;\n    });\n    while (!generationEnded) {\n        const value = await new Promise((resolve) => setTimeout(() => resolve(records.shift()), 0));\n        if (value) {\n            yield value;\n        }\n        generationEnded = streamEnded && records.length === 0;\n    }\n}\n\nclass EventStreamMarshaller {\n    universalMarshaller;\n    constructor({ utf8Encoder, utf8Decoder }) {\n        this.universalMarshaller = new eventstreamSerdeUniversal.EventStreamMarshaller({\n            utf8Decoder,\n            utf8Encoder,\n        });\n    }\n    deserialize(body, deserializer) {\n        const bodyIterable = typeof body[Symbol.asyncIterator] === \"function\" ? body : readabletoIterable(body);\n        return this.universalMarshaller.deserialize(bodyIterable, deserializer);\n    }\n    serialize(input, serializer) {\n        return stream.Readable.from(this.universalMarshaller.serialize(input, serializer));\n    }\n}\n\nconst eventStreamSerdeProvider = (options) => new EventStreamMarshaller(options);\n\nexports.EventStreamMarshaller = EventStreamMarshaller;\nexports.eventStreamSerdeProvider = eventStreamSerdeProvider;\n","'use strict';\n\nvar eventstreamCodec = require('@smithy/eventstream-codec');\n\nfunction getChunkedStream(source) {\n    let currentMessageTotalLength = 0;\n    let currentMessagePendingLength = 0;\n    let currentMessage = null;\n    let messageLengthBuffer = null;\n    const allocateMessage = (size) => {\n        if (typeof size !== \"number\") {\n            throw new Error(\"Attempted to allocate an event message where size was not a number: \" + size);\n        }\n        currentMessageTotalLength = size;\n        currentMessagePendingLength = 4;\n        currentMessage = new Uint8Array(size);\n        const currentMessageView = new DataView(currentMessage.buffer);\n        currentMessageView.setUint32(0, size, false);\n    };\n    const iterator = async function* () {\n        const sourceIterator = source[Symbol.asyncIterator]();\n        while (true) {\n            const { value, done } = await sourceIterator.next();\n            if (done) {\n                if (!currentMessageTotalLength) {\n                    return;\n                }\n                else if (currentMessageTotalLength === currentMessagePendingLength) {\n                    yield currentMessage;\n                }\n                else {\n                    throw new Error(\"Truncated event message received.\");\n                }\n                return;\n            }\n            const chunkLength = value.length;\n            let currentOffset = 0;\n            while (currentOffset < chunkLength) {\n                if (!currentMessage) {\n                    const bytesRemaining = chunkLength - currentOffset;\n                    if (!messageLengthBuffer) {\n                        messageLengthBuffer = new Uint8Array(4);\n                    }\n                    const numBytesForTotal = Math.min(4 - currentMessagePendingLength, bytesRemaining);\n                    messageLengthBuffer.set(value.slice(currentOffset, currentOffset + numBytesForTotal), currentMessagePendingLength);\n                    currentMessagePendingLength += numBytesForTotal;\n                    currentOffset += numBytesForTotal;\n                    if (currentMessagePendingLength < 4) {\n                        break;\n                    }\n                    allocateMessage(new DataView(messageLengthBuffer.buffer).getUint32(0, false));\n                    messageLengthBuffer = null;\n                }\n                const numBytesToWrite = Math.min(currentMessageTotalLength - currentMessagePendingLength, chunkLength - currentOffset);\n                currentMessage.set(value.slice(currentOffset, currentOffset + numBytesToWrite), currentMessagePendingLength);\n                currentMessagePendingLength += numBytesToWrite;\n                currentOffset += numBytesToWrite;\n                if (currentMessageTotalLength && currentMessageTotalLength === currentMessagePendingLength) {\n                    yield currentMessage;\n                    currentMessage = null;\n                    currentMessageTotalLength = 0;\n                    currentMessagePendingLength = 0;\n                }\n            }\n        }\n    };\n    return {\n        [Symbol.asyncIterator]: iterator,\n    };\n}\n\nfunction getMessageUnmarshaller(deserializer, toUtf8) {\n    return async function (message) {\n        const { value: messageType } = message.headers[\":message-type\"];\n        if (messageType === \"error\") {\n            const unmodeledError = new Error(message.headers[\":error-message\"].value || \"UnknownError\");\n            unmodeledError.name = message.headers[\":error-code\"].value;\n            throw unmodeledError;\n        }\n        else if (messageType === \"exception\") {\n            const code = message.headers[\":exception-type\"].value;\n            const exception = { [code]: message };\n            const deserializedException = await deserializer(exception);\n            if (deserializedException.$unknown) {\n                const error = new Error(toUtf8(message.body));\n                error.name = code;\n                throw error;\n            }\n            throw deserializedException[code];\n        }\n        else if (messageType === \"event\") {\n            const event = {\n                [message.headers[\":event-type\"].value]: message,\n            };\n            const deserialized = await deserializer(event);\n            if (deserialized.$unknown)\n                return;\n            return deserialized;\n        }\n        else {\n            throw Error(`Unrecognizable event type: ${message.headers[\":event-type\"].value}`);\n        }\n    };\n}\n\nclass EventStreamMarshaller {\n    eventStreamCodec;\n    utfEncoder;\n    constructor({ utf8Encoder, utf8Decoder }) {\n        this.eventStreamCodec = new eventstreamCodec.EventStreamCodec(utf8Encoder, utf8Decoder);\n        this.utfEncoder = utf8Encoder;\n    }\n    deserialize(body, deserializer) {\n        const inputStream = getChunkedStream(body);\n        return new eventstreamCodec.SmithyMessageDecoderStream({\n            messageStream: new eventstreamCodec.MessageDecoderStream({ inputStream, decoder: this.eventStreamCodec }),\n            deserializer: getMessageUnmarshaller(deserializer, this.utfEncoder),\n        });\n    }\n    serialize(inputStream, serializer) {\n        return new eventstreamCodec.MessageEncoderStream({\n            messageStream: new eventstreamCodec.SmithyMessageEncoderStream({ inputStream, serializer }),\n            encoder: this.eventStreamCodec,\n            includeEndFrame: true,\n        });\n    }\n}\n\nconst eventStreamSerdeProvider = (options) => new EventStreamMarshaller(options);\n\nexports.EventStreamMarshaller = EventStreamMarshaller;\nexports.eventStreamSerdeProvider = eventStreamSerdeProvider;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\nvar querystringBuilder = require('@smithy/querystring-builder');\nvar utilBase64 = require('@smithy/util-base64');\n\nfunction createRequest(url, requestOptions) {\n    return new Request(url, requestOptions);\n}\n\nfunction requestTimeout(timeoutInMs = 0) {\n    return new Promise((resolve, reject) => {\n        if (timeoutInMs) {\n            setTimeout(() => {\n                const timeoutError = new Error(`Request did not complete within ${timeoutInMs} ms`);\n                timeoutError.name = \"TimeoutError\";\n                reject(timeoutError);\n            }, timeoutInMs);\n        }\n    });\n}\n\nconst keepAliveSupport = {\n    supported: undefined,\n};\nclass FetchHttpHandler {\n    config;\n    configProvider;\n    static create(instanceOrOptions) {\n        if (typeof instanceOrOptions?.handle === \"function\") {\n            return instanceOrOptions;\n        }\n        return new FetchHttpHandler(instanceOrOptions);\n    }\n    constructor(options) {\n        if (typeof options === \"function\") {\n            this.configProvider = options().then((opts) => opts || {});\n        }\n        else {\n            this.config = options ?? {};\n            this.configProvider = Promise.resolve(this.config);\n        }\n        if (keepAliveSupport.supported === undefined) {\n            keepAliveSupport.supported = Boolean(typeof Request !== \"undefined\" && \"keepalive\" in createRequest(\"https://[::1]\"));\n        }\n    }\n    destroy() {\n    }\n    async handle(request, { abortSignal, requestTimeout: requestTimeout$1 } = {}) {\n        if (!this.config) {\n            this.config = await this.configProvider;\n        }\n        const requestTimeoutInMs = requestTimeout$1 ?? this.config.requestTimeout;\n        const keepAlive = this.config.keepAlive === true;\n        const credentials = this.config.credentials;\n        if (abortSignal?.aborted) {\n            const abortError = new Error(\"Request aborted\");\n            abortError.name = \"AbortError\";\n            return Promise.reject(abortError);\n        }\n        let path = request.path;\n        const queryString = querystringBuilder.buildQueryString(request.query || {});\n        if (queryString) {\n            path += `?${queryString}`;\n        }\n        if (request.fragment) {\n            path += `#${request.fragment}`;\n        }\n        let auth = \"\";\n        if (request.username != null || request.password != null) {\n            const username = request.username ?? \"\";\n            const password = request.password ?? \"\";\n            auth = `${username}:${password}@`;\n        }\n        const { port, method } = request;\n        const url = `${request.protocol}//${auth}${request.hostname}${port ? `:${port}` : \"\"}${path}`;\n        const body = method === \"GET\" || method === \"HEAD\" ? undefined : request.body;\n        const requestOptions = {\n            body,\n            headers: new Headers(request.headers),\n            method: method,\n            credentials,\n        };\n        if (this.config?.cache) {\n            requestOptions.cache = this.config.cache;\n        }\n        if (body) {\n            requestOptions.duplex = \"half\";\n        }\n        if (typeof AbortController !== \"undefined\") {\n            requestOptions.signal = abortSignal;\n        }\n        if (keepAliveSupport.supported) {\n            requestOptions.keepalive = keepAlive;\n        }\n        if (typeof this.config.requestInit === \"function\") {\n            Object.assign(requestOptions, this.config.requestInit(request));\n        }\n        let removeSignalEventListener = () => { };\n        const fetchRequest = createRequest(url, requestOptions);\n        const raceOfPromises = [\n            fetch(fetchRequest).then((response) => {\n                const fetchHeaders = response.headers;\n                const transformedHeaders = {};\n                for (const pair of fetchHeaders.entries()) {\n                    transformedHeaders[pair[0]] = pair[1];\n                }\n                const hasReadableStream = response.body != undefined;\n                if (!hasReadableStream) {\n                    return response.blob().then((body) => ({\n                        response: new protocolHttp.HttpResponse({\n                            headers: transformedHeaders,\n                            reason: response.statusText,\n                            statusCode: response.status,\n                            body,\n                        }),\n                    }));\n                }\n                return {\n                    response: new protocolHttp.HttpResponse({\n                        headers: transformedHeaders,\n                        reason: response.statusText,\n                        statusCode: response.status,\n                        body: response.body,\n                    }),\n                };\n            }),\n            requestTimeout(requestTimeoutInMs),\n        ];\n        if (abortSignal) {\n            raceOfPromises.push(new Promise((resolve, reject) => {\n                const onAbort = () => {\n                    const abortError = new Error(\"Request aborted\");\n                    abortError.name = \"AbortError\";\n                    reject(abortError);\n                };\n                if (typeof abortSignal.addEventListener === \"function\") {\n                    const signal = abortSignal;\n                    signal.addEventListener(\"abort\", onAbort, { once: true });\n                    removeSignalEventListener = () => signal.removeEventListener(\"abort\", onAbort);\n                }\n                else {\n                    abortSignal.onabort = onAbort;\n                }\n            }));\n        }\n        return Promise.race(raceOfPromises).finally(removeSignalEventListener);\n    }\n    updateHttpClientConfig(key, value) {\n        this.config = undefined;\n        this.configProvider = this.configProvider.then((config) => {\n            config[key] = value;\n            return config;\n        });\n    }\n    httpHandlerConfigs() {\n        return this.config ?? {};\n    }\n}\n\nconst streamCollector = async (stream) => {\n    if ((typeof Blob === \"function\" && stream instanceof Blob) || stream.constructor?.name === \"Blob\") {\n        if (Blob.prototype.arrayBuffer !== undefined) {\n            return new Uint8Array(await stream.arrayBuffer());\n        }\n        return collectBlob(stream);\n    }\n    return collectStream(stream);\n};\nasync function collectBlob(blob) {\n    const base64 = await readToBase64(blob);\n    const arrayBuffer = utilBase64.fromBase64(base64);\n    return new Uint8Array(arrayBuffer);\n}\nasync function collectStream(stream) {\n    const chunks = [];\n    const reader = stream.getReader();\n    let isDone = false;\n    let length = 0;\n    while (!isDone) {\n        const { done, value } = await reader.read();\n        if (value) {\n            chunks.push(value);\n            length += value.length;\n        }\n        isDone = done;\n    }\n    const collected = new Uint8Array(length);\n    let offset = 0;\n    for (const chunk of chunks) {\n        collected.set(chunk, offset);\n        offset += chunk.length;\n    }\n    return collected;\n}\nfunction readToBase64(blob) {\n    return new Promise((resolve, reject) => {\n        const reader = new FileReader();\n        reader.onloadend = () => {\n            if (reader.readyState !== 2) {\n                return reject(new Error(\"Reader aborted too early\"));\n            }\n            const result = (reader.result ?? \"\");\n            const commaIndex = result.indexOf(\",\");\n            const dataOffset = commaIndex > -1 ? commaIndex + 1 : result.length;\n            resolve(result.substring(dataOffset));\n        };\n        reader.onabort = () => reject(new Error(\"Read aborted\"));\n        reader.onerror = () => reject(reader.error);\n        reader.readAsDataURL(blob);\n    });\n}\n\nexports.FetchHttpHandler = FetchHttpHandler;\nexports.keepAliveSupport = keepAliveSupport;\nexports.streamCollector = streamCollector;\n","'use strict';\n\nvar utilBufferFrom = require('@smithy/util-buffer-from');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar buffer = require('buffer');\nvar crypto = require('crypto');\n\nclass Hash {\n    algorithmIdentifier;\n    secret;\n    hash;\n    constructor(algorithmIdentifier, secret) {\n        this.algorithmIdentifier = algorithmIdentifier;\n        this.secret = secret;\n        this.reset();\n    }\n    update(toHash, encoding) {\n        this.hash.update(utilUtf8.toUint8Array(castSourceData(toHash, encoding)));\n    }\n    digest() {\n        return Promise.resolve(this.hash.digest());\n    }\n    reset() {\n        this.hash = this.secret\n            ? crypto.createHmac(this.algorithmIdentifier, castSourceData(this.secret))\n            : crypto.createHash(this.algorithmIdentifier);\n    }\n}\nfunction castSourceData(toCast, encoding) {\n    if (buffer.Buffer.isBuffer(toCast)) {\n        return toCast;\n    }\n    if (typeof toCast === \"string\") {\n        return utilBufferFrom.fromString(toCast, encoding);\n    }\n    if (ArrayBuffer.isView(toCast)) {\n        return utilBufferFrom.fromArrayBuffer(toCast.buffer, toCast.byteOffset, toCast.byteLength);\n    }\n    return utilBufferFrom.fromArrayBuffer(toCast);\n}\n\nexports.Hash = Hash;\n","'use strict';\n\nvar fs = require('fs');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar stream = require('stream');\n\nclass HashCalculator extends stream.Writable {\n    hash;\n    constructor(hash, options) {\n        super(options);\n        this.hash = hash;\n    }\n    _write(chunk, encoding, callback) {\n        try {\n            this.hash.update(utilUtf8.toUint8Array(chunk));\n        }\n        catch (err) {\n            return callback(err);\n        }\n        callback();\n    }\n}\n\nconst fileStreamHasher = (hashCtor, fileStream) => new Promise((resolve, reject) => {\n    if (!isReadStream(fileStream)) {\n        reject(new Error(\"Unable to calculate hash for non-file streams.\"));\n        return;\n    }\n    const fileStreamTee = fs.createReadStream(fileStream.path, {\n        start: fileStream.start,\n        end: fileStream.end,\n    });\n    const hash = new hashCtor();\n    const hashCalculator = new HashCalculator(hash);\n    fileStreamTee.pipe(hashCalculator);\n    fileStreamTee.on(\"error\", (err) => {\n        hashCalculator.end();\n        reject(err);\n    });\n    hashCalculator.on(\"error\", reject);\n    hashCalculator.on(\"finish\", function () {\n        hash.digest().then(resolve).catch(reject);\n    });\n});\nconst isReadStream = (stream) => typeof stream.path === \"string\";\n\nconst readableStreamHasher = (hashCtor, readableStream) => {\n    if (readableStream.readableFlowing !== null) {\n        throw new Error(\"Unable to calculate hash for flowing readable stream\");\n    }\n    const hash = new hashCtor();\n    const hashCalculator = new HashCalculator(hash);\n    readableStream.pipe(hashCalculator);\n    return new Promise((resolve, reject) => {\n        readableStream.on(\"error\", (err) => {\n            hashCalculator.end();\n            reject(err);\n        });\n        hashCalculator.on(\"error\", reject);\n        hashCalculator.on(\"finish\", () => {\n            hash.digest().then(resolve).catch(reject);\n        });\n    });\n};\n\nexports.fileStreamHasher = fileStreamHasher;\nexports.readableStreamHasher = readableStreamHasher;\n","'use strict';\n\nconst isArrayBuffer = (arg) => (typeof ArrayBuffer === \"function\" && arg instanceof ArrayBuffer) ||\n    Object.prototype.toString.call(arg) === \"[object ArrayBuffer]\";\n\nexports.isArrayBuffer = isArrayBuffer;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\n\nconst CONTENT_LENGTH_HEADER = \"content-length\";\nfunction contentLengthMiddleware(bodyLengthChecker) {\n    return (next) => async (args) => {\n        const request = args.request;\n        if (protocolHttp.HttpRequest.isInstance(request)) {\n            const { body, headers } = request;\n            if (body &&\n                Object.keys(headers)\n                    .map((str) => str.toLowerCase())\n                    .indexOf(CONTENT_LENGTH_HEADER) === -1) {\n                try {\n                    const length = bodyLengthChecker(body);\n                    request.headers = {\n                        ...request.headers,\n                        [CONTENT_LENGTH_HEADER]: String(length),\n                    };\n                }\n                catch (error) {\n                }\n            }\n        }\n        return next({\n            ...args,\n            request,\n        });\n    };\n}\nconst contentLengthMiddlewareOptions = {\n    step: \"build\",\n    tags: [\"SET_CONTENT_LENGTH\", \"CONTENT_LENGTH\"],\n    name: \"contentLengthMiddleware\",\n    override: true,\n};\nconst getContentLengthPlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(contentLengthMiddleware(options.bodyLengthChecker), contentLengthMiddlewareOptions);\n    },\n});\n\nexports.contentLengthMiddleware = contentLengthMiddleware;\nexports.contentLengthMiddlewareOptions = contentLengthMiddlewareOptions;\nexports.getContentLengthPlugin = getContentLengthPlugin;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getEndpointFromConfig = void 0;\nconst node_config_provider_1 = require(\"@smithy/node-config-provider\");\nconst getEndpointUrlConfig_1 = require(\"./getEndpointUrlConfig\");\nconst getEndpointFromConfig = async (serviceId) => (0, node_config_provider_1.loadConfig)((0, getEndpointUrlConfig_1.getEndpointUrlConfig)(serviceId ?? \"\"))();\nexports.getEndpointFromConfig = getEndpointFromConfig;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getEndpointUrlConfig = void 0;\nconst shared_ini_file_loader_1 = require(\"@smithy/shared-ini-file-loader\");\nconst ENV_ENDPOINT_URL = \"AWS_ENDPOINT_URL\";\nconst CONFIG_ENDPOINT_URL = \"endpoint_url\";\nconst getEndpointUrlConfig = (serviceId) => ({\n    environmentVariableSelector: (env) => {\n        const serviceSuffixParts = serviceId.split(\" \").map((w) => w.toUpperCase());\n        const serviceEndpointUrl = env[[ENV_ENDPOINT_URL, ...serviceSuffixParts].join(\"_\")];\n        if (serviceEndpointUrl)\n            return serviceEndpointUrl;\n        const endpointUrl = env[ENV_ENDPOINT_URL];\n        if (endpointUrl)\n            return endpointUrl;\n        return undefined;\n    },\n    configFileSelector: (profile, config) => {\n        if (config && profile.services) {\n            const servicesSection = config[[\"services\", profile.services].join(shared_ini_file_loader_1.CONFIG_PREFIX_SEPARATOR)];\n            if (servicesSection) {\n                const servicePrefixParts = serviceId.split(\" \").map((w) => w.toLowerCase());\n                const endpointUrl = servicesSection[[servicePrefixParts.join(\"_\"), CONFIG_ENDPOINT_URL].join(shared_ini_file_loader_1.CONFIG_PREFIX_SEPARATOR)];\n                if (endpointUrl)\n                    return endpointUrl;\n            }\n        }\n        const endpointUrl = profile[CONFIG_ENDPOINT_URL];\n        if (endpointUrl)\n            return endpointUrl;\n        return undefined;\n    },\n    default: undefined,\n});\nexports.getEndpointUrlConfig = getEndpointUrlConfig;\n","'use strict';\n\nvar getEndpointFromConfig = require('./adaptors/getEndpointFromConfig');\nvar urlParser = require('@smithy/url-parser');\nvar core = require('@smithy/core');\nvar utilMiddleware = require('@smithy/util-middleware');\nvar middlewareSerde = require('@smithy/middleware-serde');\n\nconst resolveParamsForS3 = async (endpointParams) => {\n    const bucket = endpointParams?.Bucket || \"\";\n    if (typeof endpointParams.Bucket === \"string\") {\n        endpointParams.Bucket = bucket.replace(/#/g, encodeURIComponent(\"#\")).replace(/\\?/g, encodeURIComponent(\"?\"));\n    }\n    if (isArnBucketName(bucket)) {\n        if (endpointParams.ForcePathStyle === true) {\n            throw new Error(\"Path-style addressing cannot be used with ARN buckets\");\n        }\n    }\n    else if (!isDnsCompatibleBucketName(bucket) ||\n        (bucket.indexOf(\".\") !== -1 && !String(endpointParams.Endpoint).startsWith(\"http:\")) ||\n        bucket.toLowerCase() !== bucket ||\n        bucket.length < 3) {\n        endpointParams.ForcePathStyle = true;\n    }\n    if (endpointParams.DisableMultiRegionAccessPoints) {\n        endpointParams.disableMultiRegionAccessPoints = true;\n        endpointParams.DisableMRAP = true;\n    }\n    return endpointParams;\n};\nconst DOMAIN_PATTERN = /^[a-z0-9][a-z0-9\\.\\-]{1,61}[a-z0-9]$/;\nconst IP_ADDRESS_PATTERN = /(\\d+\\.){3}\\d+/;\nconst DOTS_PATTERN = /\\.\\./;\nconst isDnsCompatibleBucketName = (bucketName) => DOMAIN_PATTERN.test(bucketName) && !IP_ADDRESS_PATTERN.test(bucketName) && !DOTS_PATTERN.test(bucketName);\nconst isArnBucketName = (bucketName) => {\n    const [arn, partition, service, , , bucket] = bucketName.split(\":\");\n    const isArn = arn === \"arn\" && bucketName.split(\":\").length >= 6;\n    const isValidArn = Boolean(isArn && partition && service && bucket);\n    if (isArn && !isValidArn) {\n        throw new Error(`Invalid ARN: ${bucketName} was an invalid ARN.`);\n    }\n    return isValidArn;\n};\n\nconst createConfigValueProvider = (configKey, canonicalEndpointParamKey, config, isClientContextParam = false) => {\n    const configProvider = async () => {\n        let configValue;\n        if (isClientContextParam) {\n            const clientContextParams = config.clientContextParams;\n            const nestedValue = clientContextParams?.[configKey];\n            configValue = nestedValue ?? config[configKey] ?? config[canonicalEndpointParamKey];\n        }\n        else {\n            configValue = config[configKey] ?? config[canonicalEndpointParamKey];\n        }\n        if (typeof configValue === \"function\") {\n            return configValue();\n        }\n        return configValue;\n    };\n    if (configKey === \"credentialScope\" || canonicalEndpointParamKey === \"CredentialScope\") {\n        return async () => {\n            const credentials = typeof config.credentials === \"function\" ? await config.credentials() : config.credentials;\n            const configValue = credentials?.credentialScope ?? credentials?.CredentialScope;\n            return configValue;\n        };\n    }\n    if (configKey === \"accountId\" || canonicalEndpointParamKey === \"AccountId\") {\n        return async () => {\n            const credentials = typeof config.credentials === \"function\" ? await config.credentials() : config.credentials;\n            const configValue = credentials?.accountId ?? credentials?.AccountId;\n            return configValue;\n        };\n    }\n    if (configKey === \"endpoint\" || canonicalEndpointParamKey === \"endpoint\") {\n        return async () => {\n            if (config.isCustomEndpoint === false) {\n                return undefined;\n            }\n            const endpoint = await configProvider();\n            if (endpoint && typeof endpoint === \"object\") {\n                if (\"url\" in endpoint) {\n                    return endpoint.url.href;\n                }\n                if (\"hostname\" in endpoint) {\n                    const { protocol, hostname, port, path } = endpoint;\n                    return `${protocol}//${hostname}${port ? \":\" + port : \"\"}${path}`;\n                }\n            }\n            return endpoint;\n        };\n    }\n    return configProvider;\n};\n\nconst toEndpointV1 = (endpoint) => {\n    if (typeof endpoint === \"object\") {\n        if (\"url\" in endpoint) {\n            return urlParser.parseUrl(endpoint.url);\n        }\n        return endpoint;\n    }\n    return urlParser.parseUrl(endpoint);\n};\n\nconst getEndpointFromInstructions = async (commandInput, instructionsSupplier, clientConfig, context) => {\n    if (!clientConfig.isCustomEndpoint) {\n        let endpointFromConfig;\n        if (clientConfig.serviceConfiguredEndpoint) {\n            endpointFromConfig = await clientConfig.serviceConfiguredEndpoint();\n        }\n        else {\n            endpointFromConfig = await getEndpointFromConfig.getEndpointFromConfig(clientConfig.serviceId);\n        }\n        if (endpointFromConfig) {\n            clientConfig.endpoint = () => Promise.resolve(toEndpointV1(endpointFromConfig));\n            clientConfig.isCustomEndpoint = true;\n        }\n    }\n    const endpointParams = await resolveParams(commandInput, instructionsSupplier, clientConfig);\n    if (typeof clientConfig.endpointProvider !== \"function\") {\n        throw new Error(\"config.endpointProvider is not set.\");\n    }\n    const endpoint = clientConfig.endpointProvider(endpointParams, context);\n    return endpoint;\n};\nconst resolveParams = async (commandInput, instructionsSupplier, clientConfig) => {\n    const endpointParams = {};\n    const instructions = instructionsSupplier?.getEndpointParameterInstructions?.() || {};\n    for (const [name, instruction] of Object.entries(instructions)) {\n        switch (instruction.type) {\n            case \"staticContextParams\":\n                endpointParams[name] = instruction.value;\n                break;\n            case \"contextParams\":\n                endpointParams[name] = commandInput[instruction.name];\n                break;\n            case \"clientContextParams\":\n            case \"builtInParams\":\n                endpointParams[name] = await createConfigValueProvider(instruction.name, name, clientConfig, instruction.type !== \"builtInParams\")();\n                break;\n            case \"operationContextParams\":\n                endpointParams[name] = instruction.get(commandInput);\n                break;\n            default:\n                throw new Error(\"Unrecognized endpoint parameter instruction: \" + JSON.stringify(instruction));\n        }\n    }\n    if (Object.keys(instructions).length === 0) {\n        Object.assign(endpointParams, clientConfig);\n    }\n    if (String(clientConfig.serviceId).toLowerCase() === \"s3\") {\n        await resolveParamsForS3(endpointParams);\n    }\n    return endpointParams;\n};\n\nconst endpointMiddleware = ({ config, instructions, }) => {\n    return (next, context) => async (args) => {\n        if (config.isCustomEndpoint) {\n            core.setFeature(context, \"ENDPOINT_OVERRIDE\", \"N\");\n        }\n        const endpoint = await getEndpointFromInstructions(args.input, {\n            getEndpointParameterInstructions() {\n                return instructions;\n            },\n        }, { ...config }, context);\n        context.endpointV2 = endpoint;\n        context.authSchemes = endpoint.properties?.authSchemes;\n        const authScheme = context.authSchemes?.[0];\n        if (authScheme) {\n            context[\"signing_region\"] = authScheme.signingRegion;\n            context[\"signing_service\"] = authScheme.signingName;\n            const smithyContext = utilMiddleware.getSmithyContext(context);\n            const httpAuthOption = smithyContext?.selectedHttpAuthScheme?.httpAuthOption;\n            if (httpAuthOption) {\n                httpAuthOption.signingProperties = Object.assign(httpAuthOption.signingProperties || {}, {\n                    signing_region: authScheme.signingRegion,\n                    signingRegion: authScheme.signingRegion,\n                    signing_service: authScheme.signingName,\n                    signingName: authScheme.signingName,\n                    signingRegionSet: authScheme.signingRegionSet,\n                }, authScheme.properties);\n            }\n        }\n        return next({\n            ...args,\n        });\n    };\n};\n\nconst endpointMiddlewareOptions = {\n    step: \"serialize\",\n    tags: [\"ENDPOINT_PARAMETERS\", \"ENDPOINT_V2\", \"ENDPOINT\"],\n    name: \"endpointV2Middleware\",\n    override: true,\n    relation: \"before\",\n    toMiddleware: middlewareSerde.serializerMiddlewareOption.name,\n};\nconst getEndpointPlugin = (config, instructions) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(endpointMiddleware({\n            config,\n            instructions,\n        }), endpointMiddlewareOptions);\n    },\n});\n\nconst resolveEndpointConfig = (input) => {\n    const tls = input.tls ?? true;\n    const { endpoint, useDualstackEndpoint, useFipsEndpoint } = input;\n    const customEndpointProvider = endpoint != null ? async () => toEndpointV1(await utilMiddleware.normalizeProvider(endpoint)()) : undefined;\n    const isCustomEndpoint = !!endpoint;\n    const resolvedConfig = Object.assign(input, {\n        endpoint: customEndpointProvider,\n        tls,\n        isCustomEndpoint,\n        useDualstackEndpoint: utilMiddleware.normalizeProvider(useDualstackEndpoint ?? false),\n        useFipsEndpoint: utilMiddleware.normalizeProvider(useFipsEndpoint ?? false),\n    });\n    let configuredEndpointPromise = undefined;\n    resolvedConfig.serviceConfiguredEndpoint = async () => {\n        if (input.serviceId && !configuredEndpointPromise) {\n            configuredEndpointPromise = getEndpointFromConfig.getEndpointFromConfig(input.serviceId);\n        }\n        return configuredEndpointPromise;\n    };\n    return resolvedConfig;\n};\n\nconst resolveEndpointRequiredConfig = (input) => {\n    const { endpoint } = input;\n    if (endpoint === undefined) {\n        input.endpoint = async () => {\n            throw new Error(\"@smithy/middleware-endpoint: (default endpointRuleSet) endpoint is not set - you must configure an endpoint.\");\n        };\n    }\n    return input;\n};\n\nexports.endpointMiddleware = endpointMiddleware;\nexports.endpointMiddlewareOptions = endpointMiddlewareOptions;\nexports.getEndpointFromInstructions = getEndpointFromInstructions;\nexports.getEndpointPlugin = getEndpointPlugin;\nexports.resolveEndpointConfig = resolveEndpointConfig;\nexports.resolveEndpointRequiredConfig = resolveEndpointRequiredConfig;\nexports.resolveParams = resolveParams;\nexports.toEndpointV1 = toEndpointV1;\n","'use strict';\n\nvar utilRetry = require('@smithy/util-retry');\nvar protocolHttp = require('@smithy/protocol-http');\nvar serviceErrorClassification = require('@smithy/service-error-classification');\nvar uuid = require('@smithy/uuid');\nvar utilMiddleware = require('@smithy/util-middleware');\nvar smithyClient = require('@smithy/smithy-client');\nvar isStreamingPayload = require('./isStreamingPayload/isStreamingPayload');\n\nconst getDefaultRetryQuota = (initialRetryTokens, options) => {\n    const MAX_CAPACITY = initialRetryTokens;\n    const noRetryIncrement = utilRetry.NO_RETRY_INCREMENT;\n    const retryCost = utilRetry.RETRY_COST;\n    const timeoutRetryCost = utilRetry.TIMEOUT_RETRY_COST;\n    let availableCapacity = initialRetryTokens;\n    const getCapacityAmount = (error) => (error.name === \"TimeoutError\" ? timeoutRetryCost : retryCost);\n    const hasRetryTokens = (error) => getCapacityAmount(error) <= availableCapacity;\n    const retrieveRetryTokens = (error) => {\n        if (!hasRetryTokens(error)) {\n            throw new Error(\"No retry token available\");\n        }\n        const capacityAmount = getCapacityAmount(error);\n        availableCapacity -= capacityAmount;\n        return capacityAmount;\n    };\n    const releaseRetryTokens = (capacityReleaseAmount) => {\n        availableCapacity += capacityReleaseAmount ?? noRetryIncrement;\n        availableCapacity = Math.min(availableCapacity, MAX_CAPACITY);\n    };\n    return Object.freeze({\n        hasRetryTokens,\n        retrieveRetryTokens,\n        releaseRetryTokens,\n    });\n};\n\nconst defaultDelayDecider = (delayBase, attempts) => Math.floor(Math.min(utilRetry.MAXIMUM_RETRY_DELAY, Math.random() * 2 ** attempts * delayBase));\n\nconst defaultRetryDecider = (error) => {\n    if (!error) {\n        return false;\n    }\n    return serviceErrorClassification.isRetryableByTrait(error) || serviceErrorClassification.isClockSkewError(error) || serviceErrorClassification.isThrottlingError(error) || serviceErrorClassification.isTransientError(error);\n};\n\nconst asSdkError = (error) => {\n    if (error instanceof Error)\n        return error;\n    if (error instanceof Object)\n        return Object.assign(new Error(), error);\n    if (typeof error === \"string\")\n        return new Error(error);\n    return new Error(`AWS SDK error wrapper for ${error}`);\n};\n\nclass StandardRetryStrategy {\n    maxAttemptsProvider;\n    retryDecider;\n    delayDecider;\n    retryQuota;\n    mode = utilRetry.RETRY_MODES.STANDARD;\n    constructor(maxAttemptsProvider, options) {\n        this.maxAttemptsProvider = maxAttemptsProvider;\n        this.retryDecider = options?.retryDecider ?? defaultRetryDecider;\n        this.delayDecider = options?.delayDecider ?? defaultDelayDecider;\n        this.retryQuota = options?.retryQuota ?? getDefaultRetryQuota(utilRetry.INITIAL_RETRY_TOKENS);\n    }\n    shouldRetry(error, attempts, maxAttempts) {\n        return attempts < maxAttempts && this.retryDecider(error) && this.retryQuota.hasRetryTokens(error);\n    }\n    async getMaxAttempts() {\n        let maxAttempts;\n        try {\n            maxAttempts = await this.maxAttemptsProvider();\n        }\n        catch (error) {\n            maxAttempts = utilRetry.DEFAULT_MAX_ATTEMPTS;\n        }\n        return maxAttempts;\n    }\n    async retry(next, args, options) {\n        let retryTokenAmount;\n        let attempts = 0;\n        let totalDelay = 0;\n        const maxAttempts = await this.getMaxAttempts();\n        const { request } = args;\n        if (protocolHttp.HttpRequest.isInstance(request)) {\n            request.headers[utilRetry.INVOCATION_ID_HEADER] = uuid.v4();\n        }\n        while (true) {\n            try {\n                if (protocolHttp.HttpRequest.isInstance(request)) {\n                    request.headers[utilRetry.REQUEST_HEADER] = `attempt=${attempts + 1}; max=${maxAttempts}`;\n                }\n                if (options?.beforeRequest) {\n                    await options.beforeRequest();\n                }\n                const { response, output } = await next(args);\n                if (options?.afterRequest) {\n                    options.afterRequest(response);\n                }\n                this.retryQuota.releaseRetryTokens(retryTokenAmount);\n                output.$metadata.attempts = attempts + 1;\n                output.$metadata.totalRetryDelay = totalDelay;\n                return { response, output };\n            }\n            catch (e) {\n                const err = asSdkError(e);\n                attempts++;\n                if (this.shouldRetry(err, attempts, maxAttempts)) {\n                    retryTokenAmount = this.retryQuota.retrieveRetryTokens(err);\n                    const delayFromDecider = this.delayDecider(serviceErrorClassification.isThrottlingError(err) ? utilRetry.THROTTLING_RETRY_DELAY_BASE : utilRetry.DEFAULT_RETRY_DELAY_BASE, attempts);\n                    const delayFromResponse = getDelayFromRetryAfterHeader(err.$response);\n                    const delay = Math.max(delayFromResponse || 0, delayFromDecider);\n                    totalDelay += delay;\n                    await new Promise((resolve) => setTimeout(resolve, delay));\n                    continue;\n                }\n                if (!err.$metadata) {\n                    err.$metadata = {};\n                }\n                err.$metadata.attempts = attempts;\n                err.$metadata.totalRetryDelay = totalDelay;\n                throw err;\n            }\n        }\n    }\n}\nconst getDelayFromRetryAfterHeader = (response) => {\n    if (!protocolHttp.HttpResponse.isInstance(response))\n        return;\n    const retryAfterHeaderName = Object.keys(response.headers).find((key) => key.toLowerCase() === \"retry-after\");\n    if (!retryAfterHeaderName)\n        return;\n    const retryAfter = response.headers[retryAfterHeaderName];\n    const retryAfterSeconds = Number(retryAfter);\n    if (!Number.isNaN(retryAfterSeconds))\n        return retryAfterSeconds * 1000;\n    const retryAfterDate = new Date(retryAfter);\n    return retryAfterDate.getTime() - Date.now();\n};\n\nclass AdaptiveRetryStrategy extends StandardRetryStrategy {\n    rateLimiter;\n    constructor(maxAttemptsProvider, options) {\n        const { rateLimiter, ...superOptions } = options ?? {};\n        super(maxAttemptsProvider, superOptions);\n        this.rateLimiter = rateLimiter ?? new utilRetry.DefaultRateLimiter();\n        this.mode = utilRetry.RETRY_MODES.ADAPTIVE;\n    }\n    async retry(next, args) {\n        return super.retry(next, args, {\n            beforeRequest: async () => {\n                return this.rateLimiter.getSendToken();\n            },\n            afterRequest: (response) => {\n                this.rateLimiter.updateClientSendingRate(response);\n            },\n        });\n    }\n}\n\nconst ENV_MAX_ATTEMPTS = \"AWS_MAX_ATTEMPTS\";\nconst CONFIG_MAX_ATTEMPTS = \"max_attempts\";\nconst NODE_MAX_ATTEMPT_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => {\n        const value = env[ENV_MAX_ATTEMPTS];\n        if (!value)\n            return undefined;\n        const maxAttempt = parseInt(value);\n        if (Number.isNaN(maxAttempt)) {\n            throw new Error(`Environment variable ${ENV_MAX_ATTEMPTS} mast be a number, got \"${value}\"`);\n        }\n        return maxAttempt;\n    },\n    configFileSelector: (profile) => {\n        const value = profile[CONFIG_MAX_ATTEMPTS];\n        if (!value)\n            return undefined;\n        const maxAttempt = parseInt(value);\n        if (Number.isNaN(maxAttempt)) {\n            throw new Error(`Shared config file entry ${CONFIG_MAX_ATTEMPTS} mast be a number, got \"${value}\"`);\n        }\n        return maxAttempt;\n    },\n    default: utilRetry.DEFAULT_MAX_ATTEMPTS,\n};\nconst resolveRetryConfig = (input) => {\n    const { retryStrategy, retryMode: _retryMode, maxAttempts: _maxAttempts } = input;\n    const maxAttempts = utilMiddleware.normalizeProvider(_maxAttempts ?? utilRetry.DEFAULT_MAX_ATTEMPTS);\n    return Object.assign(input, {\n        maxAttempts,\n        retryStrategy: async () => {\n            if (retryStrategy) {\n                return retryStrategy;\n            }\n            const retryMode = await utilMiddleware.normalizeProvider(_retryMode)();\n            if (retryMode === utilRetry.RETRY_MODES.ADAPTIVE) {\n                return new utilRetry.AdaptiveRetryStrategy(maxAttempts);\n            }\n            return new utilRetry.StandardRetryStrategy(maxAttempts);\n        },\n    });\n};\nconst ENV_RETRY_MODE = \"AWS_RETRY_MODE\";\nconst CONFIG_RETRY_MODE = \"retry_mode\";\nconst NODE_RETRY_MODE_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => env[ENV_RETRY_MODE],\n    configFileSelector: (profile) => profile[CONFIG_RETRY_MODE],\n    default: utilRetry.DEFAULT_RETRY_MODE,\n};\n\nconst omitRetryHeadersMiddleware = () => (next) => async (args) => {\n    const { request } = args;\n    if (protocolHttp.HttpRequest.isInstance(request)) {\n        delete request.headers[utilRetry.INVOCATION_ID_HEADER];\n        delete request.headers[utilRetry.REQUEST_HEADER];\n    }\n    return next(args);\n};\nconst omitRetryHeadersMiddlewareOptions = {\n    name: \"omitRetryHeadersMiddleware\",\n    tags: [\"RETRY\", \"HEADERS\", \"OMIT_RETRY_HEADERS\"],\n    relation: \"before\",\n    toMiddleware: \"awsAuthMiddleware\",\n    override: true,\n};\nconst getOmitRetryHeadersPlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.addRelativeTo(omitRetryHeadersMiddleware(), omitRetryHeadersMiddlewareOptions);\n    },\n});\n\nconst retryMiddleware = (options) => (next, context) => async (args) => {\n    let retryStrategy = await options.retryStrategy();\n    const maxAttempts = await options.maxAttempts();\n    if (isRetryStrategyV2(retryStrategy)) {\n        retryStrategy = retryStrategy;\n        let retryToken = await retryStrategy.acquireInitialRetryToken(context[\"partition_id\"]);\n        let lastError = new Error();\n        let attempts = 0;\n        let totalRetryDelay = 0;\n        const { request } = args;\n        const isRequest = protocolHttp.HttpRequest.isInstance(request);\n        if (isRequest) {\n            request.headers[utilRetry.INVOCATION_ID_HEADER] = uuid.v4();\n        }\n        while (true) {\n            try {\n                if (isRequest) {\n                    request.headers[utilRetry.REQUEST_HEADER] = `attempt=${attempts + 1}; max=${maxAttempts}`;\n                }\n                const { response, output } = await next(args);\n                retryStrategy.recordSuccess(retryToken);\n                output.$metadata.attempts = attempts + 1;\n                output.$metadata.totalRetryDelay = totalRetryDelay;\n                return { response, output };\n            }\n            catch (e) {\n                const retryErrorInfo = getRetryErrorInfo(e);\n                lastError = asSdkError(e);\n                if (isRequest && isStreamingPayload.isStreamingPayload(request)) {\n                    (context.logger instanceof smithyClient.NoOpLogger ? console : context.logger)?.warn(\"An error was encountered in a non-retryable streaming request.\");\n                    throw lastError;\n                }\n                try {\n                    retryToken = await retryStrategy.refreshRetryTokenForRetry(retryToken, retryErrorInfo);\n                }\n                catch (refreshError) {\n                    if (!lastError.$metadata) {\n                        lastError.$metadata = {};\n                    }\n                    lastError.$metadata.attempts = attempts + 1;\n                    lastError.$metadata.totalRetryDelay = totalRetryDelay;\n                    throw lastError;\n                }\n                attempts = retryToken.getRetryCount();\n                const delay = retryToken.getRetryDelay();\n                totalRetryDelay += delay;\n                await new Promise((resolve) => setTimeout(resolve, delay));\n            }\n        }\n    }\n    else {\n        retryStrategy = retryStrategy;\n        if (retryStrategy?.mode)\n            context.userAgent = [...(context.userAgent || []), [\"cfg/retry-mode\", retryStrategy.mode]];\n        return retryStrategy.retry(next, args);\n    }\n};\nconst isRetryStrategyV2 = (retryStrategy) => typeof retryStrategy.acquireInitialRetryToken !== \"undefined\" &&\n    typeof retryStrategy.refreshRetryTokenForRetry !== \"undefined\" &&\n    typeof retryStrategy.recordSuccess !== \"undefined\";\nconst getRetryErrorInfo = (error) => {\n    const errorInfo = {\n        error,\n        errorType: getRetryErrorType(error),\n    };\n    const retryAfterHint = getRetryAfterHint(error.$response);\n    if (retryAfterHint) {\n        errorInfo.retryAfterHint = retryAfterHint;\n    }\n    return errorInfo;\n};\nconst getRetryErrorType = (error) => {\n    if (serviceErrorClassification.isThrottlingError(error))\n        return \"THROTTLING\";\n    if (serviceErrorClassification.isTransientError(error))\n        return \"TRANSIENT\";\n    if (serviceErrorClassification.isServerError(error))\n        return \"SERVER_ERROR\";\n    return \"CLIENT_ERROR\";\n};\nconst retryMiddlewareOptions = {\n    name: \"retryMiddleware\",\n    tags: [\"RETRY\"],\n    step: \"finalizeRequest\",\n    priority: \"high\",\n    override: true,\n};\nconst getRetryPlugin = (options) => ({\n    applyToStack: (clientStack) => {\n        clientStack.add(retryMiddleware(options), retryMiddlewareOptions);\n    },\n});\nconst getRetryAfterHint = (response) => {\n    if (!protocolHttp.HttpResponse.isInstance(response))\n        return;\n    const retryAfterHeaderName = Object.keys(response.headers).find((key) => key.toLowerCase() === \"retry-after\");\n    if (!retryAfterHeaderName)\n        return;\n    const retryAfter = response.headers[retryAfterHeaderName];\n    const retryAfterSeconds = Number(retryAfter);\n    if (!Number.isNaN(retryAfterSeconds))\n        return new Date(retryAfterSeconds * 1000);\n    const retryAfterDate = new Date(retryAfter);\n    return retryAfterDate;\n};\n\nexports.AdaptiveRetryStrategy = AdaptiveRetryStrategy;\nexports.CONFIG_MAX_ATTEMPTS = CONFIG_MAX_ATTEMPTS;\nexports.CONFIG_RETRY_MODE = CONFIG_RETRY_MODE;\nexports.ENV_MAX_ATTEMPTS = ENV_MAX_ATTEMPTS;\nexports.ENV_RETRY_MODE = ENV_RETRY_MODE;\nexports.NODE_MAX_ATTEMPT_CONFIG_OPTIONS = NODE_MAX_ATTEMPT_CONFIG_OPTIONS;\nexports.NODE_RETRY_MODE_CONFIG_OPTIONS = NODE_RETRY_MODE_CONFIG_OPTIONS;\nexports.StandardRetryStrategy = StandardRetryStrategy;\nexports.defaultDelayDecider = defaultDelayDecider;\nexports.defaultRetryDecider = defaultRetryDecider;\nexports.getOmitRetryHeadersPlugin = getOmitRetryHeadersPlugin;\nexports.getRetryAfterHint = getRetryAfterHint;\nexports.getRetryPlugin = getRetryPlugin;\nexports.omitRetryHeadersMiddleware = omitRetryHeadersMiddleware;\nexports.omitRetryHeadersMiddlewareOptions = omitRetryHeadersMiddlewareOptions;\nexports.resolveRetryConfig = resolveRetryConfig;\nexports.retryMiddleware = retryMiddleware;\nexports.retryMiddlewareOptions = retryMiddlewareOptions;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.isStreamingPayload = void 0;\nconst stream_1 = require(\"stream\");\nconst isStreamingPayload = (request) => request?.body instanceof stream_1.Readable ||\n    (typeof ReadableStream !== \"undefined\" && request?.body instanceof ReadableStream);\nexports.isStreamingPayload = isStreamingPayload;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\n\nconst deserializerMiddleware = (options, deserializer) => (next, context) => async (args) => {\n    const { response } = await next(args);\n    try {\n        const parsed = await deserializer(response, options);\n        return {\n            response,\n            output: parsed,\n        };\n    }\n    catch (error) {\n        Object.defineProperty(error, \"$response\", {\n            value: response,\n            enumerable: false,\n            writable: false,\n            configurable: false,\n        });\n        if (!(\"$metadata\" in error)) {\n            const hint = `Deserialization error: to see the raw response, inspect the hidden field {error}.$response on this object.`;\n            try {\n                error.message += \"\\n  \" + hint;\n            }\n            catch (e) {\n                if (!context.logger || context.logger?.constructor?.name === \"NoOpLogger\") {\n                    console.warn(hint);\n                }\n                else {\n                    context.logger?.warn?.(hint);\n                }\n            }\n            if (typeof error.$responseBodyText !== \"undefined\") {\n                if (error.$response) {\n                    error.$response.body = error.$responseBodyText;\n                }\n            }\n            try {\n                if (protocolHttp.HttpResponse.isInstance(response)) {\n                    const { headers = {} } = response;\n                    const headerEntries = Object.entries(headers);\n                    error.$metadata = {\n                        httpStatusCode: response.statusCode,\n                        requestId: findHeader(/^x-[\\w-]+-request-?id$/, headerEntries),\n                        extendedRequestId: findHeader(/^x-[\\w-]+-id-2$/, headerEntries),\n                        cfId: findHeader(/^x-[\\w-]+-cf-id$/, headerEntries),\n                    };\n                }\n            }\n            catch (e) {\n            }\n        }\n        throw error;\n    }\n};\nconst findHeader = (pattern, headers) => {\n    return (headers.find(([k]) => {\n        return k.match(pattern);\n    }) || [void 0, void 0])[1];\n};\n\nconst serializerMiddleware = (options, serializer) => (next, context) => async (args) => {\n    const endpointConfig = options;\n    const endpoint = context.endpointV2?.url && endpointConfig.urlParser\n        ? async () => endpointConfig.urlParser(context.endpointV2.url)\n        : endpointConfig.endpoint;\n    if (!endpoint) {\n        throw new Error(\"No valid endpoint provider available.\");\n    }\n    const request = await serializer(args.input, { ...options, endpoint });\n    return next({\n        ...args,\n        request,\n    });\n};\n\nconst deserializerMiddlewareOption = {\n    name: \"deserializerMiddleware\",\n    step: \"deserialize\",\n    tags: [\"DESERIALIZER\"],\n    override: true,\n};\nconst serializerMiddlewareOption = {\n    name: \"serializerMiddleware\",\n    step: \"serialize\",\n    tags: [\"SERIALIZER\"],\n    override: true,\n};\nfunction getSerdePlugin(config, serializer, deserializer) {\n    return {\n        applyToStack: (commandStack) => {\n            commandStack.add(deserializerMiddleware(config, deserializer), deserializerMiddlewareOption);\n            commandStack.add(serializerMiddleware(config, serializer), serializerMiddlewareOption);\n        },\n    };\n}\n\nexports.deserializerMiddleware = deserializerMiddleware;\nexports.deserializerMiddlewareOption = deserializerMiddlewareOption;\nexports.getSerdePlugin = getSerdePlugin;\nexports.serializerMiddleware = serializerMiddleware;\nexports.serializerMiddlewareOption = serializerMiddlewareOption;\n","'use strict';\n\nconst getAllAliases = (name, aliases) => {\n    const _aliases = [];\n    if (name) {\n        _aliases.push(name);\n    }\n    if (aliases) {\n        for (const alias of aliases) {\n            _aliases.push(alias);\n        }\n    }\n    return _aliases;\n};\nconst getMiddlewareNameWithAliases = (name, aliases) => {\n    return `${name || \"anonymous\"}${aliases && aliases.length > 0 ? ` (a.k.a. ${aliases.join(\",\")})` : \"\"}`;\n};\nconst constructStack = () => {\n    let absoluteEntries = [];\n    let relativeEntries = [];\n    let identifyOnResolve = false;\n    const entriesNameSet = new Set();\n    const sort = (entries) => entries.sort((a, b) => stepWeights[b.step] - stepWeights[a.step] ||\n        priorityWeights[b.priority || \"normal\"] - priorityWeights[a.priority || \"normal\"]);\n    const removeByName = (toRemove) => {\n        let isRemoved = false;\n        const filterCb = (entry) => {\n            const aliases = getAllAliases(entry.name, entry.aliases);\n            if (aliases.includes(toRemove)) {\n                isRemoved = true;\n                for (const alias of aliases) {\n                    entriesNameSet.delete(alias);\n                }\n                return false;\n            }\n            return true;\n        };\n        absoluteEntries = absoluteEntries.filter(filterCb);\n        relativeEntries = relativeEntries.filter(filterCb);\n        return isRemoved;\n    };\n    const removeByReference = (toRemove) => {\n        let isRemoved = false;\n        const filterCb = (entry) => {\n            if (entry.middleware === toRemove) {\n                isRemoved = true;\n                for (const alias of getAllAliases(entry.name, entry.aliases)) {\n                    entriesNameSet.delete(alias);\n                }\n                return false;\n            }\n            return true;\n        };\n        absoluteEntries = absoluteEntries.filter(filterCb);\n        relativeEntries = relativeEntries.filter(filterCb);\n        return isRemoved;\n    };\n    const cloneTo = (toStack) => {\n        absoluteEntries.forEach((entry) => {\n            toStack.add(entry.middleware, { ...entry });\n        });\n        relativeEntries.forEach((entry) => {\n            toStack.addRelativeTo(entry.middleware, { ...entry });\n        });\n        toStack.identifyOnResolve?.(stack.identifyOnResolve());\n        return toStack;\n    };\n    const expandRelativeMiddlewareList = (from) => {\n        const expandedMiddlewareList = [];\n        from.before.forEach((entry) => {\n            if (entry.before.length === 0 && entry.after.length === 0) {\n                expandedMiddlewareList.push(entry);\n            }\n            else {\n                expandedMiddlewareList.push(...expandRelativeMiddlewareList(entry));\n            }\n        });\n        expandedMiddlewareList.push(from);\n        from.after.reverse().forEach((entry) => {\n            if (entry.before.length === 0 && entry.after.length === 0) {\n                expandedMiddlewareList.push(entry);\n            }\n            else {\n                expandedMiddlewareList.push(...expandRelativeMiddlewareList(entry));\n            }\n        });\n        return expandedMiddlewareList;\n    };\n    const getMiddlewareList = (debug = false) => {\n        const normalizedAbsoluteEntries = [];\n        const normalizedRelativeEntries = [];\n        const normalizedEntriesNameMap = {};\n        absoluteEntries.forEach((entry) => {\n            const normalizedEntry = {\n                ...entry,\n                before: [],\n                after: [],\n            };\n            for (const alias of getAllAliases(normalizedEntry.name, normalizedEntry.aliases)) {\n                normalizedEntriesNameMap[alias] = normalizedEntry;\n            }\n            normalizedAbsoluteEntries.push(normalizedEntry);\n        });\n        relativeEntries.forEach((entry) => {\n            const normalizedEntry = {\n                ...entry,\n                before: [],\n                after: [],\n            };\n            for (const alias of getAllAliases(normalizedEntry.name, normalizedEntry.aliases)) {\n                normalizedEntriesNameMap[alias] = normalizedEntry;\n            }\n            normalizedRelativeEntries.push(normalizedEntry);\n        });\n        normalizedRelativeEntries.forEach((entry) => {\n            if (entry.toMiddleware) {\n                const toMiddleware = normalizedEntriesNameMap[entry.toMiddleware];\n                if (toMiddleware === undefined) {\n                    if (debug) {\n                        return;\n                    }\n                    throw new Error(`${entry.toMiddleware} is not found when adding ` +\n                        `${getMiddlewareNameWithAliases(entry.name, entry.aliases)} ` +\n                        `middleware ${entry.relation} ${entry.toMiddleware}`);\n                }\n                if (entry.relation === \"after\") {\n                    toMiddleware.after.push(entry);\n                }\n                if (entry.relation === \"before\") {\n                    toMiddleware.before.push(entry);\n                }\n            }\n        });\n        const mainChain = sort(normalizedAbsoluteEntries)\n            .map(expandRelativeMiddlewareList)\n            .reduce((wholeList, expandedMiddlewareList) => {\n            wholeList.push(...expandedMiddlewareList);\n            return wholeList;\n        }, []);\n        return mainChain;\n    };\n    const stack = {\n        add: (middleware, options = {}) => {\n            const { name, override, aliases: _aliases } = options;\n            const entry = {\n                step: \"initialize\",\n                priority: \"normal\",\n                middleware,\n                ...options,\n            };\n            const aliases = getAllAliases(name, _aliases);\n            if (aliases.length > 0) {\n                if (aliases.some((alias) => entriesNameSet.has(alias))) {\n                    if (!override)\n                        throw new Error(`Duplicate middleware name '${getMiddlewareNameWithAliases(name, _aliases)}'`);\n                    for (const alias of aliases) {\n                        const toOverrideIndex = absoluteEntries.findIndex((entry) => entry.name === alias || entry.aliases?.some((a) => a === alias));\n                        if (toOverrideIndex === -1) {\n                            continue;\n                        }\n                        const toOverride = absoluteEntries[toOverrideIndex];\n                        if (toOverride.step !== entry.step || entry.priority !== toOverride.priority) {\n                            throw new Error(`\"${getMiddlewareNameWithAliases(toOverride.name, toOverride.aliases)}\" middleware with ` +\n                                `${toOverride.priority} priority in ${toOverride.step} step cannot ` +\n                                `be overridden by \"${getMiddlewareNameWithAliases(name, _aliases)}\" middleware with ` +\n                                `${entry.priority} priority in ${entry.step} step.`);\n                        }\n                        absoluteEntries.splice(toOverrideIndex, 1);\n                    }\n                }\n                for (const alias of aliases) {\n                    entriesNameSet.add(alias);\n                }\n            }\n            absoluteEntries.push(entry);\n        },\n        addRelativeTo: (middleware, options) => {\n            const { name, override, aliases: _aliases } = options;\n            const entry = {\n                middleware,\n                ...options,\n            };\n            const aliases = getAllAliases(name, _aliases);\n            if (aliases.length > 0) {\n                if (aliases.some((alias) => entriesNameSet.has(alias))) {\n                    if (!override)\n                        throw new Error(`Duplicate middleware name '${getMiddlewareNameWithAliases(name, _aliases)}'`);\n                    for (const alias of aliases) {\n                        const toOverrideIndex = relativeEntries.findIndex((entry) => entry.name === alias || entry.aliases?.some((a) => a === alias));\n                        if (toOverrideIndex === -1) {\n                            continue;\n                        }\n                        const toOverride = relativeEntries[toOverrideIndex];\n                        if (toOverride.toMiddleware !== entry.toMiddleware || toOverride.relation !== entry.relation) {\n                            throw new Error(`\"${getMiddlewareNameWithAliases(toOverride.name, toOverride.aliases)}\" middleware ` +\n                                `${toOverride.relation} \"${toOverride.toMiddleware}\" middleware cannot be overridden ` +\n                                `by \"${getMiddlewareNameWithAliases(name, _aliases)}\" middleware ${entry.relation} ` +\n                                `\"${entry.toMiddleware}\" middleware.`);\n                        }\n                        relativeEntries.splice(toOverrideIndex, 1);\n                    }\n                }\n                for (const alias of aliases) {\n                    entriesNameSet.add(alias);\n                }\n            }\n            relativeEntries.push(entry);\n        },\n        clone: () => cloneTo(constructStack()),\n        use: (plugin) => {\n            plugin.applyToStack(stack);\n        },\n        remove: (toRemove) => {\n            if (typeof toRemove === \"string\")\n                return removeByName(toRemove);\n            else\n                return removeByReference(toRemove);\n        },\n        removeByTag: (toRemove) => {\n            let isRemoved = false;\n            const filterCb = (entry) => {\n                const { tags, name, aliases: _aliases } = entry;\n                if (tags && tags.includes(toRemove)) {\n                    const aliases = getAllAliases(name, _aliases);\n                    for (const alias of aliases) {\n                        entriesNameSet.delete(alias);\n                    }\n                    isRemoved = true;\n                    return false;\n                }\n                return true;\n            };\n            absoluteEntries = absoluteEntries.filter(filterCb);\n            relativeEntries = relativeEntries.filter(filterCb);\n            return isRemoved;\n        },\n        concat: (from) => {\n            const cloned = cloneTo(constructStack());\n            cloned.use(from);\n            cloned.identifyOnResolve(identifyOnResolve || cloned.identifyOnResolve() || (from.identifyOnResolve?.() ?? false));\n            return cloned;\n        },\n        applyToStack: cloneTo,\n        identify: () => {\n            return getMiddlewareList(true).map((mw) => {\n                const step = mw.step ??\n                    mw.relation +\n                        \" \" +\n                        mw.toMiddleware;\n                return getMiddlewareNameWithAliases(mw.name, mw.aliases) + \" - \" + step;\n            });\n        },\n        identifyOnResolve(toggle) {\n            if (typeof toggle === \"boolean\")\n                identifyOnResolve = toggle;\n            return identifyOnResolve;\n        },\n        resolve: (handler, context) => {\n            for (const middleware of getMiddlewareList()\n                .map((entry) => entry.middleware)\n                .reverse()) {\n                handler = middleware(handler, context);\n            }\n            if (identifyOnResolve) {\n                console.log(stack.identify());\n            }\n            return handler;\n        },\n    };\n    return stack;\n};\nconst stepWeights = {\n    initialize: 5,\n    serialize: 4,\n    build: 3,\n    finalizeRequest: 2,\n    deserialize: 1,\n};\nconst priorityWeights = {\n    high: 3,\n    normal: 2,\n    low: 1,\n};\n\nexports.constructStack = constructStack;\n","'use strict';\n\nvar propertyProvider = require('@smithy/property-provider');\nvar sharedIniFileLoader = require('@smithy/shared-ini-file-loader');\n\nfunction getSelectorName(functionString) {\n    try {\n        const constants = new Set(Array.from(functionString.match(/([A-Z_]){3,}/g) ?? []));\n        constants.delete(\"CONFIG\");\n        constants.delete(\"CONFIG_PREFIX_SEPARATOR\");\n        constants.delete(\"ENV\");\n        return [...constants].join(\", \");\n    }\n    catch (e) {\n        return functionString;\n    }\n}\n\nconst fromEnv = (envVarSelector, options) => async () => {\n    try {\n        const config = envVarSelector(process.env, options);\n        if (config === undefined) {\n            throw new Error();\n        }\n        return config;\n    }\n    catch (e) {\n        throw new propertyProvider.CredentialsProviderError(e.message || `Not found in ENV: ${getSelectorName(envVarSelector.toString())}`, { logger: options?.logger });\n    }\n};\n\nconst fromSharedConfigFiles = (configSelector, { preferredFile = \"config\", ...init } = {}) => async () => {\n    const profile = sharedIniFileLoader.getProfileName(init);\n    const { configFile, credentialsFile } = await sharedIniFileLoader.loadSharedConfigFiles(init);\n    const profileFromCredentials = credentialsFile[profile] || {};\n    const profileFromConfig = configFile[profile] || {};\n    const mergedProfile = preferredFile === \"config\"\n        ? { ...profileFromCredentials, ...profileFromConfig }\n        : { ...profileFromConfig, ...profileFromCredentials };\n    try {\n        const cfgFile = preferredFile === \"config\" ? configFile : credentialsFile;\n        const configValue = configSelector(mergedProfile, cfgFile);\n        if (configValue === undefined) {\n            throw new Error();\n        }\n        return configValue;\n    }\n    catch (e) {\n        throw new propertyProvider.CredentialsProviderError(e.message || `Not found in config files w/ profile [${profile}]: ${getSelectorName(configSelector.toString())}`, { logger: init.logger });\n    }\n};\n\nconst isFunction = (func) => typeof func === \"function\";\nconst fromStatic = (defaultValue) => isFunction(defaultValue) ? async () => await defaultValue() : propertyProvider.fromStatic(defaultValue);\n\nconst loadConfig = ({ environmentVariableSelector, configFileSelector, default: defaultValue }, configuration = {}) => {\n    const { signingName, logger } = configuration;\n    const envOptions = { signingName, logger };\n    return propertyProvider.memoize(propertyProvider.chain(fromEnv(environmentVariableSelector, envOptions), fromSharedConfigFiles(configFileSelector, configuration), fromStatic(defaultValue)));\n};\n\nexports.loadConfig = loadConfig;\n","'use strict';\n\nvar protocolHttp = require('@smithy/protocol-http');\nvar querystringBuilder = require('@smithy/querystring-builder');\nvar http = require('http');\nvar https = require('https');\nvar stream = require('stream');\nvar http2 = require('http2');\n\nconst NODEJS_TIMEOUT_ERROR_CODES = [\"ECONNRESET\", \"EPIPE\", \"ETIMEDOUT\"];\n\nconst getTransformedHeaders = (headers) => {\n    const transformedHeaders = {};\n    for (const name of Object.keys(headers)) {\n        const headerValues = headers[name];\n        transformedHeaders[name] = Array.isArray(headerValues) ? headerValues.join(\",\") : headerValues;\n    }\n    return transformedHeaders;\n};\n\nconst timing = {\n    setTimeout: (cb, ms) => setTimeout(cb, ms),\n    clearTimeout: (timeoutId) => clearTimeout(timeoutId),\n};\n\nconst DEFER_EVENT_LISTENER_TIME$2 = 1000;\nconst setConnectionTimeout = (request, reject, timeoutInMs = 0) => {\n    if (!timeoutInMs) {\n        return -1;\n    }\n    const registerTimeout = (offset) => {\n        const timeoutId = timing.setTimeout(() => {\n            request.destroy();\n            reject(Object.assign(new Error(`@smithy/node-http-handler - the request socket did not establish a connection with the server within the configured timeout of ${timeoutInMs} ms.`), {\n                name: \"TimeoutError\",\n            }));\n        }, timeoutInMs - offset);\n        const doWithSocket = (socket) => {\n            if (socket?.connecting) {\n                socket.on(\"connect\", () => {\n                    timing.clearTimeout(timeoutId);\n                });\n            }\n            else {\n                timing.clearTimeout(timeoutId);\n            }\n        };\n        if (request.socket) {\n            doWithSocket(request.socket);\n        }\n        else {\n            request.on(\"socket\", doWithSocket);\n        }\n    };\n    if (timeoutInMs < 2000) {\n        registerTimeout(0);\n        return 0;\n    }\n    return timing.setTimeout(registerTimeout.bind(null, DEFER_EVENT_LISTENER_TIME$2), DEFER_EVENT_LISTENER_TIME$2);\n};\n\nconst setRequestTimeout = (req, reject, timeoutInMs = 0, throwOnRequestTimeout, logger) => {\n    if (timeoutInMs) {\n        return timing.setTimeout(() => {\n            let msg = `@smithy/node-http-handler - [${throwOnRequestTimeout ? \"ERROR\" : \"WARN\"}] a request has exceeded the configured ${timeoutInMs} ms requestTimeout.`;\n            if (throwOnRequestTimeout) {\n                const error = Object.assign(new Error(msg), {\n                    name: \"TimeoutError\",\n                    code: \"ETIMEDOUT\",\n                });\n                req.destroy(error);\n                reject(error);\n            }\n            else {\n                msg += ` Init client requestHandler with throwOnRequestTimeout=true to turn this into an error.`;\n                logger?.warn?.(msg);\n            }\n        }, timeoutInMs);\n    }\n    return -1;\n};\n\nconst DEFER_EVENT_LISTENER_TIME$1 = 3000;\nconst setSocketKeepAlive = (request, { keepAlive, keepAliveMsecs }, deferTimeMs = DEFER_EVENT_LISTENER_TIME$1) => {\n    if (keepAlive !== true) {\n        return -1;\n    }\n    const registerListener = () => {\n        if (request.socket) {\n            request.socket.setKeepAlive(keepAlive, keepAliveMsecs || 0);\n        }\n        else {\n            request.on(\"socket\", (socket) => {\n                socket.setKeepAlive(keepAlive, keepAliveMsecs || 0);\n            });\n        }\n    };\n    if (deferTimeMs === 0) {\n        registerListener();\n        return 0;\n    }\n    return timing.setTimeout(registerListener, deferTimeMs);\n};\n\nconst DEFER_EVENT_LISTENER_TIME = 3000;\nconst setSocketTimeout = (request, reject, timeoutInMs = 0) => {\n    const registerTimeout = (offset) => {\n        const timeout = timeoutInMs - offset;\n        const onTimeout = () => {\n            request.destroy();\n            reject(Object.assign(new Error(`@smithy/node-http-handler - the request socket timed out after ${timeoutInMs} ms of inactivity (configured by client requestHandler).`), { name: \"TimeoutError\" }));\n        };\n        if (request.socket) {\n            request.socket.setTimeout(timeout, onTimeout);\n            request.on(\"close\", () => request.socket?.removeListener(\"timeout\", onTimeout));\n        }\n        else {\n            request.setTimeout(timeout, onTimeout);\n        }\n    };\n    if (0 < timeoutInMs && timeoutInMs < 6000) {\n        registerTimeout(0);\n        return 0;\n    }\n    return timing.setTimeout(registerTimeout.bind(null, timeoutInMs === 0 ? 0 : DEFER_EVENT_LISTENER_TIME), DEFER_EVENT_LISTENER_TIME);\n};\n\nconst MIN_WAIT_TIME = 6_000;\nasync function writeRequestBody(httpRequest, request, maxContinueTimeoutMs = MIN_WAIT_TIME, externalAgent = false) {\n    const headers = request.headers ?? {};\n    const expect = headers.Expect || headers.expect;\n    let timeoutId = -1;\n    let sendBody = true;\n    if (!externalAgent && expect === \"100-continue\") {\n        sendBody = await Promise.race([\n            new Promise((resolve) => {\n                timeoutId = Number(timing.setTimeout(() => resolve(true), Math.max(MIN_WAIT_TIME, maxContinueTimeoutMs)));\n            }),\n            new Promise((resolve) => {\n                httpRequest.on(\"continue\", () => {\n                    timing.clearTimeout(timeoutId);\n                    resolve(true);\n                });\n                httpRequest.on(\"response\", () => {\n                    timing.clearTimeout(timeoutId);\n                    resolve(false);\n                });\n                httpRequest.on(\"error\", () => {\n                    timing.clearTimeout(timeoutId);\n                    resolve(false);\n                });\n            }),\n        ]);\n    }\n    if (sendBody) {\n        writeBody(httpRequest, request.body);\n    }\n}\nfunction writeBody(httpRequest, body) {\n    if (body instanceof stream.Readable) {\n        body.pipe(httpRequest);\n        return;\n    }\n    if (body) {\n        if (Buffer.isBuffer(body) || typeof body === \"string\") {\n            httpRequest.end(body);\n            return;\n        }\n        const uint8 = body;\n        if (typeof uint8 === \"object\" &&\n            uint8.buffer &&\n            typeof uint8.byteOffset === \"number\" &&\n            typeof uint8.byteLength === \"number\") {\n            httpRequest.end(Buffer.from(uint8.buffer, uint8.byteOffset, uint8.byteLength));\n            return;\n        }\n        httpRequest.end(Buffer.from(body));\n        return;\n    }\n    httpRequest.end();\n}\n\nconst DEFAULT_REQUEST_TIMEOUT = 0;\nclass NodeHttpHandler {\n    config;\n    configProvider;\n    socketWarningTimestamp = 0;\n    externalAgent = false;\n    metadata = { handlerProtocol: \"http/1.1\" };\n    static create(instanceOrOptions) {\n        if (typeof instanceOrOptions?.handle === \"function\") {\n            return instanceOrOptions;\n        }\n        return new NodeHttpHandler(instanceOrOptions);\n    }\n    static checkSocketUsage(agent, socketWarningTimestamp, logger = console) {\n        const { sockets, requests, maxSockets } = agent;\n        if (typeof maxSockets !== \"number\" || maxSockets === Infinity) {\n            return socketWarningTimestamp;\n        }\n        const interval = 15_000;\n        if (Date.now() - interval < socketWarningTimestamp) {\n            return socketWarningTimestamp;\n        }\n        if (sockets && requests) {\n            for (const origin in sockets) {\n                const socketsInUse = sockets[origin]?.length ?? 0;\n                const requestsEnqueued = requests[origin]?.length ?? 0;\n                if (socketsInUse >= maxSockets && requestsEnqueued >= 2 * maxSockets) {\n                    logger?.warn?.(`@smithy/node-http-handler:WARN - socket usage at capacity=${socketsInUse} and ${requestsEnqueued} additional requests are enqueued.\nSee https://docs.aws.amazon.com/sdk-for-javascript/v3/developer-guide/node-configuring-maxsockets.html\nor increase socketAcquisitionWarningTimeout=(millis) in the NodeHttpHandler config.`);\n                    return Date.now();\n                }\n            }\n        }\n        return socketWarningTimestamp;\n    }\n    constructor(options) {\n        this.configProvider = new Promise((resolve, reject) => {\n            if (typeof options === \"function\") {\n                options()\n                    .then((_options) => {\n                    resolve(this.resolveDefaultConfig(_options));\n                })\n                    .catch(reject);\n            }\n            else {\n                resolve(this.resolveDefaultConfig(options));\n            }\n        });\n    }\n    resolveDefaultConfig(options) {\n        const { requestTimeout, connectionTimeout, socketTimeout, socketAcquisitionWarningTimeout, httpAgent, httpsAgent, throwOnRequestTimeout, logger, } = options || {};\n        const keepAlive = true;\n        const maxSockets = 50;\n        return {\n            connectionTimeout,\n            requestTimeout,\n            socketTimeout,\n            socketAcquisitionWarningTimeout,\n            throwOnRequestTimeout,\n            httpAgent: (() => {\n                if (httpAgent instanceof http.Agent || typeof httpAgent?.destroy === \"function\") {\n                    this.externalAgent = true;\n                    return httpAgent;\n                }\n                return new http.Agent({ keepAlive, maxSockets, ...httpAgent });\n            })(),\n            httpsAgent: (() => {\n                if (httpsAgent instanceof https.Agent || typeof httpsAgent?.destroy === \"function\") {\n                    this.externalAgent = true;\n                    return httpsAgent;\n                }\n                return new https.Agent({ keepAlive, maxSockets, ...httpsAgent });\n            })(),\n            logger,\n        };\n    }\n    destroy() {\n        this.config?.httpAgent?.destroy();\n        this.config?.httpsAgent?.destroy();\n    }\n    async handle(request, { abortSignal, requestTimeout } = {}) {\n        if (!this.config) {\n            this.config = await this.configProvider;\n        }\n        return new Promise((_resolve, _reject) => {\n            const config = this.config;\n            let writeRequestBodyPromise = undefined;\n            const timeouts = [];\n            const resolve = async (arg) => {\n                await writeRequestBodyPromise;\n                timeouts.forEach(timing.clearTimeout);\n                _resolve(arg);\n            };\n            const reject = async (arg) => {\n                await writeRequestBodyPromise;\n                timeouts.forEach(timing.clearTimeout);\n                _reject(arg);\n            };\n            if (abortSignal?.aborted) {\n                const abortError = new Error(\"Request aborted\");\n                abortError.name = \"AbortError\";\n                reject(abortError);\n                return;\n            }\n            const isSSL = request.protocol === \"https:\";\n            const headers = request.headers ?? {};\n            const expectContinue = (headers.Expect ?? headers.expect) === \"100-continue\";\n            let agent = isSSL ? config.httpsAgent : config.httpAgent;\n            if (expectContinue && !this.externalAgent) {\n                agent = new (isSSL ? https.Agent : http.Agent)({\n                    keepAlive: false,\n                    maxSockets: Infinity,\n                });\n            }\n            timeouts.push(timing.setTimeout(() => {\n                this.socketWarningTimestamp = NodeHttpHandler.checkSocketUsage(agent, this.socketWarningTimestamp, config.logger);\n            }, config.socketAcquisitionWarningTimeout ?? (config.requestTimeout ?? 2000) + (config.connectionTimeout ?? 1000)));\n            const queryString = querystringBuilder.buildQueryString(request.query || {});\n            let auth = undefined;\n            if (request.username != null || request.password != null) {\n                const username = request.username ?? \"\";\n                const password = request.password ?? \"\";\n                auth = `${username}:${password}`;\n            }\n            let path = request.path;\n            if (queryString) {\n                path += `?${queryString}`;\n            }\n            if (request.fragment) {\n                path += `#${request.fragment}`;\n            }\n            let hostname = request.hostname ?? \"\";\n            if (hostname[0] === \"[\" && hostname.endsWith(\"]\")) {\n                hostname = request.hostname.slice(1, -1);\n            }\n            else {\n                hostname = request.hostname;\n            }\n            const nodeHttpsOptions = {\n                headers: request.headers,\n                host: hostname,\n                method: request.method,\n                path,\n                port: request.port,\n                agent,\n                auth,\n            };\n            const requestFunc = isSSL ? https.request : http.request;\n            const req = requestFunc(nodeHttpsOptions, (res) => {\n                const httpResponse = new protocolHttp.HttpResponse({\n                    statusCode: res.statusCode || -1,\n                    reason: res.statusMessage,\n                    headers: getTransformedHeaders(res.headers),\n                    body: res,\n                });\n                resolve({ response: httpResponse });\n            });\n            req.on(\"error\", (err) => {\n                if (NODEJS_TIMEOUT_ERROR_CODES.includes(err.code)) {\n                    reject(Object.assign(err, { name: \"TimeoutError\" }));\n                }\n                else {\n                    reject(err);\n                }\n            });\n            if (abortSignal) {\n                const onAbort = () => {\n                    req.destroy();\n                    const abortError = new Error(\"Request aborted\");\n                    abortError.name = \"AbortError\";\n                    reject(abortError);\n                };\n                if (typeof abortSignal.addEventListener === \"function\") {\n                    const signal = abortSignal;\n                    signal.addEventListener(\"abort\", onAbort, { once: true });\n                    req.once(\"close\", () => signal.removeEventListener(\"abort\", onAbort));\n                }\n                else {\n                    abortSignal.onabort = onAbort;\n                }\n            }\n            const effectiveRequestTimeout = requestTimeout ?? config.requestTimeout;\n            timeouts.push(setConnectionTimeout(req, reject, config.connectionTimeout));\n            timeouts.push(setRequestTimeout(req, reject, effectiveRequestTimeout, config.throwOnRequestTimeout, config.logger ?? console));\n            timeouts.push(setSocketTimeout(req, reject, config.socketTimeout));\n            const httpAgent = nodeHttpsOptions.agent;\n            if (typeof httpAgent === \"object\" && \"keepAlive\" in httpAgent) {\n                timeouts.push(setSocketKeepAlive(req, {\n                    keepAlive: httpAgent.keepAlive,\n                    keepAliveMsecs: httpAgent.keepAliveMsecs,\n                }));\n            }\n            writeRequestBodyPromise = writeRequestBody(req, request, effectiveRequestTimeout, this.externalAgent).catch((e) => {\n                timeouts.forEach(timing.clearTimeout);\n                return _reject(e);\n            });\n        });\n    }\n    updateHttpClientConfig(key, value) {\n        this.config = undefined;\n        this.configProvider = this.configProvider.then((config) => {\n            return {\n                ...config,\n                [key]: value,\n            };\n        });\n    }\n    httpHandlerConfigs() {\n        return this.config ?? {};\n    }\n}\n\nclass NodeHttp2ConnectionPool {\n    sessions = [];\n    constructor(sessions) {\n        this.sessions = sessions ?? [];\n    }\n    poll() {\n        if (this.sessions.length > 0) {\n            return this.sessions.shift();\n        }\n    }\n    offerLast(session) {\n        this.sessions.push(session);\n    }\n    contains(session) {\n        return this.sessions.includes(session);\n    }\n    remove(session) {\n        this.sessions = this.sessions.filter((s) => s !== session);\n    }\n    [Symbol.iterator]() {\n        return this.sessions[Symbol.iterator]();\n    }\n    destroy(connection) {\n        for (const session of this.sessions) {\n            if (session === connection) {\n                if (!session.destroyed) {\n                    session.destroy();\n                }\n            }\n        }\n    }\n}\n\nclass NodeHttp2ConnectionManager {\n    constructor(config) {\n        this.config = config;\n        if (this.config.maxConcurrency && this.config.maxConcurrency <= 0) {\n            throw new RangeError(\"maxConcurrency must be greater than zero.\");\n        }\n    }\n    config;\n    sessionCache = new Map();\n    lease(requestContext, connectionConfiguration) {\n        const url = this.getUrlString(requestContext);\n        const existingPool = this.sessionCache.get(url);\n        if (existingPool) {\n            const existingSession = existingPool.poll();\n            if (existingSession && !this.config.disableConcurrency) {\n                return existingSession;\n            }\n        }\n        const session = http2.connect(url);\n        if (this.config.maxConcurrency) {\n            session.settings({ maxConcurrentStreams: this.config.maxConcurrency }, (err) => {\n                if (err) {\n                    throw new Error(\"Fail to set maxConcurrentStreams to \" +\n                        this.config.maxConcurrency +\n                        \"when creating new session for \" +\n                        requestContext.destination.toString());\n                }\n            });\n        }\n        session.unref();\n        const destroySessionCb = () => {\n            session.destroy();\n            this.deleteSession(url, session);\n        };\n        session.on(\"goaway\", destroySessionCb);\n        session.on(\"error\", destroySessionCb);\n        session.on(\"frameError\", destroySessionCb);\n        session.on(\"close\", () => this.deleteSession(url, session));\n        if (connectionConfiguration.requestTimeout) {\n            session.setTimeout(connectionConfiguration.requestTimeout, destroySessionCb);\n        }\n        const connectionPool = this.sessionCache.get(url) || new NodeHttp2ConnectionPool();\n        connectionPool.offerLast(session);\n        this.sessionCache.set(url, connectionPool);\n        return session;\n    }\n    deleteSession(authority, session) {\n        const existingConnectionPool = this.sessionCache.get(authority);\n        if (!existingConnectionPool) {\n            return;\n        }\n        if (!existingConnectionPool.contains(session)) {\n            return;\n        }\n        existingConnectionPool.remove(session);\n        this.sessionCache.set(authority, existingConnectionPool);\n    }\n    release(requestContext, session) {\n        const cacheKey = this.getUrlString(requestContext);\n        this.sessionCache.get(cacheKey)?.offerLast(session);\n    }\n    destroy() {\n        for (const [key, connectionPool] of this.sessionCache) {\n            for (const session of connectionPool) {\n                if (!session.destroyed) {\n                    session.destroy();\n                }\n                connectionPool.remove(session);\n            }\n            this.sessionCache.delete(key);\n        }\n    }\n    setMaxConcurrentStreams(maxConcurrentStreams) {\n        if (maxConcurrentStreams && maxConcurrentStreams <= 0) {\n            throw new RangeError(\"maxConcurrentStreams must be greater than zero.\");\n        }\n        this.config.maxConcurrency = maxConcurrentStreams;\n    }\n    setDisableConcurrentStreams(disableConcurrentStreams) {\n        this.config.disableConcurrency = disableConcurrentStreams;\n    }\n    getUrlString(request) {\n        return request.destination.toString();\n    }\n}\n\nclass NodeHttp2Handler {\n    config;\n    configProvider;\n    metadata = { handlerProtocol: \"h2\" };\n    connectionManager = new NodeHttp2ConnectionManager({});\n    static create(instanceOrOptions) {\n        if (typeof instanceOrOptions?.handle === \"function\") {\n            return instanceOrOptions;\n        }\n        return new NodeHttp2Handler(instanceOrOptions);\n    }\n    constructor(options) {\n        this.configProvider = new Promise((resolve, reject) => {\n            if (typeof options === \"function\") {\n                options()\n                    .then((opts) => {\n                    resolve(opts || {});\n                })\n                    .catch(reject);\n            }\n            else {\n                resolve(options || {});\n            }\n        });\n    }\n    destroy() {\n        this.connectionManager.destroy();\n    }\n    async handle(request, { abortSignal, requestTimeout } = {}) {\n        if (!this.config) {\n            this.config = await this.configProvider;\n            this.connectionManager.setDisableConcurrentStreams(this.config.disableConcurrentStreams || false);\n            if (this.config.maxConcurrentStreams) {\n                this.connectionManager.setMaxConcurrentStreams(this.config.maxConcurrentStreams);\n            }\n        }\n        const { requestTimeout: configRequestTimeout, disableConcurrentStreams } = this.config;\n        const effectiveRequestTimeout = requestTimeout ?? configRequestTimeout;\n        return new Promise((_resolve, _reject) => {\n            let fulfilled = false;\n            let writeRequestBodyPromise = undefined;\n            const resolve = async (arg) => {\n                await writeRequestBodyPromise;\n                _resolve(arg);\n            };\n            const reject = async (arg) => {\n                await writeRequestBodyPromise;\n                _reject(arg);\n            };\n            if (abortSignal?.aborted) {\n                fulfilled = true;\n                const abortError = new Error(\"Request aborted\");\n                abortError.name = \"AbortError\";\n                reject(abortError);\n                return;\n            }\n            const { hostname, method, port, protocol, query } = request;\n            let auth = \"\";\n            if (request.username != null || request.password != null) {\n                const username = request.username ?? \"\";\n                const password = request.password ?? \"\";\n                auth = `${username}:${password}@`;\n            }\n            const authority = `${protocol}//${auth}${hostname}${port ? `:${port}` : \"\"}`;\n            const requestContext = { destination: new URL(authority) };\n            const session = this.connectionManager.lease(requestContext, {\n                requestTimeout: this.config?.sessionTimeout,\n                disableConcurrentStreams: disableConcurrentStreams || false,\n            });\n            const rejectWithDestroy = (err) => {\n                if (disableConcurrentStreams) {\n                    this.destroySession(session);\n                }\n                fulfilled = true;\n                reject(err);\n            };\n            const queryString = querystringBuilder.buildQueryString(query || {});\n            let path = request.path;\n            if (queryString) {\n                path += `?${queryString}`;\n            }\n            if (request.fragment) {\n                path += `#${request.fragment}`;\n            }\n            const req = session.request({\n                ...request.headers,\n                [http2.constants.HTTP2_HEADER_PATH]: path,\n                [http2.constants.HTTP2_HEADER_METHOD]: method,\n            });\n            session.ref();\n            req.on(\"response\", (headers) => {\n                const httpResponse = new protocolHttp.HttpResponse({\n                    statusCode: headers[\":status\"] || -1,\n                    headers: getTransformedHeaders(headers),\n                    body: req,\n                });\n                fulfilled = true;\n                resolve({ response: httpResponse });\n                if (disableConcurrentStreams) {\n                    session.close();\n                    this.connectionManager.deleteSession(authority, session);\n                }\n            });\n            if (effectiveRequestTimeout) {\n                req.setTimeout(effectiveRequestTimeout, () => {\n                    req.close();\n                    const timeoutError = new Error(`Stream timed out because of no activity for ${effectiveRequestTimeout} ms`);\n                    timeoutError.name = \"TimeoutError\";\n                    rejectWithDestroy(timeoutError);\n                });\n            }\n            if (abortSignal) {\n                const onAbort = () => {\n                    req.close();\n                    const abortError = new Error(\"Request aborted\");\n                    abortError.name = \"AbortError\";\n                    rejectWithDestroy(abortError);\n                };\n                if (typeof abortSignal.addEventListener === \"function\") {\n                    const signal = abortSignal;\n                    signal.addEventListener(\"abort\", onAbort, { once: true });\n                    req.once(\"close\", () => signal.removeEventListener(\"abort\", onAbort));\n                }\n                else {\n                    abortSignal.onabort = onAbort;\n                }\n            }\n            req.on(\"frameError\", (type, code, id) => {\n                rejectWithDestroy(new Error(`Frame type id ${type} in stream id ${id} has failed with code ${code}.`));\n            });\n            req.on(\"error\", rejectWithDestroy);\n            req.on(\"aborted\", () => {\n                rejectWithDestroy(new Error(`HTTP/2 stream is abnormally aborted in mid-communication with result code ${req.rstCode}.`));\n            });\n            req.on(\"close\", () => {\n                session.unref();\n                if (disableConcurrentStreams) {\n                    session.destroy();\n                }\n                if (!fulfilled) {\n                    rejectWithDestroy(new Error(\"Unexpected error: http2 request did not get a response\"));\n                }\n            });\n            writeRequestBodyPromise = writeRequestBody(req, request, effectiveRequestTimeout);\n        });\n    }\n    updateHttpClientConfig(key, value) {\n        this.config = undefined;\n        this.configProvider = this.configProvider.then((config) => {\n            return {\n                ...config,\n                [key]: value,\n            };\n        });\n    }\n    httpHandlerConfigs() {\n        return this.config ?? {};\n    }\n    destroySession(session) {\n        if (!session.destroyed) {\n            session.destroy();\n        }\n    }\n}\n\nclass Collector extends stream.Writable {\n    bufferedBytes = [];\n    _write(chunk, encoding, callback) {\n        this.bufferedBytes.push(chunk);\n        callback();\n    }\n}\n\nconst streamCollector = (stream) => {\n    if (isReadableStreamInstance(stream)) {\n        return collectReadableStream(stream);\n    }\n    return new Promise((resolve, reject) => {\n        const collector = new Collector();\n        stream.pipe(collector);\n        stream.on(\"error\", (err) => {\n            collector.end();\n            reject(err);\n        });\n        collector.on(\"error\", reject);\n        collector.on(\"finish\", function () {\n            const bytes = new Uint8Array(Buffer.concat(this.bufferedBytes));\n            resolve(bytes);\n        });\n    });\n};\nconst isReadableStreamInstance = (stream) => typeof ReadableStream === \"function\" && stream instanceof ReadableStream;\nasync function collectReadableStream(stream) {\n    const chunks = [];\n    const reader = stream.getReader();\n    let isDone = false;\n    let length = 0;\n    while (!isDone) {\n        const { done, value } = await reader.read();\n        if (value) {\n            chunks.push(value);\n            length += value.length;\n        }\n        isDone = done;\n    }\n    const collected = new Uint8Array(length);\n    let offset = 0;\n    for (const chunk of chunks) {\n        collected.set(chunk, offset);\n        offset += chunk.length;\n    }\n    return collected;\n}\n\nexports.DEFAULT_REQUEST_TIMEOUT = DEFAULT_REQUEST_TIMEOUT;\nexports.NodeHttp2Handler = NodeHttp2Handler;\nexports.NodeHttpHandler = NodeHttpHandler;\nexports.streamCollector = streamCollector;\n","'use strict';\n\nclass ProviderError extends Error {\n    name = \"ProviderError\";\n    tryNextLink;\n    constructor(message, options = true) {\n        let logger;\n        let tryNextLink = true;\n        if (typeof options === \"boolean\") {\n            logger = undefined;\n            tryNextLink = options;\n        }\n        else if (options != null && typeof options === \"object\") {\n            logger = options.logger;\n            tryNextLink = options.tryNextLink ?? true;\n        }\n        super(message);\n        this.tryNextLink = tryNextLink;\n        Object.setPrototypeOf(this, ProviderError.prototype);\n        logger?.debug?.(`@smithy/property-provider ${tryNextLink ? \"->\" : \"(!)\"} ${message}`);\n    }\n    static from(error, options = true) {\n        return Object.assign(new this(error.message, options), error);\n    }\n}\n\nclass CredentialsProviderError extends ProviderError {\n    name = \"CredentialsProviderError\";\n    constructor(message, options = true) {\n        super(message, options);\n        Object.setPrototypeOf(this, CredentialsProviderError.prototype);\n    }\n}\n\nclass TokenProviderError extends ProviderError {\n    name = \"TokenProviderError\";\n    constructor(message, options = true) {\n        super(message, options);\n        Object.setPrototypeOf(this, TokenProviderError.prototype);\n    }\n}\n\nconst chain = (...providers) => async () => {\n    if (providers.length === 0) {\n        throw new ProviderError(\"No providers in chain\");\n    }\n    let lastProviderError;\n    for (const provider of providers) {\n        try {\n            const credentials = await provider();\n            return credentials;\n        }\n        catch (err) {\n            lastProviderError = err;\n            if (err?.tryNextLink) {\n                continue;\n            }\n            throw err;\n        }\n    }\n    throw lastProviderError;\n};\n\nconst fromStatic = (staticValue) => () => Promise.resolve(staticValue);\n\nconst memoize = (provider, isExpired, requiresRefresh) => {\n    let resolved;\n    let pending;\n    let hasResult;\n    let isConstant = false;\n    const coalesceProvider = async () => {\n        if (!pending) {\n            pending = provider();\n        }\n        try {\n            resolved = await pending;\n            hasResult = true;\n            isConstant = false;\n        }\n        finally {\n            pending = undefined;\n        }\n        return resolved;\n    };\n    if (isExpired === undefined) {\n        return async (options) => {\n            if (!hasResult || options?.forceRefresh) {\n                resolved = await coalesceProvider();\n            }\n            return resolved;\n        };\n    }\n    return async (options) => {\n        if (!hasResult || options?.forceRefresh) {\n            resolved = await coalesceProvider();\n        }\n        if (isConstant) {\n            return resolved;\n        }\n        if (requiresRefresh && !requiresRefresh(resolved)) {\n            isConstant = true;\n            return resolved;\n        }\n        if (isExpired(resolved)) {\n            await coalesceProvider();\n            return resolved;\n        }\n        return resolved;\n    };\n};\n\nexports.CredentialsProviderError = CredentialsProviderError;\nexports.ProviderError = ProviderError;\nexports.TokenProviderError = TokenProviderError;\nexports.chain = chain;\nexports.fromStatic = fromStatic;\nexports.memoize = memoize;\n","'use strict';\n\nvar types = require('@smithy/types');\n\nconst getHttpHandlerExtensionConfiguration = (runtimeConfig) => {\n    return {\n        setHttpHandler(handler) {\n            runtimeConfig.httpHandler = handler;\n        },\n        httpHandler() {\n            return runtimeConfig.httpHandler;\n        },\n        updateHttpClientConfig(key, value) {\n            runtimeConfig.httpHandler?.updateHttpClientConfig(key, value);\n        },\n        httpHandlerConfigs() {\n            return runtimeConfig.httpHandler.httpHandlerConfigs();\n        },\n    };\n};\nconst resolveHttpHandlerRuntimeConfig = (httpHandlerExtensionConfiguration) => {\n    return {\n        httpHandler: httpHandlerExtensionConfiguration.httpHandler(),\n    };\n};\n\nclass Field {\n    name;\n    kind;\n    values;\n    constructor({ name, kind = types.FieldPosition.HEADER, values = [] }) {\n        this.name = name;\n        this.kind = kind;\n        this.values = values;\n    }\n    add(value) {\n        this.values.push(value);\n    }\n    set(values) {\n        this.values = values;\n    }\n    remove(value) {\n        this.values = this.values.filter((v) => v !== value);\n    }\n    toString() {\n        return this.values.map((v) => (v.includes(\",\") || v.includes(\" \") ? `\"${v}\"` : v)).join(\", \");\n    }\n    get() {\n        return this.values;\n    }\n}\n\nclass Fields {\n    entries = {};\n    encoding;\n    constructor({ fields = [], encoding = \"utf-8\" }) {\n        fields.forEach(this.setField.bind(this));\n        this.encoding = encoding;\n    }\n    setField(field) {\n        this.entries[field.name.toLowerCase()] = field;\n    }\n    getField(name) {\n        return this.entries[name.toLowerCase()];\n    }\n    removeField(name) {\n        delete this.entries[name.toLowerCase()];\n    }\n    getByType(kind) {\n        return Object.values(this.entries).filter((field) => field.kind === kind);\n    }\n}\n\nclass HttpRequest {\n    method;\n    protocol;\n    hostname;\n    port;\n    path;\n    query;\n    headers;\n    username;\n    password;\n    fragment;\n    body;\n    constructor(options) {\n        this.method = options.method || \"GET\";\n        this.hostname = options.hostname || \"localhost\";\n        this.port = options.port;\n        this.query = options.query || {};\n        this.headers = options.headers || {};\n        this.body = options.body;\n        this.protocol = options.protocol\n            ? options.protocol.slice(-1) !== \":\"\n                ? `${options.protocol}:`\n                : options.protocol\n            : \"https:\";\n        this.path = options.path ? (options.path.charAt(0) !== \"/\" ? `/${options.path}` : options.path) : \"/\";\n        this.username = options.username;\n        this.password = options.password;\n        this.fragment = options.fragment;\n    }\n    static clone(request) {\n        const cloned = new HttpRequest({\n            ...request,\n            headers: { ...request.headers },\n        });\n        if (cloned.query) {\n            cloned.query = cloneQuery(cloned.query);\n        }\n        return cloned;\n    }\n    static isInstance(request) {\n        if (!request) {\n            return false;\n        }\n        const req = request;\n        return (\"method\" in req &&\n            \"protocol\" in req &&\n            \"hostname\" in req &&\n            \"path\" in req &&\n            typeof req[\"query\"] === \"object\" &&\n            typeof req[\"headers\"] === \"object\");\n    }\n    clone() {\n        return HttpRequest.clone(this);\n    }\n}\nfunction cloneQuery(query) {\n    return Object.keys(query).reduce((carry, paramName) => {\n        const param = query[paramName];\n        return {\n            ...carry,\n            [paramName]: Array.isArray(param) ? [...param] : param,\n        };\n    }, {});\n}\n\nclass HttpResponse {\n    statusCode;\n    reason;\n    headers;\n    body;\n    constructor(options) {\n        this.statusCode = options.statusCode;\n        this.reason = options.reason;\n        this.headers = options.headers || {};\n        this.body = options.body;\n    }\n    static isInstance(response) {\n        if (!response)\n            return false;\n        const resp = response;\n        return typeof resp.statusCode === \"number\" && typeof resp.headers === \"object\";\n    }\n}\n\nfunction isValidHostname(hostname) {\n    const hostPattern = /^[a-z0-9][a-z0-9\\.\\-]*[a-z0-9]$/;\n    return hostPattern.test(hostname);\n}\n\nexports.Field = Field;\nexports.Fields = Fields;\nexports.HttpRequest = HttpRequest;\nexports.HttpResponse = HttpResponse;\nexports.getHttpHandlerExtensionConfiguration = getHttpHandlerExtensionConfiguration;\nexports.isValidHostname = isValidHostname;\nexports.resolveHttpHandlerRuntimeConfig = resolveHttpHandlerRuntimeConfig;\n","'use strict';\n\nvar utilUriEscape = require('@smithy/util-uri-escape');\n\nfunction buildQueryString(query) {\n    const parts = [];\n    for (let key of Object.keys(query).sort()) {\n        const value = query[key];\n        key = utilUriEscape.escapeUri(key);\n        if (Array.isArray(value)) {\n            for (let i = 0, iLen = value.length; i < iLen; i++) {\n                parts.push(`${key}=${utilUriEscape.escapeUri(value[i])}`);\n            }\n        }\n        else {\n            let qsEntry = key;\n            if (value || typeof value === \"string\") {\n                qsEntry += `=${utilUriEscape.escapeUri(value)}`;\n            }\n            parts.push(qsEntry);\n        }\n    }\n    return parts.join(\"&\");\n}\n\nexports.buildQueryString = buildQueryString;\n","'use strict';\n\nfunction parseQueryString(querystring) {\n    const query = {};\n    querystring = querystring.replace(/^\\?/, \"\");\n    if (querystring) {\n        for (const pair of querystring.split(\"&\")) {\n            let [key, value = null] = pair.split(\"=\");\n            key = decodeURIComponent(key);\n            if (value) {\n                value = decodeURIComponent(value);\n            }\n            if (!(key in query)) {\n                query[key] = value;\n            }\n            else if (Array.isArray(query[key])) {\n                query[key].push(value);\n            }\n            else {\n                query[key] = [query[key], value];\n            }\n        }\n    }\n    return query;\n}\n\nexports.parseQueryString = parseQueryString;\n","'use strict';\n\nconst CLOCK_SKEW_ERROR_CODES = [\n    \"AuthFailure\",\n    \"InvalidSignatureException\",\n    \"RequestExpired\",\n    \"RequestInTheFuture\",\n    \"RequestTimeTooSkewed\",\n    \"SignatureDoesNotMatch\",\n];\nconst THROTTLING_ERROR_CODES = [\n    \"BandwidthLimitExceeded\",\n    \"EC2ThrottledException\",\n    \"LimitExceededException\",\n    \"PriorRequestNotComplete\",\n    \"ProvisionedThroughputExceededException\",\n    \"RequestLimitExceeded\",\n    \"RequestThrottled\",\n    \"RequestThrottledException\",\n    \"SlowDown\",\n    \"ThrottledException\",\n    \"Throttling\",\n    \"ThrottlingException\",\n    \"TooManyRequestsException\",\n    \"TransactionInProgressException\",\n];\nconst TRANSIENT_ERROR_CODES = [\"TimeoutError\", \"RequestTimeout\", \"RequestTimeoutException\"];\nconst TRANSIENT_ERROR_STATUS_CODES = [500, 502, 503, 504];\nconst NODEJS_TIMEOUT_ERROR_CODES = [\"ECONNRESET\", \"ECONNREFUSED\", \"EPIPE\", \"ETIMEDOUT\"];\nconst NODEJS_NETWORK_ERROR_CODES = [\"EHOSTUNREACH\", \"ENETUNREACH\", \"ENOTFOUND\"];\n\nconst isRetryableByTrait = (error) => error?.$retryable !== undefined;\nconst isClockSkewError = (error) => CLOCK_SKEW_ERROR_CODES.includes(error.name);\nconst isClockSkewCorrectedError = (error) => error.$metadata?.clockSkewCorrected;\nconst isBrowserNetworkError = (error) => {\n    const errorMessages = new Set([\n        \"Failed to fetch\",\n        \"NetworkError when attempting to fetch resource\",\n        \"The Internet connection appears to be offline\",\n        \"Load failed\",\n        \"Network request failed\",\n    ]);\n    const isValid = error && error instanceof TypeError;\n    if (!isValid) {\n        return false;\n    }\n    return errorMessages.has(error.message);\n};\nconst isThrottlingError = (error) => error.$metadata?.httpStatusCode === 429 ||\n    THROTTLING_ERROR_CODES.includes(error.name) ||\n    error.$retryable?.throttling == true;\nconst isTransientError = (error, depth = 0) => isRetryableByTrait(error) ||\n    isClockSkewCorrectedError(error) ||\n    TRANSIENT_ERROR_CODES.includes(error.name) ||\n    NODEJS_TIMEOUT_ERROR_CODES.includes(error?.code || \"\") ||\n    NODEJS_NETWORK_ERROR_CODES.includes(error?.code || \"\") ||\n    TRANSIENT_ERROR_STATUS_CODES.includes(error.$metadata?.httpStatusCode || 0) ||\n    isBrowserNetworkError(error) ||\n    (error.cause !== undefined && depth <= 10 && isTransientError(error.cause, depth + 1));\nconst isServerError = (error) => {\n    if (error.$metadata?.httpStatusCode !== undefined) {\n        const statusCode = error.$metadata.httpStatusCode;\n        if (500 <= statusCode && statusCode <= 599 && !isTransientError(error)) {\n            return true;\n        }\n        return false;\n    }\n    return false;\n};\n\nexports.isBrowserNetworkError = isBrowserNetworkError;\nexports.isClockSkewCorrectedError = isClockSkewCorrectedError;\nexports.isClockSkewError = isClockSkewError;\nexports.isRetryableByTrait = isRetryableByTrait;\nexports.isServerError = isServerError;\nexports.isThrottlingError = isThrottlingError;\nexports.isTransientError = isTransientError;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getHomeDir = void 0;\nconst os_1 = require(\"os\");\nconst path_1 = require(\"path\");\nconst homeDirCache = {};\nconst getHomeDirCacheKey = () => {\n    if (process && process.geteuid) {\n        return `${process.geteuid()}`;\n    }\n    return \"DEFAULT\";\n};\nconst getHomeDir = () => {\n    const { HOME, USERPROFILE, HOMEPATH, HOMEDRIVE = `C:${path_1.sep}` } = process.env;\n    if (HOME)\n        return HOME;\n    if (USERPROFILE)\n        return USERPROFILE;\n    if (HOMEPATH)\n        return `${HOMEDRIVE}${HOMEPATH}`;\n    const homeDirCacheKey = getHomeDirCacheKey();\n    if (!homeDirCache[homeDirCacheKey])\n        homeDirCache[homeDirCacheKey] = (0, os_1.homedir)();\n    return homeDirCache[homeDirCacheKey];\n};\nexports.getHomeDir = getHomeDir;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getSSOTokenFilepath = void 0;\nconst crypto_1 = require(\"crypto\");\nconst path_1 = require(\"path\");\nconst getHomeDir_1 = require(\"./getHomeDir\");\nconst getSSOTokenFilepath = (id) => {\n    const hasher = (0, crypto_1.createHash)(\"sha1\");\n    const cacheName = hasher.update(id).digest(\"hex\");\n    return (0, path_1.join)((0, getHomeDir_1.getHomeDir)(), \".aws\", \"sso\", \"cache\", `${cacheName}.json`);\n};\nexports.getSSOTokenFilepath = getSSOTokenFilepath;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getSSOTokenFromFile = exports.tokenIntercept = void 0;\nconst promises_1 = require(\"fs/promises\");\nconst getSSOTokenFilepath_1 = require(\"./getSSOTokenFilepath\");\nexports.tokenIntercept = {};\nconst getSSOTokenFromFile = async (id) => {\n    if (exports.tokenIntercept[id]) {\n        return exports.tokenIntercept[id];\n    }\n    const ssoTokenFilepath = (0, getSSOTokenFilepath_1.getSSOTokenFilepath)(id);\n    const ssoTokenText = await (0, promises_1.readFile)(ssoTokenFilepath, \"utf8\");\n    return JSON.parse(ssoTokenText);\n};\nexports.getSSOTokenFromFile = getSSOTokenFromFile;\n","'use strict';\n\nvar getHomeDir = require('./getHomeDir');\nvar getSSOTokenFilepath = require('./getSSOTokenFilepath');\nvar getSSOTokenFromFile = require('./getSSOTokenFromFile');\nvar path = require('path');\nvar types = require('@smithy/types');\nvar readFile = require('./readFile');\n\nconst ENV_PROFILE = \"AWS_PROFILE\";\nconst DEFAULT_PROFILE = \"default\";\nconst getProfileName = (init) => init.profile || process.env[ENV_PROFILE] || DEFAULT_PROFILE;\n\nconst CONFIG_PREFIX_SEPARATOR = \".\";\n\nconst getConfigData = (data) => Object.entries(data)\n    .filter(([key]) => {\n    const indexOfSeparator = key.indexOf(CONFIG_PREFIX_SEPARATOR);\n    if (indexOfSeparator === -1) {\n        return false;\n    }\n    return Object.values(types.IniSectionType).includes(key.substring(0, indexOfSeparator));\n})\n    .reduce((acc, [key, value]) => {\n    const indexOfSeparator = key.indexOf(CONFIG_PREFIX_SEPARATOR);\n    const updatedKey = key.substring(0, indexOfSeparator) === types.IniSectionType.PROFILE ? key.substring(indexOfSeparator + 1) : key;\n    acc[updatedKey] = value;\n    return acc;\n}, {\n    ...(data.default && { default: data.default }),\n});\n\nconst ENV_CONFIG_PATH = \"AWS_CONFIG_FILE\";\nconst getConfigFilepath = () => process.env[ENV_CONFIG_PATH] || path.join(getHomeDir.getHomeDir(), \".aws\", \"config\");\n\nconst ENV_CREDENTIALS_PATH = \"AWS_SHARED_CREDENTIALS_FILE\";\nconst getCredentialsFilepath = () => process.env[ENV_CREDENTIALS_PATH] || path.join(getHomeDir.getHomeDir(), \".aws\", \"credentials\");\n\nconst prefixKeyRegex = /^([\\w-]+)\\s([\"'])?([\\w-@\\+\\.%:/]+)\\2$/;\nconst profileNameBlockList = [\"__proto__\", \"profile __proto__\"];\nconst parseIni = (iniData) => {\n    const map = {};\n    let currentSection;\n    let currentSubSection;\n    for (const iniLine of iniData.split(/\\r?\\n/)) {\n        const trimmedLine = iniLine.split(/(^|\\s)[;#]/)[0].trim();\n        const isSection = trimmedLine[0] === \"[\" && trimmedLine[trimmedLine.length - 1] === \"]\";\n        if (isSection) {\n            currentSection = undefined;\n            currentSubSection = undefined;\n            const sectionName = trimmedLine.substring(1, trimmedLine.length - 1);\n            const matches = prefixKeyRegex.exec(sectionName);\n            if (matches) {\n                const [, prefix, , name] = matches;\n                if (Object.values(types.IniSectionType).includes(prefix)) {\n                    currentSection = [prefix, name].join(CONFIG_PREFIX_SEPARATOR);\n                }\n            }\n            else {\n                currentSection = sectionName;\n            }\n            if (profileNameBlockList.includes(sectionName)) {\n                throw new Error(`Found invalid profile name \"${sectionName}\"`);\n            }\n        }\n        else if (currentSection) {\n            const indexOfEqualsSign = trimmedLine.indexOf(\"=\");\n            if (![0, -1].includes(indexOfEqualsSign)) {\n                const [name, value] = [\n                    trimmedLine.substring(0, indexOfEqualsSign).trim(),\n                    trimmedLine.substring(indexOfEqualsSign + 1).trim(),\n                ];\n                if (value === \"\") {\n                    currentSubSection = name;\n                }\n                else {\n                    if (currentSubSection && iniLine.trimStart() === iniLine) {\n                        currentSubSection = undefined;\n                    }\n                    map[currentSection] = map[currentSection] || {};\n                    const key = currentSubSection ? [currentSubSection, name].join(CONFIG_PREFIX_SEPARATOR) : name;\n                    map[currentSection][key] = value;\n                }\n            }\n        }\n    }\n    return map;\n};\n\nconst swallowError$1 = () => ({});\nconst loadSharedConfigFiles = async (init = {}) => {\n    const { filepath = getCredentialsFilepath(), configFilepath = getConfigFilepath() } = init;\n    const homeDir = getHomeDir.getHomeDir();\n    const relativeHomeDirPrefix = \"~/\";\n    let resolvedFilepath = filepath;\n    if (filepath.startsWith(relativeHomeDirPrefix)) {\n        resolvedFilepath = path.join(homeDir, filepath.slice(2));\n    }\n    let resolvedConfigFilepath = configFilepath;\n    if (configFilepath.startsWith(relativeHomeDirPrefix)) {\n        resolvedConfigFilepath = path.join(homeDir, configFilepath.slice(2));\n    }\n    const parsedFiles = await Promise.all([\n        readFile.readFile(resolvedConfigFilepath, {\n            ignoreCache: init.ignoreCache,\n        })\n            .then(parseIni)\n            .then(getConfigData)\n            .catch(swallowError$1),\n        readFile.readFile(resolvedFilepath, {\n            ignoreCache: init.ignoreCache,\n        })\n            .then(parseIni)\n            .catch(swallowError$1),\n    ]);\n    return {\n        configFile: parsedFiles[0],\n        credentialsFile: parsedFiles[1],\n    };\n};\n\nconst getSsoSessionData = (data) => Object.entries(data)\n    .filter(([key]) => key.startsWith(types.IniSectionType.SSO_SESSION + CONFIG_PREFIX_SEPARATOR))\n    .reduce((acc, [key, value]) => ({ ...acc, [key.substring(key.indexOf(CONFIG_PREFIX_SEPARATOR) + 1)]: value }), {});\n\nconst swallowError = () => ({});\nconst loadSsoSessionData = async (init = {}) => readFile.readFile(init.configFilepath ?? getConfigFilepath())\n    .then(parseIni)\n    .then(getSsoSessionData)\n    .catch(swallowError);\n\nconst mergeConfigFiles = (...files) => {\n    const merged = {};\n    for (const file of files) {\n        for (const [key, values] of Object.entries(file)) {\n            if (merged[key] !== undefined) {\n                Object.assign(merged[key], values);\n            }\n            else {\n                merged[key] = values;\n            }\n        }\n    }\n    return merged;\n};\n\nconst parseKnownFiles = async (init) => {\n    const parsedFiles = await loadSharedConfigFiles(init);\n    return mergeConfigFiles(parsedFiles.configFile, parsedFiles.credentialsFile);\n};\n\nconst externalDataInterceptor = {\n    getFileRecord() {\n        return readFile.fileIntercept;\n    },\n    interceptFile(path, contents) {\n        readFile.fileIntercept[path] = Promise.resolve(contents);\n    },\n    getTokenRecord() {\n        return getSSOTokenFromFile.tokenIntercept;\n    },\n    interceptToken(id, contents) {\n        getSSOTokenFromFile.tokenIntercept[id] = contents;\n    },\n};\n\nObject.defineProperty(exports, \"getSSOTokenFromFile\", {\n    enumerable: true,\n    get: function () { return getSSOTokenFromFile.getSSOTokenFromFile; }\n});\nObject.defineProperty(exports, \"readFile\", {\n    enumerable: true,\n    get: function () { return readFile.readFile; }\n});\nexports.CONFIG_PREFIX_SEPARATOR = CONFIG_PREFIX_SEPARATOR;\nexports.DEFAULT_PROFILE = DEFAULT_PROFILE;\nexports.ENV_PROFILE = ENV_PROFILE;\nexports.externalDataInterceptor = externalDataInterceptor;\nexports.getProfileName = getProfileName;\nexports.loadSharedConfigFiles = loadSharedConfigFiles;\nexports.loadSsoSessionData = loadSsoSessionData;\nexports.parseKnownFiles = parseKnownFiles;\nObject.keys(getHomeDir).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return getHomeDir[k]; }\n    });\n});\nObject.keys(getSSOTokenFilepath).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return getSSOTokenFilepath[k]; }\n    });\n});\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.readFile = exports.fileIntercept = exports.filePromises = void 0;\nconst promises_1 = require(\"node:fs/promises\");\nexports.filePromises = {};\nexports.fileIntercept = {};\nconst readFile = (path, options) => {\n    if (exports.fileIntercept[path] !== undefined) {\n        return exports.fileIntercept[path];\n    }\n    if (!exports.filePromises[path] || options?.ignoreCache) {\n        exports.filePromises[path] = (0, promises_1.readFile)(path, \"utf8\");\n    }\n    return exports.filePromises[path];\n};\nexports.readFile = readFile;\n","'use strict';\n\nvar utilHexEncoding = require('@smithy/util-hex-encoding');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar isArrayBuffer = require('@smithy/is-array-buffer');\nvar protocolHttp = require('@smithy/protocol-http');\nvar utilMiddleware = require('@smithy/util-middleware');\nvar utilUriEscape = require('@smithy/util-uri-escape');\n\nconst ALGORITHM_QUERY_PARAM = \"X-Amz-Algorithm\";\nconst CREDENTIAL_QUERY_PARAM = \"X-Amz-Credential\";\nconst AMZ_DATE_QUERY_PARAM = \"X-Amz-Date\";\nconst SIGNED_HEADERS_QUERY_PARAM = \"X-Amz-SignedHeaders\";\nconst EXPIRES_QUERY_PARAM = \"X-Amz-Expires\";\nconst SIGNATURE_QUERY_PARAM = \"X-Amz-Signature\";\nconst TOKEN_QUERY_PARAM = \"X-Amz-Security-Token\";\nconst REGION_SET_PARAM = \"X-Amz-Region-Set\";\nconst AUTH_HEADER = \"authorization\";\nconst AMZ_DATE_HEADER = AMZ_DATE_QUERY_PARAM.toLowerCase();\nconst DATE_HEADER = \"date\";\nconst GENERATED_HEADERS = [AUTH_HEADER, AMZ_DATE_HEADER, DATE_HEADER];\nconst SIGNATURE_HEADER = SIGNATURE_QUERY_PARAM.toLowerCase();\nconst SHA256_HEADER = \"x-amz-content-sha256\";\nconst TOKEN_HEADER = TOKEN_QUERY_PARAM.toLowerCase();\nconst HOST_HEADER = \"host\";\nconst ALWAYS_UNSIGNABLE_HEADERS = {\n    authorization: true,\n    \"cache-control\": true,\n    connection: true,\n    expect: true,\n    from: true,\n    \"keep-alive\": true,\n    \"max-forwards\": true,\n    pragma: true,\n    referer: true,\n    te: true,\n    trailer: true,\n    \"transfer-encoding\": true,\n    upgrade: true,\n    \"user-agent\": true,\n    \"x-amzn-trace-id\": true,\n};\nconst PROXY_HEADER_PATTERN = /^proxy-/;\nconst SEC_HEADER_PATTERN = /^sec-/;\nconst UNSIGNABLE_PATTERNS = [/^proxy-/i, /^sec-/i];\nconst ALGORITHM_IDENTIFIER = \"AWS4-HMAC-SHA256\";\nconst ALGORITHM_IDENTIFIER_V4A = \"AWS4-ECDSA-P256-SHA256\";\nconst EVENT_ALGORITHM_IDENTIFIER = \"AWS4-HMAC-SHA256-PAYLOAD\";\nconst UNSIGNED_PAYLOAD = \"UNSIGNED-PAYLOAD\";\nconst MAX_CACHE_SIZE = 50;\nconst KEY_TYPE_IDENTIFIER = \"aws4_request\";\nconst MAX_PRESIGNED_TTL = 60 * 60 * 24 * 7;\n\nconst signingKeyCache = {};\nconst cacheQueue = [];\nconst createScope = (shortDate, region, service) => `${shortDate}/${region}/${service}/${KEY_TYPE_IDENTIFIER}`;\nconst getSigningKey = async (sha256Constructor, credentials, shortDate, region, service) => {\n    const credsHash = await hmac(sha256Constructor, credentials.secretAccessKey, credentials.accessKeyId);\n    const cacheKey = `${shortDate}:${region}:${service}:${utilHexEncoding.toHex(credsHash)}:${credentials.sessionToken}`;\n    if (cacheKey in signingKeyCache) {\n        return signingKeyCache[cacheKey];\n    }\n    cacheQueue.push(cacheKey);\n    while (cacheQueue.length > MAX_CACHE_SIZE) {\n        delete signingKeyCache[cacheQueue.shift()];\n    }\n    let key = `AWS4${credentials.secretAccessKey}`;\n    for (const signable of [shortDate, region, service, KEY_TYPE_IDENTIFIER]) {\n        key = await hmac(sha256Constructor, key, signable);\n    }\n    return (signingKeyCache[cacheKey] = key);\n};\nconst clearCredentialCache = () => {\n    cacheQueue.length = 0;\n    Object.keys(signingKeyCache).forEach((cacheKey) => {\n        delete signingKeyCache[cacheKey];\n    });\n};\nconst hmac = (ctor, secret, data) => {\n    const hash = new ctor(secret);\n    hash.update(utilUtf8.toUint8Array(data));\n    return hash.digest();\n};\n\nconst getCanonicalHeaders = ({ headers }, unsignableHeaders, signableHeaders) => {\n    const canonical = {};\n    for (const headerName of Object.keys(headers).sort()) {\n        if (headers[headerName] == undefined) {\n            continue;\n        }\n        const canonicalHeaderName = headerName.toLowerCase();\n        if (canonicalHeaderName in ALWAYS_UNSIGNABLE_HEADERS ||\n            unsignableHeaders?.has(canonicalHeaderName) ||\n            PROXY_HEADER_PATTERN.test(canonicalHeaderName) ||\n            SEC_HEADER_PATTERN.test(canonicalHeaderName)) {\n            if (!signableHeaders || (signableHeaders && !signableHeaders.has(canonicalHeaderName))) {\n                continue;\n            }\n        }\n        canonical[canonicalHeaderName] = headers[headerName].trim().replace(/\\s+/g, \" \");\n    }\n    return canonical;\n};\n\nconst getPayloadHash = async ({ headers, body }, hashConstructor) => {\n    for (const headerName of Object.keys(headers)) {\n        if (headerName.toLowerCase() === SHA256_HEADER) {\n            return headers[headerName];\n        }\n    }\n    if (body == undefined) {\n        return \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\";\n    }\n    else if (typeof body === \"string\" || ArrayBuffer.isView(body) || isArrayBuffer.isArrayBuffer(body)) {\n        const hashCtor = new hashConstructor();\n        hashCtor.update(utilUtf8.toUint8Array(body));\n        return utilHexEncoding.toHex(await hashCtor.digest());\n    }\n    return UNSIGNED_PAYLOAD;\n};\n\nclass HeaderFormatter {\n    format(headers) {\n        const chunks = [];\n        for (const headerName of Object.keys(headers)) {\n            const bytes = utilUtf8.fromUtf8(headerName);\n            chunks.push(Uint8Array.from([bytes.byteLength]), bytes, this.formatHeaderValue(headers[headerName]));\n        }\n        const out = new Uint8Array(chunks.reduce((carry, bytes) => carry + bytes.byteLength, 0));\n        let position = 0;\n        for (const chunk of chunks) {\n            out.set(chunk, position);\n            position += chunk.byteLength;\n        }\n        return out;\n    }\n    formatHeaderValue(header) {\n        switch (header.type) {\n            case \"boolean\":\n                return Uint8Array.from([header.value ? 0 : 1]);\n            case \"byte\":\n                return Uint8Array.from([2, header.value]);\n            case \"short\":\n                const shortView = new DataView(new ArrayBuffer(3));\n                shortView.setUint8(0, 3);\n                shortView.setInt16(1, header.value, false);\n                return new Uint8Array(shortView.buffer);\n            case \"integer\":\n                const intView = new DataView(new ArrayBuffer(5));\n                intView.setUint8(0, 4);\n                intView.setInt32(1, header.value, false);\n                return new Uint8Array(intView.buffer);\n            case \"long\":\n                const longBytes = new Uint8Array(9);\n                longBytes[0] = 5;\n                longBytes.set(header.value.bytes, 1);\n                return longBytes;\n            case \"binary\":\n                const binView = new DataView(new ArrayBuffer(3 + header.value.byteLength));\n                binView.setUint8(0, 6);\n                binView.setUint16(1, header.value.byteLength, false);\n                const binBytes = new Uint8Array(binView.buffer);\n                binBytes.set(header.value, 3);\n                return binBytes;\n            case \"string\":\n                const utf8Bytes = utilUtf8.fromUtf8(header.value);\n                const strView = new DataView(new ArrayBuffer(3 + utf8Bytes.byteLength));\n                strView.setUint8(0, 7);\n                strView.setUint16(1, utf8Bytes.byteLength, false);\n                const strBytes = new Uint8Array(strView.buffer);\n                strBytes.set(utf8Bytes, 3);\n                return strBytes;\n            case \"timestamp\":\n                const tsBytes = new Uint8Array(9);\n                tsBytes[0] = 8;\n                tsBytes.set(Int64.fromNumber(header.value.valueOf()).bytes, 1);\n                return tsBytes;\n            case \"uuid\":\n                if (!UUID_PATTERN.test(header.value)) {\n                    throw new Error(`Invalid UUID received: ${header.value}`);\n                }\n                const uuidBytes = new Uint8Array(17);\n                uuidBytes[0] = 9;\n                uuidBytes.set(utilHexEncoding.fromHex(header.value.replace(/\\-/g, \"\")), 1);\n                return uuidBytes;\n        }\n    }\n}\nconst UUID_PATTERN = /^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$/;\nclass Int64 {\n    bytes;\n    constructor(bytes) {\n        this.bytes = bytes;\n        if (bytes.byteLength !== 8) {\n            throw new Error(\"Int64 buffers must be exactly 8 bytes\");\n        }\n    }\n    static fromNumber(number) {\n        if (number > 9_223_372_036_854_775_807 || number < -9223372036854776e3) {\n            throw new Error(`${number} is too large (or, if negative, too small) to represent as an Int64`);\n        }\n        const bytes = new Uint8Array(8);\n        for (let i = 7, remaining = Math.abs(Math.round(number)); i > -1 && remaining > 0; i--, remaining /= 256) {\n            bytes[i] = remaining;\n        }\n        if (number < 0) {\n            negate(bytes);\n        }\n        return new Int64(bytes);\n    }\n    valueOf() {\n        const bytes = this.bytes.slice(0);\n        const negative = bytes[0] & 0b10000000;\n        if (negative) {\n            negate(bytes);\n        }\n        return parseInt(utilHexEncoding.toHex(bytes), 16) * (negative ? -1 : 1);\n    }\n    toString() {\n        return String(this.valueOf());\n    }\n}\nfunction negate(bytes) {\n    for (let i = 0; i < 8; i++) {\n        bytes[i] ^= 0xff;\n    }\n    for (let i = 7; i > -1; i--) {\n        bytes[i]++;\n        if (bytes[i] !== 0)\n            break;\n    }\n}\n\nconst hasHeader = (soughtHeader, headers) => {\n    soughtHeader = soughtHeader.toLowerCase();\n    for (const headerName of Object.keys(headers)) {\n        if (soughtHeader === headerName.toLowerCase()) {\n            return true;\n        }\n    }\n    return false;\n};\n\nconst moveHeadersToQuery = (request, options = {}) => {\n    const { headers, query = {} } = protocolHttp.HttpRequest.clone(request);\n    for (const name of Object.keys(headers)) {\n        const lname = name.toLowerCase();\n        if ((lname.slice(0, 6) === \"x-amz-\" && !options.unhoistableHeaders?.has(lname)) ||\n            options.hoistableHeaders?.has(lname)) {\n            query[name] = headers[name];\n            delete headers[name];\n        }\n    }\n    return {\n        ...request,\n        headers,\n        query,\n    };\n};\n\nconst prepareRequest = (request) => {\n    request = protocolHttp.HttpRequest.clone(request);\n    for (const headerName of Object.keys(request.headers)) {\n        if (GENERATED_HEADERS.indexOf(headerName.toLowerCase()) > -1) {\n            delete request.headers[headerName];\n        }\n    }\n    return request;\n};\n\nconst getCanonicalQuery = ({ query = {} }) => {\n    const keys = [];\n    const serialized = {};\n    for (const key of Object.keys(query)) {\n        if (key.toLowerCase() === SIGNATURE_HEADER) {\n            continue;\n        }\n        const encodedKey = utilUriEscape.escapeUri(key);\n        keys.push(encodedKey);\n        const value = query[key];\n        if (typeof value === \"string\") {\n            serialized[encodedKey] = `${encodedKey}=${utilUriEscape.escapeUri(value)}`;\n        }\n        else if (Array.isArray(value)) {\n            serialized[encodedKey] = value\n                .slice(0)\n                .reduce((encoded, value) => encoded.concat([`${encodedKey}=${utilUriEscape.escapeUri(value)}`]), [])\n                .sort()\n                .join(\"&\");\n        }\n    }\n    return keys\n        .sort()\n        .map((key) => serialized[key])\n        .filter((serialized) => serialized)\n        .join(\"&\");\n};\n\nconst iso8601 = (time) => toDate(time)\n    .toISOString()\n    .replace(/\\.\\d{3}Z$/, \"Z\");\nconst toDate = (time) => {\n    if (typeof time === \"number\") {\n        return new Date(time * 1000);\n    }\n    if (typeof time === \"string\") {\n        if (Number(time)) {\n            return new Date(Number(time) * 1000);\n        }\n        return new Date(time);\n    }\n    return time;\n};\n\nclass SignatureV4Base {\n    service;\n    regionProvider;\n    credentialProvider;\n    sha256;\n    uriEscapePath;\n    applyChecksum;\n    constructor({ applyChecksum, credentials, region, service, sha256, uriEscapePath = true, }) {\n        this.service = service;\n        this.sha256 = sha256;\n        this.uriEscapePath = uriEscapePath;\n        this.applyChecksum = typeof applyChecksum === \"boolean\" ? applyChecksum : true;\n        this.regionProvider = utilMiddleware.normalizeProvider(region);\n        this.credentialProvider = utilMiddleware.normalizeProvider(credentials);\n    }\n    createCanonicalRequest(request, canonicalHeaders, payloadHash) {\n        const sortedHeaders = Object.keys(canonicalHeaders).sort();\n        return `${request.method}\n${this.getCanonicalPath(request)}\n${getCanonicalQuery(request)}\n${sortedHeaders.map((name) => `${name}:${canonicalHeaders[name]}`).join(\"\\n\")}\n\n${sortedHeaders.join(\";\")}\n${payloadHash}`;\n    }\n    async createStringToSign(longDate, credentialScope, canonicalRequest, algorithmIdentifier) {\n        const hash = new this.sha256();\n        hash.update(utilUtf8.toUint8Array(canonicalRequest));\n        const hashedRequest = await hash.digest();\n        return `${algorithmIdentifier}\n${longDate}\n${credentialScope}\n${utilHexEncoding.toHex(hashedRequest)}`;\n    }\n    getCanonicalPath({ path }) {\n        if (this.uriEscapePath) {\n            const normalizedPathSegments = [];\n            for (const pathSegment of path.split(\"/\")) {\n                if (pathSegment?.length === 0)\n                    continue;\n                if (pathSegment === \".\")\n                    continue;\n                if (pathSegment === \"..\") {\n                    normalizedPathSegments.pop();\n                }\n                else {\n                    normalizedPathSegments.push(pathSegment);\n                }\n            }\n            const normalizedPath = `${path?.startsWith(\"/\") ? \"/\" : \"\"}${normalizedPathSegments.join(\"/\")}${normalizedPathSegments.length > 0 && path?.endsWith(\"/\") ? \"/\" : \"\"}`;\n            const doubleEncoded = utilUriEscape.escapeUri(normalizedPath);\n            return doubleEncoded.replace(/%2F/g, \"/\");\n        }\n        return path;\n    }\n    validateResolvedCredentials(credentials) {\n        if (typeof credentials !== \"object\" ||\n            typeof credentials.accessKeyId !== \"string\" ||\n            typeof credentials.secretAccessKey !== \"string\") {\n            throw new Error(\"Resolved credential object is not valid\");\n        }\n    }\n    formatDate(now) {\n        const longDate = iso8601(now).replace(/[\\-:]/g, \"\");\n        return {\n            longDate,\n            shortDate: longDate.slice(0, 8),\n        };\n    }\n    getCanonicalHeaderList(headers) {\n        return Object.keys(headers).sort().join(\";\");\n    }\n}\n\nclass SignatureV4 extends SignatureV4Base {\n    headerFormatter = new HeaderFormatter();\n    constructor({ applyChecksum, credentials, region, service, sha256, uriEscapePath = true, }) {\n        super({\n            applyChecksum,\n            credentials,\n            region,\n            service,\n            sha256,\n            uriEscapePath,\n        });\n    }\n    async presign(originalRequest, options = {}) {\n        const { signingDate = new Date(), expiresIn = 3600, unsignableHeaders, unhoistableHeaders, signableHeaders, hoistableHeaders, signingRegion, signingService, } = options;\n        const credentials = await this.credentialProvider();\n        this.validateResolvedCredentials(credentials);\n        const region = signingRegion ?? (await this.regionProvider());\n        const { longDate, shortDate } = this.formatDate(signingDate);\n        if (expiresIn > MAX_PRESIGNED_TTL) {\n            return Promise.reject(\"Signature version 4 presigned URLs\" + \" must have an expiration date less than one week in\" + \" the future\");\n        }\n        const scope = createScope(shortDate, region, signingService ?? this.service);\n        const request = moveHeadersToQuery(prepareRequest(originalRequest), { unhoistableHeaders, hoistableHeaders });\n        if (credentials.sessionToken) {\n            request.query[TOKEN_QUERY_PARAM] = credentials.sessionToken;\n        }\n        request.query[ALGORITHM_QUERY_PARAM] = ALGORITHM_IDENTIFIER;\n        request.query[CREDENTIAL_QUERY_PARAM] = `${credentials.accessKeyId}/${scope}`;\n        request.query[AMZ_DATE_QUERY_PARAM] = longDate;\n        request.query[EXPIRES_QUERY_PARAM] = expiresIn.toString(10);\n        const canonicalHeaders = getCanonicalHeaders(request, unsignableHeaders, signableHeaders);\n        request.query[SIGNED_HEADERS_QUERY_PARAM] = this.getCanonicalHeaderList(canonicalHeaders);\n        request.query[SIGNATURE_QUERY_PARAM] = await this.getSignature(longDate, scope, this.getSigningKey(credentials, region, shortDate, signingService), this.createCanonicalRequest(request, canonicalHeaders, await getPayloadHash(originalRequest, this.sha256)));\n        return request;\n    }\n    async sign(toSign, options) {\n        if (typeof toSign === \"string\") {\n            return this.signString(toSign, options);\n        }\n        else if (toSign.headers && toSign.payload) {\n            return this.signEvent(toSign, options);\n        }\n        else if (toSign.message) {\n            return this.signMessage(toSign, options);\n        }\n        else {\n            return this.signRequest(toSign, options);\n        }\n    }\n    async signEvent({ headers, payload }, { signingDate = new Date(), priorSignature, signingRegion, signingService }) {\n        const region = signingRegion ?? (await this.regionProvider());\n        const { shortDate, longDate } = this.formatDate(signingDate);\n        const scope = createScope(shortDate, region, signingService ?? this.service);\n        const hashedPayload = await getPayloadHash({ headers: {}, body: payload }, this.sha256);\n        const hash = new this.sha256();\n        hash.update(headers);\n        const hashedHeaders = utilHexEncoding.toHex(await hash.digest());\n        const stringToSign = [\n            EVENT_ALGORITHM_IDENTIFIER,\n            longDate,\n            scope,\n            priorSignature,\n            hashedHeaders,\n            hashedPayload,\n        ].join(\"\\n\");\n        return this.signString(stringToSign, { signingDate, signingRegion: region, signingService });\n    }\n    async signMessage(signableMessage, { signingDate = new Date(), signingRegion, signingService }) {\n        const promise = this.signEvent({\n            headers: this.headerFormatter.format(signableMessage.message.headers),\n            payload: signableMessage.message.body,\n        }, {\n            signingDate,\n            signingRegion,\n            signingService,\n            priorSignature: signableMessage.priorSignature,\n        });\n        return promise.then((signature) => {\n            return { message: signableMessage.message, signature };\n        });\n    }\n    async signString(stringToSign, { signingDate = new Date(), signingRegion, signingService } = {}) {\n        const credentials = await this.credentialProvider();\n        this.validateResolvedCredentials(credentials);\n        const region = signingRegion ?? (await this.regionProvider());\n        const { shortDate } = this.formatDate(signingDate);\n        const hash = new this.sha256(await this.getSigningKey(credentials, region, shortDate, signingService));\n        hash.update(utilUtf8.toUint8Array(stringToSign));\n        return utilHexEncoding.toHex(await hash.digest());\n    }\n    async signRequest(requestToSign, { signingDate = new Date(), signableHeaders, unsignableHeaders, signingRegion, signingService, } = {}) {\n        const credentials = await this.credentialProvider();\n        this.validateResolvedCredentials(credentials);\n        const region = signingRegion ?? (await this.regionProvider());\n        const request = prepareRequest(requestToSign);\n        const { longDate, shortDate } = this.formatDate(signingDate);\n        const scope = createScope(shortDate, region, signingService ?? this.service);\n        request.headers[AMZ_DATE_HEADER] = longDate;\n        if (credentials.sessionToken) {\n            request.headers[TOKEN_HEADER] = credentials.sessionToken;\n        }\n        const payloadHash = await getPayloadHash(request, this.sha256);\n        if (!hasHeader(SHA256_HEADER, request.headers) && this.applyChecksum) {\n            request.headers[SHA256_HEADER] = payloadHash;\n        }\n        const canonicalHeaders = getCanonicalHeaders(request, unsignableHeaders, signableHeaders);\n        const signature = await this.getSignature(longDate, scope, this.getSigningKey(credentials, region, shortDate, signingService), this.createCanonicalRequest(request, canonicalHeaders, payloadHash));\n        request.headers[AUTH_HEADER] =\n            `${ALGORITHM_IDENTIFIER} ` +\n                `Credential=${credentials.accessKeyId}/${scope}, ` +\n                `SignedHeaders=${this.getCanonicalHeaderList(canonicalHeaders)}, ` +\n                `Signature=${signature}`;\n        return request;\n    }\n    async getSignature(longDate, credentialScope, keyPromise, canonicalRequest) {\n        const stringToSign = await this.createStringToSign(longDate, credentialScope, canonicalRequest, ALGORITHM_IDENTIFIER);\n        const hash = new this.sha256(await keyPromise);\n        hash.update(utilUtf8.toUint8Array(stringToSign));\n        return utilHexEncoding.toHex(await hash.digest());\n    }\n    getSigningKey(credentials, region, shortDate, service) {\n        return getSigningKey(this.sha256, credentials, shortDate, region, service || this.service);\n    }\n}\n\nconst signatureV4aContainer = {\n    SignatureV4a: null,\n};\n\nexports.ALGORITHM_IDENTIFIER = ALGORITHM_IDENTIFIER;\nexports.ALGORITHM_IDENTIFIER_V4A = ALGORITHM_IDENTIFIER_V4A;\nexports.ALGORITHM_QUERY_PARAM = ALGORITHM_QUERY_PARAM;\nexports.ALWAYS_UNSIGNABLE_HEADERS = ALWAYS_UNSIGNABLE_HEADERS;\nexports.AMZ_DATE_HEADER = AMZ_DATE_HEADER;\nexports.AMZ_DATE_QUERY_PARAM = AMZ_DATE_QUERY_PARAM;\nexports.AUTH_HEADER = AUTH_HEADER;\nexports.CREDENTIAL_QUERY_PARAM = CREDENTIAL_QUERY_PARAM;\nexports.DATE_HEADER = DATE_HEADER;\nexports.EVENT_ALGORITHM_IDENTIFIER = EVENT_ALGORITHM_IDENTIFIER;\nexports.EXPIRES_QUERY_PARAM = EXPIRES_QUERY_PARAM;\nexports.GENERATED_HEADERS = GENERATED_HEADERS;\nexports.HOST_HEADER = HOST_HEADER;\nexports.KEY_TYPE_IDENTIFIER = KEY_TYPE_IDENTIFIER;\nexports.MAX_CACHE_SIZE = MAX_CACHE_SIZE;\nexports.MAX_PRESIGNED_TTL = MAX_PRESIGNED_TTL;\nexports.PROXY_HEADER_PATTERN = PROXY_HEADER_PATTERN;\nexports.REGION_SET_PARAM = REGION_SET_PARAM;\nexports.SEC_HEADER_PATTERN = SEC_HEADER_PATTERN;\nexports.SHA256_HEADER = SHA256_HEADER;\nexports.SIGNATURE_HEADER = SIGNATURE_HEADER;\nexports.SIGNATURE_QUERY_PARAM = SIGNATURE_QUERY_PARAM;\nexports.SIGNED_HEADERS_QUERY_PARAM = SIGNED_HEADERS_QUERY_PARAM;\nexports.SignatureV4 = SignatureV4;\nexports.SignatureV4Base = SignatureV4Base;\nexports.TOKEN_HEADER = TOKEN_HEADER;\nexports.TOKEN_QUERY_PARAM = TOKEN_QUERY_PARAM;\nexports.UNSIGNABLE_PATTERNS = UNSIGNABLE_PATTERNS;\nexports.UNSIGNED_PAYLOAD = UNSIGNED_PAYLOAD;\nexports.clearCredentialCache = clearCredentialCache;\nexports.createScope = createScope;\nexports.getCanonicalHeaders = getCanonicalHeaders;\nexports.getCanonicalQuery = getCanonicalQuery;\nexports.getPayloadHash = getPayloadHash;\nexports.getSigningKey = getSigningKey;\nexports.hasHeader = hasHeader;\nexports.moveHeadersToQuery = moveHeadersToQuery;\nexports.prepareRequest = prepareRequest;\nexports.signatureV4aContainer = signatureV4aContainer;\n","'use strict';\n\nvar middlewareStack = require('@smithy/middleware-stack');\nvar protocols = require('@smithy/core/protocols');\nvar types = require('@smithy/types');\nvar schema = require('@smithy/core/schema');\nvar serde = require('@smithy/core/serde');\n\nclass Client {\n    config;\n    middlewareStack = middlewareStack.constructStack();\n    initConfig;\n    handlers;\n    constructor(config) {\n        this.config = config;\n        const { protocol, protocolSettings } = config;\n        if (protocolSettings) {\n            if (typeof protocol === \"function\") {\n                config.protocol = new protocol(protocolSettings);\n            }\n        }\n    }\n    send(command, optionsOrCb, cb) {\n        const options = typeof optionsOrCb !== \"function\" ? optionsOrCb : undefined;\n        const callback = typeof optionsOrCb === \"function\" ? optionsOrCb : cb;\n        const useHandlerCache = options === undefined && this.config.cacheMiddleware === true;\n        let handler;\n        if (useHandlerCache) {\n            if (!this.handlers) {\n                this.handlers = new WeakMap();\n            }\n            const handlers = this.handlers;\n            if (handlers.has(command.constructor)) {\n                handler = handlers.get(command.constructor);\n            }\n            else {\n                handler = command.resolveMiddleware(this.middlewareStack, this.config, options);\n                handlers.set(command.constructor, handler);\n            }\n        }\n        else {\n            delete this.handlers;\n            handler = command.resolveMiddleware(this.middlewareStack, this.config, options);\n        }\n        if (callback) {\n            handler(command)\n                .then((result) => callback(null, result.output), (err) => callback(err))\n                .catch(() => { });\n        }\n        else {\n            return handler(command).then((result) => result.output);\n        }\n    }\n    destroy() {\n        this.config?.requestHandler?.destroy?.();\n        delete this.handlers;\n    }\n}\n\nconst SENSITIVE_STRING$1 = \"***SensitiveInformation***\";\nfunction schemaLogFilter(schema$1, data) {\n    if (data == null) {\n        return data;\n    }\n    const ns = schema.NormalizedSchema.of(schema$1);\n    if (ns.getMergedTraits().sensitive) {\n        return SENSITIVE_STRING$1;\n    }\n    if (ns.isListSchema()) {\n        const isSensitive = !!ns.getValueSchema().getMergedTraits().sensitive;\n        if (isSensitive) {\n            return SENSITIVE_STRING$1;\n        }\n    }\n    else if (ns.isMapSchema()) {\n        const isSensitive = !!ns.getKeySchema().getMergedTraits().sensitive || !!ns.getValueSchema().getMergedTraits().sensitive;\n        if (isSensitive) {\n            return SENSITIVE_STRING$1;\n        }\n    }\n    else if (ns.isStructSchema() && typeof data === \"object\") {\n        const object = data;\n        const newObject = {};\n        for (const [member, memberNs] of ns.structIterator()) {\n            if (object[member] != null) {\n                newObject[member] = schemaLogFilter(memberNs, object[member]);\n            }\n        }\n        return newObject;\n    }\n    return data;\n}\n\nclass Command {\n    middlewareStack = middlewareStack.constructStack();\n    schema;\n    static classBuilder() {\n        return new ClassBuilder();\n    }\n    resolveMiddlewareWithContext(clientStack, configuration, options, { middlewareFn, clientName, commandName, inputFilterSensitiveLog, outputFilterSensitiveLog, smithyContext, additionalContext, CommandCtor, }) {\n        for (const mw of middlewareFn.bind(this)(CommandCtor, clientStack, configuration, options)) {\n            this.middlewareStack.use(mw);\n        }\n        const stack = clientStack.concat(this.middlewareStack);\n        const { logger } = configuration;\n        const handlerExecutionContext = {\n            logger,\n            clientName,\n            commandName,\n            inputFilterSensitiveLog,\n            outputFilterSensitiveLog,\n            [types.SMITHY_CONTEXT_KEY]: {\n                commandInstance: this,\n                ...smithyContext,\n            },\n            ...additionalContext,\n        };\n        const { requestHandler } = configuration;\n        return stack.resolve((request) => requestHandler.handle(request.request, options || {}), handlerExecutionContext);\n    }\n}\nclass ClassBuilder {\n    _init = () => { };\n    _ep = {};\n    _middlewareFn = () => [];\n    _commandName = \"\";\n    _clientName = \"\";\n    _additionalContext = {};\n    _smithyContext = {};\n    _inputFilterSensitiveLog = undefined;\n    _outputFilterSensitiveLog = undefined;\n    _serializer = null;\n    _deserializer = null;\n    _operationSchema;\n    init(cb) {\n        this._init = cb;\n    }\n    ep(endpointParameterInstructions) {\n        this._ep = endpointParameterInstructions;\n        return this;\n    }\n    m(middlewareSupplier) {\n        this._middlewareFn = middlewareSupplier;\n        return this;\n    }\n    s(service, operation, smithyContext = {}) {\n        this._smithyContext = {\n            service,\n            operation,\n            ...smithyContext,\n        };\n        return this;\n    }\n    c(additionalContext = {}) {\n        this._additionalContext = additionalContext;\n        return this;\n    }\n    n(clientName, commandName) {\n        this._clientName = clientName;\n        this._commandName = commandName;\n        return this;\n    }\n    f(inputFilter = (_) => _, outputFilter = (_) => _) {\n        this._inputFilterSensitiveLog = inputFilter;\n        this._outputFilterSensitiveLog = outputFilter;\n        return this;\n    }\n    ser(serializer) {\n        this._serializer = serializer;\n        return this;\n    }\n    de(deserializer) {\n        this._deserializer = deserializer;\n        return this;\n    }\n    sc(operation) {\n        this._operationSchema = operation;\n        this._smithyContext.operationSchema = operation;\n        return this;\n    }\n    build() {\n        const closure = this;\n        let CommandRef;\n        return (CommandRef = class extends Command {\n            input;\n            static getEndpointParameterInstructions() {\n                return closure._ep;\n            }\n            constructor(...[input]) {\n                super();\n                this.input = input ?? {};\n                closure._init(this);\n                this.schema = closure._operationSchema;\n            }\n            resolveMiddleware(stack, configuration, options) {\n                const op = closure._operationSchema;\n                const input = op?.[4] ?? op?.input;\n                const output = op?.[5] ?? op?.output;\n                return this.resolveMiddlewareWithContext(stack, configuration, options, {\n                    CommandCtor: CommandRef,\n                    middlewareFn: closure._middlewareFn,\n                    clientName: closure._clientName,\n                    commandName: closure._commandName,\n                    inputFilterSensitiveLog: closure._inputFilterSensitiveLog ?? (op ? schemaLogFilter.bind(null, input) : (_) => _),\n                    outputFilterSensitiveLog: closure._outputFilterSensitiveLog ?? (op ? schemaLogFilter.bind(null, output) : (_) => _),\n                    smithyContext: closure._smithyContext,\n                    additionalContext: closure._additionalContext,\n                });\n            }\n            serialize = closure._serializer;\n            deserialize = closure._deserializer;\n        });\n    }\n}\n\nconst SENSITIVE_STRING = \"***SensitiveInformation***\";\n\nconst createAggregatedClient = (commands, Client, options) => {\n    for (const [command, CommandCtor] of Object.entries(commands)) {\n        const methodImpl = async function (args, optionsOrCb, cb) {\n            const command = new CommandCtor(args);\n            if (typeof optionsOrCb === \"function\") {\n                this.send(command, optionsOrCb);\n            }\n            else if (typeof cb === \"function\") {\n                if (typeof optionsOrCb !== \"object\")\n                    throw new Error(`Expected http options but got ${typeof optionsOrCb}`);\n                this.send(command, optionsOrCb || {}, cb);\n            }\n            else {\n                return this.send(command, optionsOrCb);\n            }\n        };\n        const methodName = (command[0].toLowerCase() + command.slice(1)).replace(/Command$/, \"\");\n        Client.prototype[methodName] = methodImpl;\n    }\n    const { paginators = {}, waiters = {} } = options ?? {};\n    for (const [paginatorName, paginatorFn] of Object.entries(paginators)) {\n        if (Client.prototype[paginatorName] === void 0) {\n            Client.prototype[paginatorName] = function (commandInput = {}, paginationConfiguration, ...rest) {\n                return paginatorFn({\n                    ...paginationConfiguration,\n                    client: this,\n                }, commandInput, ...rest);\n            };\n        }\n    }\n    for (const [waiterName, waiterFn] of Object.entries(waiters)) {\n        if (Client.prototype[waiterName] === void 0) {\n            Client.prototype[waiterName] = async function (commandInput = {}, waiterConfiguration, ...rest) {\n                let config = waiterConfiguration;\n                if (typeof waiterConfiguration === \"number\") {\n                    config = {\n                        maxWaitTime: waiterConfiguration,\n                    };\n                }\n                return waiterFn({\n                    ...config,\n                    client: this,\n                }, commandInput, ...rest);\n            };\n        }\n    }\n};\n\nclass ServiceException extends Error {\n    $fault;\n    $response;\n    $retryable;\n    $metadata;\n    constructor(options) {\n        super(options.message);\n        Object.setPrototypeOf(this, Object.getPrototypeOf(this).constructor.prototype);\n        this.name = options.name;\n        this.$fault = options.$fault;\n        this.$metadata = options.$metadata;\n    }\n    static isInstance(value) {\n        if (!value)\n            return false;\n        const candidate = value;\n        return (ServiceException.prototype.isPrototypeOf(candidate) ||\n            (Boolean(candidate.$fault) &&\n                Boolean(candidate.$metadata) &&\n                (candidate.$fault === \"client\" || candidate.$fault === \"server\")));\n    }\n    static [Symbol.hasInstance](instance) {\n        if (!instance)\n            return false;\n        const candidate = instance;\n        if (this === ServiceException) {\n            return ServiceException.isInstance(instance);\n        }\n        if (ServiceException.isInstance(instance)) {\n            if (candidate.name && this.name) {\n                return this.prototype.isPrototypeOf(instance) || candidate.name === this.name;\n            }\n            return this.prototype.isPrototypeOf(instance);\n        }\n        return false;\n    }\n}\nconst decorateServiceException = (exception, additions = {}) => {\n    Object.entries(additions)\n        .filter(([, v]) => v !== undefined)\n        .forEach(([k, v]) => {\n        if (exception[k] == undefined || exception[k] === \"\") {\n            exception[k] = v;\n        }\n    });\n    const message = exception.message || exception.Message || \"UnknownError\";\n    exception.message = message;\n    delete exception.Message;\n    return exception;\n};\n\nconst throwDefaultError = ({ output, parsedBody, exceptionCtor, errorCode }) => {\n    const $metadata = deserializeMetadata(output);\n    const statusCode = $metadata.httpStatusCode ? $metadata.httpStatusCode + \"\" : undefined;\n    const response = new exceptionCtor({\n        name: parsedBody?.code || parsedBody?.Code || errorCode || statusCode || \"UnknownError\",\n        $fault: \"client\",\n        $metadata,\n    });\n    throw decorateServiceException(response, parsedBody);\n};\nconst withBaseException = (ExceptionCtor) => {\n    return ({ output, parsedBody, errorCode }) => {\n        throwDefaultError({ output, parsedBody, exceptionCtor: ExceptionCtor, errorCode });\n    };\n};\nconst deserializeMetadata = (output) => ({\n    httpStatusCode: output.statusCode,\n    requestId: output.headers[\"x-amzn-requestid\"] ?? output.headers[\"x-amzn-request-id\"] ?? output.headers[\"x-amz-request-id\"],\n    extendedRequestId: output.headers[\"x-amz-id-2\"],\n    cfId: output.headers[\"x-amz-cf-id\"],\n});\n\nconst loadConfigsForDefaultMode = (mode) => {\n    switch (mode) {\n        case \"standard\":\n            return {\n                retryMode: \"standard\",\n                connectionTimeout: 3100,\n            };\n        case \"in-region\":\n            return {\n                retryMode: \"standard\",\n                connectionTimeout: 1100,\n            };\n        case \"cross-region\":\n            return {\n                retryMode: \"standard\",\n                connectionTimeout: 3100,\n            };\n        case \"mobile\":\n            return {\n                retryMode: \"standard\",\n                connectionTimeout: 30000,\n            };\n        default:\n            return {};\n    }\n};\n\nlet warningEmitted = false;\nconst emitWarningIfUnsupportedVersion = (version) => {\n    if (version && !warningEmitted && parseInt(version.substring(1, version.indexOf(\".\"))) < 16) {\n        warningEmitted = true;\n    }\n};\n\nconst getChecksumConfiguration = (runtimeConfig) => {\n    const checksumAlgorithms = [];\n    for (const id in types.AlgorithmId) {\n        const algorithmId = types.AlgorithmId[id];\n        if (runtimeConfig[algorithmId] === undefined) {\n            continue;\n        }\n        checksumAlgorithms.push({\n            algorithmId: () => algorithmId,\n            checksumConstructor: () => runtimeConfig[algorithmId],\n        });\n    }\n    return {\n        addChecksumAlgorithm(algo) {\n            checksumAlgorithms.push(algo);\n        },\n        checksumAlgorithms() {\n            return checksumAlgorithms;\n        },\n    };\n};\nconst resolveChecksumRuntimeConfig = (clientConfig) => {\n    const runtimeConfig = {};\n    clientConfig.checksumAlgorithms().forEach((checksumAlgorithm) => {\n        runtimeConfig[checksumAlgorithm.algorithmId()] = checksumAlgorithm.checksumConstructor();\n    });\n    return runtimeConfig;\n};\n\nconst getRetryConfiguration = (runtimeConfig) => {\n    return {\n        setRetryStrategy(retryStrategy) {\n            runtimeConfig.retryStrategy = retryStrategy;\n        },\n        retryStrategy() {\n            return runtimeConfig.retryStrategy;\n        },\n    };\n};\nconst resolveRetryRuntimeConfig = (retryStrategyConfiguration) => {\n    const runtimeConfig = {};\n    runtimeConfig.retryStrategy = retryStrategyConfiguration.retryStrategy();\n    return runtimeConfig;\n};\n\nconst getDefaultExtensionConfiguration = (runtimeConfig) => {\n    return Object.assign(getChecksumConfiguration(runtimeConfig), getRetryConfiguration(runtimeConfig));\n};\nconst getDefaultClientConfiguration = getDefaultExtensionConfiguration;\nconst resolveDefaultRuntimeConfig = (config) => {\n    return Object.assign(resolveChecksumRuntimeConfig(config), resolveRetryRuntimeConfig(config));\n};\n\nconst getArrayIfSingleItem = (mayBeArray) => Array.isArray(mayBeArray) ? mayBeArray : [mayBeArray];\n\nconst getValueFromTextNode = (obj) => {\n    const textNodeName = \"#text\";\n    for (const key in obj) {\n        if (obj.hasOwnProperty(key) && obj[key][textNodeName] !== undefined) {\n            obj[key] = obj[key][textNodeName];\n        }\n        else if (typeof obj[key] === \"object\" && obj[key] !== null) {\n            obj[key] = getValueFromTextNode(obj[key]);\n        }\n    }\n    return obj;\n};\n\nconst isSerializableHeaderValue = (value) => {\n    return value != null;\n};\n\nclass NoOpLogger {\n    trace() { }\n    debug() { }\n    info() { }\n    warn() { }\n    error() { }\n}\n\nfunction map(arg0, arg1, arg2) {\n    let target;\n    let filter;\n    let instructions;\n    if (typeof arg1 === \"undefined\" && typeof arg2 === \"undefined\") {\n        target = {};\n        instructions = arg0;\n    }\n    else {\n        target = arg0;\n        if (typeof arg1 === \"function\") {\n            filter = arg1;\n            instructions = arg2;\n            return mapWithFilter(target, filter, instructions);\n        }\n        else {\n            instructions = arg1;\n        }\n    }\n    for (const key of Object.keys(instructions)) {\n        if (!Array.isArray(instructions[key])) {\n            target[key] = instructions[key];\n            continue;\n        }\n        applyInstruction(target, null, instructions, key);\n    }\n    return target;\n}\nconst convertMap = (target) => {\n    const output = {};\n    for (const [k, v] of Object.entries(target || {})) {\n        output[k] = [, v];\n    }\n    return output;\n};\nconst take = (source, instructions) => {\n    const out = {};\n    for (const key in instructions) {\n        applyInstruction(out, source, instructions, key);\n    }\n    return out;\n};\nconst mapWithFilter = (target, filter, instructions) => {\n    return map(target, Object.entries(instructions).reduce((_instructions, [key, value]) => {\n        if (Array.isArray(value)) {\n            _instructions[key] = value;\n        }\n        else {\n            if (typeof value === \"function\") {\n                _instructions[key] = [filter, value()];\n            }\n            else {\n                _instructions[key] = [filter, value];\n            }\n        }\n        return _instructions;\n    }, {}));\n};\nconst applyInstruction = (target, source, instructions, targetKey) => {\n    if (source !== null) {\n        let instruction = instructions[targetKey];\n        if (typeof instruction === \"function\") {\n            instruction = [, instruction];\n        }\n        const [filter = nonNullish, valueFn = pass, sourceKey = targetKey] = instruction;\n        if ((typeof filter === \"function\" && filter(source[sourceKey])) || (typeof filter !== \"function\" && !!filter)) {\n            target[targetKey] = valueFn(source[sourceKey]);\n        }\n        return;\n    }\n    let [filter, value] = instructions[targetKey];\n    if (typeof value === \"function\") {\n        let _value;\n        const defaultFilterPassed = filter === undefined && (_value = value()) != null;\n        const customFilterPassed = (typeof filter === \"function\" && !!filter(void 0)) || (typeof filter !== \"function\" && !!filter);\n        if (defaultFilterPassed) {\n            target[targetKey] = _value;\n        }\n        else if (customFilterPassed) {\n            target[targetKey] = value();\n        }\n    }\n    else {\n        const defaultFilterPassed = filter === undefined && value != null;\n        const customFilterPassed = (typeof filter === \"function\" && !!filter(value)) || (typeof filter !== \"function\" && !!filter);\n        if (defaultFilterPassed || customFilterPassed) {\n            target[targetKey] = value;\n        }\n    }\n};\nconst nonNullish = (_) => _ != null;\nconst pass = (_) => _;\n\nconst serializeFloat = (value) => {\n    if (value !== value) {\n        return \"NaN\";\n    }\n    switch (value) {\n        case Infinity:\n            return \"Infinity\";\n        case -Infinity:\n            return \"-Infinity\";\n        default:\n            return value;\n    }\n};\nconst serializeDateTime = (date) => date.toISOString().replace(\".000Z\", \"Z\");\n\nconst _json = (obj) => {\n    if (obj == null) {\n        return {};\n    }\n    if (Array.isArray(obj)) {\n        return obj.filter((_) => _ != null).map(_json);\n    }\n    if (typeof obj === \"object\") {\n        const target = {};\n        for (const key of Object.keys(obj)) {\n            if (obj[key] == null) {\n                continue;\n            }\n            target[key] = _json(obj[key]);\n        }\n        return target;\n    }\n    return obj;\n};\n\nObject.defineProperty(exports, \"collectBody\", {\n    enumerable: true,\n    get: function () { return protocols.collectBody; }\n});\nObject.defineProperty(exports, \"extendedEncodeURIComponent\", {\n    enumerable: true,\n    get: function () { return protocols.extendedEncodeURIComponent; }\n});\nObject.defineProperty(exports, \"resolvedPath\", {\n    enumerable: true,\n    get: function () { return protocols.resolvedPath; }\n});\nexports.Client = Client;\nexports.Command = Command;\nexports.NoOpLogger = NoOpLogger;\nexports.SENSITIVE_STRING = SENSITIVE_STRING;\nexports.ServiceException = ServiceException;\nexports._json = _json;\nexports.convertMap = convertMap;\nexports.createAggregatedClient = createAggregatedClient;\nexports.decorateServiceException = decorateServiceException;\nexports.emitWarningIfUnsupportedVersion = emitWarningIfUnsupportedVersion;\nexports.getArrayIfSingleItem = getArrayIfSingleItem;\nexports.getDefaultClientConfiguration = getDefaultClientConfiguration;\nexports.getDefaultExtensionConfiguration = getDefaultExtensionConfiguration;\nexports.getValueFromTextNode = getValueFromTextNode;\nexports.isSerializableHeaderValue = isSerializableHeaderValue;\nexports.loadConfigsForDefaultMode = loadConfigsForDefaultMode;\nexports.map = map;\nexports.resolveDefaultRuntimeConfig = resolveDefaultRuntimeConfig;\nexports.serializeDateTime = serializeDateTime;\nexports.serializeFloat = serializeFloat;\nexports.take = take;\nexports.throwDefaultError = throwDefaultError;\nexports.withBaseException = withBaseException;\nObject.keys(serde).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return serde[k]; }\n    });\n});\n","'use strict';\n\nexports.HttpAuthLocation = void 0;\n(function (HttpAuthLocation) {\n    HttpAuthLocation[\"HEADER\"] = \"header\";\n    HttpAuthLocation[\"QUERY\"] = \"query\";\n})(exports.HttpAuthLocation || (exports.HttpAuthLocation = {}));\n\nexports.HttpApiKeyAuthLocation = void 0;\n(function (HttpApiKeyAuthLocation) {\n    HttpApiKeyAuthLocation[\"HEADER\"] = \"header\";\n    HttpApiKeyAuthLocation[\"QUERY\"] = \"query\";\n})(exports.HttpApiKeyAuthLocation || (exports.HttpApiKeyAuthLocation = {}));\n\nexports.EndpointURLScheme = void 0;\n(function (EndpointURLScheme) {\n    EndpointURLScheme[\"HTTP\"] = \"http\";\n    EndpointURLScheme[\"HTTPS\"] = \"https\";\n})(exports.EndpointURLScheme || (exports.EndpointURLScheme = {}));\n\nexports.AlgorithmId = void 0;\n(function (AlgorithmId) {\n    AlgorithmId[\"MD5\"] = \"md5\";\n    AlgorithmId[\"CRC32\"] = \"crc32\";\n    AlgorithmId[\"CRC32C\"] = \"crc32c\";\n    AlgorithmId[\"SHA1\"] = \"sha1\";\n    AlgorithmId[\"SHA256\"] = \"sha256\";\n})(exports.AlgorithmId || (exports.AlgorithmId = {}));\nconst getChecksumConfiguration = (runtimeConfig) => {\n    const checksumAlgorithms = [];\n    if (runtimeConfig.sha256 !== undefined) {\n        checksumAlgorithms.push({\n            algorithmId: () => exports.AlgorithmId.SHA256,\n            checksumConstructor: () => runtimeConfig.sha256,\n        });\n    }\n    if (runtimeConfig.md5 != undefined) {\n        checksumAlgorithms.push({\n            algorithmId: () => exports.AlgorithmId.MD5,\n            checksumConstructor: () => runtimeConfig.md5,\n        });\n    }\n    return {\n        addChecksumAlgorithm(algo) {\n            checksumAlgorithms.push(algo);\n        },\n        checksumAlgorithms() {\n            return checksumAlgorithms;\n        },\n    };\n};\nconst resolveChecksumRuntimeConfig = (clientConfig) => {\n    const runtimeConfig = {};\n    clientConfig.checksumAlgorithms().forEach((checksumAlgorithm) => {\n        runtimeConfig[checksumAlgorithm.algorithmId()] = checksumAlgorithm.checksumConstructor();\n    });\n    return runtimeConfig;\n};\n\nconst getDefaultClientConfiguration = (runtimeConfig) => {\n    return getChecksumConfiguration(runtimeConfig);\n};\nconst resolveDefaultRuntimeConfig = (config) => {\n    return resolveChecksumRuntimeConfig(config);\n};\n\nexports.FieldPosition = void 0;\n(function (FieldPosition) {\n    FieldPosition[FieldPosition[\"HEADER\"] = 0] = \"HEADER\";\n    FieldPosition[FieldPosition[\"TRAILER\"] = 1] = \"TRAILER\";\n})(exports.FieldPosition || (exports.FieldPosition = {}));\n\nconst SMITHY_CONTEXT_KEY = \"__smithy_context\";\n\nexports.IniSectionType = void 0;\n(function (IniSectionType) {\n    IniSectionType[\"PROFILE\"] = \"profile\";\n    IniSectionType[\"SSO_SESSION\"] = \"sso-session\";\n    IniSectionType[\"SERVICES\"] = \"services\";\n})(exports.IniSectionType || (exports.IniSectionType = {}));\n\nexports.RequestHandlerProtocol = void 0;\n(function (RequestHandlerProtocol) {\n    RequestHandlerProtocol[\"HTTP_0_9\"] = \"http/0.9\";\n    RequestHandlerProtocol[\"HTTP_1_0\"] = \"http/1.0\";\n    RequestHandlerProtocol[\"TDS_8_0\"] = \"tds/8.0\";\n})(exports.RequestHandlerProtocol || (exports.RequestHandlerProtocol = {}));\n\nexports.SMITHY_CONTEXT_KEY = SMITHY_CONTEXT_KEY;\nexports.getDefaultClientConfiguration = getDefaultClientConfiguration;\nexports.resolveDefaultRuntimeConfig = resolveDefaultRuntimeConfig;\n","'use strict';\n\nvar querystringParser = require('@smithy/querystring-parser');\n\nconst parseUrl = (url) => {\n    if (typeof url === \"string\") {\n        return parseUrl(new URL(url));\n    }\n    const { hostname, pathname, port, protocol, search } = url;\n    let query;\n    if (search) {\n        query = querystringParser.parseQueryString(search);\n    }\n    return {\n        hostname,\n        port: port ? parseInt(port) : undefined,\n        protocol,\n        path: pathname,\n        query,\n    };\n};\n\nexports.parseUrl = parseUrl;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fromBase64 = void 0;\nconst util_buffer_from_1 = require(\"@smithy/util-buffer-from\");\nconst BASE64_REGEX = /^[A-Za-z0-9+/]*={0,2}$/;\nconst fromBase64 = (input) => {\n    if ((input.length * 3) % 4 !== 0) {\n        throw new TypeError(`Incorrect padding on base64 string.`);\n    }\n    if (!BASE64_REGEX.exec(input)) {\n        throw new TypeError(`Invalid base64 string.`);\n    }\n    const buffer = (0, util_buffer_from_1.fromString)(input, \"base64\");\n    return new Uint8Array(buffer.buffer, buffer.byteOffset, buffer.byteLength);\n};\nexports.fromBase64 = fromBase64;\n","'use strict';\n\nvar fromBase64 = require('./fromBase64');\nvar toBase64 = require('./toBase64');\n\n\n\nObject.keys(fromBase64).forEach(function (k) {\n\tif (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n\t\tenumerable: true,\n\t\tget: function () { return fromBase64[k]; }\n\t});\n});\nObject.keys(toBase64).forEach(function (k) {\n\tif (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n\t\tenumerable: true,\n\t\tget: function () { return toBase64[k]; }\n\t});\n});\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toBase64 = void 0;\nconst util_buffer_from_1 = require(\"@smithy/util-buffer-from\");\nconst util_utf8_1 = require(\"@smithy/util-utf8\");\nconst toBase64 = (_input) => {\n    let input;\n    if (typeof _input === \"string\") {\n        input = (0, util_utf8_1.fromUtf8)(_input);\n    }\n    else {\n        input = _input;\n    }\n    if (typeof input !== \"object\" || typeof input.byteOffset !== \"number\" || typeof input.byteLength !== \"number\") {\n        throw new Error(\"@smithy/util-base64: toBase64 encoder function only accepts string | Uint8Array.\");\n    }\n    return (0, util_buffer_from_1.fromArrayBuffer)(input.buffer, input.byteOffset, input.byteLength).toString(\"base64\");\n};\nexports.toBase64 = toBase64;\n","'use strict';\n\nconst TEXT_ENCODER = typeof TextEncoder == \"function\" ? new TextEncoder() : null;\nconst calculateBodyLength = (body) => {\n    if (typeof body === \"string\") {\n        if (TEXT_ENCODER) {\n            return TEXT_ENCODER.encode(body).byteLength;\n        }\n        let len = body.length;\n        for (let i = len - 1; i >= 0; i--) {\n            const code = body.charCodeAt(i);\n            if (code > 0x7f && code <= 0x7ff)\n                len++;\n            else if (code > 0x7ff && code <= 0xffff)\n                len += 2;\n            if (code >= 0xdc00 && code <= 0xdfff)\n                i--;\n        }\n        return len;\n    }\n    else if (typeof body.byteLength === \"number\") {\n        return body.byteLength;\n    }\n    else if (typeof body.size === \"number\") {\n        return body.size;\n    }\n    throw new Error(`Body Length computation failed for ${body}`);\n};\n\nexports.calculateBodyLength = calculateBodyLength;\n","'use strict';\n\nvar node_fs = require('node:fs');\n\nconst calculateBodyLength = (body) => {\n    if (!body) {\n        return 0;\n    }\n    if (typeof body === \"string\") {\n        return Buffer.byteLength(body);\n    }\n    else if (typeof body.byteLength === \"number\") {\n        return body.byteLength;\n    }\n    else if (typeof body.size === \"number\") {\n        return body.size;\n    }\n    else if (typeof body.start === \"number\" && typeof body.end === \"number\") {\n        return body.end + 1 - body.start;\n    }\n    else if (body instanceof node_fs.ReadStream) {\n        if (body.path != null) {\n            return node_fs.lstatSync(body.path).size;\n        }\n        else if (typeof body.fd === \"number\") {\n            return node_fs.fstatSync(body.fd).size;\n        }\n    }\n    throw new Error(`Body Length computation failed for ${body}`);\n};\n\nexports.calculateBodyLength = calculateBodyLength;\n","'use strict';\n\nvar isArrayBuffer = require('@smithy/is-array-buffer');\nvar buffer = require('buffer');\n\nconst fromArrayBuffer = (input, offset = 0, length = input.byteLength - offset) => {\n    if (!isArrayBuffer.isArrayBuffer(input)) {\n        throw new TypeError(`The \"input\" argument must be ArrayBuffer. Received type ${typeof input} (${input})`);\n    }\n    return buffer.Buffer.from(input, offset, length);\n};\nconst fromString = (input, encoding) => {\n    if (typeof input !== \"string\") {\n        throw new TypeError(`The \"input\" argument must be of type string. Received type ${typeof input} (${input})`);\n    }\n    return encoding ? buffer.Buffer.from(input, encoding) : buffer.Buffer.from(input);\n};\n\nexports.fromArrayBuffer = fromArrayBuffer;\nexports.fromString = fromString;\n","'use strict';\n\nconst booleanSelector = (obj, key, type) => {\n    if (!(key in obj))\n        return undefined;\n    if (obj[key] === \"true\")\n        return true;\n    if (obj[key] === \"false\")\n        return false;\n    throw new Error(`Cannot load ${type} \"${key}\". Expected \"true\" or \"false\", got ${obj[key]}.`);\n};\n\nconst numberSelector = (obj, key, type) => {\n    if (!(key in obj))\n        return undefined;\n    const numberValue = parseInt(obj[key], 10);\n    if (Number.isNaN(numberValue)) {\n        throw new TypeError(`Cannot load ${type} '${key}'. Expected number, got '${obj[key]}'.`);\n    }\n    return numberValue;\n};\n\nexports.SelectorType = void 0;\n(function (SelectorType) {\n    SelectorType[\"ENV\"] = \"env\";\n    SelectorType[\"CONFIG\"] = \"shared config entry\";\n})(exports.SelectorType || (exports.SelectorType = {}));\n\nexports.booleanSelector = booleanSelector;\nexports.numberSelector = numberSelector;\n","'use strict';\n\nvar configResolver = require('@smithy/config-resolver');\nvar nodeConfigProvider = require('@smithy/node-config-provider');\nvar propertyProvider = require('@smithy/property-provider');\n\nconst AWS_EXECUTION_ENV = \"AWS_EXECUTION_ENV\";\nconst AWS_REGION_ENV = \"AWS_REGION\";\nconst AWS_DEFAULT_REGION_ENV = \"AWS_DEFAULT_REGION\";\nconst ENV_IMDS_DISABLED = \"AWS_EC2_METADATA_DISABLED\";\nconst DEFAULTS_MODE_OPTIONS = [\"in-region\", \"cross-region\", \"mobile\", \"standard\", \"legacy\"];\nconst IMDS_REGION_PATH = \"/latest/meta-data/placement/region\";\n\nconst AWS_DEFAULTS_MODE_ENV = \"AWS_DEFAULTS_MODE\";\nconst AWS_DEFAULTS_MODE_CONFIG = \"defaults_mode\";\nconst NODE_DEFAULTS_MODE_CONFIG_OPTIONS = {\n    environmentVariableSelector: (env) => {\n        return env[AWS_DEFAULTS_MODE_ENV];\n    },\n    configFileSelector: (profile) => {\n        return profile[AWS_DEFAULTS_MODE_CONFIG];\n    },\n    default: \"legacy\",\n};\n\nconst resolveDefaultsModeConfig = ({ region = nodeConfigProvider.loadConfig(configResolver.NODE_REGION_CONFIG_OPTIONS), defaultsMode = nodeConfigProvider.loadConfig(NODE_DEFAULTS_MODE_CONFIG_OPTIONS), } = {}) => propertyProvider.memoize(async () => {\n    const mode = typeof defaultsMode === \"function\" ? await defaultsMode() : defaultsMode;\n    switch (mode?.toLowerCase()) {\n        case \"auto\":\n            return resolveNodeDefaultsModeAuto(region);\n        case \"in-region\":\n        case \"cross-region\":\n        case \"mobile\":\n        case \"standard\":\n        case \"legacy\":\n            return Promise.resolve(mode?.toLocaleLowerCase());\n        case undefined:\n            return Promise.resolve(\"legacy\");\n        default:\n            throw new Error(`Invalid parameter for \"defaultsMode\", expect ${DEFAULTS_MODE_OPTIONS.join(\", \")}, got ${mode}`);\n    }\n});\nconst resolveNodeDefaultsModeAuto = async (clientRegion) => {\n    if (clientRegion) {\n        const resolvedRegion = typeof clientRegion === \"function\" ? await clientRegion() : clientRegion;\n        const inferredRegion = await inferPhysicalRegion();\n        if (!inferredRegion) {\n            return \"standard\";\n        }\n        if (resolvedRegion === inferredRegion) {\n            return \"in-region\";\n        }\n        else {\n            return \"cross-region\";\n        }\n    }\n    return \"standard\";\n};\nconst inferPhysicalRegion = async () => {\n    if (process.env[AWS_EXECUTION_ENV] && (process.env[AWS_REGION_ENV] || process.env[AWS_DEFAULT_REGION_ENV])) {\n        return process.env[AWS_REGION_ENV] ?? process.env[AWS_DEFAULT_REGION_ENV];\n    }\n    if (!process.env[ENV_IMDS_DISABLED]) {\n        try {\n            const { getInstanceMetadataEndpoint, httpRequest } = await import('@smithy/credential-provider-imds');\n            const endpoint = await getInstanceMetadataEndpoint();\n            return (await httpRequest({ ...endpoint, path: IMDS_REGION_PATH })).toString();\n        }\n        catch (e) {\n        }\n    }\n};\n\nexports.resolveDefaultsModeConfig = resolveDefaultsModeConfig;\n","'use strict';\n\nvar types = require('@smithy/types');\n\nclass EndpointCache {\n    capacity;\n    data = new Map();\n    parameters = [];\n    constructor({ size, params }) {\n        this.capacity = size ?? 50;\n        if (params) {\n            this.parameters = params;\n        }\n    }\n    get(endpointParams, resolver) {\n        const key = this.hash(endpointParams);\n        if (key === false) {\n            return resolver();\n        }\n        if (!this.data.has(key)) {\n            if (this.data.size > this.capacity + 10) {\n                const keys = this.data.keys();\n                let i = 0;\n                while (true) {\n                    const { value, done } = keys.next();\n                    this.data.delete(value);\n                    if (done || ++i > 10) {\n                        break;\n                    }\n                }\n            }\n            this.data.set(key, resolver());\n        }\n        return this.data.get(key);\n    }\n    size() {\n        return this.data.size;\n    }\n    hash(endpointParams) {\n        let buffer = \"\";\n        const { parameters } = this;\n        if (parameters.length === 0) {\n            return false;\n        }\n        for (const param of parameters) {\n            const val = String(endpointParams[param] ?? \"\");\n            if (val.includes(\"|;\")) {\n                return false;\n            }\n            buffer += val + \"|;\";\n        }\n        return buffer;\n    }\n}\n\nconst IP_V4_REGEX = new RegExp(`^(?:25[0-5]|2[0-4]\\\\d|1\\\\d\\\\d|[1-9]\\\\d|\\\\d)(?:\\\\.(?:25[0-5]|2[0-4]\\\\d|1\\\\d\\\\d|[1-9]\\\\d|\\\\d)){3}$`);\nconst isIpAddress = (value) => IP_V4_REGEX.test(value) || (value.startsWith(\"[\") && value.endsWith(\"]\"));\n\nconst VALID_HOST_LABEL_REGEX = new RegExp(`^(?!.*-$)(?!-)[a-zA-Z0-9-]{1,63}$`);\nconst isValidHostLabel = (value, allowSubDomains = false) => {\n    if (!allowSubDomains) {\n        return VALID_HOST_LABEL_REGEX.test(value);\n    }\n    const labels = value.split(\".\");\n    for (const label of labels) {\n        if (!isValidHostLabel(label)) {\n            return false;\n        }\n    }\n    return true;\n};\n\nconst customEndpointFunctions = {};\n\nconst debugId = \"endpoints\";\n\nfunction toDebugString(input) {\n    if (typeof input !== \"object\" || input == null) {\n        return input;\n    }\n    if (\"ref\" in input) {\n        return `$${toDebugString(input.ref)}`;\n    }\n    if (\"fn\" in input) {\n        return `${input.fn}(${(input.argv || []).map(toDebugString).join(\", \")})`;\n    }\n    return JSON.stringify(input, null, 2);\n}\n\nclass EndpointError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = \"EndpointError\";\n    }\n}\n\nconst booleanEquals = (value1, value2) => value1 === value2;\n\nconst getAttrPathList = (path) => {\n    const parts = path.split(\".\");\n    const pathList = [];\n    for (const part of parts) {\n        const squareBracketIndex = part.indexOf(\"[\");\n        if (squareBracketIndex !== -1) {\n            if (part.indexOf(\"]\") !== part.length - 1) {\n                throw new EndpointError(`Path: '${path}' does not end with ']'`);\n            }\n            const arrayIndex = part.slice(squareBracketIndex + 1, -1);\n            if (Number.isNaN(parseInt(arrayIndex))) {\n                throw new EndpointError(`Invalid array index: '${arrayIndex}' in path: '${path}'`);\n            }\n            if (squareBracketIndex !== 0) {\n                pathList.push(part.slice(0, squareBracketIndex));\n            }\n            pathList.push(arrayIndex);\n        }\n        else {\n            pathList.push(part);\n        }\n    }\n    return pathList;\n};\n\nconst getAttr = (value, path) => getAttrPathList(path).reduce((acc, index) => {\n    if (typeof acc !== \"object\") {\n        throw new EndpointError(`Index '${index}' in '${path}' not found in '${JSON.stringify(value)}'`);\n    }\n    else if (Array.isArray(acc)) {\n        return acc[parseInt(index)];\n    }\n    return acc[index];\n}, value);\n\nconst isSet = (value) => value != null;\n\nconst not = (value) => !value;\n\nconst DEFAULT_PORTS = {\n    [types.EndpointURLScheme.HTTP]: 80,\n    [types.EndpointURLScheme.HTTPS]: 443,\n};\nconst parseURL = (value) => {\n    const whatwgURL = (() => {\n        try {\n            if (value instanceof URL) {\n                return value;\n            }\n            if (typeof value === \"object\" && \"hostname\" in value) {\n                const { hostname, port, protocol = \"\", path = \"\", query = {} } = value;\n                const url = new URL(`${protocol}//${hostname}${port ? `:${port}` : \"\"}${path}`);\n                url.search = Object.entries(query)\n                    .map(([k, v]) => `${k}=${v}`)\n                    .join(\"&\");\n                return url;\n            }\n            return new URL(value);\n        }\n        catch (error) {\n            return null;\n        }\n    })();\n    if (!whatwgURL) {\n        console.error(`Unable to parse ${JSON.stringify(value)} as a whatwg URL.`);\n        return null;\n    }\n    const urlString = whatwgURL.href;\n    const { host, hostname, pathname, protocol, search } = whatwgURL;\n    if (search) {\n        return null;\n    }\n    const scheme = protocol.slice(0, -1);\n    if (!Object.values(types.EndpointURLScheme).includes(scheme)) {\n        return null;\n    }\n    const isIp = isIpAddress(hostname);\n    const inputContainsDefaultPort = urlString.includes(`${host}:${DEFAULT_PORTS[scheme]}`) ||\n        (typeof value === \"string\" && value.includes(`${host}:${DEFAULT_PORTS[scheme]}`));\n    const authority = `${host}${inputContainsDefaultPort ? `:${DEFAULT_PORTS[scheme]}` : ``}`;\n    return {\n        scheme,\n        authority,\n        path: pathname,\n        normalizedPath: pathname.endsWith(\"/\") ? pathname : `${pathname}/`,\n        isIp,\n    };\n};\n\nconst stringEquals = (value1, value2) => value1 === value2;\n\nconst substring = (input, start, stop, reverse) => {\n    if (start >= stop || input.length < stop) {\n        return null;\n    }\n    if (!reverse) {\n        return input.substring(start, stop);\n    }\n    return input.substring(input.length - stop, input.length - start);\n};\n\nconst uriEncode = (value) => encodeURIComponent(value).replace(/[!*'()]/g, (c) => `%${c.charCodeAt(0).toString(16).toUpperCase()}`);\n\nconst endpointFunctions = {\n    booleanEquals,\n    getAttr,\n    isSet,\n    isValidHostLabel,\n    not,\n    parseURL,\n    stringEquals,\n    substring,\n    uriEncode,\n};\n\nconst evaluateTemplate = (template, options) => {\n    const evaluatedTemplateArr = [];\n    const templateContext = {\n        ...options.endpointParams,\n        ...options.referenceRecord,\n    };\n    let currentIndex = 0;\n    while (currentIndex < template.length) {\n        const openingBraceIndex = template.indexOf(\"{\", currentIndex);\n        if (openingBraceIndex === -1) {\n            evaluatedTemplateArr.push(template.slice(currentIndex));\n            break;\n        }\n        evaluatedTemplateArr.push(template.slice(currentIndex, openingBraceIndex));\n        const closingBraceIndex = template.indexOf(\"}\", openingBraceIndex);\n        if (closingBraceIndex === -1) {\n            evaluatedTemplateArr.push(template.slice(openingBraceIndex));\n            break;\n        }\n        if (template[openingBraceIndex + 1] === \"{\" && template[closingBraceIndex + 1] === \"}\") {\n            evaluatedTemplateArr.push(template.slice(openingBraceIndex + 1, closingBraceIndex));\n            currentIndex = closingBraceIndex + 2;\n        }\n        const parameterName = template.substring(openingBraceIndex + 1, closingBraceIndex);\n        if (parameterName.includes(\"#\")) {\n            const [refName, attrName] = parameterName.split(\"#\");\n            evaluatedTemplateArr.push(getAttr(templateContext[refName], attrName));\n        }\n        else {\n            evaluatedTemplateArr.push(templateContext[parameterName]);\n        }\n        currentIndex = closingBraceIndex + 1;\n    }\n    return evaluatedTemplateArr.join(\"\");\n};\n\nconst getReferenceValue = ({ ref }, options) => {\n    const referenceRecord = {\n        ...options.endpointParams,\n        ...options.referenceRecord,\n    };\n    return referenceRecord[ref];\n};\n\nconst evaluateExpression = (obj, keyName, options) => {\n    if (typeof obj === \"string\") {\n        return evaluateTemplate(obj, options);\n    }\n    else if (obj[\"fn\"]) {\n        return group$2.callFunction(obj, options);\n    }\n    else if (obj[\"ref\"]) {\n        return getReferenceValue(obj, options);\n    }\n    throw new EndpointError(`'${keyName}': ${String(obj)} is not a string, function or reference.`);\n};\nconst callFunction = ({ fn, argv }, options) => {\n    const evaluatedArgs = argv.map((arg) => [\"boolean\", \"number\"].includes(typeof arg) ? arg : group$2.evaluateExpression(arg, \"arg\", options));\n    const fnSegments = fn.split(\".\");\n    if (fnSegments[0] in customEndpointFunctions && fnSegments[1] != null) {\n        return customEndpointFunctions[fnSegments[0]][fnSegments[1]](...evaluatedArgs);\n    }\n    return endpointFunctions[fn](...evaluatedArgs);\n};\nconst group$2 = {\n    evaluateExpression,\n    callFunction,\n};\n\nconst evaluateCondition = ({ assign, ...fnArgs }, options) => {\n    if (assign && assign in options.referenceRecord) {\n        throw new EndpointError(`'${assign}' is already defined in Reference Record.`);\n    }\n    const value = callFunction(fnArgs, options);\n    options.logger?.debug?.(`${debugId} evaluateCondition: ${toDebugString(fnArgs)} = ${toDebugString(value)}`);\n    return {\n        result: value === \"\" ? true : !!value,\n        ...(assign != null && { toAssign: { name: assign, value } }),\n    };\n};\n\nconst evaluateConditions = (conditions = [], options) => {\n    const conditionsReferenceRecord = {};\n    for (const condition of conditions) {\n        const { result, toAssign } = evaluateCondition(condition, {\n            ...options,\n            referenceRecord: {\n                ...options.referenceRecord,\n                ...conditionsReferenceRecord,\n            },\n        });\n        if (!result) {\n            return { result };\n        }\n        if (toAssign) {\n            conditionsReferenceRecord[toAssign.name] = toAssign.value;\n            options.logger?.debug?.(`${debugId} assign: ${toAssign.name} := ${toDebugString(toAssign.value)}`);\n        }\n    }\n    return { result: true, referenceRecord: conditionsReferenceRecord };\n};\n\nconst getEndpointHeaders = (headers, options) => Object.entries(headers).reduce((acc, [headerKey, headerVal]) => ({\n    ...acc,\n    [headerKey]: headerVal.map((headerValEntry) => {\n        const processedExpr = evaluateExpression(headerValEntry, \"Header value entry\", options);\n        if (typeof processedExpr !== \"string\") {\n            throw new EndpointError(`Header '${headerKey}' value '${processedExpr}' is not a string`);\n        }\n        return processedExpr;\n    }),\n}), {});\n\nconst getEndpointProperties = (properties, options) => Object.entries(properties).reduce((acc, [propertyKey, propertyVal]) => ({\n    ...acc,\n    [propertyKey]: group$1.getEndpointProperty(propertyVal, options),\n}), {});\nconst getEndpointProperty = (property, options) => {\n    if (Array.isArray(property)) {\n        return property.map((propertyEntry) => getEndpointProperty(propertyEntry, options));\n    }\n    switch (typeof property) {\n        case \"string\":\n            return evaluateTemplate(property, options);\n        case \"object\":\n            if (property === null) {\n                throw new EndpointError(`Unexpected endpoint property: ${property}`);\n            }\n            return group$1.getEndpointProperties(property, options);\n        case \"boolean\":\n            return property;\n        default:\n            throw new EndpointError(`Unexpected endpoint property type: ${typeof property}`);\n    }\n};\nconst group$1 = {\n    getEndpointProperty,\n    getEndpointProperties,\n};\n\nconst getEndpointUrl = (endpointUrl, options) => {\n    const expression = evaluateExpression(endpointUrl, \"Endpoint URL\", options);\n    if (typeof expression === \"string\") {\n        try {\n            return new URL(expression);\n        }\n        catch (error) {\n            console.error(`Failed to construct URL with ${expression}`, error);\n            throw error;\n        }\n    }\n    throw new EndpointError(`Endpoint URL must be a string, got ${typeof expression}`);\n};\n\nconst evaluateEndpointRule = (endpointRule, options) => {\n    const { conditions, endpoint } = endpointRule;\n    const { result, referenceRecord } = evaluateConditions(conditions, options);\n    if (!result) {\n        return;\n    }\n    const endpointRuleOptions = {\n        ...options,\n        referenceRecord: { ...options.referenceRecord, ...referenceRecord },\n    };\n    const { url, properties, headers } = endpoint;\n    options.logger?.debug?.(`${debugId} Resolving endpoint from template: ${toDebugString(endpoint)}`);\n    return {\n        ...(headers != undefined && {\n            headers: getEndpointHeaders(headers, endpointRuleOptions),\n        }),\n        ...(properties != undefined && {\n            properties: getEndpointProperties(properties, endpointRuleOptions),\n        }),\n        url: getEndpointUrl(url, endpointRuleOptions),\n    };\n};\n\nconst evaluateErrorRule = (errorRule, options) => {\n    const { conditions, error } = errorRule;\n    const { result, referenceRecord } = evaluateConditions(conditions, options);\n    if (!result) {\n        return;\n    }\n    throw new EndpointError(evaluateExpression(error, \"Error\", {\n        ...options,\n        referenceRecord: { ...options.referenceRecord, ...referenceRecord },\n    }));\n};\n\nconst evaluateRules = (rules, options) => {\n    for (const rule of rules) {\n        if (rule.type === \"endpoint\") {\n            const endpointOrUndefined = evaluateEndpointRule(rule, options);\n            if (endpointOrUndefined) {\n                return endpointOrUndefined;\n            }\n        }\n        else if (rule.type === \"error\") {\n            evaluateErrorRule(rule, options);\n        }\n        else if (rule.type === \"tree\") {\n            const endpointOrUndefined = group.evaluateTreeRule(rule, options);\n            if (endpointOrUndefined) {\n                return endpointOrUndefined;\n            }\n        }\n        else {\n            throw new EndpointError(`Unknown endpoint rule: ${rule}`);\n        }\n    }\n    throw new EndpointError(`Rules evaluation failed`);\n};\nconst evaluateTreeRule = (treeRule, options) => {\n    const { conditions, rules } = treeRule;\n    const { result, referenceRecord } = evaluateConditions(conditions, options);\n    if (!result) {\n        return;\n    }\n    return group.evaluateRules(rules, {\n        ...options,\n        referenceRecord: { ...options.referenceRecord, ...referenceRecord },\n    });\n};\nconst group = {\n    evaluateRules,\n    evaluateTreeRule,\n};\n\nconst resolveEndpoint = (ruleSetObject, options) => {\n    const { endpointParams, logger } = options;\n    const { parameters, rules } = ruleSetObject;\n    options.logger?.debug?.(`${debugId} Initial EndpointParams: ${toDebugString(endpointParams)}`);\n    const paramsWithDefault = Object.entries(parameters)\n        .filter(([, v]) => v.default != null)\n        .map(([k, v]) => [k, v.default]);\n    if (paramsWithDefault.length > 0) {\n        for (const [paramKey, paramDefaultValue] of paramsWithDefault) {\n            endpointParams[paramKey] = endpointParams[paramKey] ?? paramDefaultValue;\n        }\n    }\n    const requiredParams = Object.entries(parameters)\n        .filter(([, v]) => v.required)\n        .map(([k]) => k);\n    for (const requiredParam of requiredParams) {\n        if (endpointParams[requiredParam] == null) {\n            throw new EndpointError(`Missing required parameter: '${requiredParam}'`);\n        }\n    }\n    const endpoint = evaluateRules(rules, { endpointParams, logger, referenceRecord: {} });\n    options.logger?.debug?.(`${debugId} Resolved endpoint: ${toDebugString(endpoint)}`);\n    return endpoint;\n};\n\nexports.EndpointCache = EndpointCache;\nexports.EndpointError = EndpointError;\nexports.customEndpointFunctions = customEndpointFunctions;\nexports.isIpAddress = isIpAddress;\nexports.isValidHostLabel = isValidHostLabel;\nexports.resolveEndpoint = resolveEndpoint;\n","'use strict';\n\nconst SHORT_TO_HEX = {};\nconst HEX_TO_SHORT = {};\nfor (let i = 0; i < 256; i++) {\n    let encodedByte = i.toString(16).toLowerCase();\n    if (encodedByte.length === 1) {\n        encodedByte = `0${encodedByte}`;\n    }\n    SHORT_TO_HEX[i] = encodedByte;\n    HEX_TO_SHORT[encodedByte] = i;\n}\nfunction fromHex(encoded) {\n    if (encoded.length % 2 !== 0) {\n        throw new Error(\"Hex encoded strings must have an even number length\");\n    }\n    const out = new Uint8Array(encoded.length / 2);\n    for (let i = 0; i < encoded.length; i += 2) {\n        const encodedByte = encoded.slice(i, i + 2).toLowerCase();\n        if (encodedByte in HEX_TO_SHORT) {\n            out[i / 2] = HEX_TO_SHORT[encodedByte];\n        }\n        else {\n            throw new Error(`Cannot decode unrecognized sequence ${encodedByte} as hexadecimal`);\n        }\n    }\n    return out;\n}\nfunction toHex(bytes) {\n    let out = \"\";\n    for (let i = 0; i < bytes.byteLength; i++) {\n        out += SHORT_TO_HEX[bytes[i]];\n    }\n    return out;\n}\n\nexports.fromHex = fromHex;\nexports.toHex = toHex;\n","'use strict';\n\nvar types = require('@smithy/types');\n\nconst getSmithyContext = (context) => context[types.SMITHY_CONTEXT_KEY] || (context[types.SMITHY_CONTEXT_KEY] = {});\n\nconst normalizeProvider = (input) => {\n    if (typeof input === \"function\")\n        return input;\n    const promisified = Promise.resolve(input);\n    return () => promisified;\n};\n\nexports.getSmithyContext = getSmithyContext;\nexports.normalizeProvider = normalizeProvider;\n","'use strict';\n\nvar serviceErrorClassification = require('@smithy/service-error-classification');\n\nexports.RETRY_MODES = void 0;\n(function (RETRY_MODES) {\n    RETRY_MODES[\"STANDARD\"] = \"standard\";\n    RETRY_MODES[\"ADAPTIVE\"] = \"adaptive\";\n})(exports.RETRY_MODES || (exports.RETRY_MODES = {}));\nconst DEFAULT_MAX_ATTEMPTS = 3;\nconst DEFAULT_RETRY_MODE = exports.RETRY_MODES.STANDARD;\n\nclass DefaultRateLimiter {\n    static setTimeoutFn = setTimeout;\n    beta;\n    minCapacity;\n    minFillRate;\n    scaleConstant;\n    smooth;\n    currentCapacity = 0;\n    enabled = false;\n    lastMaxRate = 0;\n    measuredTxRate = 0;\n    requestCount = 0;\n    fillRate;\n    lastThrottleTime;\n    lastTimestamp = 0;\n    lastTxRateBucket;\n    maxCapacity;\n    timeWindow = 0;\n    constructor(options) {\n        this.beta = options?.beta ?? 0.7;\n        this.minCapacity = options?.minCapacity ?? 1;\n        this.minFillRate = options?.minFillRate ?? 0.5;\n        this.scaleConstant = options?.scaleConstant ?? 0.4;\n        this.smooth = options?.smooth ?? 0.8;\n        const currentTimeInSeconds = this.getCurrentTimeInSeconds();\n        this.lastThrottleTime = currentTimeInSeconds;\n        this.lastTxRateBucket = Math.floor(this.getCurrentTimeInSeconds());\n        this.fillRate = this.minFillRate;\n        this.maxCapacity = this.minCapacity;\n    }\n    getCurrentTimeInSeconds() {\n        return Date.now() / 1000;\n    }\n    async getSendToken() {\n        return this.acquireTokenBucket(1);\n    }\n    async acquireTokenBucket(amount) {\n        if (!this.enabled) {\n            return;\n        }\n        this.refillTokenBucket();\n        if (amount > this.currentCapacity) {\n            const delay = ((amount - this.currentCapacity) / this.fillRate) * 1000;\n            await new Promise((resolve) => DefaultRateLimiter.setTimeoutFn(resolve, delay));\n        }\n        this.currentCapacity = this.currentCapacity - amount;\n    }\n    refillTokenBucket() {\n        const timestamp = this.getCurrentTimeInSeconds();\n        if (!this.lastTimestamp) {\n            this.lastTimestamp = timestamp;\n            return;\n        }\n        const fillAmount = (timestamp - this.lastTimestamp) * this.fillRate;\n        this.currentCapacity = Math.min(this.maxCapacity, this.currentCapacity + fillAmount);\n        this.lastTimestamp = timestamp;\n    }\n    updateClientSendingRate(response) {\n        let calculatedRate;\n        this.updateMeasuredRate();\n        if (serviceErrorClassification.isThrottlingError(response)) {\n            const rateToUse = !this.enabled ? this.measuredTxRate : Math.min(this.measuredTxRate, this.fillRate);\n            this.lastMaxRate = rateToUse;\n            this.calculateTimeWindow();\n            this.lastThrottleTime = this.getCurrentTimeInSeconds();\n            calculatedRate = this.cubicThrottle(rateToUse);\n            this.enableTokenBucket();\n        }\n        else {\n            this.calculateTimeWindow();\n            calculatedRate = this.cubicSuccess(this.getCurrentTimeInSeconds());\n        }\n        const newRate = Math.min(calculatedRate, 2 * this.measuredTxRate);\n        this.updateTokenBucketRate(newRate);\n    }\n    calculateTimeWindow() {\n        this.timeWindow = this.getPrecise(Math.pow((this.lastMaxRate * (1 - this.beta)) / this.scaleConstant, 1 / 3));\n    }\n    cubicThrottle(rateToUse) {\n        return this.getPrecise(rateToUse * this.beta);\n    }\n    cubicSuccess(timestamp) {\n        return this.getPrecise(this.scaleConstant * Math.pow(timestamp - this.lastThrottleTime - this.timeWindow, 3) + this.lastMaxRate);\n    }\n    enableTokenBucket() {\n        this.enabled = true;\n    }\n    updateTokenBucketRate(newRate) {\n        this.refillTokenBucket();\n        this.fillRate = Math.max(newRate, this.minFillRate);\n        this.maxCapacity = Math.max(newRate, this.minCapacity);\n        this.currentCapacity = Math.min(this.currentCapacity, this.maxCapacity);\n    }\n    updateMeasuredRate() {\n        const t = this.getCurrentTimeInSeconds();\n        const timeBucket = Math.floor(t * 2) / 2;\n        this.requestCount++;\n        if (timeBucket > this.lastTxRateBucket) {\n            const currentRate = this.requestCount / (timeBucket - this.lastTxRateBucket);\n            this.measuredTxRate = this.getPrecise(currentRate * this.smooth + this.measuredTxRate * (1 - this.smooth));\n            this.requestCount = 0;\n            this.lastTxRateBucket = timeBucket;\n        }\n    }\n    getPrecise(num) {\n        return parseFloat(num.toFixed(8));\n    }\n}\n\nconst DEFAULT_RETRY_DELAY_BASE = 100;\nconst MAXIMUM_RETRY_DELAY = 20 * 1000;\nconst THROTTLING_RETRY_DELAY_BASE = 500;\nconst INITIAL_RETRY_TOKENS = 500;\nconst RETRY_COST = 5;\nconst TIMEOUT_RETRY_COST = 10;\nconst NO_RETRY_INCREMENT = 1;\nconst INVOCATION_ID_HEADER = \"amz-sdk-invocation-id\";\nconst REQUEST_HEADER = \"amz-sdk-request\";\n\nconst getDefaultRetryBackoffStrategy = () => {\n    let delayBase = DEFAULT_RETRY_DELAY_BASE;\n    const computeNextBackoffDelay = (attempts) => {\n        return Math.floor(Math.min(MAXIMUM_RETRY_DELAY, Math.random() * 2 ** attempts * delayBase));\n    };\n    const setDelayBase = (delay) => {\n        delayBase = delay;\n    };\n    return {\n        computeNextBackoffDelay,\n        setDelayBase,\n    };\n};\n\nconst createDefaultRetryToken = ({ retryDelay, retryCount, retryCost, }) => {\n    const getRetryCount = () => retryCount;\n    const getRetryDelay = () => Math.min(MAXIMUM_RETRY_DELAY, retryDelay);\n    const getRetryCost = () => retryCost;\n    return {\n        getRetryCount,\n        getRetryDelay,\n        getRetryCost,\n    };\n};\n\nclass StandardRetryStrategy {\n    maxAttempts;\n    mode = exports.RETRY_MODES.STANDARD;\n    capacity = INITIAL_RETRY_TOKENS;\n    retryBackoffStrategy = getDefaultRetryBackoffStrategy();\n    maxAttemptsProvider;\n    constructor(maxAttempts) {\n        this.maxAttempts = maxAttempts;\n        this.maxAttemptsProvider = typeof maxAttempts === \"function\" ? maxAttempts : async () => maxAttempts;\n    }\n    async acquireInitialRetryToken(retryTokenScope) {\n        return createDefaultRetryToken({\n            retryDelay: DEFAULT_RETRY_DELAY_BASE,\n            retryCount: 0,\n        });\n    }\n    async refreshRetryTokenForRetry(token, errorInfo) {\n        const maxAttempts = await this.getMaxAttempts();\n        if (this.shouldRetry(token, errorInfo, maxAttempts)) {\n            const errorType = errorInfo.errorType;\n            this.retryBackoffStrategy.setDelayBase(errorType === \"THROTTLING\" ? THROTTLING_RETRY_DELAY_BASE : DEFAULT_RETRY_DELAY_BASE);\n            const delayFromErrorType = this.retryBackoffStrategy.computeNextBackoffDelay(token.getRetryCount());\n            const retryDelay = errorInfo.retryAfterHint\n                ? Math.max(errorInfo.retryAfterHint.getTime() - Date.now() || 0, delayFromErrorType)\n                : delayFromErrorType;\n            const capacityCost = this.getCapacityCost(errorType);\n            this.capacity -= capacityCost;\n            return createDefaultRetryToken({\n                retryDelay,\n                retryCount: token.getRetryCount() + 1,\n                retryCost: capacityCost,\n            });\n        }\n        throw new Error(\"No retry token available\");\n    }\n    recordSuccess(token) {\n        this.capacity = Math.max(INITIAL_RETRY_TOKENS, this.capacity + (token.getRetryCost() ?? NO_RETRY_INCREMENT));\n    }\n    getCapacity() {\n        return this.capacity;\n    }\n    async getMaxAttempts() {\n        try {\n            return await this.maxAttemptsProvider();\n        }\n        catch (error) {\n            console.warn(`Max attempts provider could not resolve. Using default of ${DEFAULT_MAX_ATTEMPTS}`);\n            return DEFAULT_MAX_ATTEMPTS;\n        }\n    }\n    shouldRetry(tokenToRenew, errorInfo, maxAttempts) {\n        const attempts = tokenToRenew.getRetryCount() + 1;\n        return (attempts < maxAttempts &&\n            this.capacity >= this.getCapacityCost(errorInfo.errorType) &&\n            this.isRetryableError(errorInfo.errorType));\n    }\n    getCapacityCost(errorType) {\n        return errorType === \"TRANSIENT\" ? TIMEOUT_RETRY_COST : RETRY_COST;\n    }\n    isRetryableError(errorType) {\n        return errorType === \"THROTTLING\" || errorType === \"TRANSIENT\";\n    }\n}\n\nclass AdaptiveRetryStrategy {\n    maxAttemptsProvider;\n    rateLimiter;\n    standardRetryStrategy;\n    mode = exports.RETRY_MODES.ADAPTIVE;\n    constructor(maxAttemptsProvider, options) {\n        this.maxAttemptsProvider = maxAttemptsProvider;\n        const { rateLimiter } = options ?? {};\n        this.rateLimiter = rateLimiter ?? new DefaultRateLimiter();\n        this.standardRetryStrategy = new StandardRetryStrategy(maxAttemptsProvider);\n    }\n    async acquireInitialRetryToken(retryTokenScope) {\n        await this.rateLimiter.getSendToken();\n        return this.standardRetryStrategy.acquireInitialRetryToken(retryTokenScope);\n    }\n    async refreshRetryTokenForRetry(tokenToRenew, errorInfo) {\n        this.rateLimiter.updateClientSendingRate(errorInfo);\n        return this.standardRetryStrategy.refreshRetryTokenForRetry(tokenToRenew, errorInfo);\n    }\n    recordSuccess(token) {\n        this.rateLimiter.updateClientSendingRate({});\n        this.standardRetryStrategy.recordSuccess(token);\n    }\n}\n\nclass ConfiguredRetryStrategy extends StandardRetryStrategy {\n    computeNextBackoffDelay;\n    constructor(maxAttempts, computeNextBackoffDelay = DEFAULT_RETRY_DELAY_BASE) {\n        super(typeof maxAttempts === \"function\" ? maxAttempts : async () => maxAttempts);\n        if (typeof computeNextBackoffDelay === \"number\") {\n            this.computeNextBackoffDelay = () => computeNextBackoffDelay;\n        }\n        else {\n            this.computeNextBackoffDelay = computeNextBackoffDelay;\n        }\n    }\n    async refreshRetryTokenForRetry(tokenToRenew, errorInfo) {\n        const token = await super.refreshRetryTokenForRetry(tokenToRenew, errorInfo);\n        token.getRetryDelay = () => this.computeNextBackoffDelay(token.getRetryCount());\n        return token;\n    }\n}\n\nexports.AdaptiveRetryStrategy = AdaptiveRetryStrategy;\nexports.ConfiguredRetryStrategy = ConfiguredRetryStrategy;\nexports.DEFAULT_MAX_ATTEMPTS = DEFAULT_MAX_ATTEMPTS;\nexports.DEFAULT_RETRY_DELAY_BASE = DEFAULT_RETRY_DELAY_BASE;\nexports.DEFAULT_RETRY_MODE = DEFAULT_RETRY_MODE;\nexports.DefaultRateLimiter = DefaultRateLimiter;\nexports.INITIAL_RETRY_TOKENS = INITIAL_RETRY_TOKENS;\nexports.INVOCATION_ID_HEADER = INVOCATION_ID_HEADER;\nexports.MAXIMUM_RETRY_DELAY = MAXIMUM_RETRY_DELAY;\nexports.NO_RETRY_INCREMENT = NO_RETRY_INCREMENT;\nexports.REQUEST_HEADER = REQUEST_HEADER;\nexports.RETRY_COST = RETRY_COST;\nexports.StandardRetryStrategy = StandardRetryStrategy;\nexports.THROTTLING_RETRY_DELAY_BASE = THROTTLING_RETRY_DELAY_BASE;\nexports.TIMEOUT_RETRY_COST = TIMEOUT_RETRY_COST;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ByteArrayCollector = void 0;\nclass ByteArrayCollector {\n    allocByteArray;\n    byteLength = 0;\n    byteArrays = [];\n    constructor(allocByteArray) {\n        this.allocByteArray = allocByteArray;\n    }\n    push(byteArray) {\n        this.byteArrays.push(byteArray);\n        this.byteLength += byteArray.byteLength;\n    }\n    flush() {\n        if (this.byteArrays.length === 1) {\n            const bytes = this.byteArrays[0];\n            this.reset();\n            return bytes;\n        }\n        const aggregation = this.allocByteArray(this.byteLength);\n        let cursor = 0;\n        for (let i = 0; i < this.byteArrays.length; ++i) {\n            const bytes = this.byteArrays[i];\n            aggregation.set(bytes, cursor);\n            cursor += bytes.byteLength;\n        }\n        this.reset();\n        return aggregation;\n    }\n    reset() {\n        this.byteArrays = [];\n        this.byteLength = 0;\n    }\n}\nexports.ByteArrayCollector = ByteArrayCollector;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ChecksumStream = void 0;\nconst ReadableStreamRef = typeof ReadableStream === \"function\" ? ReadableStream : function () { };\nclass ChecksumStream extends ReadableStreamRef {\n}\nexports.ChecksumStream = ChecksumStream;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.ChecksumStream = void 0;\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst stream_1 = require(\"stream\");\nclass ChecksumStream extends stream_1.Duplex {\n    expectedChecksum;\n    checksumSourceLocation;\n    checksum;\n    source;\n    base64Encoder;\n    constructor({ expectedChecksum, checksum, source, checksumSourceLocation, base64Encoder, }) {\n        super();\n        if (typeof source.pipe === \"function\") {\n            this.source = source;\n        }\n        else {\n            throw new Error(`@smithy/util-stream: unsupported source type ${source?.constructor?.name ?? source} in ChecksumStream.`);\n        }\n        this.base64Encoder = base64Encoder ?? util_base64_1.toBase64;\n        this.expectedChecksum = expectedChecksum;\n        this.checksum = checksum;\n        this.checksumSourceLocation = checksumSourceLocation;\n        this.source.pipe(this);\n    }\n    _read(size) { }\n    _write(chunk, encoding, callback) {\n        try {\n            this.checksum.update(chunk);\n            this.push(chunk);\n        }\n        catch (e) {\n            return callback(e);\n        }\n        return callback();\n    }\n    async _final(callback) {\n        try {\n            const digest = await this.checksum.digest();\n            const received = this.base64Encoder(digest);\n            if (this.expectedChecksum !== received) {\n                return callback(new Error(`Checksum mismatch: expected \"${this.expectedChecksum}\" but received \"${received}\"` +\n                    ` in response header \"${this.checksumSourceLocation}\".`));\n            }\n        }\n        catch (e) {\n            return callback(e);\n        }\n        this.push(null);\n        return callback();\n    }\n}\nexports.ChecksumStream = ChecksumStream;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createChecksumStream = void 0;\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst stream_type_check_1 = require(\"../stream-type-check\");\nconst ChecksumStream_browser_1 = require(\"./ChecksumStream.browser\");\nconst createChecksumStream = ({ expectedChecksum, checksum, source, checksumSourceLocation, base64Encoder, }) => {\n    if (!(0, stream_type_check_1.isReadableStream)(source)) {\n        throw new Error(`@smithy/util-stream: unsupported source type ${source?.constructor?.name ?? source} in ChecksumStream.`);\n    }\n    const encoder = base64Encoder ?? util_base64_1.toBase64;\n    if (typeof TransformStream !== \"function\") {\n        throw new Error(\"@smithy/util-stream: unable to instantiate ChecksumStream because API unavailable: ReadableStream/TransformStream.\");\n    }\n    const transform = new TransformStream({\n        start() { },\n        async transform(chunk, controller) {\n            checksum.update(chunk);\n            controller.enqueue(chunk);\n        },\n        async flush(controller) {\n            const digest = await checksum.digest();\n            const received = encoder(digest);\n            if (expectedChecksum !== received) {\n                const error = new Error(`Checksum mismatch: expected \"${expectedChecksum}\" but received \"${received}\"` +\n                    ` in response header \"${checksumSourceLocation}\".`);\n                controller.error(error);\n            }\n            else {\n                controller.terminate();\n            }\n        },\n    });\n    source.pipeThrough(transform);\n    const readable = transform.readable;\n    Object.setPrototypeOf(readable, ChecksumStream_browser_1.ChecksumStream.prototype);\n    return readable;\n};\nexports.createChecksumStream = createChecksumStream;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createChecksumStream = createChecksumStream;\nconst stream_type_check_1 = require(\"../stream-type-check\");\nconst ChecksumStream_1 = require(\"./ChecksumStream\");\nconst createChecksumStream_browser_1 = require(\"./createChecksumStream.browser\");\nfunction createChecksumStream(init) {\n    if (typeof ReadableStream === \"function\" && (0, stream_type_check_1.isReadableStream)(init.source)) {\n        return (0, createChecksumStream_browser_1.createChecksumStream)(init);\n    }\n    return new ChecksumStream_1.ChecksumStream(init);\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createBufferedReadable = createBufferedReadable;\nconst node_stream_1 = require(\"node:stream\");\nconst ByteArrayCollector_1 = require(\"./ByteArrayCollector\");\nconst createBufferedReadableStream_1 = require(\"./createBufferedReadableStream\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nfunction createBufferedReadable(upstream, size, logger) {\n    if ((0, stream_type_check_1.isReadableStream)(upstream)) {\n        return (0, createBufferedReadableStream_1.createBufferedReadableStream)(upstream, size, logger);\n    }\n    const downstream = new node_stream_1.Readable({ read() { } });\n    let streamBufferingLoggedWarning = false;\n    let bytesSeen = 0;\n    const buffers = [\n        \"\",\n        new ByteArrayCollector_1.ByteArrayCollector((size) => new Uint8Array(size)),\n        new ByteArrayCollector_1.ByteArrayCollector((size) => Buffer.from(new Uint8Array(size))),\n    ];\n    let mode = -1;\n    upstream.on(\"data\", (chunk) => {\n        const chunkMode = (0, createBufferedReadableStream_1.modeOf)(chunk, true);\n        if (mode !== chunkMode) {\n            if (mode >= 0) {\n                downstream.push((0, createBufferedReadableStream_1.flush)(buffers, mode));\n            }\n            mode = chunkMode;\n        }\n        if (mode === -1) {\n            downstream.push(chunk);\n            return;\n        }\n        const chunkSize = (0, createBufferedReadableStream_1.sizeOf)(chunk);\n        bytesSeen += chunkSize;\n        const bufferSize = (0, createBufferedReadableStream_1.sizeOf)(buffers[mode]);\n        if (chunkSize >= size && bufferSize === 0) {\n            downstream.push(chunk);\n        }\n        else {\n            const newSize = (0, createBufferedReadableStream_1.merge)(buffers, mode, chunk);\n            if (!streamBufferingLoggedWarning && bytesSeen > size * 2) {\n                streamBufferingLoggedWarning = true;\n                logger?.warn(`@smithy/util-stream - stream chunk size ${chunkSize} is below threshold of ${size}, automatically buffering.`);\n            }\n            if (newSize >= size) {\n                downstream.push((0, createBufferedReadableStream_1.flush)(buffers, mode));\n            }\n        }\n    });\n    upstream.on(\"end\", () => {\n        if (mode !== -1) {\n            const remainder = (0, createBufferedReadableStream_1.flush)(buffers, mode);\n            if ((0, createBufferedReadableStream_1.sizeOf)(remainder) > 0) {\n                downstream.push(remainder);\n            }\n        }\n        downstream.push(null);\n    });\n    return downstream;\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.createBufferedReadable = void 0;\nexports.createBufferedReadableStream = createBufferedReadableStream;\nexports.merge = merge;\nexports.flush = flush;\nexports.sizeOf = sizeOf;\nexports.modeOf = modeOf;\nconst ByteArrayCollector_1 = require(\"./ByteArrayCollector\");\nfunction createBufferedReadableStream(upstream, size, logger) {\n    const reader = upstream.getReader();\n    let streamBufferingLoggedWarning = false;\n    let bytesSeen = 0;\n    const buffers = [\"\", new ByteArrayCollector_1.ByteArrayCollector((size) => new Uint8Array(size))];\n    let mode = -1;\n    const pull = async (controller) => {\n        const { value, done } = await reader.read();\n        const chunk = value;\n        if (done) {\n            if (mode !== -1) {\n                const remainder = flush(buffers, mode);\n                if (sizeOf(remainder) > 0) {\n                    controller.enqueue(remainder);\n                }\n            }\n            controller.close();\n        }\n        else {\n            const chunkMode = modeOf(chunk, false);\n            if (mode !== chunkMode) {\n                if (mode >= 0) {\n                    controller.enqueue(flush(buffers, mode));\n                }\n                mode = chunkMode;\n            }\n            if (mode === -1) {\n                controller.enqueue(chunk);\n                return;\n            }\n            const chunkSize = sizeOf(chunk);\n            bytesSeen += chunkSize;\n            const bufferSize = sizeOf(buffers[mode]);\n            if (chunkSize >= size && bufferSize === 0) {\n                controller.enqueue(chunk);\n            }\n            else {\n                const newSize = merge(buffers, mode, chunk);\n                if (!streamBufferingLoggedWarning && bytesSeen > size * 2) {\n                    streamBufferingLoggedWarning = true;\n                    logger?.warn(`@smithy/util-stream - stream chunk size ${chunkSize} is below threshold of ${size}, automatically buffering.`);\n                }\n                if (newSize >= size) {\n                    controller.enqueue(flush(buffers, mode));\n                }\n                else {\n                    await pull(controller);\n                }\n            }\n        }\n    };\n    return new ReadableStream({\n        pull,\n    });\n}\nexports.createBufferedReadable = createBufferedReadableStream;\nfunction merge(buffers, mode, chunk) {\n    switch (mode) {\n        case 0:\n            buffers[0] += chunk;\n            return sizeOf(buffers[0]);\n        case 1:\n        case 2:\n            buffers[mode].push(chunk);\n            return sizeOf(buffers[mode]);\n    }\n}\nfunction flush(buffers, mode) {\n    switch (mode) {\n        case 0:\n            const s = buffers[0];\n            buffers[0] = \"\";\n            return s;\n        case 1:\n        case 2:\n            return buffers[mode].flush();\n    }\n    throw new Error(`@smithy/util-stream - invalid index ${mode} given to flush()`);\n}\nfunction sizeOf(chunk) {\n    return chunk?.byteLength ?? chunk?.length ?? 0;\n}\nfunction modeOf(chunk, allowBuffer = true) {\n    if (allowBuffer && typeof Buffer !== \"undefined\" && chunk instanceof Buffer) {\n        return 2;\n    }\n    if (chunk instanceof Uint8Array) {\n        return 1;\n    }\n    if (typeof chunk === \"string\") {\n        return 0;\n    }\n    return -1;\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getAwsChunkedEncodingStream = void 0;\nconst getAwsChunkedEncodingStream = (readableStream, options) => {\n    const { base64Encoder, bodyLengthChecker, checksumAlgorithmFn, checksumLocationName, streamHasher } = options;\n    const checksumRequired = base64Encoder !== undefined &&\n        bodyLengthChecker !== undefined &&\n        checksumAlgorithmFn !== undefined &&\n        checksumLocationName !== undefined &&\n        streamHasher !== undefined;\n    const digest = checksumRequired ? streamHasher(checksumAlgorithmFn, readableStream) : undefined;\n    const reader = readableStream.getReader();\n    return new ReadableStream({\n        async pull(controller) {\n            const { value, done } = await reader.read();\n            if (done) {\n                controller.enqueue(`0\\r\\n`);\n                if (checksumRequired) {\n                    const checksum = base64Encoder(await digest);\n                    controller.enqueue(`${checksumLocationName}:${checksum}\\r\\n`);\n                    controller.enqueue(`\\r\\n`);\n                }\n                controller.close();\n            }\n            else {\n                controller.enqueue(`${(bodyLengthChecker(value) || 0).toString(16)}\\r\\n${value}\\r\\n`);\n            }\n        },\n    });\n};\nexports.getAwsChunkedEncodingStream = getAwsChunkedEncodingStream;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getAwsChunkedEncodingStream = getAwsChunkedEncodingStream;\nconst node_stream_1 = require(\"node:stream\");\nconst getAwsChunkedEncodingStream_browser_1 = require(\"./getAwsChunkedEncodingStream.browser\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nfunction getAwsChunkedEncodingStream(stream, options) {\n    const readable = stream;\n    const readableStream = stream;\n    if ((0, stream_type_check_1.isReadableStream)(readableStream)) {\n        return (0, getAwsChunkedEncodingStream_browser_1.getAwsChunkedEncodingStream)(readableStream, options);\n    }\n    const { base64Encoder, bodyLengthChecker, checksumAlgorithmFn, checksumLocationName, streamHasher } = options;\n    const checksumRequired = base64Encoder !== undefined &&\n        checksumAlgorithmFn !== undefined &&\n        checksumLocationName !== undefined &&\n        streamHasher !== undefined;\n    const digest = checksumRequired ? streamHasher(checksumAlgorithmFn, readable) : undefined;\n    const awsChunkedEncodingStream = new node_stream_1.Readable({\n        read: () => { },\n    });\n    readable.on(\"data\", (data) => {\n        const length = bodyLengthChecker(data) || 0;\n        if (length === 0) {\n            return;\n        }\n        awsChunkedEncodingStream.push(`${length.toString(16)}\\r\\n`);\n        awsChunkedEncodingStream.push(data);\n        awsChunkedEncodingStream.push(\"\\r\\n\");\n    });\n    readable.on(\"end\", async () => {\n        awsChunkedEncodingStream.push(`0\\r\\n`);\n        if (checksumRequired) {\n            const checksum = base64Encoder(await digest);\n            awsChunkedEncodingStream.push(`${checksumLocationName}:${checksum}\\r\\n`);\n            awsChunkedEncodingStream.push(`\\r\\n`);\n        }\n        awsChunkedEncodingStream.push(null);\n    });\n    return awsChunkedEncodingStream;\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.headStream = headStream;\nasync function headStream(stream, bytes) {\n    let byteLengthCounter = 0;\n    const chunks = [];\n    const reader = stream.getReader();\n    let isDone = false;\n    while (!isDone) {\n        const { done, value } = await reader.read();\n        if (value) {\n            chunks.push(value);\n            byteLengthCounter += value?.byteLength ?? 0;\n        }\n        if (byteLengthCounter >= bytes) {\n            break;\n        }\n        isDone = done;\n    }\n    reader.releaseLock();\n    const collected = new Uint8Array(Math.min(bytes, byteLengthCounter));\n    let offset = 0;\n    for (const chunk of chunks) {\n        if (chunk.byteLength > collected.byteLength - offset) {\n            collected.set(chunk.subarray(0, collected.byteLength - offset), offset);\n            break;\n        }\n        else {\n            collected.set(chunk, offset);\n        }\n        offset += chunk.length;\n    }\n    return collected;\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.headStream = void 0;\nconst stream_1 = require(\"stream\");\nconst headStream_browser_1 = require(\"./headStream.browser\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nconst headStream = (stream, bytes) => {\n    if ((0, stream_type_check_1.isReadableStream)(stream)) {\n        return (0, headStream_browser_1.headStream)(stream, bytes);\n    }\n    return new Promise((resolve, reject) => {\n        const collector = new Collector();\n        collector.limit = bytes;\n        stream.pipe(collector);\n        stream.on(\"error\", (err) => {\n            collector.end();\n            reject(err);\n        });\n        collector.on(\"error\", reject);\n        collector.on(\"finish\", function () {\n            const bytes = new Uint8Array(Buffer.concat(this.buffers));\n            resolve(bytes);\n        });\n    });\n};\nexports.headStream = headStream;\nclass Collector extends stream_1.Writable {\n    buffers = [];\n    limit = Infinity;\n    bytesBuffered = 0;\n    _write(chunk, encoding, callback) {\n        this.buffers.push(chunk);\n        this.bytesBuffered += chunk.byteLength ?? 0;\n        if (this.bytesBuffered >= this.limit) {\n            const excess = this.bytesBuffered - this.limit;\n            const tailBuffer = this.buffers[this.buffers.length - 1];\n            this.buffers[this.buffers.length - 1] = tailBuffer.subarray(0, tailBuffer.byteLength - excess);\n            this.emit(\"finish\");\n        }\n        callback();\n    }\n}\n","'use strict';\n\nvar utilBase64 = require('@smithy/util-base64');\nvar utilUtf8 = require('@smithy/util-utf8');\nvar ChecksumStream = require('./checksum/ChecksumStream');\nvar createChecksumStream = require('./checksum/createChecksumStream');\nvar createBufferedReadable = require('./createBufferedReadable');\nvar getAwsChunkedEncodingStream = require('./getAwsChunkedEncodingStream');\nvar headStream = require('./headStream');\nvar sdkStreamMixin = require('./sdk-stream-mixin');\nvar splitStream = require('./splitStream');\nvar streamTypeCheck = require('./stream-type-check');\n\nclass Uint8ArrayBlobAdapter extends Uint8Array {\n    static fromString(source, encoding = \"utf-8\") {\n        if (typeof source === \"string\") {\n            if (encoding === \"base64\") {\n                return Uint8ArrayBlobAdapter.mutate(utilBase64.fromBase64(source));\n            }\n            return Uint8ArrayBlobAdapter.mutate(utilUtf8.fromUtf8(source));\n        }\n        throw new Error(`Unsupported conversion from ${typeof source} to Uint8ArrayBlobAdapter.`);\n    }\n    static mutate(source) {\n        Object.setPrototypeOf(source, Uint8ArrayBlobAdapter.prototype);\n        return source;\n    }\n    transformToString(encoding = \"utf-8\") {\n        if (encoding === \"base64\") {\n            return utilBase64.toBase64(this);\n        }\n        return utilUtf8.toUtf8(this);\n    }\n}\n\nObject.defineProperty(exports, \"isBlob\", {\n    enumerable: true,\n    get: function () { return streamTypeCheck.isBlob; }\n});\nObject.defineProperty(exports, \"isReadableStream\", {\n    enumerable: true,\n    get: function () { return streamTypeCheck.isReadableStream; }\n});\nexports.Uint8ArrayBlobAdapter = Uint8ArrayBlobAdapter;\nObject.keys(ChecksumStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return ChecksumStream[k]; }\n    });\n});\nObject.keys(createChecksumStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return createChecksumStream[k]; }\n    });\n});\nObject.keys(createBufferedReadable).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return createBufferedReadable[k]; }\n    });\n});\nObject.keys(getAwsChunkedEncodingStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return getAwsChunkedEncodingStream[k]; }\n    });\n});\nObject.keys(headStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return headStream[k]; }\n    });\n});\nObject.keys(sdkStreamMixin).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return sdkStreamMixin[k]; }\n    });\n});\nObject.keys(splitStream).forEach(function (k) {\n    if (k !== 'default' && !Object.prototype.hasOwnProperty.call(exports, k)) Object.defineProperty(exports, k, {\n        enumerable: true,\n        get: function () { return splitStream[k]; }\n    });\n});\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.sdkStreamMixin = void 0;\nconst fetch_http_handler_1 = require(\"@smithy/fetch-http-handler\");\nconst util_base64_1 = require(\"@smithy/util-base64\");\nconst util_hex_encoding_1 = require(\"@smithy/util-hex-encoding\");\nconst util_utf8_1 = require(\"@smithy/util-utf8\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nconst ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED = \"The stream has already been transformed.\";\nconst sdkStreamMixin = (stream) => {\n    if (!isBlobInstance(stream) && !(0, stream_type_check_1.isReadableStream)(stream)) {\n        const name = stream?.__proto__?.constructor?.name || stream;\n        throw new Error(`Unexpected stream implementation, expect Blob or ReadableStream, got ${name}`);\n    }\n    let transformed = false;\n    const transformToByteArray = async () => {\n        if (transformed) {\n            throw new Error(ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED);\n        }\n        transformed = true;\n        return await (0, fetch_http_handler_1.streamCollector)(stream);\n    };\n    const blobToWebStream = (blob) => {\n        if (typeof blob.stream !== \"function\") {\n            throw new Error(\"Cannot transform payload Blob to web stream. Please make sure the Blob.stream() is polyfilled.\\n\" +\n                \"If you are using React Native, this API is not yet supported, see: https://react-native.canny.io/feature-requests/p/fetch-streaming-body\");\n        }\n        return blob.stream();\n    };\n    return Object.assign(stream, {\n        transformToByteArray: transformToByteArray,\n        transformToString: async (encoding) => {\n            const buf = await transformToByteArray();\n            if (encoding === \"base64\") {\n                return (0, util_base64_1.toBase64)(buf);\n            }\n            else if (encoding === \"hex\") {\n                return (0, util_hex_encoding_1.toHex)(buf);\n            }\n            else if (encoding === undefined || encoding === \"utf8\" || encoding === \"utf-8\") {\n                return (0, util_utf8_1.toUtf8)(buf);\n            }\n            else if (typeof TextDecoder === \"function\") {\n                return new TextDecoder(encoding).decode(buf);\n            }\n            else {\n                throw new Error(\"TextDecoder is not available, please make sure polyfill is provided.\");\n            }\n        },\n        transformToWebStream: () => {\n            if (transformed) {\n                throw new Error(ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED);\n            }\n            transformed = true;\n            if (isBlobInstance(stream)) {\n                return blobToWebStream(stream);\n            }\n            else if ((0, stream_type_check_1.isReadableStream)(stream)) {\n                return stream;\n            }\n            else {\n                throw new Error(`Cannot transform payload to web stream, got ${stream}`);\n            }\n        },\n    });\n};\nexports.sdkStreamMixin = sdkStreamMixin;\nconst isBlobInstance = (stream) => typeof Blob === \"function\" && stream instanceof Blob;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.sdkStreamMixin = void 0;\nconst node_http_handler_1 = require(\"@smithy/node-http-handler\");\nconst util_buffer_from_1 = require(\"@smithy/util-buffer-from\");\nconst stream_1 = require(\"stream\");\nconst sdk_stream_mixin_browser_1 = require(\"./sdk-stream-mixin.browser\");\nconst ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED = \"The stream has already been transformed.\";\nconst sdkStreamMixin = (stream) => {\n    if (!(stream instanceof stream_1.Readable)) {\n        try {\n            return (0, sdk_stream_mixin_browser_1.sdkStreamMixin)(stream);\n        }\n        catch (e) {\n            const name = stream?.__proto__?.constructor?.name || stream;\n            throw new Error(`Unexpected stream implementation, expect Stream.Readable instance, got ${name}`);\n        }\n    }\n    let transformed = false;\n    const transformToByteArray = async () => {\n        if (transformed) {\n            throw new Error(ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED);\n        }\n        transformed = true;\n        return await (0, node_http_handler_1.streamCollector)(stream);\n    };\n    return Object.assign(stream, {\n        transformToByteArray,\n        transformToString: async (encoding) => {\n            const buf = await transformToByteArray();\n            if (encoding === undefined || Buffer.isEncoding(encoding)) {\n                return (0, util_buffer_from_1.fromArrayBuffer)(buf.buffer, buf.byteOffset, buf.byteLength).toString(encoding);\n            }\n            else {\n                const decoder = new TextDecoder(encoding);\n                return decoder.decode(buf);\n            }\n        },\n        transformToWebStream: () => {\n            if (transformed) {\n                throw new Error(ERR_MSG_STREAM_HAS_BEEN_TRANSFORMED);\n            }\n            if (stream.readableFlowing !== null) {\n                throw new Error(\"The stream has been consumed by other callbacks.\");\n            }\n            if (typeof stream_1.Readable.toWeb !== \"function\") {\n                throw new Error(\"Readable.toWeb() is not supported. Please ensure a polyfill is available.\");\n            }\n            transformed = true;\n            return stream_1.Readable.toWeb(stream);\n        },\n    });\n};\nexports.sdkStreamMixin = sdkStreamMixin;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.splitStream = splitStream;\nasync function splitStream(stream) {\n    if (typeof stream.stream === \"function\") {\n        stream = stream.stream();\n    }\n    const readableStream = stream;\n    return readableStream.tee();\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.splitStream = splitStream;\nconst stream_1 = require(\"stream\");\nconst splitStream_browser_1 = require(\"./splitStream.browser\");\nconst stream_type_check_1 = require(\"./stream-type-check\");\nasync function splitStream(stream) {\n    if ((0, stream_type_check_1.isReadableStream)(stream) || (0, stream_type_check_1.isBlob)(stream)) {\n        return (0, splitStream_browser_1.splitStream)(stream);\n    }\n    const stream1 = new stream_1.PassThrough();\n    const stream2 = new stream_1.PassThrough();\n    stream.pipe(stream1);\n    stream.pipe(stream2);\n    return [stream1, stream2];\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.isBlob = exports.isReadableStream = void 0;\nconst isReadableStream = (stream) => typeof ReadableStream === \"function\" &&\n    (stream?.constructor?.name === ReadableStream.name || stream instanceof ReadableStream);\nexports.isReadableStream = isReadableStream;\nconst isBlob = (blob) => {\n    return typeof Blob === \"function\" && (blob?.constructor?.name === Blob.name || blob instanceof Blob);\n};\nexports.isBlob = isBlob;\n","'use strict';\n\nconst escapeUri = (uri) => encodeURIComponent(uri).replace(/[!'()*]/g, hexEncode);\nconst hexEncode = (c) => `%${c.charCodeAt(0).toString(16).toUpperCase()}`;\n\nconst escapeUriPath = (uri) => uri.split(\"/\").map(escapeUri).join(\"/\");\n\nexports.escapeUri = escapeUri;\nexports.escapeUriPath = escapeUriPath;\n","'use strict';\n\nvar utilBufferFrom = require('@smithy/util-buffer-from');\n\nconst fromUtf8 = (input) => {\n    const buf = utilBufferFrom.fromString(input, \"utf8\");\n    return new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength / Uint8Array.BYTES_PER_ELEMENT);\n};\n\nconst toUint8Array = (data) => {\n    if (typeof data === \"string\") {\n        return fromUtf8(data);\n    }\n    if (ArrayBuffer.isView(data)) {\n        return new Uint8Array(data.buffer, data.byteOffset, data.byteLength / Uint8Array.BYTES_PER_ELEMENT);\n    }\n    return new Uint8Array(data);\n};\n\nconst toUtf8 = (input) => {\n    if (typeof input === \"string\") {\n        return input;\n    }\n    if (typeof input !== \"object\" || typeof input.byteOffset !== \"number\" || typeof input.byteLength !== \"number\") {\n        throw new Error(\"@smithy/util-utf8: toUtf8 encoder function only accepts string | Uint8Array.\");\n    }\n    return utilBufferFrom.fromArrayBuffer(input.buffer, input.byteOffset, input.byteLength).toString(\"utf8\");\n};\n\nexports.fromUtf8 = fromUtf8;\nexports.toUint8Array = toUint8Array;\nexports.toUtf8 = toUtf8;\n","'use strict';\n\nconst getCircularReplacer = () => {\n    const seen = new WeakSet();\n    return (key, value) => {\n        if (typeof value === \"object\" && value !== null) {\n            if (seen.has(value)) {\n                return \"[Circular]\";\n            }\n            seen.add(value);\n        }\n        return value;\n    };\n};\n\nconst sleep = (seconds) => {\n    return new Promise((resolve) => setTimeout(resolve, seconds * 1000));\n};\n\nconst waiterServiceDefaults = {\n    minDelay: 2,\n    maxDelay: 120,\n};\nexports.WaiterState = void 0;\n(function (WaiterState) {\n    WaiterState[\"ABORTED\"] = \"ABORTED\";\n    WaiterState[\"FAILURE\"] = \"FAILURE\";\n    WaiterState[\"SUCCESS\"] = \"SUCCESS\";\n    WaiterState[\"RETRY\"] = \"RETRY\";\n    WaiterState[\"TIMEOUT\"] = \"TIMEOUT\";\n})(exports.WaiterState || (exports.WaiterState = {}));\nconst checkExceptions = (result) => {\n    if (result.state === exports.WaiterState.ABORTED) {\n        const abortError = new Error(`${JSON.stringify({\n            ...result,\n            reason: \"Request was aborted\",\n        }, getCircularReplacer())}`);\n        abortError.name = \"AbortError\";\n        throw abortError;\n    }\n    else if (result.state === exports.WaiterState.TIMEOUT) {\n        const timeoutError = new Error(`${JSON.stringify({\n            ...result,\n            reason: \"Waiter has timed out\",\n        }, getCircularReplacer())}`);\n        timeoutError.name = \"TimeoutError\";\n        throw timeoutError;\n    }\n    else if (result.state !== exports.WaiterState.SUCCESS) {\n        throw new Error(`${JSON.stringify(result, getCircularReplacer())}`);\n    }\n    return result;\n};\n\nconst exponentialBackoffWithJitter = (minDelay, maxDelay, attemptCeiling, attempt) => {\n    if (attempt > attemptCeiling)\n        return maxDelay;\n    const delay = minDelay * 2 ** (attempt - 1);\n    return randomInRange(minDelay, delay);\n};\nconst randomInRange = (min, max) => min + Math.random() * (max - min);\nconst runPolling = async ({ minDelay, maxDelay, maxWaitTime, abortController, client, abortSignal }, input, acceptorChecks) => {\n    const observedResponses = {};\n    const { state, reason } = await acceptorChecks(client, input);\n    if (reason) {\n        const message = createMessageFromResponse(reason);\n        observedResponses[message] |= 0;\n        observedResponses[message] += 1;\n    }\n    if (state !== exports.WaiterState.RETRY) {\n        return { state, reason, observedResponses };\n    }\n    let currentAttempt = 1;\n    const waitUntil = Date.now() + maxWaitTime * 1000;\n    const attemptCeiling = Math.log(maxDelay / minDelay) / Math.log(2) + 1;\n    while (true) {\n        if (abortController?.signal?.aborted || abortSignal?.aborted) {\n            const message = \"AbortController signal aborted.\";\n            observedResponses[message] |= 0;\n            observedResponses[message] += 1;\n            return { state: exports.WaiterState.ABORTED, observedResponses };\n        }\n        const delay = exponentialBackoffWithJitter(minDelay, maxDelay, attemptCeiling, currentAttempt);\n        if (Date.now() + delay * 1000 > waitUntil) {\n            return { state: exports.WaiterState.TIMEOUT, observedResponses };\n        }\n        await sleep(delay);\n        const { state, reason } = await acceptorChecks(client, input);\n        if (reason) {\n            const message = createMessageFromResponse(reason);\n            observedResponses[message] |= 0;\n            observedResponses[message] += 1;\n        }\n        if (state !== exports.WaiterState.RETRY) {\n            return { state, reason, observedResponses };\n        }\n        currentAttempt += 1;\n    }\n};\nconst createMessageFromResponse = (reason) => {\n    if (reason?.$responseBodyText) {\n        return `Deserialization error for body: ${reason.$responseBodyText}`;\n    }\n    if (reason?.$metadata?.httpStatusCode) {\n        if (reason.$response || reason.message) {\n            return `${reason.$response.statusCode ?? reason.$metadata.httpStatusCode ?? \"Unknown\"}: ${reason.message}`;\n        }\n        return `${reason.$metadata.httpStatusCode}: OK`;\n    }\n    return String(reason?.message ?? JSON.stringify(reason, getCircularReplacer()) ?? \"Unknown\");\n};\n\nconst validateWaiterOptions = (options) => {\n    if (options.maxWaitTime <= 0) {\n        throw new Error(`WaiterConfiguration.maxWaitTime must be greater than 0`);\n    }\n    else if (options.minDelay <= 0) {\n        throw new Error(`WaiterConfiguration.minDelay must be greater than 0`);\n    }\n    else if (options.maxDelay <= 0) {\n        throw new Error(`WaiterConfiguration.maxDelay must be greater than 0`);\n    }\n    else if (options.maxWaitTime <= options.minDelay) {\n        throw new Error(`WaiterConfiguration.maxWaitTime [${options.maxWaitTime}] must be greater than WaiterConfiguration.minDelay [${options.minDelay}] for this waiter`);\n    }\n    else if (options.maxDelay < options.minDelay) {\n        throw new Error(`WaiterConfiguration.maxDelay [${options.maxDelay}] must be greater than WaiterConfiguration.minDelay [${options.minDelay}] for this waiter`);\n    }\n};\n\nconst abortTimeout = (abortSignal) => {\n    let onAbort;\n    const promise = new Promise((resolve) => {\n        onAbort = () => resolve({ state: exports.WaiterState.ABORTED });\n        if (typeof abortSignal.addEventListener === \"function\") {\n            abortSignal.addEventListener(\"abort\", onAbort);\n        }\n        else {\n            abortSignal.onabort = onAbort;\n        }\n    });\n    return {\n        clearListener() {\n            if (typeof abortSignal.removeEventListener === \"function\") {\n                abortSignal.removeEventListener(\"abort\", onAbort);\n            }\n        },\n        aborted: promise,\n    };\n};\nconst createWaiter = async (options, input, acceptorChecks) => {\n    const params = {\n        ...waiterServiceDefaults,\n        ...options,\n    };\n    validateWaiterOptions(params);\n    const exitConditions = [runPolling(params, input, acceptorChecks)];\n    const finalize = [];\n    if (options.abortSignal) {\n        const { aborted, clearListener } = abortTimeout(options.abortSignal);\n        finalize.push(clearListener);\n        exitConditions.push(aborted);\n    }\n    if (options.abortController?.signal) {\n        const { aborted, clearListener } = abortTimeout(options.abortController.signal);\n        finalize.push(clearListener);\n        exitConditions.push(aborted);\n    }\n    return Promise.race(exitConditions).then((result) => {\n        for (const fn of finalize) {\n            fn();\n        }\n        return result;\n    });\n};\n\nexports.checkExceptions = checkExceptions;\nexports.createWaiter = createWaiter;\nexports.waiterServiceDefaults = waiterServiceDefaults;\n","'use strict';\n\nvar randomUUID = require('./randomUUID');\n\nconst decimalToHex = Array.from({ length: 256 }, (_, i) => i.toString(16).padStart(2, \"0\"));\nconst v4 = () => {\n    if (randomUUID.randomUUID) {\n        return randomUUID.randomUUID();\n    }\n    const rnds = new Uint8Array(16);\n    crypto.getRandomValues(rnds);\n    rnds[6] = (rnds[6] & 0x0f) | 0x40;\n    rnds[8] = (rnds[8] & 0x3f) | 0x80;\n    return (decimalToHex[rnds[0]] +\n        decimalToHex[rnds[1]] +\n        decimalToHex[rnds[2]] +\n        decimalToHex[rnds[3]] +\n        \"-\" +\n        decimalToHex[rnds[4]] +\n        decimalToHex[rnds[5]] +\n        \"-\" +\n        decimalToHex[rnds[6]] +\n        decimalToHex[rnds[7]] +\n        \"-\" +\n        decimalToHex[rnds[8]] +\n        decimalToHex[rnds[9]] +\n        \"-\" +\n        decimalToHex[rnds[10]] +\n        decimalToHex[rnds[11]] +\n        decimalToHex[rnds[12]] +\n        decimalToHex[rnds[13]] +\n        decimalToHex[rnds[14]] +\n        decimalToHex[rnds[15]]);\n};\n\nexports.v4 = v4;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.randomUUID = void 0;\nconst tslib_1 = require(\"tslib\");\nconst crypto_1 = tslib_1.__importDefault(require(\"crypto\"));\nexports.randomUUID = crypto_1.default.randomUUID.bind(crypto_1.default);\n","/**\n * @author Toru Nagashima <https://github.com/mysticatea>\n * See LICENSE file in root directory for full license.\n */\n'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar eventTargetShim = require('event-target-shim');\n\n/**\n * The signal class.\n * @see https://dom.spec.whatwg.org/#abortsignal\n */\nclass AbortSignal extends eventTargetShim.EventTarget {\n    /**\n     * AbortSignal cannot be constructed directly.\n     */\n    constructor() {\n        super();\n        throw new TypeError(\"AbortSignal cannot be constructed directly\");\n    }\n    /**\n     * Returns `true` if this `AbortSignal`'s `AbortController` has signaled to abort, and `false` otherwise.\n     */\n    get aborted() {\n        const aborted = abortedFlags.get(this);\n        if (typeof aborted !== \"boolean\") {\n            throw new TypeError(`Expected 'this' to be an 'AbortSignal' object, but got ${this === null ? \"null\" : typeof this}`);\n        }\n        return aborted;\n    }\n}\neventTargetShim.defineEventAttribute(AbortSignal.prototype, \"abort\");\n/**\n * Create an AbortSignal object.\n */\nfunction createAbortSignal() {\n    const signal = Object.create(AbortSignal.prototype);\n    eventTargetShim.EventTarget.call(signal);\n    abortedFlags.set(signal, false);\n    return signal;\n}\n/**\n * Abort a given signal.\n */\nfunction abortSignal(signal) {\n    if (abortedFlags.get(signal) !== false) {\n        return;\n    }\n    abortedFlags.set(signal, true);\n    signal.dispatchEvent({ type: \"abort\" });\n}\n/**\n * Aborted flag for each instances.\n */\nconst abortedFlags = new WeakMap();\n// Properties should be enumerable.\nObject.defineProperties(AbortSignal.prototype, {\n    aborted: { enumerable: true },\n});\n// `toString()` should return `\"[object AbortSignal]\"`\nif (typeof Symbol === \"function\" && typeof Symbol.toStringTag === \"symbol\") {\n    Object.defineProperty(AbortSignal.prototype, Symbol.toStringTag, {\n        configurable: true,\n        value: \"AbortSignal\",\n    });\n}\n\n/**\n * The AbortController.\n * @see https://dom.spec.whatwg.org/#abortcontroller\n */\nclass AbortController {\n    /**\n     * Initialize this controller.\n     */\n    constructor() {\n        signals.set(this, createAbortSignal());\n    }\n    /**\n     * Returns the `AbortSignal` object associated with this object.\n     */\n    get signal() {\n        return getSignal(this);\n    }\n    /**\n     * Abort and signal to any observers that the associated activity is to be aborted.\n     */\n    abort() {\n        abortSignal(getSignal(this));\n    }\n}\n/**\n * Associated signals.\n */\nconst signals = new WeakMap();\n/**\n * Get the associated signal of a given controller.\n */\nfunction getSignal(controller) {\n    const signal = signals.get(controller);\n    if (signal == null) {\n        throw new TypeError(`Expected 'this' to be an 'AbortController' object, but got ${controller === null ? \"null\" : typeof controller}`);\n    }\n    return signal;\n}\n// Properties should be enumerable.\nObject.defineProperties(AbortController.prototype, {\n    signal: { enumerable: true },\n    abort: { enumerable: true },\n});\nif (typeof Symbol === \"function\" && typeof Symbol.toStringTag === \"symbol\") {\n    Object.defineProperty(AbortController.prototype, Symbol.toStringTag, {\n        configurable: true,\n        value: \"AbortController\",\n    });\n}\n\nexports.AbortController = AbortController;\nexports.AbortSignal = AbortSignal;\nexports.default = AbortController;\n\nmodule.exports = AbortController\nmodule.exports.AbortController = module.exports[\"default\"] = AbortController\nmodule.exports.AbortSignal = AbortSignal\n//# sourceMappingURL=abort-controller.js.map\n","/**\n * archiver-utils\n *\n * Copyright (c) 2012-2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-archiver/blob/master/LICENSE-MIT\n */\nvar fs = require('graceful-fs');\nvar path = require('path');\n\nvar flatten = require('lodash/flatten');\nvar difference = require('lodash/difference');\nvar union = require('lodash/union');\nvar isPlainObject = require('lodash/isPlainObject');\n\nvar glob = require('glob');\n\nvar file = module.exports = {};\n\nvar pathSeparatorRe = /[\\/\\\\]/g;\n\n// Process specified wildcard glob patterns or filenames against a\n// callback, excluding and uniquing files in the result set.\nvar processPatterns = function(patterns, fn) {\n  // Filepaths to return.\n  var result = [];\n  // Iterate over flattened patterns array.\n  flatten(patterns).forEach(function(pattern) {\n    // If the first character is ! it should be omitted\n    var exclusion = pattern.indexOf('!') === 0;\n    // If the pattern is an exclusion, remove the !\n    if (exclusion) { pattern = pattern.slice(1); }\n    // Find all matching files for this pattern.\n    var matches = fn(pattern);\n    if (exclusion) {\n      // If an exclusion, remove matching files.\n      result = difference(result, matches);\n    } else {\n      // Otherwise add matching files.\n      result = union(result, matches);\n    }\n  });\n  return result;\n};\n\n// True if the file path exists.\nfile.exists = function() {\n  var filepath = path.join.apply(path, arguments);\n  return fs.existsSync(filepath);\n};\n\n// Return an array of all file paths that match the given wildcard patterns.\nfile.expand = function(...args) {\n  // If the first argument is an options object, save those options to pass\n  // into the File.prototype.glob.sync method.\n  var options = isPlainObject(args[0]) ? args.shift() : {};\n  // Use the first argument if it's an Array, otherwise convert the arguments\n  // object to an array and use that.\n  var patterns = Array.isArray(args[0]) ? args[0] : args;\n  // Return empty set if there are no patterns or filepaths.\n  if (patterns.length === 0) { return []; }\n  // Return all matching filepaths.\n  var matches = processPatterns(patterns, function(pattern) {\n    // Find all matching files for this pattern.\n    return glob.sync(pattern, options);\n  });\n  // Filter result set?\n  if (options.filter) {\n    matches = matches.filter(function(filepath) {\n      filepath = path.join(options.cwd || '', filepath);\n      try {\n        if (typeof options.filter === 'function') {\n          return options.filter(filepath);\n        } else {\n          // If the file is of the right type and exists, this should work.\n          return fs.statSync(filepath)[options.filter]();\n        }\n      } catch(e) {\n        // Otherwise, it's probably not the right type.\n        return false;\n      }\n    });\n  }\n  return matches;\n};\n\n// Build a multi task \"files\" object dynamically.\nfile.expandMapping = function(patterns, destBase, options) {\n  options = Object.assign({\n    rename: function(destBase, destPath) {\n      return path.join(destBase || '', destPath);\n    }\n  }, options);\n  var files = [];\n  var fileByDest = {};\n  // Find all files matching pattern, using passed-in options.\n  file.expand(options, patterns).forEach(function(src) {\n    var destPath = src;\n    // Flatten?\n    if (options.flatten) {\n      destPath = path.basename(destPath);\n    }\n    // Change the extension?\n    if (options.ext) {\n      destPath = destPath.replace(/(\\.[^\\/]*)?$/, options.ext);\n    }\n    // Generate destination filename.\n    var dest = options.rename(destBase, destPath, options);\n    // Prepend cwd to src path if necessary.\n    if (options.cwd) { src = path.join(options.cwd, src); }\n    // Normalize filepaths to be unix-style.\n    dest = dest.replace(pathSeparatorRe, '/');\n    src = src.replace(pathSeparatorRe, '/');\n    // Map correct src path to dest path.\n    if (fileByDest[dest]) {\n      // If dest already exists, push this src onto that dest's src array.\n      fileByDest[dest].src.push(src);\n    } else {\n      // Otherwise create a new src-dest file mapping object.\n      files.push({\n        src: [src],\n        dest: dest,\n      });\n      // And store a reference for later use.\n      fileByDest[dest] = files[files.length - 1];\n    }\n  });\n  return files;\n};\n\n// reusing bits of grunt's multi-task source normalization\nfile.normalizeFilesArray = function(data) {\n  var files = [];\n\n  data.forEach(function(obj) {\n    var prop;\n    if ('src' in obj || 'dest' in obj) {\n      files.push(obj);\n    }\n  });\n\n  if (files.length === 0) {\n    return [];\n  }\n\n  files = _(files).chain().forEach(function(obj) {\n    if (!('src' in obj) || !obj.src) { return; }\n    // Normalize .src properties to flattened array.\n    if (Array.isArray(obj.src)) {\n      obj.src = flatten(obj.src);\n    } else {\n      obj.src = [obj.src];\n    }\n  }).map(function(obj) {\n    // Build options object, removing unwanted properties.\n    var expandOptions = Object.assign({}, obj);\n    delete expandOptions.src;\n    delete expandOptions.dest;\n\n    // Expand file mappings.\n    if (obj.expand) {\n      return file.expandMapping(obj.src, obj.dest, expandOptions).map(function(mapObj) {\n        // Copy obj properties to result.\n        var result = Object.assign({}, obj);\n        // Make a clone of the orig obj available.\n        result.orig = Object.assign({}, obj);\n        // Set .src and .dest, processing both as templates.\n        result.src = mapObj.src;\n        result.dest = mapObj.dest;\n        // Remove unwanted properties.\n        ['expand', 'cwd', 'flatten', 'rename', 'ext'].forEach(function(prop) {\n          delete result[prop];\n        });\n        return result;\n      });\n    }\n\n    // Copy obj properties to result, adding an .orig property.\n    var result = Object.assign({}, obj);\n    // Make a clone of the orig obj available.\n    result.orig = Object.assign({}, obj);\n\n    if ('src' in result) {\n      // Expose an expand-on-demand getter method as .src.\n      Object.defineProperty(result, 'src', {\n        enumerable: true,\n        get: function fn() {\n          var src;\n          if (!('result' in fn)) {\n            src = obj.src;\n            // If src is an array, flatten it. Otherwise, make it into an array.\n            src = Array.isArray(src) ? flatten(src) : [src];\n            // Expand src files, memoizing result.\n            fn.result = file.expand(expandOptions, src);\n          }\n          return fn.result;\n        }\n      });\n    }\n\n    if ('dest' in result) {\n      result.dest = obj.dest;\n    }\n\n    return result;\n  }).flatten().value();\n\n  return files;\n};\n","/**\n * archiver-utils\n *\n * Copyright (c) 2015 Chris Talkington.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/archiver-utils/blob/master/LICENSE\n */\nvar fs = require('graceful-fs');\nvar path = require('path');\nvar isStream = require('is-stream');\nvar lazystream = require('lazystream');\nvar normalizePath = require('normalize-path');\nvar defaults = require('lodash/defaults');\n\nvar Stream = require('stream').Stream;\nvar PassThrough = require('readable-stream').PassThrough;\n\nvar utils = module.exports = {};\nutils.file = require('./file.js');\n\nutils.collectStream = function(source, callback) {\n  var collection = [];\n  var size = 0;\n\n  source.on('error', callback);\n\n  source.on('data', function(chunk) {\n    collection.push(chunk);\n    size += chunk.length;\n  });\n\n  source.on('end', function() {\n    var buf = Buffer.alloc(size);\n    var offset = 0;\n\n    collection.forEach(function(data) {\n      data.copy(buf, offset);\n      offset += data.length;\n    });\n\n    callback(null, buf);\n  });\n};\n\nutils.dateify = function(dateish) {\n  dateish = dateish || new Date();\n\n  if (dateish instanceof Date) {\n    dateish = dateish;\n  } else if (typeof dateish === 'string') {\n    dateish = new Date(dateish);\n  } else {\n    dateish = new Date();\n  }\n\n  return dateish;\n};\n\n// this is slightly different from lodash version\nutils.defaults = function(object, source, guard) {\n  var args = arguments;\n  args[0] = args[0] || {};\n\n  return defaults(...args);\n};\n\nutils.isStream = function(source) {\n  return isStream(source);\n};\n\nutils.lazyReadStream = function(filepath) {\n  return new lazystream.Readable(function() {\n    return fs.createReadStream(filepath);\n  });\n};\n\nutils.normalizeInputSource = function(source) {\n  if (source === null) {\n    return Buffer.alloc(0);\n  } else if (typeof source === 'string') {\n    return Buffer.from(source);\n  } else if (utils.isStream(source)) {\n    // Always pipe through a PassThrough stream to guarantee pausing the stream if it's already flowing,\n    // since it will only be processed in a (distant) future iteration of the event loop, and will lose\n    // data if already flowing now.\n    return source.pipe(new PassThrough());\n  }\n\n  return source;\n};\n\nutils.sanitizePath = function(filepath) {\n  return normalizePath(filepath, false).replace(/^\\w+:/, '').replace(/^(\\.\\.\\/|\\/)+/, '');\n};\n\nutils.trailingSlashIt = function(str) {\n  return str.slice(-1) !== '/' ? str + '/' : str;\n};\n\nutils.unixifyPath = function(filepath) {\n  return normalizePath(filepath, false).replace(/^\\w+:/, '');\n};\n\nutils.walkdir = function(dirpath, base, callback) {\n  var results = [];\n\n  if (typeof base === 'function') {\n    callback = base;\n    base = dirpath;\n  }\n\n  fs.readdir(dirpath, function(err, list) {\n    var i = 0;\n    var file;\n    var filepath;\n\n    if (err) {\n      return callback(err);\n    }\n\n    (function next() {\n      file = list[i++];\n\n      if (!file) {\n        return callback(null, results);\n      }\n\n      filepath = path.join(dirpath, file);\n\n      fs.stat(filepath, function(err, stats) {\n        results.push({\n          path: filepath,\n          relative: path.relative(base, filepath).replace(/\\\\/g, '/'),\n          stats: stats\n        });\n\n        if (stats && stats.isDirectory()) {\n          utils.walkdir(filepath, base, function(err, res) {\n\t    if(err){\n\t      return callback(err);\n\t    }\n\n            res.forEach(function(dirEntry) {\n              results.push(dirEntry);\n            });\n\t\t  \n            next();  \n          });\n        } else {\n          next();\n        }\n      });\n    })();\n  });\n};\n","/**\n * Archiver Vending\n *\n * @ignore\n * @license [MIT]{@link https://github.com/archiverjs/node-archiver/blob/master/LICENSE}\n * @copyright (c) 2012-2014 Chris Talkington, contributors.\n */\nvar Archiver = require('./lib/core');\n\nvar formats = {};\n\n/**\n * Dispenses a new Archiver instance.\n *\n * @constructor\n * @param  {String} format The archive format to use.\n * @param  {Object} options See [Archiver]{@link Archiver}\n * @return {Archiver}\n */\nvar vending = function(format, options) {\n  return vending.create(format, options);\n};\n\n/**\n * Creates a new Archiver instance.\n *\n * @param  {String} format The archive format to use.\n * @param  {Object} options See [Archiver]{@link Archiver}\n * @return {Archiver}\n */\nvending.create = function(format, options) {\n  if (formats[format]) {\n    var instance = new Archiver(format, options);\n    instance.setFormat(format);\n    instance.setModule(new formats[format](options));\n\n    return instance;\n  } else {\n    throw new Error('create(' + format + '): format not registered');\n  }\n};\n\n/**\n * Registers a format for use with archiver.\n *\n * @param  {String} format The name of the format.\n * @param  {Function} module The function for archiver to interact with.\n * @return void\n */\nvending.registerFormat = function(format, module) {\n  if (formats[format]) {\n    throw new Error('register(' + format + '): format already registered');\n  }\n\n  if (typeof module !== 'function') {\n    throw new Error('register(' + format + '): format module invalid');\n  }\n\n  if (typeof module.prototype.append !== 'function' || typeof module.prototype.finalize !== 'function') {\n    throw new Error('register(' + format + '): format module missing methods');\n  }\n\n  formats[format] = module;\n};\n\n/**\n * Check if the format is already registered.\n * \n * @param {String} format the name of the format.\n * @return boolean\n */\nvending.isRegisteredFormat = function (format) {\n  if (formats[format]) {\n    return true;\n  }\n  \n  return false;\n};\n\nvending.registerFormat('zip', require('./lib/plugins/zip'));\nvending.registerFormat('tar', require('./lib/plugins/tar'));\nvending.registerFormat('json', require('./lib/plugins/json'));\n\nmodule.exports = vending;","/**\n * Archiver Core\n *\n * @ignore\n * @license [MIT]{@link https://github.com/archiverjs/node-archiver/blob/master/LICENSE}\n * @copyright (c) 2012-2014 Chris Talkington, contributors.\n */\nvar fs = require('fs');\nvar glob = require('readdir-glob');\nvar async = require('async');\nvar path = require('path');\nvar util = require('archiver-utils');\n\nvar inherits = require('util').inherits;\nvar ArchiverError = require('./error');\nvar Transform = require('readable-stream').Transform;\n\nvar win32 = process.platform === 'win32';\n\n/**\n * @constructor\n * @param {String} format The archive format to use.\n * @param {(CoreOptions|TransformOptions)} options See also {@link ZipOptions} and {@link TarOptions}.\n */\nvar Archiver = function(format, options) {\n  if (!(this instanceof Archiver)) {\n    return new Archiver(format, options);\n  }\n\n  if (typeof format !== 'string') {\n    options = format;\n    format = 'zip';\n  }\n\n  options = this.options = util.defaults(options, {\n    highWaterMark: 1024 * 1024,\n    statConcurrency: 4\n  });\n\n  Transform.call(this, options);\n\n  this._format = false;\n  this._module = false;\n  this._pending = 0;\n  this._pointer = 0;\n\n  this._entriesCount = 0;\n  this._entriesProcessedCount = 0;\n  this._fsEntriesTotalBytes = 0;\n  this._fsEntriesProcessedBytes = 0;\n\n  this._queue = async.queue(this._onQueueTask.bind(this), 1);\n  this._queue.drain(this._onQueueDrain.bind(this));\n\n  this._statQueue = async.queue(this._onStatQueueTask.bind(this), options.statConcurrency);\n  this._statQueue.drain(this._onQueueDrain.bind(this));\n\n  this._state = {\n    aborted: false,\n    finalize: false,\n    finalizing: false,\n    finalized: false,\n    modulePiped: false\n  };\n\n  this._streams = [];\n};\n\ninherits(Archiver, Transform);\n\n/**\n * Internal logic for `abort`.\n *\n * @private\n * @return void\n */\nArchiver.prototype._abort = function() {\n  this._state.aborted = true;\n  this._queue.kill();\n  this._statQueue.kill();\n\n  if (this._queue.idle()) {\n    this._shutdown();\n  }\n};\n\n/**\n * Internal helper for appending files.\n *\n * @private\n * @param  {String} filepath The source filepath.\n * @param  {EntryData} data The entry data.\n * @return void\n */\nArchiver.prototype._append = function(filepath, data) {\n  data = data || {};\n\n  var task = {\n    source: null,\n    filepath: filepath\n  };\n\n  if (!data.name) {\n    data.name = filepath;\n  }\n\n  data.sourcePath = filepath;\n  task.data = data;\n  this._entriesCount++;\n\n  if (data.stats && data.stats instanceof fs.Stats) {\n    task = this._updateQueueTaskWithStats(task, data.stats);\n    if (task) {\n      if (data.stats.size) {\n        this._fsEntriesTotalBytes += data.stats.size;\n      }\n\n      this._queue.push(task);\n    }\n  } else {\n    this._statQueue.push(task);\n  }\n};\n\n/**\n * Internal logic for `finalize`.\n *\n * @private\n * @return void\n */\nArchiver.prototype._finalize = function() {\n  if (this._state.finalizing || this._state.finalized || this._state.aborted) {\n    return;\n  }\n\n  this._state.finalizing = true;\n\n  this._moduleFinalize();\n\n  this._state.finalizing = false;\n  this._state.finalized = true;\n};\n\n/**\n * Checks the various state variables to determine if we can `finalize`.\n *\n * @private\n * @return {Boolean}\n */\nArchiver.prototype._maybeFinalize = function() {\n  if (this._state.finalizing || this._state.finalized || this._state.aborted) {\n    return false;\n  }\n\n  if (this._state.finalize && this._pending === 0 && this._queue.idle() && this._statQueue.idle()) {\n    this._finalize();\n    return true;\n  }\n\n  return false;\n};\n\n/**\n * Appends an entry to the module.\n *\n * @private\n * @fires  Archiver#entry\n * @param  {(Buffer|Stream)} source\n * @param  {EntryData} data\n * @param  {Function} callback\n * @return void\n */\nArchiver.prototype._moduleAppend = function(source, data, callback) {\n  if (this._state.aborted) {\n    callback();\n    return;\n  }\n\n  this._module.append(source, data, function(err) {\n    this._task = null;\n\n    if (this._state.aborted) {\n      this._shutdown();\n      return;\n    }\n\n    if (err) {\n      this.emit('error', err);\n      setImmediate(callback);\n      return;\n    }\n\n    /**\n     * Fires when the entry's input has been processed and appended to the archive.\n     *\n     * @event Archiver#entry\n     * @type {EntryData}\n     */\n    this.emit('entry', data);\n    this._entriesProcessedCount++;\n\n    if (data.stats && data.stats.size) {\n      this._fsEntriesProcessedBytes += data.stats.size;\n    }\n\n    /**\n     * @event Archiver#progress\n     * @type {ProgressData}\n     */\n    this.emit('progress', {\n      entries: {\n        total: this._entriesCount,\n        processed: this._entriesProcessedCount\n      },\n      fs: {\n        totalBytes: this._fsEntriesTotalBytes,\n        processedBytes: this._fsEntriesProcessedBytes\n      }\n    });\n\n    setImmediate(callback);\n  }.bind(this));\n};\n\n/**\n * Finalizes the module.\n *\n * @private\n * @return void\n */\nArchiver.prototype._moduleFinalize = function() {\n  if (typeof this._module.finalize === 'function') {\n    this._module.finalize();\n  } else if (typeof this._module.end === 'function') {\n    this._module.end();\n  } else {\n    this.emit('error', new ArchiverError('NOENDMETHOD'));\n  }\n};\n\n/**\n * Pipes the module to our internal stream with error bubbling.\n *\n * @private\n * @return void\n */\nArchiver.prototype._modulePipe = function() {\n  this._module.on('error', this._onModuleError.bind(this));\n  this._module.pipe(this);\n  this._state.modulePiped = true;\n};\n\n/**\n * Determines if the current module supports a defined feature.\n *\n * @private\n * @param  {String} key\n * @return {Boolean}\n */\nArchiver.prototype._moduleSupports = function(key) {\n  if (!this._module.supports || !this._module.supports[key]) {\n    return false;\n  }\n\n  return this._module.supports[key];\n};\n\n/**\n * Unpipes the module from our internal stream.\n *\n * @private\n * @return void\n */\nArchiver.prototype._moduleUnpipe = function() {\n  this._module.unpipe(this);\n  this._state.modulePiped = false;\n};\n\n/**\n * Normalizes entry data with fallbacks for key properties.\n *\n * @private\n * @param  {Object} data\n * @param  {fs.Stats} stats\n * @return {Object}\n */\nArchiver.prototype._normalizeEntryData = function(data, stats) {\n  data = util.defaults(data, {\n    type: 'file',\n    name: null,\n    date: null,\n    mode: null,\n    prefix: null,\n    sourcePath: null,\n    stats: false\n  });\n\n  if (stats && data.stats === false) {\n    data.stats = stats;\n  }\n\n  var isDir = data.type === 'directory';\n\n  if (data.name) {\n    if (typeof data.prefix === 'string' && '' !== data.prefix) {\n      data.name = data.prefix + '/' + data.name;\n      data.prefix = null;\n    }\n\n    data.name = util.sanitizePath(data.name);\n\n    if (data.type !== 'symlink' && data.name.slice(-1) === '/') {\n      isDir = true;\n      data.type = 'directory';\n    } else if (isDir) {\n      data.name += '/';\n    }\n  }\n\n  // 511 === 0777; 493 === 0755; 438 === 0666; 420 === 0644\n  if (typeof data.mode === 'number') {\n    if (win32) {\n      data.mode &= 511;\n    } else {\n      data.mode &= 4095\n    }\n  } else if (data.stats && data.mode === null) {\n    if (win32) {\n      data.mode = data.stats.mode & 511;\n    } else {\n      data.mode = data.stats.mode & 4095;\n    }\n\n    // stat isn't reliable on windows; force 0755 for dir\n    if (win32 && isDir) {\n      data.mode = 493;\n    }\n  } else if (data.mode === null) {\n    data.mode = isDir ? 493 : 420;\n  }\n\n  if (data.stats && data.date === null) {\n    data.date = data.stats.mtime;\n  } else {\n    data.date = util.dateify(data.date);\n  }\n\n  return data;\n};\n\n/**\n * Error listener that re-emits error on to our internal stream.\n *\n * @private\n * @param  {Error} err\n * @return void\n */\nArchiver.prototype._onModuleError = function(err) {\n  /**\n   * @event Archiver#error\n   * @type {ErrorData}\n   */\n  this.emit('error', err);\n};\n\n/**\n * Checks the various state variables after queue has drained to determine if\n * we need to `finalize`.\n *\n * @private\n * @return void\n */\nArchiver.prototype._onQueueDrain = function() {\n  if (this._state.finalizing || this._state.finalized || this._state.aborted) {\n    return;\n  }\n\n  if (this._state.finalize && this._pending === 0 && this._queue.idle() && this._statQueue.idle()) {\n    this._finalize();\n  }\n};\n\n/**\n * Appends each queue task to the module.\n *\n * @private\n * @param  {Object} task\n * @param  {Function} callback\n * @return void\n */\nArchiver.prototype._onQueueTask = function(task, callback) {\n  var fullCallback = () => {\n    if(task.data.callback) {\n      task.data.callback();\n    }\n    callback();\n  }\n\n  if (this._state.finalizing || this._state.finalized || this._state.aborted) {\n    fullCallback();\n    return;\n  }\n\n  this._task = task;\n  this._moduleAppend(task.source, task.data, fullCallback);\n};\n\n/**\n * Performs a file stat and reinjects the task back into the queue.\n *\n * @private\n * @param  {Object} task\n * @param  {Function} callback\n * @return void\n */\nArchiver.prototype._onStatQueueTask = function(task, callback) {\n  if (this._state.finalizing || this._state.finalized || this._state.aborted) {\n    callback();\n    return;\n  }\n\n  fs.lstat(task.filepath, function(err, stats) {\n    if (this._state.aborted) {\n      setImmediate(callback);\n      return;\n    }\n\n    if (err) {\n      this._entriesCount--;\n\n      /**\n       * @event Archiver#warning\n       * @type {ErrorData}\n       */\n      this.emit('warning', err);\n      setImmediate(callback);\n      return;\n    }\n\n    task = this._updateQueueTaskWithStats(task, stats);\n\n    if (task) {\n      if (stats.size) {\n        this._fsEntriesTotalBytes += stats.size;\n      }\n\n      this._queue.push(task);\n    }\n\n    setImmediate(callback);\n  }.bind(this));\n};\n\n/**\n * Unpipes the module and ends our internal stream.\n *\n * @private\n * @return void\n */\nArchiver.prototype._shutdown = function() {\n  this._moduleUnpipe();\n  this.end();\n};\n\n/**\n * Tracks the bytes emitted by our internal stream.\n *\n * @private\n * @param  {Buffer} chunk\n * @param  {String} encoding\n * @param  {Function} callback\n * @return void\n */\nArchiver.prototype._transform = function(chunk, encoding, callback) {\n  if (chunk) {\n    this._pointer += chunk.length;\n  }\n\n  callback(null, chunk);\n};\n\n/**\n * Updates and normalizes a queue task using stats data.\n *\n * @private\n * @param  {Object} task\n * @param  {fs.Stats} stats\n * @return {Object}\n */\nArchiver.prototype._updateQueueTaskWithStats = function(task, stats) {\n  if (stats.isFile()) {\n    task.data.type = 'file';\n    task.data.sourceType = 'stream';\n    task.source = util.lazyReadStream(task.filepath);\n  } else if (stats.isDirectory() && this._moduleSupports('directory')) {\n    task.data.name = util.trailingSlashIt(task.data.name);\n    task.data.type = 'directory';\n    task.data.sourcePath = util.trailingSlashIt(task.filepath);\n    task.data.sourceType = 'buffer';\n    task.source = Buffer.concat([]);\n  } else if (stats.isSymbolicLink() && this._moduleSupports('symlink')) {\n    var linkPath = fs.readlinkSync(task.filepath);\n    var dirName = path.dirname(task.filepath);\n    task.data.type = 'symlink';\n    task.data.linkname = path.relative(dirName, path.resolve(dirName, linkPath));\n    task.data.sourceType = 'buffer';\n    task.source = Buffer.concat([]);\n  } else {\n    if (stats.isDirectory()) {\n      this.emit('warning', new ArchiverError('DIRECTORYNOTSUPPORTED', task.data));\n    } else if (stats.isSymbolicLink()) {\n      this.emit('warning', new ArchiverError('SYMLINKNOTSUPPORTED', task.data));\n    } else {\n      this.emit('warning', new ArchiverError('ENTRYNOTSUPPORTED', task.data));\n    }\n\n    return null;\n  }\n\n  task.data = this._normalizeEntryData(task.data, stats);\n\n  return task;\n};\n\n/**\n * Aborts the archiving process, taking a best-effort approach, by:\n *\n * - removing any pending queue tasks\n * - allowing any active queue workers to finish\n * - detaching internal module pipes\n * - ending both sides of the Transform stream\n *\n * It will NOT drain any remaining sources.\n *\n * @return {this}\n */\nArchiver.prototype.abort = function() {\n  if (this._state.aborted || this._state.finalized) {\n    return this;\n  }\n\n  this._abort();\n\n  return this;\n};\n\n/**\n * Appends an input source (text string, buffer, or stream) to the instance.\n *\n * When the instance has received, processed, and emitted the input, the `entry`\n * event is fired.\n *\n * @fires  Archiver#entry\n * @param  {(Buffer|Stream|String)} source The input source.\n * @param  {EntryData} data See also {@link ZipEntryData} and {@link TarEntryData}.\n * @return {this}\n */\nArchiver.prototype.append = function(source, data) {\n  if (this._state.finalize || this._state.aborted) {\n    this.emit('error', new ArchiverError('QUEUECLOSED'));\n    return this;\n  }\n\n  data = this._normalizeEntryData(data);\n\n  if (typeof data.name !== 'string' || data.name.length === 0) {\n    this.emit('error', new ArchiverError('ENTRYNAMEREQUIRED'));\n    return this;\n  }\n\n  if (data.type === 'directory' && !this._moduleSupports('directory')) {\n    this.emit('error', new ArchiverError('DIRECTORYNOTSUPPORTED', { name: data.name }));\n    return this;\n  }\n\n  source = util.normalizeInputSource(source);\n\n  if (Buffer.isBuffer(source)) {\n    data.sourceType = 'buffer';\n  } else if (util.isStream(source)) {\n    data.sourceType = 'stream';\n  } else {\n    this.emit('error', new ArchiverError('INPUTSTEAMBUFFERREQUIRED', { name: data.name }));\n    return this;\n  }\n\n  this._entriesCount++;\n  this._queue.push({\n    data: data,\n    source: source\n  });\n\n  return this;\n};\n\n/**\n * Appends a directory and its files, recursively, given its dirpath.\n *\n * @param  {String} dirpath The source directory path.\n * @param  {String} destpath The destination path within the archive.\n * @param  {(EntryData|Function)} data See also [ZipEntryData]{@link ZipEntryData} and\n * [TarEntryData]{@link TarEntryData}.\n * @return {this}\n */\nArchiver.prototype.directory = function(dirpath, destpath, data) {\n  if (this._state.finalize || this._state.aborted) {\n    this.emit('error', new ArchiverError('QUEUECLOSED'));\n    return this;\n  }\n\n  if (typeof dirpath !== 'string' || dirpath.length === 0) {\n    this.emit('error', new ArchiverError('DIRECTORYDIRPATHREQUIRED'));\n    return this;\n  }\n\n  this._pending++;\n\n  if (destpath === false) {\n    destpath = '';\n  } else if (typeof destpath !== 'string'){\n    destpath = dirpath;\n  }\n\n  var dataFunction = false;\n  if (typeof data === 'function') {\n    dataFunction = data;\n    data = {};\n  } else if (typeof data !== 'object') {\n    data = {};\n  }\n\n  var globOptions = {\n    stat: true,\n    dot: true\n  };\n\n  function onGlobEnd() {\n    this._pending--;\n    this._maybeFinalize();\n  }\n\n  function onGlobError(err) {\n    this.emit('error', err);\n  }\n\n  function onGlobMatch(match){\n    globber.pause();\n\n    var ignoreMatch = false;\n    var entryData = Object.assign({}, data);\n    entryData.name = match.relative;\n    entryData.prefix = destpath;\n    entryData.stats = match.stat;\n    entryData.callback = globber.resume.bind(globber);\n\n    try {\n      if (dataFunction) {\n        entryData = dataFunction(entryData);\n\n        if (entryData === false) {\n          ignoreMatch = true;\n        } else if (typeof entryData !== 'object') {\n          throw new ArchiverError('DIRECTORYFUNCTIONINVALIDDATA', { dirpath: dirpath });\n        }\n      }\n    } catch(e) {\n      this.emit('error', e);\n      return;\n    }\n\n    if (ignoreMatch) {\n      globber.resume();\n      return;\n    }\n\n    this._append(match.absolute, entryData);\n  }\n\n  var globber = glob(dirpath, globOptions);\n  globber.on('error', onGlobError.bind(this));\n  globber.on('match', onGlobMatch.bind(this));\n  globber.on('end', onGlobEnd.bind(this));\n\n  return this;\n};\n\n/**\n * Appends a file given its filepath using a\n * [lazystream]{@link https://github.com/jpommerening/node-lazystream} wrapper to\n * prevent issues with open file limits.\n *\n * When the instance has received, processed, and emitted the file, the `entry`\n * event is fired.\n *\n * @param  {String} filepath The source filepath.\n * @param  {EntryData} data See also [ZipEntryData]{@link ZipEntryData} and\n * [TarEntryData]{@link TarEntryData}.\n * @return {this}\n */\nArchiver.prototype.file = function(filepath, data) {\n  if (this._state.finalize || this._state.aborted) {\n    this.emit('error', new ArchiverError('QUEUECLOSED'));\n    return this;\n  }\n\n  if (typeof filepath !== 'string' || filepath.length === 0) {\n    this.emit('error', new ArchiverError('FILEFILEPATHREQUIRED'));\n    return this;\n  }\n\n  this._append(filepath, data);\n\n  return this;\n};\n\n/**\n * Appends multiple files that match a glob pattern.\n *\n * @param  {String} pattern The [glob pattern]{@link https://github.com/isaacs/minimatch} to match.\n * @param  {Object} options See [node-readdir-glob]{@link https://github.com/yqnn/node-readdir-glob#options}.\n * @param  {EntryData} data See also [ZipEntryData]{@link ZipEntryData} and\n * [TarEntryData]{@link TarEntryData}.\n * @return {this}\n */\nArchiver.prototype.glob = function(pattern, options, data) {\n  this._pending++;\n\n  options = util.defaults(options, {\n    stat: true,\n    pattern: pattern\n  });\n\n  function onGlobEnd() {\n    this._pending--;\n    this._maybeFinalize();\n  }\n\n  function onGlobError(err) {\n    this.emit('error', err);\n  }\n\n  function onGlobMatch(match){\n    globber.pause();\n    var entryData = Object.assign({}, data);\n    entryData.callback = globber.resume.bind(globber);\n    entryData.stats = match.stat;\n    entryData.name = match.relative;\n\n    this._append(match.absolute, entryData);\n  }\n\n  var globber = glob(options.cwd || '.', options);\n  globber.on('error', onGlobError.bind(this));\n  globber.on('match', onGlobMatch.bind(this));\n  globber.on('end', onGlobEnd.bind(this));\n\n  return this;\n};\n\n/**\n * Finalizes the instance and prevents further appending to the archive\n * structure (queue will continue til drained).\n *\n * The `end`, `close` or `finish` events on the destination stream may fire\n * right after calling this method so you should set listeners beforehand to\n * properly detect stream completion.\n *\n * @return {Promise}\n */\nArchiver.prototype.finalize = function() {\n  if (this._state.aborted) {\n    var abortedError = new ArchiverError('ABORTED');\n    this.emit('error', abortedError);\n    return Promise.reject(abortedError);\n  }\n\n  if (this._state.finalize) {\n    var finalizingError = new ArchiverError('FINALIZING');\n    this.emit('error', finalizingError);\n    return Promise.reject(finalizingError);\n  }\n\n  this._state.finalize = true;\n\n  if (this._pending === 0 && this._queue.idle() && this._statQueue.idle()) {\n    this._finalize();\n  }\n\n  var self = this;\n\n  return new Promise(function(resolve, reject) {\n    var errored;\n\n    self._module.on('end', function() {\n      if (!errored) {\n        resolve();\n      }\n    })\n\n    self._module.on('error', function(err) {\n      errored = true;\n      reject(err);\n    })\n  })\n};\n\n/**\n * Sets the module format name used for archiving.\n *\n * @param {String} format The name of the format.\n * @return {this}\n */\nArchiver.prototype.setFormat = function(format) {\n  if (this._format) {\n    this.emit('error', new ArchiverError('FORMATSET'));\n    return this;\n  }\n\n  this._format = format;\n\n  return this;\n};\n\n/**\n * Sets the module used for archiving.\n *\n * @param {Function} module The function for archiver to interact with.\n * @return {this}\n */\nArchiver.prototype.setModule = function(module) {\n  if (this._state.aborted) {\n    this.emit('error', new ArchiverError('ABORTED'));\n    return this;\n  }\n\n  if (this._state.module) {\n    this.emit('error', new ArchiverError('MODULESET'));\n    return this;\n  }\n\n  this._module = module;\n  this._modulePipe();\n\n  return this;\n};\n\n/**\n * Appends a symlink to the instance.\n *\n * This does NOT interact with filesystem and is used for programmatically creating symlinks.\n *\n * @param  {String} filepath The symlink path (within archive).\n * @param  {String} target The target path (within archive).\n * @param  {Number} mode Sets the entry permissions.\n * @return {this}\n */\nArchiver.prototype.symlink = function(filepath, target, mode) {\n  if (this._state.finalize || this._state.aborted) {\n    this.emit('error', new ArchiverError('QUEUECLOSED'));\n    return this;\n  }\n\n  if (typeof filepath !== 'string' || filepath.length === 0) {\n    this.emit('error', new ArchiverError('SYMLINKFILEPATHREQUIRED'));\n    return this;\n  }\n\n  if (typeof target !== 'string' || target.length === 0) {\n    this.emit('error', new ArchiverError('SYMLINKTARGETREQUIRED', { filepath: filepath }));\n    return this;\n  }\n\n  if (!this._moduleSupports('symlink')) {\n    this.emit('error', new ArchiverError('SYMLINKNOTSUPPORTED', { filepath: filepath }));\n    return this;\n  }\n\n  var data = {};\n  data.type = 'symlink';\n  data.name = filepath.replace(/\\\\/g, '/');\n  data.linkname = target.replace(/\\\\/g, '/');\n  data.sourceType = 'buffer';\n\n  if (typeof mode === \"number\") {\n    data.mode = mode;\n  }\n\n  this._entriesCount++;\n  this._queue.push({\n    data: data,\n    source: Buffer.concat([])\n  });\n\n  return this;\n};\n\n/**\n * Returns the current length (in bytes) that has been emitted.\n *\n * @return {Number}\n */\nArchiver.prototype.pointer = function() {\n  return this._pointer;\n};\n\n/**\n * Middleware-like helper that has yet to be fully implemented.\n *\n * @private\n * @param  {Function} plugin\n * @return {this}\n */\nArchiver.prototype.use = function(plugin) {\n  this._streams.push(plugin);\n  return this;\n};\n\nmodule.exports = Archiver;\n\n/**\n * @typedef {Object} CoreOptions\n * @global\n * @property {Number} [statConcurrency=4] Sets the number of workers used to\n * process the internal fs stat queue.\n */\n\n/**\n * @typedef {Object} TransformOptions\n * @property {Boolean} [allowHalfOpen=true] If set to false, then the stream\n * will automatically end the readable side when the writable side ends and vice\n * versa.\n * @property {Boolean} [readableObjectMode=false] Sets objectMode for readable\n * side of the stream. Has no effect if objectMode is true.\n * @property {Boolean} [writableObjectMode=false] Sets objectMode for writable\n * side of the stream. Has no effect if objectMode is true.\n * @property {Boolean} [decodeStrings=true] Whether or not to decode strings\n * into Buffers before passing them to _write(). `Writable`\n * @property {String} [encoding=NULL] If specified, then buffers will be decoded\n * to strings using the specified encoding. `Readable`\n * @property {Number} [highWaterMark=16kb] The maximum number of bytes to store\n * in the internal buffer before ceasing to read from the underlying resource.\n * `Readable` `Writable`\n * @property {Boolean} [objectMode=false] Whether this stream should behave as a\n * stream of objects. Meaning that stream.read(n) returns a single value instead\n * of a Buffer of size n. `Readable` `Writable`\n */\n\n/**\n * @typedef {Object} EntryData\n * @property {String} name Sets the entry name including internal path.\n * @property {(String|Date)} [date=NOW()] Sets the entry date.\n * @property {Number} [mode=D:0755/F:0644] Sets the entry permissions.\n * @property {String} [prefix] Sets a path prefix for the entry name. Useful\n * when working with methods like `directory` or `glob`.\n * @property {fs.Stats} [stats] Sets the fs stat data for this entry allowing\n * for reduction of fs stat calls when stat data is already known.\n */\n\n/**\n * @typedef {Object} ErrorData\n * @property {String} message The message of the error.\n * @property {String} code The error code assigned to this error.\n * @property {String} data Additional data provided for reporting or debugging (where available).\n */\n\n/**\n * @typedef {Object} ProgressData\n * @property {Object} entries\n * @property {Number} entries.total Number of entries that have been appended.\n * @property {Number} entries.processed Number of entries that have been processed.\n * @property {Object} fs\n * @property {Number} fs.totalBytes Number of bytes that have been appended. Calculated asynchronously and might not be accurate: it growth while entries are added. (based on fs.Stats)\n * @property {Number} fs.processedBytes Number of bytes that have been processed. (based on fs.Stats)\n */\n","/**\n * Archiver Core\n *\n * @ignore\n * @license [MIT]{@link https://github.com/archiverjs/node-archiver/blob/master/LICENSE}\n * @copyright (c) 2012-2014 Chris Talkington, contributors.\n */\n\nvar util = require('util');\n\nconst ERROR_CODES = {\n  'ABORTED': 'archive was aborted',\n  'DIRECTORYDIRPATHREQUIRED': 'diretory dirpath argument must be a non-empty string value',\n  'DIRECTORYFUNCTIONINVALIDDATA': 'invalid data returned by directory custom data function',\n  'ENTRYNAMEREQUIRED': 'entry name must be a non-empty string value',\n  'FILEFILEPATHREQUIRED': 'file filepath argument must be a non-empty string value',\n  'FINALIZING': 'archive already finalizing',\n  'QUEUECLOSED': 'queue closed',\n  'NOENDMETHOD': 'no suitable finalize/end method defined by module',\n  'DIRECTORYNOTSUPPORTED': 'support for directory entries not defined by module',\n  'FORMATSET': 'archive format already set',\n  'INPUTSTEAMBUFFERREQUIRED': 'input source must be valid Stream or Buffer instance',\n  'MODULESET': 'module already set',\n  'SYMLINKNOTSUPPORTED': 'support for symlink entries not defined by module',\n  'SYMLINKFILEPATHREQUIRED': 'symlink filepath argument must be a non-empty string value',\n  'SYMLINKTARGETREQUIRED': 'symlink target argument must be a non-empty string value',\n  'ENTRYNOTSUPPORTED': 'entry not supported'\n};\n\nfunction ArchiverError(code, data) {\n  Error.captureStackTrace(this, this.constructor);\n  //this.name = this.constructor.name;\n  this.message = ERROR_CODES[code] || code;\n  this.code = code;\n  this.data = data;\n}\n\nutil.inherits(ArchiverError, Error);\n\nexports = module.exports = ArchiverError;","/**\n * JSON Format Plugin\n *\n * @module plugins/json\n * @license [MIT]{@link https://github.com/archiverjs/node-archiver/blob/master/LICENSE}\n * @copyright (c) 2012-2014 Chris Talkington, contributors.\n */\nvar inherits = require('util').inherits;\nvar Transform = require('readable-stream').Transform;\n\nvar crc32 = require('buffer-crc32');\nvar util = require('archiver-utils');\n\n/**\n * @constructor\n * @param {(JsonOptions|TransformOptions)} options\n */\nvar Json = function(options) {\n  if (!(this instanceof Json)) {\n    return new Json(options);\n  }\n\n  options = this.options = util.defaults(options, {});\n\n  Transform.call(this, options);\n\n  this.supports = {\n    directory: true,\n    symlink: true\n  };\n\n  this.files = [];\n};\n\ninherits(Json, Transform);\n\n/**\n * [_transform description]\n *\n * @private\n * @param  {Buffer}   chunk\n * @param  {String}   encoding\n * @param  {Function} callback\n * @return void\n */\nJson.prototype._transform = function(chunk, encoding, callback) {\n  callback(null, chunk);\n};\n\n/**\n * [_writeStringified description]\n *\n * @private\n * @return void\n */\nJson.prototype._writeStringified = function() {\n  var fileString = JSON.stringify(this.files);\n  this.write(fileString);\n};\n\n/**\n * [append description]\n *\n * @param  {(Buffer|Stream)}   source\n * @param  {EntryData}   data\n * @param  {Function} callback\n * @return void\n */\nJson.prototype.append = function(source, data, callback) {\n  var self = this;\n\n  data.crc32 = 0;\n\n  function onend(err, sourceBuffer) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    data.size = sourceBuffer.length || 0;\n    data.crc32 = crc32.unsigned(sourceBuffer);\n\n    self.files.push(data);\n\n    callback(null, data);\n  }\n\n  if (data.sourceType === 'buffer') {\n    onend(null, source);\n  } else if (data.sourceType === 'stream') {\n    util.collectStream(source, onend);\n  }\n};\n\n/**\n * [finalize description]\n *\n * @return void\n */\nJson.prototype.finalize = function() {\n  this._writeStringified();\n  this.end();\n};\n\nmodule.exports = Json;\n\n/**\n * @typedef {Object} JsonOptions\n * @global\n */\n","/**\n * TAR Format Plugin\n *\n * @module plugins/tar\n * @license [MIT]{@link https://github.com/archiverjs/node-archiver/blob/master/LICENSE}\n * @copyright (c) 2012-2014 Chris Talkington, contributors.\n */\nvar zlib = require('zlib');\n\nvar engine = require('tar-stream');\nvar util = require('archiver-utils');\n\n/**\n * @constructor\n * @param {TarOptions} options\n */\nvar Tar = function(options) {\n  if (!(this instanceof Tar)) {\n    return new Tar(options);\n  }\n\n  options = this.options = util.defaults(options, {\n    gzip: false\n  });\n\n  if (typeof options.gzipOptions !== 'object') {\n    options.gzipOptions = {};\n  }\n\n  this.supports = {\n    directory: true,\n    symlink: true\n  };\n\n  this.engine = engine.pack(options);\n  this.compressor = false;\n\n  if (options.gzip) {\n    this.compressor = zlib.createGzip(options.gzipOptions);\n    this.compressor.on('error', this._onCompressorError.bind(this));\n  }\n};\n\n/**\n * [_onCompressorError description]\n *\n * @private\n * @param  {Error} err\n * @return void\n */\nTar.prototype._onCompressorError = function(err) {\n  this.engine.emit('error', err);\n};\n\n/**\n * [append description]\n *\n * @param  {(Buffer|Stream)} source\n * @param  {TarEntryData} data\n * @param  {Function} callback\n * @return void\n */\nTar.prototype.append = function(source, data, callback) {\n  var self = this;\n\n  data.mtime = data.date;\n\n  function append(err, sourceBuffer) {\n    if (err) {\n      callback(err);\n      return;\n    }\n\n    self.engine.entry(data, sourceBuffer, function(err) {\n      callback(err, data);\n    });\n  }\n\n  if (data.sourceType === 'buffer') {\n    append(null, source);\n  } else if (data.sourceType === 'stream' && data.stats) {\n    data.size = data.stats.size;\n\n    var entry = self.engine.entry(data, function(err) {\n      callback(err, data);\n    });\n\n    source.pipe(entry);\n  } else if (data.sourceType === 'stream') {\n    util.collectStream(source, append);\n  }\n};\n\n/**\n * [finalize description]\n *\n * @return void\n */\nTar.prototype.finalize = function() {\n  this.engine.finalize();\n};\n\n/**\n * [on description]\n *\n * @return this.engine\n */\nTar.prototype.on = function() {\n  return this.engine.on.apply(this.engine, arguments);\n};\n\n/**\n * [pipe description]\n *\n * @param  {String} destination\n * @param  {Object} options\n * @return this.engine\n */\nTar.prototype.pipe = function(destination, options) {\n  if (this.compressor) {\n    return this.engine.pipe.apply(this.engine, [this.compressor]).pipe(destination, options);\n  } else {\n    return this.engine.pipe.apply(this.engine, arguments);\n  }\n};\n\n/**\n * [unpipe description]\n *\n * @return this.engine\n */\nTar.prototype.unpipe = function() {\n  if (this.compressor) {\n    return this.compressor.unpipe.apply(this.compressor, arguments);\n  } else {\n    return this.engine.unpipe.apply(this.engine, arguments);\n  }\n};\n\nmodule.exports = Tar;\n\n/**\n * @typedef {Object} TarOptions\n * @global\n * @property {Boolean} [gzip=false] Compress the tar archive using gzip.\n * @property {Object} [gzipOptions] Passed to [zlib]{@link https://nodejs.org/api/zlib.html#zlib_class_options}\n * to control compression.\n * @property {*} [*] See [tar-stream]{@link https://github.com/mafintosh/tar-stream} documentation for additional properties.\n */\n\n/**\n * @typedef {Object} TarEntryData\n * @global\n * @property {String} name Sets the entry name including internal path.\n * @property {(String|Date)} [date=NOW()] Sets the entry date.\n * @property {Number} [mode=D:0755/F:0644] Sets the entry permissions.\n * @property {String} [prefix] Sets a path prefix for the entry name. Useful\n * when working with methods like `directory` or `glob`.\n * @property {fs.Stats} [stats] Sets the fs stat data for this entry allowing\n * for reduction of fs stat calls when stat data is already known.\n */\n\n/**\n * TarStream Module\n * @external TarStream\n * @see {@link https://github.com/mafintosh/tar-stream}\n */\n","/**\n * ZIP Format Plugin\n *\n * @module plugins/zip\n * @license [MIT]{@link https://github.com/archiverjs/node-archiver/blob/master/LICENSE}\n * @copyright (c) 2012-2014 Chris Talkington, contributors.\n */\nvar engine = require('zip-stream');\nvar util = require('archiver-utils');\n\n/**\n * @constructor\n * @param {ZipOptions} [options]\n * @param {String} [options.comment] Sets the zip archive comment.\n * @param {Boolean} [options.forceLocalTime=false] Forces the archive to contain local file times instead of UTC.\n * @param {Boolean} [options.forceZip64=false] Forces the archive to contain ZIP64 headers.\n * @param {Boolean} [options.namePrependSlash=false] Prepends a forward slash to archive file paths.\n * @param {Boolean} [options.store=false] Sets the compression method to STORE.\n * @param {Object} [options.zlib] Passed to [zlib]{@link https://nodejs.org/api/zlib.html#zlib_class_options}\n */\nvar Zip = function(options) {\n  if (!(this instanceof Zip)) {\n    return new Zip(options);\n  }\n\n  options = this.options = util.defaults(options, {\n    comment: '',\n    forceUTC: false,\n    namePrependSlash: false,\n    store: false\n  });\n\n  this.supports = {\n    directory: true,\n    symlink: true\n  };\n\n  this.engine = new engine(options);\n};\n\n/**\n * @param  {(Buffer|Stream)} source\n * @param  {ZipEntryData} data\n * @param  {String} data.name Sets the entry name including internal path.\n * @param  {(String|Date)} [data.date=NOW()] Sets the entry date.\n * @param  {Number} [data.mode=D:0755/F:0644] Sets the entry permissions.\n * @param  {String} [data.prefix] Sets a path prefix for the entry name. Useful\n * when working with methods like `directory` or `glob`.\n * @param  {fs.Stats} [data.stats] Sets the fs stat data for this entry allowing\n * for reduction of fs stat calls when stat data is already known.\n * @param  {Boolean} [data.store=ZipOptions.store] Sets the compression method to STORE.\n * @param  {Function} callback\n * @return void\n */\nZip.prototype.append = function(source, data, callback) {\n  this.engine.entry(source, data, callback);\n};\n\n/**\n * @return void\n */\nZip.prototype.finalize = function() {\n  this.engine.finalize();\n};\n\n/**\n * @return this.engine\n */\nZip.prototype.on = function() {\n  return this.engine.on.apply(this.engine, arguments);\n};\n\n/**\n * @return this.engine\n */\nZip.prototype.pipe = function() {\n  return this.engine.pipe.apply(this.engine, arguments);\n};\n\n/**\n * @return this.engine\n */\nZip.prototype.unpipe = function() {\n  return this.engine.unpipe.apply(this.engine, arguments);\n};\n\nmodule.exports = Zip;\n\n/**\n * @typedef {Object} ZipOptions\n * @global\n * @property {String} [comment] Sets the zip archive comment.\n * @property {Boolean} [forceLocalTime=false] Forces the archive to contain local file times instead of UTC.\n * @property {Boolean} [forceZip64=false] Forces the archive to contain ZIP64 headers.\n * @prpperty {Boolean} [namePrependSlash=false] Prepends a forward slash to archive file paths.\n * @property {Boolean} [store=false] Sets the compression method to STORE.\n * @property {Object} [zlib] Passed to [zlib]{@link https://nodejs.org/api/zlib.html#zlib_class_options}\n * to control compression.\n * @property {*} [*] See [zip-stream]{@link https://archiverjs.com/zip-stream/ZipStream.html} documentation for current list of properties.\n */\n\n/**\n * @typedef {Object} ZipEntryData\n * @global\n * @property {String} name Sets the entry name including internal path.\n * @property {(String|Date)} [date=NOW()] Sets the entry date.\n * @property {Number} [mode=D:0755/F:0644] Sets the entry permissions.\n * @property {Boolean} [namePrependSlash=ZipOptions.namePrependSlash] Prepends a forward slash to archive file paths.\n * @property {String} [prefix] Sets a path prefix for the entry name. Useful\n * when working with methods like `directory` or `glob`.\n * @property {fs.Stats} [stats] Sets the fs stat data for this entry allowing\n * for reduction of fs stat calls when stat data is already known.\n * @property {Boolean} [store=ZipOptions.store] Sets the compression method to STORE.\n */\n\n/**\n * ZipStream Module\n * @external ZipStream\n * @see {@link https://www.archiverjs.com/zip-stream/ZipStream.html}\n */\n","(function (global, factory) {\n    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n    typeof define === 'function' && define.amd ? define(['exports'], factory) :\n    (global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.async = {}));\n})(this, (function (exports) { 'use strict';\n\n    /**\n     * Creates a continuation function with some arguments already applied.\n     *\n     * Useful as a shorthand when combined with other control flow functions. Any\n     * arguments passed to the returned function are added to the arguments\n     * originally passed to apply.\n     *\n     * @name apply\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @category Util\n     * @param {Function} fn - The function you want to eventually apply all\n     * arguments to. Invokes with (arguments...).\n     * @param {...*} arguments... - Any number of arguments to automatically apply\n     * when the continuation is called.\n     * @returns {Function} the partially-applied function\n     * @example\n     *\n     * // using apply\n     * async.parallel([\n     *     async.apply(fs.writeFile, 'testfile1', 'test1'),\n     *     async.apply(fs.writeFile, 'testfile2', 'test2')\n     * ]);\n     *\n     *\n     * // the same process without using apply\n     * async.parallel([\n     *     function(callback) {\n     *         fs.writeFile('testfile1', 'test1', callback);\n     *     },\n     *     function(callback) {\n     *         fs.writeFile('testfile2', 'test2', callback);\n     *     }\n     * ]);\n     *\n     * // It's possible to pass any number of additional arguments when calling the\n     * // continuation:\n     *\n     * node> var fn = async.apply(sys.puts, 'one');\n     * node> fn('two', 'three');\n     * one\n     * two\n     * three\n     */\n    function apply(fn, ...args) {\n        return (...callArgs) => fn(...args,...callArgs);\n    }\n\n    function initialParams (fn) {\n        return function (...args/*, callback*/) {\n            var callback = args.pop();\n            return fn.call(this, args, callback);\n        };\n    }\n\n    /* istanbul ignore file */\n\n    var hasQueueMicrotask = typeof queueMicrotask === 'function' && queueMicrotask;\n    var hasSetImmediate = typeof setImmediate === 'function' && setImmediate;\n    var hasNextTick = typeof process === 'object' && typeof process.nextTick === 'function';\n\n    function fallback(fn) {\n        setTimeout(fn, 0);\n    }\n\n    function wrap(defer) {\n        return (fn, ...args) => defer(() => fn(...args));\n    }\n\n    var _defer$1;\n\n    if (hasQueueMicrotask) {\n        _defer$1 = queueMicrotask;\n    } else if (hasSetImmediate) {\n        _defer$1 = setImmediate;\n    } else if (hasNextTick) {\n        _defer$1 = process.nextTick;\n    } else {\n        _defer$1 = fallback;\n    }\n\n    var setImmediate$1 = wrap(_defer$1);\n\n    /**\n     * Take a sync function and make it async, passing its return value to a\n     * callback. This is useful for plugging sync functions into a waterfall,\n     * series, or other async functions. Any arguments passed to the generated\n     * function will be passed to the wrapped function (except for the final\n     * callback argument). Errors thrown will be passed to the callback.\n     *\n     * If the function passed to `asyncify` returns a Promise, that promises's\n     * resolved/rejected state will be used to call the callback, rather than simply\n     * the synchronous return value.\n     *\n     * This also means you can asyncify ES2017 `async` functions.\n     *\n     * @name asyncify\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @alias wrapSync\n     * @category Util\n     * @param {Function} func - The synchronous function, or Promise-returning\n     * function to convert to an {@link AsyncFunction}.\n     * @returns {AsyncFunction} An asynchronous wrapper of the `func`. To be\n     * invoked with `(args..., callback)`.\n     * @example\n     *\n     * // passing a regular synchronous function\n     * async.waterfall([\n     *     async.apply(fs.readFile, filename, \"utf8\"),\n     *     async.asyncify(JSON.parse),\n     *     function (data, next) {\n     *         // data is the result of parsing the text.\n     *         // If there was a parsing error, it would have been caught.\n     *     }\n     * ], callback);\n     *\n     * // passing a function returning a promise\n     * async.waterfall([\n     *     async.apply(fs.readFile, filename, \"utf8\"),\n     *     async.asyncify(function (contents) {\n     *         return db.model.create(contents);\n     *     }),\n     *     function (model, next) {\n     *         // `model` is the instantiated model object.\n     *         // If there was an error, this function would be skipped.\n     *     }\n     * ], callback);\n     *\n     * // es2017 example, though `asyncify` is not needed if your JS environment\n     * // supports async functions out of the box\n     * var q = async.queue(async.asyncify(async function(file) {\n     *     var intermediateStep = await processFile(file);\n     *     return await somePromise(intermediateStep)\n     * }));\n     *\n     * q.push(files);\n     */\n    function asyncify(func) {\n        if (isAsync(func)) {\n            return function (...args/*, callback*/) {\n                const callback = args.pop();\n                const promise = func.apply(this, args);\n                return handlePromise(promise, callback)\n            }\n        }\n\n        return initialParams(function (args, callback) {\n            var result;\n            try {\n                result = func.apply(this, args);\n            } catch (e) {\n                return callback(e);\n            }\n            // if result is Promise object\n            if (result && typeof result.then === 'function') {\n                return handlePromise(result, callback)\n            } else {\n                callback(null, result);\n            }\n        });\n    }\n\n    function handlePromise(promise, callback) {\n        return promise.then(value => {\n            invokeCallback(callback, null, value);\n        }, err => {\n            invokeCallback(callback, err && (err instanceof Error || err.message) ? err : new Error(err));\n        });\n    }\n\n    function invokeCallback(callback, error, value) {\n        try {\n            callback(error, value);\n        } catch (err) {\n            setImmediate$1(e => { throw e }, err);\n        }\n    }\n\n    function isAsync(fn) {\n        return fn[Symbol.toStringTag] === 'AsyncFunction';\n    }\n\n    function isAsyncGenerator(fn) {\n        return fn[Symbol.toStringTag] === 'AsyncGenerator';\n    }\n\n    function isAsyncIterable(obj) {\n        return typeof obj[Symbol.asyncIterator] === 'function';\n    }\n\n    function wrapAsync(asyncFn) {\n        if (typeof asyncFn !== 'function') throw new Error('expected a function')\n        return isAsync(asyncFn) ? asyncify(asyncFn) : asyncFn;\n    }\n\n    // conditionally promisify a function.\n    // only return a promise if a callback is omitted\n    function awaitify (asyncFn, arity) {\n        if (!arity) arity = asyncFn.length;\n        if (!arity) throw new Error('arity is undefined')\n        function awaitable (...args) {\n            if (typeof args[arity - 1] === 'function') {\n                return asyncFn.apply(this, args)\n            }\n\n            return new Promise((resolve, reject) => {\n                args[arity - 1] = (err, ...cbArgs) => {\n                    if (err) return reject(err)\n                    resolve(cbArgs.length > 1 ? cbArgs : cbArgs[0]);\n                };\n                asyncFn.apply(this, args);\n            })\n        }\n\n        return awaitable\n    }\n\n    function applyEach$1 (eachfn) {\n        return function applyEach(fns, ...callArgs) {\n            const go = awaitify(function (callback) {\n                var that = this;\n                return eachfn(fns, (fn, cb) => {\n                    wrapAsync(fn).apply(that, callArgs.concat(cb));\n                }, callback);\n            });\n            return go;\n        };\n    }\n\n    function _asyncMap(eachfn, arr, iteratee, callback) {\n        arr = arr || [];\n        var results = [];\n        var counter = 0;\n        var _iteratee = wrapAsync(iteratee);\n\n        return eachfn(arr, (value, _, iterCb) => {\n            var index = counter++;\n            _iteratee(value, (err, v) => {\n                results[index] = v;\n                iterCb(err);\n            });\n        }, err => {\n            callback(err, results);\n        });\n    }\n\n    function isArrayLike(value) {\n        return value &&\n            typeof value.length === 'number' &&\n            value.length >= 0 &&\n            value.length % 1 === 0;\n    }\n\n    // A temporary value used to identify if the loop should be broken.\n    // See #1064, #1293\n    const breakLoop = {};\n\n    function once(fn) {\n        function wrapper (...args) {\n            if (fn === null) return;\n            var callFn = fn;\n            fn = null;\n            callFn.apply(this, args);\n        }\n        Object.assign(wrapper, fn);\n        return wrapper\n    }\n\n    function getIterator (coll) {\n        return coll[Symbol.iterator] && coll[Symbol.iterator]();\n    }\n\n    function createArrayIterator(coll) {\n        var i = -1;\n        var len = coll.length;\n        return function next() {\n            return ++i < len ? {value: coll[i], key: i} : null;\n        }\n    }\n\n    function createES2015Iterator(iterator) {\n        var i = -1;\n        return function next() {\n            var item = iterator.next();\n            if (item.done)\n                return null;\n            i++;\n            return {value: item.value, key: i};\n        }\n    }\n\n    function createObjectIterator(obj) {\n        var okeys = obj ? Object.keys(obj) : [];\n        var i = -1;\n        var len = okeys.length;\n        return function next() {\n            var key = okeys[++i];\n            if (key === '__proto__') {\n                return next();\n            }\n            return i < len ? {value: obj[key], key} : null;\n        };\n    }\n\n    function createIterator(coll) {\n        if (isArrayLike(coll)) {\n            return createArrayIterator(coll);\n        }\n\n        var iterator = getIterator(coll);\n        return iterator ? createES2015Iterator(iterator) : createObjectIterator(coll);\n    }\n\n    function onlyOnce(fn) {\n        return function (...args) {\n            if (fn === null) throw new Error(\"Callback was already called.\");\n            var callFn = fn;\n            fn = null;\n            callFn.apply(this, args);\n        };\n    }\n\n    // for async generators\n    function asyncEachOfLimit(generator, limit, iteratee, callback) {\n        let done = false;\n        let canceled = false;\n        let awaiting = false;\n        let running = 0;\n        let idx = 0;\n\n        function replenish() {\n            //console.log('replenish')\n            if (running >= limit || awaiting || done) return\n            //console.log('replenish awaiting')\n            awaiting = true;\n            generator.next().then(({value, done: iterDone}) => {\n                //console.log('got value', value)\n                if (canceled || done) return\n                awaiting = false;\n                if (iterDone) {\n                    done = true;\n                    if (running <= 0) {\n                        //console.log('done nextCb')\n                        callback(null);\n                    }\n                    return;\n                }\n                running++;\n                iteratee(value, idx, iterateeCallback);\n                idx++;\n                replenish();\n            }).catch(handleError);\n        }\n\n        function iterateeCallback(err, result) {\n            //console.log('iterateeCallback')\n            running -= 1;\n            if (canceled) return\n            if (err) return handleError(err)\n\n            if (err === false) {\n                done = true;\n                canceled = true;\n                return\n            }\n\n            if (result === breakLoop || (done && running <= 0)) {\n                done = true;\n                //console.log('done iterCb')\n                return callback(null);\n            }\n            replenish();\n        }\n\n        function handleError(err) {\n            if (canceled) return\n            awaiting = false;\n            done = true;\n            callback(err);\n        }\n\n        replenish();\n    }\n\n    var eachOfLimit$2 = (limit) => {\n        return (obj, iteratee, callback) => {\n            callback = once(callback);\n            if (limit <= 0) {\n                throw new RangeError('concurrency limit cannot be less than 1')\n            }\n            if (!obj) {\n                return callback(null);\n            }\n            if (isAsyncGenerator(obj)) {\n                return asyncEachOfLimit(obj, limit, iteratee, callback)\n            }\n            if (isAsyncIterable(obj)) {\n                return asyncEachOfLimit(obj[Symbol.asyncIterator](), limit, iteratee, callback)\n            }\n            var nextElem = createIterator(obj);\n            var done = false;\n            var canceled = false;\n            var running = 0;\n            var looping = false;\n\n            function iterateeCallback(err, value) {\n                if (canceled) return\n                running -= 1;\n                if (err) {\n                    done = true;\n                    callback(err);\n                }\n                else if (err === false) {\n                    done = true;\n                    canceled = true;\n                }\n                else if (value === breakLoop || (done && running <= 0)) {\n                    done = true;\n                    return callback(null);\n                }\n                else if (!looping) {\n                    replenish();\n                }\n            }\n\n            function replenish () {\n                looping = true;\n                while (running < limit && !done) {\n                    var elem = nextElem();\n                    if (elem === null) {\n                        done = true;\n                        if (running <= 0) {\n                            callback(null);\n                        }\n                        return;\n                    }\n                    running += 1;\n                    iteratee(elem.value, elem.key, onlyOnce(iterateeCallback));\n                }\n                looping = false;\n            }\n\n            replenish();\n        };\n    };\n\n    /**\n     * The same as [`eachOf`]{@link module:Collections.eachOf} but runs a maximum of `limit` async operations at a\n     * time.\n     *\n     * @name eachOfLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.eachOf]{@link module:Collections.eachOf}\n     * @alias forEachOfLimit\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - An async function to apply to each\n     * item in `coll`. The `key` is the item's key, or index in the case of an\n     * array.\n     * Invoked with (item, key, callback).\n     * @param {Function} [callback] - A callback which is called when all\n     * `iteratee` functions have finished, or an error occurs. Invoked with (err).\n     * @returns {Promise} a promise, if a callback is omitted\n     */\n    function eachOfLimit(coll, limit, iteratee, callback) {\n        return eachOfLimit$2(limit)(coll, wrapAsync(iteratee), callback);\n    }\n\n    var eachOfLimit$1 = awaitify(eachOfLimit, 4);\n\n    // eachOf implementation optimized for array-likes\n    function eachOfArrayLike(coll, iteratee, callback) {\n        callback = once(callback);\n        var index = 0,\n            completed = 0,\n            {length} = coll,\n            canceled = false;\n        if (length === 0) {\n            callback(null);\n        }\n\n        function iteratorCallback(err, value) {\n            if (err === false) {\n                canceled = true;\n            }\n            if (canceled === true) return\n            if (err) {\n                callback(err);\n            } else if ((++completed === length) || value === breakLoop) {\n                callback(null);\n            }\n        }\n\n        for (; index < length; index++) {\n            iteratee(coll[index], index, onlyOnce(iteratorCallback));\n        }\n    }\n\n    // a generic version of eachOf which can handle array, object, and iterator cases.\n    function eachOfGeneric (coll, iteratee, callback) {\n        return eachOfLimit$1(coll, Infinity, iteratee, callback);\n    }\n\n    /**\n     * Like [`each`]{@link module:Collections.each}, except that it passes the key (or index) as the second argument\n     * to the iteratee.\n     *\n     * @name eachOf\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @alias forEachOf\n     * @category Collection\n     * @see [async.each]{@link module:Collections.each}\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - A function to apply to each\n     * item in `coll`.\n     * The `key` is the item's key, or index in the case of an array.\n     * Invoked with (item, key, callback).\n     * @param {Function} [callback] - A callback which is called when all\n     * `iteratee` functions have finished, or an error occurs. Invoked with (err).\n     * @returns {Promise} a promise, if a callback is omitted\n     * @example\n     *\n     * // dev.json is a file containing a valid json object config for dev environment\n     * // dev.json is a file containing a valid json object config for test environment\n     * // prod.json is a file containing a valid json object config for prod environment\n     * // invalid.json is a file with a malformed json object\n     *\n     * let configs = {}; //global variable\n     * let validConfigFileMap = {dev: 'dev.json', test: 'test.json', prod: 'prod.json'};\n     * let invalidConfigFileMap = {dev: 'dev.json', test: 'test.json', invalid: 'invalid.json'};\n     *\n     * // asynchronous function that reads a json file and parses the contents as json object\n     * function parseFile(file, key, callback) {\n     *     fs.readFile(file, \"utf8\", function(err, data) {\n     *         if (err) return calback(err);\n     *         try {\n     *             configs[key] = JSON.parse(data);\n     *         } catch (e) {\n     *             return callback(e);\n     *         }\n     *         callback();\n     *     });\n     * }\n     *\n     * // Using callbacks\n     * async.forEachOf(validConfigFileMap, parseFile, function (err) {\n     *     if (err) {\n     *         console.error(err);\n     *     } else {\n     *         console.log(configs);\n     *         // configs is now a map of JSON data, e.g.\n     *         // { dev: //parsed dev.json, test: //parsed test.json, prod: //parsed prod.json}\n     *     }\n     * });\n     *\n     * //Error handing\n     * async.forEachOf(invalidConfigFileMap, parseFile, function (err) {\n     *     if (err) {\n     *         console.error(err);\n     *         // JSON parse error exception\n     *     } else {\n     *         console.log(configs);\n     *     }\n     * });\n     *\n     * // Using Promises\n     * async.forEachOf(validConfigFileMap, parseFile)\n     * .then( () => {\n     *     console.log(configs);\n     *     // configs is now a map of JSON data, e.g.\n     *     // { dev: //parsed dev.json, test: //parsed test.json, prod: //parsed prod.json}\n     * }).catch( err => {\n     *     console.error(err);\n     * });\n     *\n     * //Error handing\n     * async.forEachOf(invalidConfigFileMap, parseFile)\n     * .then( () => {\n     *     console.log(configs);\n     * }).catch( err => {\n     *     console.error(err);\n     *     // JSON parse error exception\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let result = await async.forEachOf(validConfigFileMap, parseFile);\n     *         console.log(configs);\n     *         // configs is now a map of JSON data, e.g.\n     *         // { dev: //parsed dev.json, test: //parsed test.json, prod: //parsed prod.json}\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * //Error handing\n     * async () => {\n     *     try {\n     *         let result = await async.forEachOf(invalidConfigFileMap, parseFile);\n     *         console.log(configs);\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *         // JSON parse error exception\n     *     }\n     * }\n     *\n     */\n    function eachOf(coll, iteratee, callback) {\n        var eachOfImplementation = isArrayLike(coll) ? eachOfArrayLike : eachOfGeneric;\n        return eachOfImplementation(coll, wrapAsync(iteratee), callback);\n    }\n\n    var eachOf$1 = awaitify(eachOf, 3);\n\n    /**\n     * Produces a new collection of values by mapping each value in `coll` through\n     * the `iteratee` function. The `iteratee` is called with an item from `coll`\n     * and a callback for when it has finished processing. Each of these callbacks\n     * takes 2 arguments: an `error`, and the transformed item from `coll`. If\n     * `iteratee` passes an error to its callback, the main `callback` (for the\n     * `map` function) is immediately called with the error.\n     *\n     * Note, that since this function applies the `iteratee` to each item in\n     * parallel, there is no guarantee that the `iteratee` functions will complete\n     * in order. However, the results array will be in the same order as the\n     * original `coll`.\n     *\n     * If `map` is passed an Object, the results will be an Array.  The results\n     * will roughly be in the order of the original Objects' keys (but this can\n     * vary across JavaScript engines).\n     *\n     * @name map\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * The iteratee should complete with the transformed item.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. Results is an Array of the\n     * transformed items from the `coll`. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback is passed\n     * @example\n     *\n     * // file1.txt is a file that is 1000 bytes in size\n     * // file2.txt is a file that is 2000 bytes in size\n     * // file3.txt is a file that is 3000 bytes in size\n     * // file4.txt does not exist\n     *\n     * const fileList = ['file1.txt','file2.txt','file3.txt'];\n     * const withMissingFileList = ['file1.txt','file2.txt','file4.txt'];\n     *\n     * // asynchronous function that returns the file size in bytes\n     * function getFileSizeInBytes(file, callback) {\n     *     fs.stat(file, function(err, stat) {\n     *         if (err) {\n     *             return callback(err);\n     *         }\n     *         callback(null, stat.size);\n     *     });\n     * }\n     *\n     * // Using callbacks\n     * async.map(fileList, getFileSizeInBytes, function(err, results) {\n     *     if (err) {\n     *         console.log(err);\n     *     } else {\n     *         console.log(results);\n     *         // results is now an array of the file size in bytes for each file, e.g.\n     *         // [ 1000, 2000, 3000]\n     *     }\n     * });\n     *\n     * // Error Handling\n     * async.map(withMissingFileList, getFileSizeInBytes, function(err, results) {\n     *     if (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *     } else {\n     *         console.log(results);\n     *     }\n     * });\n     *\n     * // Using Promises\n     * async.map(fileList, getFileSizeInBytes)\n     * .then( results => {\n     *     console.log(results);\n     *     // results is now an array of the file size in bytes for each file, e.g.\n     *     // [ 1000, 2000, 3000]\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * // Error Handling\n     * async.map(withMissingFileList, getFileSizeInBytes)\n     * .then( results => {\n     *     console.log(results);\n     * }).catch( err => {\n     *     console.log(err);\n     *     // [ Error: ENOENT: no such file or directory ]\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let results = await async.map(fileList, getFileSizeInBytes);\n     *         console.log(results);\n     *         // results is now an array of the file size in bytes for each file, e.g.\n     *         // [ 1000, 2000, 3000]\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * // Error Handling\n     * async () => {\n     *     try {\n     *         let results = await async.map(withMissingFileList, getFileSizeInBytes);\n     *         console.log(results);\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *     }\n     * }\n     *\n     */\n    function map (coll, iteratee, callback) {\n        return _asyncMap(eachOf$1, coll, iteratee, callback)\n    }\n    var map$1 = awaitify(map, 3);\n\n    /**\n     * Applies the provided arguments to each function in the array, calling\n     * `callback` after all functions have completed. If you only provide the first\n     * argument, `fns`, then it will return a function which lets you pass in the\n     * arguments as if it were a single function call. If more arguments are\n     * provided, `callback` is required while `args` is still optional. The results\n     * for each of the applied async functions are passed to the final callback\n     * as an array.\n     *\n     * @name applyEach\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {Array|Iterable|AsyncIterable|Object} fns - A collection of {@link AsyncFunction}s\n     * to all call with the same arguments\n     * @param {...*} [args] - any number of separate arguments to pass to the\n     * function.\n     * @param {Function} [callback] - the final argument should be the callback,\n     * called when all functions have completed processing.\n     * @returns {AsyncFunction} - Returns a function that takes no args other than\n     * an optional callback, that is the result of applying the `args` to each\n     * of the functions.\n     * @example\n     *\n     * const appliedFn = async.applyEach([enableSearch, updateSchema], 'bucket')\n     *\n     * appliedFn((err, results) => {\n     *     // results[0] is the results for `enableSearch`\n     *     // results[1] is the results for `updateSchema`\n     * });\n     *\n     * // partial application example:\n     * async.each(\n     *     buckets,\n     *     async (bucket) => async.applyEach([enableSearch, updateSchema], bucket)(),\n     *     callback\n     * );\n     */\n    var applyEach = applyEach$1(map$1);\n\n    /**\n     * The same as [`eachOf`]{@link module:Collections.eachOf} but runs only a single async operation at a time.\n     *\n     * @name eachOfSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.eachOf]{@link module:Collections.eachOf}\n     * @alias forEachOfSeries\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * Invoked with (item, key, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. Invoked with (err).\n     * @returns {Promise} a promise, if a callback is omitted\n     */\n    function eachOfSeries(coll, iteratee, callback) {\n        return eachOfLimit$1(coll, 1, iteratee, callback)\n    }\n    var eachOfSeries$1 = awaitify(eachOfSeries, 3);\n\n    /**\n     * The same as [`map`]{@link module:Collections.map} but runs only a single async operation at a time.\n     *\n     * @name mapSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.map]{@link module:Collections.map}\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * The iteratee should complete with the transformed item.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. Results is an array of the\n     * transformed items from the `coll`. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function mapSeries (coll, iteratee, callback) {\n        return _asyncMap(eachOfSeries$1, coll, iteratee, callback)\n    }\n    var mapSeries$1 = awaitify(mapSeries, 3);\n\n    /**\n     * The same as [`applyEach`]{@link module:ControlFlow.applyEach} but runs only a single async operation at a time.\n     *\n     * @name applyEachSeries\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.applyEach]{@link module:ControlFlow.applyEach}\n     * @category Control Flow\n     * @param {Array|Iterable|AsyncIterable|Object} fns - A collection of {@link AsyncFunction}s to all\n     * call with the same arguments\n     * @param {...*} [args] - any number of separate arguments to pass to the\n     * function.\n     * @param {Function} [callback] - the final argument should be the callback,\n     * called when all functions have completed processing.\n     * @returns {AsyncFunction} - A function, that when called, is the result of\n     * appling the `args` to the list of functions.  It takes no args, other than\n     * a callback.\n     */\n    var applyEachSeries = applyEach$1(mapSeries$1);\n\n    const PROMISE_SYMBOL = Symbol('promiseCallback');\n\n    function promiseCallback () {\n        let resolve, reject;\n        function callback (err, ...args) {\n            if (err) return reject(err)\n            resolve(args.length > 1 ? args : args[0]);\n        }\n\n        callback[PROMISE_SYMBOL] = new Promise((res, rej) => {\n            resolve = res,\n            reject = rej;\n        });\n\n        return callback\n    }\n\n    /**\n     * Determines the best order for running the {@link AsyncFunction}s in `tasks`, based on\n     * their requirements. Each function can optionally depend on other functions\n     * being completed first, and each function is run as soon as its requirements\n     * are satisfied.\n     *\n     * If any of the {@link AsyncFunction}s pass an error to their callback, the `auto` sequence\n     * will stop. Further tasks will not execute (so any other functions depending\n     * on it will not run), and the main `callback` is immediately called with the\n     * error.\n     *\n     * {@link AsyncFunction}s also receive an object containing the results of functions which\n     * have completed so far as the first argument, if they have dependencies. If a\n     * task function has no dependencies, it will only be passed a callback.\n     *\n     * @name auto\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {Object} tasks - An object. Each of its properties is either a\n     * function or an array of requirements, with the {@link AsyncFunction} itself the last item\n     * in the array. The object's key of a property serves as the name of the task\n     * defined by that property, i.e. can be used when specifying requirements for\n     * other tasks. The function receives one or two arguments:\n     * * a `results` object, containing the results of the previously executed\n     *   functions, only passed if the task has any dependencies,\n     * * a `callback(err, result)` function, which must be called when finished,\n     *   passing an `error` (which can be `null`) and the result of the function's\n     *   execution.\n     * @param {number} [concurrency=Infinity] - An optional `integer` for\n     * determining the maximum number of tasks that can be run in parallel. By\n     * default, as many as possible.\n     * @param {Function} [callback] - An optional callback which is called when all\n     * the tasks have been completed. It receives the `err` argument if any `tasks`\n     * pass an error to their callback. Results are always returned; however, if an\n     * error occurs, no further `tasks` will be performed, and the results object\n     * will only contain partial results. Invoked with (err, results).\n     * @returns {Promise} a promise, if a callback is not passed\n     * @example\n     *\n     * //Using Callbacks\n     * async.auto({\n     *     get_data: function(callback) {\n     *         // async code to get some data\n     *         callback(null, 'data', 'converted to array');\n     *     },\n     *     make_folder: function(callback) {\n     *         // async code to create a directory to store a file in\n     *         // this is run at the same time as getting the data\n     *         callback(null, 'folder');\n     *     },\n     *     write_file: ['get_data', 'make_folder', function(results, callback) {\n     *         // once there is some data and the directory exists,\n     *         // write the data to a file in the directory\n     *         callback(null, 'filename');\n     *     }],\n     *     email_link: ['write_file', function(results, callback) {\n     *         // once the file is written let's email a link to it...\n     *         callback(null, {'file':results.write_file, 'email':'user@example.com'});\n     *     }]\n     * }, function(err, results) {\n     *     if (err) {\n     *         console.log('err = ', err);\n     *     }\n     *     console.log('results = ', results);\n     *     // results = {\n     *     //     get_data: ['data', 'converted to array']\n     *     //     make_folder; 'folder',\n     *     //     write_file: 'filename'\n     *     //     email_link: { file: 'filename', email: 'user@example.com' }\n     *     // }\n     * });\n     *\n     * //Using Promises\n     * async.auto({\n     *     get_data: function(callback) {\n     *         console.log('in get_data');\n     *         // async code to get some data\n     *         callback(null, 'data', 'converted to array');\n     *     },\n     *     make_folder: function(callback) {\n     *         console.log('in make_folder');\n     *         // async code to create a directory to store a file in\n     *         // this is run at the same time as getting the data\n     *         callback(null, 'folder');\n     *     },\n     *     write_file: ['get_data', 'make_folder', function(results, callback) {\n     *         // once there is some data and the directory exists,\n     *         // write the data to a file in the directory\n     *         callback(null, 'filename');\n     *     }],\n     *     email_link: ['write_file', function(results, callback) {\n     *         // once the file is written let's email a link to it...\n     *         callback(null, {'file':results.write_file, 'email':'user@example.com'});\n     *     }]\n     * }).then(results => {\n     *     console.log('results = ', results);\n     *     // results = {\n     *     //     get_data: ['data', 'converted to array']\n     *     //     make_folder; 'folder',\n     *     //     write_file: 'filename'\n     *     //     email_link: { file: 'filename', email: 'user@example.com' }\n     *     // }\n     * }).catch(err => {\n     *     console.log('err = ', err);\n     * });\n     *\n     * //Using async/await\n     * async () => {\n     *     try {\n     *         let results = await async.auto({\n     *             get_data: function(callback) {\n     *                 // async code to get some data\n     *                 callback(null, 'data', 'converted to array');\n     *             },\n     *             make_folder: function(callback) {\n     *                 // async code to create a directory to store a file in\n     *                 // this is run at the same time as getting the data\n     *                 callback(null, 'folder');\n     *             },\n     *             write_file: ['get_data', 'make_folder', function(results, callback) {\n     *                 // once there is some data and the directory exists,\n     *                 // write the data to a file in the directory\n     *                 callback(null, 'filename');\n     *             }],\n     *             email_link: ['write_file', function(results, callback) {\n     *                 // once the file is written let's email a link to it...\n     *                 callback(null, {'file':results.write_file, 'email':'user@example.com'});\n     *             }]\n     *         });\n     *         console.log('results = ', results);\n     *         // results = {\n     *         //     get_data: ['data', 'converted to array']\n     *         //     make_folder; 'folder',\n     *         //     write_file: 'filename'\n     *         //     email_link: { file: 'filename', email: 'user@example.com' }\n     *         // }\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function auto(tasks, concurrency, callback) {\n        if (typeof concurrency !== 'number') {\n            // concurrency is optional, shift the args.\n            callback = concurrency;\n            concurrency = null;\n        }\n        callback = once(callback || promiseCallback());\n        var numTasks = Object.keys(tasks).length;\n        if (!numTasks) {\n            return callback(null);\n        }\n        if (!concurrency) {\n            concurrency = numTasks;\n        }\n\n        var results = {};\n        var runningTasks = 0;\n        var canceled = false;\n        var hasError = false;\n\n        var listeners = Object.create(null);\n\n        var readyTasks = [];\n\n        // for cycle detection:\n        var readyToCheck = []; // tasks that have been identified as reachable\n        // without the possibility of returning to an ancestor task\n        var uncheckedDependencies = {};\n\n        Object.keys(tasks).forEach(key => {\n            var task = tasks[key];\n            if (!Array.isArray(task)) {\n                // no dependencies\n                enqueueTask(key, [task]);\n                readyToCheck.push(key);\n                return;\n            }\n\n            var dependencies = task.slice(0, task.length - 1);\n            var remainingDependencies = dependencies.length;\n            if (remainingDependencies === 0) {\n                enqueueTask(key, task);\n                readyToCheck.push(key);\n                return;\n            }\n            uncheckedDependencies[key] = remainingDependencies;\n\n            dependencies.forEach(dependencyName => {\n                if (!tasks[dependencyName]) {\n                    throw new Error('async.auto task `' + key +\n                        '` has a non-existent dependency `' +\n                        dependencyName + '` in ' +\n                        dependencies.join(', '));\n                }\n                addListener(dependencyName, () => {\n                    remainingDependencies--;\n                    if (remainingDependencies === 0) {\n                        enqueueTask(key, task);\n                    }\n                });\n            });\n        });\n\n        checkForDeadlocks();\n        processQueue();\n\n        function enqueueTask(key, task) {\n            readyTasks.push(() => runTask(key, task));\n        }\n\n        function processQueue() {\n            if (canceled) return\n            if (readyTasks.length === 0 && runningTasks === 0) {\n                return callback(null, results);\n            }\n            while(readyTasks.length && runningTasks < concurrency) {\n                var run = readyTasks.shift();\n                run();\n            }\n\n        }\n\n        function addListener(taskName, fn) {\n            var taskListeners = listeners[taskName];\n            if (!taskListeners) {\n                taskListeners = listeners[taskName] = [];\n            }\n\n            taskListeners.push(fn);\n        }\n\n        function taskComplete(taskName) {\n            var taskListeners = listeners[taskName] || [];\n            taskListeners.forEach(fn => fn());\n            processQueue();\n        }\n\n\n        function runTask(key, task) {\n            if (hasError) return;\n\n            var taskCallback = onlyOnce((err, ...result) => {\n                runningTasks--;\n                if (err === false) {\n                    canceled = true;\n                    return\n                }\n                if (result.length < 2) {\n                    [result] = result;\n                }\n                if (err) {\n                    var safeResults = {};\n                    Object.keys(results).forEach(rkey => {\n                        safeResults[rkey] = results[rkey];\n                    });\n                    safeResults[key] = result;\n                    hasError = true;\n                    listeners = Object.create(null);\n                    if (canceled) return\n                    callback(err, safeResults);\n                } else {\n                    results[key] = result;\n                    taskComplete(key);\n                }\n            });\n\n            runningTasks++;\n            var taskFn = wrapAsync(task[task.length - 1]);\n            if (task.length > 1) {\n                taskFn(results, taskCallback);\n            } else {\n                taskFn(taskCallback);\n            }\n        }\n\n        function checkForDeadlocks() {\n            // Kahn's algorithm\n            // https://en.wikipedia.org/wiki/Topological_sorting#Kahn.27s_algorithm\n            // http://connalle.blogspot.com/2013/10/topological-sortingkahn-algorithm.html\n            var currentTask;\n            var counter = 0;\n            while (readyToCheck.length) {\n                currentTask = readyToCheck.pop();\n                counter++;\n                getDependents(currentTask).forEach(dependent => {\n                    if (--uncheckedDependencies[dependent] === 0) {\n                        readyToCheck.push(dependent);\n                    }\n                });\n            }\n\n            if (counter !== numTasks) {\n                throw new Error(\n                    'async.auto cannot execute tasks due to a recursive dependency'\n                );\n            }\n        }\n\n        function getDependents(taskName) {\n            var result = [];\n            Object.keys(tasks).forEach(key => {\n                const task = tasks[key];\n                if (Array.isArray(task) && task.indexOf(taskName) >= 0) {\n                    result.push(key);\n                }\n            });\n            return result;\n        }\n\n        return callback[PROMISE_SYMBOL]\n    }\n\n    var FN_ARGS = /^(?:async\\s)?(?:function)?\\s*(?:\\w+\\s*)?\\(([^)]+)\\)(?:\\s*{)/;\n    var ARROW_FN_ARGS = /^(?:async\\s)?\\s*(?:\\(\\s*)?((?:[^)=\\s]\\s*)*)(?:\\)\\s*)?=>/;\n    var FN_ARG_SPLIT = /,/;\n    var FN_ARG = /(=.+)?(\\s*)$/;\n\n    function stripComments(string) {\n        let stripped = '';\n        let index = 0;\n        let endBlockComment = string.indexOf('*/');\n        while (index < string.length) {\n            if (string[index] === '/' && string[index+1] === '/') {\n                // inline comment\n                let endIndex = string.indexOf('\\n', index);\n                index = (endIndex === -1) ? string.length : endIndex;\n            } else if ((endBlockComment !== -1) && (string[index] === '/') && (string[index+1] === '*')) {\n                // block comment\n                let endIndex = string.indexOf('*/', index);\n                if (endIndex !== -1) {\n                    index = endIndex + 2;\n                    endBlockComment = string.indexOf('*/', index);\n                } else {\n                    stripped += string[index];\n                    index++;\n                }\n            } else {\n                stripped += string[index];\n                index++;\n            }\n        }\n        return stripped;\n    }\n\n    function parseParams(func) {\n        const src = stripComments(func.toString());\n        let match = src.match(FN_ARGS);\n        if (!match) {\n            match = src.match(ARROW_FN_ARGS);\n        }\n        if (!match) throw new Error('could not parse args in autoInject\\nSource:\\n' + src)\n        let [, args] = match;\n        return args\n            .replace(/\\s/g, '')\n            .split(FN_ARG_SPLIT)\n            .map((arg) => arg.replace(FN_ARG, '').trim());\n    }\n\n    /**\n     * A dependency-injected version of the [async.auto]{@link module:ControlFlow.auto} function. Dependent\n     * tasks are specified as parameters to the function, after the usual callback\n     * parameter, with the parameter names matching the names of the tasks it\n     * depends on. This can provide even more readable task graphs which can be\n     * easier to maintain.\n     *\n     * If a final callback is specified, the task results are similarly injected,\n     * specified as named parameters after the initial error parameter.\n     *\n     * The autoInject function is purely syntactic sugar and its semantics are\n     * otherwise equivalent to [async.auto]{@link module:ControlFlow.auto}.\n     *\n     * @name autoInject\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.auto]{@link module:ControlFlow.auto}\n     * @category Control Flow\n     * @param {Object} tasks - An object, each of whose properties is an {@link AsyncFunction} of\n     * the form 'func([dependencies...], callback). The object's key of a property\n     * serves as the name of the task defined by that property, i.e. can be used\n     * when specifying requirements for other tasks.\n     * * The `callback` parameter is a `callback(err, result)` which must be called\n     *   when finished, passing an `error` (which can be `null`) and the result of\n     *   the function's execution. The remaining parameters name other tasks on\n     *   which the task is dependent, and the results from those tasks are the\n     *   arguments of those parameters.\n     * @param {Function} [callback] - An optional callback which is called when all\n     * the tasks have been completed. It receives the `err` argument if any `tasks`\n     * pass an error to their callback, and a `results` object with any completed\n     * task results, similar to `auto`.\n     * @returns {Promise} a promise, if no callback is passed\n     * @example\n     *\n     * //  The example from `auto` can be rewritten as follows:\n     * async.autoInject({\n     *     get_data: function(callback) {\n     *         // async code to get some data\n     *         callback(null, 'data', 'converted to array');\n     *     },\n     *     make_folder: function(callback) {\n     *         // async code to create a directory to store a file in\n     *         // this is run at the same time as getting the data\n     *         callback(null, 'folder');\n     *     },\n     *     write_file: function(get_data, make_folder, callback) {\n     *         // once there is some data and the directory exists,\n     *         // write the data to a file in the directory\n     *         callback(null, 'filename');\n     *     },\n     *     email_link: function(write_file, callback) {\n     *         // once the file is written let's email a link to it...\n     *         // write_file contains the filename returned by write_file.\n     *         callback(null, {'file':write_file, 'email':'user@example.com'});\n     *     }\n     * }, function(err, results) {\n     *     console.log('err = ', err);\n     *     console.log('email_link = ', results.email_link);\n     * });\n     *\n     * // If you are using a JS minifier that mangles parameter names, `autoInject`\n     * // will not work with plain functions, since the parameter names will be\n     * // collapsed to a single letter identifier.  To work around this, you can\n     * // explicitly specify the names of the parameters your task function needs\n     * // in an array, similar to Angular.js dependency injection.\n     *\n     * // This still has an advantage over plain `auto`, since the results a task\n     * // depends on are still spread into arguments.\n     * async.autoInject({\n     *     //...\n     *     write_file: ['get_data', 'make_folder', function(get_data, make_folder, callback) {\n     *         callback(null, 'filename');\n     *     }],\n     *     email_link: ['write_file', function(write_file, callback) {\n     *         callback(null, {'file':write_file, 'email':'user@example.com'});\n     *     }]\n     *     //...\n     * }, function(err, results) {\n     *     console.log('err = ', err);\n     *     console.log('email_link = ', results.email_link);\n     * });\n     */\n    function autoInject(tasks, callback) {\n        var newTasks = {};\n\n        Object.keys(tasks).forEach(key => {\n            var taskFn = tasks[key];\n            var params;\n            var fnIsAsync = isAsync(taskFn);\n            var hasNoDeps =\n                (!fnIsAsync && taskFn.length === 1) ||\n                (fnIsAsync && taskFn.length === 0);\n\n            if (Array.isArray(taskFn)) {\n                params = [...taskFn];\n                taskFn = params.pop();\n\n                newTasks[key] = params.concat(params.length > 0 ? newTask : taskFn);\n            } else if (hasNoDeps) {\n                // no dependencies, use the function as-is\n                newTasks[key] = taskFn;\n            } else {\n                params = parseParams(taskFn);\n                if ((taskFn.length === 0 && !fnIsAsync) && params.length === 0) {\n                    throw new Error(\"autoInject task functions require explicit parameters.\");\n                }\n\n                // remove callback param\n                if (!fnIsAsync) params.pop();\n\n                newTasks[key] = params.concat(newTask);\n            }\n\n            function newTask(results, taskCb) {\n                var newArgs = params.map(name => results[name]);\n                newArgs.push(taskCb);\n                wrapAsync(taskFn)(...newArgs);\n            }\n        });\n\n        return auto(newTasks, callback);\n    }\n\n    // Simple doubly linked list (https://en.wikipedia.org/wiki/Doubly_linked_list) implementation\n    // used for queues. This implementation assumes that the node provided by the user can be modified\n    // to adjust the next and last properties. We implement only the minimal functionality\n    // for queue support.\n    class DLL {\n        constructor() {\n            this.head = this.tail = null;\n            this.length = 0;\n        }\n\n        removeLink(node) {\n            if (node.prev) node.prev.next = node.next;\n            else this.head = node.next;\n            if (node.next) node.next.prev = node.prev;\n            else this.tail = node.prev;\n\n            node.prev = node.next = null;\n            this.length -= 1;\n            return node;\n        }\n\n        empty () {\n            while(this.head) this.shift();\n            return this;\n        }\n\n        insertAfter(node, newNode) {\n            newNode.prev = node;\n            newNode.next = node.next;\n            if (node.next) node.next.prev = newNode;\n            else this.tail = newNode;\n            node.next = newNode;\n            this.length += 1;\n        }\n\n        insertBefore(node, newNode) {\n            newNode.prev = node.prev;\n            newNode.next = node;\n            if (node.prev) node.prev.next = newNode;\n            else this.head = newNode;\n            node.prev = newNode;\n            this.length += 1;\n        }\n\n        unshift(node) {\n            if (this.head) this.insertBefore(this.head, node);\n            else setInitial(this, node);\n        }\n\n        push(node) {\n            if (this.tail) this.insertAfter(this.tail, node);\n            else setInitial(this, node);\n        }\n\n        shift() {\n            return this.head && this.removeLink(this.head);\n        }\n\n        pop() {\n            return this.tail && this.removeLink(this.tail);\n        }\n\n        toArray() {\n            return [...this]\n        }\n\n        *[Symbol.iterator] () {\n            var cur = this.head;\n            while (cur) {\n                yield cur.data;\n                cur = cur.next;\n            }\n        }\n\n        remove (testFn) {\n            var curr = this.head;\n            while(curr) {\n                var {next} = curr;\n                if (testFn(curr)) {\n                    this.removeLink(curr);\n                }\n                curr = next;\n            }\n            return this;\n        }\n    }\n\n    function setInitial(dll, node) {\n        dll.length = 1;\n        dll.head = dll.tail = node;\n    }\n\n    function queue$1(worker, concurrency, payload) {\n        if (concurrency == null) {\n            concurrency = 1;\n        }\n        else if(concurrency === 0) {\n            throw new RangeError('Concurrency must not be zero');\n        }\n\n        var _worker = wrapAsync(worker);\n        var numRunning = 0;\n        var workersList = [];\n        const events = {\n            error: [],\n            drain: [],\n            saturated: [],\n            unsaturated: [],\n            empty: []\n        };\n\n        function on (event, handler) {\n            events[event].push(handler);\n        }\n\n        function once (event, handler) {\n            const handleAndRemove = (...args) => {\n                off(event, handleAndRemove);\n                handler(...args);\n            };\n            events[event].push(handleAndRemove);\n        }\n\n        function off (event, handler) {\n            if (!event) return Object.keys(events).forEach(ev => events[ev] = [])\n            if (!handler) return events[event] = []\n            events[event] = events[event].filter(ev => ev !== handler);\n        }\n\n        function trigger (event, ...args) {\n            events[event].forEach(handler => handler(...args));\n        }\n\n        var processingScheduled = false;\n        function _insert(data, insertAtFront, rejectOnError, callback) {\n            if (callback != null && typeof callback !== 'function') {\n                throw new Error('task callback must be a function');\n            }\n            q.started = true;\n\n            var res, rej;\n            function promiseCallback (err, ...args) {\n                // we don't care about the error, let the global error handler\n                // deal with it\n                if (err) return rejectOnError ? rej(err) : res()\n                if (args.length <= 1) return res(args[0])\n                res(args);\n            }\n\n            var item = q._createTaskItem(\n                data,\n                rejectOnError ? promiseCallback :\n                    (callback || promiseCallback)\n            );\n\n            if (insertAtFront) {\n                q._tasks.unshift(item);\n            } else {\n                q._tasks.push(item);\n            }\n\n            if (!processingScheduled) {\n                processingScheduled = true;\n                setImmediate$1(() => {\n                    processingScheduled = false;\n                    q.process();\n                });\n            }\n\n            if (rejectOnError || !callback) {\n                return new Promise((resolve, reject) => {\n                    res = resolve;\n                    rej = reject;\n                })\n            }\n        }\n\n        function _createCB(tasks) {\n            return function (err, ...args) {\n                numRunning -= 1;\n\n                for (var i = 0, l = tasks.length; i < l; i++) {\n                    var task = tasks[i];\n\n                    var index = workersList.indexOf(task);\n                    if (index === 0) {\n                        workersList.shift();\n                    } else if (index > 0) {\n                        workersList.splice(index, 1);\n                    }\n\n                    task.callback(err, ...args);\n\n                    if (err != null) {\n                        trigger('error', err, task.data);\n                    }\n                }\n\n                if (numRunning <= (q.concurrency - q.buffer) ) {\n                    trigger('unsaturated');\n                }\n\n                if (q.idle()) {\n                    trigger('drain');\n                }\n                q.process();\n            };\n        }\n\n        function _maybeDrain(data) {\n            if (data.length === 0 && q.idle()) {\n                // call drain immediately if there are no tasks\n                setImmediate$1(() => trigger('drain'));\n                return true\n            }\n            return false\n        }\n\n        const eventMethod = (name) => (handler) => {\n            if (!handler) {\n                return new Promise((resolve, reject) => {\n                    once(name, (err, data) => {\n                        if (err) return reject(err)\n                        resolve(data);\n                    });\n                })\n            }\n            off(name);\n            on(name, handler);\n\n        };\n\n        var isProcessing = false;\n        var q = {\n            _tasks: new DLL(),\n            _createTaskItem (data, callback) {\n                return {\n                    data,\n                    callback\n                };\n            },\n            *[Symbol.iterator] () {\n                yield* q._tasks[Symbol.iterator]();\n            },\n            concurrency,\n            payload,\n            buffer: concurrency / 4,\n            started: false,\n            paused: false,\n            push (data, callback) {\n                if (Array.isArray(data)) {\n                    if (_maybeDrain(data)) return\n                    return data.map(datum => _insert(datum, false, false, callback))\n                }\n                return _insert(data, false, false, callback);\n            },\n            pushAsync (data, callback) {\n                if (Array.isArray(data)) {\n                    if (_maybeDrain(data)) return\n                    return data.map(datum => _insert(datum, false, true, callback))\n                }\n                return _insert(data, false, true, callback);\n            },\n            kill () {\n                off();\n                q._tasks.empty();\n            },\n            unshift (data, callback) {\n                if (Array.isArray(data)) {\n                    if (_maybeDrain(data)) return\n                    return data.map(datum => _insert(datum, true, false, callback))\n                }\n                return _insert(data, true, false, callback);\n            },\n            unshiftAsync (data, callback) {\n                if (Array.isArray(data)) {\n                    if (_maybeDrain(data)) return\n                    return data.map(datum => _insert(datum, true, true, callback))\n                }\n                return _insert(data, true, true, callback);\n            },\n            remove (testFn) {\n                q._tasks.remove(testFn);\n            },\n            process () {\n                // Avoid trying to start too many processing operations. This can occur\n                // when callbacks resolve synchronously (#1267).\n                if (isProcessing) {\n                    return;\n                }\n                isProcessing = true;\n                while(!q.paused && numRunning < q.concurrency && q._tasks.length){\n                    var tasks = [], data = [];\n                    var l = q._tasks.length;\n                    if (q.payload) l = Math.min(l, q.payload);\n                    for (var i = 0; i < l; i++) {\n                        var node = q._tasks.shift();\n                        tasks.push(node);\n                        workersList.push(node);\n                        data.push(node.data);\n                    }\n\n                    numRunning += 1;\n\n                    if (q._tasks.length === 0) {\n                        trigger('empty');\n                    }\n\n                    if (numRunning === q.concurrency) {\n                        trigger('saturated');\n                    }\n\n                    var cb = onlyOnce(_createCB(tasks));\n                    _worker(data, cb);\n                }\n                isProcessing = false;\n            },\n            length () {\n                return q._tasks.length;\n            },\n            running () {\n                return numRunning;\n            },\n            workersList () {\n                return workersList;\n            },\n            idle() {\n                return q._tasks.length + numRunning === 0;\n            },\n            pause () {\n                q.paused = true;\n            },\n            resume () {\n                if (q.paused === false) { return; }\n                q.paused = false;\n                setImmediate$1(q.process);\n            }\n        };\n        // define these as fixed properties, so people get useful errors when updating\n        Object.defineProperties(q, {\n            saturated: {\n                writable: false,\n                value: eventMethod('saturated')\n            },\n            unsaturated: {\n                writable: false,\n                value: eventMethod('unsaturated')\n            },\n            empty: {\n                writable: false,\n                value: eventMethod('empty')\n            },\n            drain: {\n                writable: false,\n                value: eventMethod('drain')\n            },\n            error: {\n                writable: false,\n                value: eventMethod('error')\n            },\n        });\n        return q;\n    }\n\n    /**\n     * Creates a `cargo` object with the specified payload. Tasks added to the\n     * cargo will be processed altogether (up to the `payload` limit). If the\n     * `worker` is in progress, the task is queued until it becomes available. Once\n     * the `worker` has completed some tasks, each callback of those tasks is\n     * called. Check out [these](https://camo.githubusercontent.com/6bbd36f4cf5b35a0f11a96dcd2e97711ffc2fb37/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313637363837312f36383130382f62626330636662302d356632392d313165322d393734662d3333393763363464633835382e676966) [animations](https://camo.githubusercontent.com/f4810e00e1c5f5f8addbe3e9f49064fd5d102699/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313637363837312f36383130312f38346339323036362d356632392d313165322d383134662d3964336430323431336266642e676966)\n     * for how `cargo` and `queue` work.\n     *\n     * While [`queue`]{@link module:ControlFlow.queue} passes only one task to one of a group of workers\n     * at a time, cargo passes an array of tasks to a single worker, repeating\n     * when the worker is finished.\n     *\n     * @name cargo\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.queue]{@link module:ControlFlow.queue}\n     * @category Control Flow\n     * @param {AsyncFunction} worker - An asynchronous function for processing an array\n     * of queued tasks. Invoked with `(tasks, callback)`.\n     * @param {number} [payload=Infinity] - An optional `integer` for determining\n     * how many tasks should be processed per round; if omitted, the default is\n     * unlimited.\n     * @returns {module:ControlFlow.QueueObject} A cargo object to manage the tasks. Callbacks can\n     * attached as certain properties to listen for specific events during the\n     * lifecycle of the cargo and inner queue.\n     * @example\n     *\n     * // create a cargo object with payload 2\n     * var cargo = async.cargo(function(tasks, callback) {\n     *     for (var i=0; i<tasks.length; i++) {\n     *         console.log('hello ' + tasks[i].name);\n     *     }\n     *     callback();\n     * }, 2);\n     *\n     * // add some items\n     * cargo.push({name: 'foo'}, function(err) {\n     *     console.log('finished processing foo');\n     * });\n     * cargo.push({name: 'bar'}, function(err) {\n     *     console.log('finished processing bar');\n     * });\n     * await cargo.push({name: 'baz'});\n     * console.log('finished processing baz');\n     */\n    function cargo$1(worker, payload) {\n        return queue$1(worker, 1, payload);\n    }\n\n    /**\n     * Creates a `cargoQueue` object with the specified payload. Tasks added to the\n     * cargoQueue will be processed together (up to the `payload` limit) in `concurrency` parallel workers.\n     * If the all `workers` are in progress, the task is queued until one becomes available. Once\n     * a `worker` has completed some tasks, each callback of those tasks is\n     * called. Check out [these](https://camo.githubusercontent.com/6bbd36f4cf5b35a0f11a96dcd2e97711ffc2fb37/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313637363837312f36383130382f62626330636662302d356632392d313165322d393734662d3333393763363464633835382e676966) [animations](https://camo.githubusercontent.com/f4810e00e1c5f5f8addbe3e9f49064fd5d102699/68747470733a2f2f662e636c6f75642e6769746875622e636f6d2f6173736574732f313637363837312f36383130312f38346339323036362d356632392d313165322d383134662d3964336430323431336266642e676966)\n     * for how `cargo` and `queue` work.\n     *\n     * While [`queue`]{@link module:ControlFlow.queue} passes only one task to one of a group of workers\n     * at a time, and [`cargo`]{@link module:ControlFlow.cargo} passes an array of tasks to a single worker,\n     * the cargoQueue passes an array of tasks to multiple parallel workers.\n     *\n     * @name cargoQueue\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.queue]{@link module:ControlFlow.queue}\n     * @see [async.cargo]{@link module:ControlFLow.cargo}\n     * @category Control Flow\n     * @param {AsyncFunction} worker - An asynchronous function for processing an array\n     * of queued tasks. Invoked with `(tasks, callback)`.\n     * @param {number} [concurrency=1] - An `integer` for determining how many\n     * `worker` functions should be run in parallel.  If omitted, the concurrency\n     * defaults to `1`.  If the concurrency is `0`, an error is thrown.\n     * @param {number} [payload=Infinity] - An optional `integer` for determining\n     * how many tasks should be processed per round; if omitted, the default is\n     * unlimited.\n     * @returns {module:ControlFlow.QueueObject} A cargoQueue object to manage the tasks. Callbacks can\n     * attached as certain properties to listen for specific events during the\n     * lifecycle of the cargoQueue and inner queue.\n     * @example\n     *\n     * // create a cargoQueue object with payload 2 and concurrency 2\n     * var cargoQueue = async.cargoQueue(function(tasks, callback) {\n     *     for (var i=0; i<tasks.length; i++) {\n     *         console.log('hello ' + tasks[i].name);\n     *     }\n     *     callback();\n     * }, 2, 2);\n     *\n     * // add some items\n     * cargoQueue.push({name: 'foo'}, function(err) {\n     *     console.log('finished processing foo');\n     * });\n     * cargoQueue.push({name: 'bar'}, function(err) {\n     *     console.log('finished processing bar');\n     * });\n     * cargoQueue.push({name: 'baz'}, function(err) {\n     *     console.log('finished processing baz');\n     * });\n     * cargoQueue.push({name: 'boo'}, function(err) {\n     *     console.log('finished processing boo');\n     * });\n     */\n    function cargo(worker, concurrency, payload) {\n        return queue$1(worker, concurrency, payload);\n    }\n\n    /**\n     * Reduces `coll` into a single value using an async `iteratee` to return each\n     * successive step. `memo` is the initial state of the reduction. This function\n     * only operates in series.\n     *\n     * For performance reasons, it may make sense to split a call to this function\n     * into a parallel map, and then use the normal `Array.prototype.reduce` on the\n     * results. This function is for situations where each step in the reduction\n     * needs to be async; if you can get the data before reducing it, then it's\n     * probably a good idea to do so.\n     *\n     * @name reduce\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @alias inject\n     * @alias foldl\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {*} memo - The initial state of the reduction.\n     * @param {AsyncFunction} iteratee - A function applied to each item in the\n     * array to produce the next step in the reduction.\n     * The `iteratee` should complete with the next state of the reduction.\n     * If the iteratee completes with an error, the reduction is stopped and the\n     * main `callback` is immediately called with the error.\n     * Invoked with (memo, item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Result is the reduced value. Invoked with\n     * (err, result).\n     * @returns {Promise} a promise, if no callback is passed\n     * @example\n     *\n     * // file1.txt is a file that is 1000 bytes in size\n     * // file2.txt is a file that is 2000 bytes in size\n     * // file3.txt is a file that is 3000 bytes in size\n     * // file4.txt does not exist\n     *\n     * const fileList = ['file1.txt','file2.txt','file3.txt'];\n     * const withMissingFileList = ['file1.txt','file2.txt','file3.txt', 'file4.txt'];\n     *\n     * // asynchronous function that computes the file size in bytes\n     * // file size is added to the memoized value, then returned\n     * function getFileSizeInBytes(memo, file, callback) {\n     *     fs.stat(file, function(err, stat) {\n     *         if (err) {\n     *             return callback(err);\n     *         }\n     *         callback(null, memo + stat.size);\n     *     });\n     * }\n     *\n     * // Using callbacks\n     * async.reduce(fileList, 0, getFileSizeInBytes, function(err, result) {\n     *     if (err) {\n     *         console.log(err);\n     *     } else {\n     *         console.log(result);\n     *         // 6000\n     *         // which is the sum of the file sizes of the three files\n     *     }\n     * });\n     *\n     * // Error Handling\n     * async.reduce(withMissingFileList, 0, getFileSizeInBytes, function(err, result) {\n     *     if (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *     } else {\n     *         console.log(result);\n     *     }\n     * });\n     *\n     * // Using Promises\n     * async.reduce(fileList, 0, getFileSizeInBytes)\n     * .then( result => {\n     *     console.log(result);\n     *     // 6000\n     *     // which is the sum of the file sizes of the three files\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * // Error Handling\n     * async.reduce(withMissingFileList, 0, getFileSizeInBytes)\n     * .then( result => {\n     *     console.log(result);\n     * }).catch( err => {\n     *     console.log(err);\n     *     // [ Error: ENOENT: no such file or directory ]\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let result = await async.reduce(fileList, 0, getFileSizeInBytes);\n     *         console.log(result);\n     *         // 6000\n     *         // which is the sum of the file sizes of the three files\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * // Error Handling\n     * async () => {\n     *     try {\n     *         let result = await async.reduce(withMissingFileList, 0, getFileSizeInBytes);\n     *         console.log(result);\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *     }\n     * }\n     *\n     */\n    function reduce(coll, memo, iteratee, callback) {\n        callback = once(callback);\n        var _iteratee = wrapAsync(iteratee);\n        return eachOfSeries$1(coll, (x, i, iterCb) => {\n            _iteratee(memo, x, (err, v) => {\n                memo = v;\n                iterCb(err);\n            });\n        }, err => callback(err, memo));\n    }\n    var reduce$1 = awaitify(reduce, 4);\n\n    /**\n     * Version of the compose function that is more natural to read. Each function\n     * consumes the return value of the previous function. It is the equivalent of\n     * [compose]{@link module:ControlFlow.compose} with the arguments reversed.\n     *\n     * Each function is executed with the `this` binding of the composed function.\n     *\n     * @name seq\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.compose]{@link module:ControlFlow.compose}\n     * @category Control Flow\n     * @param {...AsyncFunction} functions - the asynchronous functions to compose\n     * @returns {Function} a function that composes the `functions` in order\n     * @example\n     *\n     * // Requires lodash (or underscore), express3 and dresende's orm2.\n     * // Part of an app, that fetches cats of the logged user.\n     * // This example uses `seq` function to avoid overnesting and error\n     * // handling clutter.\n     * app.get('/cats', function(request, response) {\n     *     var User = request.models.User;\n     *     async.seq(\n     *         User.get.bind(User),  // 'User.get' has signature (id, callback(err, data))\n     *         function(user, fn) {\n     *             user.getCats(fn);      // 'getCats' has signature (callback(err, data))\n     *         }\n     *     )(req.session.user_id, function (err, cats) {\n     *         if (err) {\n     *             console.error(err);\n     *             response.json({ status: 'error', message: err.message });\n     *         } else {\n     *             response.json({ status: 'ok', message: 'Cats found', data: cats });\n     *         }\n     *     });\n     * });\n     */\n    function seq(...functions) {\n        var _functions = functions.map(wrapAsync);\n        return function (...args) {\n            var that = this;\n\n            var cb = args[args.length - 1];\n            if (typeof cb == 'function') {\n                args.pop();\n            } else {\n                cb = promiseCallback();\n            }\n\n            reduce$1(_functions, args, (newargs, fn, iterCb) => {\n                fn.apply(that, newargs.concat((err, ...nextargs) => {\n                    iterCb(err, nextargs);\n                }));\n            },\n            (err, results) => cb(err, ...results));\n\n            return cb[PROMISE_SYMBOL]\n        };\n    }\n\n    /**\n     * Creates a function which is a composition of the passed asynchronous\n     * functions. Each function consumes the return value of the function that\n     * follows. Composing functions `f()`, `g()`, and `h()` would produce the result\n     * of `f(g(h()))`, only this version uses callbacks to obtain the return values.\n     *\n     * If the last argument to the composed function is not a function, a promise\n     * is returned when you call it.\n     *\n     * Each function is executed with the `this` binding of the composed function.\n     *\n     * @name compose\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {...AsyncFunction} functions - the asynchronous functions to compose\n     * @returns {Function} an asynchronous function that is the composed\n     * asynchronous `functions`\n     * @example\n     *\n     * function add1(n, callback) {\n     *     setTimeout(function () {\n     *         callback(null, n + 1);\n     *     }, 10);\n     * }\n     *\n     * function mul3(n, callback) {\n     *     setTimeout(function () {\n     *         callback(null, n * 3);\n     *     }, 10);\n     * }\n     *\n     * var add1mul3 = async.compose(mul3, add1);\n     * add1mul3(4, function (err, result) {\n     *     // result now equals 15\n     * });\n     */\n    function compose(...args) {\n        return seq(...args.reverse());\n    }\n\n    /**\n     * The same as [`map`]{@link module:Collections.map} but runs a maximum of `limit` async operations at a time.\n     *\n     * @name mapLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.map]{@link module:Collections.map}\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * The iteratee should complete with the transformed item.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. Results is an array of the\n     * transformed items from the `coll`. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function mapLimit (coll, limit, iteratee, callback) {\n        return _asyncMap(eachOfLimit$2(limit), coll, iteratee, callback)\n    }\n    var mapLimit$1 = awaitify(mapLimit, 4);\n\n    /**\n     * The same as [`concat`]{@link module:Collections.concat} but runs a maximum of `limit` async operations at a time.\n     *\n     * @name concatLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.concat]{@link module:Collections.concat}\n     * @category Collection\n     * @alias flatMapLimit\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - A function to apply to each item in `coll`,\n     * which should use an array as its result. Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished, or an error occurs. Results is an array\n     * containing the concatenated results of the `iteratee` function. Invoked with\n     * (err, results).\n     * @returns A Promise, if no callback is passed\n     */\n    function concatLimit(coll, limit, iteratee, callback) {\n        var _iteratee = wrapAsync(iteratee);\n        return mapLimit$1(coll, limit, (val, iterCb) => {\n            _iteratee(val, (err, ...args) => {\n                if (err) return iterCb(err);\n                return iterCb(err, args);\n            });\n        }, (err, mapResults) => {\n            var result = [];\n            for (var i = 0; i < mapResults.length; i++) {\n                if (mapResults[i]) {\n                    result = result.concat(...mapResults[i]);\n                }\n            }\n\n            return callback(err, result);\n        });\n    }\n    var concatLimit$1 = awaitify(concatLimit, 4);\n\n    /**\n     * Applies `iteratee` to each item in `coll`, concatenating the results. Returns\n     * the concatenated list. The `iteratee`s are called in parallel, and the\n     * results are concatenated as they return. The results array will be returned in\n     * the original order of `coll` passed to the `iteratee` function.\n     *\n     * @name concat\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @category Collection\n     * @alias flatMap\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - A function to apply to each item in `coll`,\n     * which should use an array as its result. Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished, or an error occurs. Results is an array\n     * containing the concatenated results of the `iteratee` function. Invoked with\n     * (err, results).\n     * @returns A Promise, if no callback is passed\n     * @example\n     *\n     * // dir1 is a directory that contains file1.txt, file2.txt\n     * // dir2 is a directory that contains file3.txt, file4.txt\n     * // dir3 is a directory that contains file5.txt\n     * // dir4 does not exist\n     *\n     * let directoryList = ['dir1','dir2','dir3'];\n     * let withMissingDirectoryList = ['dir1','dir2','dir3', 'dir4'];\n     *\n     * // Using callbacks\n     * async.concat(directoryList, fs.readdir, function(err, results) {\n     *    if (err) {\n     *        console.log(err);\n     *    } else {\n     *        console.log(results);\n     *        // [ 'file1.txt', 'file2.txt', 'file3.txt', 'file4.txt', file5.txt ]\n     *    }\n     * });\n     *\n     * // Error Handling\n     * async.concat(withMissingDirectoryList, fs.readdir, function(err, results) {\n     *    if (err) {\n     *        console.log(err);\n     *        // [ Error: ENOENT: no such file or directory ]\n     *        // since dir4 does not exist\n     *    } else {\n     *        console.log(results);\n     *    }\n     * });\n     *\n     * // Using Promises\n     * async.concat(directoryList, fs.readdir)\n     * .then(results => {\n     *     console.log(results);\n     *     // [ 'file1.txt', 'file2.txt', 'file3.txt', 'file4.txt', file5.txt ]\n     * }).catch(err => {\n     *      console.log(err);\n     * });\n     *\n     * // Error Handling\n     * async.concat(withMissingDirectoryList, fs.readdir)\n     * .then(results => {\n     *     console.log(results);\n     * }).catch(err => {\n     *     console.log(err);\n     *     // [ Error: ENOENT: no such file or directory ]\n     *     // since dir4 does not exist\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let results = await async.concat(directoryList, fs.readdir);\n     *         console.log(results);\n     *         // [ 'file1.txt', 'file2.txt', 'file3.txt', 'file4.txt', file5.txt ]\n     *     } catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * // Error Handling\n     * async () => {\n     *     try {\n     *         let results = await async.concat(withMissingDirectoryList, fs.readdir);\n     *         console.log(results);\n     *     } catch (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *         // since dir4 does not exist\n     *     }\n     * }\n     *\n     */\n    function concat(coll, iteratee, callback) {\n        return concatLimit$1(coll, Infinity, iteratee, callback)\n    }\n    var concat$1 = awaitify(concat, 3);\n\n    /**\n     * The same as [`concat`]{@link module:Collections.concat} but runs only a single async operation at a time.\n     *\n     * @name concatSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.concat]{@link module:Collections.concat}\n     * @category Collection\n     * @alias flatMapSeries\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - A function to apply to each item in `coll`.\n     * The iteratee should complete with an array an array of results.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished, or an error occurs. Results is an array\n     * containing the concatenated results of the `iteratee` function. Invoked with\n     * (err, results).\n     * @returns A Promise, if no callback is passed\n     */\n    function concatSeries(coll, iteratee, callback) {\n        return concatLimit$1(coll, 1, iteratee, callback)\n    }\n    var concatSeries$1 = awaitify(concatSeries, 3);\n\n    /**\n     * Returns a function that when called, calls-back with the values provided.\n     * Useful as the first function in a [`waterfall`]{@link module:ControlFlow.waterfall}, or for plugging values in to\n     * [`auto`]{@link module:ControlFlow.auto}.\n     *\n     * @name constant\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @category Util\n     * @param {...*} arguments... - Any number of arguments to automatically invoke\n     * callback with.\n     * @returns {AsyncFunction} Returns a function that when invoked, automatically\n     * invokes the callback with the previous given arguments.\n     * @example\n     *\n     * async.waterfall([\n     *     async.constant(42),\n     *     function (value, next) {\n     *         // value === 42\n     *     },\n     *     //...\n     * ], callback);\n     *\n     * async.waterfall([\n     *     async.constant(filename, \"utf8\"),\n     *     fs.readFile,\n     *     function (fileData, next) {\n     *         //...\n     *     }\n     *     //...\n     * ], callback);\n     *\n     * async.auto({\n     *     hostname: async.constant(\"https://server.net/\"),\n     *     port: findFreePort,\n     *     launchServer: [\"hostname\", \"port\", function (options, cb) {\n     *         startServer(options, cb);\n     *     }],\n     *     //...\n     * }, callback);\n     */\n    function constant$1(...args) {\n        return function (...ignoredArgs/*, callback*/) {\n            var callback = ignoredArgs.pop();\n            return callback(null, ...args);\n        };\n    }\n\n    function _createTester(check, getResult) {\n        return (eachfn, arr, _iteratee, cb) => {\n            var testPassed = false;\n            var testResult;\n            const iteratee = wrapAsync(_iteratee);\n            eachfn(arr, (value, _, callback) => {\n                iteratee(value, (err, result) => {\n                    if (err || err === false) return callback(err);\n\n                    if (check(result) && !testResult) {\n                        testPassed = true;\n                        testResult = getResult(true, value);\n                        return callback(null, breakLoop);\n                    }\n                    callback();\n                });\n            }, err => {\n                if (err) return cb(err);\n                cb(null, testPassed ? testResult : getResult(false));\n            });\n        };\n    }\n\n    /**\n     * Returns the first value in `coll` that passes an async truth test. The\n     * `iteratee` is applied in parallel, meaning the first iteratee to return\n     * `true` will fire the detect `callback` with that result. That means the\n     * result might not be the first item in the original `coll` (in terms of order)\n     * that passes the test.\n\n     * If order within the original `coll` is important, then look at\n     * [`detectSeries`]{@link module:Collections.detectSeries}.\n     *\n     * @name detect\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @alias find\n     * @category Collections\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - A truth test to apply to each item in `coll`.\n     * The iteratee must complete with a boolean value as its result.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called as soon as any\n     * iteratee returns `true`, or after all the `iteratee` functions have finished.\n     * Result will be the first item in the array that passes the truth test\n     * (iteratee) or the value `undefined` if none passed. Invoked with\n     * (err, result).\n     * @returns {Promise} a promise, if a callback is omitted\n     * @example\n     *\n     * // dir1 is a directory that contains file1.txt, file2.txt\n     * // dir2 is a directory that contains file3.txt, file4.txt\n     * // dir3 is a directory that contains file5.txt\n     *\n     * // asynchronous function that checks if a file exists\n     * function fileExists(file, callback) {\n     *    fs.access(file, fs.constants.F_OK, (err) => {\n     *        callback(null, !err);\n     *    });\n     * }\n     *\n     * async.detect(['file3.txt','file2.txt','dir1/file1.txt'], fileExists,\n     *    function(err, result) {\n     *        console.log(result);\n     *        // dir1/file1.txt\n     *        // result now equals the first file in the list that exists\n     *    }\n     *);\n     *\n     * // Using Promises\n     * async.detect(['file3.txt','file2.txt','dir1/file1.txt'], fileExists)\n     * .then(result => {\n     *     console.log(result);\n     *     // dir1/file1.txt\n     *     // result now equals the first file in the list that exists\n     * }).catch(err => {\n     *     console.log(err);\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let result = await async.detect(['file3.txt','file2.txt','dir1/file1.txt'], fileExists);\n     *         console.log(result);\n     *         // dir1/file1.txt\n     *         // result now equals the file in the list that exists\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function detect(coll, iteratee, callback) {\n        return _createTester(bool => bool, (res, item) => item)(eachOf$1, coll, iteratee, callback)\n    }\n    var detect$1 = awaitify(detect, 3);\n\n    /**\n     * The same as [`detect`]{@link module:Collections.detect} but runs a maximum of `limit` async operations at a\n     * time.\n     *\n     * @name detectLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.detect]{@link module:Collections.detect}\n     * @alias findLimit\n     * @category Collections\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - A truth test to apply to each item in `coll`.\n     * The iteratee must complete with a boolean value as its result.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called as soon as any\n     * iteratee returns `true`, or after all the `iteratee` functions have finished.\n     * Result will be the first item in the array that passes the truth test\n     * (iteratee) or the value `undefined` if none passed. Invoked with\n     * (err, result).\n     * @returns {Promise} a promise, if a callback is omitted\n     */\n    function detectLimit(coll, limit, iteratee, callback) {\n        return _createTester(bool => bool, (res, item) => item)(eachOfLimit$2(limit), coll, iteratee, callback)\n    }\n    var detectLimit$1 = awaitify(detectLimit, 4);\n\n    /**\n     * The same as [`detect`]{@link module:Collections.detect} but runs only a single async operation at a time.\n     *\n     * @name detectSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.detect]{@link module:Collections.detect}\n     * @alias findSeries\n     * @category Collections\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - A truth test to apply to each item in `coll`.\n     * The iteratee must complete with a boolean value as its result.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called as soon as any\n     * iteratee returns `true`, or after all the `iteratee` functions have finished.\n     * Result will be the first item in the array that passes the truth test\n     * (iteratee) or the value `undefined` if none passed. Invoked with\n     * (err, result).\n     * @returns {Promise} a promise, if a callback is omitted\n     */\n    function detectSeries(coll, iteratee, callback) {\n        return _createTester(bool => bool, (res, item) => item)(eachOfLimit$2(1), coll, iteratee, callback)\n    }\n\n    var detectSeries$1 = awaitify(detectSeries, 3);\n\n    function consoleFunc(name) {\n        return (fn, ...args) => wrapAsync(fn)(...args, (err, ...resultArgs) => {\n            /* istanbul ignore else */\n            if (typeof console === 'object') {\n                /* istanbul ignore else */\n                if (err) {\n                    /* istanbul ignore else */\n                    if (console.error) {\n                        console.error(err);\n                    }\n                } else if (console[name]) { /* istanbul ignore else */\n                    resultArgs.forEach(x => console[name](x));\n                }\n            }\n        })\n    }\n\n    /**\n     * Logs the result of an [`async` function]{@link AsyncFunction} to the\n     * `console` using `console.dir` to display the properties of the resulting object.\n     * Only works in Node.js or in browsers that support `console.dir` and\n     * `console.error` (such as FF and Chrome).\n     * If multiple arguments are returned from the async function,\n     * `console.dir` is called on each argument in order.\n     *\n     * @name dir\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @category Util\n     * @param {AsyncFunction} function - The function you want to eventually apply\n     * all arguments to.\n     * @param {...*} arguments... - Any number of arguments to apply to the function.\n     * @example\n     *\n     * // in a module\n     * var hello = function(name, callback) {\n     *     setTimeout(function() {\n     *         callback(null, {hello: name});\n     *     }, 1000);\n     * };\n     *\n     * // in the node repl\n     * node> async.dir(hello, 'world');\n     * {hello: 'world'}\n     */\n    var dir = consoleFunc('dir');\n\n    /**\n     * The post-check version of [`whilst`]{@link module:ControlFlow.whilst}. To reflect the difference in\n     * the order of operations, the arguments `test` and `iteratee` are switched.\n     *\n     * `doWhilst` is to `whilst` as `do while` is to `while` in plain JavaScript.\n     *\n     * @name doWhilst\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.whilst]{@link module:ControlFlow.whilst}\n     * @category Control Flow\n     * @param {AsyncFunction} iteratee - A function which is called each time `test`\n     * passes. Invoked with (callback).\n     * @param {AsyncFunction} test - asynchronous truth test to perform after each\n     * execution of `iteratee`. Invoked with (...args, callback), where `...args` are the\n     * non-error args from the previous callback of `iteratee`.\n     * @param {Function} [callback] - A callback which is called after the test\n     * function has failed and repeated execution of `iteratee` has stopped.\n     * `callback` will be passed an error and any arguments passed to the final\n     * `iteratee`'s callback. Invoked with (err, [results]);\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function doWhilst(iteratee, test, callback) {\n        callback = onlyOnce(callback);\n        var _fn = wrapAsync(iteratee);\n        var _test = wrapAsync(test);\n        var results;\n\n        function next(err, ...args) {\n            if (err) return callback(err);\n            if (err === false) return;\n            results = args;\n            _test(...args, check);\n        }\n\n        function check(err, truth) {\n            if (err) return callback(err);\n            if (err === false) return;\n            if (!truth) return callback(null, ...results);\n            _fn(next);\n        }\n\n        return check(null, true);\n    }\n\n    var doWhilst$1 = awaitify(doWhilst, 3);\n\n    /**\n     * Like ['doWhilst']{@link module:ControlFlow.doWhilst}, except the `test` is inverted. Note the\n     * argument ordering differs from `until`.\n     *\n     * @name doUntil\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.doWhilst]{@link module:ControlFlow.doWhilst}\n     * @category Control Flow\n     * @param {AsyncFunction} iteratee - An async function which is called each time\n     * `test` fails. Invoked with (callback).\n     * @param {AsyncFunction} test - asynchronous truth test to perform after each\n     * execution of `iteratee`. Invoked with (...args, callback), where `...args` are the\n     * non-error args from the previous callback of `iteratee`\n     * @param {Function} [callback] - A callback which is called after the test\n     * function has passed and repeated execution of `iteratee` has stopped. `callback`\n     * will be passed an error and any arguments passed to the final `iteratee`'s\n     * callback. Invoked with (err, [results]);\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function doUntil(iteratee, test, callback) {\n        const _test = wrapAsync(test);\n        return doWhilst$1(iteratee, (...args) => {\n            const cb = args.pop();\n            _test(...args, (err, truth) => cb (err, !truth));\n        }, callback);\n    }\n\n    function _withoutIndex(iteratee) {\n        return (value, index, callback) => iteratee(value, callback);\n    }\n\n    /**\n     * Applies the function `iteratee` to each item in `coll`, in parallel.\n     * The `iteratee` is called with an item from the list, and a callback for when\n     * it has finished. If the `iteratee` passes an error to its `callback`, the\n     * main `callback` (for the `each` function) is immediately called with the\n     * error.\n     *\n     * Note, that since this function applies `iteratee` to each item in parallel,\n     * there is no guarantee that the iteratee functions will complete in order.\n     *\n     * @name each\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @alias forEach\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async function to apply to\n     * each item in `coll`. Invoked with (item, callback).\n     * The array index is not passed to the iteratee.\n     * If you need the index, use `eachOf`.\n     * @param {Function} [callback] - A callback which is called when all\n     * `iteratee` functions have finished, or an error occurs. Invoked with (err).\n     * @returns {Promise} a promise, if a callback is omitted\n     * @example\n     *\n     * // dir1 is a directory that contains file1.txt, file2.txt\n     * // dir2 is a directory that contains file3.txt, file4.txt\n     * // dir3 is a directory that contains file5.txt\n     * // dir4 does not exist\n     *\n     * const fileList = [ 'dir1/file2.txt', 'dir2/file3.txt', 'dir/file5.txt'];\n     * const withMissingFileList = ['dir1/file1.txt', 'dir4/file2.txt'];\n     *\n     * // asynchronous function that deletes a file\n     * const deleteFile = function(file, callback) {\n     *     fs.unlink(file, callback);\n     * };\n     *\n     * // Using callbacks\n     * async.each(fileList, deleteFile, function(err) {\n     *     if( err ) {\n     *         console.log(err);\n     *     } else {\n     *         console.log('All files have been deleted successfully');\n     *     }\n     * });\n     *\n     * // Error Handling\n     * async.each(withMissingFileList, deleteFile, function(err){\n     *     console.log(err);\n     *     // [ Error: ENOENT: no such file or directory ]\n     *     // since dir4/file2.txt does not exist\n     *     // dir1/file1.txt could have been deleted\n     * });\n     *\n     * // Using Promises\n     * async.each(fileList, deleteFile)\n     * .then( () => {\n     *     console.log('All files have been deleted successfully');\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * // Error Handling\n     * async.each(fileList, deleteFile)\n     * .then( () => {\n     *     console.log('All files have been deleted successfully');\n     * }).catch( err => {\n     *     console.log(err);\n     *     // [ Error: ENOENT: no such file or directory ]\n     *     // since dir4/file2.txt does not exist\n     *     // dir1/file1.txt could have been deleted\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         await async.each(files, deleteFile);\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * // Error Handling\n     * async () => {\n     *     try {\n     *         await async.each(withMissingFileList, deleteFile);\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *         // since dir4/file2.txt does not exist\n     *         // dir1/file1.txt could have been deleted\n     *     }\n     * }\n     *\n     */\n    function eachLimit$2(coll, iteratee, callback) {\n        return eachOf$1(coll, _withoutIndex(wrapAsync(iteratee)), callback);\n    }\n\n    var each = awaitify(eachLimit$2, 3);\n\n    /**\n     * The same as [`each`]{@link module:Collections.each} but runs a maximum of `limit` async operations at a time.\n     *\n     * @name eachLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.each]{@link module:Collections.each}\n     * @alias forEachLimit\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * The array index is not passed to the iteratee.\n     * If you need the index, use `eachOfLimit`.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called when all\n     * `iteratee` functions have finished, or an error occurs. Invoked with (err).\n     * @returns {Promise} a promise, if a callback is omitted\n     */\n    function eachLimit(coll, limit, iteratee, callback) {\n        return eachOfLimit$2(limit)(coll, _withoutIndex(wrapAsync(iteratee)), callback);\n    }\n    var eachLimit$1 = awaitify(eachLimit, 4);\n\n    /**\n     * The same as [`each`]{@link module:Collections.each} but runs only a single async operation at a time.\n     *\n     * Note, that unlike [`each`]{@link module:Collections.each}, this function applies iteratee to each item\n     * in series and therefore the iteratee functions will complete in order.\n\n     * @name eachSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.each]{@link module:Collections.each}\n     * @alias forEachSeries\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async function to apply to each\n     * item in `coll`.\n     * The array index is not passed to the iteratee.\n     * If you need the index, use `eachOfSeries`.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called when all\n     * `iteratee` functions have finished, or an error occurs. Invoked with (err).\n     * @returns {Promise} a promise, if a callback is omitted\n     */\n    function eachSeries(coll, iteratee, callback) {\n        return eachLimit$1(coll, 1, iteratee, callback)\n    }\n    var eachSeries$1 = awaitify(eachSeries, 3);\n\n    /**\n     * Wrap an async function and ensure it calls its callback on a later tick of\n     * the event loop.  If the function already calls its callback on a next tick,\n     * no extra deferral is added. This is useful for preventing stack overflows\n     * (`RangeError: Maximum call stack size exceeded`) and generally keeping\n     * [Zalgo](http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony)\n     * contained. ES2017 `async` functions are returned as-is -- they are immune\n     * to Zalgo's corrupting influences, as they always resolve on a later tick.\n     *\n     * @name ensureAsync\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @category Util\n     * @param {AsyncFunction} fn - an async function, one that expects a node-style\n     * callback as its last argument.\n     * @returns {AsyncFunction} Returns a wrapped function with the exact same call\n     * signature as the function passed in.\n     * @example\n     *\n     * function sometimesAsync(arg, callback) {\n     *     if (cache[arg]) {\n     *         return callback(null, cache[arg]); // this would be synchronous!!\n     *     } else {\n     *         doSomeIO(arg, callback); // this IO would be asynchronous\n     *     }\n     * }\n     *\n     * // this has a risk of stack overflows if many results are cached in a row\n     * async.mapSeries(args, sometimesAsync, done);\n     *\n     * // this will defer sometimesAsync's callback if necessary,\n     * // preventing stack overflows\n     * async.mapSeries(args, async.ensureAsync(sometimesAsync), done);\n     */\n    function ensureAsync(fn) {\n        if (isAsync(fn)) return fn;\n        return function (...args/*, callback*/) {\n            var callback = args.pop();\n            var sync = true;\n            args.push((...innerArgs) => {\n                if (sync) {\n                    setImmediate$1(() => callback(...innerArgs));\n                } else {\n                    callback(...innerArgs);\n                }\n            });\n            fn.apply(this, args);\n            sync = false;\n        };\n    }\n\n    /**\n     * Returns `true` if every element in `coll` satisfies an async test. If any\n     * iteratee call returns `false`, the main `callback` is immediately called.\n     *\n     * @name every\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @alias all\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async truth test to apply to each item\n     * in the collection in parallel.\n     * The iteratee must complete with a boolean result value.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Result will be either `true` or `false`\n     * depending on the values of the async tests. Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback provided\n     * @example\n     *\n     * // dir1 is a directory that contains file1.txt, file2.txt\n     * // dir2 is a directory that contains file3.txt, file4.txt\n     * // dir3 is a directory that contains file5.txt\n     * // dir4 does not exist\n     *\n     * const fileList = ['dir1/file1.txt','dir2/file3.txt','dir3/file5.txt'];\n     * const withMissingFileList = ['file1.txt','file2.txt','file4.txt'];\n     *\n     * // asynchronous function that checks if a file exists\n     * function fileExists(file, callback) {\n     *    fs.access(file, fs.constants.F_OK, (err) => {\n     *        callback(null, !err);\n     *    });\n     * }\n     *\n     * // Using callbacks\n     * async.every(fileList, fileExists, function(err, result) {\n     *     console.log(result);\n     *     // true\n     *     // result is true since every file exists\n     * });\n     *\n     * async.every(withMissingFileList, fileExists, function(err, result) {\n     *     console.log(result);\n     *     // false\n     *     // result is false since NOT every file exists\n     * });\n     *\n     * // Using Promises\n     * async.every(fileList, fileExists)\n     * .then( result => {\n     *     console.log(result);\n     *     // true\n     *     // result is true since every file exists\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * async.every(withMissingFileList, fileExists)\n     * .then( result => {\n     *     console.log(result);\n     *     // false\n     *     // result is false since NOT every file exists\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let result = await async.every(fileList, fileExists);\n     *         console.log(result);\n     *         // true\n     *         // result is true since every file exists\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * async () => {\n     *     try {\n     *         let result = await async.every(withMissingFileList, fileExists);\n     *         console.log(result);\n     *         // false\n     *         // result is false since NOT every file exists\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function every(coll, iteratee, callback) {\n        return _createTester(bool => !bool, res => !res)(eachOf$1, coll, iteratee, callback)\n    }\n    var every$1 = awaitify(every, 3);\n\n    /**\n     * The same as [`every`]{@link module:Collections.every} but runs a maximum of `limit` async operations at a time.\n     *\n     * @name everyLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.every]{@link module:Collections.every}\n     * @alias allLimit\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - An async truth test to apply to each item\n     * in the collection in parallel.\n     * The iteratee must complete with a boolean result value.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Result will be either `true` or `false`\n     * depending on the values of the async tests. Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback provided\n     */\n    function everyLimit(coll, limit, iteratee, callback) {\n        return _createTester(bool => !bool, res => !res)(eachOfLimit$2(limit), coll, iteratee, callback)\n    }\n    var everyLimit$1 = awaitify(everyLimit, 4);\n\n    /**\n     * The same as [`every`]{@link module:Collections.every} but runs only a single async operation at a time.\n     *\n     * @name everySeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.every]{@link module:Collections.every}\n     * @alias allSeries\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async truth test to apply to each item\n     * in the collection in series.\n     * The iteratee must complete with a boolean result value.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Result will be either `true` or `false`\n     * depending on the values of the async tests. Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback provided\n     */\n    function everySeries(coll, iteratee, callback) {\n        return _createTester(bool => !bool, res => !res)(eachOfSeries$1, coll, iteratee, callback)\n    }\n    var everySeries$1 = awaitify(everySeries, 3);\n\n    function filterArray(eachfn, arr, iteratee, callback) {\n        var truthValues = new Array(arr.length);\n        eachfn(arr, (x, index, iterCb) => {\n            iteratee(x, (err, v) => {\n                truthValues[index] = !!v;\n                iterCb(err);\n            });\n        }, err => {\n            if (err) return callback(err);\n            var results = [];\n            for (var i = 0; i < arr.length; i++) {\n                if (truthValues[i]) results.push(arr[i]);\n            }\n            callback(null, results);\n        });\n    }\n\n    function filterGeneric(eachfn, coll, iteratee, callback) {\n        var results = [];\n        eachfn(coll, (x, index, iterCb) => {\n            iteratee(x, (err, v) => {\n                if (err) return iterCb(err);\n                if (v) {\n                    results.push({index, value: x});\n                }\n                iterCb(err);\n            });\n        }, err => {\n            if (err) return callback(err);\n            callback(null, results\n                .sort((a, b) => a.index - b.index)\n                .map(v => v.value));\n        });\n    }\n\n    function _filter(eachfn, coll, iteratee, callback) {\n        var filter = isArrayLike(coll) ? filterArray : filterGeneric;\n        return filter(eachfn, coll, wrapAsync(iteratee), callback);\n    }\n\n    /**\n     * Returns a new array of all the values in `coll` which pass an async truth\n     * test. This operation is performed in parallel, but the results array will be\n     * in the same order as the original.\n     *\n     * @name filter\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @alias select\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {Function} iteratee - A truth test to apply to each item in `coll`.\n     * The `iteratee` is passed a `callback(err, truthValue)`, which must be called\n     * with a boolean argument once it has completed. Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback provided\n     * @example\n     *\n     * // dir1 is a directory that contains file1.txt, file2.txt\n     * // dir2 is a directory that contains file3.txt, file4.txt\n     * // dir3 is a directory that contains file5.txt\n     *\n     * const files = ['dir1/file1.txt','dir2/file3.txt','dir3/file6.txt'];\n     *\n     * // asynchronous function that checks if a file exists\n     * function fileExists(file, callback) {\n     *    fs.access(file, fs.constants.F_OK, (err) => {\n     *        callback(null, !err);\n     *    });\n     * }\n     *\n     * // Using callbacks\n     * async.filter(files, fileExists, function(err, results) {\n     *    if(err) {\n     *        console.log(err);\n     *    } else {\n     *        console.log(results);\n     *        // [ 'dir1/file1.txt', 'dir2/file3.txt' ]\n     *        // results is now an array of the existing files\n     *    }\n     * });\n     *\n     * // Using Promises\n     * async.filter(files, fileExists)\n     * .then(results => {\n     *     console.log(results);\n     *     // [ 'dir1/file1.txt', 'dir2/file3.txt' ]\n     *     // results is now an array of the existing files\n     * }).catch(err => {\n     *     console.log(err);\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let results = await async.filter(files, fileExists);\n     *         console.log(results);\n     *         // [ 'dir1/file1.txt', 'dir2/file3.txt' ]\n     *         // results is now an array of the existing files\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function filter (coll, iteratee, callback) {\n        return _filter(eachOf$1, coll, iteratee, callback)\n    }\n    var filter$1 = awaitify(filter, 3);\n\n    /**\n     * The same as [`filter`]{@link module:Collections.filter} but runs a maximum of `limit` async operations at a\n     * time.\n     *\n     * @name filterLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.filter]{@link module:Collections.filter}\n     * @alias selectLimit\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {Function} iteratee - A truth test to apply to each item in `coll`.\n     * The `iteratee` is passed a `callback(err, truthValue)`, which must be called\n     * with a boolean argument once it has completed. Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback provided\n     */\n    function filterLimit (coll, limit, iteratee, callback) {\n        return _filter(eachOfLimit$2(limit), coll, iteratee, callback)\n    }\n    var filterLimit$1 = awaitify(filterLimit, 4);\n\n    /**\n     * The same as [`filter`]{@link module:Collections.filter} but runs only a single async operation at a time.\n     *\n     * @name filterSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.filter]{@link module:Collections.filter}\n     * @alias selectSeries\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {Function} iteratee - A truth test to apply to each item in `coll`.\n     * The `iteratee` is passed a `callback(err, truthValue)`, which must be called\n     * with a boolean argument once it has completed. Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Invoked with (err, results)\n     * @returns {Promise} a promise, if no callback provided\n     */\n    function filterSeries (coll, iteratee, callback) {\n        return _filter(eachOfSeries$1, coll, iteratee, callback)\n    }\n    var filterSeries$1 = awaitify(filterSeries, 3);\n\n    /**\n     * Calls the asynchronous function `fn` with a callback parameter that allows it\n     * to call itself again, in series, indefinitely.\n\n     * If an error is passed to the callback then `errback` is called with the\n     * error, and execution stops, otherwise it will never be called.\n     *\n     * @name forever\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {AsyncFunction} fn - an async function to call repeatedly.\n     * Invoked with (next).\n     * @param {Function} [errback] - when `fn` passes an error to it's callback,\n     * this function will be called, and execution stops. Invoked with (err).\n     * @returns {Promise} a promise that rejects if an error occurs and an errback\n     * is not passed\n     * @example\n     *\n     * async.forever(\n     *     function(next) {\n     *         // next is suitable for passing to things that need a callback(err [, whatever]);\n     *         // it will result in this function being called again.\n     *     },\n     *     function(err) {\n     *         // if next is called with a value in its first parameter, it will appear\n     *         // in here as 'err', and execution will stop.\n     *     }\n     * );\n     */\n    function forever(fn, errback) {\n        var done = onlyOnce(errback);\n        var task = wrapAsync(ensureAsync(fn));\n\n        function next(err) {\n            if (err) return done(err);\n            if (err === false) return;\n            task(next);\n        }\n        return next();\n    }\n    var forever$1 = awaitify(forever, 2);\n\n    /**\n     * The same as [`groupBy`]{@link module:Collections.groupBy} but runs a maximum of `limit` async operations at a time.\n     *\n     * @name groupByLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.groupBy]{@link module:Collections.groupBy}\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * The iteratee should complete with a `key` to group the value under.\n     * Invoked with (value, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. Result is an `Object` whoses\n     * properties are arrays of values which returned the corresponding key.\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function groupByLimit(coll, limit, iteratee, callback) {\n        var _iteratee = wrapAsync(iteratee);\n        return mapLimit$1(coll, limit, (val, iterCb) => {\n            _iteratee(val, (err, key) => {\n                if (err) return iterCb(err);\n                return iterCb(err, {key, val});\n            });\n        }, (err, mapResults) => {\n            var result = {};\n            // from MDN, handle object having an `hasOwnProperty` prop\n            var {hasOwnProperty} = Object.prototype;\n\n            for (var i = 0; i < mapResults.length; i++) {\n                if (mapResults[i]) {\n                    var {key} = mapResults[i];\n                    var {val} = mapResults[i];\n\n                    if (hasOwnProperty.call(result, key)) {\n                        result[key].push(val);\n                    } else {\n                        result[key] = [val];\n                    }\n                }\n            }\n\n            return callback(err, result);\n        });\n    }\n\n    var groupByLimit$1 = awaitify(groupByLimit, 4);\n\n    /**\n     * Returns a new object, where each value corresponds to an array of items, from\n     * `coll`, that returned the corresponding key. That is, the keys of the object\n     * correspond to the values passed to the `iteratee` callback.\n     *\n     * Note: Since this function applies the `iteratee` to each item in parallel,\n     * there is no guarantee that the `iteratee` functions will complete in order.\n     * However, the values for each key in the `result` will be in the same order as\n     * the original `coll`. For Objects, the values will roughly be in the order of\n     * the original Objects' keys (but this can vary across JavaScript engines).\n     *\n     * @name groupBy\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * The iteratee should complete with a `key` to group the value under.\n     * Invoked with (value, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. Result is an `Object` whoses\n     * properties are arrays of values which returned the corresponding key.\n     * @returns {Promise} a promise, if no callback is passed\n     * @example\n     *\n     * // dir1 is a directory that contains file1.txt, file2.txt\n     * // dir2 is a directory that contains file3.txt, file4.txt\n     * // dir3 is a directory that contains file5.txt\n     * // dir4 does not exist\n     *\n     * const files = ['dir1/file1.txt','dir2','dir4']\n     *\n     * // asynchronous function that detects file type as none, file, or directory\n     * function detectFile(file, callback) {\n     *     fs.stat(file, function(err, stat) {\n     *         if (err) {\n     *             return callback(null, 'none');\n     *         }\n     *         callback(null, stat.isDirectory() ? 'directory' : 'file');\n     *     });\n     * }\n     *\n     * //Using callbacks\n     * async.groupBy(files, detectFile, function(err, result) {\n     *     if(err) {\n     *         console.log(err);\n     *     } else {\n     *\t       console.log(result);\n     *         // {\n     *         //     file: [ 'dir1/file1.txt' ],\n     *         //     none: [ 'dir4' ],\n     *         //     directory: [ 'dir2']\n     *         // }\n     *         // result is object containing the files grouped by type\n     *     }\n     * });\n     *\n     * // Using Promises\n     * async.groupBy(files, detectFile)\n     * .then( result => {\n     *     console.log(result);\n     *     // {\n     *     //     file: [ 'dir1/file1.txt' ],\n     *     //     none: [ 'dir4' ],\n     *     //     directory: [ 'dir2']\n     *     // }\n     *     // result is object containing the files grouped by type\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let result = await async.groupBy(files, detectFile);\n     *         console.log(result);\n     *         // {\n     *         //     file: [ 'dir1/file1.txt' ],\n     *         //     none: [ 'dir4' ],\n     *         //     directory: [ 'dir2']\n     *         // }\n     *         // result is object containing the files grouped by type\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function groupBy (coll, iteratee, callback) {\n        return groupByLimit$1(coll, Infinity, iteratee, callback)\n    }\n\n    /**\n     * The same as [`groupBy`]{@link module:Collections.groupBy} but runs only a single async operation at a time.\n     *\n     * @name groupBySeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.groupBy]{@link module:Collections.groupBy}\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * The iteratee should complete with a `key` to group the value under.\n     * Invoked with (value, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. Result is an `Object` whose\n     * properties are arrays of values which returned the corresponding key.\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function groupBySeries (coll, iteratee, callback) {\n        return groupByLimit$1(coll, 1, iteratee, callback)\n    }\n\n    /**\n     * Logs the result of an `async` function to the `console`. Only works in\n     * Node.js or in browsers that support `console.log` and `console.error` (such\n     * as FF and Chrome). If multiple arguments are returned from the async\n     * function, `console.log` is called on each argument in order.\n     *\n     * @name log\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @category Util\n     * @param {AsyncFunction} function - The function you want to eventually apply\n     * all arguments to.\n     * @param {...*} arguments... - Any number of arguments to apply to the function.\n     * @example\n     *\n     * // in a module\n     * var hello = function(name, callback) {\n     *     setTimeout(function() {\n     *         callback(null, 'hello ' + name);\n     *     }, 1000);\n     * };\n     *\n     * // in the node repl\n     * node> async.log(hello, 'world');\n     * 'hello world'\n     */\n    var log = consoleFunc('log');\n\n    /**\n     * The same as [`mapValues`]{@link module:Collections.mapValues} but runs a maximum of `limit` async operations at a\n     * time.\n     *\n     * @name mapValuesLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.mapValues]{@link module:Collections.mapValues}\n     * @category Collection\n     * @param {Object} obj - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - A function to apply to each value and key\n     * in `coll`.\n     * The iteratee should complete with the transformed value as its result.\n     * Invoked with (value, key, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. `result` is a new object consisting\n     * of each key from `obj`, with each transformed value on the right-hand side.\n     * Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function mapValuesLimit(obj, limit, iteratee, callback) {\n        callback = once(callback);\n        var newObj = {};\n        var _iteratee = wrapAsync(iteratee);\n        return eachOfLimit$2(limit)(obj, (val, key, next) => {\n            _iteratee(val, key, (err, result) => {\n                if (err) return next(err);\n                newObj[key] = result;\n                next(err);\n            });\n        }, err => callback(err, newObj));\n    }\n\n    var mapValuesLimit$1 = awaitify(mapValuesLimit, 4);\n\n    /**\n     * A relative of [`map`]{@link module:Collections.map}, designed for use with objects.\n     *\n     * Produces a new Object by mapping each value of `obj` through the `iteratee`\n     * function. The `iteratee` is called each `value` and `key` from `obj` and a\n     * callback for when it has finished processing. Each of these callbacks takes\n     * two arguments: an `error`, and the transformed item from `obj`. If `iteratee`\n     * passes an error to its callback, the main `callback` (for the `mapValues`\n     * function) is immediately called with the error.\n     *\n     * Note, the order of the keys in the result is not guaranteed.  The keys will\n     * be roughly in the order they complete, (but this is very engine-specific)\n     *\n     * @name mapValues\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @category Collection\n     * @param {Object} obj - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - A function to apply to each value and key\n     * in `coll`.\n     * The iteratee should complete with the transformed value as its result.\n     * Invoked with (value, key, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. `result` is a new object consisting\n     * of each key from `obj`, with each transformed value on the right-hand side.\n     * Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback is passed\n     * @example\n     *\n     * // file1.txt is a file that is 1000 bytes in size\n     * // file2.txt is a file that is 2000 bytes in size\n     * // file3.txt is a file that is 3000 bytes in size\n     * // file4.txt does not exist\n     *\n     * const fileMap = {\n     *     f1: 'file1.txt',\n     *     f2: 'file2.txt',\n     *     f3: 'file3.txt'\n     * };\n     *\n     * const withMissingFileMap = {\n     *     f1: 'file1.txt',\n     *     f2: 'file2.txt',\n     *     f3: 'file4.txt'\n     * };\n     *\n     * // asynchronous function that returns the file size in bytes\n     * function getFileSizeInBytes(file, key, callback) {\n     *     fs.stat(file, function(err, stat) {\n     *         if (err) {\n     *             return callback(err);\n     *         }\n     *         callback(null, stat.size);\n     *     });\n     * }\n     *\n     * // Using callbacks\n     * async.mapValues(fileMap, getFileSizeInBytes, function(err, result) {\n     *     if (err) {\n     *         console.log(err);\n     *     } else {\n     *         console.log(result);\n     *         // result is now a map of file size in bytes for each file, e.g.\n     *         // {\n     *         //     f1: 1000,\n     *         //     f2: 2000,\n     *         //     f3: 3000\n     *         // }\n     *     }\n     * });\n     *\n     * // Error handling\n     * async.mapValues(withMissingFileMap, getFileSizeInBytes, function(err, result) {\n     *     if (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *     } else {\n     *         console.log(result);\n     *     }\n     * });\n     *\n     * // Using Promises\n     * async.mapValues(fileMap, getFileSizeInBytes)\n     * .then( result => {\n     *     console.log(result);\n     *     // result is now a map of file size in bytes for each file, e.g.\n     *     // {\n     *     //     f1: 1000,\n     *     //     f2: 2000,\n     *     //     f3: 3000\n     *     // }\n     * }).catch (err => {\n     *     console.log(err);\n     * });\n     *\n     * // Error Handling\n     * async.mapValues(withMissingFileMap, getFileSizeInBytes)\n     * .then( result => {\n     *     console.log(result);\n     * }).catch (err => {\n     *     console.log(err);\n     *     // [ Error: ENOENT: no such file or directory ]\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let result = await async.mapValues(fileMap, getFileSizeInBytes);\n     *         console.log(result);\n     *         // result is now a map of file size in bytes for each file, e.g.\n     *         // {\n     *         //     f1: 1000,\n     *         //     f2: 2000,\n     *         //     f3: 3000\n     *         // }\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * // Error Handling\n     * async () => {\n     *     try {\n     *         let result = await async.mapValues(withMissingFileMap, getFileSizeInBytes);\n     *         console.log(result);\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *     }\n     * }\n     *\n     */\n    function mapValues(obj, iteratee, callback) {\n        return mapValuesLimit$1(obj, Infinity, iteratee, callback)\n    }\n\n    /**\n     * The same as [`mapValues`]{@link module:Collections.mapValues} but runs only a single async operation at a time.\n     *\n     * @name mapValuesSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.mapValues]{@link module:Collections.mapValues}\n     * @category Collection\n     * @param {Object} obj - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - A function to apply to each value and key\n     * in `coll`.\n     * The iteratee should complete with the transformed value as its result.\n     * Invoked with (value, key, callback).\n     * @param {Function} [callback] - A callback which is called when all `iteratee`\n     * functions have finished, or an error occurs. `result` is a new object consisting\n     * of each key from `obj`, with each transformed value on the right-hand side.\n     * Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function mapValuesSeries(obj, iteratee, callback) {\n        return mapValuesLimit$1(obj, 1, iteratee, callback)\n    }\n\n    /**\n     * Caches the results of an async function. When creating a hash to store\n     * function results against, the callback is omitted from the hash and an\n     * optional hash function can be used.\n     *\n     * **Note: if the async function errs, the result will not be cached and\n     * subsequent calls will call the wrapped function.**\n     *\n     * If no hash function is specified, the first argument is used as a hash key,\n     * which may work reasonably if it is a string or a data type that converts to a\n     * distinct string. Note that objects and arrays will not behave reasonably.\n     * Neither will cases where the other arguments are significant. In such cases,\n     * specify your own hash function.\n     *\n     * The cache of results is exposed as the `memo` property of the function\n     * returned by `memoize`.\n     *\n     * @name memoize\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @category Util\n     * @param {AsyncFunction} fn - The async function to proxy and cache results from.\n     * @param {Function} hasher - An optional function for generating a custom hash\n     * for storing results. It has all the arguments applied to it apart from the\n     * callback, and must be synchronous.\n     * @returns {AsyncFunction} a memoized version of `fn`\n     * @example\n     *\n     * var slow_fn = function(name, callback) {\n     *     // do something\n     *     callback(null, result);\n     * };\n     * var fn = async.memoize(slow_fn);\n     *\n     * // fn can now be used as if it were slow_fn\n     * fn('some name', function() {\n     *     // callback\n     * });\n     */\n    function memoize(fn, hasher = v => v) {\n        var memo = Object.create(null);\n        var queues = Object.create(null);\n        var _fn = wrapAsync(fn);\n        var memoized = initialParams((args, callback) => {\n            var key = hasher(...args);\n            if (key in memo) {\n                setImmediate$1(() => callback(null, ...memo[key]));\n            } else if (key in queues) {\n                queues[key].push(callback);\n            } else {\n                queues[key] = [callback];\n                _fn(...args, (err, ...resultArgs) => {\n                    // #1465 don't memoize if an error occurred\n                    if (!err) {\n                        memo[key] = resultArgs;\n                    }\n                    var q = queues[key];\n                    delete queues[key];\n                    for (var i = 0, l = q.length; i < l; i++) {\n                        q[i](err, ...resultArgs);\n                    }\n                });\n            }\n        });\n        memoized.memo = memo;\n        memoized.unmemoized = fn;\n        return memoized;\n    }\n\n    /* istanbul ignore file */\n\n    /**\n     * Calls `callback` on a later loop around the event loop. In Node.js this just\n     * calls `process.nextTick`.  In the browser it will use `setImmediate` if\n     * available, otherwise `setTimeout(callback, 0)`, which means other higher\n     * priority events may precede the execution of `callback`.\n     *\n     * This is used internally for browser-compatibility purposes.\n     *\n     * @name nextTick\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @see [async.setImmediate]{@link module:Utils.setImmediate}\n     * @category Util\n     * @param {Function} callback - The function to call on a later loop around\n     * the event loop. Invoked with (args...).\n     * @param {...*} args... - any number of additional arguments to pass to the\n     * callback on the next tick.\n     * @example\n     *\n     * var call_order = [];\n     * async.nextTick(function() {\n     *     call_order.push('two');\n     *     // call_order now equals ['one','two']\n     * });\n     * call_order.push('one');\n     *\n     * async.setImmediate(function (a, b, c) {\n     *     // a, b, and c equal 1, 2, and 3\n     * }, 1, 2, 3);\n     */\n    var _defer;\n\n    if (hasNextTick) {\n        _defer = process.nextTick;\n    } else if (hasSetImmediate) {\n        _defer = setImmediate;\n    } else {\n        _defer = fallback;\n    }\n\n    var nextTick = wrap(_defer);\n\n    var _parallel = awaitify((eachfn, tasks, callback) => {\n        var results = isArrayLike(tasks) ? [] : {};\n\n        eachfn(tasks, (task, key, taskCb) => {\n            wrapAsync(task)((err, ...result) => {\n                if (result.length < 2) {\n                    [result] = result;\n                }\n                results[key] = result;\n                taskCb(err);\n            });\n        }, err => callback(err, results));\n    }, 3);\n\n    /**\n     * Run the `tasks` collection of functions in parallel, without waiting until\n     * the previous function has completed. If any of the functions pass an error to\n     * its callback, the main `callback` is immediately called with the value of the\n     * error. Once the `tasks` have completed, the results are passed to the final\n     * `callback` as an array.\n     *\n     * **Note:** `parallel` is about kicking-off I/O tasks in parallel, not about\n     * parallel execution of code.  If your tasks do not use any timers or perform\n     * any I/O, they will actually be executed in series.  Any synchronous setup\n     * sections for each task will happen one after the other.  JavaScript remains\n     * single-threaded.\n     *\n     * **Hint:** Use [`reflect`]{@link module:Utils.reflect} to continue the\n     * execution of other tasks when a task fails.\n     *\n     * It is also possible to use an object instead of an array. Each property will\n     * be run as a function and the results will be passed to the final `callback`\n     * as an object instead of an array. This can be a more readable way of handling\n     * results from {@link async.parallel}.\n     *\n     * @name parallel\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {Array|Iterable|AsyncIterable|Object} tasks - A collection of\n     * [async functions]{@link AsyncFunction} to run.\n     * Each async function can complete with any number of optional `result` values.\n     * @param {Function} [callback] - An optional callback to run once all the\n     * functions have completed successfully. This function gets a results array\n     * (or object) containing all the result arguments passed to the task callbacks.\n     * Invoked with (err, results).\n     * @returns {Promise} a promise, if a callback is not passed\n     *\n     * @example\n     *\n     * //Using Callbacks\n     * async.parallel([\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'one');\n     *         }, 200);\n     *     },\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'two');\n     *         }, 100);\n     *     }\n     * ], function(err, results) {\n     *     console.log(results);\n     *     // results is equal to ['one','two'] even though\n     *     // the second function had a shorter timeout.\n     * });\n     *\n     * // an example using an object instead of an array\n     * async.parallel({\n     *     one: function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 1);\n     *         }, 200);\n     *     },\n     *     two: function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 2);\n     *         }, 100);\n     *     }\n     * }, function(err, results) {\n     *     console.log(results);\n     *     // results is equal to: { one: 1, two: 2 }\n     * });\n     *\n     * //Using Promises\n     * async.parallel([\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'one');\n     *         }, 200);\n     *     },\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'two');\n     *         }, 100);\n     *     }\n     * ]).then(results => {\n     *     console.log(results);\n     *     // results is equal to ['one','two'] even though\n     *     // the second function had a shorter timeout.\n     * }).catch(err => {\n     *     console.log(err);\n     * });\n     *\n     * // an example using an object instead of an array\n     * async.parallel({\n     *     one: function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 1);\n     *         }, 200);\n     *     },\n     *     two: function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 2);\n     *         }, 100);\n     *     }\n     * }).then(results => {\n     *     console.log(results);\n     *     // results is equal to: { one: 1, two: 2 }\n     * }).catch(err => {\n     *     console.log(err);\n     * });\n     *\n     * //Using async/await\n     * async () => {\n     *     try {\n     *         let results = await async.parallel([\n     *             function(callback) {\n     *                 setTimeout(function() {\n     *                     callback(null, 'one');\n     *                 }, 200);\n     *             },\n     *             function(callback) {\n     *                 setTimeout(function() {\n     *                     callback(null, 'two');\n     *                 }, 100);\n     *             }\n     *         ]);\n     *         console.log(results);\n     *         // results is equal to ['one','two'] even though\n     *         // the second function had a shorter timeout.\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * // an example using an object instead of an array\n     * async () => {\n     *     try {\n     *         let results = await async.parallel({\n     *             one: function(callback) {\n     *                 setTimeout(function() {\n     *                     callback(null, 1);\n     *                 }, 200);\n     *             },\n     *            two: function(callback) {\n     *                 setTimeout(function() {\n     *                     callback(null, 2);\n     *                 }, 100);\n     *            }\n     *         });\n     *         console.log(results);\n     *         // results is equal to: { one: 1, two: 2 }\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function parallel(tasks, callback) {\n        return _parallel(eachOf$1, tasks, callback);\n    }\n\n    /**\n     * The same as [`parallel`]{@link module:ControlFlow.parallel} but runs a maximum of `limit` async operations at a\n     * time.\n     *\n     * @name parallelLimit\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.parallel]{@link module:ControlFlow.parallel}\n     * @category Control Flow\n     * @param {Array|Iterable|AsyncIterable|Object} tasks - A collection of\n     * [async functions]{@link AsyncFunction} to run.\n     * Each async function can complete with any number of optional `result` values.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {Function} [callback] - An optional callback to run once all the\n     * functions have completed successfully. This function gets a results array\n     * (or object) containing all the result arguments passed to the task callbacks.\n     * Invoked with (err, results).\n     * @returns {Promise} a promise, if a callback is not passed\n     */\n    function parallelLimit(tasks, limit, callback) {\n        return _parallel(eachOfLimit$2(limit), tasks, callback);\n    }\n\n    /**\n     * A queue of tasks for the worker function to complete.\n     * @typedef {Iterable} QueueObject\n     * @memberOf module:ControlFlow\n     * @property {Function} length - a function returning the number of items\n     * waiting to be processed. Invoke with `queue.length()`.\n     * @property {boolean} started - a boolean indicating whether or not any\n     * items have been pushed and processed by the queue.\n     * @property {Function} running - a function returning the number of items\n     * currently being processed. Invoke with `queue.running()`.\n     * @property {Function} workersList - a function returning the array of items\n     * currently being processed. Invoke with `queue.workersList()`.\n     * @property {Function} idle - a function returning false if there are items\n     * waiting or being processed, or true if not. Invoke with `queue.idle()`.\n     * @property {number} concurrency - an integer for determining how many `worker`\n     * functions should be run in parallel. This property can be changed after a\n     * `queue` is created to alter the concurrency on-the-fly.\n     * @property {number} payload - an integer that specifies how many items are\n     * passed to the worker function at a time. only applies if this is a\n     * [cargo]{@link module:ControlFlow.cargo} object\n     * @property {AsyncFunction} push - add a new task to the `queue`. Calls `callback`\n     * once the `worker` has finished processing the task. Instead of a single task,\n     * a `tasks` array can be submitted. The respective callback is used for every\n     * task in the list. Invoke with `queue.push(task, [callback])`,\n     * @property {AsyncFunction} unshift - add a new task to the front of the `queue`.\n     * Invoke with `queue.unshift(task, [callback])`.\n     * @property {AsyncFunction} pushAsync - the same as `q.push`, except this returns\n     * a promise that rejects if an error occurs.\n     * @property {AsyncFunction} unshiftAsync - the same as `q.unshift`, except this returns\n     * a promise that rejects if an error occurs.\n     * @property {Function} remove - remove items from the queue that match a test\n     * function.  The test function will be passed an object with a `data` property,\n     * and a `priority` property, if this is a\n     * [priorityQueue]{@link module:ControlFlow.priorityQueue} object.\n     * Invoked with `queue.remove(testFn)`, where `testFn` is of the form\n     * `function ({data, priority}) {}` and returns a Boolean.\n     * @property {Function} saturated - a function that sets a callback that is\n     * called when the number of running workers hits the `concurrency` limit, and\n     * further tasks will be queued.  If the callback is omitted, `q.saturated()`\n     * returns a promise for the next occurrence.\n     * @property {Function} unsaturated - a function that sets a callback that is\n     * called when the number of running workers is less than the `concurrency` &\n     * `buffer` limits, and further tasks will not be queued. If the callback is\n     * omitted, `q.unsaturated()` returns a promise for the next occurrence.\n     * @property {number} buffer - A minimum threshold buffer in order to say that\n     * the `queue` is `unsaturated`.\n     * @property {Function} empty - a function that sets a callback that is called\n     * when the last item from the `queue` is given to a `worker`. If the callback\n     * is omitted, `q.empty()` returns a promise for the next occurrence.\n     * @property {Function} drain - a function that sets a callback that is called\n     * when the last item from the `queue` has returned from the `worker`. If the\n     * callback is omitted, `q.drain()` returns a promise for the next occurrence.\n     * @property {Function} error - a function that sets a callback that is called\n     * when a task errors. Has the signature `function(error, task)`. If the\n     * callback is omitted, `error()` returns a promise that rejects on the next\n     * error.\n     * @property {boolean} paused - a boolean for determining whether the queue is\n     * in a paused state.\n     * @property {Function} pause - a function that pauses the processing of tasks\n     * until `resume()` is called. Invoke with `queue.pause()`.\n     * @property {Function} resume - a function that resumes the processing of\n     * queued tasks when the queue is paused. Invoke with `queue.resume()`.\n     * @property {Function} kill - a function that removes the `drain` callback and\n     * empties remaining tasks from the queue forcing it to go idle. No more tasks\n     * should be pushed to the queue after calling this function. Invoke with `queue.kill()`.\n     *\n     * @example\n     * const q = async.queue(worker, 2)\n     * q.push(item1)\n     * q.push(item2)\n     * q.push(item3)\n     * // queues are iterable, spread into an array to inspect\n     * const items = [...q] // [item1, item2, item3]\n     * // or use for of\n     * for (let item of q) {\n     *     console.log(item)\n     * }\n     *\n     * q.drain(() => {\n     *     console.log('all done')\n     * })\n     * // or\n     * await q.drain()\n     */\n\n    /**\n     * Creates a `queue` object with the specified `concurrency`. Tasks added to the\n     * `queue` are processed in parallel (up to the `concurrency` limit). If all\n     * `worker`s are in progress, the task is queued until one becomes available.\n     * Once a `worker` completes a `task`, that `task`'s callback is called.\n     *\n     * @name queue\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {AsyncFunction} worker - An async function for processing a queued task.\n     * If you want to handle errors from an individual task, pass a callback to\n     * `q.push()`. Invoked with (task, callback).\n     * @param {number} [concurrency=1] - An `integer` for determining how many\n     * `worker` functions should be run in parallel.  If omitted, the concurrency\n     * defaults to `1`.  If the concurrency is `0`, an error is thrown.\n     * @returns {module:ControlFlow.QueueObject} A queue object to manage the tasks. Callbacks can be\n     * attached as certain properties to listen for specific events during the\n     * lifecycle of the queue.\n     * @example\n     *\n     * // create a queue object with concurrency 2\n     * var q = async.queue(function(task, callback) {\n     *     console.log('hello ' + task.name);\n     *     callback();\n     * }, 2);\n     *\n     * // assign a callback\n     * q.drain(function() {\n     *     console.log('all items have been processed');\n     * });\n     * // or await the end\n     * await q.drain()\n     *\n     * // assign an error callback\n     * q.error(function(err, task) {\n     *     console.error('task experienced an error');\n     * });\n     *\n     * // add some items to the queue\n     * q.push({name: 'foo'}, function(err) {\n     *     console.log('finished processing foo');\n     * });\n     * // callback is optional\n     * q.push({name: 'bar'});\n     *\n     * // add some items to the queue (batch-wise)\n     * q.push([{name: 'baz'},{name: 'bay'},{name: 'bax'}], function(err) {\n     *     console.log('finished processing item');\n     * });\n     *\n     * // add some items to the front of the queue\n     * q.unshift({name: 'bar'}, function (err) {\n     *     console.log('finished processing bar');\n     * });\n     */\n    function queue (worker, concurrency) {\n        var _worker = wrapAsync(worker);\n        return queue$1((items, cb) => {\n            _worker(items[0], cb);\n        }, concurrency, 1);\n    }\n\n    // Binary min-heap implementation used for priority queue.\n    // Implementation is stable, i.e. push time is considered for equal priorities\n    class Heap {\n        constructor() {\n            this.heap = [];\n            this.pushCount = Number.MIN_SAFE_INTEGER;\n        }\n\n        get length() {\n            return this.heap.length;\n        }\n\n        empty () {\n            this.heap = [];\n            return this;\n        }\n\n        percUp(index) {\n            let p;\n\n            while (index > 0 && smaller(this.heap[index], this.heap[p=parent(index)])) {\n                let t = this.heap[index];\n                this.heap[index] = this.heap[p];\n                this.heap[p] = t;\n\n                index = p;\n            }\n        }\n\n        percDown(index) {\n            let l;\n\n            while ((l=leftChi(index)) < this.heap.length) {\n                if (l+1 < this.heap.length && smaller(this.heap[l+1], this.heap[l])) {\n                    l = l+1;\n                }\n\n                if (smaller(this.heap[index], this.heap[l])) {\n                    break;\n                }\n\n                let t = this.heap[index];\n                this.heap[index] = this.heap[l];\n                this.heap[l] = t;\n\n                index = l;\n            }\n        }\n\n        push(node) {\n            node.pushCount = ++this.pushCount;\n            this.heap.push(node);\n            this.percUp(this.heap.length-1);\n        }\n\n        unshift(node) {\n            return this.heap.push(node);\n        }\n\n        shift() {\n            let [top] = this.heap;\n\n            this.heap[0] = this.heap[this.heap.length-1];\n            this.heap.pop();\n            this.percDown(0);\n\n            return top;\n        }\n\n        toArray() {\n            return [...this];\n        }\n\n        *[Symbol.iterator] () {\n            for (let i = 0; i < this.heap.length; i++) {\n                yield this.heap[i].data;\n            }\n        }\n\n        remove (testFn) {\n            let j = 0;\n            for (let i = 0; i < this.heap.length; i++) {\n                if (!testFn(this.heap[i])) {\n                    this.heap[j] = this.heap[i];\n                    j++;\n                }\n            }\n\n            this.heap.splice(j);\n\n            for (let i = parent(this.heap.length-1); i >= 0; i--) {\n                this.percDown(i);\n            }\n\n            return this;\n        }\n    }\n\n    function leftChi(i) {\n        return (i<<1)+1;\n    }\n\n    function parent(i) {\n        return ((i+1)>>1)-1;\n    }\n\n    function smaller(x, y) {\n        if (x.priority !== y.priority) {\n            return x.priority < y.priority;\n        }\n        else {\n            return x.pushCount < y.pushCount;\n        }\n    }\n\n    /**\n     * The same as [async.queue]{@link module:ControlFlow.queue} only tasks are assigned a priority and\n     * completed in ascending priority order.\n     *\n     * @name priorityQueue\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.queue]{@link module:ControlFlow.queue}\n     * @category Control Flow\n     * @param {AsyncFunction} worker - An async function for processing a queued task.\n     * If you want to handle errors from an individual task, pass a callback to\n     * `q.push()`.\n     * Invoked with (task, callback).\n     * @param {number} concurrency - An `integer` for determining how many `worker`\n     * functions should be run in parallel.  If omitted, the concurrency defaults to\n     * `1`.  If the concurrency is `0`, an error is thrown.\n     * @returns {module:ControlFlow.QueueObject} A priorityQueue object to manage the tasks. There are three\n     * differences between `queue` and `priorityQueue` objects:\n     * * `push(task, priority, [callback])` - `priority` should be a number. If an\n     *   array of `tasks` is given, all tasks will be assigned the same priority.\n     * * `pushAsync(task, priority, [callback])` - the same as `priorityQueue.push`,\n     *   except this returns a promise that rejects if an error occurs.\n     * * The `unshift` and `unshiftAsync` methods were removed.\n     */\n    function priorityQueue(worker, concurrency) {\n        // Start with a normal queue\n        var q = queue(worker, concurrency);\n\n        var {\n            push,\n            pushAsync\n        } = q;\n\n        q._tasks = new Heap();\n        q._createTaskItem = ({data, priority}, callback) => {\n            return {\n                data,\n                priority,\n                callback\n            };\n        };\n\n        function createDataItems(tasks, priority) {\n            if (!Array.isArray(tasks)) {\n                return {data: tasks, priority};\n            }\n            return tasks.map(data => { return {data, priority}; });\n        }\n\n        // Override push to accept second parameter representing priority\n        q.push = function(data, priority = 0, callback) {\n            return push(createDataItems(data, priority), callback);\n        };\n\n        q.pushAsync = function(data, priority = 0, callback) {\n            return pushAsync(createDataItems(data, priority), callback);\n        };\n\n        // Remove unshift functions\n        delete q.unshift;\n        delete q.unshiftAsync;\n\n        return q;\n    }\n\n    /**\n     * Runs the `tasks` array of functions in parallel, without waiting until the\n     * previous function has completed. Once any of the `tasks` complete or pass an\n     * error to its callback, the main `callback` is immediately called. It's\n     * equivalent to `Promise.race()`.\n     *\n     * @name race\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {Array} tasks - An array containing [async functions]{@link AsyncFunction}\n     * to run. Each function can complete with an optional `result` value.\n     * @param {Function} callback - A callback to run once any of the functions have\n     * completed. This function gets an error or result from the first function that\n     * completed. Invoked with (err, result).\n     * @returns {Promise} a promise, if a callback is omitted\n     * @example\n     *\n     * async.race([\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'one');\n     *         }, 200);\n     *     },\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'two');\n     *         }, 100);\n     *     }\n     * ],\n     * // main callback\n     * function(err, result) {\n     *     // the result will be equal to 'two' as it finishes earlier\n     * });\n     */\n    function race(tasks, callback) {\n        callback = once(callback);\n        if (!Array.isArray(tasks)) return callback(new TypeError('First argument to race must be an array of functions'));\n        if (!tasks.length) return callback();\n        for (var i = 0, l = tasks.length; i < l; i++) {\n            wrapAsync(tasks[i])(callback);\n        }\n    }\n\n    var race$1 = awaitify(race, 2);\n\n    /**\n     * Same as [`reduce`]{@link module:Collections.reduce}, only operates on `array` in reverse order.\n     *\n     * @name reduceRight\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.reduce]{@link module:Collections.reduce}\n     * @alias foldr\n     * @category Collection\n     * @param {Array} array - A collection to iterate over.\n     * @param {*} memo - The initial state of the reduction.\n     * @param {AsyncFunction} iteratee - A function applied to each item in the\n     * array to produce the next step in the reduction.\n     * The `iteratee` should complete with the next state of the reduction.\n     * If the iteratee completes with an error, the reduction is stopped and the\n     * main `callback` is immediately called with the error.\n     * Invoked with (memo, item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Result is the reduced value. Invoked with\n     * (err, result).\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function reduceRight (array, memo, iteratee, callback) {\n        var reversed = [...array].reverse();\n        return reduce$1(reversed, memo, iteratee, callback);\n    }\n\n    /**\n     * Wraps the async function in another function that always completes with a\n     * result object, even when it errors.\n     *\n     * The result object has either the property `error` or `value`.\n     *\n     * @name reflect\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @category Util\n     * @param {AsyncFunction} fn - The async function you want to wrap\n     * @returns {Function} - A function that always passes null to it's callback as\n     * the error. The second argument to the callback will be an `object` with\n     * either an `error` or a `value` property.\n     * @example\n     *\n     * async.parallel([\n     *     async.reflect(function(callback) {\n     *         // do some stuff ...\n     *         callback(null, 'one');\n     *     }),\n     *     async.reflect(function(callback) {\n     *         // do some more stuff but error ...\n     *         callback('bad stuff happened');\n     *     }),\n     *     async.reflect(function(callback) {\n     *         // do some more stuff ...\n     *         callback(null, 'two');\n     *     })\n     * ],\n     * // optional callback\n     * function(err, results) {\n     *     // values\n     *     // results[0].value = 'one'\n     *     // results[1].error = 'bad stuff happened'\n     *     // results[2].value = 'two'\n     * });\n     */\n    function reflect(fn) {\n        var _fn = wrapAsync(fn);\n        return initialParams(function reflectOn(args, reflectCallback) {\n            args.push((error, ...cbArgs) => {\n                let retVal = {};\n                if (error) {\n                    retVal.error = error;\n                }\n                if (cbArgs.length > 0){\n                    var value = cbArgs;\n                    if (cbArgs.length <= 1) {\n                        [value] = cbArgs;\n                    }\n                    retVal.value = value;\n                }\n                reflectCallback(null, retVal);\n            });\n\n            return _fn.apply(this, args);\n        });\n    }\n\n    /**\n     * A helper function that wraps an array or an object of functions with `reflect`.\n     *\n     * @name reflectAll\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @see [async.reflect]{@link module:Utils.reflect}\n     * @category Util\n     * @param {Array|Object|Iterable} tasks - The collection of\n     * [async functions]{@link AsyncFunction} to wrap in `async.reflect`.\n     * @returns {Array} Returns an array of async functions, each wrapped in\n     * `async.reflect`\n     * @example\n     *\n     * let tasks = [\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'one');\n     *         }, 200);\n     *     },\n     *     function(callback) {\n     *         // do some more stuff but error ...\n     *         callback(new Error('bad stuff happened'));\n     *     },\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'two');\n     *         }, 100);\n     *     }\n     * ];\n     *\n     * async.parallel(async.reflectAll(tasks),\n     * // optional callback\n     * function(err, results) {\n     *     // values\n     *     // results[0].value = 'one'\n     *     // results[1].error = Error('bad stuff happened')\n     *     // results[2].value = 'two'\n     * });\n     *\n     * // an example using an object instead of an array\n     * let tasks = {\n     *     one: function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'one');\n     *         }, 200);\n     *     },\n     *     two: function(callback) {\n     *         callback('two');\n     *     },\n     *     three: function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'three');\n     *         }, 100);\n     *     }\n     * };\n     *\n     * async.parallel(async.reflectAll(tasks),\n     * // optional callback\n     * function(err, results) {\n     *     // values\n     *     // results.one.value = 'one'\n     *     // results.two.error = 'two'\n     *     // results.three.value = 'three'\n     * });\n     */\n    function reflectAll(tasks) {\n        var results;\n        if (Array.isArray(tasks)) {\n            results = tasks.map(reflect);\n        } else {\n            results = {};\n            Object.keys(tasks).forEach(key => {\n                results[key] = reflect.call(this, tasks[key]);\n            });\n        }\n        return results;\n    }\n\n    function reject$2(eachfn, arr, _iteratee, callback) {\n        const iteratee = wrapAsync(_iteratee);\n        return _filter(eachfn, arr, (value, cb) => {\n            iteratee(value, (err, v) => {\n                cb(err, !v);\n            });\n        }, callback);\n    }\n\n    /**\n     * The opposite of [`filter`]{@link module:Collections.filter}. Removes values that pass an `async` truth test.\n     *\n     * @name reject\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.filter]{@link module:Collections.filter}\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {Function} iteratee - An async truth test to apply to each item in\n     * `coll`.\n     * The should complete with a boolean value as its `result`.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback is passed\n     * @example\n     *\n     * // dir1 is a directory that contains file1.txt, file2.txt\n     * // dir2 is a directory that contains file3.txt, file4.txt\n     * // dir3 is a directory that contains file5.txt\n     *\n     * const fileList = ['dir1/file1.txt','dir2/file3.txt','dir3/file6.txt'];\n     *\n     * // asynchronous function that checks if a file exists\n     * function fileExists(file, callback) {\n     *    fs.access(file, fs.constants.F_OK, (err) => {\n     *        callback(null, !err);\n     *    });\n     * }\n     *\n     * // Using callbacks\n     * async.reject(fileList, fileExists, function(err, results) {\n     *    // [ 'dir3/file6.txt' ]\n     *    // results now equals an array of the non-existing files\n     * });\n     *\n     * // Using Promises\n     * async.reject(fileList, fileExists)\n     * .then( results => {\n     *     console.log(results);\n     *     // [ 'dir3/file6.txt' ]\n     *     // results now equals an array of the non-existing files\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let results = await async.reject(fileList, fileExists);\n     *         console.log(results);\n     *         // [ 'dir3/file6.txt' ]\n     *         // results now equals an array of the non-existing files\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function reject (coll, iteratee, callback) {\n        return reject$2(eachOf$1, coll, iteratee, callback)\n    }\n    var reject$1 = awaitify(reject, 3);\n\n    /**\n     * The same as [`reject`]{@link module:Collections.reject} but runs a maximum of `limit` async operations at a\n     * time.\n     *\n     * @name rejectLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.reject]{@link module:Collections.reject}\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {Function} iteratee - An async truth test to apply to each item in\n     * `coll`.\n     * The should complete with a boolean value as its `result`.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function rejectLimit (coll, limit, iteratee, callback) {\n        return reject$2(eachOfLimit$2(limit), coll, iteratee, callback)\n    }\n    var rejectLimit$1 = awaitify(rejectLimit, 4);\n\n    /**\n     * The same as [`reject`]{@link module:Collections.reject} but runs only a single async operation at a time.\n     *\n     * @name rejectSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.reject]{@link module:Collections.reject}\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {Function} iteratee - An async truth test to apply to each item in\n     * `coll`.\n     * The should complete with a boolean value as its `result`.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback is passed\n     */\n    function rejectSeries (coll, iteratee, callback) {\n        return reject$2(eachOfSeries$1, coll, iteratee, callback)\n    }\n    var rejectSeries$1 = awaitify(rejectSeries, 3);\n\n    function constant(value) {\n        return function () {\n            return value;\n        }\n    }\n\n    /**\n     * Attempts to get a successful response from `task` no more than `times` times\n     * before returning an error. If the task is successful, the `callback` will be\n     * passed the result of the successful task. If all attempts fail, the callback\n     * will be passed the error and result (if any) of the final attempt.\n     *\n     * @name retry\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @see [async.retryable]{@link module:ControlFlow.retryable}\n     * @param {Object|number} [opts = {times: 5, interval: 0}| 5] - Can be either an\n     * object with `times` and `interval` or a number.\n     * * `times` - The number of attempts to make before giving up.  The default\n     *   is `5`.\n     * * `interval` - The time to wait between retries, in milliseconds.  The\n     *   default is `0`. The interval may also be specified as a function of the\n     *   retry count (see example).\n     * * `errorFilter` - An optional synchronous function that is invoked on\n     *   erroneous result. If it returns `true` the retry attempts will continue;\n     *   if the function returns `false` the retry flow is aborted with the current\n     *   attempt's error and result being returned to the final callback.\n     *   Invoked with (err).\n     * * If `opts` is a number, the number specifies the number of times to retry,\n     *   with the default interval of `0`.\n     * @param {AsyncFunction} task - An async function to retry.\n     * Invoked with (callback).\n     * @param {Function} [callback] - An optional callback which is called when the\n     * task has succeeded, or after the final failed attempt. It receives the `err`\n     * and `result` arguments of the last attempt at completing the `task`. Invoked\n     * with (err, results).\n     * @returns {Promise} a promise if no callback provided\n     *\n     * @example\n     *\n     * // The `retry` function can be used as a stand-alone control flow by passing\n     * // a callback, as shown below:\n     *\n     * // try calling apiMethod 3 times\n     * async.retry(3, apiMethod, function(err, result) {\n     *     // do something with the result\n     * });\n     *\n     * // try calling apiMethod 3 times, waiting 200 ms between each retry\n     * async.retry({times: 3, interval: 200}, apiMethod, function(err, result) {\n     *     // do something with the result\n     * });\n     *\n     * // try calling apiMethod 10 times with exponential backoff\n     * // (i.e. intervals of 100, 200, 400, 800, 1600, ... milliseconds)\n     * async.retry({\n     *   times: 10,\n     *   interval: function(retryCount) {\n     *     return 50 * Math.pow(2, retryCount);\n     *   }\n     * }, apiMethod, function(err, result) {\n     *     // do something with the result\n     * });\n     *\n     * // try calling apiMethod the default 5 times no delay between each retry\n     * async.retry(apiMethod, function(err, result) {\n     *     // do something with the result\n     * });\n     *\n     * // try calling apiMethod only when error condition satisfies, all other\n     * // errors will abort the retry control flow and return to final callback\n     * async.retry({\n     *   errorFilter: function(err) {\n     *     return err.message === 'Temporary error'; // only retry on a specific error\n     *   }\n     * }, apiMethod, function(err, result) {\n     *     // do something with the result\n     * });\n     *\n     * // to retry individual methods that are not as reliable within other\n     * // control flow functions, use the `retryable` wrapper:\n     * async.auto({\n     *     users: api.getUsers.bind(api),\n     *     payments: async.retryable(3, api.getPayments.bind(api))\n     * }, function(err, results) {\n     *     // do something with the results\n     * });\n     *\n     */\n    const DEFAULT_TIMES = 5;\n    const DEFAULT_INTERVAL = 0;\n\n    function retry(opts, task, callback) {\n        var options = {\n            times: DEFAULT_TIMES,\n            intervalFunc: constant(DEFAULT_INTERVAL)\n        };\n\n        if (arguments.length < 3 && typeof opts === 'function') {\n            callback = task || promiseCallback();\n            task = opts;\n        } else {\n            parseTimes(options, opts);\n            callback = callback || promiseCallback();\n        }\n\n        if (typeof task !== 'function') {\n            throw new Error(\"Invalid arguments for async.retry\");\n        }\n\n        var _task = wrapAsync(task);\n\n        var attempt = 1;\n        function retryAttempt() {\n            _task((err, ...args) => {\n                if (err === false) return\n                if (err && attempt++ < options.times &&\n                    (typeof options.errorFilter != 'function' ||\n                        options.errorFilter(err))) {\n                    setTimeout(retryAttempt, options.intervalFunc(attempt - 1));\n                } else {\n                    callback(err, ...args);\n                }\n            });\n        }\n\n        retryAttempt();\n        return callback[PROMISE_SYMBOL]\n    }\n\n    function parseTimes(acc, t) {\n        if (typeof t === 'object') {\n            acc.times = +t.times || DEFAULT_TIMES;\n\n            acc.intervalFunc = typeof t.interval === 'function' ?\n                t.interval :\n                constant(+t.interval || DEFAULT_INTERVAL);\n\n            acc.errorFilter = t.errorFilter;\n        } else if (typeof t === 'number' || typeof t === 'string') {\n            acc.times = +t || DEFAULT_TIMES;\n        } else {\n            throw new Error(\"Invalid arguments for async.retry\");\n        }\n    }\n\n    /**\n     * A close relative of [`retry`]{@link module:ControlFlow.retry}.  This method\n     * wraps a task and makes it retryable, rather than immediately calling it\n     * with retries.\n     *\n     * @name retryable\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.retry]{@link module:ControlFlow.retry}\n     * @category Control Flow\n     * @param {Object|number} [opts = {times: 5, interval: 0}| 5] - optional\n     * options, exactly the same as from `retry`, except for a `opts.arity` that\n     * is the arity of the `task` function, defaulting to `task.length`\n     * @param {AsyncFunction} task - the asynchronous function to wrap.\n     * This function will be passed any arguments passed to the returned wrapper.\n     * Invoked with (...args, callback).\n     * @returns {AsyncFunction} The wrapped function, which when invoked, will\n     * retry on an error, based on the parameters specified in `opts`.\n     * This function will accept the same parameters as `task`.\n     * @example\n     *\n     * async.auto({\n     *     dep1: async.retryable(3, getFromFlakyService),\n     *     process: [\"dep1\", async.retryable(3, function (results, cb) {\n     *         maybeProcessData(results.dep1, cb);\n     *     })]\n     * }, callback);\n     */\n    function retryable (opts, task) {\n        if (!task) {\n            task = opts;\n            opts = null;\n        }\n        let arity = (opts && opts.arity) || task.length;\n        if (isAsync(task)) {\n            arity += 1;\n        }\n        var _task = wrapAsync(task);\n        return initialParams((args, callback) => {\n            if (args.length < arity - 1 || callback == null) {\n                args.push(callback);\n                callback = promiseCallback();\n            }\n            function taskFn(cb) {\n                _task(...args, cb);\n            }\n\n            if (opts) retry(opts, taskFn, callback);\n            else retry(taskFn, callback);\n\n            return callback[PROMISE_SYMBOL]\n        });\n    }\n\n    /**\n     * Run the functions in the `tasks` collection in series, each one running once\n     * the previous function has completed. If any functions in the series pass an\n     * error to its callback, no more functions are run, and `callback` is\n     * immediately called with the value of the error. Otherwise, `callback`\n     * receives an array of results when `tasks` have completed.\n     *\n     * It is also possible to use an object instead of an array. Each property will\n     * be run as a function, and the results will be passed to the final `callback`\n     * as an object instead of an array. This can be a more readable way of handling\n     *  results from {@link async.series}.\n     *\n     * **Note** that while many implementations preserve the order of object\n     * properties, the [ECMAScript Language Specification](http://www.ecma-international.org/ecma-262/5.1/#sec-8.6)\n     * explicitly states that\n     *\n     * > The mechanics and order of enumerating the properties is not specified.\n     *\n     * So if you rely on the order in which your series of functions are executed,\n     * and want this to work on all platforms, consider using an array.\n     *\n     * @name series\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {Array|Iterable|AsyncIterable|Object} tasks - A collection containing\n     * [async functions]{@link AsyncFunction} to run in series.\n     * Each function can complete with any number of optional `result` values.\n     * @param {Function} [callback] - An optional callback to run once all the\n     * functions have completed. This function gets a results array (or object)\n     * containing all the result arguments passed to the `task` callbacks. Invoked\n     * with (err, result).\n     * @return {Promise} a promise, if no callback is passed\n     * @example\n     *\n     * //Using Callbacks\n     * async.series([\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             // do some async task\n     *             callback(null, 'one');\n     *         }, 200);\n     *     },\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             // then do another async task\n     *             callback(null, 'two');\n     *         }, 100);\n     *     }\n     * ], function(err, results) {\n     *     console.log(results);\n     *     // results is equal to ['one','two']\n     * });\n     *\n     * // an example using objects instead of arrays\n     * async.series({\n     *     one: function(callback) {\n     *         setTimeout(function() {\n     *             // do some async task\n     *             callback(null, 1);\n     *         }, 200);\n     *     },\n     *     two: function(callback) {\n     *         setTimeout(function() {\n     *             // then do another async task\n     *             callback(null, 2);\n     *         }, 100);\n     *     }\n     * }, function(err, results) {\n     *     console.log(results);\n     *     // results is equal to: { one: 1, two: 2 }\n     * });\n     *\n     * //Using Promises\n     * async.series([\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'one');\n     *         }, 200);\n     *     },\n     *     function(callback) {\n     *         setTimeout(function() {\n     *             callback(null, 'two');\n     *         }, 100);\n     *     }\n     * ]).then(results => {\n     *     console.log(results);\n     *     // results is equal to ['one','two']\n     * }).catch(err => {\n     *     console.log(err);\n     * });\n     *\n     * // an example using an object instead of an array\n     * async.series({\n     *     one: function(callback) {\n     *         setTimeout(function() {\n     *             // do some async task\n     *             callback(null, 1);\n     *         }, 200);\n     *     },\n     *     two: function(callback) {\n     *         setTimeout(function() {\n     *             // then do another async task\n     *             callback(null, 2);\n     *         }, 100);\n     *     }\n     * }).then(results => {\n     *     console.log(results);\n     *     // results is equal to: { one: 1, two: 2 }\n     * }).catch(err => {\n     *     console.log(err);\n     * });\n     *\n     * //Using async/await\n     * async () => {\n     *     try {\n     *         let results = await async.series([\n     *             function(callback) {\n     *                 setTimeout(function() {\n     *                     // do some async task\n     *                     callback(null, 'one');\n     *                 }, 200);\n     *             },\n     *             function(callback) {\n     *                 setTimeout(function() {\n     *                     // then do another async task\n     *                     callback(null, 'two');\n     *                 }, 100);\n     *             }\n     *         ]);\n     *         console.log(results);\n     *         // results is equal to ['one','two']\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * // an example using an object instead of an array\n     * async () => {\n     *     try {\n     *         let results = await async.parallel({\n     *             one: function(callback) {\n     *                 setTimeout(function() {\n     *                     // do some async task\n     *                     callback(null, 1);\n     *                 }, 200);\n     *             },\n     *            two: function(callback) {\n     *                 setTimeout(function() {\n     *                     // then do another async task\n     *                     callback(null, 2);\n     *                 }, 100);\n     *            }\n     *         });\n     *         console.log(results);\n     *         // results is equal to: { one: 1, two: 2 }\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function series(tasks, callback) {\n        return _parallel(eachOfSeries$1, tasks, callback);\n    }\n\n    /**\n     * Returns `true` if at least one element in the `coll` satisfies an async test.\n     * If any iteratee call returns `true`, the main `callback` is immediately\n     * called.\n     *\n     * @name some\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @alias any\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async truth test to apply to each item\n     * in the collections in parallel.\n     * The iteratee should complete with a boolean `result` value.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called as soon as any\n     * iteratee returns `true`, or after all the iteratee functions have finished.\n     * Result will be either `true` or `false` depending on the values of the async\n     * tests. Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback provided\n     * @example\n     *\n     * // dir1 is a directory that contains file1.txt, file2.txt\n     * // dir2 is a directory that contains file3.txt, file4.txt\n     * // dir3 is a directory that contains file5.txt\n     * // dir4 does not exist\n     *\n     * // asynchronous function that checks if a file exists\n     * function fileExists(file, callback) {\n     *    fs.access(file, fs.constants.F_OK, (err) => {\n     *        callback(null, !err);\n     *    });\n     * }\n     *\n     * // Using callbacks\n     * async.some(['dir1/missing.txt','dir2/missing.txt','dir3/file5.txt'], fileExists,\n     *    function(err, result) {\n     *        console.log(result);\n     *        // true\n     *        // result is true since some file in the list exists\n     *    }\n     *);\n     *\n     * async.some(['dir1/missing.txt','dir2/missing.txt','dir4/missing.txt'], fileExists,\n     *    function(err, result) {\n     *        console.log(result);\n     *        // false\n     *        // result is false since none of the files exists\n     *    }\n     *);\n     *\n     * // Using Promises\n     * async.some(['dir1/missing.txt','dir2/missing.txt','dir3/file5.txt'], fileExists)\n     * .then( result => {\n     *     console.log(result);\n     *     // true\n     *     // result is true since some file in the list exists\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * async.some(['dir1/missing.txt','dir2/missing.txt','dir4/missing.txt'], fileExists)\n     * .then( result => {\n     *     console.log(result);\n     *     // false\n     *     // result is false since none of the files exists\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let result = await async.some(['dir1/missing.txt','dir2/missing.txt','dir3/file5.txt'], fileExists);\n     *         console.log(result);\n     *         // true\n     *         // result is true since some file in the list exists\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     * async () => {\n     *     try {\n     *         let result = await async.some(['dir1/missing.txt','dir2/missing.txt','dir4/missing.txt'], fileExists);\n     *         console.log(result);\n     *         // false\n     *         // result is false since none of the files exists\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function some(coll, iteratee, callback) {\n        return _createTester(Boolean, res => res)(eachOf$1, coll, iteratee, callback)\n    }\n    var some$1 = awaitify(some, 3);\n\n    /**\n     * The same as [`some`]{@link module:Collections.some} but runs a maximum of `limit` async operations at a time.\n     *\n     * @name someLimit\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.some]{@link module:Collections.some}\n     * @alias anyLimit\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - An async truth test to apply to each item\n     * in the collections in parallel.\n     * The iteratee should complete with a boolean `result` value.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called as soon as any\n     * iteratee returns `true`, or after all the iteratee functions have finished.\n     * Result will be either `true` or `false` depending on the values of the async\n     * tests. Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback provided\n     */\n    function someLimit(coll, limit, iteratee, callback) {\n        return _createTester(Boolean, res => res)(eachOfLimit$2(limit), coll, iteratee, callback)\n    }\n    var someLimit$1 = awaitify(someLimit, 4);\n\n    /**\n     * The same as [`some`]{@link module:Collections.some} but runs only a single async operation at a time.\n     *\n     * @name someSeries\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @see [async.some]{@link module:Collections.some}\n     * @alias anySeries\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async truth test to apply to each item\n     * in the collections in series.\n     * The iteratee should complete with a boolean `result` value.\n     * Invoked with (item, callback).\n     * @param {Function} [callback] - A callback which is called as soon as any\n     * iteratee returns `true`, or after all the iteratee functions have finished.\n     * Result will be either `true` or `false` depending on the values of the async\n     * tests. Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback provided\n     */\n    function someSeries(coll, iteratee, callback) {\n        return _createTester(Boolean, res => res)(eachOfSeries$1, coll, iteratee, callback)\n    }\n    var someSeries$1 = awaitify(someSeries, 3);\n\n    /**\n     * Sorts a list by the results of running each `coll` value through an async\n     * `iteratee`.\n     *\n     * @name sortBy\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {AsyncFunction} iteratee - An async function to apply to each item in\n     * `coll`.\n     * The iteratee should complete with a value to use as the sort criteria as\n     * its `result`.\n     * Invoked with (item, callback).\n     * @param {Function} callback - A callback which is called after all the\n     * `iteratee` functions have finished, or an error occurs. Results is the items\n     * from the original `coll` sorted by the values returned by the `iteratee`\n     * calls. Invoked with (err, results).\n     * @returns {Promise} a promise, if no callback passed\n     * @example\n     *\n     * // bigfile.txt is a file that is 251100 bytes in size\n     * // mediumfile.txt is a file that is 11000 bytes in size\n     * // smallfile.txt is a file that is 121 bytes in size\n     *\n     * // asynchronous function that returns the file size in bytes\n     * function getFileSizeInBytes(file, callback) {\n     *     fs.stat(file, function(err, stat) {\n     *         if (err) {\n     *             return callback(err);\n     *         }\n     *         callback(null, stat.size);\n     *     });\n     * }\n     *\n     * // Using callbacks\n     * async.sortBy(['mediumfile.txt','smallfile.txt','bigfile.txt'], getFileSizeInBytes,\n     *     function(err, results) {\n     *         if (err) {\n     *             console.log(err);\n     *         } else {\n     *             console.log(results);\n     *             // results is now the original array of files sorted by\n     *             // file size (ascending by default), e.g.\n     *             // [ 'smallfile.txt', 'mediumfile.txt', 'bigfile.txt']\n     *         }\n     *     }\n     * );\n     *\n     * // By modifying the callback parameter the\n     * // sorting order can be influenced:\n     *\n     * // ascending order\n     * async.sortBy(['mediumfile.txt','smallfile.txt','bigfile.txt'], function(file, callback) {\n     *     getFileSizeInBytes(file, function(getFileSizeErr, fileSize) {\n     *         if (getFileSizeErr) return callback(getFileSizeErr);\n     *         callback(null, fileSize);\n     *     });\n     * }, function(err, results) {\n     *         if (err) {\n     *             console.log(err);\n     *         } else {\n     *             console.log(results);\n     *             // results is now the original array of files sorted by\n     *             // file size (ascending by default), e.g.\n     *             // [ 'smallfile.txt', 'mediumfile.txt', 'bigfile.txt']\n     *         }\n     *     }\n     * );\n     *\n     * // descending order\n     * async.sortBy(['bigfile.txt','mediumfile.txt','smallfile.txt'], function(file, callback) {\n     *     getFileSizeInBytes(file, function(getFileSizeErr, fileSize) {\n     *         if (getFileSizeErr) {\n     *             return callback(getFileSizeErr);\n     *         }\n     *         callback(null, fileSize * -1);\n     *     });\n     * }, function(err, results) {\n     *         if (err) {\n     *             console.log(err);\n     *         } else {\n     *             console.log(results);\n     *             // results is now the original array of files sorted by\n     *             // file size (ascending by default), e.g.\n     *             // [ 'bigfile.txt', 'mediumfile.txt', 'smallfile.txt']\n     *         }\n     *     }\n     * );\n     *\n     * // Error handling\n     * async.sortBy(['mediumfile.txt','smallfile.txt','missingfile.txt'], getFileSizeInBytes,\n     *     function(err, results) {\n     *         if (err) {\n     *             console.log(err);\n     *             // [ Error: ENOENT: no such file or directory ]\n     *         } else {\n     *             console.log(results);\n     *         }\n     *     }\n     * );\n     *\n     * // Using Promises\n     * async.sortBy(['mediumfile.txt','smallfile.txt','bigfile.txt'], getFileSizeInBytes)\n     * .then( results => {\n     *     console.log(results);\n     *     // results is now the original array of files sorted by\n     *     // file size (ascending by default), e.g.\n     *     // [ 'smallfile.txt', 'mediumfile.txt', 'bigfile.txt']\n     * }).catch( err => {\n     *     console.log(err);\n     * });\n     *\n     * // Error handling\n     * async.sortBy(['mediumfile.txt','smallfile.txt','missingfile.txt'], getFileSizeInBytes)\n     * .then( results => {\n     *     console.log(results);\n     * }).catch( err => {\n     *     console.log(err);\n     *     // [ Error: ENOENT: no such file or directory ]\n     * });\n     *\n     * // Using async/await\n     * (async () => {\n     *     try {\n     *         let results = await async.sortBy(['bigfile.txt','mediumfile.txt','smallfile.txt'], getFileSizeInBytes);\n     *         console.log(results);\n     *         // results is now the original array of files sorted by\n     *         // file size (ascending by default), e.g.\n     *         // [ 'smallfile.txt', 'mediumfile.txt', 'bigfile.txt']\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * })();\n     *\n     * // Error handling\n     * async () => {\n     *     try {\n     *         let results = await async.sortBy(['missingfile.txt','mediumfile.txt','smallfile.txt'], getFileSizeInBytes);\n     *         console.log(results);\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *         // [ Error: ENOENT: no such file or directory ]\n     *     }\n     * }\n     *\n     */\n    function sortBy (coll, iteratee, callback) {\n        var _iteratee = wrapAsync(iteratee);\n        return map$1(coll, (x, iterCb) => {\n            _iteratee(x, (err, criteria) => {\n                if (err) return iterCb(err);\n                iterCb(err, {value: x, criteria});\n            });\n        }, (err, results) => {\n            if (err) return callback(err);\n            callback(null, results.sort(comparator).map(v => v.value));\n        });\n\n        function comparator(left, right) {\n            var a = left.criteria, b = right.criteria;\n            return a < b ? -1 : a > b ? 1 : 0;\n        }\n    }\n    var sortBy$1 = awaitify(sortBy, 3);\n\n    /**\n     * Sets a time limit on an asynchronous function. If the function does not call\n     * its callback within the specified milliseconds, it will be called with a\n     * timeout error. The code property for the error object will be `'ETIMEDOUT'`.\n     *\n     * @name timeout\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @category Util\n     * @param {AsyncFunction} asyncFn - The async function to limit in time.\n     * @param {number} milliseconds - The specified time limit.\n     * @param {*} [info] - Any variable you want attached (`string`, `object`, etc)\n     * to timeout Error for more information..\n     * @returns {AsyncFunction} Returns a wrapped function that can be used with any\n     * of the control flow functions.\n     * Invoke this function with the same parameters as you would `asyncFunc`.\n     * @example\n     *\n     * function myFunction(foo, callback) {\n     *     doAsyncTask(foo, function(err, data) {\n     *         // handle errors\n     *         if (err) return callback(err);\n     *\n     *         // do some stuff ...\n     *\n     *         // return processed data\n     *         return callback(null, data);\n     *     });\n     * }\n     *\n     * var wrapped = async.timeout(myFunction, 1000);\n     *\n     * // call `wrapped` as you would `myFunction`\n     * wrapped({ bar: 'bar' }, function(err, data) {\n     *     // if `myFunction` takes < 1000 ms to execute, `err`\n     *     // and `data` will have their expected values\n     *\n     *     // else `err` will be an Error with the code 'ETIMEDOUT'\n     * });\n     */\n    function timeout(asyncFn, milliseconds, info) {\n        var fn = wrapAsync(asyncFn);\n\n        return initialParams((args, callback) => {\n            var timedOut = false;\n            var timer;\n\n            function timeoutCallback() {\n                var name = asyncFn.name || 'anonymous';\n                var error  = new Error('Callback function \"' + name + '\" timed out.');\n                error.code = 'ETIMEDOUT';\n                if (info) {\n                    error.info = info;\n                }\n                timedOut = true;\n                callback(error);\n            }\n\n            args.push((...cbArgs) => {\n                if (!timedOut) {\n                    callback(...cbArgs);\n                    clearTimeout(timer);\n                }\n            });\n\n            // setup timer and call original function\n            timer = setTimeout(timeoutCallback, milliseconds);\n            fn(...args);\n        });\n    }\n\n    function range(size) {\n        var result = Array(size);\n        while (size--) {\n            result[size] = size;\n        }\n        return result;\n    }\n\n    /**\n     * The same as [times]{@link module:ControlFlow.times} but runs a maximum of `limit` async operations at a\n     * time.\n     *\n     * @name timesLimit\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.times]{@link module:ControlFlow.times}\n     * @category Control Flow\n     * @param {number} count - The number of times to run the function.\n     * @param {number} limit - The maximum number of async operations at a time.\n     * @param {AsyncFunction} iteratee - The async function to call `n` times.\n     * Invoked with the iteration index and a callback: (n, next).\n     * @param {Function} callback - see [async.map]{@link module:Collections.map}.\n     * @returns {Promise} a promise, if no callback is provided\n     */\n    function timesLimit(count, limit, iteratee, callback) {\n        var _iteratee = wrapAsync(iteratee);\n        return mapLimit$1(range(count), limit, _iteratee, callback);\n    }\n\n    /**\n     * Calls the `iteratee` function `n` times, and accumulates results in the same\n     * manner you would use with [map]{@link module:Collections.map}.\n     *\n     * @name times\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.map]{@link module:Collections.map}\n     * @category Control Flow\n     * @param {number} n - The number of times to run the function.\n     * @param {AsyncFunction} iteratee - The async function to call `n` times.\n     * Invoked with the iteration index and a callback: (n, next).\n     * @param {Function} callback - see {@link module:Collections.map}.\n     * @returns {Promise} a promise, if no callback is provided\n     * @example\n     *\n     * // Pretend this is some complicated async factory\n     * var createUser = function(id, callback) {\n     *     callback(null, {\n     *         id: 'user' + id\n     *     });\n     * };\n     *\n     * // generate 5 users\n     * async.times(5, function(n, next) {\n     *     createUser(n, function(err, user) {\n     *         next(err, user);\n     *     });\n     * }, function(err, users) {\n     *     // we should now have 5 users\n     * });\n     */\n    function times (n, iteratee, callback) {\n        return timesLimit(n, Infinity, iteratee, callback)\n    }\n\n    /**\n     * The same as [times]{@link module:ControlFlow.times} but runs only a single async operation at a time.\n     *\n     * @name timesSeries\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.times]{@link module:ControlFlow.times}\n     * @category Control Flow\n     * @param {number} n - The number of times to run the function.\n     * @param {AsyncFunction} iteratee - The async function to call `n` times.\n     * Invoked with the iteration index and a callback: (n, next).\n     * @param {Function} callback - see {@link module:Collections.map}.\n     * @returns {Promise} a promise, if no callback is provided\n     */\n    function timesSeries (n, iteratee, callback) {\n        return timesLimit(n, 1, iteratee, callback)\n    }\n\n    /**\n     * A relative of `reduce`.  Takes an Object or Array, and iterates over each\n     * element in parallel, each step potentially mutating an `accumulator` value.\n     * The type of the accumulator defaults to the type of collection passed in.\n     *\n     * @name transform\n     * @static\n     * @memberOf module:Collections\n     * @method\n     * @category Collection\n     * @param {Array|Iterable|AsyncIterable|Object} coll - A collection to iterate over.\n     * @param {*} [accumulator] - The initial state of the transform.  If omitted,\n     * it will default to an empty Object or Array, depending on the type of `coll`\n     * @param {AsyncFunction} iteratee - A function applied to each item in the\n     * collection that potentially modifies the accumulator.\n     * Invoked with (accumulator, item, key, callback).\n     * @param {Function} [callback] - A callback which is called after all the\n     * `iteratee` functions have finished. Result is the transformed accumulator.\n     * Invoked with (err, result).\n     * @returns {Promise} a promise, if no callback provided\n     * @example\n     *\n     * // file1.txt is a file that is 1000 bytes in size\n     * // file2.txt is a file that is 2000 bytes in size\n     * // file3.txt is a file that is 3000 bytes in size\n     *\n     * // helper function that returns human-readable size format from bytes\n     * function formatBytes(bytes, decimals = 2) {\n     *   // implementation not included for brevity\n     *   return humanReadbleFilesize;\n     * }\n     *\n     * const fileList = ['file1.txt','file2.txt','file3.txt'];\n     *\n     * // asynchronous function that returns the file size, transformed to human-readable format\n     * // e.g. 1024 bytes = 1KB, 1234 bytes = 1.21 KB, 1048576 bytes = 1MB, etc.\n     * function transformFileSize(acc, value, key, callback) {\n     *     fs.stat(value, function(err, stat) {\n     *         if (err) {\n     *             return callback(err);\n     *         }\n     *         acc[key] = formatBytes(stat.size);\n     *         callback(null);\n     *     });\n     * }\n     *\n     * // Using callbacks\n     * async.transform(fileList, transformFileSize, function(err, result) {\n     *     if(err) {\n     *         console.log(err);\n     *     } else {\n     *         console.log(result);\n     *         // [ '1000 Bytes', '1.95 KB', '2.93 KB' ]\n     *     }\n     * });\n     *\n     * // Using Promises\n     * async.transform(fileList, transformFileSize)\n     * .then(result => {\n     *     console.log(result);\n     *     // [ '1000 Bytes', '1.95 KB', '2.93 KB' ]\n     * }).catch(err => {\n     *     console.log(err);\n     * });\n     *\n     * // Using async/await\n     * (async () => {\n     *     try {\n     *         let result = await async.transform(fileList, transformFileSize);\n     *         console.log(result);\n     *         // [ '1000 Bytes', '1.95 KB', '2.93 KB' ]\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * })();\n     *\n     * @example\n     *\n     * // file1.txt is a file that is 1000 bytes in size\n     * // file2.txt is a file that is 2000 bytes in size\n     * // file3.txt is a file that is 3000 bytes in size\n     *\n     * // helper function that returns human-readable size format from bytes\n     * function formatBytes(bytes, decimals = 2) {\n     *   // implementation not included for brevity\n     *   return humanReadbleFilesize;\n     * }\n     *\n     * const fileMap = { f1: 'file1.txt', f2: 'file2.txt', f3: 'file3.txt' };\n     *\n     * // asynchronous function that returns the file size, transformed to human-readable format\n     * // e.g. 1024 bytes = 1KB, 1234 bytes = 1.21 KB, 1048576 bytes = 1MB, etc.\n     * function transformFileSize(acc, value, key, callback) {\n     *     fs.stat(value, function(err, stat) {\n     *         if (err) {\n     *             return callback(err);\n     *         }\n     *         acc[key] = formatBytes(stat.size);\n     *         callback(null);\n     *     });\n     * }\n     *\n     * // Using callbacks\n     * async.transform(fileMap, transformFileSize, function(err, result) {\n     *     if(err) {\n     *         console.log(err);\n     *     } else {\n     *         console.log(result);\n     *         // { f1: '1000 Bytes', f2: '1.95 KB', f3: '2.93 KB' }\n     *     }\n     * });\n     *\n     * // Using Promises\n     * async.transform(fileMap, transformFileSize)\n     * .then(result => {\n     *     console.log(result);\n     *     // { f1: '1000 Bytes', f2: '1.95 KB', f3: '2.93 KB' }\n     * }).catch(err => {\n     *     console.log(err);\n     * });\n     *\n     * // Using async/await\n     * async () => {\n     *     try {\n     *         let result = await async.transform(fileMap, transformFileSize);\n     *         console.log(result);\n     *         // { f1: '1000 Bytes', f2: '1.95 KB', f3: '2.93 KB' }\n     *     }\n     *     catch (err) {\n     *         console.log(err);\n     *     }\n     * }\n     *\n     */\n    function transform (coll, accumulator, iteratee, callback) {\n        if (arguments.length <= 3 && typeof accumulator === 'function') {\n            callback = iteratee;\n            iteratee = accumulator;\n            accumulator = Array.isArray(coll) ? [] : {};\n        }\n        callback = once(callback || promiseCallback());\n        var _iteratee = wrapAsync(iteratee);\n\n        eachOf$1(coll, (v, k, cb) => {\n            _iteratee(accumulator, v, k, cb);\n        }, err => callback(err, accumulator));\n        return callback[PROMISE_SYMBOL]\n    }\n\n    /**\n     * It runs each task in series but stops whenever any of the functions were\n     * successful. If one of the tasks were successful, the `callback` will be\n     * passed the result of the successful task. If all tasks fail, the callback\n     * will be passed the error and result (if any) of the final attempt.\n     *\n     * @name tryEach\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {Array|Iterable|AsyncIterable|Object} tasks - A collection containing functions to\n     * run, each function is passed a `callback(err, result)` it must call on\n     * completion with an error `err` (which can be `null`) and an optional `result`\n     * value.\n     * @param {Function} [callback] - An optional callback which is called when one\n     * of the tasks has succeeded, or all have failed. It receives the `err` and\n     * `result` arguments of the last attempt at completing the `task`. Invoked with\n     * (err, results).\n     * @returns {Promise} a promise, if no callback is passed\n     * @example\n     * async.tryEach([\n     *     function getDataFromFirstWebsite(callback) {\n     *         // Try getting the data from the first website\n     *         callback(err, data);\n     *     },\n     *     function getDataFromSecondWebsite(callback) {\n     *         // First website failed,\n     *         // Try getting the data from the backup website\n     *         callback(err, data);\n     *     }\n     * ],\n     * // optional callback\n     * function(err, results) {\n     *     Now do something with the data.\n     * });\n     *\n     */\n    function tryEach(tasks, callback) {\n        var error = null;\n        var result;\n        return eachSeries$1(tasks, (task, taskCb) => {\n            wrapAsync(task)((err, ...args) => {\n                if (err === false) return taskCb(err);\n\n                if (args.length < 2) {\n                    [result] = args;\n                } else {\n                    result = args;\n                }\n                error = err;\n                taskCb(err ? null : {});\n            });\n        }, () => callback(error, result));\n    }\n\n    var tryEach$1 = awaitify(tryEach);\n\n    /**\n     * Undoes a [memoize]{@link module:Utils.memoize}d function, reverting it to the original,\n     * unmemoized form. Handy for testing.\n     *\n     * @name unmemoize\n     * @static\n     * @memberOf module:Utils\n     * @method\n     * @see [async.memoize]{@link module:Utils.memoize}\n     * @category Util\n     * @param {AsyncFunction} fn - the memoized function\n     * @returns {AsyncFunction} a function that calls the original unmemoized function\n     */\n    function unmemoize(fn) {\n        return (...args) => {\n            return (fn.unmemoized || fn)(...args);\n        };\n    }\n\n    /**\n     * Repeatedly call `iteratee`, while `test` returns `true`. Calls `callback` when\n     * stopped, or an error occurs.\n     *\n     * @name whilst\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {AsyncFunction} test - asynchronous truth test to perform before each\n     * execution of `iteratee`. Invoked with (callback).\n     * @param {AsyncFunction} iteratee - An async function which is called each time\n     * `test` passes. Invoked with (callback).\n     * @param {Function} [callback] - A callback which is called after the test\n     * function has failed and repeated execution of `iteratee` has stopped. `callback`\n     * will be passed an error and any arguments passed to the final `iteratee`'s\n     * callback. Invoked with (err, [results]);\n     * @returns {Promise} a promise, if no callback is passed\n     * @example\n     *\n     * var count = 0;\n     * async.whilst(\n     *     function test(cb) { cb(null, count < 5); },\n     *     function iter(callback) {\n     *         count++;\n     *         setTimeout(function() {\n     *             callback(null, count);\n     *         }, 1000);\n     *     },\n     *     function (err, n) {\n     *         // 5 seconds have passed, n = 5\n     *     }\n     * );\n     */\n    function whilst(test, iteratee, callback) {\n        callback = onlyOnce(callback);\n        var _fn = wrapAsync(iteratee);\n        var _test = wrapAsync(test);\n        var results = [];\n\n        function next(err, ...rest) {\n            if (err) return callback(err);\n            results = rest;\n            if (err === false) return;\n            _test(check);\n        }\n\n        function check(err, truth) {\n            if (err) return callback(err);\n            if (err === false) return;\n            if (!truth) return callback(null, ...results);\n            _fn(next);\n        }\n\n        return _test(check);\n    }\n    var whilst$1 = awaitify(whilst, 3);\n\n    /**\n     * Repeatedly call `iteratee` until `test` returns `true`. Calls `callback` when\n     * stopped, or an error occurs. `callback` will be passed an error and any\n     * arguments passed to the final `iteratee`'s callback.\n     *\n     * The inverse of [whilst]{@link module:ControlFlow.whilst}.\n     *\n     * @name until\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @see [async.whilst]{@link module:ControlFlow.whilst}\n     * @category Control Flow\n     * @param {AsyncFunction} test - asynchronous truth test to perform before each\n     * execution of `iteratee`. Invoked with (callback).\n     * @param {AsyncFunction} iteratee - An async function which is called each time\n     * `test` fails. Invoked with (callback).\n     * @param {Function} [callback] - A callback which is called after the test\n     * function has passed and repeated execution of `iteratee` has stopped. `callback`\n     * will be passed an error and any arguments passed to the final `iteratee`'s\n     * callback. Invoked with (err, [results]);\n     * @returns {Promise} a promise, if a callback is not passed\n     *\n     * @example\n     * const results = []\n     * let finished = false\n     * async.until(function test(cb) {\n     *     cb(null, finished)\n     * }, function iter(next) {\n     *     fetchPage(url, (err, body) => {\n     *         if (err) return next(err)\n     *         results = results.concat(body.objects)\n     *         finished = !!body.next\n     *         next(err)\n     *     })\n     * }, function done (err) {\n     *     // all pages have been fetched\n     * })\n     */\n    function until(test, iteratee, callback) {\n        const _test = wrapAsync(test);\n        return whilst$1((cb) => _test((err, truth) => cb (err, !truth)), iteratee, callback);\n    }\n\n    /**\n     * Runs the `tasks` array of functions in series, each passing their results to\n     * the next in the array. However, if any of the `tasks` pass an error to their\n     * own callback, the next function is not executed, and the main `callback` is\n     * immediately called with the error.\n     *\n     * @name waterfall\n     * @static\n     * @memberOf module:ControlFlow\n     * @method\n     * @category Control Flow\n     * @param {Array} tasks - An array of [async functions]{@link AsyncFunction}\n     * to run.\n     * Each function should complete with any number of `result` values.\n     * The `result` values will be passed as arguments, in order, to the next task.\n     * @param {Function} [callback] - An optional callback to run once all the\n     * functions have completed. This will be passed the results of the last task's\n     * callback. Invoked with (err, [results]).\n     * @returns {Promise} a promise, if a callback is omitted\n     * @example\n     *\n     * async.waterfall([\n     *     function(callback) {\n     *         callback(null, 'one', 'two');\n     *     },\n     *     function(arg1, arg2, callback) {\n     *         // arg1 now equals 'one' and arg2 now equals 'two'\n     *         callback(null, 'three');\n     *     },\n     *     function(arg1, callback) {\n     *         // arg1 now equals 'three'\n     *         callback(null, 'done');\n     *     }\n     * ], function (err, result) {\n     *     // result now equals 'done'\n     * });\n     *\n     * // Or, with named functions:\n     * async.waterfall([\n     *     myFirstFunction,\n     *     mySecondFunction,\n     *     myLastFunction,\n     * ], function (err, result) {\n     *     // result now equals 'done'\n     * });\n     * function myFirstFunction(callback) {\n     *     callback(null, 'one', 'two');\n     * }\n     * function mySecondFunction(arg1, arg2, callback) {\n     *     // arg1 now equals 'one' and arg2 now equals 'two'\n     *     callback(null, 'three');\n     * }\n     * function myLastFunction(arg1, callback) {\n     *     // arg1 now equals 'three'\n     *     callback(null, 'done');\n     * }\n     */\n    function waterfall (tasks, callback) {\n        callback = once(callback);\n        if (!Array.isArray(tasks)) return callback(new Error('First argument to waterfall must be an array of functions'));\n        if (!tasks.length) return callback();\n        var taskIndex = 0;\n\n        function nextTask(args) {\n            var task = wrapAsync(tasks[taskIndex++]);\n            task(...args, onlyOnce(next));\n        }\n\n        function next(err, ...args) {\n            if (err === false) return\n            if (err || taskIndex === tasks.length) {\n                return callback(err, ...args);\n            }\n            nextTask(args);\n        }\n\n        nextTask([]);\n    }\n\n    var waterfall$1 = awaitify(waterfall);\n\n    /**\n     * An \"async function\" in the context of Async is an asynchronous function with\n     * a variable number of parameters, with the final parameter being a callback.\n     * (`function (arg1, arg2, ..., callback) {}`)\n     * The final callback is of the form `callback(err, results...)`, which must be\n     * called once the function is completed.  The callback should be called with a\n     * Error as its first argument to signal that an error occurred.\n     * Otherwise, if no error occurred, it should be called with `null` as the first\n     * argument, and any additional `result` arguments that may apply, to signal\n     * successful completion.\n     * The callback must be called exactly once, ideally on a later tick of the\n     * JavaScript event loop.\n     *\n     * This type of function is also referred to as a \"Node-style async function\",\n     * or a \"continuation passing-style function\" (CPS). Most of the methods of this\n     * library are themselves CPS/Node-style async functions, or functions that\n     * return CPS/Node-style async functions.\n     *\n     * Wherever we accept a Node-style async function, we also directly accept an\n     * [ES2017 `async` function]{@link https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/async_function}.\n     * In this case, the `async` function will not be passed a final callback\n     * argument, and any thrown error will be used as the `err` argument of the\n     * implicit callback, and the return value will be used as the `result` value.\n     * (i.e. a `rejected` of the returned Promise becomes the `err` callback\n     * argument, and a `resolved` value becomes the `result`.)\n     *\n     * Note, due to JavaScript limitations, we can only detect native `async`\n     * functions and not transpilied implementations.\n     * Your environment must have `async`/`await` support for this to work.\n     * (e.g. Node > v7.6, or a recent version of a modern browser).\n     * If you are using `async` functions through a transpiler (e.g. Babel), you\n     * must still wrap the function with [asyncify]{@link module:Utils.asyncify},\n     * because the `async function` will be compiled to an ordinary function that\n     * returns a promise.\n     *\n     * @typedef {Function} AsyncFunction\n     * @static\n     */\n\n\n    var index = {\n        apply,\n        applyEach,\n        applyEachSeries,\n        asyncify,\n        auto,\n        autoInject,\n        cargo: cargo$1,\n        cargoQueue: cargo,\n        compose,\n        concat: concat$1,\n        concatLimit: concatLimit$1,\n        concatSeries: concatSeries$1,\n        constant: constant$1,\n        detect: detect$1,\n        detectLimit: detectLimit$1,\n        detectSeries: detectSeries$1,\n        dir,\n        doUntil,\n        doWhilst: doWhilst$1,\n        each,\n        eachLimit: eachLimit$1,\n        eachOf: eachOf$1,\n        eachOfLimit: eachOfLimit$1,\n        eachOfSeries: eachOfSeries$1,\n        eachSeries: eachSeries$1,\n        ensureAsync,\n        every: every$1,\n        everyLimit: everyLimit$1,\n        everySeries: everySeries$1,\n        filter: filter$1,\n        filterLimit: filterLimit$1,\n        filterSeries: filterSeries$1,\n        forever: forever$1,\n        groupBy,\n        groupByLimit: groupByLimit$1,\n        groupBySeries,\n        log,\n        map: map$1,\n        mapLimit: mapLimit$1,\n        mapSeries: mapSeries$1,\n        mapValues,\n        mapValuesLimit: mapValuesLimit$1,\n        mapValuesSeries,\n        memoize,\n        nextTick,\n        parallel,\n        parallelLimit,\n        priorityQueue,\n        queue,\n        race: race$1,\n        reduce: reduce$1,\n        reduceRight,\n        reflect,\n        reflectAll,\n        reject: reject$1,\n        rejectLimit: rejectLimit$1,\n        rejectSeries: rejectSeries$1,\n        retry,\n        retryable,\n        seq,\n        series,\n        setImmediate: setImmediate$1,\n        some: some$1,\n        someLimit: someLimit$1,\n        someSeries: someSeries$1,\n        sortBy: sortBy$1,\n        timeout,\n        times,\n        timesLimit,\n        timesSeries,\n        transform,\n        tryEach: tryEach$1,\n        unmemoize,\n        until,\n        waterfall: waterfall$1,\n        whilst: whilst$1,\n\n        // aliases\n        all: every$1,\n        allLimit: everyLimit$1,\n        allSeries: everySeries$1,\n        any: some$1,\n        anyLimit: someLimit$1,\n        anySeries: someSeries$1,\n        find: detect$1,\n        findLimit: detectLimit$1,\n        findSeries: detectSeries$1,\n        flatMap: concat$1,\n        flatMapLimit: concatLimit$1,\n        flatMapSeries: concatSeries$1,\n        forEach: each,\n        forEachSeries: eachSeries$1,\n        forEachLimit: eachLimit$1,\n        forEachOf: eachOf$1,\n        forEachOfSeries: eachOfSeries$1,\n        forEachOfLimit: eachOfLimit$1,\n        inject: reduce$1,\n        foldl: reduce$1,\n        foldr: reduceRight,\n        select: filter$1,\n        selectLimit: filterLimit$1,\n        selectSeries: filterSeries$1,\n        wrapSync: asyncify,\n        during: whilst$1,\n        doDuring: doWhilst$1\n    };\n\n    exports.all = every$1;\n    exports.allLimit = everyLimit$1;\n    exports.allSeries = everySeries$1;\n    exports.any = some$1;\n    exports.anyLimit = someLimit$1;\n    exports.anySeries = someSeries$1;\n    exports.apply = apply;\n    exports.applyEach = applyEach;\n    exports.applyEachSeries = applyEachSeries;\n    exports.asyncify = asyncify;\n    exports.auto = auto;\n    exports.autoInject = autoInject;\n    exports.cargo = cargo$1;\n    exports.cargoQueue = cargo;\n    exports.compose = compose;\n    exports.concat = concat$1;\n    exports.concatLimit = concatLimit$1;\n    exports.concatSeries = concatSeries$1;\n    exports.constant = constant$1;\n    exports.default = index;\n    exports.detect = detect$1;\n    exports.detectLimit = detectLimit$1;\n    exports.detectSeries = detectSeries$1;\n    exports.dir = dir;\n    exports.doDuring = doWhilst$1;\n    exports.doUntil = doUntil;\n    exports.doWhilst = doWhilst$1;\n    exports.during = whilst$1;\n    exports.each = each;\n    exports.eachLimit = eachLimit$1;\n    exports.eachOf = eachOf$1;\n    exports.eachOfLimit = eachOfLimit$1;\n    exports.eachOfSeries = eachOfSeries$1;\n    exports.eachSeries = eachSeries$1;\n    exports.ensureAsync = ensureAsync;\n    exports.every = every$1;\n    exports.everyLimit = everyLimit$1;\n    exports.everySeries = everySeries$1;\n    exports.filter = filter$1;\n    exports.filterLimit = filterLimit$1;\n    exports.filterSeries = filterSeries$1;\n    exports.find = detect$1;\n    exports.findLimit = detectLimit$1;\n    exports.findSeries = detectSeries$1;\n    exports.flatMap = concat$1;\n    exports.flatMapLimit = concatLimit$1;\n    exports.flatMapSeries = concatSeries$1;\n    exports.foldl = reduce$1;\n    exports.foldr = reduceRight;\n    exports.forEach = each;\n    exports.forEachLimit = eachLimit$1;\n    exports.forEachOf = eachOf$1;\n    exports.forEachOfLimit = eachOfLimit$1;\n    exports.forEachOfSeries = eachOfSeries$1;\n    exports.forEachSeries = eachSeries$1;\n    exports.forever = forever$1;\n    exports.groupBy = groupBy;\n    exports.groupByLimit = groupByLimit$1;\n    exports.groupBySeries = groupBySeries;\n    exports.inject = reduce$1;\n    exports.log = log;\n    exports.map = map$1;\n    exports.mapLimit = mapLimit$1;\n    exports.mapSeries = mapSeries$1;\n    exports.mapValues = mapValues;\n    exports.mapValuesLimit = mapValuesLimit$1;\n    exports.mapValuesSeries = mapValuesSeries;\n    exports.memoize = memoize;\n    exports.nextTick = nextTick;\n    exports.parallel = parallel;\n    exports.parallelLimit = parallelLimit;\n    exports.priorityQueue = priorityQueue;\n    exports.queue = queue;\n    exports.race = race$1;\n    exports.reduce = reduce$1;\n    exports.reduceRight = reduceRight;\n    exports.reflect = reflect;\n    exports.reflectAll = reflectAll;\n    exports.reject = reject$1;\n    exports.rejectLimit = rejectLimit$1;\n    exports.rejectSeries = rejectSeries$1;\n    exports.retry = retry;\n    exports.retryable = retryable;\n    exports.select = filter$1;\n    exports.selectLimit = filterLimit$1;\n    exports.selectSeries = filterSeries$1;\n    exports.seq = seq;\n    exports.series = series;\n    exports.setImmediate = setImmediate$1;\n    exports.some = some$1;\n    exports.someLimit = someLimit$1;\n    exports.someSeries = someSeries$1;\n    exports.sortBy = sortBy$1;\n    exports.timeout = timeout;\n    exports.times = times;\n    exports.timesLimit = timesLimit;\n    exports.timesSeries = timesSeries;\n    exports.transform = transform;\n    exports.tryEach = tryEach$1;\n    exports.unmemoize = unmemoize;\n    exports.until = until;\n    exports.waterfall = waterfall$1;\n    exports.whilst = whilst$1;\n    exports.wrapSync = asyncify;\n\n    Object.defineProperty(exports, '__esModule', { value: true });\n\n}));\n","function isBuffer(value) {\n  return Buffer.isBuffer(value) || value instanceof Uint8Array\n}\n\nfunction isEncoding(encoding) {\n  return Buffer.isEncoding(encoding)\n}\n\nfunction alloc(size, fill, encoding) {\n  return Buffer.alloc(size, fill, encoding)\n}\n\nfunction allocUnsafe(size) {\n  return Buffer.allocUnsafe(size)\n}\n\nfunction allocUnsafeSlow(size) {\n  return Buffer.allocUnsafeSlow(size)\n}\n\nfunction byteLength(string, encoding) {\n  return Buffer.byteLength(string, encoding)\n}\n\nfunction compare(a, b) {\n  return Buffer.compare(a, b)\n}\n\nfunction concat(buffers, totalLength) {\n  return Buffer.concat(buffers, totalLength)\n}\n\nfunction copy(source, target, targetStart, start, end) {\n  return toBuffer(source).copy(target, targetStart, start, end)\n}\n\nfunction equals(a, b) {\n  return toBuffer(a).equals(b)\n}\n\nfunction fill(buffer, value, offset, end, encoding) {\n  return toBuffer(buffer).fill(value, offset, end, encoding)\n}\n\nfunction from(value, encodingOrOffset, length) {\n  return Buffer.from(value, encodingOrOffset, length)\n}\n\nfunction includes(buffer, value, byteOffset, encoding) {\n  return toBuffer(buffer).includes(value, byteOffset, encoding)\n}\n\nfunction indexOf(buffer, value, byfeOffset, encoding) {\n  return toBuffer(buffer).indexOf(value, byfeOffset, encoding)\n}\n\nfunction lastIndexOf(buffer, value, byteOffset, encoding) {\n  return toBuffer(buffer).lastIndexOf(value, byteOffset, encoding)\n}\n\nfunction swap16(buffer) {\n  return toBuffer(buffer).swap16()\n}\n\nfunction swap32(buffer) {\n  return toBuffer(buffer).swap32()\n}\n\nfunction swap64(buffer) {\n  return toBuffer(buffer).swap64()\n}\n\nfunction toBuffer(buffer) {\n  if (Buffer.isBuffer(buffer)) return buffer\n  return Buffer.from(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n}\n\nfunction toString(buffer, encoding, start, end) {\n  return toBuffer(buffer).toString(encoding, start, end)\n}\n\nfunction write(buffer, string, offset, length, encoding) {\n  return toBuffer(buffer).write(string, offset, length, encoding)\n}\n\nfunction readDoubleBE(buffer, offset) {\n  return toBuffer(buffer).readDoubleBE(offset)\n}\n\nfunction readDoubleLE(buffer, offset) {\n  return toBuffer(buffer).readDoubleLE(offset)\n}\n\nfunction readFloatBE(buffer, offset) {\n  return toBuffer(buffer).readFloatBE(offset)\n}\n\nfunction readFloatLE(buffer, offset) {\n  return toBuffer(buffer).readFloatLE(offset)\n}\n\nfunction readInt32BE(buffer, offset) {\n  return toBuffer(buffer).readInt32BE(offset)\n}\n\nfunction readInt32LE(buffer, offset) {\n  return toBuffer(buffer).readInt32LE(offset)\n}\n\nfunction readUInt32BE(buffer, offset) {\n  return toBuffer(buffer).readUInt32BE(offset)\n}\n\nfunction readUInt32LE(buffer, offset) {\n  return toBuffer(buffer).readUInt32LE(offset)\n}\n\nfunction writeDoubleBE(buffer, value, offset) {\n  return toBuffer(buffer).writeDoubleBE(value, offset)\n}\n\nfunction writeDoubleLE(buffer, value, offset) {\n  return toBuffer(buffer).writeDoubleLE(value, offset)\n}\n\nfunction writeFloatBE(buffer, value, offset) {\n  return toBuffer(buffer).writeFloatBE(value, offset)\n}\n\nfunction writeFloatLE(buffer, value, offset) {\n  return toBuffer(buffer).writeFloatLE(value, offset)\n}\n\nfunction writeInt32BE(buffer, value, offset) {\n  return toBuffer(buffer).writeInt32BE(value, offset)\n}\n\nfunction writeInt32LE(buffer, value, offset) {\n  return toBuffer(buffer).writeInt32LE(value, offset)\n}\n\nfunction writeUInt32BE(buffer, value, offset) {\n  return toBuffer(buffer).writeUInt32BE(value, offset)\n}\n\nfunction writeUInt32LE(buffer, value, offset) {\n  return toBuffer(buffer).writeUInt32LE(value, offset)\n}\n\nmodule.exports = {\n  isBuffer,\n  isEncoding,\n  alloc,\n  allocUnsafe,\n  allocUnsafeSlow,\n  byteLength,\n  compare,\n  concat,\n  copy,\n  equals,\n  fill,\n  from,\n  includes,\n  indexOf,\n  lastIndexOf,\n  swap16,\n  swap32,\n  swap64,\n  toBuffer,\n  toString,\n  write,\n  readDoubleBE,\n  readDoubleLE,\n  readFloatBE,\n  readFloatLE,\n  readInt32BE,\n  readInt32LE,\n  readUInt32BE,\n  readUInt32LE,\n  writeDoubleBE,\n  writeDoubleLE,\n  writeFloatBE,\n  writeFloatLE,\n  writeInt32BE,\n  writeInt32LE,\n  writeUInt32BE,\n  writeUInt32LE\n}\n","'use strict';\nmodule.exports = balanced;\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    if(a===b) {\n      return [ai, bi];\n    }\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n","var balanced = require('balanced-match');\n\nmodule.exports = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m) return [str];\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand(m.post, false)\n    : [''];\n\n  if (/\\$$/.test(m.pre)) {    \n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre+ '{' + m.body + '}' + post[k];\n      expansions.push(expansion);\n    }\n  } else {\n    var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n    var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n    var isSequence = isNumericSequence || isAlphaSequence;\n    var isOptions = m.body.indexOf(',') >= 0;\n    if (!isSequence && !isOptions) {\n      // {a},b}\n      if (m.post.match(/,(?!,).*\\}/)) {\n        str = m.pre + '{' + m.body + escClose + m.post;\n        return expand(str);\n      }\n      return [str];\n    }\n\n    var n;\n    if (isSequence) {\n      n = m.body.split(/\\.\\./);\n    } else {\n      n = parseCommaParts(m.body);\n      if (n.length === 1) {\n        // x{{a,b}}y ==> x{a}y x{b}y\n        n = expand(n[0], false).map(embrace);\n        if (n.length === 1) {\n          return post.map(function(p) {\n            return m.pre + n[0] + p;\n          });\n        }\n      }\n    }\n\n    // at this point, n is the parts, and we know it's not a comma set\n    // with a single entry.\n    var N;\n\n    if (isSequence) {\n      var x = numeric(n[0]);\n      var y = numeric(n[1]);\n      var width = Math.max(n[0].length, n[1].length)\n      var incr = n.length == 3\n        ? Math.abs(numeric(n[2]))\n        : 1;\n      var test = lte;\n      var reverse = y < x;\n      if (reverse) {\n        incr *= -1;\n        test = gte;\n      }\n      var pad = n.some(isPadded);\n\n      N = [];\n\n      for (var i = x; test(i, y); i += incr) {\n        var c;\n        if (isAlphaSequence) {\n          c = String.fromCharCode(i);\n          if (c === '\\\\')\n            c = '';\n        } else {\n          c = String(i);\n          if (pad) {\n            var need = width - c.length;\n            if (need > 0) {\n              var z = new Array(need + 1).join('0');\n              if (i < 0)\n                c = '-' + z + c.slice(1);\n              else\n                c = z + c;\n            }\n          }\n        }\n        N.push(c);\n      }\n    } else {\n      N = [];\n\n      for (var j = 0; j < n.length; j++) {\n        N.push.apply(N, expand(n[j], false));\n      }\n    }\n\n    for (var j = 0; j < N.length; j++) {\n      for (var k = 0; k < post.length; k++) {\n        var expansion = pre + N[j] + post[k];\n        if (!isTop || isSequence || expansion)\n          expansions.push(expansion);\n      }\n    }\n  }\n\n  return expansions;\n}\n\n","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nvar ArchiveEntry = module.exports = function() {};\n\nArchiveEntry.prototype.getName = function() {};\n\nArchiveEntry.prototype.getSize = function() {};\n\nArchiveEntry.prototype.getLastModifiedDate = function() {};\n\nArchiveEntry.prototype.isDirectory = function() {};","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nvar inherits = require('util').inherits;\nvar isStream = require('is-stream');\nvar Transform = require('readable-stream').Transform;\n\nvar ArchiveEntry = require('./archive-entry');\nvar util = require('../util');\n\nvar ArchiveOutputStream = module.exports = function(options) {\n  if (!(this instanceof ArchiveOutputStream)) {\n    return new ArchiveOutputStream(options);\n  }\n\n  Transform.call(this, options);\n\n  this.offset = 0;\n  this._archive = {\n    finish: false,\n    finished: false,\n    processing: false\n  };\n};\n\ninherits(ArchiveOutputStream, Transform);\n\nArchiveOutputStream.prototype._appendBuffer = function(zae, source, callback) {\n  // scaffold only\n};\n\nArchiveOutputStream.prototype._appendStream = function(zae, source, callback) {\n  // scaffold only\n};\n\nArchiveOutputStream.prototype._emitErrorCallback = function(err) {\n  if (err) {\n    this.emit('error', err);\n  }\n};\n\nArchiveOutputStream.prototype._finish = function(ae) {\n  // scaffold only\n};\n\nArchiveOutputStream.prototype._normalizeEntry = function(ae) {\n  // scaffold only\n};\n\nArchiveOutputStream.prototype._transform = function(chunk, encoding, callback) {\n  callback(null, chunk);\n};\n\nArchiveOutputStream.prototype.entry = function(ae, source, callback) {\n  source = source || null;\n\n  if (typeof callback !== 'function') {\n    callback = this._emitErrorCallback.bind(this);\n  }\n\n  if (!(ae instanceof ArchiveEntry)) {\n    callback(new Error('not a valid instance of ArchiveEntry'));\n    return;\n  }\n\n  if (this._archive.finish || this._archive.finished) {\n    callback(new Error('unacceptable entry after finish'));\n    return;\n  }\n\n  if (this._archive.processing) {\n    callback(new Error('already processing an entry'));\n    return;\n  }\n\n  this._archive.processing = true;\n  this._normalizeEntry(ae);\n  this._entry = ae;\n\n  source = util.normalizeInputSource(source);\n\n  if (Buffer.isBuffer(source)) {\n    this._appendBuffer(ae, source, callback);\n  } else if (isStream(source)) {\n    this._appendStream(ae, source, callback);\n  } else {\n    this._archive.processing = false;\n    callback(new Error('input source must be valid Stream or Buffer instance'));\n    return;\n  }\n\n  return this;\n};\n\nArchiveOutputStream.prototype.finish = function() {\n  if (this._archive.processing) {\n    this._archive.finish = true;\n    return;\n  }\n\n  this._finish();\n};\n\nArchiveOutputStream.prototype.getBytesWritten = function() {\n  return this.offset;\n};\n\nArchiveOutputStream.prototype.write = function(chunk, cb) {\n  if (chunk) {\n    this.offset += chunk.length;\n  }\n\n  return Transform.prototype.write.call(this, chunk, cb);\n};","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nmodule.exports = {\n  WORD: 4,\n  DWORD: 8,\n  EMPTY: Buffer.alloc(0),\n\n  SHORT: 2,\n  SHORT_MASK: 0xffff,\n  SHORT_SHIFT: 16,\n  SHORT_ZERO: Buffer.from(Array(2)),\n  LONG: 4,\n  LONG_ZERO: Buffer.from(Array(4)),\n\n  MIN_VERSION_INITIAL: 10,\n  MIN_VERSION_DATA_DESCRIPTOR: 20,\n  MIN_VERSION_ZIP64: 45,\n  VERSION_MADEBY: 45,\n\n  METHOD_STORED: 0,\n  METHOD_DEFLATED: 8,\n\n  PLATFORM_UNIX: 3,\n  PLATFORM_FAT: 0,\n\n  SIG_LFH: 0x04034b50,\n  SIG_DD: 0x08074b50,\n  SIG_CFH: 0x02014b50,\n  SIG_EOCD: 0x06054b50,\n  SIG_ZIP64_EOCD: 0x06064B50,\n  SIG_ZIP64_EOCD_LOC: 0x07064B50,\n\n  ZIP64_MAGIC_SHORT: 0xffff,\n  ZIP64_MAGIC: 0xffffffff,\n  ZIP64_EXTRA_ID: 0x0001,\n\n  ZLIB_NO_COMPRESSION: 0,\n  ZLIB_BEST_SPEED: 1,\n  ZLIB_BEST_COMPRESSION: 9,\n  ZLIB_DEFAULT_COMPRESSION: -1,\n\n  MODE_MASK: 0xFFF,\n  DEFAULT_FILE_MODE: 33188, // 010644 = -rw-r--r-- = S_IFREG | S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH\n  DEFAULT_DIR_MODE: 16877,  // 040755 = drwxr-xr-x = S_IFDIR | S_IRWXU | S_IRGRP | S_IXGRP | S_IROTH | S_IXOTH\n\n  EXT_FILE_ATTR_DIR: 1106051088,  // 010173200020 = drwxr-xr-x = (((S_IFDIR | 0755) << 16) | S_DOS_D)\n  EXT_FILE_ATTR_FILE: 2175008800, // 020151000040 = -rw-r--r-- = (((S_IFREG | 0644) << 16) | S_DOS_A) >>> 0\n\n  // Unix file types\n  S_IFMT: 61440,   // 0170000 type of file mask\n  S_IFIFO: 4096,   // 010000 named pipe (fifo)\n  S_IFCHR: 8192,   // 020000 character special\n  S_IFDIR: 16384,  // 040000 directory\n  S_IFBLK: 24576,  // 060000 block special\n  S_IFREG: 32768,  // 0100000 regular\n  S_IFLNK: 40960,  // 0120000 symbolic link\n  S_IFSOCK: 49152, // 0140000 socket\n\n  // DOS file type flags\n  S_DOS_A: 32, // 040 Archive\n  S_DOS_D: 16, // 020 Directory\n  S_DOS_V: 8,  // 010 Volume\n  S_DOS_S: 4,  // 04 System\n  S_DOS_H: 2,  // 02 Hidden\n  S_DOS_R: 1   // 01 Read Only\n};\n","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nvar zipUtil = require('./util');\n\nvar DATA_DESCRIPTOR_FLAG = 1 << 3;\nvar ENCRYPTION_FLAG = 1 << 0;\nvar NUMBER_OF_SHANNON_FANO_TREES_FLAG = 1 << 2;\nvar SLIDING_DICTIONARY_SIZE_FLAG = 1 << 1;\nvar STRONG_ENCRYPTION_FLAG = 1 << 6;\nvar UFT8_NAMES_FLAG = 1 << 11;\n\nvar GeneralPurposeBit = module.exports = function() {\n  if (!(this instanceof GeneralPurposeBit)) {\n    return new GeneralPurposeBit();\n  }\n\n  this.descriptor = false;\n  this.encryption = false;\n  this.utf8 = false;\n  this.numberOfShannonFanoTrees = 0;\n  this.strongEncryption = false;\n  this.slidingDictionarySize = 0;\n\n  return this;\n};\n\nGeneralPurposeBit.prototype.encode = function() {\n  return zipUtil.getShortBytes(\n    (this.descriptor ? DATA_DESCRIPTOR_FLAG : 0) |\n    (this.utf8 ? UFT8_NAMES_FLAG : 0) |\n    (this.encryption ? ENCRYPTION_FLAG : 0) |\n    (this.strongEncryption ? STRONG_ENCRYPTION_FLAG : 0)\n  );\n};\n\nGeneralPurposeBit.prototype.parse = function(buf, offset) {\n  var flag = zipUtil.getShortBytesValue(buf, offset);\n  var gbp = new GeneralPurposeBit();\n\n  gbp.useDataDescriptor((flag & DATA_DESCRIPTOR_FLAG) !== 0);\n  gbp.useUTF8ForNames((flag & UFT8_NAMES_FLAG) !== 0);\n  gbp.useStrongEncryption((flag & STRONG_ENCRYPTION_FLAG) !== 0);\n  gbp.useEncryption((flag & ENCRYPTION_FLAG) !== 0);\n  gbp.setSlidingDictionarySize((flag & SLIDING_DICTIONARY_SIZE_FLAG) !== 0 ? 8192 : 4096);\n  gbp.setNumberOfShannonFanoTrees((flag & NUMBER_OF_SHANNON_FANO_TREES_FLAG) !== 0 ? 3 : 2);\n\n  return gbp;\n};\n\nGeneralPurposeBit.prototype.setNumberOfShannonFanoTrees = function(n) {\n  this.numberOfShannonFanoTrees = n;\n};\n\nGeneralPurposeBit.prototype.getNumberOfShannonFanoTrees = function() {\n  return this.numberOfShannonFanoTrees;\n};\n\nGeneralPurposeBit.prototype.setSlidingDictionarySize = function(n) {\n  this.slidingDictionarySize = n;\n};\n\nGeneralPurposeBit.prototype.getSlidingDictionarySize = function() {\n  return this.slidingDictionarySize;\n};\n\nGeneralPurposeBit.prototype.useDataDescriptor = function(b) {\n  this.descriptor = b;\n};\n\nGeneralPurposeBit.prototype.usesDataDescriptor = function() {\n  return this.descriptor;\n};\n\nGeneralPurposeBit.prototype.useEncryption = function(b) {\n  this.encryption = b;\n};\n\nGeneralPurposeBit.prototype.usesEncryption = function() {\n  return this.encryption;\n};\n\nGeneralPurposeBit.prototype.useStrongEncryption = function(b) {\n  this.strongEncryption = b;\n};\n\nGeneralPurposeBit.prototype.usesStrongEncryption = function() {\n  return this.strongEncryption;\n};\n\nGeneralPurposeBit.prototype.useUTF8ForNames = function(b) {\n  this.utf8 = b;\n};\n\nGeneralPurposeBit.prototype.usesUTF8ForNames = function() {\n  return this.utf8;\n};","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nmodule.exports = {\n    /**\n     * Bits used for permissions (and sticky bit)\n     */\n    PERM_MASK: 4095, // 07777\n\n    /**\n     * Bits used to indicate the filesystem object type.\n     */\n    FILE_TYPE_FLAG: 61440, // 0170000\n\n    /**\n     * Indicates symbolic links.\n     */\n    LINK_FLAG: 40960, // 0120000\n\n    /**\n     * Indicates plain files.\n     */\n    FILE_FLAG: 32768, // 0100000\n\n    /**\n     * Indicates directories.\n     */\n    DIR_FLAG: 16384, // 040000\n\n    // ----------------------------------------------------------\n    // somewhat arbitrary choices that are quite common for shared\n    // installations\n    // -----------------------------------------------------------\n\n    /**\n     * Default permissions for symbolic links.\n     */\n    DEFAULT_LINK_PERM: 511, // 0777\n\n    /**\n     * Default permissions for directories.\n     */\n    DEFAULT_DIR_PERM: 493, // 0755\n\n    /**\n     * Default permissions for plain files.\n     */\n    DEFAULT_FILE_PERM: 420 // 0644\n};","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nvar util = module.exports = {};\n\nutil.dateToDos = function(d, forceLocalTime) {\n  forceLocalTime = forceLocalTime || false;\n\n  var year = forceLocalTime ? d.getFullYear() : d.getUTCFullYear();\n\n  if (year < 1980) {\n    return 2162688; // 1980-1-1 00:00:00\n  } else if (year >= 2044) {\n    return 2141175677; // 2043-12-31 23:59:58\n  }\n\n  var val = {\n    year: year,\n    month: forceLocalTime ? d.getMonth() : d.getUTCMonth(),\n    date: forceLocalTime ? d.getDate() : d.getUTCDate(),\n    hours: forceLocalTime ? d.getHours() : d.getUTCHours(),\n    minutes: forceLocalTime ? d.getMinutes() : d.getUTCMinutes(),\n    seconds: forceLocalTime ? d.getSeconds() : d.getUTCSeconds()\n  };\n\n  return ((val.year - 1980) << 25) | ((val.month + 1) << 21) | (val.date << 16) |\n    (val.hours << 11) | (val.minutes << 5) | (val.seconds / 2);\n};\n\nutil.dosToDate = function(dos) {\n  return new Date(((dos >> 25) & 0x7f) + 1980, ((dos >> 21) & 0x0f) - 1, (dos >> 16) & 0x1f, (dos >> 11) & 0x1f, (dos >> 5) & 0x3f, (dos & 0x1f) << 1);\n};\n\nutil.fromDosTime = function(buf) {\n  return util.dosToDate(buf.readUInt32LE(0));\n};\n\nutil.getEightBytes = function(v) {\n  var buf = Buffer.alloc(8);\n  buf.writeUInt32LE(v % 0x0100000000, 0);\n  buf.writeUInt32LE((v / 0x0100000000) | 0, 4);\n\n  return buf;\n};\n\nutil.getShortBytes = function(v) {\n  var buf = Buffer.alloc(2);\n  buf.writeUInt16LE((v & 0xFFFF) >>> 0, 0);\n\n  return buf;\n};\n\nutil.getShortBytesValue = function(buf, offset) {\n  return buf.readUInt16LE(offset);\n};\n\nutil.getLongBytes = function(v) {\n  var buf = Buffer.alloc(4);\n  buf.writeUInt32LE((v & 0xFFFFFFFF) >>> 0, 0);\n\n  return buf;\n};\n\nutil.getLongBytesValue = function(buf, offset) {\n  return buf.readUInt32LE(offset);\n};\n\nutil.toDosTime = function(d) {\n  return util.getLongBytes(util.dateToDos(d));\n};","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nvar inherits = require('util').inherits;\nvar normalizePath = require('normalize-path');\n\nvar ArchiveEntry = require('../archive-entry');\nvar GeneralPurposeBit = require('./general-purpose-bit');\nvar UnixStat = require('./unix-stat');\n\nvar constants = require('./constants');\nvar zipUtil = require('./util');\n\nvar ZipArchiveEntry = module.exports = function(name) {\n  if (!(this instanceof ZipArchiveEntry)) {\n    return new ZipArchiveEntry(name);\n  }\n\n  ArchiveEntry.call(this);\n\n  this.platform = constants.PLATFORM_FAT;\n  this.method = -1;\n\n  this.name = null;\n  this.size = 0;\n  this.csize = 0;\n  this.gpb = new GeneralPurposeBit();\n  this.crc = 0;\n  this.time = -1;\n\n  this.minver = constants.MIN_VERSION_INITIAL;\n  this.mode = -1;\n  this.extra = null;\n  this.exattr = 0;\n  this.inattr = 0;\n  this.comment = null;\n\n  if (name) {\n    this.setName(name);\n  }\n};\n\ninherits(ZipArchiveEntry, ArchiveEntry);\n\n/**\n * Returns the extra fields related to the entry.\n *\n * @returns {Buffer}\n */\nZipArchiveEntry.prototype.getCentralDirectoryExtra = function() {\n  return this.getExtra();\n};\n\n/**\n * Returns the comment set for the entry.\n *\n * @returns {string}\n */\nZipArchiveEntry.prototype.getComment = function() {\n  return this.comment !== null ? this.comment : '';\n};\n\n/**\n * Returns the compressed size of the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getCompressedSize = function() {\n  return this.csize;\n};\n\n/**\n * Returns the CRC32 digest for the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getCrc = function() {\n  return this.crc;\n};\n\n/**\n * Returns the external file attributes for the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getExternalAttributes = function() {\n  return this.exattr;\n};\n\n/**\n * Returns the extra fields related to the entry.\n *\n * @returns {Buffer}\n */\nZipArchiveEntry.prototype.getExtra = function() {\n  return this.extra !== null ? this.extra : constants.EMPTY;\n};\n\n/**\n * Returns the general purpose bits related to the entry.\n *\n * @returns {GeneralPurposeBit}\n */\nZipArchiveEntry.prototype.getGeneralPurposeBit = function() {\n  return this.gpb;\n};\n\n/**\n * Returns the internal file attributes for the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getInternalAttributes = function() {\n  return this.inattr;\n};\n\n/**\n * Returns the last modified date of the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getLastModifiedDate = function() {\n  return this.getTime();\n};\n\n/**\n * Returns the extra fields related to the entry.\n *\n * @returns {Buffer}\n */\nZipArchiveEntry.prototype.getLocalFileDataExtra = function() {\n  return this.getExtra();\n};\n\n/**\n * Returns the compression method used on the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getMethod = function() {\n  return this.method;\n};\n\n/**\n * Returns the filename of the entry.\n *\n * @returns {string}\n */\nZipArchiveEntry.prototype.getName = function() {\n  return this.name;\n};\n\n/**\n * Returns the platform on which the entry was made.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getPlatform = function() {\n  return this.platform;\n};\n\n/**\n * Returns the size of the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getSize = function() {\n  return this.size;\n};\n\n/**\n * Returns a date object representing the last modified date of the entry.\n *\n * @returns {number|Date}\n */\nZipArchiveEntry.prototype.getTime = function() {\n  return this.time !== -1 ? zipUtil.dosToDate(this.time) : -1;\n};\n\n/**\n * Returns the DOS timestamp for the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getTimeDos = function() {\n  return this.time !== -1 ? this.time : 0;\n};\n\n/**\n * Returns the UNIX file permissions for the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getUnixMode = function() {\n  return this.platform !== constants.PLATFORM_UNIX ? 0 : ((this.getExternalAttributes() >> constants.SHORT_SHIFT) & constants.SHORT_MASK);\n};\n\n/**\n * Returns the version of ZIP needed to extract the entry.\n *\n * @returns {number}\n */\nZipArchiveEntry.prototype.getVersionNeededToExtract = function() {\n  return this.minver;\n};\n\n/**\n * Sets the comment of the entry.\n *\n * @param comment\n */\nZipArchiveEntry.prototype.setComment = function(comment) {\n  if (Buffer.byteLength(comment) !== comment.length) {\n    this.getGeneralPurposeBit().useUTF8ForNames(true);\n  }\n\n  this.comment = comment;\n};\n\n/**\n * Sets the compressed size of the entry.\n *\n * @param size\n */\nZipArchiveEntry.prototype.setCompressedSize = function(size) {\n  if (size < 0) {\n    throw new Error('invalid entry compressed size');\n  }\n\n  this.csize = size;\n};\n\n/**\n * Sets the checksum of the entry.\n *\n * @param crc\n */\nZipArchiveEntry.prototype.setCrc = function(crc) {\n  if (crc < 0) {\n    throw new Error('invalid entry crc32');\n  }\n\n  this.crc = crc;\n};\n\n/**\n * Sets the external file attributes of the entry.\n *\n * @param attr\n */\nZipArchiveEntry.prototype.setExternalAttributes = function(attr) {\n  this.exattr = attr >>> 0;\n};\n\n/**\n * Sets the extra fields related to the entry.\n *\n * @param extra\n */\nZipArchiveEntry.prototype.setExtra = function(extra) {\n  this.extra = extra;\n};\n\n/**\n * Sets the general purpose bits related to the entry.\n *\n * @param gpb\n */\nZipArchiveEntry.prototype.setGeneralPurposeBit = function(gpb) {\n  if (!(gpb instanceof GeneralPurposeBit)) {\n    throw new Error('invalid entry GeneralPurposeBit');\n  }\n\n  this.gpb = gpb;\n};\n\n/**\n * Sets the internal file attributes of the entry.\n *\n * @param attr\n */\nZipArchiveEntry.prototype.setInternalAttributes = function(attr) {\n  this.inattr = attr;\n};\n\n/**\n * Sets the compression method of the entry.\n *\n * @param method\n */\nZipArchiveEntry.prototype.setMethod = function(method) {\n  if (method < 0) {\n    throw new Error('invalid entry compression method');\n  }\n\n  this.method = method;\n};\n\n/**\n * Sets the name of the entry.\n *\n * @param name\n * @param prependSlash\n */\nZipArchiveEntry.prototype.setName = function(name, prependSlash = false) {\n  name = normalizePath(name, false)\n    .replace(/^\\w+:/, '')\n    .replace(/^(\\.\\.\\/|\\/)+/, '');\n\n  if (prependSlash) {\n    name = `/${name}`;\n  }\n\n  if (Buffer.byteLength(name) !== name.length) {\n    this.getGeneralPurposeBit().useUTF8ForNames(true);\n  }\n\n  this.name = name;\n};\n\n/**\n * Sets the platform on which the entry was made.\n *\n * @param platform\n */\nZipArchiveEntry.prototype.setPlatform = function(platform) {\n  this.platform = platform;\n};\n\n/**\n * Sets the size of the entry.\n *\n * @param size\n */\nZipArchiveEntry.prototype.setSize = function(size) {\n  if (size < 0) {\n    throw new Error('invalid entry size');\n  }\n\n  this.size = size;\n};\n\n/**\n * Sets the time of the entry.\n *\n * @param time\n * @param forceLocalTime\n */\nZipArchiveEntry.prototype.setTime = function(time, forceLocalTime) {\n  if (!(time instanceof Date)) {\n    throw new Error('invalid entry time');\n  }\n\n  this.time = zipUtil.dateToDos(time, forceLocalTime);\n};\n\n/**\n * Sets the UNIX file permissions for the entry.\n *\n * @param mode\n */\nZipArchiveEntry.prototype.setUnixMode = function(mode) {\n  mode |= this.isDirectory() ? constants.S_IFDIR : constants.S_IFREG;\n\n  var extattr = 0;\n  extattr |= (mode << constants.SHORT_SHIFT) | (this.isDirectory() ? constants.S_DOS_D : constants.S_DOS_A);\n\n  this.setExternalAttributes(extattr);\n  this.mode = mode & constants.MODE_MASK;\n  this.platform = constants.PLATFORM_UNIX;\n};\n\n/**\n * Sets the version of ZIP needed to extract this entry.\n *\n * @param minver\n */\nZipArchiveEntry.prototype.setVersionNeededToExtract = function(minver) {\n  this.minver = minver;\n};\n\n/**\n * Returns true if this entry represents a directory.\n *\n * @returns {boolean}\n */\nZipArchiveEntry.prototype.isDirectory = function() {\n  return this.getName().slice(-1) === '/';\n};\n\n/**\n * Returns true if this entry represents a unix symlink,\n * in which case the entry's content contains the target path\n * for the symlink.\n *\n * @returns {boolean}\n */\nZipArchiveEntry.prototype.isUnixSymlink = function() {\n  return (this.getUnixMode() & UnixStat.FILE_TYPE_FLAG) === UnixStat.LINK_FLAG;\n};\n\n/**\n * Returns true if this entry is using the ZIP64 extension of ZIP.\n *\n * @returns {boolean}\n */\nZipArchiveEntry.prototype.isZip64 = function() {\n  return this.csize > constants.ZIP64_MAGIC || this.size > constants.ZIP64_MAGIC;\n};\n","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nvar inherits = require('util').inherits;\nvar crc32 = require('crc-32');\nvar {CRC32Stream} = require('crc32-stream');\nvar {DeflateCRC32Stream} = require('crc32-stream');\n\nvar ArchiveOutputStream = require('../archive-output-stream');\nvar ZipArchiveEntry = require('./zip-archive-entry');\nvar GeneralPurposeBit = require('./general-purpose-bit');\n\nvar constants = require('./constants');\nvar util = require('../../util');\nvar zipUtil = require('./util');\n\nvar ZipArchiveOutputStream = module.exports = function(options) {\n  if (!(this instanceof ZipArchiveOutputStream)) {\n    return new ZipArchiveOutputStream(options);\n  }\n\n  options = this.options = this._defaults(options);\n\n  ArchiveOutputStream.call(this, options);\n\n  this._entry = null;\n  this._entries = [];\n  this._archive = {\n    centralLength: 0,\n    centralOffset: 0,\n    comment: '',\n    finish: false,\n    finished: false,\n    processing: false,\n    forceZip64: options.forceZip64,\n    forceLocalTime: options.forceLocalTime\n  };\n};\n\ninherits(ZipArchiveOutputStream, ArchiveOutputStream);\n\nZipArchiveOutputStream.prototype._afterAppend = function(ae) {\n  this._entries.push(ae);\n\n  if (ae.getGeneralPurposeBit().usesDataDescriptor()) {\n    this._writeDataDescriptor(ae);\n  }\n\n  this._archive.processing = false;\n  this._entry = null;\n\n  if (this._archive.finish && !this._archive.finished) {\n    this._finish();\n  }\n};\n\nZipArchiveOutputStream.prototype._appendBuffer = function(ae, source, callback) {\n  if (source.length === 0) {\n    ae.setMethod(constants.METHOD_STORED);\n  }\n\n  var method = ae.getMethod();\n\n  if (method === constants.METHOD_STORED) {\n    ae.setSize(source.length);\n    ae.setCompressedSize(source.length);\n    ae.setCrc(crc32.buf(source) >>> 0);\n  }\n\n  this._writeLocalFileHeader(ae);\n\n  if (method === constants.METHOD_STORED) {\n    this.write(source);\n    this._afterAppend(ae);\n    callback(null, ae);\n    return;\n  } else if (method === constants.METHOD_DEFLATED) {\n    this._smartStream(ae, callback).end(source);\n    return;\n  } else {\n    callback(new Error('compression method ' + method + ' not implemented'));\n    return;\n  }\n};\n\nZipArchiveOutputStream.prototype._appendStream = function(ae, source, callback) {\n  ae.getGeneralPurposeBit().useDataDescriptor(true);\n  ae.setVersionNeededToExtract(constants.MIN_VERSION_DATA_DESCRIPTOR);\n\n  this._writeLocalFileHeader(ae);\n\n  var smart = this._smartStream(ae, callback);\n  source.once('error', function(err) {\n    smart.emit('error', err);\n    smart.end();\n  })\n  source.pipe(smart);\n};\n\nZipArchiveOutputStream.prototype._defaults = function(o) {\n  if (typeof o !== 'object') {\n    o = {};\n  }\n\n  if (typeof o.zlib !== 'object') {\n    o.zlib = {};\n  }\n\n  if (typeof o.zlib.level !== 'number') {\n    o.zlib.level = constants.ZLIB_BEST_SPEED;\n  }\n\n  o.forceZip64 = !!o.forceZip64;\n  o.forceLocalTime = !!o.forceLocalTime;\n\n  return o;\n};\n\nZipArchiveOutputStream.prototype._finish = function() {\n  this._archive.centralOffset = this.offset;\n\n  this._entries.forEach(function(ae) {\n    this._writeCentralFileHeader(ae);\n  }.bind(this));\n\n  this._archive.centralLength = this.offset - this._archive.centralOffset;\n\n  if (this.isZip64()) {\n    this._writeCentralDirectoryZip64();\n  }\n\n  this._writeCentralDirectoryEnd();\n\n  this._archive.processing = false;\n  this._archive.finish = true;\n  this._archive.finished = true;\n  this.end();\n};\n\nZipArchiveOutputStream.prototype._normalizeEntry = function(ae) {\n  if (ae.getMethod() === -1) {\n    ae.setMethod(constants.METHOD_DEFLATED);\n  }\n\n  if (ae.getMethod() === constants.METHOD_DEFLATED) {\n    ae.getGeneralPurposeBit().useDataDescriptor(true);\n    ae.setVersionNeededToExtract(constants.MIN_VERSION_DATA_DESCRIPTOR);\n  }\n\n  if (ae.getTime() === -1) {\n    ae.setTime(new Date(), this._archive.forceLocalTime);\n  }\n\n  ae._offsets = {\n    file: 0,\n    data: 0,\n    contents: 0,\n  };\n};\n\nZipArchiveOutputStream.prototype._smartStream = function(ae, callback) {\n  var deflate = ae.getMethod() === constants.METHOD_DEFLATED;\n  var process = deflate ? new DeflateCRC32Stream(this.options.zlib) : new CRC32Stream();\n  var error = null;\n\n  function handleStuff() {\n    var digest = process.digest().readUInt32BE(0);\n    ae.setCrc(digest);\n    ae.setSize(process.size());\n    ae.setCompressedSize(process.size(true));\n    this._afterAppend(ae);\n    callback(error, ae);\n  }\n\n  process.once('end', handleStuff.bind(this));\n  process.once('error', function(err) {\n    error = err;\n  });\n\n  process.pipe(this, { end: false });\n\n  return process;\n};\n\nZipArchiveOutputStream.prototype._writeCentralDirectoryEnd = function() {\n  var records = this._entries.length;\n  var size = this._archive.centralLength;\n  var offset = this._archive.centralOffset;\n\n  if (this.isZip64()) {\n    records = constants.ZIP64_MAGIC_SHORT;\n    size = constants.ZIP64_MAGIC;\n    offset = constants.ZIP64_MAGIC;\n  }\n\n  // signature\n  this.write(zipUtil.getLongBytes(constants.SIG_EOCD));\n\n  // disk numbers\n  this.write(constants.SHORT_ZERO);\n  this.write(constants.SHORT_ZERO);\n\n  // number of entries\n  this.write(zipUtil.getShortBytes(records));\n  this.write(zipUtil.getShortBytes(records));\n\n  // length and location of CD\n  this.write(zipUtil.getLongBytes(size));\n  this.write(zipUtil.getLongBytes(offset));\n\n  // archive comment\n  var comment = this.getComment();\n  var commentLength = Buffer.byteLength(comment);\n  this.write(zipUtil.getShortBytes(commentLength));\n  this.write(comment);\n};\n\nZipArchiveOutputStream.prototype._writeCentralDirectoryZip64 = function() {\n  // signature\n  this.write(zipUtil.getLongBytes(constants.SIG_ZIP64_EOCD));\n\n  // size of the ZIP64 EOCD record\n  this.write(zipUtil.getEightBytes(44));\n\n  // version made by\n  this.write(zipUtil.getShortBytes(constants.MIN_VERSION_ZIP64));\n\n  // version to extract\n  this.write(zipUtil.getShortBytes(constants.MIN_VERSION_ZIP64));\n\n  // disk numbers\n  this.write(constants.LONG_ZERO);\n  this.write(constants.LONG_ZERO);\n\n  // number of entries\n  this.write(zipUtil.getEightBytes(this._entries.length));\n  this.write(zipUtil.getEightBytes(this._entries.length));\n\n  // length and location of CD\n  this.write(zipUtil.getEightBytes(this._archive.centralLength));\n  this.write(zipUtil.getEightBytes(this._archive.centralOffset));\n\n  // extensible data sector\n  // not implemented at this time\n\n  // end of central directory locator\n  this.write(zipUtil.getLongBytes(constants.SIG_ZIP64_EOCD_LOC));\n\n  // disk number holding the ZIP64 EOCD record\n  this.write(constants.LONG_ZERO);\n\n  // relative offset of the ZIP64 EOCD record\n  this.write(zipUtil.getEightBytes(this._archive.centralOffset + this._archive.centralLength));\n\n  // total number of disks\n  this.write(zipUtil.getLongBytes(1));\n};\n\nZipArchiveOutputStream.prototype._writeCentralFileHeader = function(ae) {\n  var gpb = ae.getGeneralPurposeBit();\n  var method = ae.getMethod();\n  var fileOffset = ae._offsets.file;\n\n  var size = ae.getSize();\n  var compressedSize = ae.getCompressedSize();\n\n  if (ae.isZip64() || fileOffset > constants.ZIP64_MAGIC) {\n    size = constants.ZIP64_MAGIC;\n    compressedSize = constants.ZIP64_MAGIC;\n    fileOffset = constants.ZIP64_MAGIC;\n\n    ae.setVersionNeededToExtract(constants.MIN_VERSION_ZIP64);\n\n    var extraBuf = Buffer.concat([\n      zipUtil.getShortBytes(constants.ZIP64_EXTRA_ID),\n      zipUtil.getShortBytes(24),\n      zipUtil.getEightBytes(ae.getSize()),\n      zipUtil.getEightBytes(ae.getCompressedSize()),\n      zipUtil.getEightBytes(ae._offsets.file)\n    ], 28);\n\n    ae.setExtra(extraBuf);\n  }\n\n  // signature\n  this.write(zipUtil.getLongBytes(constants.SIG_CFH));\n\n  // version made by\n  this.write(zipUtil.getShortBytes((ae.getPlatform() << 8) | constants.VERSION_MADEBY));\n\n  // version to extract and general bit flag\n  this.write(zipUtil.getShortBytes(ae.getVersionNeededToExtract()));\n  this.write(gpb.encode());\n\n  // compression method\n  this.write(zipUtil.getShortBytes(method));\n\n  // datetime\n  this.write(zipUtil.getLongBytes(ae.getTimeDos()));\n\n  // crc32 checksum\n  this.write(zipUtil.getLongBytes(ae.getCrc()));\n\n  // sizes\n  this.write(zipUtil.getLongBytes(compressedSize));\n  this.write(zipUtil.getLongBytes(size));\n\n  var name = ae.getName();\n  var comment = ae.getComment();\n  var extra = ae.getCentralDirectoryExtra();\n\n  if (gpb.usesUTF8ForNames()) {\n    name = Buffer.from(name);\n    comment = Buffer.from(comment);\n  }\n\n  // name length\n  this.write(zipUtil.getShortBytes(name.length));\n\n  // extra length\n  this.write(zipUtil.getShortBytes(extra.length));\n\n  // comments length\n  this.write(zipUtil.getShortBytes(comment.length));\n\n  // disk number start\n  this.write(constants.SHORT_ZERO);\n\n  // internal attributes\n  this.write(zipUtil.getShortBytes(ae.getInternalAttributes()));\n\n  // external attributes\n  this.write(zipUtil.getLongBytes(ae.getExternalAttributes()));\n\n  // relative offset of LFH\n  this.write(zipUtil.getLongBytes(fileOffset));\n\n  // name\n  this.write(name);\n\n  // extra\n  this.write(extra);\n\n  // comment\n  this.write(comment);\n};\n\nZipArchiveOutputStream.prototype._writeDataDescriptor = function(ae) {\n  // signature\n  this.write(zipUtil.getLongBytes(constants.SIG_DD));\n\n  // crc32 checksum\n  this.write(zipUtil.getLongBytes(ae.getCrc()));\n\n  // sizes\n  if (ae.isZip64()) {\n    this.write(zipUtil.getEightBytes(ae.getCompressedSize()));\n    this.write(zipUtil.getEightBytes(ae.getSize()));\n  } else {\n    this.write(zipUtil.getLongBytes(ae.getCompressedSize()));\n    this.write(zipUtil.getLongBytes(ae.getSize()));\n  }\n};\n\nZipArchiveOutputStream.prototype._writeLocalFileHeader = function(ae) {\n  var gpb = ae.getGeneralPurposeBit();\n  var method = ae.getMethod();\n  var name = ae.getName();\n  var extra = ae.getLocalFileDataExtra();\n\n  if (ae.isZip64()) {\n    gpb.useDataDescriptor(true);\n    ae.setVersionNeededToExtract(constants.MIN_VERSION_ZIP64);\n  }\n\n  if (gpb.usesUTF8ForNames()) {\n    name = Buffer.from(name);\n  }\n\n  ae._offsets.file = this.offset;\n\n  // signature\n  this.write(zipUtil.getLongBytes(constants.SIG_LFH));\n\n  // version to extract and general bit flag\n  this.write(zipUtil.getShortBytes(ae.getVersionNeededToExtract()));\n  this.write(gpb.encode());\n\n  // compression method\n  this.write(zipUtil.getShortBytes(method));\n\n  // datetime\n  this.write(zipUtil.getLongBytes(ae.getTimeDos()));\n\n  ae._offsets.data = this.offset;\n\n  // crc32 checksum and sizes\n  if (gpb.usesDataDescriptor()) {\n    this.write(constants.LONG_ZERO);\n    this.write(constants.LONG_ZERO);\n    this.write(constants.LONG_ZERO);\n  } else {\n    this.write(zipUtil.getLongBytes(ae.getCrc()));\n    this.write(zipUtil.getLongBytes(ae.getCompressedSize()));\n    this.write(zipUtil.getLongBytes(ae.getSize()));\n  }\n\n  // name length\n  this.write(zipUtil.getShortBytes(name.length));\n\n  // extra length\n  this.write(zipUtil.getShortBytes(extra.length));\n\n  // name\n  this.write(name);\n\n  // extra\n  this.write(extra);\n\n  ae._offsets.contents = this.offset;\n};\n\nZipArchiveOutputStream.prototype.getComment = function(comment) {\n  return this._archive.comment !== null ? this._archive.comment : '';\n};\n\nZipArchiveOutputStream.prototype.isZip64 = function() {\n  return this._archive.forceZip64 || this._entries.length > constants.ZIP64_MAGIC_SHORT || this._archive.centralLength > constants.ZIP64_MAGIC || this._archive.centralOffset > constants.ZIP64_MAGIC;\n};\n\nZipArchiveOutputStream.prototype.setComment = function(comment) {\n  this._archive.comment = comment;\n};\n","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nmodule.exports = {\n  ArchiveEntry: require('./archivers/archive-entry'),\n  ZipArchiveEntry: require('./archivers/zip/zip-archive-entry'),\n  ArchiveOutputStream: require('./archivers/archive-output-stream'),\n  ZipArchiveOutputStream: require('./archivers/zip/zip-archive-output-stream')\n};","/**\n * node-compress-commons\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-compress-commons/blob/master/LICENSE-MIT\n */\nvar Stream = require('stream').Stream;\nvar PassThrough = require('readable-stream').PassThrough;\nvar isStream = require('is-stream');\n\nvar util = module.exports = {};\n\nutil.normalizeInputSource = function(source) {\n  if (source === null) {\n    return Buffer.alloc(0);\n  } else if (typeof source === 'string') {\n    return Buffer.from(source);\n  } else if (isStream(source) && !source._readableState) {\n    var normalized = new PassThrough();\n    source.pipe(normalized);\n\n    return normalized;\n  }\n\n  return source;\n};","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = require('buffer').Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n","/*! crc32.js (C) 2014-present SheetJS -- http://sheetjs.com */\n/* vim: set ts=2: */\n/*exported CRC32 */\nvar CRC32;\n(function (factory) {\n\t/*jshint ignore:start */\n\t/*eslint-disable */\n\tif(typeof DO_NOT_EXPORT_CRC === 'undefined') {\n\t\tif('object' === typeof exports) {\n\t\t\tfactory(exports);\n\t\t} else if ('function' === typeof define && define.amd) {\n\t\t\tdefine(function () {\n\t\t\t\tvar module = {};\n\t\t\t\tfactory(module);\n\t\t\t\treturn module;\n\t\t\t});\n\t\t} else {\n\t\t\tfactory(CRC32 = {});\n\t\t}\n\t} else {\n\t\tfactory(CRC32 = {});\n\t}\n\t/*eslint-enable */\n\t/*jshint ignore:end */\n}(function(CRC32) {\nCRC32.version = '1.2.2';\n/*global Int32Array */\nfunction signed_crc_table() {\n\tvar c = 0, table = new Array(256);\n\n\tfor(var n =0; n != 256; ++n){\n\t\tc = n;\n\t\tc = ((c&1) ? (-306674912 ^ (c >>> 1)) : (c >>> 1));\n\t\tc = ((c&1) ? (-306674912 ^ (c >>> 1)) : (c >>> 1));\n\t\tc = ((c&1) ? (-306674912 ^ (c >>> 1)) : (c >>> 1));\n\t\tc = ((c&1) ? (-306674912 ^ (c >>> 1)) : (c >>> 1));\n\t\tc = ((c&1) ? (-306674912 ^ (c >>> 1)) : (c >>> 1));\n\t\tc = ((c&1) ? (-306674912 ^ (c >>> 1)) : (c >>> 1));\n\t\tc = ((c&1) ? (-306674912 ^ (c >>> 1)) : (c >>> 1));\n\t\tc = ((c&1) ? (-306674912 ^ (c >>> 1)) : (c >>> 1));\n\t\ttable[n] = c;\n\t}\n\n\treturn typeof Int32Array !== 'undefined' ? new Int32Array(table) : table;\n}\n\nvar T0 = signed_crc_table();\nfunction slice_by_16_tables(T) {\n\tvar c = 0, v = 0, n = 0, table = typeof Int32Array !== 'undefined' ? new Int32Array(4096) : new Array(4096) ;\n\n\tfor(n = 0; n != 256; ++n) table[n] = T[n];\n\tfor(n = 0; n != 256; ++n) {\n\t\tv = T[n];\n\t\tfor(c = 256 + n; c < 4096; c += 256) v = table[c] = (v >>> 8) ^ T[v & 0xFF];\n\t}\n\tvar out = [];\n\tfor(n = 1; n != 16; ++n) out[n - 1] = typeof Int32Array !== 'undefined' ? table.subarray(n * 256, n * 256 + 256) : table.slice(n * 256, n * 256 + 256);\n\treturn out;\n}\nvar TT = slice_by_16_tables(T0);\nvar T1 = TT[0],  T2 = TT[1],  T3 = TT[2],  T4 = TT[3],  T5 = TT[4];\nvar T6 = TT[5],  T7 = TT[6],  T8 = TT[7],  T9 = TT[8],  Ta = TT[9];\nvar Tb = TT[10], Tc = TT[11], Td = TT[12], Te = TT[13], Tf = TT[14];\nfunction crc32_bstr(bstr, seed) {\n\tvar C = seed ^ -1;\n\tfor(var i = 0, L = bstr.length; i < L;) C = (C>>>8) ^ T0[(C^bstr.charCodeAt(i++))&0xFF];\n\treturn ~C;\n}\n\nfunction crc32_buf(B, seed) {\n\tvar C = seed ^ -1, L = B.length - 15, i = 0;\n\tfor(; i < L;) C =\n\t\tTf[B[i++] ^ (C & 255)] ^\n\t\tTe[B[i++] ^ ((C >> 8) & 255)] ^\n\t\tTd[B[i++] ^ ((C >> 16) & 255)] ^\n\t\tTc[B[i++] ^ (C >>> 24)] ^\n\t\tTb[B[i++]] ^ Ta[B[i++]] ^ T9[B[i++]] ^ T8[B[i++]] ^\n\t\tT7[B[i++]] ^ T6[B[i++]] ^ T5[B[i++]] ^ T4[B[i++]] ^\n\t\tT3[B[i++]] ^ T2[B[i++]] ^ T1[B[i++]] ^ T0[B[i++]];\n\tL += 15;\n\twhile(i < L) C = (C>>>8) ^ T0[(C^B[i++])&0xFF];\n\treturn ~C;\n}\n\nfunction crc32_str(str, seed) {\n\tvar C = seed ^ -1;\n\tfor(var i = 0, L = str.length, c = 0, d = 0; i < L;) {\n\t\tc = str.charCodeAt(i++);\n\t\tif(c < 0x80) {\n\t\t\tC = (C>>>8) ^ T0[(C^c)&0xFF];\n\t\t} else if(c < 0x800) {\n\t\t\tC = (C>>>8) ^ T0[(C ^ (192|((c>>6)&31)))&0xFF];\n\t\t\tC = (C>>>8) ^ T0[(C ^ (128|(c&63)))&0xFF];\n\t\t} else if(c >= 0xD800 && c < 0xE000) {\n\t\t\tc = (c&1023)+64; d = str.charCodeAt(i++)&1023;\n\t\t\tC = (C>>>8) ^ T0[(C ^ (240|((c>>8)&7)))&0xFF];\n\t\t\tC = (C>>>8) ^ T0[(C ^ (128|((c>>2)&63)))&0xFF];\n\t\t\tC = (C>>>8) ^ T0[(C ^ (128|((d>>6)&15)|((c&3)<<4)))&0xFF];\n\t\t\tC = (C>>>8) ^ T0[(C ^ (128|(d&63)))&0xFF];\n\t\t} else {\n\t\t\tC = (C>>>8) ^ T0[(C ^ (224|((c>>12)&15)))&0xFF];\n\t\t\tC = (C>>>8) ^ T0[(C ^ (128|((c>>6)&63)))&0xFF];\n\t\t\tC = (C>>>8) ^ T0[(C ^ (128|(c&63)))&0xFF];\n\t\t}\n\t}\n\treturn ~C;\n}\nCRC32.table = T0;\n// $FlowIgnore\nCRC32.bstr = crc32_bstr;\n// $FlowIgnore\nCRC32.buf = crc32_buf;\n// $FlowIgnore\nCRC32.str = crc32_str;\n}));\n","/**\n * node-crc32-stream\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-crc32-stream/blob/master/LICENSE-MIT\n */\n\n 'use strict';\n\nconst {Transform} = require('readable-stream');\n\nconst crc32 = require('crc-32');\n\nclass CRC32Stream extends Transform {\n  constructor(options) {\n    super(options);\n    this.checksum = Buffer.allocUnsafe(4);\n    this.checksum.writeInt32BE(0, 0);\n\n    this.rawSize = 0;\n  }\n\n  _transform(chunk, encoding, callback) {\n    if (chunk) {\n      this.checksum = crc32.buf(chunk, this.checksum) >>> 0;\n      this.rawSize += chunk.length;\n    }\n\n    callback(null, chunk);\n  }\n\n  digest(encoding) {\n    const checksum = Buffer.allocUnsafe(4);\n    checksum.writeUInt32BE(this.checksum >>> 0, 0);\n    return encoding ? checksum.toString(encoding) : checksum;\n  }\n\n  hex() {\n    return this.digest('hex').toUpperCase();\n  }\n\n  size() {\n    return this.rawSize;\n  }\n}\n\nmodule.exports = CRC32Stream;\n","/**\n * node-crc32-stream\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-crc32-stream/blob/master/LICENSE-MIT\n */\n\n'use strict';\n\nconst {DeflateRaw} = require('zlib');\n\nconst crc32 = require('crc-32');\n\nclass DeflateCRC32Stream extends DeflateRaw {\n  constructor(options) {\n    super(options);\n\n    this.checksum = Buffer.allocUnsafe(4);\n    this.checksum.writeInt32BE(0, 0);\n\n    this.rawSize = 0;\n    this.compressedSize = 0;\n  }\n\n  push(chunk, encoding) {\n    if (chunk) {\n      this.compressedSize += chunk.length;\n    }\n\n    return super.push(chunk, encoding);\n  }\n\n  _transform(chunk, encoding, callback) {\n    if (chunk) {\n      this.checksum = crc32.buf(chunk, this.checksum) >>> 0;\n      this.rawSize += chunk.length;\n    }\n\n    super._transform(chunk, encoding, callback)\n  }\n\n  digest(encoding) {\n    const checksum = Buffer.allocUnsafe(4);\n    checksum.writeUInt32BE(this.checksum >>> 0, 0);\n    return encoding ? checksum.toString(encoding) : checksum;\n  }\n\n  hex() {\n    return this.digest('hex').toUpperCase();\n  }\n\n  size(compressed = false) {\n    if (compressed) {\n      return this.compressedSize;\n    } else {\n      return this.rawSize;\n    }\n  }\n}\n\nmodule.exports = DeflateCRC32Stream;\n","/**\n * node-crc32-stream\n *\n * Copyright (c) 2014 Chris Talkington, contributors.\n * Licensed under the MIT license.\n * https://github.com/archiverjs/node-crc32-stream/blob/master/LICENSE-MIT\n */\n\n'use strict';\n\nmodule.exports = {\n  CRC32Stream: require('./crc32-stream'),\n  DeflateCRC32Stream: require('./deflate-crc32-stream')\n}\n","/**\n * @author Toru Nagashima <https://github.com/mysticatea>\n * @copyright 2015 Toru Nagashima. All rights reserved.\n * See LICENSE file in root directory for full license.\n */\n'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\n/**\n * @typedef {object} PrivateData\n * @property {EventTarget} eventTarget The event target.\n * @property {{type:string}} event The original event object.\n * @property {number} eventPhase The current event phase.\n * @property {EventTarget|null} currentTarget The current event target.\n * @property {boolean} canceled The flag to prevent default.\n * @property {boolean} stopped The flag to stop propagation.\n * @property {boolean} immediateStopped The flag to stop propagation immediately.\n * @property {Function|null} passiveListener The listener if the current listener is passive. Otherwise this is null.\n * @property {number} timeStamp The unix time.\n * @private\n */\n\n/**\n * Private data for event wrappers.\n * @type {WeakMap<Event, PrivateData>}\n * @private\n */\nconst privateData = new WeakMap();\n\n/**\n * Cache for wrapper classes.\n * @type {WeakMap<Object, Function>}\n * @private\n */\nconst wrappers = new WeakMap();\n\n/**\n * Get private data.\n * @param {Event} event The event object to get private data.\n * @returns {PrivateData} The private data of the event.\n * @private\n */\nfunction pd(event) {\n    const retv = privateData.get(event);\n    console.assert(\n        retv != null,\n        \"'this' is expected an Event object, but got\",\n        event\n    );\n    return retv\n}\n\n/**\n * https://dom.spec.whatwg.org/#set-the-canceled-flag\n * @param data {PrivateData} private data.\n */\nfunction setCancelFlag(data) {\n    if (data.passiveListener != null) {\n        if (\n            typeof console !== \"undefined\" &&\n            typeof console.error === \"function\"\n        ) {\n            console.error(\n                \"Unable to preventDefault inside passive event listener invocation.\",\n                data.passiveListener\n            );\n        }\n        return\n    }\n    if (!data.event.cancelable) {\n        return\n    }\n\n    data.canceled = true;\n    if (typeof data.event.preventDefault === \"function\") {\n        data.event.preventDefault();\n    }\n}\n\n/**\n * @see https://dom.spec.whatwg.org/#interface-event\n * @private\n */\n/**\n * The event wrapper.\n * @constructor\n * @param {EventTarget} eventTarget The event target of this dispatching.\n * @param {Event|{type:string}} event The original event to wrap.\n */\nfunction Event(eventTarget, event) {\n    privateData.set(this, {\n        eventTarget,\n        event,\n        eventPhase: 2,\n        currentTarget: eventTarget,\n        canceled: false,\n        stopped: false,\n        immediateStopped: false,\n        passiveListener: null,\n        timeStamp: event.timeStamp || Date.now(),\n    });\n\n    // https://heycam.github.io/webidl/#Unforgeable\n    Object.defineProperty(this, \"isTrusted\", { value: false, enumerable: true });\n\n    // Define accessors\n    const keys = Object.keys(event);\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i];\n        if (!(key in this)) {\n            Object.defineProperty(this, key, defineRedirectDescriptor(key));\n        }\n    }\n}\n\n// Should be enumerable, but class methods are not enumerable.\nEvent.prototype = {\n    /**\n     * The type of this event.\n     * @type {string}\n     */\n    get type() {\n        return pd(this).event.type\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     */\n    get target() {\n        return pd(this).eventTarget\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     */\n    get currentTarget() {\n        return pd(this).currentTarget\n    },\n\n    /**\n     * @returns {EventTarget[]} The composed path of this event.\n     */\n    composedPath() {\n        const currentTarget = pd(this).currentTarget;\n        if (currentTarget == null) {\n            return []\n        }\n        return [currentTarget]\n    },\n\n    /**\n     * Constant of NONE.\n     * @type {number}\n     */\n    get NONE() {\n        return 0\n    },\n\n    /**\n     * Constant of CAPTURING_PHASE.\n     * @type {number}\n     */\n    get CAPTURING_PHASE() {\n        return 1\n    },\n\n    /**\n     * Constant of AT_TARGET.\n     * @type {number}\n     */\n    get AT_TARGET() {\n        return 2\n    },\n\n    /**\n     * Constant of BUBBLING_PHASE.\n     * @type {number}\n     */\n    get BUBBLING_PHASE() {\n        return 3\n    },\n\n    /**\n     * The target of this event.\n     * @type {number}\n     */\n    get eventPhase() {\n        return pd(this).eventPhase\n    },\n\n    /**\n     * Stop event bubbling.\n     * @returns {void}\n     */\n    stopPropagation() {\n        const data = pd(this);\n\n        data.stopped = true;\n        if (typeof data.event.stopPropagation === \"function\") {\n            data.event.stopPropagation();\n        }\n    },\n\n    /**\n     * Stop event bubbling.\n     * @returns {void}\n     */\n    stopImmediatePropagation() {\n        const data = pd(this);\n\n        data.stopped = true;\n        data.immediateStopped = true;\n        if (typeof data.event.stopImmediatePropagation === \"function\") {\n            data.event.stopImmediatePropagation();\n        }\n    },\n\n    /**\n     * The flag to be bubbling.\n     * @type {boolean}\n     */\n    get bubbles() {\n        return Boolean(pd(this).event.bubbles)\n    },\n\n    /**\n     * The flag to be cancelable.\n     * @type {boolean}\n     */\n    get cancelable() {\n        return Boolean(pd(this).event.cancelable)\n    },\n\n    /**\n     * Cancel this event.\n     * @returns {void}\n     */\n    preventDefault() {\n        setCancelFlag(pd(this));\n    },\n\n    /**\n     * The flag to indicate cancellation state.\n     * @type {boolean}\n     */\n    get defaultPrevented() {\n        return pd(this).canceled\n    },\n\n    /**\n     * The flag to be composed.\n     * @type {boolean}\n     */\n    get composed() {\n        return Boolean(pd(this).event.composed)\n    },\n\n    /**\n     * The unix time of this event.\n     * @type {number}\n     */\n    get timeStamp() {\n        return pd(this).timeStamp\n    },\n\n    /**\n     * The target of this event.\n     * @type {EventTarget}\n     * @deprecated\n     */\n    get srcElement() {\n        return pd(this).eventTarget\n    },\n\n    /**\n     * The flag to stop event bubbling.\n     * @type {boolean}\n     * @deprecated\n     */\n    get cancelBubble() {\n        return pd(this).stopped\n    },\n    set cancelBubble(value) {\n        if (!value) {\n            return\n        }\n        const data = pd(this);\n\n        data.stopped = true;\n        if (typeof data.event.cancelBubble === \"boolean\") {\n            data.event.cancelBubble = true;\n        }\n    },\n\n    /**\n     * The flag to indicate cancellation state.\n     * @type {boolean}\n     * @deprecated\n     */\n    get returnValue() {\n        return !pd(this).canceled\n    },\n    set returnValue(value) {\n        if (!value) {\n            setCancelFlag(pd(this));\n        }\n    },\n\n    /**\n     * Initialize this event object. But do nothing under event dispatching.\n     * @param {string} type The event type.\n     * @param {boolean} [bubbles=false] The flag to be possible to bubble up.\n     * @param {boolean} [cancelable=false] The flag to be possible to cancel.\n     * @deprecated\n     */\n    initEvent() {\n        // Do nothing.\n    },\n};\n\n// `constructor` is not enumerable.\nObject.defineProperty(Event.prototype, \"constructor\", {\n    value: Event,\n    configurable: true,\n    writable: true,\n});\n\n// Ensure `event instanceof window.Event` is `true`.\nif (typeof window !== \"undefined\" && typeof window.Event !== \"undefined\") {\n    Object.setPrototypeOf(Event.prototype, window.Event.prototype);\n\n    // Make association for wrappers.\n    wrappers.set(window.Event.prototype, Event);\n}\n\n/**\n * Get the property descriptor to redirect a given property.\n * @param {string} key Property name to define property descriptor.\n * @returns {PropertyDescriptor} The property descriptor to redirect the property.\n * @private\n */\nfunction defineRedirectDescriptor(key) {\n    return {\n        get() {\n            return pd(this).event[key]\n        },\n        set(value) {\n            pd(this).event[key] = value;\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Get the property descriptor to call a given method property.\n * @param {string} key Property name to define property descriptor.\n * @returns {PropertyDescriptor} The property descriptor to call the method property.\n * @private\n */\nfunction defineCallDescriptor(key) {\n    return {\n        value() {\n            const event = pd(this).event;\n            return event[key].apply(event, arguments)\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Define new wrapper class.\n * @param {Function} BaseEvent The base wrapper class.\n * @param {Object} proto The prototype of the original event.\n * @returns {Function} The defined wrapper class.\n * @private\n */\nfunction defineWrapper(BaseEvent, proto) {\n    const keys = Object.keys(proto);\n    if (keys.length === 0) {\n        return BaseEvent\n    }\n\n    /** CustomEvent */\n    function CustomEvent(eventTarget, event) {\n        BaseEvent.call(this, eventTarget, event);\n    }\n\n    CustomEvent.prototype = Object.create(BaseEvent.prototype, {\n        constructor: { value: CustomEvent, configurable: true, writable: true },\n    });\n\n    // Define accessors.\n    for (let i = 0; i < keys.length; ++i) {\n        const key = keys[i];\n        if (!(key in BaseEvent.prototype)) {\n            const descriptor = Object.getOwnPropertyDescriptor(proto, key);\n            const isFunc = typeof descriptor.value === \"function\";\n            Object.defineProperty(\n                CustomEvent.prototype,\n                key,\n                isFunc\n                    ? defineCallDescriptor(key)\n                    : defineRedirectDescriptor(key)\n            );\n        }\n    }\n\n    return CustomEvent\n}\n\n/**\n * Get the wrapper class of a given prototype.\n * @param {Object} proto The prototype of the original event to get its wrapper.\n * @returns {Function} The wrapper class.\n * @private\n */\nfunction getWrapper(proto) {\n    if (proto == null || proto === Object.prototype) {\n        return Event\n    }\n\n    let wrapper = wrappers.get(proto);\n    if (wrapper == null) {\n        wrapper = defineWrapper(getWrapper(Object.getPrototypeOf(proto)), proto);\n        wrappers.set(proto, wrapper);\n    }\n    return wrapper\n}\n\n/**\n * Wrap a given event to management a dispatching.\n * @param {EventTarget} eventTarget The event target of this dispatching.\n * @param {Object} event The event to wrap.\n * @returns {Event} The wrapper instance.\n * @private\n */\nfunction wrapEvent(eventTarget, event) {\n    const Wrapper = getWrapper(Object.getPrototypeOf(event));\n    return new Wrapper(eventTarget, event)\n}\n\n/**\n * Get the immediateStopped flag of a given event.\n * @param {Event} event The event to get.\n * @returns {boolean} The flag to stop propagation immediately.\n * @private\n */\nfunction isStopped(event) {\n    return pd(event).immediateStopped\n}\n\n/**\n * Set the current event phase of a given event.\n * @param {Event} event The event to set current target.\n * @param {number} eventPhase New event phase.\n * @returns {void}\n * @private\n */\nfunction setEventPhase(event, eventPhase) {\n    pd(event).eventPhase = eventPhase;\n}\n\n/**\n * Set the current target of a given event.\n * @param {Event} event The event to set current target.\n * @param {EventTarget|null} currentTarget New current target.\n * @returns {void}\n * @private\n */\nfunction setCurrentTarget(event, currentTarget) {\n    pd(event).currentTarget = currentTarget;\n}\n\n/**\n * Set a passive listener of a given event.\n * @param {Event} event The event to set current target.\n * @param {Function|null} passiveListener New passive listener.\n * @returns {void}\n * @private\n */\nfunction setPassiveListener(event, passiveListener) {\n    pd(event).passiveListener = passiveListener;\n}\n\n/**\n * @typedef {object} ListenerNode\n * @property {Function} listener\n * @property {1|2|3} listenerType\n * @property {boolean} passive\n * @property {boolean} once\n * @property {ListenerNode|null} next\n * @private\n */\n\n/**\n * @type {WeakMap<object, Map<string, ListenerNode>>}\n * @private\n */\nconst listenersMap = new WeakMap();\n\n// Listener types\nconst CAPTURE = 1;\nconst BUBBLE = 2;\nconst ATTRIBUTE = 3;\n\n/**\n * Check whether a given value is an object or not.\n * @param {any} x The value to check.\n * @returns {boolean} `true` if the value is an object.\n */\nfunction isObject(x) {\n    return x !== null && typeof x === \"object\" //eslint-disable-line no-restricted-syntax\n}\n\n/**\n * Get listeners.\n * @param {EventTarget} eventTarget The event target to get.\n * @returns {Map<string, ListenerNode>} The listeners.\n * @private\n */\nfunction getListeners(eventTarget) {\n    const listeners = listenersMap.get(eventTarget);\n    if (listeners == null) {\n        throw new TypeError(\n            \"'this' is expected an EventTarget object, but got another value.\"\n        )\n    }\n    return listeners\n}\n\n/**\n * Get the property descriptor for the event attribute of a given event.\n * @param {string} eventName The event name to get property descriptor.\n * @returns {PropertyDescriptor} The property descriptor.\n * @private\n */\nfunction defineEventAttributeDescriptor(eventName) {\n    return {\n        get() {\n            const listeners = getListeners(this);\n            let node = listeners.get(eventName);\n            while (node != null) {\n                if (node.listenerType === ATTRIBUTE) {\n                    return node.listener\n                }\n                node = node.next;\n            }\n            return null\n        },\n\n        set(listener) {\n            if (typeof listener !== \"function\" && !isObject(listener)) {\n                listener = null; // eslint-disable-line no-param-reassign\n            }\n            const listeners = getListeners(this);\n\n            // Traverse to the tail while removing old value.\n            let prev = null;\n            let node = listeners.get(eventName);\n            while (node != null) {\n                if (node.listenerType === ATTRIBUTE) {\n                    // Remove old value.\n                    if (prev !== null) {\n                        prev.next = node.next;\n                    } else if (node.next !== null) {\n                        listeners.set(eventName, node.next);\n                    } else {\n                        listeners.delete(eventName);\n                    }\n                } else {\n                    prev = node;\n                }\n\n                node = node.next;\n            }\n\n            // Add new value.\n            if (listener !== null) {\n                const newNode = {\n                    listener,\n                    listenerType: ATTRIBUTE,\n                    passive: false,\n                    once: false,\n                    next: null,\n                };\n                if (prev === null) {\n                    listeners.set(eventName, newNode);\n                } else {\n                    prev.next = newNode;\n                }\n            }\n        },\n        configurable: true,\n        enumerable: true,\n    }\n}\n\n/**\n * Define an event attribute (e.g. `eventTarget.onclick`).\n * @param {Object} eventTargetPrototype The event target prototype to define an event attrbite.\n * @param {string} eventName The event name to define.\n * @returns {void}\n */\nfunction defineEventAttribute(eventTargetPrototype, eventName) {\n    Object.defineProperty(\n        eventTargetPrototype,\n        `on${eventName}`,\n        defineEventAttributeDescriptor(eventName)\n    );\n}\n\n/**\n * Define a custom EventTarget with event attributes.\n * @param {string[]} eventNames Event names for event attributes.\n * @returns {EventTarget} The custom EventTarget.\n * @private\n */\nfunction defineCustomEventTarget(eventNames) {\n    /** CustomEventTarget */\n    function CustomEventTarget() {\n        EventTarget.call(this);\n    }\n\n    CustomEventTarget.prototype = Object.create(EventTarget.prototype, {\n        constructor: {\n            value: CustomEventTarget,\n            configurable: true,\n            writable: true,\n        },\n    });\n\n    for (let i = 0; i < eventNames.length; ++i) {\n        defineEventAttribute(CustomEventTarget.prototype, eventNames[i]);\n    }\n\n    return CustomEventTarget\n}\n\n/**\n * EventTarget.\n *\n * - This is constructor if no arguments.\n * - This is a function which returns a CustomEventTarget constructor if there are arguments.\n *\n * For example:\n *\n *     class A extends EventTarget {}\n *     class B extends EventTarget(\"message\") {}\n *     class C extends EventTarget(\"message\", \"error\") {}\n *     class D extends EventTarget([\"message\", \"error\"]) {}\n */\nfunction EventTarget() {\n    /*eslint-disable consistent-return */\n    if (this instanceof EventTarget) {\n        listenersMap.set(this, new Map());\n        return\n    }\n    if (arguments.length === 1 && Array.isArray(arguments[0])) {\n        return defineCustomEventTarget(arguments[0])\n    }\n    if (arguments.length > 0) {\n        const types = new Array(arguments.length);\n        for (let i = 0; i < arguments.length; ++i) {\n            types[i] = arguments[i];\n        }\n        return defineCustomEventTarget(types)\n    }\n    throw new TypeError(\"Cannot call a class as a function\")\n    /*eslint-enable consistent-return */\n}\n\n// Should be enumerable, but class methods are not enumerable.\nEventTarget.prototype = {\n    /**\n     * Add a given listener to this event target.\n     * @param {string} eventName The event name to add.\n     * @param {Function} listener The listener to add.\n     * @param {boolean|{capture?:boolean,passive?:boolean,once?:boolean}} [options] The options for this listener.\n     * @returns {void}\n     */\n    addEventListener(eventName, listener, options) {\n        if (listener == null) {\n            return\n        }\n        if (typeof listener !== \"function\" && !isObject(listener)) {\n            throw new TypeError(\"'listener' should be a function or an object.\")\n        }\n\n        const listeners = getListeners(this);\n        const optionsIsObj = isObject(options);\n        const capture = optionsIsObj\n            ? Boolean(options.capture)\n            : Boolean(options);\n        const listenerType = capture ? CAPTURE : BUBBLE;\n        const newNode = {\n            listener,\n            listenerType,\n            passive: optionsIsObj && Boolean(options.passive),\n            once: optionsIsObj && Boolean(options.once),\n            next: null,\n        };\n\n        // Set it as the first node if the first node is null.\n        let node = listeners.get(eventName);\n        if (node === undefined) {\n            listeners.set(eventName, newNode);\n            return\n        }\n\n        // Traverse to the tail while checking duplication..\n        let prev = null;\n        while (node != null) {\n            if (\n                node.listener === listener &&\n                node.listenerType === listenerType\n            ) {\n                // Should ignore duplication.\n                return\n            }\n            prev = node;\n            node = node.next;\n        }\n\n        // Add it.\n        prev.next = newNode;\n    },\n\n    /**\n     * Remove a given listener from this event target.\n     * @param {string} eventName The event name to remove.\n     * @param {Function} listener The listener to remove.\n     * @param {boolean|{capture?:boolean,passive?:boolean,once?:boolean}} [options] The options for this listener.\n     * @returns {void}\n     */\n    removeEventListener(eventName, listener, options) {\n        if (listener == null) {\n            return\n        }\n\n        const listeners = getListeners(this);\n        const capture = isObject(options)\n            ? Boolean(options.capture)\n            : Boolean(options);\n        const listenerType = capture ? CAPTURE : BUBBLE;\n\n        let prev = null;\n        let node = listeners.get(eventName);\n        while (node != null) {\n            if (\n                node.listener === listener &&\n                node.listenerType === listenerType\n            ) {\n                if (prev !== null) {\n                    prev.next = node.next;\n                } else if (node.next !== null) {\n                    listeners.set(eventName, node.next);\n                } else {\n                    listeners.delete(eventName);\n                }\n                return\n            }\n\n            prev = node;\n            node = node.next;\n        }\n    },\n\n    /**\n     * Dispatch a given event.\n     * @param {Event|{type:string}} event The event to dispatch.\n     * @returns {boolean} `false` if canceled.\n     */\n    dispatchEvent(event) {\n        if (event == null || typeof event.type !== \"string\") {\n            throw new TypeError('\"event.type\" should be a string.')\n        }\n\n        // If listeners aren't registered, terminate.\n        const listeners = getListeners(this);\n        const eventName = event.type;\n        let node = listeners.get(eventName);\n        if (node == null) {\n            return true\n        }\n\n        // Since we cannot rewrite several properties, so wrap object.\n        const wrappedEvent = wrapEvent(this, event);\n\n        // This doesn't process capturing phase and bubbling phase.\n        // This isn't participating in a tree.\n        let prev = null;\n        while (node != null) {\n            // Remove this listener if it's once\n            if (node.once) {\n                if (prev !== null) {\n                    prev.next = node.next;\n                } else if (node.next !== null) {\n                    listeners.set(eventName, node.next);\n                } else {\n                    listeners.delete(eventName);\n                }\n            } else {\n                prev = node;\n            }\n\n            // Call this listener\n            setPassiveListener(\n                wrappedEvent,\n                node.passive ? node.listener : null\n            );\n            if (typeof node.listener === \"function\") {\n                try {\n                    node.listener.call(this, wrappedEvent);\n                } catch (err) {\n                    if (\n                        typeof console !== \"undefined\" &&\n                        typeof console.error === \"function\"\n                    ) {\n                        console.error(err);\n                    }\n                }\n            } else if (\n                node.listenerType !== ATTRIBUTE &&\n                typeof node.listener.handleEvent === \"function\"\n            ) {\n                node.listener.handleEvent(wrappedEvent);\n            }\n\n            // Break if `event.stopImmediatePropagation` was called.\n            if (isStopped(wrappedEvent)) {\n                break\n            }\n\n            node = node.next;\n        }\n        setPassiveListener(wrappedEvent, null);\n        setEventPhase(wrappedEvent, 0);\n        setCurrentTarget(wrappedEvent, null);\n\n        return !wrappedEvent.defaultPrevented\n    },\n};\n\n// `constructor` is not enumerable.\nObject.defineProperty(EventTarget.prototype, \"constructor\", {\n    value: EventTarget,\n    configurable: true,\n    writable: true,\n});\n\n// Ensure `eventTarget instanceof window.EventTarget` is `true`.\nif (\n    typeof window !== \"undefined\" &&\n    typeof window.EventTarget !== \"undefined\"\n) {\n    Object.setPrototypeOf(EventTarget.prototype, window.EventTarget.prototype);\n}\n\nexports.defineEventAttribute = defineEventAttribute;\nexports.EventTarget = EventTarget;\nexports.default = EventTarget;\n\nmodule.exports = EventTarget\nmodule.exports.EventTarget = module.exports[\"default\"] = EventTarget\nmodule.exports.defineEventAttribute = defineEventAttribute\n//# sourceMappingURL=event-target-shim.js.map\n","module.exports = require('events')\n","module.exports = class FixedFIFO {\n  constructor (hwm) {\n    if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) throw new Error('Max size for a FixedFIFO should be a power of two')\n    this.buffer = new Array(hwm)\n    this.mask = hwm - 1\n    this.top = 0\n    this.btm = 0\n    this.next = null\n  }\n\n  clear () {\n    this.top = this.btm = 0\n    this.next = null\n    this.buffer.fill(undefined)\n  }\n\n  push (data) {\n    if (this.buffer[this.top] !== undefined) return false\n    this.buffer[this.top] = data\n    this.top = (this.top + 1) & this.mask\n    return true\n  }\n\n  shift () {\n    const last = this.buffer[this.btm]\n    if (last === undefined) return undefined\n    this.buffer[this.btm] = undefined\n    this.btm = (this.btm + 1) & this.mask\n    return last\n  }\n\n  peek () {\n    return this.buffer[this.btm]\n  }\n\n  isEmpty () {\n    return this.buffer[this.btm] === undefined\n  }\n}\n","const FixedFIFO = require('./fixed-size')\n\nmodule.exports = class FastFIFO {\n  constructor (hwm) {\n    this.hwm = hwm || 16\n    this.head = new FixedFIFO(this.hwm)\n    this.tail = this.head\n    this.length = 0\n  }\n\n  clear () {\n    this.head = this.tail\n    this.head.clear()\n    this.length = 0\n  }\n\n  push (val) {\n    this.length++\n    if (!this.head.push(val)) {\n      const prev = this.head\n      this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length)\n      this.head.push(val)\n    }\n  }\n\n  shift () {\n    if (this.length !== 0) this.length--\n    const val = this.tail.shift()\n    if (val === undefined && this.tail.next) {\n      const next = this.tail.next\n      this.tail.next = null\n      this.tail = next\n      return this.tail.shift()\n    }\n\n    return val\n  }\n\n  peek () {\n    const val = this.tail.peek()\n    if (val === undefined && this.tail.next) return this.tail.next.peek()\n    return val\n  }\n\n  isEmpty () {\n    return this.length === 0\n  }\n}\n","'use strict'\n\nmodule.exports = clone\n\nvar getPrototypeOf = Object.getPrototypeOf || function (obj) {\n  return obj.__proto__\n}\n\nfunction clone (obj) {\n  if (obj === null || typeof obj !== 'object')\n    return obj\n\n  if (obj instanceof Object)\n    var copy = { __proto__: getPrototypeOf(obj) }\n  else\n    var copy = Object.create(null)\n\n  Object.getOwnPropertyNames(obj).forEach(function (key) {\n    Object.defineProperty(copy, key, Object.getOwnPropertyDescriptor(obj, key))\n  })\n\n  return copy\n}\n","var fs = require('fs')\nvar polyfills = require('./polyfills.js')\nvar legacy = require('./legacy-streams.js')\nvar clone = require('./clone.js')\n\nvar util = require('util')\n\n/* istanbul ignore next - node 0.x polyfill */\nvar gracefulQueue\nvar previousSymbol\n\n/* istanbul ignore else - node 0.x polyfill */\nif (typeof Symbol === 'function' && typeof Symbol.for === 'function') {\n  gracefulQueue = Symbol.for('graceful-fs.queue')\n  // This is used in testing by future versions\n  previousSymbol = Symbol.for('graceful-fs.previous')\n} else {\n  gracefulQueue = '___graceful-fs.queue'\n  previousSymbol = '___graceful-fs.previous'\n}\n\nfunction noop () {}\n\nfunction publishQueue(context, queue) {\n  Object.defineProperty(context, gracefulQueue, {\n    get: function() {\n      return queue\n    }\n  })\n}\n\nvar debug = noop\nif (util.debuglog)\n  debug = util.debuglog('gfs4')\nelse if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || ''))\n  debug = function() {\n    var m = util.format.apply(util, arguments)\n    m = 'GFS4: ' + m.split(/\\n/).join('\\nGFS4: ')\n    console.error(m)\n  }\n\n// Once time initialization\nif (!fs[gracefulQueue]) {\n  // This queue can be shared by multiple loaded instances\n  var queue = global[gracefulQueue] || []\n  publishQueue(fs, queue)\n\n  // Patch fs.close/closeSync to shared queue version, because we need\n  // to retry() whenever a close happens *anywhere* in the program.\n  // This is essential when multiple graceful-fs instances are\n  // in play at the same time.\n  fs.close = (function (fs$close) {\n    function close (fd, cb) {\n      return fs$close.call(fs, fd, function (err) {\n        // This function uses the graceful-fs shared queue\n        if (!err) {\n          resetQueue()\n        }\n\n        if (typeof cb === 'function')\n          cb.apply(this, arguments)\n      })\n    }\n\n    Object.defineProperty(close, previousSymbol, {\n      value: fs$close\n    })\n    return close\n  })(fs.close)\n\n  fs.closeSync = (function (fs$closeSync) {\n    function closeSync (fd) {\n      // This function uses the graceful-fs shared queue\n      fs$closeSync.apply(fs, arguments)\n      resetQueue()\n    }\n\n    Object.defineProperty(closeSync, previousSymbol, {\n      value: fs$closeSync\n    })\n    return closeSync\n  })(fs.closeSync)\n\n  if (/\\bgfs4\\b/i.test(process.env.NODE_DEBUG || '')) {\n    process.on('exit', function() {\n      debug(fs[gracefulQueue])\n      require('assert').equal(fs[gracefulQueue].length, 0)\n    })\n  }\n}\n\nif (!global[gracefulQueue]) {\n  publishQueue(global, fs[gracefulQueue]);\n}\n\nmodule.exports = patch(clone(fs))\nif (process.env.TEST_GRACEFUL_FS_GLOBAL_PATCH && !fs.__patched) {\n    module.exports = patch(fs)\n    fs.__patched = true;\n}\n\nfunction patch (fs) {\n  // Everything that references the open() function needs to be in here\n  polyfills(fs)\n  fs.gracefulify = patch\n\n  fs.createReadStream = createReadStream\n  fs.createWriteStream = createWriteStream\n  var fs$readFile = fs.readFile\n  fs.readFile = readFile\n  function readFile (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$readFile(path, options, cb)\n\n    function go$readFile (path, options, cb, startTime) {\n      return fs$readFile(path, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$readFile, [path, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$writeFile = fs.writeFile\n  fs.writeFile = writeFile\n  function writeFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$writeFile(path, data, options, cb)\n\n    function go$writeFile (path, data, options, cb, startTime) {\n      return fs$writeFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$writeFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$appendFile = fs.appendFile\n  if (fs$appendFile)\n    fs.appendFile = appendFile\n  function appendFile (path, data, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    return go$appendFile(path, data, options, cb)\n\n    function go$appendFile (path, data, options, cb, startTime) {\n      return fs$appendFile(path, data, options, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$appendFile, [path, data, options, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$copyFile = fs.copyFile\n  if (fs$copyFile)\n    fs.copyFile = copyFile\n  function copyFile (src, dest, flags, cb) {\n    if (typeof flags === 'function') {\n      cb = flags\n      flags = 0\n    }\n    return go$copyFile(src, dest, flags, cb)\n\n    function go$copyFile (src, dest, flags, cb, startTime) {\n      return fs$copyFile(src, dest, flags, function (err) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$copyFile, [src, dest, flags, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  var fs$readdir = fs.readdir\n  fs.readdir = readdir\n  var noReaddirOptionVersions = /^v[0-5]\\./\n  function readdir (path, options, cb) {\n    if (typeof options === 'function')\n      cb = options, options = null\n\n    var go$readdir = noReaddirOptionVersions.test(process.version)\n      ? function go$readdir (path, options, cb, startTime) {\n        return fs$readdir(path, fs$readdirCallback(\n          path, options, cb, startTime\n        ))\n      }\n      : function go$readdir (path, options, cb, startTime) {\n        return fs$readdir(path, options, fs$readdirCallback(\n          path, options, cb, startTime\n        ))\n      }\n\n    return go$readdir(path, options, cb)\n\n    function fs$readdirCallback (path, options, cb, startTime) {\n      return function (err, files) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([\n            go$readdir,\n            [path, options, cb],\n            err,\n            startTime || Date.now(),\n            Date.now()\n          ])\n        else {\n          if (files && files.sort)\n            files.sort()\n\n          if (typeof cb === 'function')\n            cb.call(this, err, files)\n        }\n      }\n    }\n  }\n\n  if (process.version.substr(0, 4) === 'v0.8') {\n    var legStreams = legacy(fs)\n    ReadStream = legStreams.ReadStream\n    WriteStream = legStreams.WriteStream\n  }\n\n  var fs$ReadStream = fs.ReadStream\n  if (fs$ReadStream) {\n    ReadStream.prototype = Object.create(fs$ReadStream.prototype)\n    ReadStream.prototype.open = ReadStream$open\n  }\n\n  var fs$WriteStream = fs.WriteStream\n  if (fs$WriteStream) {\n    WriteStream.prototype = Object.create(fs$WriteStream.prototype)\n    WriteStream.prototype.open = WriteStream$open\n  }\n\n  Object.defineProperty(fs, 'ReadStream', {\n    get: function () {\n      return ReadStream\n    },\n    set: function (val) {\n      ReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  Object.defineProperty(fs, 'WriteStream', {\n    get: function () {\n      return WriteStream\n    },\n    set: function (val) {\n      WriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  // legacy names\n  var FileReadStream = ReadStream\n  Object.defineProperty(fs, 'FileReadStream', {\n    get: function () {\n      return FileReadStream\n    },\n    set: function (val) {\n      FileReadStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n  var FileWriteStream = WriteStream\n  Object.defineProperty(fs, 'FileWriteStream', {\n    get: function () {\n      return FileWriteStream\n    },\n    set: function (val) {\n      FileWriteStream = val\n    },\n    enumerable: true,\n    configurable: true\n  })\n\n  function ReadStream (path, options) {\n    if (this instanceof ReadStream)\n      return fs$ReadStream.apply(this, arguments), this\n    else\n      return ReadStream.apply(Object.create(ReadStream.prototype), arguments)\n  }\n\n  function ReadStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        if (that.autoClose)\n          that.destroy()\n\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n        that.read()\n      }\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (this instanceof WriteStream)\n      return fs$WriteStream.apply(this, arguments), this\n    else\n      return WriteStream.apply(Object.create(WriteStream.prototype), arguments)\n  }\n\n  function WriteStream$open () {\n    var that = this\n    open(that.path, that.flags, that.mode, function (err, fd) {\n      if (err) {\n        that.destroy()\n        that.emit('error', err)\n      } else {\n        that.fd = fd\n        that.emit('open', fd)\n      }\n    })\n  }\n\n  function createReadStream (path, options) {\n    return new fs.ReadStream(path, options)\n  }\n\n  function createWriteStream (path, options) {\n    return new fs.WriteStream(path, options)\n  }\n\n  var fs$open = fs.open\n  fs.open = open\n  function open (path, flags, mode, cb) {\n    if (typeof mode === 'function')\n      cb = mode, mode = null\n\n    return go$open(path, flags, mode, cb)\n\n    function go$open (path, flags, mode, cb, startTime) {\n      return fs$open(path, flags, mode, function (err, fd) {\n        if (err && (err.code === 'EMFILE' || err.code === 'ENFILE'))\n          enqueue([go$open, [path, flags, mode, cb], err, startTime || Date.now(), Date.now()])\n        else {\n          if (typeof cb === 'function')\n            cb.apply(this, arguments)\n        }\n      })\n    }\n  }\n\n  return fs\n}\n\nfunction enqueue (elem) {\n  debug('ENQUEUE', elem[0].name, elem[1])\n  fs[gracefulQueue].push(elem)\n  retry()\n}\n\n// keep track of the timeout between retry() calls\nvar retryTimer\n\n// reset the startTime and lastTime to now\n// this resets the start of the 60 second overall timeout as well as the\n// delay between attempts so that we'll retry these jobs sooner\nfunction resetQueue () {\n  var now = Date.now()\n  for (var i = 0; i < fs[gracefulQueue].length; ++i) {\n    // entries that are only a length of 2 are from an older version, don't\n    // bother modifying those since they'll be retried anyway.\n    if (fs[gracefulQueue][i].length > 2) {\n      fs[gracefulQueue][i][3] = now // startTime\n      fs[gracefulQueue][i][4] = now // lastTime\n    }\n  }\n  // call retry to make sure we're actively processing the queue\n  retry()\n}\n\nfunction retry () {\n  // clear the timer and remove it to help prevent unintended concurrency\n  clearTimeout(retryTimer)\n  retryTimer = undefined\n\n  if (fs[gracefulQueue].length === 0)\n    return\n\n  var elem = fs[gracefulQueue].shift()\n  var fn = elem[0]\n  var args = elem[1]\n  // these items may be unset if they were added by an older graceful-fs\n  var err = elem[2]\n  var startTime = elem[3]\n  var lastTime = elem[4]\n\n  // if we don't have a startTime we have no way of knowing if we've waited\n  // long enough, so go ahead and retry this item now\n  if (startTime === undefined) {\n    debug('RETRY', fn.name, args)\n    fn.apply(null, args)\n  } else if (Date.now() - startTime >= 60000) {\n    // it's been more than 60 seconds total, bail now\n    debug('TIMEOUT', fn.name, args)\n    var cb = args.pop()\n    if (typeof cb === 'function')\n      cb.call(null, err)\n  } else {\n    // the amount of time between the last attempt and right now\n    var sinceAttempt = Date.now() - lastTime\n    // the amount of time between when we first tried, and when we last tried\n    // rounded up to at least 1\n    var sinceStart = Math.max(lastTime - startTime, 1)\n    // backoff. wait longer than the total time we've been retrying, but only\n    // up to a maximum of 100ms\n    var desiredDelay = Math.min(sinceStart * 1.2, 100)\n    // it's been long enough since the last retry, do it again\n    if (sinceAttempt >= desiredDelay) {\n      debug('RETRY', fn.name, args)\n      fn.apply(null, args.concat([startTime]))\n    } else {\n      // if we can't do this job yet, push it to the end of the queue\n      // and let the next iteration check again\n      fs[gracefulQueue].push(elem)\n    }\n  }\n\n  // schedule our next run if one isn't already scheduled\n  if (retryTimer === undefined) {\n    retryTimer = setTimeout(retry, 0)\n  }\n}\n","var Stream = require('stream').Stream\n\nmodule.exports = legacy\n\nfunction legacy (fs) {\n  return {\n    ReadStream: ReadStream,\n    WriteStream: WriteStream\n  }\n\n  function ReadStream (path, options) {\n    if (!(this instanceof ReadStream)) return new ReadStream(path, options);\n\n    Stream.call(this);\n\n    var self = this;\n\n    this.path = path;\n    this.fd = null;\n    this.readable = true;\n    this.paused = false;\n\n    this.flags = 'r';\n    this.mode = 438; /*=0666*/\n    this.bufferSize = 64 * 1024;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.encoding) this.setEncoding(this.encoding);\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.end === undefined) {\n        this.end = Infinity;\n      } else if ('number' !== typeof this.end) {\n        throw TypeError('end must be a Number');\n      }\n\n      if (this.start > this.end) {\n        throw new Error('start must be <= end');\n      }\n\n      this.pos = this.start;\n    }\n\n    if (this.fd !== null) {\n      process.nextTick(function() {\n        self._read();\n      });\n      return;\n    }\n\n    fs.open(this.path, this.flags, this.mode, function (err, fd) {\n      if (err) {\n        self.emit('error', err);\n        self.readable = false;\n        return;\n      }\n\n      self.fd = fd;\n      self.emit('open', fd);\n      self._read();\n    })\n  }\n\n  function WriteStream (path, options) {\n    if (!(this instanceof WriteStream)) return new WriteStream(path, options);\n\n    Stream.call(this);\n\n    this.path = path;\n    this.fd = null;\n    this.writable = true;\n\n    this.flags = 'w';\n    this.encoding = 'binary';\n    this.mode = 438; /*=0666*/\n    this.bytesWritten = 0;\n\n    options = options || {};\n\n    // Mixin options into this\n    var keys = Object.keys(options);\n    for (var index = 0, length = keys.length; index < length; index++) {\n      var key = keys[index];\n      this[key] = options[key];\n    }\n\n    if (this.start !== undefined) {\n      if ('number' !== typeof this.start) {\n        throw TypeError('start must be a Number');\n      }\n      if (this.start < 0) {\n        throw new Error('start must be >= zero');\n      }\n\n      this.pos = this.start;\n    }\n\n    this.busy = false;\n    this._queue = [];\n\n    if (this.fd === null) {\n      this._open = fs.open;\n      this._queue.push([this._open, this.path, this.flags, this.mode, undefined]);\n      this.flush();\n    }\n  }\n}\n","var constants = require('constants')\n\nvar origCwd = process.cwd\nvar cwd = null\n\nvar platform = process.env.GRACEFUL_FS_PLATFORM || process.platform\n\nprocess.cwd = function() {\n  if (!cwd)\n    cwd = origCwd.call(process)\n  return cwd\n}\ntry {\n  process.cwd()\n} catch (er) {}\n\n// This check is needed until node.js 12 is required\nif (typeof process.chdir === 'function') {\n  var chdir = process.chdir\n  process.chdir = function (d) {\n    cwd = null\n    chdir.call(process, d)\n  }\n  if (Object.setPrototypeOf) Object.setPrototypeOf(process.chdir, chdir)\n}\n\nmodule.exports = patch\n\nfunction patch (fs) {\n  // (re-)implement some things that are known busted or missing.\n\n  // lchmod, broken prior to 0.6.2\n  // back-port the fix here.\n  if (constants.hasOwnProperty('O_SYMLINK') &&\n      process.version.match(/^v0\\.6\\.[0-2]|^v0\\.5\\./)) {\n    patchLchmod(fs)\n  }\n\n  // lutimes implementation, or no-op\n  if (!fs.lutimes) {\n    patchLutimes(fs)\n  }\n\n  // https://github.com/isaacs/node-graceful-fs/issues/4\n  // Chown should not fail on einval or eperm if non-root.\n  // It should not fail on enosys ever, as this just indicates\n  // that a fs doesn't support the intended operation.\n\n  fs.chown = chownFix(fs.chown)\n  fs.fchown = chownFix(fs.fchown)\n  fs.lchown = chownFix(fs.lchown)\n\n  fs.chmod = chmodFix(fs.chmod)\n  fs.fchmod = chmodFix(fs.fchmod)\n  fs.lchmod = chmodFix(fs.lchmod)\n\n  fs.chownSync = chownFixSync(fs.chownSync)\n  fs.fchownSync = chownFixSync(fs.fchownSync)\n  fs.lchownSync = chownFixSync(fs.lchownSync)\n\n  fs.chmodSync = chmodFixSync(fs.chmodSync)\n  fs.fchmodSync = chmodFixSync(fs.fchmodSync)\n  fs.lchmodSync = chmodFixSync(fs.lchmodSync)\n\n  fs.stat = statFix(fs.stat)\n  fs.fstat = statFix(fs.fstat)\n  fs.lstat = statFix(fs.lstat)\n\n  fs.statSync = statFixSync(fs.statSync)\n  fs.fstatSync = statFixSync(fs.fstatSync)\n  fs.lstatSync = statFixSync(fs.lstatSync)\n\n  // if lchmod/lchown do not exist, then make them no-ops\n  if (fs.chmod && !fs.lchmod) {\n    fs.lchmod = function (path, mode, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchmodSync = function () {}\n  }\n  if (fs.chown && !fs.lchown) {\n    fs.lchown = function (path, uid, gid, cb) {\n      if (cb) process.nextTick(cb)\n    }\n    fs.lchownSync = function () {}\n  }\n\n  // on Windows, A/V software can lock the directory, causing this\n  // to fail with an EACCES or EPERM if the directory contains newly\n  // created files.  Try again on failure, for up to 60 seconds.\n\n  // Set the timeout this long because some Windows Anti-Virus, such as Parity\n  // bit9, may lock files for up to a minute, causing npm package install\n  // failures. Also, take care to yield the scheduler. Windows scheduling gives\n  // CPU to a busy looping process, which can cause the program causing the lock\n  // contention to be starved of CPU by node, so the contention doesn't resolve.\n  if (platform === \"win32\") {\n    fs.rename = typeof fs.rename !== 'function' ? fs.rename\n    : (function (fs$rename) {\n      function rename (from, to, cb) {\n        var start = Date.now()\n        var backoff = 0;\n        fs$rename(from, to, function CB (er) {\n          if (er\n              && (er.code === \"EACCES\" || er.code === \"EPERM\" || er.code === \"EBUSY\")\n              && Date.now() - start < 60000) {\n            setTimeout(function() {\n              fs.stat(to, function (stater, st) {\n                if (stater && stater.code === \"ENOENT\")\n                  fs$rename(from, to, CB);\n                else\n                  cb(er)\n              })\n            }, backoff)\n            if (backoff < 100)\n              backoff += 10;\n            return;\n          }\n          if (cb) cb(er)\n        })\n      }\n      if (Object.setPrototypeOf) Object.setPrototypeOf(rename, fs$rename)\n      return rename\n    })(fs.rename)\n  }\n\n  // if read() returns EAGAIN, then just try it again.\n  fs.read = typeof fs.read !== 'function' ? fs.read\n  : (function (fs$read) {\n    function read (fd, buffer, offset, length, position, callback_) {\n      var callback\n      if (callback_ && typeof callback_ === 'function') {\n        var eagCounter = 0\n        callback = function (er, _, __) {\n          if (er && er.code === 'EAGAIN' && eagCounter < 10) {\n            eagCounter ++\n            return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n          }\n          callback_.apply(this, arguments)\n        }\n      }\n      return fs$read.call(fs, fd, buffer, offset, length, position, callback)\n    }\n\n    // This ensures `util.promisify` works as it does for native `fs.read`.\n    if (Object.setPrototypeOf) Object.setPrototypeOf(read, fs$read)\n    return read\n  })(fs.read)\n\n  fs.readSync = typeof fs.readSync !== 'function' ? fs.readSync\n  : (function (fs$readSync) { return function (fd, buffer, offset, length, position) {\n    var eagCounter = 0\n    while (true) {\n      try {\n        return fs$readSync.call(fs, fd, buffer, offset, length, position)\n      } catch (er) {\n        if (er.code === 'EAGAIN' && eagCounter < 10) {\n          eagCounter ++\n          continue\n        }\n        throw er\n      }\n    }\n  }})(fs.readSync)\n\n  function patchLchmod (fs) {\n    fs.lchmod = function (path, mode, callback) {\n      fs.open( path\n             , constants.O_WRONLY | constants.O_SYMLINK\n             , mode\n             , function (err, fd) {\n        if (err) {\n          if (callback) callback(err)\n          return\n        }\n        // prefer to return the chmod error, if one occurs,\n        // but still try to close, and report closing errors if they occur.\n        fs.fchmod(fd, mode, function (err) {\n          fs.close(fd, function(err2) {\n            if (callback) callback(err || err2)\n          })\n        })\n      })\n    }\n\n    fs.lchmodSync = function (path, mode) {\n      var fd = fs.openSync(path, constants.O_WRONLY | constants.O_SYMLINK, mode)\n\n      // prefer to return the chmod error, if one occurs,\n      // but still try to close, and report closing errors if they occur.\n      var threw = true\n      var ret\n      try {\n        ret = fs.fchmodSync(fd, mode)\n        threw = false\n      } finally {\n        if (threw) {\n          try {\n            fs.closeSync(fd)\n          } catch (er) {}\n        } else {\n          fs.closeSync(fd)\n        }\n      }\n      return ret\n    }\n  }\n\n  function patchLutimes (fs) {\n    if (constants.hasOwnProperty(\"O_SYMLINK\") && fs.futimes) {\n      fs.lutimes = function (path, at, mt, cb) {\n        fs.open(path, constants.O_SYMLINK, function (er, fd) {\n          if (er) {\n            if (cb) cb(er)\n            return\n          }\n          fs.futimes(fd, at, mt, function (er) {\n            fs.close(fd, function (er2) {\n              if (cb) cb(er || er2)\n            })\n          })\n        })\n      }\n\n      fs.lutimesSync = function (path, at, mt) {\n        var fd = fs.openSync(path, constants.O_SYMLINK)\n        var ret\n        var threw = true\n        try {\n          ret = fs.futimesSync(fd, at, mt)\n          threw = false\n        } finally {\n          if (threw) {\n            try {\n              fs.closeSync(fd)\n            } catch (er) {}\n          } else {\n            fs.closeSync(fd)\n          }\n        }\n        return ret\n      }\n\n    } else if (fs.futimes) {\n      fs.lutimes = function (_a, _b, _c, cb) { if (cb) process.nextTick(cb) }\n      fs.lutimesSync = function () {}\n    }\n  }\n\n  function chmodFix (orig) {\n    if (!orig) return orig\n    return function (target, mode, cb) {\n      return orig.call(fs, target, mode, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chmodFixSync (orig) {\n    if (!orig) return orig\n    return function (target, mode) {\n      try {\n        return orig.call(fs, target, mode)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n\n  function chownFix (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid, cb) {\n      return orig.call(fs, target, uid, gid, function (er) {\n        if (chownErOk(er)) er = null\n        if (cb) cb.apply(this, arguments)\n      })\n    }\n  }\n\n  function chownFixSync (orig) {\n    if (!orig) return orig\n    return function (target, uid, gid) {\n      try {\n        return orig.call(fs, target, uid, gid)\n      } catch (er) {\n        if (!chownErOk(er)) throw er\n      }\n    }\n  }\n\n  function statFix (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options, cb) {\n      if (typeof options === 'function') {\n        cb = options\n        options = null\n      }\n      function callback (er, stats) {\n        if (stats) {\n          if (stats.uid < 0) stats.uid += 0x100000000\n          if (stats.gid < 0) stats.gid += 0x100000000\n        }\n        if (cb) cb.apply(this, arguments)\n      }\n      return options ? orig.call(fs, target, options, callback)\n        : orig.call(fs, target, callback)\n    }\n  }\n\n  function statFixSync (orig) {\n    if (!orig) return orig\n    // Older versions of Node erroneously returned signed integers for\n    // uid + gid.\n    return function (target, options) {\n      var stats = options ? orig.call(fs, target, options)\n        : orig.call(fs, target)\n      if (stats) {\n        if (stats.uid < 0) stats.uid += 0x100000000\n        if (stats.gid < 0) stats.gid += 0x100000000\n      }\n      return stats;\n    }\n  }\n\n  // ENOSYS means that the fs doesn't support the op. Just ignore\n  // that, because it doesn't matter.\n  //\n  // if there's no getuid, or if getuid() is something other\n  // than 0, and the error is EINVAL or EPERM, then just ignore\n  // it.\n  //\n  // This specific case is a silent failure in cp, install, tar,\n  // and most other unix tools that manage permissions.\n  //\n  // When running as root, or if other types of errors are\n  // encountered, then it's strict.\n  function chownErOk (er) {\n    if (!er)\n      return true\n\n    if (er.code === \"ENOSYS\")\n      return true\n\n    var nonroot = !process.getuid || process.getuid() !== 0\n    if (nonroot) {\n      if (er.code === \"EINVAL\" || er.code === \"EPERM\")\n        return true\n    }\n\n    return false\n  }\n}\n","try {\n  var util = require('util');\n  /* istanbul ignore next */\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  /* istanbul ignore next */\n  module.exports = require('./inherits_browser.js');\n}\n","if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n","'use strict';\n\nconst isStream = stream =>\n\tstream !== null &&\n\ttypeof stream === 'object' &&\n\ttypeof stream.pipe === 'function';\n\nisStream.writable = stream =>\n\tisStream(stream) &&\n\tstream.writable !== false &&\n\ttypeof stream._write === 'function' &&\n\ttypeof stream._writableState === 'object';\n\nisStream.readable = stream =>\n\tisStream(stream) &&\n\tstream.readable !== false &&\n\ttypeof stream._read === 'function' &&\n\ttypeof stream._readableState === 'object';\n\nisStream.duplex = stream =>\n\tisStream.writable(stream) &&\n\tisStream.readable(stream);\n\nisStream.transform = stream =>\n\tisStream.duplex(stream) &&\n\ttypeof stream._transform === 'function';\n\nmodule.exports = isStream;\n","var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n","var util = require('util');\nvar PassThrough = require('readable-stream/passthrough');\n\nmodule.exports = {\n  Readable: Readable,\n  Writable: Writable\n};\n\nutil.inherits(Readable, PassThrough);\nutil.inherits(Writable, PassThrough);\n\n// Patch the given method of instance so that the callback\n// is executed once, before the actual method is called the\n// first time.\nfunction beforeFirstCall(instance, method, callback) {\n  instance[method] = function() {\n    delete instance[method];\n    callback.apply(this, arguments);\n    return this[method].apply(this, arguments);\n  };\n}\n\nfunction Readable(fn, options) {\n  if (!(this instanceof Readable))\n    return new Readable(fn, options);\n\n  PassThrough.call(this, options);\n\n  beforeFirstCall(this, '_read', function() {\n    var source = fn.call(this, options);\n    var emit = this.emit.bind(this, 'error');\n    source.on('error', emit);\n    source.pipe(this);\n  });\n\n  this.emit('readable');\n}\n\nfunction Writable(fn, options) {\n  if (!(this instanceof Writable))\n    return new Writable(fn, options);\n\n  PassThrough.call(this, options);\n\n  beforeFirstCall(this, '_write', function() {\n    var destination = fn.call(this, options);\n    var emit = this.emit.bind(this, 'error');\n    destination.on('error', emit);\n    this.pipe(destination);\n  });\n\n  this.emit('writable');\n}\n\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = (typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : typeof self !== 'undefined' ? self : {}).Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, { hasUnpiped: false });\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = Object.create(require('core-util-is'));\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = (typeof global !== 'undefined' ? global : typeof window !== 'undefined' ? window : typeof self !== 'undefined' ? self : {}).Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n\n  // reuse the free corkReq.\n  state.corkedRequestsFree.next = corkReq;\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};","'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}","'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        pna.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        pna.nextTick(emitErrorNT, this, err);\n      }\n    }\n\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      if (!_this._writableState) {\n        pna.nextTick(emitErrorNT, _this, err);\n      } else if (!_this._writableState.errorEmitted) {\n        _this._writableState.errorEmitted = true;\n        pna.nextTick(emitErrorNT, _this, err);\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};","module.exports = require('stream');\n","module.exports = require('./readable').PassThrough\n","var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n","/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}","var hashClear = require('./_hashClear'),\n    hashDelete = require('./_hashDelete'),\n    hashGet = require('./_hashGet'),\n    hashHas = require('./_hashHas'),\n    hashSet = require('./_hashSet');\n\n/**\n * Creates a hash object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction Hash(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `Hash`.\nHash.prototype.clear = hashClear;\nHash.prototype['delete'] = hashDelete;\nHash.prototype.get = hashGet;\nHash.prototype.has = hashHas;\nHash.prototype.set = hashSet;\n\nmodule.exports = Hash;\n","var listCacheClear = require('./_listCacheClear'),\n    listCacheDelete = require('./_listCacheDelete'),\n    listCacheGet = require('./_listCacheGet'),\n    listCacheHas = require('./_listCacheHas'),\n    listCacheSet = require('./_listCacheSet');\n\n/**\n * Creates an list cache object.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction ListCache(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `ListCache`.\nListCache.prototype.clear = listCacheClear;\nListCache.prototype['delete'] = listCacheDelete;\nListCache.prototype.get = listCacheGet;\nListCache.prototype.has = listCacheHas;\nListCache.prototype.set = listCacheSet;\n\nmodule.exports = ListCache;\n","var getNative = require('./_getNative'),\n    root = require('./_root');\n\n/* Built-in method references that are verified to be native. */\nvar Map = getNative(root, 'Map');\n\nmodule.exports = Map;\n","var mapCacheClear = require('./_mapCacheClear'),\n    mapCacheDelete = require('./_mapCacheDelete'),\n    mapCacheGet = require('./_mapCacheGet'),\n    mapCacheHas = require('./_mapCacheHas'),\n    mapCacheSet = require('./_mapCacheSet');\n\n/**\n * Creates a map cache object to store key-value pairs.\n *\n * @private\n * @constructor\n * @param {Array} [entries] The key-value pairs to cache.\n */\nfunction MapCache(entries) {\n  var index = -1,\n      length = entries == null ? 0 : entries.length;\n\n  this.clear();\n  while (++index < length) {\n    var entry = entries[index];\n    this.set(entry[0], entry[1]);\n  }\n}\n\n// Add methods to `MapCache`.\nMapCache.prototype.clear = mapCacheClear;\nMapCache.prototype['delete'] = mapCacheDelete;\nMapCache.prototype.get = mapCacheGet;\nMapCache.prototype.has = mapCacheHas;\nMapCache.prototype.set = mapCacheSet;\n\nmodule.exports = MapCache;\n","var getNative = require('./_getNative'),\n    root = require('./_root');\n\n/* Built-in method references that are verified to be native. */\nvar Set = getNative(root, 'Set');\n\nmodule.exports = Set;\n","var MapCache = require('./_MapCache'),\n    setCacheAdd = require('./_setCacheAdd'),\n    setCacheHas = require('./_setCacheHas');\n\n/**\n *\n * Creates an array cache object to store unique values.\n *\n * @private\n * @constructor\n * @param {Array} [values] The values to cache.\n */\nfunction SetCache(values) {\n  var index = -1,\n      length = values == null ? 0 : values.length;\n\n  this.__data__ = new MapCache;\n  while (++index < length) {\n    this.add(values[index]);\n  }\n}\n\n// Add methods to `SetCache`.\nSetCache.prototype.add = SetCache.prototype.push = setCacheAdd;\nSetCache.prototype.has = setCacheHas;\n\nmodule.exports = SetCache;\n","var root = require('./_root');\n\n/** Built-in value references. */\nvar Symbol = root.Symbol;\n\nmodule.exports = Symbol;\n","/**\n * A faster alternative to `Function#apply`, this function invokes `func`\n * with the `this` binding of `thisArg` and the arguments of `args`.\n *\n * @private\n * @param {Function} func The function to invoke.\n * @param {*} thisArg The `this` binding of `func`.\n * @param {Array} args The arguments to invoke `func` with.\n * @returns {*} Returns the result of `func`.\n */\nfunction apply(func, thisArg, args) {\n  switch (args.length) {\n    case 0: return func.call(thisArg);\n    case 1: return func.call(thisArg, args[0]);\n    case 2: return func.call(thisArg, args[0], args[1]);\n    case 3: return func.call(thisArg, args[0], args[1], args[2]);\n  }\n  return func.apply(thisArg, args);\n}\n\nmodule.exports = apply;\n","var baseIndexOf = require('./_baseIndexOf');\n\n/**\n * A specialized version of `_.includes` for arrays without support for\n * specifying an index to search from.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludes(array, value) {\n  var length = array == null ? 0 : array.length;\n  return !!length && baseIndexOf(array, value, 0) > -1;\n}\n\nmodule.exports = arrayIncludes;\n","/**\n * This function is like `arrayIncludes` except that it accepts a comparator.\n *\n * @private\n * @param {Array} [array] The array to inspect.\n * @param {*} target The value to search for.\n * @param {Function} comparator The comparator invoked per element.\n * @returns {boolean} Returns `true` if `target` is found, else `false`.\n */\nfunction arrayIncludesWith(array, value, comparator) {\n  var index = -1,\n      length = array == null ? 0 : array.length;\n\n  while (++index < length) {\n    if (comparator(value, array[index])) {\n      return true;\n    }\n  }\n  return false;\n}\n\nmodule.exports = arrayIncludesWith;\n","var baseTimes = require('./_baseTimes'),\n    isArguments = require('./isArguments'),\n    isArray = require('./isArray'),\n    isBuffer = require('./isBuffer'),\n    isIndex = require('./_isIndex'),\n    isTypedArray = require('./isTypedArray');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Creates an array of the enumerable property names of the array-like `value`.\n *\n * @private\n * @param {*} value The value to query.\n * @param {boolean} inherited Specify returning inherited property names.\n * @returns {Array} Returns the array of property names.\n */\nfunction arrayLikeKeys(value, inherited) {\n  var isArr = isArray(value),\n      isArg = !isArr && isArguments(value),\n      isBuff = !isArr && !isArg && isBuffer(value),\n      isType = !isArr && !isArg && !isBuff && isTypedArray(value),\n      skipIndexes = isArr || isArg || isBuff || isType,\n      result = skipIndexes ? baseTimes(value.length, String) : [],\n      length = result.length;\n\n  for (var key in value) {\n    if ((inherited || hasOwnProperty.call(value, key)) &&\n        !(skipIndexes && (\n           // Safari 9 has enumerable `arguments.length` in strict mode.\n           key == 'length' ||\n           // Node.js 0.10 has enumerable non-index properties on buffers.\n           (isBuff && (key == 'offset' || key == 'parent')) ||\n           // PhantomJS 2 has enumerable non-index properties on typed arrays.\n           (isType && (key == 'buffer' || key == 'byteLength' || key == 'byteOffset')) ||\n           // Skip index properties.\n           isIndex(key, length)\n        ))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nmodule.exports = arrayLikeKeys;\n","/**\n * A specialized version of `_.map` for arrays without support for iteratee\n * shorthands.\n *\n * @private\n * @param {Array} [array] The array to iterate over.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the new mapped array.\n */\nfunction arrayMap(array, iteratee) {\n  var index = -1,\n      length = array == null ? 0 : array.length,\n      result = Array(length);\n\n  while (++index < length) {\n    result[index] = iteratee(array[index], index, array);\n  }\n  return result;\n}\n\nmodule.exports = arrayMap;\n","/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\nmodule.exports = arrayPush;\n","var eq = require('./eq');\n\n/**\n * Gets the index at which the `key` is found in `array` of key-value pairs.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} key The key to search for.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction assocIndexOf(array, key) {\n  var length = array.length;\n  while (length--) {\n    if (eq(array[length][0], key)) {\n      return length;\n    }\n  }\n  return -1;\n}\n\nmodule.exports = assocIndexOf;\n","var SetCache = require('./_SetCache'),\n    arrayIncludes = require('./_arrayIncludes'),\n    arrayIncludesWith = require('./_arrayIncludesWith'),\n    arrayMap = require('./_arrayMap'),\n    baseUnary = require('./_baseUnary'),\n    cacheHas = require('./_cacheHas');\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of methods like `_.difference` without support\n * for excluding multiple arrays or iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Array} values The values to exclude.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new array of filtered values.\n */\nfunction baseDifference(array, values, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      isCommon = true,\n      length = array.length,\n      result = [],\n      valuesLength = values.length;\n\n  if (!length) {\n    return result;\n  }\n  if (iteratee) {\n    values = arrayMap(values, baseUnary(iteratee));\n  }\n  if (comparator) {\n    includes = arrayIncludesWith;\n    isCommon = false;\n  }\n  else if (values.length >= LARGE_ARRAY_SIZE) {\n    includes = cacheHas;\n    isCommon = false;\n    values = new SetCache(values);\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee == null ? value : iteratee(value);\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var valuesIndex = valuesLength;\n      while (valuesIndex--) {\n        if (values[valuesIndex] === computed) {\n          continue outer;\n        }\n      }\n      result.push(value);\n    }\n    else if (!includes(values, computed, comparator)) {\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseDifference;\n","/**\n * The base implementation of `_.findIndex` and `_.findLastIndex` without\n * support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} predicate The function invoked per iteration.\n * @param {number} fromIndex The index to search from.\n * @param {boolean} [fromRight] Specify iterating from right to left.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseFindIndex(array, predicate, fromIndex, fromRight) {\n  var length = array.length,\n      index = fromIndex + (fromRight ? 1 : -1);\n\n  while ((fromRight ? index-- : ++index < length)) {\n    if (predicate(array[index], index, array)) {\n      return index;\n    }\n  }\n  return -1;\n}\n\nmodule.exports = baseFindIndex;\n","var arrayPush = require('./_arrayPush'),\n    isFlattenable = require('./_isFlattenable');\n\n/**\n * The base implementation of `_.flatten` with support for restricting flattening.\n *\n * @private\n * @param {Array} array The array to flatten.\n * @param {number} depth The maximum recursion depth.\n * @param {boolean} [predicate=isFlattenable] The function invoked per iteration.\n * @param {boolean} [isStrict] Restrict to values that pass `predicate` checks.\n * @param {Array} [result=[]] The initial result value.\n * @returns {Array} Returns the new flattened array.\n */\nfunction baseFlatten(array, depth, predicate, isStrict, result) {\n  var index = -1,\n      length = array.length;\n\n  predicate || (predicate = isFlattenable);\n  result || (result = []);\n\n  while (++index < length) {\n    var value = array[index];\n    if (depth > 0 && predicate(value)) {\n      if (depth > 1) {\n        // Recursively flatten arrays (susceptible to call stack limits).\n        baseFlatten(value, depth - 1, predicate, isStrict, result);\n      } else {\n        arrayPush(result, value);\n      }\n    } else if (!isStrict) {\n      result[result.length] = value;\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseFlatten;\n","var Symbol = require('./_Symbol'),\n    getRawTag = require('./_getRawTag'),\n    objectToString = require('./_objectToString');\n\n/** `Object#toString` result references. */\nvar nullTag = '[object Null]',\n    undefinedTag = '[object Undefined]';\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * The base implementation of `getTag` without fallbacks for buggy environments.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  if (value == null) {\n    return value === undefined ? undefinedTag : nullTag;\n  }\n  return (symToStringTag && symToStringTag in Object(value))\n    ? getRawTag(value)\n    : objectToString(value);\n}\n\nmodule.exports = baseGetTag;\n","var baseFindIndex = require('./_baseFindIndex'),\n    baseIsNaN = require('./_baseIsNaN'),\n    strictIndexOf = require('./_strictIndexOf');\n\n/**\n * The base implementation of `_.indexOf` without `fromIndex` bounds checks.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} fromIndex The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction baseIndexOf(array, value, fromIndex) {\n  return value === value\n    ? strictIndexOf(array, value, fromIndex)\n    : baseFindIndex(array, baseIsNaN, fromIndex);\n}\n\nmodule.exports = baseIndexOf;\n","var baseGetTag = require('./_baseGetTag'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]';\n\n/**\n * The base implementation of `_.isArguments`.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n */\nfunction baseIsArguments(value) {\n  return isObjectLike(value) && baseGetTag(value) == argsTag;\n}\n\nmodule.exports = baseIsArguments;\n","/**\n * The base implementation of `_.isNaN` without support for number objects.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is `NaN`, else `false`.\n */\nfunction baseIsNaN(value) {\n  return value !== value;\n}\n\nmodule.exports = baseIsNaN;\n","var isFunction = require('./isFunction'),\n    isMasked = require('./_isMasked'),\n    isObject = require('./isObject'),\n    toSource = require('./_toSource');\n\n/**\n * Used to match `RegExp`\n * [syntax characters](http://ecma-international.org/ecma-262/7.0/#sec-patterns).\n */\nvar reRegExpChar = /[\\\\^$.*+?()[\\]{}|]/g;\n\n/** Used to detect host constructors (Safari). */\nvar reIsHostCtor = /^\\[object .+?Constructor\\]$/;\n\n/** Used for built-in method references. */\nvar funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Used to detect if a method is native. */\nvar reIsNative = RegExp('^' +\n  funcToString.call(hasOwnProperty).replace(reRegExpChar, '\\\\$&')\n  .replace(/hasOwnProperty|(function).*?(?=\\\\\\()| for .+?(?=\\\\\\])/g, '$1.*?') + '$'\n);\n\n/**\n * The base implementation of `_.isNative` without bad shim checks.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a native function,\n *  else `false`.\n */\nfunction baseIsNative(value) {\n  if (!isObject(value) || isMasked(value)) {\n    return false;\n  }\n  var pattern = isFunction(value) ? reIsNative : reIsHostCtor;\n  return pattern.test(toSource(value));\n}\n\nmodule.exports = baseIsNative;\n","var baseGetTag = require('./_baseGetTag'),\n    isLength = require('./isLength'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]',\n    arrayTag = '[object Array]',\n    boolTag = '[object Boolean]',\n    dateTag = '[object Date]',\n    errorTag = '[object Error]',\n    funcTag = '[object Function]',\n    mapTag = '[object Map]',\n    numberTag = '[object Number]',\n    objectTag = '[object Object]',\n    regexpTag = '[object RegExp]',\n    setTag = '[object Set]',\n    stringTag = '[object String]',\n    weakMapTag = '[object WeakMap]';\n\nvar arrayBufferTag = '[object ArrayBuffer]',\n    dataViewTag = '[object DataView]',\n    float32Tag = '[object Float32Array]',\n    float64Tag = '[object Float64Array]',\n    int8Tag = '[object Int8Array]',\n    int16Tag = '[object Int16Array]',\n    int32Tag = '[object Int32Array]',\n    uint8Tag = '[object Uint8Array]',\n    uint8ClampedTag = '[object Uint8ClampedArray]',\n    uint16Tag = '[object Uint16Array]',\n    uint32Tag = '[object Uint32Array]';\n\n/** Used to identify `toStringTag` values of typed arrays. */\nvar typedArrayTags = {};\ntypedArrayTags[float32Tag] = typedArrayTags[float64Tag] =\ntypedArrayTags[int8Tag] = typedArrayTags[int16Tag] =\ntypedArrayTags[int32Tag] = typedArrayTags[uint8Tag] =\ntypedArrayTags[uint8ClampedTag] = typedArrayTags[uint16Tag] =\ntypedArrayTags[uint32Tag] = true;\ntypedArrayTags[argsTag] = typedArrayTags[arrayTag] =\ntypedArrayTags[arrayBufferTag] = typedArrayTags[boolTag] =\ntypedArrayTags[dataViewTag] = typedArrayTags[dateTag] =\ntypedArrayTags[errorTag] = typedArrayTags[funcTag] =\ntypedArrayTags[mapTag] = typedArrayTags[numberTag] =\ntypedArrayTags[objectTag] = typedArrayTags[regexpTag] =\ntypedArrayTags[setTag] = typedArrayTags[stringTag] =\ntypedArrayTags[weakMapTag] = false;\n\n/**\n * The base implementation of `_.isTypedArray` without Node.js optimizations.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n */\nfunction baseIsTypedArray(value) {\n  return isObjectLike(value) &&\n    isLength(value.length) && !!typedArrayTags[baseGetTag(value)];\n}\n\nmodule.exports = baseIsTypedArray;\n","var isObject = require('./isObject'),\n    isPrototype = require('./_isPrototype'),\n    nativeKeysIn = require('./_nativeKeysIn');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * The base implementation of `_.keysIn` which doesn't treat sparse arrays as dense.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction baseKeysIn(object) {\n  if (!isObject(object)) {\n    return nativeKeysIn(object);\n  }\n  var isProto = isPrototype(object),\n      result = [];\n\n  for (var key in object) {\n    if (!(key == 'constructor' && (isProto || !hasOwnProperty.call(object, key)))) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseKeysIn;\n","var identity = require('./identity'),\n    overRest = require('./_overRest'),\n    setToString = require('./_setToString');\n\n/**\n * The base implementation of `_.rest` which doesn't validate or coerce arguments.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @returns {Function} Returns the new function.\n */\nfunction baseRest(func, start) {\n  return setToString(overRest(func, start, identity), func + '');\n}\n\nmodule.exports = baseRest;\n","var constant = require('./constant'),\n    defineProperty = require('./_defineProperty'),\n    identity = require('./identity');\n\n/**\n * The base implementation of `setToString` without support for hot loop shorting.\n *\n * @private\n * @param {Function} func The function to modify.\n * @param {Function} string The `toString` result.\n * @returns {Function} Returns `func`.\n */\nvar baseSetToString = !defineProperty ? identity : function(func, string) {\n  return defineProperty(func, 'toString', {\n    'configurable': true,\n    'enumerable': false,\n    'value': constant(string),\n    'writable': true\n  });\n};\n\nmodule.exports = baseSetToString;\n","/**\n * The base implementation of `_.times` without support for iteratee shorthands\n * or max array length checks.\n *\n * @private\n * @param {number} n The number of times to invoke `iteratee`.\n * @param {Function} iteratee The function invoked per iteration.\n * @returns {Array} Returns the array of results.\n */\nfunction baseTimes(n, iteratee) {\n  var index = -1,\n      result = Array(n);\n\n  while (++index < n) {\n    result[index] = iteratee(index);\n  }\n  return result;\n}\n\nmodule.exports = baseTimes;\n","/**\n * The base implementation of `_.unary` without support for storing metadata.\n *\n * @private\n * @param {Function} func The function to cap arguments for.\n * @returns {Function} Returns the new capped function.\n */\nfunction baseUnary(func) {\n  return function(value) {\n    return func(value);\n  };\n}\n\nmodule.exports = baseUnary;\n","var SetCache = require('./_SetCache'),\n    arrayIncludes = require('./_arrayIncludes'),\n    arrayIncludesWith = require('./_arrayIncludesWith'),\n    cacheHas = require('./_cacheHas'),\n    createSet = require('./_createSet'),\n    setToArray = require('./_setToArray');\n\n/** Used as the size to enable large array optimizations. */\nvar LARGE_ARRAY_SIZE = 200;\n\n/**\n * The base implementation of `_.uniqBy` without support for iteratee shorthands.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {Function} [iteratee] The iteratee invoked per element.\n * @param {Function} [comparator] The comparator invoked per element.\n * @returns {Array} Returns the new duplicate free array.\n */\nfunction baseUniq(array, iteratee, comparator) {\n  var index = -1,\n      includes = arrayIncludes,\n      length = array.length,\n      isCommon = true,\n      result = [],\n      seen = result;\n\n  if (comparator) {\n    isCommon = false;\n    includes = arrayIncludesWith;\n  }\n  else if (length >= LARGE_ARRAY_SIZE) {\n    var set = iteratee ? null : createSet(array);\n    if (set) {\n      return setToArray(set);\n    }\n    isCommon = false;\n    includes = cacheHas;\n    seen = new SetCache;\n  }\n  else {\n    seen = iteratee ? [] : result;\n  }\n  outer:\n  while (++index < length) {\n    var value = array[index],\n        computed = iteratee ? iteratee(value) : value;\n\n    value = (comparator || value !== 0) ? value : 0;\n    if (isCommon && computed === computed) {\n      var seenIndex = seen.length;\n      while (seenIndex--) {\n        if (seen[seenIndex] === computed) {\n          continue outer;\n        }\n      }\n      if (iteratee) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n    else if (!includes(seen, computed, comparator)) {\n      if (seen !== result) {\n        seen.push(computed);\n      }\n      result.push(value);\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseUniq;\n","/**\n * Checks if a `cache` value for `key` exists.\n *\n * @private\n * @param {Object} cache The cache to query.\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction cacheHas(cache, key) {\n  return cache.has(key);\n}\n\nmodule.exports = cacheHas;\n","var root = require('./_root');\n\n/** Used to detect overreaching core-js shims. */\nvar coreJsData = root['__core-js_shared__'];\n\nmodule.exports = coreJsData;\n","var Set = require('./_Set'),\n    noop = require('./noop'),\n    setToArray = require('./_setToArray');\n\n/** Used as references for various `Number` constants. */\nvar INFINITY = 1 / 0;\n\n/**\n * Creates a set object of `values`.\n *\n * @private\n * @param {Array} values The values to add to the set.\n * @returns {Object} Returns the new set.\n */\nvar createSet = !(Set && (1 / setToArray(new Set([,-0]))[1]) == INFINITY) ? noop : function(values) {\n  return new Set(values);\n};\n\nmodule.exports = createSet;\n","var getNative = require('./_getNative');\n\nvar defineProperty = (function() {\n  try {\n    var func = getNative(Object, 'defineProperty');\n    func({}, '', {});\n    return func;\n  } catch (e) {}\n}());\n\nmodule.exports = defineProperty;\n","/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\nmodule.exports = freeGlobal;\n","var isKeyable = require('./_isKeyable');\n\n/**\n * Gets the data for `map`.\n *\n * @private\n * @param {Object} map The map to query.\n * @param {string} key The reference key.\n * @returns {*} Returns the map data.\n */\nfunction getMapData(map, key) {\n  var data = map.__data__;\n  return isKeyable(key)\n    ? data[typeof key == 'string' ? 'string' : 'hash']\n    : data.map;\n}\n\nmodule.exports = getMapData;\n","var baseIsNative = require('./_baseIsNative'),\n    getValue = require('./_getValue');\n\n/**\n * Gets the native function at `key` of `object`.\n *\n * @private\n * @param {Object} object The object to query.\n * @param {string} key The key of the method to get.\n * @returns {*} Returns the function if it's native, else `undefined`.\n */\nfunction getNative(object, key) {\n  var value = getValue(object, key);\n  return baseIsNative(value) ? value : undefined;\n}\n\nmodule.exports = getNative;\n","var overArg = require('./_overArg');\n\n/** Built-in value references. */\nvar getPrototype = overArg(Object.getPrototypeOf, Object);\n\nmodule.exports = getPrototype;\n","var Symbol = require('./_Symbol');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the raw `toStringTag`.\n */\nfunction getRawTag(value) {\n  var isOwn = hasOwnProperty.call(value, symToStringTag),\n      tag = value[symToStringTag];\n\n  try {\n    value[symToStringTag] = undefined;\n    var unmasked = true;\n  } catch (e) {}\n\n  var result = nativeObjectToString.call(value);\n  if (unmasked) {\n    if (isOwn) {\n      value[symToStringTag] = tag;\n    } else {\n      delete value[symToStringTag];\n    }\n  }\n  return result;\n}\n\nmodule.exports = getRawTag;\n","/**\n * Gets the value at `key` of `object`.\n *\n * @private\n * @param {Object} [object] The object to query.\n * @param {string} key The key of the property to get.\n * @returns {*} Returns the property value.\n */\nfunction getValue(object, key) {\n  return object == null ? undefined : object[key];\n}\n\nmodule.exports = getValue;\n","var nativeCreate = require('./_nativeCreate');\n\n/**\n * Removes all key-value entries from the hash.\n *\n * @private\n * @name clear\n * @memberOf Hash\n */\nfunction hashClear() {\n  this.__data__ = nativeCreate ? nativeCreate(null) : {};\n  this.size = 0;\n}\n\nmodule.exports = hashClear;\n","/**\n * Removes `key` and its value from the hash.\n *\n * @private\n * @name delete\n * @memberOf Hash\n * @param {Object} hash The hash to modify.\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction hashDelete(key) {\n  var result = this.has(key) && delete this.__data__[key];\n  this.size -= result ? 1 : 0;\n  return result;\n}\n\nmodule.exports = hashDelete;\n","var nativeCreate = require('./_nativeCreate');\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Gets the hash value for `key`.\n *\n * @private\n * @name get\n * @memberOf Hash\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction hashGet(key) {\n  var data = this.__data__;\n  if (nativeCreate) {\n    var result = data[key];\n    return result === HASH_UNDEFINED ? undefined : result;\n  }\n  return hasOwnProperty.call(data, key) ? data[key] : undefined;\n}\n\nmodule.exports = hashGet;\n","var nativeCreate = require('./_nativeCreate');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Checks if a hash value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf Hash\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction hashHas(key) {\n  var data = this.__data__;\n  return nativeCreate ? (data[key] !== undefined) : hasOwnProperty.call(data, key);\n}\n\nmodule.exports = hashHas;\n","var nativeCreate = require('./_nativeCreate');\n\n/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/**\n * Sets the hash `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf Hash\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the hash instance.\n */\nfunction hashSet(key, value) {\n  var data = this.__data__;\n  this.size += this.has(key) ? 0 : 1;\n  data[key] = (nativeCreate && value === undefined) ? HASH_UNDEFINED : value;\n  return this;\n}\n\nmodule.exports = hashSet;\n","var Symbol = require('./_Symbol'),\n    isArguments = require('./isArguments'),\n    isArray = require('./isArray');\n\n/** Built-in value references. */\nvar spreadableSymbol = Symbol ? Symbol.isConcatSpreadable : undefined;\n\n/**\n * Checks if `value` is a flattenable `arguments` object or array.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is flattenable, else `false`.\n */\nfunction isFlattenable(value) {\n  return isArray(value) || isArguments(value) ||\n    !!(spreadableSymbol && value && value[spreadableSymbol]);\n}\n\nmodule.exports = isFlattenable;\n","/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/** Used to detect unsigned integer values. */\nvar reIsUint = /^(?:0|[1-9]\\d*)$/;\n\n/**\n * Checks if `value` is a valid array-like index.\n *\n * @private\n * @param {*} value The value to check.\n * @param {number} [length=MAX_SAFE_INTEGER] The upper bounds of a valid index.\n * @returns {boolean} Returns `true` if `value` is a valid index, else `false`.\n */\nfunction isIndex(value, length) {\n  var type = typeof value;\n  length = length == null ? MAX_SAFE_INTEGER : length;\n\n  return !!length &&\n    (type == 'number' ||\n      (type != 'symbol' && reIsUint.test(value))) &&\n        (value > -1 && value % 1 == 0 && value < length);\n}\n\nmodule.exports = isIndex;\n","var eq = require('./eq'),\n    isArrayLike = require('./isArrayLike'),\n    isIndex = require('./_isIndex'),\n    isObject = require('./isObject');\n\n/**\n * Checks if the given arguments are from an iteratee call.\n *\n * @private\n * @param {*} value The potential iteratee value argument.\n * @param {*} index The potential iteratee index or key argument.\n * @param {*} object The potential iteratee object argument.\n * @returns {boolean} Returns `true` if the arguments are from an iteratee call,\n *  else `false`.\n */\nfunction isIterateeCall(value, index, object) {\n  if (!isObject(object)) {\n    return false;\n  }\n  var type = typeof index;\n  if (type == 'number'\n        ? (isArrayLike(object) && isIndex(index, object.length))\n        : (type == 'string' && index in object)\n      ) {\n    return eq(object[index], value);\n  }\n  return false;\n}\n\nmodule.exports = isIterateeCall;\n","/**\n * Checks if `value` is suitable for use as unique object key.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is suitable, else `false`.\n */\nfunction isKeyable(value) {\n  var type = typeof value;\n  return (type == 'string' || type == 'number' || type == 'symbol' || type == 'boolean')\n    ? (value !== '__proto__')\n    : (value === null);\n}\n\nmodule.exports = isKeyable;\n","var coreJsData = require('./_coreJsData');\n\n/** Used to detect methods masquerading as native. */\nvar maskSrcKey = (function() {\n  var uid = /[^.]+$/.exec(coreJsData && coreJsData.keys && coreJsData.keys.IE_PROTO || '');\n  return uid ? ('Symbol(src)_1.' + uid) : '';\n}());\n\n/**\n * Checks if `func` has its source masked.\n *\n * @private\n * @param {Function} func The function to check.\n * @returns {boolean} Returns `true` if `func` is masked, else `false`.\n */\nfunction isMasked(func) {\n  return !!maskSrcKey && (maskSrcKey in func);\n}\n\nmodule.exports = isMasked;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Checks if `value` is likely a prototype object.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a prototype, else `false`.\n */\nfunction isPrototype(value) {\n  var Ctor = value && value.constructor,\n      proto = (typeof Ctor == 'function' && Ctor.prototype) || objectProto;\n\n  return value === proto;\n}\n\nmodule.exports = isPrototype;\n","/**\n * Removes all key-value entries from the list cache.\n *\n * @private\n * @name clear\n * @memberOf ListCache\n */\nfunction listCacheClear() {\n  this.__data__ = [];\n  this.size = 0;\n}\n\nmodule.exports = listCacheClear;\n","var assocIndexOf = require('./_assocIndexOf');\n\n/** Used for built-in method references. */\nvar arrayProto = Array.prototype;\n\n/** Built-in value references. */\nvar splice = arrayProto.splice;\n\n/**\n * Removes `key` and its value from the list cache.\n *\n * @private\n * @name delete\n * @memberOf ListCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction listCacheDelete(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    return false;\n  }\n  var lastIndex = data.length - 1;\n  if (index == lastIndex) {\n    data.pop();\n  } else {\n    splice.call(data, index, 1);\n  }\n  --this.size;\n  return true;\n}\n\nmodule.exports = listCacheDelete;\n","var assocIndexOf = require('./_assocIndexOf');\n\n/**\n * Gets the list cache value for `key`.\n *\n * @private\n * @name get\n * @memberOf ListCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction listCacheGet(key) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  return index < 0 ? undefined : data[index][1];\n}\n\nmodule.exports = listCacheGet;\n","var assocIndexOf = require('./_assocIndexOf');\n\n/**\n * Checks if a list cache value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf ListCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction listCacheHas(key) {\n  return assocIndexOf(this.__data__, key) > -1;\n}\n\nmodule.exports = listCacheHas;\n","var assocIndexOf = require('./_assocIndexOf');\n\n/**\n * Sets the list cache `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf ListCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the list cache instance.\n */\nfunction listCacheSet(key, value) {\n  var data = this.__data__,\n      index = assocIndexOf(data, key);\n\n  if (index < 0) {\n    ++this.size;\n    data.push([key, value]);\n  } else {\n    data[index][1] = value;\n  }\n  return this;\n}\n\nmodule.exports = listCacheSet;\n","var Hash = require('./_Hash'),\n    ListCache = require('./_ListCache'),\n    Map = require('./_Map');\n\n/**\n * Removes all key-value entries from the map.\n *\n * @private\n * @name clear\n * @memberOf MapCache\n */\nfunction mapCacheClear() {\n  this.size = 0;\n  this.__data__ = {\n    'hash': new Hash,\n    'map': new (Map || ListCache),\n    'string': new Hash\n  };\n}\n\nmodule.exports = mapCacheClear;\n","var getMapData = require('./_getMapData');\n\n/**\n * Removes `key` and its value from the map.\n *\n * @private\n * @name delete\n * @memberOf MapCache\n * @param {string} key The key of the value to remove.\n * @returns {boolean} Returns `true` if the entry was removed, else `false`.\n */\nfunction mapCacheDelete(key) {\n  var result = getMapData(this, key)['delete'](key);\n  this.size -= result ? 1 : 0;\n  return result;\n}\n\nmodule.exports = mapCacheDelete;\n","var getMapData = require('./_getMapData');\n\n/**\n * Gets the map value for `key`.\n *\n * @private\n * @name get\n * @memberOf MapCache\n * @param {string} key The key of the value to get.\n * @returns {*} Returns the entry value.\n */\nfunction mapCacheGet(key) {\n  return getMapData(this, key).get(key);\n}\n\nmodule.exports = mapCacheGet;\n","var getMapData = require('./_getMapData');\n\n/**\n * Checks if a map value for `key` exists.\n *\n * @private\n * @name has\n * @memberOf MapCache\n * @param {string} key The key of the entry to check.\n * @returns {boolean} Returns `true` if an entry for `key` exists, else `false`.\n */\nfunction mapCacheHas(key) {\n  return getMapData(this, key).has(key);\n}\n\nmodule.exports = mapCacheHas;\n","var getMapData = require('./_getMapData');\n\n/**\n * Sets the map `key` to `value`.\n *\n * @private\n * @name set\n * @memberOf MapCache\n * @param {string} key The key of the value to set.\n * @param {*} value The value to set.\n * @returns {Object} Returns the map cache instance.\n */\nfunction mapCacheSet(key, value) {\n  var data = getMapData(this, key),\n      size = data.size;\n\n  data.set(key, value);\n  this.size += data.size == size ? 0 : 1;\n  return this;\n}\n\nmodule.exports = mapCacheSet;\n","var getNative = require('./_getNative');\n\n/* Built-in method references that are verified to be native. */\nvar nativeCreate = getNative(Object, 'create');\n\nmodule.exports = nativeCreate;\n","/**\n * This function is like\n * [`Object.keys`](http://ecma-international.org/ecma-262/7.0/#sec-object.keys)\n * except that it includes inherited enumerable properties.\n *\n * @private\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n */\nfunction nativeKeysIn(object) {\n  var result = [];\n  if (object != null) {\n    for (var key in Object(object)) {\n      result.push(key);\n    }\n  }\n  return result;\n}\n\nmodule.exports = nativeKeysIn;\n","var freeGlobal = require('./_freeGlobal');\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Detect free variable `process` from Node.js. */\nvar freeProcess = moduleExports && freeGlobal.process;\n\n/** Used to access faster Node.js helpers. */\nvar nodeUtil = (function() {\n  try {\n    // Use `util.types` for Node.js 10+.\n    var types = freeModule && freeModule.require && freeModule.require('util').types;\n\n    if (types) {\n      return types;\n    }\n\n    // Legacy `process.binding('util')` for Node.js < 10.\n    return freeProcess && freeProcess.binding && freeProcess.binding('util');\n  } catch (e) {}\n}());\n\nmodule.exports = nodeUtil;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/**\n * Converts `value` to a string using `Object.prototype.toString`.\n *\n * @private\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n */\nfunction objectToString(value) {\n  return nativeObjectToString.call(value);\n}\n\nmodule.exports = objectToString;\n","/**\n * Creates a unary function that invokes `func` with its argument transformed.\n *\n * @private\n * @param {Function} func The function to wrap.\n * @param {Function} transform The argument transform.\n * @returns {Function} Returns the new function.\n */\nfunction overArg(func, transform) {\n  return function(arg) {\n    return func(transform(arg));\n  };\n}\n\nmodule.exports = overArg;\n","var apply = require('./_apply');\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeMax = Math.max;\n\n/**\n * A specialized version of `baseRest` which transforms the rest array.\n *\n * @private\n * @param {Function} func The function to apply a rest parameter to.\n * @param {number} [start=func.length-1] The start position of the rest parameter.\n * @param {Function} transform The rest array transform.\n * @returns {Function} Returns the new function.\n */\nfunction overRest(func, start, transform) {\n  start = nativeMax(start === undefined ? (func.length - 1) : start, 0);\n  return function() {\n    var args = arguments,\n        index = -1,\n        length = nativeMax(args.length - start, 0),\n        array = Array(length);\n\n    while (++index < length) {\n      array[index] = args[start + index];\n    }\n    index = -1;\n    var otherArgs = Array(start + 1);\n    while (++index < start) {\n      otherArgs[index] = args[index];\n    }\n    otherArgs[start] = transform(array);\n    return apply(func, this, otherArgs);\n  };\n}\n\nmodule.exports = overRest;\n","var freeGlobal = require('./_freeGlobal');\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\nmodule.exports = root;\n","/** Used to stand-in for `undefined` hash values. */\nvar HASH_UNDEFINED = '__lodash_hash_undefined__';\n\n/**\n * Adds `value` to the array cache.\n *\n * @private\n * @name add\n * @memberOf SetCache\n * @alias push\n * @param {*} value The value to cache.\n * @returns {Object} Returns the cache instance.\n */\nfunction setCacheAdd(value) {\n  this.__data__.set(value, HASH_UNDEFINED);\n  return this;\n}\n\nmodule.exports = setCacheAdd;\n","/**\n * Checks if `value` is in the array cache.\n *\n * @private\n * @name has\n * @memberOf SetCache\n * @param {*} value The value to search for.\n * @returns {number} Returns `true` if `value` is found, else `false`.\n */\nfunction setCacheHas(value) {\n  return this.__data__.has(value);\n}\n\nmodule.exports = setCacheHas;\n","/**\n * Converts `set` to an array of its values.\n *\n * @private\n * @param {Object} set The set to convert.\n * @returns {Array} Returns the values.\n */\nfunction setToArray(set) {\n  var index = -1,\n      result = Array(set.size);\n\n  set.forEach(function(value) {\n    result[++index] = value;\n  });\n  return result;\n}\n\nmodule.exports = setToArray;\n","var baseSetToString = require('./_baseSetToString'),\n    shortOut = require('./_shortOut');\n\n/**\n * Sets the `toString` method of `func` to return `string`.\n *\n * @private\n * @param {Function} func The function to modify.\n * @param {Function} string The `toString` result.\n * @returns {Function} Returns `func`.\n */\nvar setToString = shortOut(baseSetToString);\n\nmodule.exports = setToString;\n","/** Used to detect hot functions by number of calls within a span of milliseconds. */\nvar HOT_COUNT = 800,\n    HOT_SPAN = 16;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeNow = Date.now;\n\n/**\n * Creates a function that'll short out and invoke `identity` instead\n * of `func` when it's called `HOT_COUNT` or more times in `HOT_SPAN`\n * milliseconds.\n *\n * @private\n * @param {Function} func The function to restrict.\n * @returns {Function} Returns the new shortable function.\n */\nfunction shortOut(func) {\n  var count = 0,\n      lastCalled = 0;\n\n  return function() {\n    var stamp = nativeNow(),\n        remaining = HOT_SPAN - (stamp - lastCalled);\n\n    lastCalled = stamp;\n    if (remaining > 0) {\n      if (++count >= HOT_COUNT) {\n        return arguments[0];\n      }\n    } else {\n      count = 0;\n    }\n    return func.apply(undefined, arguments);\n  };\n}\n\nmodule.exports = shortOut;\n","/**\n * A specialized version of `_.indexOf` which performs strict equality\n * comparisons of values, i.e. `===`.\n *\n * @private\n * @param {Array} array The array to inspect.\n * @param {*} value The value to search for.\n * @param {number} fromIndex The index to search from.\n * @returns {number} Returns the index of the matched value, else `-1`.\n */\nfunction strictIndexOf(array, value, fromIndex) {\n  var index = fromIndex - 1,\n      length = array.length;\n\n  while (++index < length) {\n    if (array[index] === value) {\n      return index;\n    }\n  }\n  return -1;\n}\n\nmodule.exports = strictIndexOf;\n","/** Used for built-in method references. */\nvar funcProto = Function.prototype;\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/**\n * Converts `func` to its source code.\n *\n * @private\n * @param {Function} func The function to convert.\n * @returns {string} Returns the source code.\n */\nfunction toSource(func) {\n  if (func != null) {\n    try {\n      return funcToString.call(func);\n    } catch (e) {}\n    try {\n      return (func + '');\n    } catch (e) {}\n  }\n  return '';\n}\n\nmodule.exports = toSource;\n","/**\n * Creates a function that returns `value`.\n *\n * @static\n * @memberOf _\n * @since 2.4.0\n * @category Util\n * @param {*} value The value to return from the new function.\n * @returns {Function} Returns the new constant function.\n * @example\n *\n * var objects = _.times(2, _.constant({ 'a': 1 }));\n *\n * console.log(objects);\n * // => [{ 'a': 1 }, { 'a': 1 }]\n *\n * console.log(objects[0] === objects[1]);\n * // => true\n */\nfunction constant(value) {\n  return function() {\n    return value;\n  };\n}\n\nmodule.exports = constant;\n","var baseRest = require('./_baseRest'),\n    eq = require('./eq'),\n    isIterateeCall = require('./_isIterateeCall'),\n    keysIn = require('./keysIn');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Assigns own and inherited enumerable string keyed properties of source\n * objects to the destination object for all destination properties that\n * resolve to `undefined`. Source objects are applied from left to right.\n * Once a property is set, additional values of the same property are ignored.\n *\n * **Note:** This method mutates `object`.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Object\n * @param {Object} object The destination object.\n * @param {...Object} [sources] The source objects.\n * @returns {Object} Returns `object`.\n * @see _.defaultsDeep\n * @example\n *\n * _.defaults({ 'a': 1 }, { 'b': 2 }, { 'a': 3 });\n * // => { 'a': 1, 'b': 2 }\n */\nvar defaults = baseRest(function(object, sources) {\n  object = Object(object);\n\n  var index = -1;\n  var length = sources.length;\n  var guard = length > 2 ? sources[2] : undefined;\n\n  if (guard && isIterateeCall(sources[0], sources[1], guard)) {\n    length = 1;\n  }\n\n  while (++index < length) {\n    var source = sources[index];\n    var props = keysIn(source);\n    var propsIndex = -1;\n    var propsLength = props.length;\n\n    while (++propsIndex < propsLength) {\n      var key = props[propsIndex];\n      var value = object[key];\n\n      if (value === undefined ||\n          (eq(value, objectProto[key]) && !hasOwnProperty.call(object, key))) {\n        object[key] = source[key];\n      }\n    }\n  }\n\n  return object;\n});\n\nmodule.exports = defaults;\n","var baseDifference = require('./_baseDifference'),\n    baseFlatten = require('./_baseFlatten'),\n    baseRest = require('./_baseRest'),\n    isArrayLikeObject = require('./isArrayLikeObject');\n\n/**\n * Creates an array of `array` values not included in the other given arrays\n * using [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons. The order and references of result values are\n * determined by the first array.\n *\n * **Note:** Unlike `_.pullAll`, this method returns a new array.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to inspect.\n * @param {...Array} [values] The values to exclude.\n * @returns {Array} Returns the new array of filtered values.\n * @see _.without, _.xor\n * @example\n *\n * _.difference([2, 1], [2, 3]);\n * // => [1]\n */\nvar difference = baseRest(function(array, values) {\n  return isArrayLikeObject(array)\n    ? baseDifference(array, baseFlatten(values, 1, isArrayLikeObject, true))\n    : [];\n});\n\nmodule.exports = difference;\n","/**\n * Performs a\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * comparison between two values to determine if they are equivalent.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to compare.\n * @param {*} other The other value to compare.\n * @returns {boolean} Returns `true` if the values are equivalent, else `false`.\n * @example\n *\n * var object = { 'a': 1 };\n * var other = { 'a': 1 };\n *\n * _.eq(object, object);\n * // => true\n *\n * _.eq(object, other);\n * // => false\n *\n * _.eq('a', 'a');\n * // => true\n *\n * _.eq('a', Object('a'));\n * // => false\n *\n * _.eq(NaN, NaN);\n * // => true\n */\nfunction eq(value, other) {\n  return value === other || (value !== value && other !== other);\n}\n\nmodule.exports = eq;\n","var baseFlatten = require('./_baseFlatten');\n\n/**\n * Flattens `array` a single level deep.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to flatten.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * _.flatten([1, [2, [3, [4]], 5]]);\n * // => [1, 2, [3, [4]], 5]\n */\nfunction flatten(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? baseFlatten(array, 1) : [];\n}\n\nmodule.exports = flatten;\n","/**\n * This method returns the first argument it receives.\n *\n * @static\n * @since 0.1.0\n * @memberOf _\n * @category Util\n * @param {*} value Any value.\n * @returns {*} Returns `value`.\n * @example\n *\n * var object = { 'a': 1 };\n *\n * console.log(_.identity(object) === object);\n * // => true\n */\nfunction identity(value) {\n  return value;\n}\n\nmodule.exports = identity;\n","var baseIsArguments = require('./_baseIsArguments'),\n    isObjectLike = require('./isObjectLike');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Built-in value references. */\nvar propertyIsEnumerable = objectProto.propertyIsEnumerable;\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nvar isArguments = baseIsArguments(function() { return arguments; }()) ? baseIsArguments : function(value) {\n  return isObjectLike(value) && hasOwnProperty.call(value, 'callee') &&\n    !propertyIsEnumerable.call(value, 'callee');\n};\n\nmodule.exports = isArguments;\n","/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\nmodule.exports = isArray;\n","var isFunction = require('./isFunction'),\n    isLength = require('./isLength');\n\n/**\n * Checks if `value` is array-like. A value is considered array-like if it's\n * not a function and has a `value.length` that's an integer greater than or\n * equal to `0` and less than or equal to `Number.MAX_SAFE_INTEGER`.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is array-like, else `false`.\n * @example\n *\n * _.isArrayLike([1, 2, 3]);\n * // => true\n *\n * _.isArrayLike(document.body.children);\n * // => true\n *\n * _.isArrayLike('abc');\n * // => true\n *\n * _.isArrayLike(_.noop);\n * // => false\n */\nfunction isArrayLike(value) {\n  return value != null && isLength(value.length) && !isFunction(value);\n}\n\nmodule.exports = isArrayLike;\n","var isArrayLike = require('./isArrayLike'),\n    isObjectLike = require('./isObjectLike');\n\n/**\n * This method is like `_.isArrayLike` except that it also checks if `value`\n * is an object.\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array-like object,\n *  else `false`.\n * @example\n *\n * _.isArrayLikeObject([1, 2, 3]);\n * // => true\n *\n * _.isArrayLikeObject(document.body.children);\n * // => true\n *\n * _.isArrayLikeObject('abc');\n * // => false\n *\n * _.isArrayLikeObject(_.noop);\n * // => false\n */\nfunction isArrayLikeObject(value) {\n  return isObjectLike(value) && isArrayLike(value);\n}\n\nmodule.exports = isArrayLikeObject;\n","var root = require('./_root'),\n    stubFalse = require('./stubFalse');\n\n/** Detect free variable `exports`. */\nvar freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;\n\n/** Detect free variable `module`. */\nvar freeModule = freeExports && typeof module == 'object' && module && !module.nodeType && module;\n\n/** Detect the popular CommonJS extension `module.exports`. */\nvar moduleExports = freeModule && freeModule.exports === freeExports;\n\n/** Built-in value references. */\nvar Buffer = moduleExports ? root.Buffer : undefined;\n\n/* Built-in method references for those with the same name as other `lodash` methods. */\nvar nativeIsBuffer = Buffer ? Buffer.isBuffer : undefined;\n\n/**\n * Checks if `value` is a buffer.\n *\n * @static\n * @memberOf _\n * @since 4.3.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a buffer, else `false`.\n * @example\n *\n * _.isBuffer(new Buffer(2));\n * // => true\n *\n * _.isBuffer(new Uint8Array(2));\n * // => false\n */\nvar isBuffer = nativeIsBuffer || stubFalse;\n\nmodule.exports = isBuffer;\n","var baseGetTag = require('./_baseGetTag'),\n    isObject = require('./isObject');\n\n/** `Object#toString` result references. */\nvar asyncTag = '[object AsyncFunction]',\n    funcTag = '[object Function]',\n    genTag = '[object GeneratorFunction]',\n    proxyTag = '[object Proxy]';\n\n/**\n * Checks if `value` is classified as a `Function` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a function, else `false`.\n * @example\n *\n * _.isFunction(_);\n * // => true\n *\n * _.isFunction(/abc/);\n * // => false\n */\nfunction isFunction(value) {\n  if (!isObject(value)) {\n    return false;\n  }\n  // The use of `Object#toString` avoids issues with the `typeof` operator\n  // in Safari 9 which returns 'object' for typed arrays and other constructors.\n  var tag = baseGetTag(value);\n  return tag == funcTag || tag == genTag || tag == asyncTag || tag == proxyTag;\n}\n\nmodule.exports = isFunction;\n","/** Used as references for various `Number` constants. */\nvar MAX_SAFE_INTEGER = 9007199254740991;\n\n/**\n * Checks if `value` is a valid array-like length.\n *\n * **Note:** This method is loosely based on\n * [`ToLength`](http://ecma-international.org/ecma-262/7.0/#sec-tolength).\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a valid length, else `false`.\n * @example\n *\n * _.isLength(3);\n * // => true\n *\n * _.isLength(Number.MIN_VALUE);\n * // => false\n *\n * _.isLength(Infinity);\n * // => false\n *\n * _.isLength('3');\n * // => false\n */\nfunction isLength(value) {\n  return typeof value == 'number' &&\n    value > -1 && value % 1 == 0 && value <= MAX_SAFE_INTEGER;\n}\n\nmodule.exports = isLength;\n","/**\n * Checks if `value` is the\n * [language type](http://www.ecma-international.org/ecma-262/7.0/#sec-ecmascript-language-types)\n * of `Object`. (e.g. arrays, functions, objects, regexes, `new Number(0)`, and `new String('')`)\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an object, else `false`.\n * @example\n *\n * _.isObject({});\n * // => true\n *\n * _.isObject([1, 2, 3]);\n * // => true\n *\n * _.isObject(_.noop);\n * // => true\n *\n * _.isObject(null);\n * // => false\n */\nfunction isObject(value) {\n  var type = typeof value;\n  return value != null && (type == 'object' || type == 'function');\n}\n\nmodule.exports = isObject;\n","/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return value != null && typeof value == 'object';\n}\n\nmodule.exports = isObjectLike;\n","var baseGetTag = require('./_baseGetTag'),\n    getPrototype = require('./_getPrototype'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar objectTag = '[object Object]';\n\n/** Used for built-in method references. */\nvar funcProto = Function.prototype,\n    objectProto = Object.prototype;\n\n/** Used to resolve the decompiled source of functions. */\nvar funcToString = funcProto.toString;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Used to infer the `Object` constructor. */\nvar objectCtorString = funcToString.call(Object);\n\n/**\n * Checks if `value` is a plain object, that is, an object created by the\n * `Object` constructor or one with a `[[Prototype]]` of `null`.\n *\n * @static\n * @memberOf _\n * @since 0.8.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a plain object, else `false`.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n * }\n *\n * _.isPlainObject(new Foo);\n * // => false\n *\n * _.isPlainObject([1, 2, 3]);\n * // => false\n *\n * _.isPlainObject({ 'x': 0, 'y': 0 });\n * // => true\n *\n * _.isPlainObject(Object.create(null));\n * // => true\n */\nfunction isPlainObject(value) {\n  if (!isObjectLike(value) || baseGetTag(value) != objectTag) {\n    return false;\n  }\n  var proto = getPrototype(value);\n  if (proto === null) {\n    return true;\n  }\n  var Ctor = hasOwnProperty.call(proto, 'constructor') && proto.constructor;\n  return typeof Ctor == 'function' && Ctor instanceof Ctor &&\n    funcToString.call(Ctor) == objectCtorString;\n}\n\nmodule.exports = isPlainObject;\n","var baseIsTypedArray = require('./_baseIsTypedArray'),\n    baseUnary = require('./_baseUnary'),\n    nodeUtil = require('./_nodeUtil');\n\n/* Node.js helper references. */\nvar nodeIsTypedArray = nodeUtil && nodeUtil.isTypedArray;\n\n/**\n * Checks if `value` is classified as a typed array.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is a typed array, else `false`.\n * @example\n *\n * _.isTypedArray(new Uint8Array);\n * // => true\n *\n * _.isTypedArray([]);\n * // => false\n */\nvar isTypedArray = nodeIsTypedArray ? baseUnary(nodeIsTypedArray) : baseIsTypedArray;\n\nmodule.exports = isTypedArray;\n","var arrayLikeKeys = require('./_arrayLikeKeys'),\n    baseKeysIn = require('./_baseKeysIn'),\n    isArrayLike = require('./isArrayLike');\n\n/**\n * Creates an array of the own and inherited enumerable property names of `object`.\n *\n * **Note:** Non-object values are coerced to objects.\n *\n * @static\n * @memberOf _\n * @since 3.0.0\n * @category Object\n * @param {Object} object The object to query.\n * @returns {Array} Returns the array of property names.\n * @example\n *\n * function Foo() {\n *   this.a = 1;\n *   this.b = 2;\n * }\n *\n * Foo.prototype.c = 3;\n *\n * _.keysIn(new Foo);\n * // => ['a', 'b', 'c'] (iteration order is not guaranteed)\n */\nfunction keysIn(object) {\n  return isArrayLike(object) ? arrayLikeKeys(object, true) : baseKeysIn(object);\n}\n\nmodule.exports = keysIn;\n","/**\n * This method returns `undefined`.\n *\n * @static\n * @memberOf _\n * @since 2.3.0\n * @category Util\n * @example\n *\n * _.times(2, _.noop);\n * // => [undefined, undefined]\n */\nfunction noop() {\n  // No operation performed.\n}\n\nmodule.exports = noop;\n","/**\n * This method returns `false`.\n *\n * @static\n * @memberOf _\n * @since 4.13.0\n * @category Util\n * @returns {boolean} Returns `false`.\n * @example\n *\n * _.times(2, _.stubFalse);\n * // => [false, false]\n */\nfunction stubFalse() {\n  return false;\n}\n\nmodule.exports = stubFalse;\n","var baseFlatten = require('./_baseFlatten'),\n    baseRest = require('./_baseRest'),\n    baseUniq = require('./_baseUniq'),\n    isArrayLikeObject = require('./isArrayLikeObject');\n\n/**\n * Creates an array of unique values, in order, from all given arrays using\n * [`SameValueZero`](http://ecma-international.org/ecma-262/7.0/#sec-samevaluezero)\n * for equality comparisons.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {...Array} [arrays] The arrays to inspect.\n * @returns {Array} Returns the new array of combined values.\n * @example\n *\n * _.union([2], [1, 2]);\n * // => [2, 1]\n */\nvar union = baseRest(function(arrays) {\n  return baseUniq(baseFlatten(arrays, 1, isArrayLikeObject, true));\n});\n\nmodule.exports = union;\n","/*!\n * normalize-path <https://github.com/jonschlinkert/normalize-path>\n *\n * Copyright (c) 2014-2018, Jon Schlinkert.\n * Released under the MIT License.\n */\n\nmodule.exports = function(path, stripTrailing) {\n  if (typeof path !== 'string') {\n    throw new TypeError('expected path to be a string');\n  }\n\n  if (path === '\\\\' || path === '/') return '/';\n\n  var len = path.length;\n  if (len <= 1) return path;\n\n  // ensure that win32 namespaces has two leading slashes, so that the path is\n  // handled properly by the win32 version of path.parse() after being normalized\n  // https://msdn.microsoft.com/library/windows/desktop/aa365247(v=vs.85).aspx#namespaces\n  var prefix = '';\n  if (len > 4 && path[3] === '\\\\') {\n    var ch = path[2];\n    if ((ch === '?' || ch === '.') && path.slice(0, 2) === '\\\\\\\\') {\n      path = path.slice(2);\n      prefix = '//';\n    }\n  }\n\n  var segs = path.split(/[/\\\\]+/);\n  if (stripTrailing !== false && segs[segs.length - 1] === '') {\n    segs.pop();\n  }\n  return prefix + segs.join('/');\n};\n","'use strict';\n\nif (typeof process === 'undefined' ||\n    !process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n","// for now just expose the builtin process global from node.js\nmodule.exports = global.process;\n","'use strict'\n\nconst { SymbolDispose } = require('../../ours/primordials')\nconst { AbortError, codes } = require('../../ours/errors')\nconst { isNodeStream, isWebStream, kControllerErrorFunction } = require('./utils')\nconst eos = require('./end-of-stream')\nconst { ERR_INVALID_ARG_TYPE } = codes\nlet addAbortListener\n\n// This method is inlined here for readable-stream\n// It also does not allow for signal to not exist on the stream\n// https://github.com/nodejs/node/pull/36061#discussion_r533718029\nconst validateAbortSignal = (signal, name) => {\n  if (typeof signal !== 'object' || !('aborted' in signal)) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)\n  }\n}\nmodule.exports.addAbortSignal = function addAbortSignal(signal, stream) {\n  validateAbortSignal(signal, 'signal')\n  if (!isNodeStream(stream) && !isWebStream(stream)) {\n    throw new ERR_INVALID_ARG_TYPE('stream', ['ReadableStream', 'WritableStream', 'Stream'], stream)\n  }\n  return module.exports.addAbortSignalNoValidate(signal, stream)\n}\nmodule.exports.addAbortSignalNoValidate = function (signal, stream) {\n  if (typeof signal !== 'object' || !('aborted' in signal)) {\n    return stream\n  }\n  const onAbort = isNodeStream(stream)\n    ? () => {\n        stream.destroy(\n          new AbortError(undefined, {\n            cause: signal.reason\n          })\n        )\n      }\n    : () => {\n        stream[kControllerErrorFunction](\n          new AbortError(undefined, {\n            cause: signal.reason\n          })\n        )\n      }\n  if (signal.aborted) {\n    onAbort()\n  } else {\n    addAbortListener = addAbortListener || require('../../ours/util').addAbortListener\n    const disposable = addAbortListener(signal, onAbort)\n    eos(stream, disposable[SymbolDispose])\n  }\n  return stream\n}\n","'use strict'\n\nconst { StringPrototypeSlice, SymbolIterator, TypedArrayPrototypeSet, Uint8Array } = require('../../ours/primordials')\nconst { Buffer } = require('buffer')\nconst { inspect } = require('../../ours/util')\nmodule.exports = class BufferList {\n  constructor() {\n    this.head = null\n    this.tail = null\n    this.length = 0\n  }\n  push(v) {\n    const entry = {\n      data: v,\n      next: null\n    }\n    if (this.length > 0) this.tail.next = entry\n    else this.head = entry\n    this.tail = entry\n    ++this.length\n  }\n  unshift(v) {\n    const entry = {\n      data: v,\n      next: this.head\n    }\n    if (this.length === 0) this.tail = entry\n    this.head = entry\n    ++this.length\n  }\n  shift() {\n    if (this.length === 0) return\n    const ret = this.head.data\n    if (this.length === 1) this.head = this.tail = null\n    else this.head = this.head.next\n    --this.length\n    return ret\n  }\n  clear() {\n    this.head = this.tail = null\n    this.length = 0\n  }\n  join(s) {\n    if (this.length === 0) return ''\n    let p = this.head\n    let ret = '' + p.data\n    while ((p = p.next) !== null) ret += s + p.data\n    return ret\n  }\n  concat(n) {\n    if (this.length === 0) return Buffer.alloc(0)\n    const ret = Buffer.allocUnsafe(n >>> 0)\n    let p = this.head\n    let i = 0\n    while (p) {\n      TypedArrayPrototypeSet(ret, p.data, i)\n      i += p.data.length\n      p = p.next\n    }\n    return ret\n  }\n\n  // Consumes a specified amount of bytes or characters from the buffered data.\n  consume(n, hasStrings) {\n    const data = this.head.data\n    if (n < data.length) {\n      // `slice` is the same for buffers and strings.\n      const slice = data.slice(0, n)\n      this.head.data = data.slice(n)\n      return slice\n    }\n    if (n === data.length) {\n      // First chunk is a perfect match.\n      return this.shift()\n    }\n    // Result spans more than one buffer.\n    return hasStrings ? this._getString(n) : this._getBuffer(n)\n  }\n  first() {\n    return this.head.data\n  }\n  *[SymbolIterator]() {\n    for (let p = this.head; p; p = p.next) {\n      yield p.data\n    }\n  }\n\n  // Consumes a specified amount of characters from the buffered data.\n  _getString(n) {\n    let ret = ''\n    let p = this.head\n    let c = 0\n    do {\n      const str = p.data\n      if (n > str.length) {\n        ret += str\n        n -= str.length\n      } else {\n        if (n === str.length) {\n          ret += str\n          ++c\n          if (p.next) this.head = p.next\n          else this.head = this.tail = null\n        } else {\n          ret += StringPrototypeSlice(str, 0, n)\n          this.head = p\n          p.data = StringPrototypeSlice(str, n)\n        }\n        break\n      }\n      ++c\n    } while ((p = p.next) !== null)\n    this.length -= c\n    return ret\n  }\n\n  // Consumes a specified amount of bytes from the buffered data.\n  _getBuffer(n) {\n    const ret = Buffer.allocUnsafe(n)\n    const retLen = n\n    let p = this.head\n    let c = 0\n    do {\n      const buf = p.data\n      if (n > buf.length) {\n        TypedArrayPrototypeSet(ret, buf, retLen - n)\n        n -= buf.length\n      } else {\n        if (n === buf.length) {\n          TypedArrayPrototypeSet(ret, buf, retLen - n)\n          ++c\n          if (p.next) this.head = p.next\n          else this.head = this.tail = null\n        } else {\n          TypedArrayPrototypeSet(ret, new Uint8Array(buf.buffer, buf.byteOffset, n), retLen - n)\n          this.head = p\n          p.data = buf.slice(n)\n        }\n        break\n      }\n      ++c\n    } while ((p = p.next) !== null)\n    this.length -= c\n    return ret\n  }\n\n  // Make sure the linked list only shows the minimal necessary information.\n  [Symbol.for('nodejs.util.inspect.custom')](_, options) {\n    return inspect(this, {\n      ...options,\n      // Only inspect one level.\n      depth: 0,\n      // It should not recurse.\n      customInspect: false\n    })\n  }\n}\n","'use strict'\n\nconst { pipeline } = require('./pipeline')\nconst Duplex = require('./duplex')\nconst { destroyer } = require('./destroy')\nconst {\n  isNodeStream,\n  isReadable,\n  isWritable,\n  isWebStream,\n  isTransformStream,\n  isWritableStream,\n  isReadableStream\n} = require('./utils')\nconst {\n  AbortError,\n  codes: { ERR_INVALID_ARG_VALUE, ERR_MISSING_ARGS }\n} = require('../../ours/errors')\nconst eos = require('./end-of-stream')\nmodule.exports = function compose(...streams) {\n  if (streams.length === 0) {\n    throw new ERR_MISSING_ARGS('streams')\n  }\n  if (streams.length === 1) {\n    return Duplex.from(streams[0])\n  }\n  const orgStreams = [...streams]\n  if (typeof streams[0] === 'function') {\n    streams[0] = Duplex.from(streams[0])\n  }\n  if (typeof streams[streams.length - 1] === 'function') {\n    const idx = streams.length - 1\n    streams[idx] = Duplex.from(streams[idx])\n  }\n  for (let n = 0; n < streams.length; ++n) {\n    if (!isNodeStream(streams[n]) && !isWebStream(streams[n])) {\n      // TODO(ronag): Add checks for non streams.\n      continue\n    }\n    if (\n      n < streams.length - 1 &&\n      !(isReadable(streams[n]) || isReadableStream(streams[n]) || isTransformStream(streams[n]))\n    ) {\n      throw new ERR_INVALID_ARG_VALUE(`streams[${n}]`, orgStreams[n], 'must be readable')\n    }\n    if (n > 0 && !(isWritable(streams[n]) || isWritableStream(streams[n]) || isTransformStream(streams[n]))) {\n      throw new ERR_INVALID_ARG_VALUE(`streams[${n}]`, orgStreams[n], 'must be writable')\n    }\n  }\n  let ondrain\n  let onfinish\n  let onreadable\n  let onclose\n  let d\n  function onfinished(err) {\n    const cb = onclose\n    onclose = null\n    if (cb) {\n      cb(err)\n    } else if (err) {\n      d.destroy(err)\n    } else if (!readable && !writable) {\n      d.destroy()\n    }\n  }\n  const head = streams[0]\n  const tail = pipeline(streams, onfinished)\n  const writable = !!(isWritable(head) || isWritableStream(head) || isTransformStream(head))\n  const readable = !!(isReadable(tail) || isReadableStream(tail) || isTransformStream(tail))\n\n  // TODO(ronag): Avoid double buffering.\n  // Implement Writable/Readable/Duplex traits.\n  // See, https://github.com/nodejs/node/pull/33515.\n  d = new Duplex({\n    // TODO (ronag): highWaterMark?\n    writableObjectMode: !!(head !== null && head !== undefined && head.writableObjectMode),\n    readableObjectMode: !!(tail !== null && tail !== undefined && tail.readableObjectMode),\n    writable,\n    readable\n  })\n  if (writable) {\n    if (isNodeStream(head)) {\n      d._write = function (chunk, encoding, callback) {\n        if (head.write(chunk, encoding)) {\n          callback()\n        } else {\n          ondrain = callback\n        }\n      }\n      d._final = function (callback) {\n        head.end()\n        onfinish = callback\n      }\n      head.on('drain', function () {\n        if (ondrain) {\n          const cb = ondrain\n          ondrain = null\n          cb()\n        }\n      })\n    } else if (isWebStream(head)) {\n      const writable = isTransformStream(head) ? head.writable : head\n      const writer = writable.getWriter()\n      d._write = async function (chunk, encoding, callback) {\n        try {\n          await writer.ready\n          writer.write(chunk).catch(() => {})\n          callback()\n        } catch (err) {\n          callback(err)\n        }\n      }\n      d._final = async function (callback) {\n        try {\n          await writer.ready\n          writer.close().catch(() => {})\n          onfinish = callback\n        } catch (err) {\n          callback(err)\n        }\n      }\n    }\n    const toRead = isTransformStream(tail) ? tail.readable : tail\n    eos(toRead, () => {\n      if (onfinish) {\n        const cb = onfinish\n        onfinish = null\n        cb()\n      }\n    })\n  }\n  if (readable) {\n    if (isNodeStream(tail)) {\n      tail.on('readable', function () {\n        if (onreadable) {\n          const cb = onreadable\n          onreadable = null\n          cb()\n        }\n      })\n      tail.on('end', function () {\n        d.push(null)\n      })\n      d._read = function () {\n        while (true) {\n          const buf = tail.read()\n          if (buf === null) {\n            onreadable = d._read\n            return\n          }\n          if (!d.push(buf)) {\n            return\n          }\n        }\n      }\n    } else if (isWebStream(tail)) {\n      const readable = isTransformStream(tail) ? tail.readable : tail\n      const reader = readable.getReader()\n      d._read = async function () {\n        while (true) {\n          try {\n            const { value, done } = await reader.read()\n            if (!d.push(value)) {\n              return\n            }\n            if (done) {\n              d.push(null)\n              return\n            }\n          } catch {\n            return\n          }\n        }\n      }\n    }\n  }\n  d._destroy = function (err, callback) {\n    if (!err && onclose !== null) {\n      err = new AbortError()\n    }\n    onreadable = null\n    ondrain = null\n    onfinish = null\n    if (onclose === null) {\n      callback(err)\n    } else {\n      onclose = callback\n      if (isNodeStream(tail)) {\n        destroyer(tail, err)\n      }\n    }\n  }\n  return d\n}\n","'use strict'\n\n/* replacement start */\n\nconst process = require('process/')\n\n/* replacement end */\n\nconst {\n  aggregateTwoErrors,\n  codes: { ERR_MULTIPLE_CALLBACK },\n  AbortError\n} = require('../../ours/errors')\nconst { Symbol } = require('../../ours/primordials')\nconst { kIsDestroyed, isDestroyed, isFinished, isServerRequest } = require('./utils')\nconst kDestroy = Symbol('kDestroy')\nconst kConstruct = Symbol('kConstruct')\nfunction checkError(err, w, r) {\n  if (err) {\n    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364\n    err.stack // eslint-disable-line no-unused-expressions\n\n    if (w && !w.errored) {\n      w.errored = err\n    }\n    if (r && !r.errored) {\n      r.errored = err\n    }\n  }\n}\n\n// Backwards compat. cb() is undocumented and unused in core but\n// unfortunately might be used by modules.\nfunction destroy(err, cb) {\n  const r = this._readableState\n  const w = this._writableState\n  // With duplex streams we use the writable side for state.\n  const s = w || r\n  if ((w !== null && w !== undefined && w.destroyed) || (r !== null && r !== undefined && r.destroyed)) {\n    if (typeof cb === 'function') {\n      cb()\n    }\n    return this\n  }\n\n  // We set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n  checkError(err, w, r)\n  if (w) {\n    w.destroyed = true\n  }\n  if (r) {\n    r.destroyed = true\n  }\n\n  // If still constructing then defer calling _destroy.\n  if (!s.constructed) {\n    this.once(kDestroy, function (er) {\n      _destroy(this, aggregateTwoErrors(er, err), cb)\n    })\n  } else {\n    _destroy(this, err, cb)\n  }\n  return this\n}\nfunction _destroy(self, err, cb) {\n  let called = false\n  function onDestroy(err) {\n    if (called) {\n      return\n    }\n    called = true\n    const r = self._readableState\n    const w = self._writableState\n    checkError(err, w, r)\n    if (w) {\n      w.closed = true\n    }\n    if (r) {\n      r.closed = true\n    }\n    if (typeof cb === 'function') {\n      cb(err)\n    }\n    if (err) {\n      process.nextTick(emitErrorCloseNT, self, err)\n    } else {\n      process.nextTick(emitCloseNT, self)\n    }\n  }\n  try {\n    self._destroy(err || null, onDestroy)\n  } catch (err) {\n    onDestroy(err)\n  }\n}\nfunction emitErrorCloseNT(self, err) {\n  emitErrorNT(self, err)\n  emitCloseNT(self)\n}\nfunction emitCloseNT(self) {\n  const r = self._readableState\n  const w = self._writableState\n  if (w) {\n    w.closeEmitted = true\n  }\n  if (r) {\n    r.closeEmitted = true\n  }\n  if ((w !== null && w !== undefined && w.emitClose) || (r !== null && r !== undefined && r.emitClose)) {\n    self.emit('close')\n  }\n}\nfunction emitErrorNT(self, err) {\n  const r = self._readableState\n  const w = self._writableState\n  if ((w !== null && w !== undefined && w.errorEmitted) || (r !== null && r !== undefined && r.errorEmitted)) {\n    return\n  }\n  if (w) {\n    w.errorEmitted = true\n  }\n  if (r) {\n    r.errorEmitted = true\n  }\n  self.emit('error', err)\n}\nfunction undestroy() {\n  const r = this._readableState\n  const w = this._writableState\n  if (r) {\n    r.constructed = true\n    r.closed = false\n    r.closeEmitted = false\n    r.destroyed = false\n    r.errored = null\n    r.errorEmitted = false\n    r.reading = false\n    r.ended = r.readable === false\n    r.endEmitted = r.readable === false\n  }\n  if (w) {\n    w.constructed = true\n    w.destroyed = false\n    w.closed = false\n    w.closeEmitted = false\n    w.errored = null\n    w.errorEmitted = false\n    w.finalCalled = false\n    w.prefinished = false\n    w.ended = w.writable === false\n    w.ending = w.writable === false\n    w.finished = w.writable === false\n  }\n}\nfunction errorOrDestroy(stream, err, sync) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n\n  const r = stream._readableState\n  const w = stream._writableState\n  if ((w !== null && w !== undefined && w.destroyed) || (r !== null && r !== undefined && r.destroyed)) {\n    return this\n  }\n  if ((r !== null && r !== undefined && r.autoDestroy) || (w !== null && w !== undefined && w.autoDestroy))\n    stream.destroy(err)\n  else if (err) {\n    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364\n    err.stack // eslint-disable-line no-unused-expressions\n\n    if (w && !w.errored) {\n      w.errored = err\n    }\n    if (r && !r.errored) {\n      r.errored = err\n    }\n    if (sync) {\n      process.nextTick(emitErrorNT, stream, err)\n    } else {\n      emitErrorNT(stream, err)\n    }\n  }\n}\nfunction construct(stream, cb) {\n  if (typeof stream._construct !== 'function') {\n    return\n  }\n  const r = stream._readableState\n  const w = stream._writableState\n  if (r) {\n    r.constructed = false\n  }\n  if (w) {\n    w.constructed = false\n  }\n  stream.once(kConstruct, cb)\n  if (stream.listenerCount(kConstruct) > 1) {\n    // Duplex\n    return\n  }\n  process.nextTick(constructNT, stream)\n}\nfunction constructNT(stream) {\n  let called = false\n  function onConstruct(err) {\n    if (called) {\n      errorOrDestroy(stream, err !== null && err !== undefined ? err : new ERR_MULTIPLE_CALLBACK())\n      return\n    }\n    called = true\n    const r = stream._readableState\n    const w = stream._writableState\n    const s = w || r\n    if (r) {\n      r.constructed = true\n    }\n    if (w) {\n      w.constructed = true\n    }\n    if (s.destroyed) {\n      stream.emit(kDestroy, err)\n    } else if (err) {\n      errorOrDestroy(stream, err, true)\n    } else {\n      process.nextTick(emitConstructNT, stream)\n    }\n  }\n  try {\n    stream._construct((err) => {\n      process.nextTick(onConstruct, err)\n    })\n  } catch (err) {\n    process.nextTick(onConstruct, err)\n  }\n}\nfunction emitConstructNT(stream) {\n  stream.emit(kConstruct)\n}\nfunction isRequest(stream) {\n  return (stream === null || stream === undefined ? undefined : stream.setHeader) && typeof stream.abort === 'function'\n}\nfunction emitCloseLegacy(stream) {\n  stream.emit('close')\n}\nfunction emitErrorCloseLegacy(stream, err) {\n  stream.emit('error', err)\n  process.nextTick(emitCloseLegacy, stream)\n}\n\n// Normalize destroy for legacy.\nfunction destroyer(stream, err) {\n  if (!stream || isDestroyed(stream)) {\n    return\n  }\n  if (!err && !isFinished(stream)) {\n    err = new AbortError()\n  }\n\n  // TODO: Remove isRequest branches.\n  if (isServerRequest(stream)) {\n    stream.socket = null\n    stream.destroy(err)\n  } else if (isRequest(stream)) {\n    stream.abort()\n  } else if (isRequest(stream.req)) {\n    stream.req.abort()\n  } else if (typeof stream.destroy === 'function') {\n    stream.destroy(err)\n  } else if (typeof stream.close === 'function') {\n    // TODO: Don't lose err?\n    stream.close()\n  } else if (err) {\n    process.nextTick(emitErrorCloseLegacy, stream, err)\n  } else {\n    process.nextTick(emitCloseLegacy, stream)\n  }\n  if (!stream.destroyed) {\n    stream[kIsDestroyed] = true\n  }\n}\nmodule.exports = {\n  construct,\n  destroyer,\n  destroy,\n  undestroy,\n  errorOrDestroy\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototype inheritance, this class\n// prototypically inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict'\n\nconst {\n  ObjectDefineProperties,\n  ObjectGetOwnPropertyDescriptor,\n  ObjectKeys,\n  ObjectSetPrototypeOf\n} = require('../../ours/primordials')\nmodule.exports = Duplex\nconst Readable = require('./readable')\nconst Writable = require('./writable')\nObjectSetPrototypeOf(Duplex.prototype, Readable.prototype)\nObjectSetPrototypeOf(Duplex, Readable)\n{\n  const keys = ObjectKeys(Writable.prototype)\n  // Allow the keys array to be GC'ed.\n  for (let i = 0; i < keys.length; i++) {\n    const method = keys[i]\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method]\n  }\n}\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options)\n  Readable.call(this, options)\n  Writable.call(this, options)\n  if (options) {\n    this.allowHalfOpen = options.allowHalfOpen !== false\n    if (options.readable === false) {\n      this._readableState.readable = false\n      this._readableState.ended = true\n      this._readableState.endEmitted = true\n    }\n    if (options.writable === false) {\n      this._writableState.writable = false\n      this._writableState.ending = true\n      this._writableState.ended = true\n      this._writableState.finished = true\n    }\n  } else {\n    this.allowHalfOpen = true\n  }\n}\nObjectDefineProperties(Duplex.prototype, {\n  writable: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writable')\n  },\n  writableHighWaterMark: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableHighWaterMark')\n  },\n  writableObjectMode: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableObjectMode')\n  },\n  writableBuffer: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableBuffer')\n  },\n  writableLength: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableLength')\n  },\n  writableFinished: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableFinished')\n  },\n  writableCorked: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableCorked')\n  },\n  writableEnded: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableEnded')\n  },\n  writableNeedDrain: {\n    __proto__: null,\n    ...ObjectGetOwnPropertyDescriptor(Writable.prototype, 'writableNeedDrain')\n  },\n  destroyed: {\n    __proto__: null,\n    get() {\n      if (this._readableState === undefined || this._writableState === undefined) {\n        return false\n      }\n      return this._readableState.destroyed && this._writableState.destroyed\n    },\n    set(value) {\n      // Backward compatibility, the user is explicitly\n      // managing destroyed.\n      if (this._readableState && this._writableState) {\n        this._readableState.destroyed = value\n        this._writableState.destroyed = value\n      }\n    }\n  }\n})\nlet webStreamsAdapters\n\n// Lazy to avoid circular references\nfunction lazyWebStreams() {\n  if (webStreamsAdapters === undefined) webStreamsAdapters = {}\n  return webStreamsAdapters\n}\nDuplex.fromWeb = function (pair, options) {\n  return lazyWebStreams().newStreamDuplexFromReadableWritablePair(pair, options)\n}\nDuplex.toWeb = function (duplex) {\n  return lazyWebStreams().newReadableWritablePairFromDuplex(duplex)\n}\nlet duplexify\nDuplex.from = function (body) {\n  if (!duplexify) {\n    duplexify = require('./duplexify')\n  }\n  return duplexify(body, 'body')\n}\n","/* replacement start */\n\nconst process = require('process/')\n\n/* replacement end */\n\n;('use strict')\nconst bufferModule = require('buffer')\nconst {\n  isReadable,\n  isWritable,\n  isIterable,\n  isNodeStream,\n  isReadableNodeStream,\n  isWritableNodeStream,\n  isDuplexNodeStream,\n  isReadableStream,\n  isWritableStream\n} = require('./utils')\nconst eos = require('./end-of-stream')\nconst {\n  AbortError,\n  codes: { ERR_INVALID_ARG_TYPE, ERR_INVALID_RETURN_VALUE }\n} = require('../../ours/errors')\nconst { destroyer } = require('./destroy')\nconst Duplex = require('./duplex')\nconst Readable = require('./readable')\nconst Writable = require('./writable')\nconst { createDeferredPromise } = require('../../ours/util')\nconst from = require('./from')\nconst Blob = globalThis.Blob || bufferModule.Blob\nconst isBlob =\n  typeof Blob !== 'undefined'\n    ? function isBlob(b) {\n        return b instanceof Blob\n      }\n    : function isBlob(b) {\n        return false\n      }\nconst AbortController = globalThis.AbortController || require('abort-controller').AbortController\nconst { FunctionPrototypeCall } = require('../../ours/primordials')\n\n// This is needed for pre node 17.\nclass Duplexify extends Duplex {\n  constructor(options) {\n    super(options)\n\n    // https://github.com/nodejs/node/pull/34385\n\n    if ((options === null || options === undefined ? undefined : options.readable) === false) {\n      this._readableState.readable = false\n      this._readableState.ended = true\n      this._readableState.endEmitted = true\n    }\n    if ((options === null || options === undefined ? undefined : options.writable) === false) {\n      this._writableState.writable = false\n      this._writableState.ending = true\n      this._writableState.ended = true\n      this._writableState.finished = true\n    }\n  }\n}\nmodule.exports = function duplexify(body, name) {\n  if (isDuplexNodeStream(body)) {\n    return body\n  }\n  if (isReadableNodeStream(body)) {\n    return _duplexify({\n      readable: body\n    })\n  }\n  if (isWritableNodeStream(body)) {\n    return _duplexify({\n      writable: body\n    })\n  }\n  if (isNodeStream(body)) {\n    return _duplexify({\n      writable: false,\n      readable: false\n    })\n  }\n  if (isReadableStream(body)) {\n    return _duplexify({\n      readable: Readable.fromWeb(body)\n    })\n  }\n  if (isWritableStream(body)) {\n    return _duplexify({\n      writable: Writable.fromWeb(body)\n    })\n  }\n  if (typeof body === 'function') {\n    const { value, write, final, destroy } = fromAsyncGen(body)\n    if (isIterable(value)) {\n      return from(Duplexify, value, {\n        // TODO (ronag): highWaterMark?\n        objectMode: true,\n        write,\n        final,\n        destroy\n      })\n    }\n    const then = value === null || value === undefined ? undefined : value.then\n    if (typeof then === 'function') {\n      let d\n      const promise = FunctionPrototypeCall(\n        then,\n        value,\n        (val) => {\n          if (val != null) {\n            throw new ERR_INVALID_RETURN_VALUE('nully', 'body', val)\n          }\n        },\n        (err) => {\n          destroyer(d, err)\n        }\n      )\n      return (d = new Duplexify({\n        // TODO (ronag): highWaterMark?\n        objectMode: true,\n        readable: false,\n        write,\n        final(cb) {\n          final(async () => {\n            try {\n              await promise\n              process.nextTick(cb, null)\n            } catch (err) {\n              process.nextTick(cb, err)\n            }\n          })\n        },\n        destroy\n      }))\n    }\n    throw new ERR_INVALID_RETURN_VALUE('Iterable, AsyncIterable or AsyncFunction', name, value)\n  }\n  if (isBlob(body)) {\n    return duplexify(body.arrayBuffer())\n  }\n  if (isIterable(body)) {\n    return from(Duplexify, body, {\n      // TODO (ronag): highWaterMark?\n      objectMode: true,\n      writable: false\n    })\n  }\n  if (\n    isReadableStream(body === null || body === undefined ? undefined : body.readable) &&\n    isWritableStream(body === null || body === undefined ? undefined : body.writable)\n  ) {\n    return Duplexify.fromWeb(body)\n  }\n  if (\n    typeof (body === null || body === undefined ? undefined : body.writable) === 'object' ||\n    typeof (body === null || body === undefined ? undefined : body.readable) === 'object'\n  ) {\n    const readable =\n      body !== null && body !== undefined && body.readable\n        ? isReadableNodeStream(body === null || body === undefined ? undefined : body.readable)\n          ? body === null || body === undefined\n            ? undefined\n            : body.readable\n          : duplexify(body.readable)\n        : undefined\n    const writable =\n      body !== null && body !== undefined && body.writable\n        ? isWritableNodeStream(body === null || body === undefined ? undefined : body.writable)\n          ? body === null || body === undefined\n            ? undefined\n            : body.writable\n          : duplexify(body.writable)\n        : undefined\n    return _duplexify({\n      readable,\n      writable\n    })\n  }\n  const then = body === null || body === undefined ? undefined : body.then\n  if (typeof then === 'function') {\n    let d\n    FunctionPrototypeCall(\n      then,\n      body,\n      (val) => {\n        if (val != null) {\n          d.push(val)\n        }\n        d.push(null)\n      },\n      (err) => {\n        destroyer(d, err)\n      }\n    )\n    return (d = new Duplexify({\n      objectMode: true,\n      writable: false,\n      read() {}\n    }))\n  }\n  throw new ERR_INVALID_ARG_TYPE(\n    name,\n    [\n      'Blob',\n      'ReadableStream',\n      'WritableStream',\n      'Stream',\n      'Iterable',\n      'AsyncIterable',\n      'Function',\n      '{ readable, writable } pair',\n      'Promise'\n    ],\n    body\n  )\n}\nfunction fromAsyncGen(fn) {\n  let { promise, resolve } = createDeferredPromise()\n  const ac = new AbortController()\n  const signal = ac.signal\n  const value = fn(\n    (async function* () {\n      while (true) {\n        const _promise = promise\n        promise = null\n        const { chunk, done, cb } = await _promise\n        process.nextTick(cb)\n        if (done) return\n        if (signal.aborted)\n          throw new AbortError(undefined, {\n            cause: signal.reason\n          })\n        ;({ promise, resolve } = createDeferredPromise())\n        yield chunk\n      }\n    })(),\n    {\n      signal\n    }\n  )\n  return {\n    value,\n    write(chunk, encoding, cb) {\n      const _resolve = resolve\n      resolve = null\n      _resolve({\n        chunk,\n        done: false,\n        cb\n      })\n    },\n    final(cb) {\n      const _resolve = resolve\n      resolve = null\n      _resolve({\n        done: true,\n        cb\n      })\n    },\n    destroy(err, cb) {\n      ac.abort()\n      cb(err)\n    }\n  }\n}\nfunction _duplexify(pair) {\n  const r = pair.readable && typeof pair.readable.read !== 'function' ? Readable.wrap(pair.readable) : pair.readable\n  const w = pair.writable\n  let readable = !!isReadable(r)\n  let writable = !!isWritable(w)\n  let ondrain\n  let onfinish\n  let onreadable\n  let onclose\n  let d\n  function onfinished(err) {\n    const cb = onclose\n    onclose = null\n    if (cb) {\n      cb(err)\n    } else if (err) {\n      d.destroy(err)\n    }\n  }\n\n  // TODO(ronag): Avoid double buffering.\n  // Implement Writable/Readable/Duplex traits.\n  // See, https://github.com/nodejs/node/pull/33515.\n  d = new Duplexify({\n    // TODO (ronag): highWaterMark?\n    readableObjectMode: !!(r !== null && r !== undefined && r.readableObjectMode),\n    writableObjectMode: !!(w !== null && w !== undefined && w.writableObjectMode),\n    readable,\n    writable\n  })\n  if (writable) {\n    eos(w, (err) => {\n      writable = false\n      if (err) {\n        destroyer(r, err)\n      }\n      onfinished(err)\n    })\n    d._write = function (chunk, encoding, callback) {\n      if (w.write(chunk, encoding)) {\n        callback()\n      } else {\n        ondrain = callback\n      }\n    }\n    d._final = function (callback) {\n      w.end()\n      onfinish = callback\n    }\n    w.on('drain', function () {\n      if (ondrain) {\n        const cb = ondrain\n        ondrain = null\n        cb()\n      }\n    })\n    w.on('finish', function () {\n      if (onfinish) {\n        const cb = onfinish\n        onfinish = null\n        cb()\n      }\n    })\n  }\n  if (readable) {\n    eos(r, (err) => {\n      readable = false\n      if (err) {\n        destroyer(r, err)\n      }\n      onfinished(err)\n    })\n    r.on('readable', function () {\n      if (onreadable) {\n        const cb = onreadable\n        onreadable = null\n        cb()\n      }\n    })\n    r.on('end', function () {\n      d.push(null)\n    })\n    d._read = function () {\n      while (true) {\n        const buf = r.read()\n        if (buf === null) {\n          onreadable = d._read\n          return\n        }\n        if (!d.push(buf)) {\n          return\n        }\n      }\n    }\n  }\n  d._destroy = function (err, callback) {\n    if (!err && onclose !== null) {\n      err = new AbortError()\n    }\n    onreadable = null\n    ondrain = null\n    onfinish = null\n    if (onclose === null) {\n      callback(err)\n    } else {\n      onclose = callback\n      destroyer(w, err)\n      destroyer(r, err)\n    }\n  }\n  return d\n}\n","// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n\n'use strict'\n\n/* replacement start */\n\nconst process = require('process/')\n\n/* replacement end */\n\nconst { AbortError, codes } = require('../../ours/errors')\nconst { ERR_INVALID_ARG_TYPE, ERR_STREAM_PREMATURE_CLOSE } = codes\nconst { kEmptyObject, once } = require('../../ours/util')\nconst { validateAbortSignal, validateFunction, validateObject, validateBoolean } = require('../validators')\nconst { Promise, PromisePrototypeThen, SymbolDispose } = require('../../ours/primordials')\nconst {\n  isClosed,\n  isReadable,\n  isReadableNodeStream,\n  isReadableStream,\n  isReadableFinished,\n  isReadableErrored,\n  isWritable,\n  isWritableNodeStream,\n  isWritableStream,\n  isWritableFinished,\n  isWritableErrored,\n  isNodeStream,\n  willEmitClose: _willEmitClose,\n  kIsClosedPromise\n} = require('./utils')\nlet addAbortListener\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function'\n}\nconst nop = () => {}\nfunction eos(stream, options, callback) {\n  var _options$readable, _options$writable\n  if (arguments.length === 2) {\n    callback = options\n    options = kEmptyObject\n  } else if (options == null) {\n    options = kEmptyObject\n  } else {\n    validateObject(options, 'options')\n  }\n  validateFunction(callback, 'callback')\n  validateAbortSignal(options.signal, 'options.signal')\n  callback = once(callback)\n  if (isReadableStream(stream) || isWritableStream(stream)) {\n    return eosWeb(stream, options, callback)\n  }\n  if (!isNodeStream(stream)) {\n    throw new ERR_INVALID_ARG_TYPE('stream', ['ReadableStream', 'WritableStream', 'Stream'], stream)\n  }\n  const readable =\n    (_options$readable = options.readable) !== null && _options$readable !== undefined\n      ? _options$readable\n      : isReadableNodeStream(stream)\n  const writable =\n    (_options$writable = options.writable) !== null && _options$writable !== undefined\n      ? _options$writable\n      : isWritableNodeStream(stream)\n  const wState = stream._writableState\n  const rState = stream._readableState\n  const onlegacyfinish = () => {\n    if (!stream.writable) {\n      onfinish()\n    }\n  }\n\n  // TODO (ronag): Improve soft detection to include core modules and\n  // common ecosystem modules that do properly emit 'close' but fail\n  // this generic check.\n  let willEmitClose =\n    _willEmitClose(stream) && isReadableNodeStream(stream) === readable && isWritableNodeStream(stream) === writable\n  let writableFinished = isWritableFinished(stream, false)\n  const onfinish = () => {\n    writableFinished = true\n    // Stream should not be destroyed here. If it is that\n    // means that user space is doing something differently and\n    // we cannot trust willEmitClose.\n    if (stream.destroyed) {\n      willEmitClose = false\n    }\n    if (willEmitClose && (!stream.readable || readable)) {\n      return\n    }\n    if (!readable || readableFinished) {\n      callback.call(stream)\n    }\n  }\n  let readableFinished = isReadableFinished(stream, false)\n  const onend = () => {\n    readableFinished = true\n    // Stream should not be destroyed here. If it is that\n    // means that user space is doing something differently and\n    // we cannot trust willEmitClose.\n    if (stream.destroyed) {\n      willEmitClose = false\n    }\n    if (willEmitClose && (!stream.writable || writable)) {\n      return\n    }\n    if (!writable || writableFinished) {\n      callback.call(stream)\n    }\n  }\n  const onerror = (err) => {\n    callback.call(stream, err)\n  }\n  let closed = isClosed(stream)\n  const onclose = () => {\n    closed = true\n    const errored = isWritableErrored(stream) || isReadableErrored(stream)\n    if (errored && typeof errored !== 'boolean') {\n      return callback.call(stream, errored)\n    }\n    if (readable && !readableFinished && isReadableNodeStream(stream, true)) {\n      if (!isReadableFinished(stream, false)) return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE())\n    }\n    if (writable && !writableFinished) {\n      if (!isWritableFinished(stream, false)) return callback.call(stream, new ERR_STREAM_PREMATURE_CLOSE())\n    }\n    callback.call(stream)\n  }\n  const onclosed = () => {\n    closed = true\n    const errored = isWritableErrored(stream) || isReadableErrored(stream)\n    if (errored && typeof errored !== 'boolean') {\n      return callback.call(stream, errored)\n    }\n    callback.call(stream)\n  }\n  const onrequest = () => {\n    stream.req.on('finish', onfinish)\n  }\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish)\n    if (!willEmitClose) {\n      stream.on('abort', onclose)\n    }\n    if (stream.req) {\n      onrequest()\n    } else {\n      stream.on('request', onrequest)\n    }\n  } else if (writable && !wState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish)\n    stream.on('close', onlegacyfinish)\n  }\n\n  // Not all streams will emit 'close' after 'aborted'.\n  if (!willEmitClose && typeof stream.aborted === 'boolean') {\n    stream.on('aborted', onclose)\n  }\n  stream.on('end', onend)\n  stream.on('finish', onfinish)\n  if (options.error !== false) {\n    stream.on('error', onerror)\n  }\n  stream.on('close', onclose)\n  if (closed) {\n    process.nextTick(onclose)\n  } else if (\n    (wState !== null && wState !== undefined && wState.errorEmitted) ||\n    (rState !== null && rState !== undefined && rState.errorEmitted)\n  ) {\n    if (!willEmitClose) {\n      process.nextTick(onclosed)\n    }\n  } else if (\n    !readable &&\n    (!willEmitClose || isReadable(stream)) &&\n    (writableFinished || isWritable(stream) === false)\n  ) {\n    process.nextTick(onclosed)\n  } else if (\n    !writable &&\n    (!willEmitClose || isWritable(stream)) &&\n    (readableFinished || isReadable(stream) === false)\n  ) {\n    process.nextTick(onclosed)\n  } else if (rState && stream.req && stream.aborted) {\n    process.nextTick(onclosed)\n  }\n  const cleanup = () => {\n    callback = nop\n    stream.removeListener('aborted', onclose)\n    stream.removeListener('complete', onfinish)\n    stream.removeListener('abort', onclose)\n    stream.removeListener('request', onrequest)\n    if (stream.req) stream.req.removeListener('finish', onfinish)\n    stream.removeListener('end', onlegacyfinish)\n    stream.removeListener('close', onlegacyfinish)\n    stream.removeListener('finish', onfinish)\n    stream.removeListener('end', onend)\n    stream.removeListener('error', onerror)\n    stream.removeListener('close', onclose)\n  }\n  if (options.signal && !closed) {\n    const abort = () => {\n      // Keep it because cleanup removes it.\n      const endCallback = callback\n      cleanup()\n      endCallback.call(\n        stream,\n        new AbortError(undefined, {\n          cause: options.signal.reason\n        })\n      )\n    }\n    if (options.signal.aborted) {\n      process.nextTick(abort)\n    } else {\n      addAbortListener = addAbortListener || require('../../ours/util').addAbortListener\n      const disposable = addAbortListener(options.signal, abort)\n      const originalCallback = callback\n      callback = once((...args) => {\n        disposable[SymbolDispose]()\n        originalCallback.apply(stream, args)\n      })\n    }\n  }\n  return cleanup\n}\nfunction eosWeb(stream, options, callback) {\n  let isAborted = false\n  let abort = nop\n  if (options.signal) {\n    abort = () => {\n      isAborted = true\n      callback.call(\n        stream,\n        new AbortError(undefined, {\n          cause: options.signal.reason\n        })\n      )\n    }\n    if (options.signal.aborted) {\n      process.nextTick(abort)\n    } else {\n      addAbortListener = addAbortListener || require('../../ours/util').addAbortListener\n      const disposable = addAbortListener(options.signal, abort)\n      const originalCallback = callback\n      callback = once((...args) => {\n        disposable[SymbolDispose]()\n        originalCallback.apply(stream, args)\n      })\n    }\n  }\n  const resolverFn = (...args) => {\n    if (!isAborted) {\n      process.nextTick(() => callback.apply(stream, args))\n    }\n  }\n  PromisePrototypeThen(stream[kIsClosedPromise].promise, resolverFn, resolverFn)\n  return nop\n}\nfunction finished(stream, opts) {\n  var _opts\n  let autoCleanup = false\n  if (opts === null) {\n    opts = kEmptyObject\n  }\n  if ((_opts = opts) !== null && _opts !== undefined && _opts.cleanup) {\n    validateBoolean(opts.cleanup, 'cleanup')\n    autoCleanup = opts.cleanup\n  }\n  return new Promise((resolve, reject) => {\n    const cleanup = eos(stream, opts, (err) => {\n      if (autoCleanup) {\n        cleanup()\n      }\n      if (err) {\n        reject(err)\n      } else {\n        resolve()\n      }\n    })\n  })\n}\nmodule.exports = eos\nmodule.exports.finished = finished\n","'use strict'\n\n/* replacement start */\n\nconst process = require('process/')\n\n/* replacement end */\n\nconst { PromisePrototypeThen, SymbolAsyncIterator, SymbolIterator } = require('../../ours/primordials')\nconst { Buffer } = require('buffer')\nconst { ERR_INVALID_ARG_TYPE, ERR_STREAM_NULL_VALUES } = require('../../ours/errors').codes\nfunction from(Readable, iterable, opts) {\n  let iterator\n  if (typeof iterable === 'string' || iterable instanceof Buffer) {\n    return new Readable({\n      objectMode: true,\n      ...opts,\n      read() {\n        this.push(iterable)\n        this.push(null)\n      }\n    })\n  }\n  let isAsync\n  if (iterable && iterable[SymbolAsyncIterator]) {\n    isAsync = true\n    iterator = iterable[SymbolAsyncIterator]()\n  } else if (iterable && iterable[SymbolIterator]) {\n    isAsync = false\n    iterator = iterable[SymbolIterator]()\n  } else {\n    throw new ERR_INVALID_ARG_TYPE('iterable', ['Iterable'], iterable)\n  }\n  const readable = new Readable({\n    objectMode: true,\n    highWaterMark: 1,\n    // TODO(ronag): What options should be allowed?\n    ...opts\n  })\n\n  // Flag to protect against _read\n  // being called before last iteration completion.\n  let reading = false\n  readable._read = function () {\n    if (!reading) {\n      reading = true\n      next()\n    }\n  }\n  readable._destroy = function (error, cb) {\n    PromisePrototypeThen(\n      close(error),\n      () => process.nextTick(cb, error),\n      // nextTick is here in case cb throws\n      (e) => process.nextTick(cb, e || error)\n    )\n  }\n  async function close(error) {\n    const hadError = error !== undefined && error !== null\n    const hasThrow = typeof iterator.throw === 'function'\n    if (hadError && hasThrow) {\n      const { value, done } = await iterator.throw(error)\n      await value\n      if (done) {\n        return\n      }\n    }\n    if (typeof iterator.return === 'function') {\n      const { value } = await iterator.return()\n      await value\n    }\n  }\n  async function next() {\n    for (;;) {\n      try {\n        const { value, done } = isAsync ? await iterator.next() : iterator.next()\n        if (done) {\n          readable.push(null)\n        } else {\n          const res = value && typeof value.then === 'function' ? await value : value\n          if (res === null) {\n            reading = false\n            throw new ERR_STREAM_NULL_VALUES()\n          } else if (readable.push(res)) {\n            continue\n          } else {\n            reading = false\n          }\n        }\n      } catch (err) {\n        readable.destroy(err)\n      }\n      break\n    }\n  }\n  return readable\n}\nmodule.exports = from\n","'use strict'\n\nconst { ArrayIsArray, ObjectSetPrototypeOf } = require('../../ours/primordials')\nconst { EventEmitter: EE } = require('events')\nfunction Stream(opts) {\n  EE.call(this, opts)\n}\nObjectSetPrototypeOf(Stream.prototype, EE.prototype)\nObjectSetPrototypeOf(Stream, EE)\nStream.prototype.pipe = function (dest, options) {\n  const source = this\n  function ondata(chunk) {\n    if (dest.writable && dest.write(chunk) === false && source.pause) {\n      source.pause()\n    }\n  }\n  source.on('data', ondata)\n  function ondrain() {\n    if (source.readable && source.resume) {\n      source.resume()\n    }\n  }\n  dest.on('drain', ondrain)\n\n  // If the 'end' option is not supplied, dest.end() will be called when\n  // source gets the 'end' or 'close' events.  Only dest.end() once.\n  if (!dest._isStdio && (!options || options.end !== false)) {\n    source.on('end', onend)\n    source.on('close', onclose)\n  }\n  let didOnEnd = false\n  function onend() {\n    if (didOnEnd) return\n    didOnEnd = true\n    dest.end()\n  }\n  function onclose() {\n    if (didOnEnd) return\n    didOnEnd = true\n    if (typeof dest.destroy === 'function') dest.destroy()\n  }\n\n  // Don't leave dangling pipes when there are errors.\n  function onerror(er) {\n    cleanup()\n    if (EE.listenerCount(this, 'error') === 0) {\n      this.emit('error', er)\n    }\n  }\n  prependListener(source, 'error', onerror)\n  prependListener(dest, 'error', onerror)\n\n  // Remove all the event listeners that were added.\n  function cleanup() {\n    source.removeListener('data', ondata)\n    dest.removeListener('drain', ondrain)\n    source.removeListener('end', onend)\n    source.removeListener('close', onclose)\n    source.removeListener('error', onerror)\n    dest.removeListener('error', onerror)\n    source.removeListener('end', cleanup)\n    source.removeListener('close', cleanup)\n    dest.removeListener('close', cleanup)\n  }\n  source.on('end', cleanup)\n  source.on('close', cleanup)\n  dest.on('close', cleanup)\n  dest.emit('pipe', source)\n\n  // Allow for unix-like usage: A.pipe(B).pipe(C)\n  return dest\n}\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn)\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn)\n  else if (ArrayIsArray(emitter._events[event])) emitter._events[event].unshift(fn)\n  else emitter._events[event] = [fn, emitter._events[event]]\n}\nmodule.exports = {\n  Stream,\n  prependListener\n}\n","'use strict'\n\nconst AbortController = globalThis.AbortController || require('abort-controller').AbortController\nconst {\n  codes: { ERR_INVALID_ARG_VALUE, ERR_INVALID_ARG_TYPE, ERR_MISSING_ARGS, ERR_OUT_OF_RANGE },\n  AbortError\n} = require('../../ours/errors')\nconst { validateAbortSignal, validateInteger, validateObject } = require('../validators')\nconst kWeakHandler = require('../../ours/primordials').Symbol('kWeak')\nconst kResistStopPropagation = require('../../ours/primordials').Symbol('kResistStopPropagation')\nconst { finished } = require('./end-of-stream')\nconst staticCompose = require('./compose')\nconst { addAbortSignalNoValidate } = require('./add-abort-signal')\nconst { isWritable, isNodeStream } = require('./utils')\nconst { deprecate } = require('../../ours/util')\nconst {\n  ArrayPrototypePush,\n  Boolean,\n  MathFloor,\n  Number,\n  NumberIsNaN,\n  Promise,\n  PromiseReject,\n  PromiseResolve,\n  PromisePrototypeThen,\n  Symbol\n} = require('../../ours/primordials')\nconst kEmpty = Symbol('kEmpty')\nconst kEof = Symbol('kEof')\nfunction compose(stream, options) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  if (isNodeStream(stream) && !isWritable(stream)) {\n    throw new ERR_INVALID_ARG_VALUE('stream', stream, 'must be writable')\n  }\n  const composedStream = staticCompose(this, stream)\n  if (options !== null && options !== undefined && options.signal) {\n    // Not validating as we already validated before\n    addAbortSignalNoValidate(options.signal, composedStream)\n  }\n  return composedStream\n}\nfunction map(fn, options) {\n  if (typeof fn !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)\n  }\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  let concurrency = 1\n  if ((options === null || options === undefined ? undefined : options.concurrency) != null) {\n    concurrency = MathFloor(options.concurrency)\n  }\n  let highWaterMark = concurrency - 1\n  if ((options === null || options === undefined ? undefined : options.highWaterMark) != null) {\n    highWaterMark = MathFloor(options.highWaterMark)\n  }\n  validateInteger(concurrency, 'options.concurrency', 1)\n  validateInteger(highWaterMark, 'options.highWaterMark', 0)\n  highWaterMark += concurrency\n  return async function* map() {\n    const signal = require('../../ours/util').AbortSignalAny(\n      [options === null || options === undefined ? undefined : options.signal].filter(Boolean)\n    )\n    const stream = this\n    const queue = []\n    const signalOpt = {\n      signal\n    }\n    let next\n    let resume\n    let done = false\n    let cnt = 0\n    function onCatch() {\n      done = true\n      afterItemProcessed()\n    }\n    function afterItemProcessed() {\n      cnt -= 1\n      maybeResume()\n    }\n    function maybeResume() {\n      if (resume && !done && cnt < concurrency && queue.length < highWaterMark) {\n        resume()\n        resume = null\n      }\n    }\n    async function pump() {\n      try {\n        for await (let val of stream) {\n          if (done) {\n            return\n          }\n          if (signal.aborted) {\n            throw new AbortError()\n          }\n          try {\n            val = fn(val, signalOpt)\n            if (val === kEmpty) {\n              continue\n            }\n            val = PromiseResolve(val)\n          } catch (err) {\n            val = PromiseReject(err)\n          }\n          cnt += 1\n          PromisePrototypeThen(val, afterItemProcessed, onCatch)\n          queue.push(val)\n          if (next) {\n            next()\n            next = null\n          }\n          if (!done && (queue.length >= highWaterMark || cnt >= concurrency)) {\n            await new Promise((resolve) => {\n              resume = resolve\n            })\n          }\n        }\n        queue.push(kEof)\n      } catch (err) {\n        const val = PromiseReject(err)\n        PromisePrototypeThen(val, afterItemProcessed, onCatch)\n        queue.push(val)\n      } finally {\n        done = true\n        if (next) {\n          next()\n          next = null\n        }\n      }\n    }\n    pump()\n    try {\n      while (true) {\n        while (queue.length > 0) {\n          const val = await queue[0]\n          if (val === kEof) {\n            return\n          }\n          if (signal.aborted) {\n            throw new AbortError()\n          }\n          if (val !== kEmpty) {\n            yield val\n          }\n          queue.shift()\n          maybeResume()\n        }\n        await new Promise((resolve) => {\n          next = resolve\n        })\n      }\n    } finally {\n      done = true\n      if (resume) {\n        resume()\n        resume = null\n      }\n    }\n  }.call(this)\n}\nfunction asIndexedPairs(options = undefined) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  return async function* asIndexedPairs() {\n    let index = 0\n    for await (const val of this) {\n      var _options$signal\n      if (\n        options !== null &&\n        options !== undefined &&\n        (_options$signal = options.signal) !== null &&\n        _options$signal !== undefined &&\n        _options$signal.aborted\n      ) {\n        throw new AbortError({\n          cause: options.signal.reason\n        })\n      }\n      yield [index++, val]\n    }\n  }.call(this)\n}\nasync function some(fn, options = undefined) {\n  for await (const unused of filter.call(this, fn, options)) {\n    return true\n  }\n  return false\n}\nasync function every(fn, options = undefined) {\n  if (typeof fn !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)\n  }\n  // https://en.wikipedia.org/wiki/De_Morgan%27s_laws\n  return !(await some.call(\n    this,\n    async (...args) => {\n      return !(await fn(...args))\n    },\n    options\n  ))\n}\nasync function find(fn, options) {\n  for await (const result of filter.call(this, fn, options)) {\n    return result\n  }\n  return undefined\n}\nasync function forEach(fn, options) {\n  if (typeof fn !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)\n  }\n  async function forEachFn(value, options) {\n    await fn(value, options)\n    return kEmpty\n  }\n  // eslint-disable-next-line no-unused-vars\n  for await (const unused of map.call(this, forEachFn, options));\n}\nfunction filter(fn, options) {\n  if (typeof fn !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('fn', ['Function', 'AsyncFunction'], fn)\n  }\n  async function filterFn(value, options) {\n    if (await fn(value, options)) {\n      return value\n    }\n    return kEmpty\n  }\n  return map.call(this, filterFn, options)\n}\n\n// Specific to provide better error to reduce since the argument is only\n// missing if the stream has no items in it - but the code is still appropriate\nclass ReduceAwareErrMissingArgs extends ERR_MISSING_ARGS {\n  constructor() {\n    super('reduce')\n    this.message = 'Reduce of an empty stream requires an initial value'\n  }\n}\nasync function reduce(reducer, initialValue, options) {\n  var _options$signal2\n  if (typeof reducer !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE('reducer', ['Function', 'AsyncFunction'], reducer)\n  }\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  let hasInitialValue = arguments.length > 1\n  if (\n    options !== null &&\n    options !== undefined &&\n    (_options$signal2 = options.signal) !== null &&\n    _options$signal2 !== undefined &&\n    _options$signal2.aborted\n  ) {\n    const err = new AbortError(undefined, {\n      cause: options.signal.reason\n    })\n    this.once('error', () => {}) // The error is already propagated\n    await finished(this.destroy(err))\n    throw err\n  }\n  const ac = new AbortController()\n  const signal = ac.signal\n  if (options !== null && options !== undefined && options.signal) {\n    const opts = {\n      once: true,\n      [kWeakHandler]: this,\n      [kResistStopPropagation]: true\n    }\n    options.signal.addEventListener('abort', () => ac.abort(), opts)\n  }\n  let gotAnyItemFromStream = false\n  try {\n    for await (const value of this) {\n      var _options$signal3\n      gotAnyItemFromStream = true\n      if (\n        options !== null &&\n        options !== undefined &&\n        (_options$signal3 = options.signal) !== null &&\n        _options$signal3 !== undefined &&\n        _options$signal3.aborted\n      ) {\n        throw new AbortError()\n      }\n      if (!hasInitialValue) {\n        initialValue = value\n        hasInitialValue = true\n      } else {\n        initialValue = await reducer(initialValue, value, {\n          signal\n        })\n      }\n    }\n    if (!gotAnyItemFromStream && !hasInitialValue) {\n      throw new ReduceAwareErrMissingArgs()\n    }\n  } finally {\n    ac.abort()\n  }\n  return initialValue\n}\nasync function toArray(options) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  const result = []\n  for await (const val of this) {\n    var _options$signal4\n    if (\n      options !== null &&\n      options !== undefined &&\n      (_options$signal4 = options.signal) !== null &&\n      _options$signal4 !== undefined &&\n      _options$signal4.aborted\n    ) {\n      throw new AbortError(undefined, {\n        cause: options.signal.reason\n      })\n    }\n    ArrayPrototypePush(result, val)\n  }\n  return result\n}\nfunction flatMap(fn, options) {\n  const values = map.call(this, fn, options)\n  return async function* flatMap() {\n    for await (const val of values) {\n      yield* val\n    }\n  }.call(this)\n}\nfunction toIntegerOrInfinity(number) {\n  // We coerce here to align with the spec\n  // https://github.com/tc39/proposal-iterator-helpers/issues/169\n  number = Number(number)\n  if (NumberIsNaN(number)) {\n    return 0\n  }\n  if (number < 0) {\n    throw new ERR_OUT_OF_RANGE('number', '>= 0', number)\n  }\n  return number\n}\nfunction drop(number, options = undefined) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  number = toIntegerOrInfinity(number)\n  return async function* drop() {\n    var _options$signal5\n    if (\n      options !== null &&\n      options !== undefined &&\n      (_options$signal5 = options.signal) !== null &&\n      _options$signal5 !== undefined &&\n      _options$signal5.aborted\n    ) {\n      throw new AbortError()\n    }\n    for await (const val of this) {\n      var _options$signal6\n      if (\n        options !== null &&\n        options !== undefined &&\n        (_options$signal6 = options.signal) !== null &&\n        _options$signal6 !== undefined &&\n        _options$signal6.aborted\n      ) {\n        throw new AbortError()\n      }\n      if (number-- <= 0) {\n        yield val\n      }\n    }\n  }.call(this)\n}\nfunction take(number, options = undefined) {\n  if (options != null) {\n    validateObject(options, 'options')\n  }\n  if ((options === null || options === undefined ? undefined : options.signal) != null) {\n    validateAbortSignal(options.signal, 'options.signal')\n  }\n  number = toIntegerOrInfinity(number)\n  return async function* take() {\n    var _options$signal7\n    if (\n      options !== null &&\n      options !== undefined &&\n      (_options$signal7 = options.signal) !== null &&\n      _options$signal7 !== undefined &&\n      _options$signal7.aborted\n    ) {\n      throw new AbortError()\n    }\n    for await (const val of this) {\n      var _options$signal8\n      if (\n        options !== null &&\n        options !== undefined &&\n        (_options$signal8 = options.signal) !== null &&\n        _options$signal8 !== undefined &&\n        _options$signal8.aborted\n      ) {\n        throw new AbortError()\n      }\n      if (number-- > 0) {\n        yield val\n      }\n\n      // Don't get another item from iterator in case we reached the end\n      if (number <= 0) {\n        return\n      }\n    }\n  }.call(this)\n}\nmodule.exports.streamReturningOperators = {\n  asIndexedPairs: deprecate(asIndexedPairs, 'readable.asIndexedPairs will be removed in a future version.'),\n  drop,\n  filter,\n  flatMap,\n  map,\n  take,\n  compose\n}\nmodule.exports.promiseReturningOperators = {\n  every,\n  forEach,\n  reduce,\n  toArray,\n  some,\n  find\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict'\n\nconst { ObjectSetPrototypeOf } = require('../../ours/primordials')\nmodule.exports = PassThrough\nconst Transform = require('./transform')\nObjectSetPrototypeOf(PassThrough.prototype, Transform.prototype)\nObjectSetPrototypeOf(PassThrough, Transform)\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options)\n  Transform.call(this, options)\n}\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk)\n}\n","/* replacement start */\n\nconst process = require('process/')\n\n/* replacement end */\n// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n\n;('use strict')\nconst { ArrayIsArray, Promise, SymbolAsyncIterator, SymbolDispose } = require('../../ours/primordials')\nconst eos = require('./end-of-stream')\nconst { once } = require('../../ours/util')\nconst destroyImpl = require('./destroy')\nconst Duplex = require('./duplex')\nconst {\n  aggregateTwoErrors,\n  codes: {\n    ERR_INVALID_ARG_TYPE,\n    ERR_INVALID_RETURN_VALUE,\n    ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED,\n    ERR_STREAM_PREMATURE_CLOSE\n  },\n  AbortError\n} = require('../../ours/errors')\nconst { validateFunction, validateAbortSignal } = require('../validators')\nconst {\n  isIterable,\n  isReadable,\n  isReadableNodeStream,\n  isNodeStream,\n  isTransformStream,\n  isWebStream,\n  isReadableStream,\n  isReadableFinished\n} = require('./utils')\nconst AbortController = globalThis.AbortController || require('abort-controller').AbortController\nlet PassThrough\nlet Readable\nlet addAbortListener\nfunction destroyer(stream, reading, writing) {\n  let finished = false\n  stream.on('close', () => {\n    finished = true\n  })\n  const cleanup = eos(\n    stream,\n    {\n      readable: reading,\n      writable: writing\n    },\n    (err) => {\n      finished = !err\n    }\n  )\n  return {\n    destroy: (err) => {\n      if (finished) return\n      finished = true\n      destroyImpl.destroyer(stream, err || new ERR_STREAM_DESTROYED('pipe'))\n    },\n    cleanup\n  }\n}\nfunction popCallback(streams) {\n  // Streams should never be an empty array. It should always contain at least\n  // a single stream. Therefore optimize for the average case instead of\n  // checking for length === 0 as well.\n  validateFunction(streams[streams.length - 1], 'streams[stream.length - 1]')\n  return streams.pop()\n}\nfunction makeAsyncIterable(val) {\n  if (isIterable(val)) {\n    return val\n  } else if (isReadableNodeStream(val)) {\n    // Legacy streams are not Iterable.\n    return fromReadable(val)\n  }\n  throw new ERR_INVALID_ARG_TYPE('val', ['Readable', 'Iterable', 'AsyncIterable'], val)\n}\nasync function* fromReadable(val) {\n  if (!Readable) {\n    Readable = require('./readable')\n  }\n  yield* Readable.prototype[SymbolAsyncIterator].call(val)\n}\nasync function pumpToNode(iterable, writable, finish, { end }) {\n  let error\n  let onresolve = null\n  const resume = (err) => {\n    if (err) {\n      error = err\n    }\n    if (onresolve) {\n      const callback = onresolve\n      onresolve = null\n      callback()\n    }\n  }\n  const wait = () =>\n    new Promise((resolve, reject) => {\n      if (error) {\n        reject(error)\n      } else {\n        onresolve = () => {\n          if (error) {\n            reject(error)\n          } else {\n            resolve()\n          }\n        }\n      }\n    })\n  writable.on('drain', resume)\n  const cleanup = eos(\n    writable,\n    {\n      readable: false\n    },\n    resume\n  )\n  try {\n    if (writable.writableNeedDrain) {\n      await wait()\n    }\n    for await (const chunk of iterable) {\n      if (!writable.write(chunk)) {\n        await wait()\n      }\n    }\n    if (end) {\n      writable.end()\n      await wait()\n    }\n    finish()\n  } catch (err) {\n    finish(error !== err ? aggregateTwoErrors(error, err) : err)\n  } finally {\n    cleanup()\n    writable.off('drain', resume)\n  }\n}\nasync function pumpToWeb(readable, writable, finish, { end }) {\n  if (isTransformStream(writable)) {\n    writable = writable.writable\n  }\n  // https://streams.spec.whatwg.org/#example-manual-write-with-backpressure\n  const writer = writable.getWriter()\n  try {\n    for await (const chunk of readable) {\n      await writer.ready\n      writer.write(chunk).catch(() => {})\n    }\n    await writer.ready\n    if (end) {\n      await writer.close()\n    }\n    finish()\n  } catch (err) {\n    try {\n      await writer.abort(err)\n      finish(err)\n    } catch (err) {\n      finish(err)\n    }\n  }\n}\nfunction pipeline(...streams) {\n  return pipelineImpl(streams, once(popCallback(streams)))\n}\nfunction pipelineImpl(streams, callback, opts) {\n  if (streams.length === 1 && ArrayIsArray(streams[0])) {\n    streams = streams[0]\n  }\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams')\n  }\n  const ac = new AbortController()\n  const signal = ac.signal\n  const outerSignal = opts === null || opts === undefined ? undefined : opts.signal\n\n  // Need to cleanup event listeners if last stream is readable\n  // https://github.com/nodejs/node/issues/35452\n  const lastStreamCleanup = []\n  validateAbortSignal(outerSignal, 'options.signal')\n  function abort() {\n    finishImpl(new AbortError())\n  }\n  addAbortListener = addAbortListener || require('../../ours/util').addAbortListener\n  let disposable\n  if (outerSignal) {\n    disposable = addAbortListener(outerSignal, abort)\n  }\n  let error\n  let value\n  const destroys = []\n  let finishCount = 0\n  function finish(err) {\n    finishImpl(err, --finishCount === 0)\n  }\n  function finishImpl(err, final) {\n    var _disposable\n    if (err && (!error || error.code === 'ERR_STREAM_PREMATURE_CLOSE')) {\n      error = err\n    }\n    if (!error && !final) {\n      return\n    }\n    while (destroys.length) {\n      destroys.shift()(error)\n    }\n    ;(_disposable = disposable) === null || _disposable === undefined ? undefined : _disposable[SymbolDispose]()\n    ac.abort()\n    if (final) {\n      if (!error) {\n        lastStreamCleanup.forEach((fn) => fn())\n      }\n      process.nextTick(callback, error, value)\n    }\n  }\n  let ret\n  for (let i = 0; i < streams.length; i++) {\n    const stream = streams[i]\n    const reading = i < streams.length - 1\n    const writing = i > 0\n    const end = reading || (opts === null || opts === undefined ? undefined : opts.end) !== false\n    const isLastStream = i === streams.length - 1\n    if (isNodeStream(stream)) {\n      if (end) {\n        const { destroy, cleanup } = destroyer(stream, reading, writing)\n        destroys.push(destroy)\n        if (isReadable(stream) && isLastStream) {\n          lastStreamCleanup.push(cleanup)\n        }\n      }\n\n      // Catch stream errors that occur after pipe/pump has completed.\n      function onError(err) {\n        if (err && err.name !== 'AbortError' && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n          finish(err)\n        }\n      }\n      stream.on('error', onError)\n      if (isReadable(stream) && isLastStream) {\n        lastStreamCleanup.push(() => {\n          stream.removeListener('error', onError)\n        })\n      }\n    }\n    if (i === 0) {\n      if (typeof stream === 'function') {\n        ret = stream({\n          signal\n        })\n        if (!isIterable(ret)) {\n          throw new ERR_INVALID_RETURN_VALUE('Iterable, AsyncIterable or Stream', 'source', ret)\n        }\n      } else if (isIterable(stream) || isReadableNodeStream(stream) || isTransformStream(stream)) {\n        ret = stream\n      } else {\n        ret = Duplex.from(stream)\n      }\n    } else if (typeof stream === 'function') {\n      if (isTransformStream(ret)) {\n        var _ret\n        ret = makeAsyncIterable((_ret = ret) === null || _ret === undefined ? undefined : _ret.readable)\n      } else {\n        ret = makeAsyncIterable(ret)\n      }\n      ret = stream(ret, {\n        signal\n      })\n      if (reading) {\n        if (!isIterable(ret, true)) {\n          throw new ERR_INVALID_RETURN_VALUE('AsyncIterable', `transform[${i - 1}]`, ret)\n        }\n      } else {\n        var _ret2\n        if (!PassThrough) {\n          PassThrough = require('./passthrough')\n        }\n\n        // If the last argument to pipeline is not a stream\n        // we must create a proxy stream so that pipeline(...)\n        // always returns a stream which can be further\n        // composed through `.pipe(stream)`.\n\n        const pt = new PassThrough({\n          objectMode: true\n        })\n\n        // Handle Promises/A+ spec, `then` could be a getter that throws on\n        // second use.\n        const then = (_ret2 = ret) === null || _ret2 === undefined ? undefined : _ret2.then\n        if (typeof then === 'function') {\n          finishCount++\n          then.call(\n            ret,\n            (val) => {\n              value = val\n              if (val != null) {\n                pt.write(val)\n              }\n              if (end) {\n                pt.end()\n              }\n              process.nextTick(finish)\n            },\n            (err) => {\n              pt.destroy(err)\n              process.nextTick(finish, err)\n            }\n          )\n        } else if (isIterable(ret, true)) {\n          finishCount++\n          pumpToNode(ret, pt, finish, {\n            end\n          })\n        } else if (isReadableStream(ret) || isTransformStream(ret)) {\n          const toRead = ret.readable || ret\n          finishCount++\n          pumpToNode(toRead, pt, finish, {\n            end\n          })\n        } else {\n          throw new ERR_INVALID_RETURN_VALUE('AsyncIterable or Promise', 'destination', ret)\n        }\n        ret = pt\n        const { destroy, cleanup } = destroyer(ret, false, true)\n        destroys.push(destroy)\n        if (isLastStream) {\n          lastStreamCleanup.push(cleanup)\n        }\n      }\n    } else if (isNodeStream(stream)) {\n      if (isReadableNodeStream(ret)) {\n        finishCount += 2\n        const cleanup = pipe(ret, stream, finish, {\n          end\n        })\n        if (isReadable(stream) && isLastStream) {\n          lastStreamCleanup.push(cleanup)\n        }\n      } else if (isTransformStream(ret) || isReadableStream(ret)) {\n        const toRead = ret.readable || ret\n        finishCount++\n        pumpToNode(toRead, stream, finish, {\n          end\n        })\n      } else if (isIterable(ret)) {\n        finishCount++\n        pumpToNode(ret, stream, finish, {\n          end\n        })\n      } else {\n        throw new ERR_INVALID_ARG_TYPE(\n          'val',\n          ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'],\n          ret\n        )\n      }\n      ret = stream\n    } else if (isWebStream(stream)) {\n      if (isReadableNodeStream(ret)) {\n        finishCount++\n        pumpToWeb(makeAsyncIterable(ret), stream, finish, {\n          end\n        })\n      } else if (isReadableStream(ret) || isIterable(ret)) {\n        finishCount++\n        pumpToWeb(ret, stream, finish, {\n          end\n        })\n      } else if (isTransformStream(ret)) {\n        finishCount++\n        pumpToWeb(ret.readable, stream, finish, {\n          end\n        })\n      } else {\n        throw new ERR_INVALID_ARG_TYPE(\n          'val',\n          ['Readable', 'Iterable', 'AsyncIterable', 'ReadableStream', 'TransformStream'],\n          ret\n        )\n      }\n      ret = stream\n    } else {\n      ret = Duplex.from(stream)\n    }\n  }\n  if (\n    (signal !== null && signal !== undefined && signal.aborted) ||\n    (outerSignal !== null && outerSignal !== undefined && outerSignal.aborted)\n  ) {\n    process.nextTick(abort)\n  }\n  return ret\n}\nfunction pipe(src, dst, finish, { end }) {\n  let ended = false\n  dst.on('close', () => {\n    if (!ended) {\n      // Finish if the destination closes before the source has completed.\n      finish(new ERR_STREAM_PREMATURE_CLOSE())\n    }\n  })\n  src.pipe(dst, {\n    end: false\n  }) // If end is true we already will have a listener to end dst.\n\n  if (end) {\n    // Compat. Before node v10.12.0 stdio used to throw an error so\n    // pipe() did/does not end() stdio destinations.\n    // Now they allow it but \"secretly\" don't close the underlying fd.\n\n    function endFn() {\n      ended = true\n      dst.end()\n    }\n    if (isReadableFinished(src)) {\n      // End the destination if the source has already ended.\n      process.nextTick(endFn)\n    } else {\n      src.once('end', endFn)\n    }\n  } else {\n    finish()\n  }\n  eos(\n    src,\n    {\n      readable: true,\n      writable: false\n    },\n    (err) => {\n      const rState = src._readableState\n      if (\n        err &&\n        err.code === 'ERR_STREAM_PREMATURE_CLOSE' &&\n        rState &&\n        rState.ended &&\n        !rState.errored &&\n        !rState.errorEmitted\n      ) {\n        // Some readable streams will emit 'close' before 'end'. However, since\n        // this is on the readable side 'end' should still be emitted if the\n        // stream has been ended and no error emitted. This should be allowed in\n        // favor of backwards compatibility. Since the stream is piped to a\n        // destination this should not result in any observable difference.\n        // We don't need to check if this is a writable premature close since\n        // eos will only fail with premature close on the reading side for\n        // duplex streams.\n        src.once('end', finish).once('error', finish)\n      } else {\n        finish(err)\n      }\n    }\n  )\n  return eos(\n    dst,\n    {\n      readable: false,\n      writable: true\n    },\n    finish\n  )\n}\nmodule.exports = {\n  pipelineImpl,\n  pipeline\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict'\n\n/* replacement start */\n\nconst process = require('process/')\n\n/* replacement end */\n\nconst {\n  ArrayPrototypeIndexOf,\n  NumberIsInteger,\n  NumberIsNaN,\n  NumberParseInt,\n  ObjectDefineProperties,\n  ObjectKeys,\n  ObjectSetPrototypeOf,\n  Promise,\n  SafeSet,\n  SymbolAsyncDispose,\n  SymbolAsyncIterator,\n  Symbol\n} = require('../../ours/primordials')\nmodule.exports = Readable\nReadable.ReadableState = ReadableState\nconst { EventEmitter: EE } = require('events')\nconst { Stream, prependListener } = require('./legacy')\nconst { Buffer } = require('buffer')\nconst { addAbortSignal } = require('./add-abort-signal')\nconst eos = require('./end-of-stream')\nlet debug = require('../../ours/util').debuglog('stream', (fn) => {\n  debug = fn\n})\nconst BufferList = require('./buffer_list')\nconst destroyImpl = require('./destroy')\nconst { getHighWaterMark, getDefaultHighWaterMark } = require('./state')\nconst {\n  aggregateTwoErrors,\n  codes: {\n    ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_OUT_OF_RANGE,\n    ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT\n  },\n  AbortError\n} = require('../../ours/errors')\nconst { validateObject } = require('../validators')\nconst kPaused = Symbol('kPaused')\nconst { StringDecoder } = require('string_decoder/')\nconst from = require('./from')\nObjectSetPrototypeOf(Readable.prototype, Stream.prototype)\nObjectSetPrototypeOf(Readable, Stream)\nconst nop = () => {}\nconst { errorOrDestroy } = destroyImpl\nconst kObjectMode = 1 << 0\nconst kEnded = 1 << 1\nconst kEndEmitted = 1 << 2\nconst kReading = 1 << 3\nconst kConstructed = 1 << 4\nconst kSync = 1 << 5\nconst kNeedReadable = 1 << 6\nconst kEmittedReadable = 1 << 7\nconst kReadableListening = 1 << 8\nconst kResumeScheduled = 1 << 9\nconst kErrorEmitted = 1 << 10\nconst kEmitClose = 1 << 11\nconst kAutoDestroy = 1 << 12\nconst kDestroyed = 1 << 13\nconst kClosed = 1 << 14\nconst kCloseEmitted = 1 << 15\nconst kMultiAwaitDrain = 1 << 16\nconst kReadingMore = 1 << 17\nconst kDataEmitted = 1 << 18\n\n// TODO(benjamingr) it is likely slower to do it this way than with free functions\nfunction makeBitMapDescriptor(bit) {\n  return {\n    enumerable: false,\n    get() {\n      return (this.state & bit) !== 0\n    },\n    set(value) {\n      if (value) this.state |= bit\n      else this.state &= ~bit\n    }\n  }\n}\nObjectDefineProperties(ReadableState.prototype, {\n  objectMode: makeBitMapDescriptor(kObjectMode),\n  ended: makeBitMapDescriptor(kEnded),\n  endEmitted: makeBitMapDescriptor(kEndEmitted),\n  reading: makeBitMapDescriptor(kReading),\n  // Stream is still being constructed and cannot be\n  // destroyed until construction finished or failed.\n  // Async construction is opt in, therefore we start as\n  // constructed.\n  constructed: makeBitMapDescriptor(kConstructed),\n  // A flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  sync: makeBitMapDescriptor(kSync),\n  // Whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  needReadable: makeBitMapDescriptor(kNeedReadable),\n  emittedReadable: makeBitMapDescriptor(kEmittedReadable),\n  readableListening: makeBitMapDescriptor(kReadableListening),\n  resumeScheduled: makeBitMapDescriptor(kResumeScheduled),\n  // True if the error was already emitted and should not be thrown again.\n  errorEmitted: makeBitMapDescriptor(kErrorEmitted),\n  emitClose: makeBitMapDescriptor(kEmitClose),\n  autoDestroy: makeBitMapDescriptor(kAutoDestroy),\n  // Has it been destroyed.\n  destroyed: makeBitMapDescriptor(kDestroyed),\n  // Indicates whether the stream has finished destroying.\n  closed: makeBitMapDescriptor(kClosed),\n  // True if close has been emitted or would have been emitted\n  // depending on emitClose.\n  closeEmitted: makeBitMapDescriptor(kCloseEmitted),\n  multiAwaitDrain: makeBitMapDescriptor(kMultiAwaitDrain),\n  // If true, a maybeReadMore has been scheduled.\n  readingMore: makeBitMapDescriptor(kReadingMore),\n  dataEmitted: makeBitMapDescriptor(kDataEmitted)\n})\nfunction ReadableState(options, stream, isDuplex) {\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof require('./duplex')\n\n  // Bit map field to store ReadableState more effciently with 1 bit per field\n  // instead of a V8 slot per field.\n  this.state = kEmitClose | kAutoDestroy | kConstructed | kSync\n  // Object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away.\n  if (options && options.objectMode) this.state |= kObjectMode\n  if (isDuplex && options && options.readableObjectMode) this.state |= kObjectMode\n\n  // The point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  this.highWaterMark = options\n    ? getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex)\n    : getDefaultHighWaterMark(false)\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift().\n  this.buffer = new BufferList()\n  this.length = 0\n  this.pipes = []\n  this.flowing = null\n  this[kPaused] = null\n\n  // Should close be emitted on destroy. Defaults to true.\n  if (options && options.emitClose === false) this.state &= ~kEmitClose\n\n  // Should .destroy() be called after 'end' (and potentially 'finish').\n  if (options && options.autoDestroy === false) this.state &= ~kAutoDestroy\n\n  // Indicates whether the stream has errored. When true no further\n  // _read calls, 'data' or 'readable' events should occur. This is needed\n  // since when autoDestroy is disabled we need a way to tell whether the\n  // stream has failed.\n  this.errored = null\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = (options && options.defaultEncoding) || 'utf8'\n\n  // Ref the piped dest which we need a drain event on it\n  // type: null | Writable | Set<Writable>.\n  this.awaitDrainWriters = null\n  this.decoder = null\n  this.encoding = null\n  if (options && options.encoding) {\n    this.decoder = new StringDecoder(options.encoding)\n    this.encoding = options.encoding\n  }\n}\nfunction Readable(options) {\n  if (!(this instanceof Readable)) return new Readable(options)\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5.\n  const isDuplex = this instanceof require('./duplex')\n  this._readableState = new ReadableState(options, this, isDuplex)\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read\n    if (typeof options.destroy === 'function') this._destroy = options.destroy\n    if (typeof options.construct === 'function') this._construct = options.construct\n    if (options.signal && !isDuplex) addAbortSignal(options.signal, this)\n  }\n  Stream.call(this, options)\n  destroyImpl.construct(this, () => {\n    if (this._readableState.needReadable) {\n      maybeReadMore(this, this._readableState)\n    }\n  })\n}\nReadable.prototype.destroy = destroyImpl.destroy\nReadable.prototype._undestroy = destroyImpl.undestroy\nReadable.prototype._destroy = function (err, cb) {\n  cb(err)\n}\nReadable.prototype[EE.captureRejectionSymbol] = function (err) {\n  this.destroy(err)\n}\nReadable.prototype[SymbolAsyncDispose] = function () {\n  let error\n  if (!this.destroyed) {\n    error = this.readableEnded ? null : new AbortError()\n    this.destroy(error)\n  }\n  return new Promise((resolve, reject) => eos(this, (err) => (err && err !== error ? reject(err) : resolve(null))))\n}\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  return readableAddChunk(this, chunk, encoding, false)\n}\n\n// Unshift should *always* be something directly out of read().\nReadable.prototype.unshift = function (chunk, encoding) {\n  return readableAddChunk(this, chunk, encoding, true)\n}\nfunction readableAddChunk(stream, chunk, encoding, addToFront) {\n  debug('readableAddChunk', chunk)\n  const state = stream._readableState\n  let err\n  if ((state.state & kObjectMode) === 0) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding\n      if (state.encoding !== encoding) {\n        if (addToFront && state.encoding) {\n          // When unshifting, if state.encoding is set, we have to save\n          // the string in the BufferList with the state encoding.\n          chunk = Buffer.from(chunk, encoding).toString(state.encoding)\n        } else {\n          chunk = Buffer.from(chunk, encoding)\n          encoding = ''\n        }\n      }\n    } else if (chunk instanceof Buffer) {\n      encoding = ''\n    } else if (Stream._isUint8Array(chunk)) {\n      chunk = Stream._uint8ArrayToBuffer(chunk)\n      encoding = ''\n    } else if (chunk != null) {\n      err = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk)\n    }\n  }\n  if (err) {\n    errorOrDestroy(stream, err)\n  } else if (chunk === null) {\n    state.state &= ~kReading\n    onEofChunk(stream, state)\n  } else if ((state.state & kObjectMode) !== 0 || (chunk && chunk.length > 0)) {\n    if (addToFront) {\n      if ((state.state & kEndEmitted) !== 0) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT())\n      else if (state.destroyed || state.errored) return false\n      else addChunk(stream, state, chunk, true)\n    } else if (state.ended) {\n      errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF())\n    } else if (state.destroyed || state.errored) {\n      return false\n    } else {\n      state.state &= ~kReading\n      if (state.decoder && !encoding) {\n        chunk = state.decoder.write(chunk)\n        if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false)\n        else maybeReadMore(stream, state)\n      } else {\n        addChunk(stream, state, chunk, false)\n      }\n    }\n  } else if (!addToFront) {\n    state.state &= ~kReading\n    maybeReadMore(stream, state)\n  }\n\n  // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0)\n}\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync && stream.listenerCount('data') > 0) {\n    // Use the guard to avoid creating `Set()` repeatedly\n    // when we have multiple pipes.\n    if ((state.state & kMultiAwaitDrain) !== 0) {\n      state.awaitDrainWriters.clear()\n    } else {\n      state.awaitDrainWriters = null\n    }\n    state.dataEmitted = true\n    stream.emit('data', chunk)\n  } else {\n    // Update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length\n    if (addToFront) state.buffer.unshift(chunk)\n    else state.buffer.push(chunk)\n    if ((state.state & kNeedReadable) !== 0) emitReadable(stream)\n  }\n  maybeReadMore(stream, state)\n}\nReadable.prototype.isPaused = function () {\n  const state = this._readableState\n  return state[kPaused] === true || state.flowing === false\n}\n\n// Backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  const decoder = new StringDecoder(enc)\n  this._readableState.decoder = decoder\n  // If setEncoding(null), decoder.encoding equals utf8.\n  this._readableState.encoding = this._readableState.decoder.encoding\n  const buffer = this._readableState.buffer\n  // Iterate over current buffer to convert already stored Buffers:\n  let content = ''\n  for (const data of buffer) {\n    content += decoder.write(data)\n  }\n  buffer.clear()\n  if (content !== '') buffer.push(content)\n  this._readableState.length = content.length\n  return this\n}\n\n// Don't raise the hwm > 1GB.\nconst MAX_HWM = 0x40000000\nfunction computeNewHighWaterMark(n) {\n  if (n > MAX_HWM) {\n    throw new ERR_OUT_OF_RANGE('size', '<= 1GiB', n)\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts.\n    n--\n    n |= n >>> 1\n    n |= n >>> 2\n    n |= n >>> 4\n    n |= n >>> 8\n    n |= n >>> 16\n    n++\n  }\n  return n\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || (state.length === 0 && state.ended)) return 0\n  if ((state.state & kObjectMode) !== 0) return 1\n  if (NumberIsNaN(n)) {\n    // Only flow one buffer at a time.\n    if (state.flowing && state.length) return state.buffer.first().length\n    return state.length\n  }\n  if (n <= state.length) return n\n  return state.ended ? state.length : 0\n}\n\n// You can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n)\n  // Same as parseInt(undefined, 10), however V8 7.3 performance regressed\n  // in this scenario, so we are doing it manually.\n  if (n === undefined) {\n    n = NaN\n  } else if (!NumberIsInteger(n)) {\n    n = NumberParseInt(n, 10)\n  }\n  const state = this._readableState\n  const nOrig = n\n\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n)\n  if (n !== 0) state.state &= ~kEmittedReadable\n\n  // If we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (\n    n === 0 &&\n    state.needReadable &&\n    ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)\n  ) {\n    debug('read: emitReadable', state.length, state.ended)\n    if (state.length === 0 && state.ended) endReadable(this)\n    else emitReadable(this)\n    return null\n  }\n  n = howMuchToRead(n, state)\n\n  // If we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this)\n    return null\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  let doRead = (state.state & kNeedReadable) !== 0\n  debug('need readable', doRead)\n\n  // If we currently have less than the highWaterMark, then also read some.\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true\n    debug('length less than watermark', doRead)\n  }\n\n  // However, if we've ended, then there's no point, if we're already\n  // reading, then it's unnecessary, if we're constructing we have to wait,\n  // and if we're destroyed or errored, then it's not allowed,\n  if (state.ended || state.reading || state.destroyed || state.errored || !state.constructed) {\n    doRead = false\n    debug('reading, ended or constructing', doRead)\n  } else if (doRead) {\n    debug('do read')\n    state.state |= kReading | kSync\n    // If the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.state |= kNeedReadable\n\n    // Call internal read method\n    try {\n      this._read(state.highWaterMark)\n    } catch (err) {\n      errorOrDestroy(this, err)\n    }\n    state.state &= ~kSync\n\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state)\n  }\n  let ret\n  if (n > 0) ret = fromList(n, state)\n  else ret = null\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark\n    n = 0\n  } else {\n    state.length -= n\n    if (state.multiAwaitDrain) {\n      state.awaitDrainWriters.clear()\n    } else {\n      state.awaitDrainWriters = null\n    }\n  }\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this)\n  }\n  if (ret !== null && !state.errorEmitted && !state.closeEmitted) {\n    state.dataEmitted = true\n    this.emit('data', ret)\n  }\n  return ret\n}\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk')\n  if (state.ended) return\n  if (state.decoder) {\n    const chunk = state.decoder.end()\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk)\n      state.length += state.objectMode ? 1 : chunk.length\n    }\n  }\n  state.ended = true\n  if (state.sync) {\n    // If we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call.\n    emitReadable(stream)\n  } else {\n    // Emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false\n    state.emittedReadable = true\n    // We have to emit readable now that we are EOF. Modules\n    // in the ecosystem (e.g. dicer) rely on this event being sync.\n    emitReadable_(stream)\n  }\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  const state = stream._readableState\n  debug('emitReadable', state.needReadable, state.emittedReadable)\n  state.needReadable = false\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing)\n    state.emittedReadable = true\n    process.nextTick(emitReadable_, stream)\n  }\n}\nfunction emitReadable_(stream) {\n  const state = stream._readableState\n  debug('emitReadable_', state.destroyed, state.length, state.ended)\n  if (!state.destroyed && !state.errored && (state.length || state.ended)) {\n    stream.emit('readable')\n    state.emittedReadable = false\n  }\n\n  // The stream needs another readable event if:\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark\n  flow(stream)\n}\n\n// At this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore && state.constructed) {\n    state.readingMore = true\n    process.nextTick(maybeReadMore_, stream, state)\n  }\n}\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (\n    !state.reading &&\n    !state.ended &&\n    (state.length < state.highWaterMark || (state.flowing && state.length === 0))\n  ) {\n    const len = state.length\n    debug('maybeReadMore read 0')\n    stream.read(0)\n    if (len === state.length)\n      // Didn't get any data, stop spinning.\n      break\n  }\n  state.readingMore = false\n}\n\n// Abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  throw new ERR_METHOD_NOT_IMPLEMENTED('_read()')\n}\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  const src = this\n  const state = this._readableState\n  if (state.pipes.length === 1) {\n    if (!state.multiAwaitDrain) {\n      state.multiAwaitDrain = true\n      state.awaitDrainWriters = new SafeSet(state.awaitDrainWriters ? [state.awaitDrainWriters] : [])\n    }\n  }\n  state.pipes.push(dest)\n  debug('pipe count=%d opts=%j', state.pipes.length, pipeOpts)\n  const doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr\n  const endFn = doEnd ? onend : unpipe\n  if (state.endEmitted) process.nextTick(endFn)\n  else src.once('end', endFn)\n  dest.on('unpipe', onunpipe)\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe')\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true\n        cleanup()\n      }\n    }\n  }\n  function onend() {\n    debug('onend')\n    dest.end()\n  }\n  let ondrain\n  let cleanedUp = false\n  function cleanup() {\n    debug('cleanup')\n    // Cleanup event handlers once the pipe is broken.\n    dest.removeListener('close', onclose)\n    dest.removeListener('finish', onfinish)\n    if (ondrain) {\n      dest.removeListener('drain', ondrain)\n    }\n    dest.removeListener('error', onerror)\n    dest.removeListener('unpipe', onunpipe)\n    src.removeListener('end', onend)\n    src.removeListener('end', unpipe)\n    src.removeListener('data', ondata)\n    cleanedUp = true\n\n    // If the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (ondrain && state.awaitDrainWriters && (!dest._writableState || dest._writableState.needDrain)) ondrain()\n  }\n  function pause() {\n    // If the user unpiped during `dest.write()`, it is possible\n    // to get stuck in a permanently paused state if that write\n    // also returned false.\n    // => Check whether `dest` is still a piping destination.\n    if (!cleanedUp) {\n      if (state.pipes.length === 1 && state.pipes[0] === dest) {\n        debug('false write response, pause', 0)\n        state.awaitDrainWriters = dest\n        state.multiAwaitDrain = false\n      } else if (state.pipes.length > 1 && state.pipes.includes(dest)) {\n        debug('false write response, pause', state.awaitDrainWriters.size)\n        state.awaitDrainWriters.add(dest)\n      }\n      src.pause()\n    }\n    if (!ondrain) {\n      // When the dest drains, it reduces the awaitDrain counter\n      // on the source.  This would be more elegant with a .once()\n      // handler in flow(), but adding and removing repeatedly is\n      // too slow.\n      ondrain = pipeOnDrain(src, dest)\n      dest.on('drain', ondrain)\n    }\n  }\n  src.on('data', ondata)\n  function ondata(chunk) {\n    debug('ondata')\n    const ret = dest.write(chunk)\n    debug('dest.write', ret)\n    if (ret === false) {\n      pause()\n    }\n  }\n\n  // If the dest has an error, then stop piping into it.\n  // However, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er)\n    unpipe()\n    dest.removeListener('error', onerror)\n    if (dest.listenerCount('error') === 0) {\n      const s = dest._writableState || dest._readableState\n      if (s && !s.errorEmitted) {\n        // User incorrectly emitted 'error' directly on the stream.\n        errorOrDestroy(dest, er)\n      } else {\n        dest.emit('error', er)\n      }\n    }\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror)\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish)\n    unpipe()\n  }\n  dest.once('close', onclose)\n  function onfinish() {\n    debug('onfinish')\n    dest.removeListener('close', onclose)\n    unpipe()\n  }\n  dest.once('finish', onfinish)\n  function unpipe() {\n    debug('unpipe')\n    src.unpipe(dest)\n  }\n\n  // Tell the dest that it's being piped to.\n  dest.emit('pipe', src)\n\n  // Start the flow if it hasn't been started already.\n\n  if (dest.writableNeedDrain === true) {\n    pause()\n  } else if (!state.flowing) {\n    debug('pipe resume')\n    src.resume()\n  }\n  return dest\n}\nfunction pipeOnDrain(src, dest) {\n  return function pipeOnDrainFunctionResult() {\n    const state = src._readableState\n\n    // `ondrain` will call directly,\n    // `this` maybe not a reference to dest,\n    // so we use the real dest here.\n    if (state.awaitDrainWriters === dest) {\n      debug('pipeOnDrain', 1)\n      state.awaitDrainWriters = null\n    } else if (state.multiAwaitDrain) {\n      debug('pipeOnDrain', state.awaitDrainWriters.size)\n      state.awaitDrainWriters.delete(dest)\n    }\n    if ((!state.awaitDrainWriters || state.awaitDrainWriters.size === 0) && src.listenerCount('data')) {\n      src.resume()\n    }\n  }\n}\nReadable.prototype.unpipe = function (dest) {\n  const state = this._readableState\n  const unpipeInfo = {\n    hasUnpiped: false\n  }\n\n  // If we're not piping anywhere, then do nothing.\n  if (state.pipes.length === 0) return this\n  if (!dest) {\n    // remove all.\n    const dests = state.pipes\n    state.pipes = []\n    this.pause()\n    for (let i = 0; i < dests.length; i++)\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      })\n    return this\n  }\n\n  // Try to find the right one.\n  const index = ArrayPrototypeIndexOf(state.pipes, dest)\n  if (index === -1) return this\n  state.pipes.splice(index, 1)\n  if (state.pipes.length === 0) this.pause()\n  dest.emit('unpipe', this, unpipeInfo)\n  return this\n}\n\n// Set up data events if they are asked for\n// Ensure readable listeners eventually get something.\nReadable.prototype.on = function (ev, fn) {\n  const res = Stream.prototype.on.call(this, ev, fn)\n  const state = this._readableState\n  if (ev === 'data') {\n    // Update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0\n\n    // Try start flowing on next tick if stream isn't explicitly paused.\n    if (state.flowing !== false) this.resume()\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true\n      state.flowing = false\n      state.emittedReadable = false\n      debug('on readable', state.length, state.reading)\n      if (state.length) {\n        emitReadable(this)\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this)\n      }\n    }\n  }\n  return res\n}\nReadable.prototype.addListener = Readable.prototype.on\nReadable.prototype.removeListener = function (ev, fn) {\n  const res = Stream.prototype.removeListener.call(this, ev, fn)\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this)\n  }\n  return res\n}\nReadable.prototype.off = Readable.prototype.removeListener\nReadable.prototype.removeAllListeners = function (ev) {\n  const res = Stream.prototype.removeAllListeners.apply(this, arguments)\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this)\n  }\n  return res\n}\nfunction updateReadableListening(self) {\n  const state = self._readableState\n  state.readableListening = self.listenerCount('readable') > 0\n  if (state.resumeScheduled && state[kPaused] === false) {\n    // Flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true\n\n    // Crude way to check if we should resume.\n  } else if (self.listenerCount('data') > 0) {\n    self.resume()\n  } else if (!state.readableListening) {\n    state.flowing = null\n  }\n}\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0')\n  self.read(0)\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  const state = this._readableState\n  if (!state.flowing) {\n    debug('resume')\n    // We flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume().\n    state.flowing = !state.readableListening\n    resume(this, state)\n  }\n  state[kPaused] = false\n  return this\n}\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true\n    process.nextTick(resume_, stream, state)\n  }\n}\nfunction resume_(stream, state) {\n  debug('resume', state.reading)\n  if (!state.reading) {\n    stream.read(0)\n  }\n  state.resumeScheduled = false\n  stream.emit('resume')\n  flow(stream)\n  if (state.flowing && !state.reading) stream.read(0)\n}\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing)\n  if (this._readableState.flowing !== false) {\n    debug('pause')\n    this._readableState.flowing = false\n    this.emit('pause')\n  }\n  this._readableState[kPaused] = true\n  return this\n}\nfunction flow(stream) {\n  const state = stream._readableState\n  debug('flow', state.flowing)\n  while (state.flowing && stream.read() !== null);\n}\n\n// Wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  let paused = false\n\n  // TODO (ronag): Should this.destroy(err) emit\n  // 'error' on the wrapped stream? Would require\n  // a static factory method, e.g. Readable.wrap(stream).\n\n  stream.on('data', (chunk) => {\n    if (!this.push(chunk) && stream.pause) {\n      paused = true\n      stream.pause()\n    }\n  })\n  stream.on('end', () => {\n    this.push(null)\n  })\n  stream.on('error', (err) => {\n    errorOrDestroy(this, err)\n  })\n  stream.on('close', () => {\n    this.destroy()\n  })\n  stream.on('destroy', () => {\n    this.destroy()\n  })\n  this._read = () => {\n    if (paused && stream.resume) {\n      paused = false\n      stream.resume()\n    }\n  }\n\n  // Proxy all the other methods. Important when wrapping filters and duplexes.\n  const streamKeys = ObjectKeys(stream)\n  for (let j = 1; j < streamKeys.length; j++) {\n    const i = streamKeys[j]\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = stream[i].bind(stream)\n    }\n  }\n  return this\n}\nReadable.prototype[SymbolAsyncIterator] = function () {\n  return streamToAsyncIterator(this)\n}\nReadable.prototype.iterator = function (options) {\n  if (options !== undefined) {\n    validateObject(options, 'options')\n  }\n  return streamToAsyncIterator(this, options)\n}\nfunction streamToAsyncIterator(stream, options) {\n  if (typeof stream.read !== 'function') {\n    stream = Readable.wrap(stream, {\n      objectMode: true\n    })\n  }\n  const iter = createAsyncIterator(stream, options)\n  iter.stream = stream\n  return iter\n}\nasync function* createAsyncIterator(stream, options) {\n  let callback = nop\n  function next(resolve) {\n    if (this === stream) {\n      callback()\n      callback = nop\n    } else {\n      callback = resolve\n    }\n  }\n  stream.on('readable', next)\n  let error\n  const cleanup = eos(\n    stream,\n    {\n      writable: false\n    },\n    (err) => {\n      error = err ? aggregateTwoErrors(error, err) : null\n      callback()\n      callback = nop\n    }\n  )\n  try {\n    while (true) {\n      const chunk = stream.destroyed ? null : stream.read()\n      if (chunk !== null) {\n        yield chunk\n      } else if (error) {\n        throw error\n      } else if (error === null) {\n        return\n      } else {\n        await new Promise(next)\n      }\n    }\n  } catch (err) {\n    error = aggregateTwoErrors(error, err)\n    throw error\n  } finally {\n    if (\n      (error || (options === null || options === undefined ? undefined : options.destroyOnReturn) !== false) &&\n      (error === undefined || stream._readableState.autoDestroy)\n    ) {\n      destroyImpl.destroyer(stream, null)\n    } else {\n      stream.off('readable', next)\n      cleanup()\n    }\n  }\n}\n\n// Making it explicit these properties are not enumerable\n// because otherwise some prototype manipulation in\n// userland will fail.\nObjectDefineProperties(Readable.prototype, {\n  readable: {\n    __proto__: null,\n    get() {\n      const r = this._readableState\n      // r.readable === false means that this is part of a Duplex stream\n      // where the readable side was disabled upon construction.\n      // Compat. The user might manually disable readable side through\n      // deprecated setter.\n      return !!r && r.readable !== false && !r.destroyed && !r.errorEmitted && !r.endEmitted\n    },\n    set(val) {\n      // Backwards compat.\n      if (this._readableState) {\n        this._readableState.readable = !!val\n      }\n    }\n  },\n  readableDidRead: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.dataEmitted\n    }\n  },\n  readableAborted: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return !!(\n        this._readableState.readable !== false &&\n        (this._readableState.destroyed || this._readableState.errored) &&\n        !this._readableState.endEmitted\n      )\n    }\n  },\n  readableHighWaterMark: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.highWaterMark\n    }\n  },\n  readableBuffer: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState && this._readableState.buffer\n    }\n  },\n  readableFlowing: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return this._readableState.flowing\n    },\n    set: function (state) {\n      if (this._readableState) {\n        this._readableState.flowing = state\n      }\n    }\n  },\n  readableLength: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState.length\n    }\n  },\n  readableObjectMode: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.objectMode : false\n    }\n  },\n  readableEncoding: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.encoding : null\n    }\n  },\n  errored: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.errored : null\n    }\n  },\n  closed: {\n    __proto__: null,\n    get() {\n      return this._readableState ? this._readableState.closed : false\n    }\n  },\n  destroyed: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.destroyed : false\n    },\n    set(value) {\n      // We ignore the value if the stream\n      // has not been initialized yet.\n      if (!this._readableState) {\n        return\n      }\n\n      // Backward compatibility, the user is explicitly\n      // managing destroyed.\n      this._readableState.destroyed = value\n    }\n  },\n  readableEnded: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._readableState ? this._readableState.endEmitted : false\n    }\n  }\n})\nObjectDefineProperties(ReadableState.prototype, {\n  // Legacy getter for `pipesCount`.\n  pipesCount: {\n    __proto__: null,\n    get() {\n      return this.pipes.length\n    }\n  },\n  // Legacy property for `paused`.\n  paused: {\n    __proto__: null,\n    get() {\n      return this[kPaused] !== false\n    },\n    set(value) {\n      this[kPaused] = !!value\n    }\n  }\n})\n\n// Exposed for testing purposes only.\nReadable._fromList = fromList\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered.\n  if (state.length === 0) return null\n  let ret\n  if (state.objectMode) ret = state.buffer.shift()\n  else if (!n || n >= state.length) {\n    // Read it all, truncate the list.\n    if (state.decoder) ret = state.buffer.join('')\n    else if (state.buffer.length === 1) ret = state.buffer.first()\n    else ret = state.buffer.concat(state.length)\n    state.buffer.clear()\n  } else {\n    // read part of list.\n    ret = state.buffer.consume(n, state.decoder)\n  }\n  return ret\n}\nfunction endReadable(stream) {\n  const state = stream._readableState\n  debug('endReadable', state.endEmitted)\n  if (!state.endEmitted) {\n    state.ended = true\n    process.nextTick(endReadableNT, state, stream)\n  }\n}\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length)\n\n  // Check that we didn't get one last unshift.\n  if (!state.errored && !state.closeEmitted && !state.endEmitted && state.length === 0) {\n    state.endEmitted = true\n    stream.emit('end')\n    if (stream.writable && stream.allowHalfOpen === false) {\n      process.nextTick(endWritableNT, stream)\n    } else if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well.\n      const wState = stream._writableState\n      const autoDestroy =\n        !wState ||\n        (wState.autoDestroy &&\n          // We don't expect the writable to ever 'finish'\n          // if writable is explicitly set to false.\n          (wState.finished || wState.writable === false))\n      if (autoDestroy) {\n        stream.destroy()\n      }\n    }\n  }\n}\nfunction endWritableNT(stream) {\n  const writable = stream.writable && !stream.writableEnded && !stream.destroyed\n  if (writable) {\n    stream.end()\n  }\n}\nReadable.from = function (iterable, opts) {\n  return from(Readable, iterable, opts)\n}\nlet webStreamsAdapters\n\n// Lazy to avoid circular references\nfunction lazyWebStreams() {\n  if (webStreamsAdapters === undefined) webStreamsAdapters = {}\n  return webStreamsAdapters\n}\nReadable.fromWeb = function (readableStream, options) {\n  return lazyWebStreams().newStreamReadableFromReadableStream(readableStream, options)\n}\nReadable.toWeb = function (streamReadable, options) {\n  return lazyWebStreams().newReadableStreamFromStreamReadable(streamReadable, options)\n}\nReadable.wrap = function (src, options) {\n  var _ref, _src$readableObjectMo\n  return new Readable({\n    objectMode:\n      (_ref =\n        (_src$readableObjectMo = src.readableObjectMode) !== null && _src$readableObjectMo !== undefined\n          ? _src$readableObjectMo\n          : src.objectMode) !== null && _ref !== undefined\n        ? _ref\n        : true,\n    ...options,\n    destroy(err, callback) {\n      destroyImpl.destroyer(src, err)\n      callback(err)\n    }\n  }).wrap(src)\n}\n","'use strict'\n\nconst { MathFloor, NumberIsInteger } = require('../../ours/primordials')\nconst { validateInteger } = require('../validators')\nconst { ERR_INVALID_ARG_VALUE } = require('../../ours/errors').codes\nlet defaultHighWaterMarkBytes = 16 * 1024\nlet defaultHighWaterMarkObjectMode = 16\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null\n}\nfunction getDefaultHighWaterMark(objectMode) {\n  return objectMode ? defaultHighWaterMarkObjectMode : defaultHighWaterMarkBytes\n}\nfunction setDefaultHighWaterMark(objectMode, value) {\n  validateInteger(value, 'value', 0)\n  if (objectMode) {\n    defaultHighWaterMarkObjectMode = value\n  } else {\n    defaultHighWaterMarkBytes = value\n  }\n}\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  const hwm = highWaterMarkFrom(options, isDuplex, duplexKey)\n  if (hwm != null) {\n    if (!NumberIsInteger(hwm) || hwm < 0) {\n      const name = isDuplex ? `options.${duplexKey}` : 'options.highWaterMark'\n      throw new ERR_INVALID_ARG_VALUE(name, hwm)\n    }\n    return MathFloor(hwm)\n  }\n\n  // Default value\n  return getDefaultHighWaterMark(state.objectMode)\n}\nmodule.exports = {\n  getHighWaterMark,\n  getDefaultHighWaterMark,\n  setDefaultHighWaterMark\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict'\n\nconst { ObjectSetPrototypeOf, Symbol } = require('../../ours/primordials')\nmodule.exports = Transform\nconst { ERR_METHOD_NOT_IMPLEMENTED } = require('../../ours/errors').codes\nconst Duplex = require('./duplex')\nconst { getHighWaterMark } = require('./state')\nObjectSetPrototypeOf(Transform.prototype, Duplex.prototype)\nObjectSetPrototypeOf(Transform, Duplex)\nconst kCallback = Symbol('kCallback')\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options)\n\n  // TODO (ronag): This should preferably always be\n  // applied but would be semver-major. Or even better;\n  // make Transform a Readable with the Writable interface.\n  const readableHighWaterMark = options ? getHighWaterMark(this, options, 'readableHighWaterMark', true) : null\n  if (readableHighWaterMark === 0) {\n    // A Duplex will buffer both on the writable and readable side while\n    // a Transform just wants to buffer hwm number of elements. To avoid\n    // buffering twice we disable buffering on the writable side.\n    options = {\n      ...options,\n      highWaterMark: null,\n      readableHighWaterMark,\n      // TODO (ronag): 0 is not optimal since we have\n      // a \"bug\" where we check needDrain before calling _write and not after.\n      // Refs: https://github.com/nodejs/node/pull/32887\n      // Refs: https://github.com/nodejs/node/pull/35941\n      writableHighWaterMark: options.writableHighWaterMark || 0\n    }\n  }\n  Duplex.call(this, options)\n\n  // We have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false\n  this[kCallback] = null\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform\n    if (typeof options.flush === 'function') this._flush = options.flush\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  // Backwards compat. Some Transform streams incorrectly implement _final\n  // instead of or in addition to _flush. By using 'prefinish' instead of\n  // implementing _final we continue supporting this unfortunate use case.\n  this.on('prefinish', prefinish)\n}\nfunction final(cb) {\n  if (typeof this._flush === 'function' && !this.destroyed) {\n    this._flush((er, data) => {\n      if (er) {\n        if (cb) {\n          cb(er)\n        } else {\n          this.destroy(er)\n        }\n        return\n      }\n      if (data != null) {\n        this.push(data)\n      }\n      this.push(null)\n      if (cb) {\n        cb()\n      }\n    })\n  } else {\n    this.push(null)\n    if (cb) {\n      cb()\n    }\n  }\n}\nfunction prefinish() {\n  if (this._final !== final) {\n    final.call(this)\n  }\n}\nTransform.prototype._final = final\nTransform.prototype._transform = function (chunk, encoding, callback) {\n  throw new ERR_METHOD_NOT_IMPLEMENTED('_transform()')\n}\nTransform.prototype._write = function (chunk, encoding, callback) {\n  const rState = this._readableState\n  const wState = this._writableState\n  const length = rState.length\n  this._transform(chunk, encoding, (err, val) => {\n    if (err) {\n      callback(err)\n      return\n    }\n    if (val != null) {\n      this.push(val)\n    }\n    if (\n      wState.ended ||\n      // Backwards compat.\n      length === rState.length ||\n      // Backwards compat.\n      rState.length < rState.highWaterMark\n    ) {\n      callback()\n    } else {\n      this[kCallback] = callback\n    }\n  })\n}\nTransform.prototype._read = function () {\n  if (this[kCallback]) {\n    const callback = this[kCallback]\n    this[kCallback] = null\n    callback()\n  }\n}\n","'use strict'\n\nconst { SymbolAsyncIterator, SymbolIterator, SymbolFor } = require('../../ours/primordials')\n\n// We need to use SymbolFor to make these globally available\n// for interopt with readable-stream, i.e. readable-stream\n// and node core needs to be able to read/write private state\n// from each other for proper interoperability.\nconst kIsDestroyed = SymbolFor('nodejs.stream.destroyed')\nconst kIsErrored = SymbolFor('nodejs.stream.errored')\nconst kIsReadable = SymbolFor('nodejs.stream.readable')\nconst kIsWritable = SymbolFor('nodejs.stream.writable')\nconst kIsDisturbed = SymbolFor('nodejs.stream.disturbed')\nconst kIsClosedPromise = SymbolFor('nodejs.webstream.isClosedPromise')\nconst kControllerErrorFunction = SymbolFor('nodejs.webstream.controllerErrorFunction')\nfunction isReadableNodeStream(obj, strict = false) {\n  var _obj$_readableState\n  return !!(\n    (\n      obj &&\n      typeof obj.pipe === 'function' &&\n      typeof obj.on === 'function' &&\n      (!strict || (typeof obj.pause === 'function' && typeof obj.resume === 'function')) &&\n      (!obj._writableState ||\n        ((_obj$_readableState = obj._readableState) === null || _obj$_readableState === undefined\n          ? undefined\n          : _obj$_readableState.readable) !== false) &&\n      // Duplex\n      (!obj._writableState || obj._readableState)\n    ) // Writable has .pipe.\n  )\n}\nfunction isWritableNodeStream(obj) {\n  var _obj$_writableState\n  return !!(\n    (\n      obj &&\n      typeof obj.write === 'function' &&\n      typeof obj.on === 'function' &&\n      (!obj._readableState ||\n        ((_obj$_writableState = obj._writableState) === null || _obj$_writableState === undefined\n          ? undefined\n          : _obj$_writableState.writable) !== false)\n    ) // Duplex\n  )\n}\nfunction isDuplexNodeStream(obj) {\n  return !!(\n    obj &&\n    typeof obj.pipe === 'function' &&\n    obj._readableState &&\n    typeof obj.on === 'function' &&\n    typeof obj.write === 'function'\n  )\n}\nfunction isNodeStream(obj) {\n  return (\n    obj &&\n    (obj._readableState ||\n      obj._writableState ||\n      (typeof obj.write === 'function' && typeof obj.on === 'function') ||\n      (typeof obj.pipe === 'function' && typeof obj.on === 'function'))\n  )\n}\nfunction isReadableStream(obj) {\n  return !!(\n    obj &&\n    !isNodeStream(obj) &&\n    typeof obj.pipeThrough === 'function' &&\n    typeof obj.getReader === 'function' &&\n    typeof obj.cancel === 'function'\n  )\n}\nfunction isWritableStream(obj) {\n  return !!(obj && !isNodeStream(obj) && typeof obj.getWriter === 'function' && typeof obj.abort === 'function')\n}\nfunction isTransformStream(obj) {\n  return !!(obj && !isNodeStream(obj) && typeof obj.readable === 'object' && typeof obj.writable === 'object')\n}\nfunction isWebStream(obj) {\n  return isReadableStream(obj) || isWritableStream(obj) || isTransformStream(obj)\n}\nfunction isIterable(obj, isAsync) {\n  if (obj == null) return false\n  if (isAsync === true) return typeof obj[SymbolAsyncIterator] === 'function'\n  if (isAsync === false) return typeof obj[SymbolIterator] === 'function'\n  return typeof obj[SymbolAsyncIterator] === 'function' || typeof obj[SymbolIterator] === 'function'\n}\nfunction isDestroyed(stream) {\n  if (!isNodeStream(stream)) return null\n  const wState = stream._writableState\n  const rState = stream._readableState\n  const state = wState || rState\n  return !!(stream.destroyed || stream[kIsDestroyed] || (state !== null && state !== undefined && state.destroyed))\n}\n\n// Have been end():d.\nfunction isWritableEnded(stream) {\n  if (!isWritableNodeStream(stream)) return null\n  if (stream.writableEnded === true) return true\n  const wState = stream._writableState\n  if (wState !== null && wState !== undefined && wState.errored) return false\n  if (typeof (wState === null || wState === undefined ? undefined : wState.ended) !== 'boolean') return null\n  return wState.ended\n}\n\n// Have emitted 'finish'.\nfunction isWritableFinished(stream, strict) {\n  if (!isWritableNodeStream(stream)) return null\n  if (stream.writableFinished === true) return true\n  const wState = stream._writableState\n  if (wState !== null && wState !== undefined && wState.errored) return false\n  if (typeof (wState === null || wState === undefined ? undefined : wState.finished) !== 'boolean') return null\n  return !!(wState.finished || (strict === false && wState.ended === true && wState.length === 0))\n}\n\n// Have been push(null):d.\nfunction isReadableEnded(stream) {\n  if (!isReadableNodeStream(stream)) return null\n  if (stream.readableEnded === true) return true\n  const rState = stream._readableState\n  if (!rState || rState.errored) return false\n  if (typeof (rState === null || rState === undefined ? undefined : rState.ended) !== 'boolean') return null\n  return rState.ended\n}\n\n// Have emitted 'end'.\nfunction isReadableFinished(stream, strict) {\n  if (!isReadableNodeStream(stream)) return null\n  const rState = stream._readableState\n  if (rState !== null && rState !== undefined && rState.errored) return false\n  if (typeof (rState === null || rState === undefined ? undefined : rState.endEmitted) !== 'boolean') return null\n  return !!(rState.endEmitted || (strict === false && rState.ended === true && rState.length === 0))\n}\nfunction isReadable(stream) {\n  if (stream && stream[kIsReadable] != null) return stream[kIsReadable]\n  if (typeof (stream === null || stream === undefined ? undefined : stream.readable) !== 'boolean') return null\n  if (isDestroyed(stream)) return false\n  return isReadableNodeStream(stream) && stream.readable && !isReadableFinished(stream)\n}\nfunction isWritable(stream) {\n  if (stream && stream[kIsWritable] != null) return stream[kIsWritable]\n  if (typeof (stream === null || stream === undefined ? undefined : stream.writable) !== 'boolean') return null\n  if (isDestroyed(stream)) return false\n  return isWritableNodeStream(stream) && stream.writable && !isWritableEnded(stream)\n}\nfunction isFinished(stream, opts) {\n  if (!isNodeStream(stream)) {\n    return null\n  }\n  if (isDestroyed(stream)) {\n    return true\n  }\n  if ((opts === null || opts === undefined ? undefined : opts.readable) !== false && isReadable(stream)) {\n    return false\n  }\n  if ((opts === null || opts === undefined ? undefined : opts.writable) !== false && isWritable(stream)) {\n    return false\n  }\n  return true\n}\nfunction isWritableErrored(stream) {\n  var _stream$_writableStat, _stream$_writableStat2\n  if (!isNodeStream(stream)) {\n    return null\n  }\n  if (stream.writableErrored) {\n    return stream.writableErrored\n  }\n  return (_stream$_writableStat =\n    (_stream$_writableStat2 = stream._writableState) === null || _stream$_writableStat2 === undefined\n      ? undefined\n      : _stream$_writableStat2.errored) !== null && _stream$_writableStat !== undefined\n    ? _stream$_writableStat\n    : null\n}\nfunction isReadableErrored(stream) {\n  var _stream$_readableStat, _stream$_readableStat2\n  if (!isNodeStream(stream)) {\n    return null\n  }\n  if (stream.readableErrored) {\n    return stream.readableErrored\n  }\n  return (_stream$_readableStat =\n    (_stream$_readableStat2 = stream._readableState) === null || _stream$_readableStat2 === undefined\n      ? undefined\n      : _stream$_readableStat2.errored) !== null && _stream$_readableStat !== undefined\n    ? _stream$_readableStat\n    : null\n}\nfunction isClosed(stream) {\n  if (!isNodeStream(stream)) {\n    return null\n  }\n  if (typeof stream.closed === 'boolean') {\n    return stream.closed\n  }\n  const wState = stream._writableState\n  const rState = stream._readableState\n  if (\n    typeof (wState === null || wState === undefined ? undefined : wState.closed) === 'boolean' ||\n    typeof (rState === null || rState === undefined ? undefined : rState.closed) === 'boolean'\n  ) {\n    return (\n      (wState === null || wState === undefined ? undefined : wState.closed) ||\n      (rState === null || rState === undefined ? undefined : rState.closed)\n    )\n  }\n  if (typeof stream._closed === 'boolean' && isOutgoingMessage(stream)) {\n    return stream._closed\n  }\n  return null\n}\nfunction isOutgoingMessage(stream) {\n  return (\n    typeof stream._closed === 'boolean' &&\n    typeof stream._defaultKeepAlive === 'boolean' &&\n    typeof stream._removedConnection === 'boolean' &&\n    typeof stream._removedContLen === 'boolean'\n  )\n}\nfunction isServerResponse(stream) {\n  return typeof stream._sent100 === 'boolean' && isOutgoingMessage(stream)\n}\nfunction isServerRequest(stream) {\n  var _stream$req\n  return (\n    typeof stream._consuming === 'boolean' &&\n    typeof stream._dumped === 'boolean' &&\n    ((_stream$req = stream.req) === null || _stream$req === undefined ? undefined : _stream$req.upgradeOrConnect) ===\n      undefined\n  )\n}\nfunction willEmitClose(stream) {\n  if (!isNodeStream(stream)) return null\n  const wState = stream._writableState\n  const rState = stream._readableState\n  const state = wState || rState\n  return (\n    (!state && isServerResponse(stream)) || !!(state && state.autoDestroy && state.emitClose && state.closed === false)\n  )\n}\nfunction isDisturbed(stream) {\n  var _stream$kIsDisturbed\n  return !!(\n    stream &&\n    ((_stream$kIsDisturbed = stream[kIsDisturbed]) !== null && _stream$kIsDisturbed !== undefined\n      ? _stream$kIsDisturbed\n      : stream.readableDidRead || stream.readableAborted)\n  )\n}\nfunction isErrored(stream) {\n  var _ref,\n    _ref2,\n    _ref3,\n    _ref4,\n    _ref5,\n    _stream$kIsErrored,\n    _stream$_readableStat3,\n    _stream$_writableStat3,\n    _stream$_readableStat4,\n    _stream$_writableStat4\n  return !!(\n    stream &&\n    ((_ref =\n      (_ref2 =\n        (_ref3 =\n          (_ref4 =\n            (_ref5 =\n              (_stream$kIsErrored = stream[kIsErrored]) !== null && _stream$kIsErrored !== undefined\n                ? _stream$kIsErrored\n                : stream.readableErrored) !== null && _ref5 !== undefined\n              ? _ref5\n              : stream.writableErrored) !== null && _ref4 !== undefined\n            ? _ref4\n            : (_stream$_readableStat3 = stream._readableState) === null || _stream$_readableStat3 === undefined\n            ? undefined\n            : _stream$_readableStat3.errorEmitted) !== null && _ref3 !== undefined\n          ? _ref3\n          : (_stream$_writableStat3 = stream._writableState) === null || _stream$_writableStat3 === undefined\n          ? undefined\n          : _stream$_writableStat3.errorEmitted) !== null && _ref2 !== undefined\n        ? _ref2\n        : (_stream$_readableStat4 = stream._readableState) === null || _stream$_readableStat4 === undefined\n        ? undefined\n        : _stream$_readableStat4.errored) !== null && _ref !== undefined\n      ? _ref\n      : (_stream$_writableStat4 = stream._writableState) === null || _stream$_writableStat4 === undefined\n      ? undefined\n      : _stream$_writableStat4.errored)\n  )\n}\nmodule.exports = {\n  isDestroyed,\n  kIsDestroyed,\n  isDisturbed,\n  kIsDisturbed,\n  isErrored,\n  kIsErrored,\n  isReadable,\n  kIsReadable,\n  kIsClosedPromise,\n  kControllerErrorFunction,\n  kIsWritable,\n  isClosed,\n  isDuplexNodeStream,\n  isFinished,\n  isIterable,\n  isReadableNodeStream,\n  isReadableStream,\n  isReadableEnded,\n  isReadableFinished,\n  isReadableErrored,\n  isNodeStream,\n  isWebStream,\n  isWritable,\n  isWritableNodeStream,\n  isWritableStream,\n  isWritableEnded,\n  isWritableFinished,\n  isWritableErrored,\n  isServerRequest,\n  isServerResponse,\n  willEmitClose,\n  isTransformStream\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict'\n\n/* replacement start */\n\nconst process = require('process/')\n\n/* replacement end */\n\nconst {\n  ArrayPrototypeSlice,\n  Error,\n  FunctionPrototypeSymbolHasInstance,\n  ObjectDefineProperty,\n  ObjectDefineProperties,\n  ObjectSetPrototypeOf,\n  StringPrototypeToLowerCase,\n  Symbol,\n  SymbolHasInstance\n} = require('../../ours/primordials')\nmodule.exports = Writable\nWritable.WritableState = WritableState\nconst { EventEmitter: EE } = require('events')\nconst Stream = require('./legacy').Stream\nconst { Buffer } = require('buffer')\nconst destroyImpl = require('./destroy')\nconst { addAbortSignal } = require('./add-abort-signal')\nconst { getHighWaterMark, getDefaultHighWaterMark } = require('./state')\nconst {\n  ERR_INVALID_ARG_TYPE,\n  ERR_METHOD_NOT_IMPLEMENTED,\n  ERR_MULTIPLE_CALLBACK,\n  ERR_STREAM_CANNOT_PIPE,\n  ERR_STREAM_DESTROYED,\n  ERR_STREAM_ALREADY_FINISHED,\n  ERR_STREAM_NULL_VALUES,\n  ERR_STREAM_WRITE_AFTER_END,\n  ERR_UNKNOWN_ENCODING\n} = require('../../ours/errors').codes\nconst { errorOrDestroy } = destroyImpl\nObjectSetPrototypeOf(Writable.prototype, Stream.prototype)\nObjectSetPrototypeOf(Writable, Stream)\nfunction nop() {}\nconst kOnFinished = Symbol('kOnFinished')\nfunction WritableState(options, stream, isDuplex) {\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof require('./duplex')\n\n  // Object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!(options && options.objectMode)\n  if (isDuplex) this.objectMode = this.objectMode || !!(options && options.writableObjectMode)\n\n  // The point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write().\n  this.highWaterMark = options\n    ? getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex)\n    : getDefaultHighWaterMark(false)\n\n  // if _final has been called.\n  this.finalCalled = false\n\n  // drain event flag.\n  this.needDrain = false\n  // At the start of calling end()\n  this.ending = false\n  // When end() has been called, and returned.\n  this.ended = false\n  // When 'finish' is emitted.\n  this.finished = false\n\n  // Has it been destroyed\n  this.destroyed = false\n\n  // Should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  const noDecode = !!(options && options.decodeStrings === false)\n  this.decodeStrings = !noDecode\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = (options && options.defaultEncoding) || 'utf8'\n\n  // Not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0\n\n  // A flag to see when we're in the middle of a write.\n  this.writing = false\n\n  // When true all writes will be buffered until .uncork() call.\n  this.corked = 0\n\n  // A flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true\n\n  // A flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false\n\n  // The callback that's passed to _write(chunk, cb).\n  this.onwrite = onwrite.bind(undefined, stream)\n\n  // The callback that the user supplies to write(chunk, encoding, cb).\n  this.writecb = null\n\n  // The amount that is being written when _write is called.\n  this.writelen = 0\n\n  // Storage for data passed to the afterWrite() callback in case of\n  // synchronous _write() completion.\n  this.afterWriteTickInfo = null\n  resetBuffer(this)\n\n  // Number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted.\n  this.pendingcb = 0\n\n  // Stream is still being constructed and cannot be\n  // destroyed until construction finished or failed.\n  // Async construction is opt in, therefore we start as\n  // constructed.\n  this.constructed = true\n\n  // Emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams.\n  this.prefinished = false\n\n  // True if the error was already emitted and should not be thrown again.\n  this.errorEmitted = false\n\n  // Should close be emitted on destroy. Defaults to true.\n  this.emitClose = !options || options.emitClose !== false\n\n  // Should .destroy() be called after 'finish' (and potentially 'end').\n  this.autoDestroy = !options || options.autoDestroy !== false\n\n  // Indicates whether the stream has errored. When true all write() calls\n  // should return false. This is needed since when autoDestroy\n  // is disabled we need a way to tell whether the stream has failed.\n  this.errored = null\n\n  // Indicates whether the stream has finished destroying.\n  this.closed = false\n\n  // True if close has been emitted or would have been emitted\n  // depending on emitClose.\n  this.closeEmitted = false\n  this[kOnFinished] = []\n}\nfunction resetBuffer(state) {\n  state.buffered = []\n  state.bufferedIndex = 0\n  state.allBuffers = true\n  state.allNoop = true\n}\nWritableState.prototype.getBuffer = function getBuffer() {\n  return ArrayPrototypeSlice(this.buffered, this.bufferedIndex)\n}\nObjectDefineProperty(WritableState.prototype, 'bufferedRequestCount', {\n  __proto__: null,\n  get() {\n    return this.buffered.length - this.bufferedIndex\n  }\n})\nfunction Writable(options) {\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5.\n  const isDuplex = this instanceof require('./duplex')\n  if (!isDuplex && !FunctionPrototypeSymbolHasInstance(Writable, this)) return new Writable(options)\n  this._writableState = new WritableState(options, this, isDuplex)\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write\n    if (typeof options.writev === 'function') this._writev = options.writev\n    if (typeof options.destroy === 'function') this._destroy = options.destroy\n    if (typeof options.final === 'function') this._final = options.final\n    if (typeof options.construct === 'function') this._construct = options.construct\n    if (options.signal) addAbortSignal(options.signal, this)\n  }\n  Stream.call(this, options)\n  destroyImpl.construct(this, () => {\n    const state = this._writableState\n    if (!state.writing) {\n      clearBuffer(this, state)\n    }\n    finishMaybe(this, state)\n  })\n}\nObjectDefineProperty(Writable, SymbolHasInstance, {\n  __proto__: null,\n  value: function (object) {\n    if (FunctionPrototypeSymbolHasInstance(this, object)) return true\n    if (this !== Writable) return false\n    return object && object._writableState instanceof WritableState\n  }\n})\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE())\n}\nfunction _write(stream, chunk, encoding, cb) {\n  const state = stream._writableState\n  if (typeof encoding === 'function') {\n    cb = encoding\n    encoding = state.defaultEncoding\n  } else {\n    if (!encoding) encoding = state.defaultEncoding\n    else if (encoding !== 'buffer' && !Buffer.isEncoding(encoding)) throw new ERR_UNKNOWN_ENCODING(encoding)\n    if (typeof cb !== 'function') cb = nop\n  }\n  if (chunk === null) {\n    throw new ERR_STREAM_NULL_VALUES()\n  } else if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      if (state.decodeStrings !== false) {\n        chunk = Buffer.from(chunk, encoding)\n        encoding = 'buffer'\n      }\n    } else if (chunk instanceof Buffer) {\n      encoding = 'buffer'\n    } else if (Stream._isUint8Array(chunk)) {\n      chunk = Stream._uint8ArrayToBuffer(chunk)\n      encoding = 'buffer'\n    } else {\n      throw new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk)\n    }\n  }\n  let err\n  if (state.ending) {\n    err = new ERR_STREAM_WRITE_AFTER_END()\n  } else if (state.destroyed) {\n    err = new ERR_STREAM_DESTROYED('write')\n  }\n  if (err) {\n    process.nextTick(cb, err)\n    errorOrDestroy(stream, err, true)\n    return err\n  }\n  state.pendingcb++\n  return writeOrBuffer(stream, state, chunk, encoding, cb)\n}\nWritable.prototype.write = function (chunk, encoding, cb) {\n  return _write(this, chunk, encoding, cb) === true\n}\nWritable.prototype.cork = function () {\n  this._writableState.corked++\n}\nWritable.prototype.uncork = function () {\n  const state = this._writableState\n  if (state.corked) {\n    state.corked--\n    if (!state.writing) clearBuffer(this, state)\n  }\n}\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = StringPrototypeToLowerCase(encoding)\n  if (!Buffer.isEncoding(encoding)) throw new ERR_UNKNOWN_ENCODING(encoding)\n  this._writableState.defaultEncoding = encoding\n  return this\n}\n\n// If we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, chunk, encoding, callback) {\n  const len = state.objectMode ? 1 : chunk.length\n  state.length += len\n\n  // stream._write resets state.length\n  const ret = state.length < state.highWaterMark\n  // We must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true\n  if (state.writing || state.corked || state.errored || !state.constructed) {\n    state.buffered.push({\n      chunk,\n      encoding,\n      callback\n    })\n    if (state.allBuffers && encoding !== 'buffer') {\n      state.allBuffers = false\n    }\n    if (state.allNoop && callback !== nop) {\n      state.allNoop = false\n    }\n  } else {\n    state.writelen = len\n    state.writecb = callback\n    state.writing = true\n    state.sync = true\n    stream._write(chunk, encoding, state.onwrite)\n    state.sync = false\n  }\n\n  // Return false if errored or destroyed in order to break\n  // any synchronous while(stream.write(data)) loops.\n  return ret && !state.errored && !state.destroyed\n}\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len\n  state.writecb = cb\n  state.writing = true\n  state.sync = true\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'))\n  else if (writev) stream._writev(chunk, state.onwrite)\n  else stream._write(chunk, encoding, state.onwrite)\n  state.sync = false\n}\nfunction onwriteError(stream, state, er, cb) {\n  --state.pendingcb\n  cb(er)\n  // Ensure callbacks are invoked even when autoDestroy is\n  // not enabled. Passing `er` here doesn't make sense since\n  // it's related to one specific write, not to the buffered\n  // writes.\n  errorBuffer(state)\n  // This can emit error, but error must always follow cb.\n  errorOrDestroy(stream, er)\n}\nfunction onwrite(stream, er) {\n  const state = stream._writableState\n  const sync = state.sync\n  const cb = state.writecb\n  if (typeof cb !== 'function') {\n    errorOrDestroy(stream, new ERR_MULTIPLE_CALLBACK())\n    return\n  }\n  state.writing = false\n  state.writecb = null\n  state.length -= state.writelen\n  state.writelen = 0\n  if (er) {\n    // Avoid V8 leak, https://github.com/nodejs/node/pull/34103#issuecomment-652002364\n    er.stack // eslint-disable-line no-unused-expressions\n\n    if (!state.errored) {\n      state.errored = er\n    }\n\n    // In case of duplex streams we need to notify the readable side of the\n    // error.\n    if (stream._readableState && !stream._readableState.errored) {\n      stream._readableState.errored = er\n    }\n    if (sync) {\n      process.nextTick(onwriteError, stream, state, er, cb)\n    } else {\n      onwriteError(stream, state, er, cb)\n    }\n  } else {\n    if (state.buffered.length > state.bufferedIndex) {\n      clearBuffer(stream, state)\n    }\n    if (sync) {\n      // It is a common case that the callback passed to .write() is always\n      // the same. In that case, we do not schedule a new nextTick(), but\n      // rather just increase a counter, to improve performance and avoid\n      // memory allocations.\n      if (state.afterWriteTickInfo !== null && state.afterWriteTickInfo.cb === cb) {\n        state.afterWriteTickInfo.count++\n      } else {\n        state.afterWriteTickInfo = {\n          count: 1,\n          cb,\n          stream,\n          state\n        }\n        process.nextTick(afterWriteTick, state.afterWriteTickInfo)\n      }\n    } else {\n      afterWrite(stream, state, 1, cb)\n    }\n  }\n}\nfunction afterWriteTick({ stream, state, count, cb }) {\n  state.afterWriteTickInfo = null\n  return afterWrite(stream, state, count, cb)\n}\nfunction afterWrite(stream, state, count, cb) {\n  const needDrain = !state.ending && !stream.destroyed && state.length === 0 && state.needDrain\n  if (needDrain) {\n    state.needDrain = false\n    stream.emit('drain')\n  }\n  while (count-- > 0) {\n    state.pendingcb--\n    cb()\n  }\n  if (state.destroyed) {\n    errorBuffer(state)\n  }\n  finishMaybe(stream, state)\n}\n\n// If there's something in the buffer waiting, then invoke callbacks.\nfunction errorBuffer(state) {\n  if (state.writing) {\n    return\n  }\n  for (let n = state.bufferedIndex; n < state.buffered.length; ++n) {\n    var _state$errored\n    const { chunk, callback } = state.buffered[n]\n    const len = state.objectMode ? 1 : chunk.length\n    state.length -= len\n    callback(\n      (_state$errored = state.errored) !== null && _state$errored !== undefined\n        ? _state$errored\n        : new ERR_STREAM_DESTROYED('write')\n    )\n  }\n  const onfinishCallbacks = state[kOnFinished].splice(0)\n  for (let i = 0; i < onfinishCallbacks.length; i++) {\n    var _state$errored2\n    onfinishCallbacks[i](\n      (_state$errored2 = state.errored) !== null && _state$errored2 !== undefined\n        ? _state$errored2\n        : new ERR_STREAM_DESTROYED('end')\n    )\n  }\n  resetBuffer(state)\n}\n\n// If there's something in the buffer waiting, then process it.\nfunction clearBuffer(stream, state) {\n  if (state.corked || state.bufferProcessing || state.destroyed || !state.constructed) {\n    return\n  }\n  const { buffered, bufferedIndex, objectMode } = state\n  const bufferedLength = buffered.length - bufferedIndex\n  if (!bufferedLength) {\n    return\n  }\n  let i = bufferedIndex\n  state.bufferProcessing = true\n  if (bufferedLength > 1 && stream._writev) {\n    state.pendingcb -= bufferedLength - 1\n    const callback = state.allNoop\n      ? nop\n      : (err) => {\n          for (let n = i; n < buffered.length; ++n) {\n            buffered[n].callback(err)\n          }\n        }\n    // Make a copy of `buffered` if it's going to be used by `callback` above,\n    // since `doWrite` will mutate the array.\n    const chunks = state.allNoop && i === 0 ? buffered : ArrayPrototypeSlice(buffered, i)\n    chunks.allBuffers = state.allBuffers\n    doWrite(stream, state, true, state.length, chunks, '', callback)\n    resetBuffer(state)\n  } else {\n    do {\n      const { chunk, encoding, callback } = buffered[i]\n      buffered[i++] = null\n      const len = objectMode ? 1 : chunk.length\n      doWrite(stream, state, false, len, chunk, encoding, callback)\n    } while (i < buffered.length && !state.writing)\n    if (i === buffered.length) {\n      resetBuffer(state)\n    } else if (i > 256) {\n      buffered.splice(0, i)\n      state.bufferedIndex = 0\n    } else {\n      state.bufferedIndex = i\n    }\n  }\n  state.bufferProcessing = false\n}\nWritable.prototype._write = function (chunk, encoding, cb) {\n  if (this._writev) {\n    this._writev(\n      [\n        {\n          chunk,\n          encoding\n        }\n      ],\n      cb\n    )\n  } else {\n    throw new ERR_METHOD_NOT_IMPLEMENTED('_write()')\n  }\n}\nWritable.prototype._writev = null\nWritable.prototype.end = function (chunk, encoding, cb) {\n  const state = this._writableState\n  if (typeof chunk === 'function') {\n    cb = chunk\n    chunk = null\n    encoding = null\n  } else if (typeof encoding === 'function') {\n    cb = encoding\n    encoding = null\n  }\n  let err\n  if (chunk !== null && chunk !== undefined) {\n    const ret = _write(this, chunk, encoding)\n    if (ret instanceof Error) {\n      err = ret\n    }\n  }\n\n  // .end() fully uncorks.\n  if (state.corked) {\n    state.corked = 1\n    this.uncork()\n  }\n  if (err) {\n    // Do nothing...\n  } else if (!state.errored && !state.ending) {\n    // This is forgiving in terms of unnecessary calls to end() and can hide\n    // logic errors. However, usually such errors are harmless and causing a\n    // hard error can be disproportionately destructive. It is not always\n    // trivial for the user to determine whether end() needs to be called\n    // or not.\n\n    state.ending = true\n    finishMaybe(this, state, true)\n    state.ended = true\n  } else if (state.finished) {\n    err = new ERR_STREAM_ALREADY_FINISHED('end')\n  } else if (state.destroyed) {\n    err = new ERR_STREAM_DESTROYED('end')\n  }\n  if (typeof cb === 'function') {\n    if (err || state.finished) {\n      process.nextTick(cb, err)\n    } else {\n      state[kOnFinished].push(cb)\n    }\n  }\n  return this\n}\nfunction needFinish(state) {\n  return (\n    state.ending &&\n    !state.destroyed &&\n    state.constructed &&\n    state.length === 0 &&\n    !state.errored &&\n    state.buffered.length === 0 &&\n    !state.finished &&\n    !state.writing &&\n    !state.errorEmitted &&\n    !state.closeEmitted\n  )\n}\nfunction callFinal(stream, state) {\n  let called = false\n  function onFinish(err) {\n    if (called) {\n      errorOrDestroy(stream, err !== null && err !== undefined ? err : ERR_MULTIPLE_CALLBACK())\n      return\n    }\n    called = true\n    state.pendingcb--\n    if (err) {\n      const onfinishCallbacks = state[kOnFinished].splice(0)\n      for (let i = 0; i < onfinishCallbacks.length; i++) {\n        onfinishCallbacks[i](err)\n      }\n      errorOrDestroy(stream, err, state.sync)\n    } else if (needFinish(state)) {\n      state.prefinished = true\n      stream.emit('prefinish')\n      // Backwards compat. Don't check state.sync here.\n      // Some streams assume 'finish' will be emitted\n      // asynchronously relative to _final callback.\n      state.pendingcb++\n      process.nextTick(finish, stream, state)\n    }\n  }\n  state.sync = true\n  state.pendingcb++\n  try {\n    stream._final(onFinish)\n  } catch (err) {\n    onFinish(err)\n  }\n  state.sync = false\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.finalCalled = true\n      callFinal(stream, state)\n    } else {\n      state.prefinished = true\n      stream.emit('prefinish')\n    }\n  }\n}\nfunction finishMaybe(stream, state, sync) {\n  if (needFinish(state)) {\n    prefinish(stream, state)\n    if (state.pendingcb === 0) {\n      if (sync) {\n        state.pendingcb++\n        process.nextTick(\n          (stream, state) => {\n            if (needFinish(state)) {\n              finish(stream, state)\n            } else {\n              state.pendingcb--\n            }\n          },\n          stream,\n          state\n        )\n      } else if (needFinish(state)) {\n        state.pendingcb++\n        finish(stream, state)\n      }\n    }\n  }\n}\nfunction finish(stream, state) {\n  state.pendingcb--\n  state.finished = true\n  const onfinishCallbacks = state[kOnFinished].splice(0)\n  for (let i = 0; i < onfinishCallbacks.length; i++) {\n    onfinishCallbacks[i]()\n  }\n  stream.emit('finish')\n  if (state.autoDestroy) {\n    // In case of duplex streams we need a way to detect\n    // if the readable side is ready for autoDestroy as well.\n    const rState = stream._readableState\n    const autoDestroy =\n      !rState ||\n      (rState.autoDestroy &&\n        // We don't expect the readable to ever 'end'\n        // if readable is explicitly set to false.\n        (rState.endEmitted || rState.readable === false))\n    if (autoDestroy) {\n      stream.destroy()\n    }\n  }\n}\nObjectDefineProperties(Writable.prototype, {\n  closed: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.closed : false\n    }\n  },\n  destroyed: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.destroyed : false\n    },\n    set(value) {\n      // Backward compatibility, the user is explicitly managing destroyed.\n      if (this._writableState) {\n        this._writableState.destroyed = value\n      }\n    }\n  },\n  writable: {\n    __proto__: null,\n    get() {\n      const w = this._writableState\n      // w.writable === false means that this is part of a Duplex stream\n      // where the writable side was disabled upon construction.\n      // Compat. The user might manually disable writable side through\n      // deprecated setter.\n      return !!w && w.writable !== false && !w.destroyed && !w.errored && !w.ending && !w.ended\n    },\n    set(val) {\n      // Backwards compatible.\n      if (this._writableState) {\n        this._writableState.writable = !!val\n      }\n    }\n  },\n  writableFinished: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.finished : false\n    }\n  },\n  writableObjectMode: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.objectMode : false\n    }\n  },\n  writableBuffer: {\n    __proto__: null,\n    get() {\n      return this._writableState && this._writableState.getBuffer()\n    }\n  },\n  writableEnded: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.ending : false\n    }\n  },\n  writableNeedDrain: {\n    __proto__: null,\n    get() {\n      const wState = this._writableState\n      if (!wState) return false\n      return !wState.destroyed && !wState.ending && wState.needDrain\n    }\n  },\n  writableHighWaterMark: {\n    __proto__: null,\n    get() {\n      return this._writableState && this._writableState.highWaterMark\n    }\n  },\n  writableCorked: {\n    __proto__: null,\n    get() {\n      return this._writableState ? this._writableState.corked : 0\n    }\n  },\n  writableLength: {\n    __proto__: null,\n    get() {\n      return this._writableState && this._writableState.length\n    }\n  },\n  errored: {\n    __proto__: null,\n    enumerable: false,\n    get() {\n      return this._writableState ? this._writableState.errored : null\n    }\n  },\n  writableAborted: {\n    __proto__: null,\n    enumerable: false,\n    get: function () {\n      return !!(\n        this._writableState.writable !== false &&\n        (this._writableState.destroyed || this._writableState.errored) &&\n        !this._writableState.finished\n      )\n    }\n  }\n})\nconst destroy = destroyImpl.destroy\nWritable.prototype.destroy = function (err, cb) {\n  const state = this._writableState\n\n  // Invoke pending callbacks.\n  if (!state.destroyed && (state.bufferedIndex < state.buffered.length || state[kOnFinished].length)) {\n    process.nextTick(errorBuffer, state)\n  }\n  destroy.call(this, err, cb)\n  return this\n}\nWritable.prototype._undestroy = destroyImpl.undestroy\nWritable.prototype._destroy = function (err, cb) {\n  cb(err)\n}\nWritable.prototype[EE.captureRejectionSymbol] = function (err) {\n  this.destroy(err)\n}\nlet webStreamsAdapters\n\n// Lazy to avoid circular references\nfunction lazyWebStreams() {\n  if (webStreamsAdapters === undefined) webStreamsAdapters = {}\n  return webStreamsAdapters\n}\nWritable.fromWeb = function (writableStream, options) {\n  return lazyWebStreams().newStreamWritableFromWritableStream(writableStream, options)\n}\nWritable.toWeb = function (streamWritable) {\n  return lazyWebStreams().newWritableStreamFromStreamWritable(streamWritable)\n}\n","/* eslint jsdoc/require-jsdoc: \"error\" */\n\n'use strict'\n\nconst {\n  ArrayIsArray,\n  ArrayPrototypeIncludes,\n  ArrayPrototypeJoin,\n  ArrayPrototypeMap,\n  NumberIsInteger,\n  NumberIsNaN,\n  NumberMAX_SAFE_INTEGER,\n  NumberMIN_SAFE_INTEGER,\n  NumberParseInt,\n  ObjectPrototypeHasOwnProperty,\n  RegExpPrototypeExec,\n  String,\n  StringPrototypeToUpperCase,\n  StringPrototypeTrim\n} = require('../ours/primordials')\nconst {\n  hideStackFrames,\n  codes: { ERR_SOCKET_BAD_PORT, ERR_INVALID_ARG_TYPE, ERR_INVALID_ARG_VALUE, ERR_OUT_OF_RANGE, ERR_UNKNOWN_SIGNAL }\n} = require('../ours/errors')\nconst { normalizeEncoding } = require('../ours/util')\nconst { isAsyncFunction, isArrayBufferView } = require('../ours/util').types\nconst signals = {}\n\n/**\n * @param {*} value\n * @returns {boolean}\n */\nfunction isInt32(value) {\n  return value === (value | 0)\n}\n\n/**\n * @param {*} value\n * @returns {boolean}\n */\nfunction isUint32(value) {\n  return value === value >>> 0\n}\nconst octalReg = /^[0-7]+$/\nconst modeDesc = 'must be a 32-bit unsigned integer or an octal string'\n\n/**\n * Parse and validate values that will be converted into mode_t (the S_*\n * constants). Only valid numbers and octal strings are allowed. They could be\n * converted to 32-bit unsigned integers or non-negative signed integers in the\n * C++ land, but any value higher than 0o777 will result in platform-specific\n * behaviors.\n * @param {*} value Values to be validated\n * @param {string} name Name of the argument\n * @param {number} [def] If specified, will be returned for invalid values\n * @returns {number}\n */\nfunction parseFileMode(value, name, def) {\n  if (typeof value === 'undefined') {\n    value = def\n  }\n  if (typeof value === 'string') {\n    if (RegExpPrototypeExec(octalReg, value) === null) {\n      throw new ERR_INVALID_ARG_VALUE(name, value, modeDesc)\n    }\n    value = NumberParseInt(value, 8)\n  }\n  validateUint32(value, name)\n  return value\n}\n\n/**\n * @callback validateInteger\n * @param {*} value\n * @param {string} name\n * @param {number} [min]\n * @param {number} [max]\n * @returns {asserts value is number}\n */\n\n/** @type {validateInteger} */\nconst validateInteger = hideStackFrames((value, name, min = NumberMIN_SAFE_INTEGER, max = NumberMAX_SAFE_INTEGER) => {\n  if (typeof value !== 'number') throw new ERR_INVALID_ARG_TYPE(name, 'number', value)\n  if (!NumberIsInteger(value)) throw new ERR_OUT_OF_RANGE(name, 'an integer', value)\n  if (value < min || value > max) throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)\n})\n\n/**\n * @callback validateInt32\n * @param {*} value\n * @param {string} name\n * @param {number} [min]\n * @param {number} [max]\n * @returns {asserts value is number}\n */\n\n/** @type {validateInt32} */\nconst validateInt32 = hideStackFrames((value, name, min = -2147483648, max = 2147483647) => {\n  // The defaults for min and max correspond to the limits of 32-bit integers.\n  if (typeof value !== 'number') {\n    throw new ERR_INVALID_ARG_TYPE(name, 'number', value)\n  }\n  if (!NumberIsInteger(value)) {\n    throw new ERR_OUT_OF_RANGE(name, 'an integer', value)\n  }\n  if (value < min || value > max) {\n    throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)\n  }\n})\n\n/**\n * @callback validateUint32\n * @param {*} value\n * @param {string} name\n * @param {number|boolean} [positive=false]\n * @returns {asserts value is number}\n */\n\n/** @type {validateUint32} */\nconst validateUint32 = hideStackFrames((value, name, positive = false) => {\n  if (typeof value !== 'number') {\n    throw new ERR_INVALID_ARG_TYPE(name, 'number', value)\n  }\n  if (!NumberIsInteger(value)) {\n    throw new ERR_OUT_OF_RANGE(name, 'an integer', value)\n  }\n  const min = positive ? 1 : 0\n  // 2 ** 32 === 4294967296\n  const max = 4294967295\n  if (value < min || value > max) {\n    throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value)\n  }\n})\n\n/**\n * @callback validateString\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is string}\n */\n\n/** @type {validateString} */\nfunction validateString(value, name) {\n  if (typeof value !== 'string') throw new ERR_INVALID_ARG_TYPE(name, 'string', value)\n}\n\n/**\n * @callback validateNumber\n * @param {*} value\n * @param {string} name\n * @param {number} [min]\n * @param {number} [max]\n * @returns {asserts value is number}\n */\n\n/** @type {validateNumber} */\nfunction validateNumber(value, name, min = undefined, max) {\n  if (typeof value !== 'number') throw new ERR_INVALID_ARG_TYPE(name, 'number', value)\n  if (\n    (min != null && value < min) ||\n    (max != null && value > max) ||\n    ((min != null || max != null) && NumberIsNaN(value))\n  ) {\n    throw new ERR_OUT_OF_RANGE(\n      name,\n      `${min != null ? `>= ${min}` : ''}${min != null && max != null ? ' && ' : ''}${max != null ? `<= ${max}` : ''}`,\n      value\n    )\n  }\n}\n\n/**\n * @callback validateOneOf\n * @template T\n * @param {T} value\n * @param {string} name\n * @param {T[]} oneOf\n */\n\n/** @type {validateOneOf} */\nconst validateOneOf = hideStackFrames((value, name, oneOf) => {\n  if (!ArrayPrototypeIncludes(oneOf, value)) {\n    const allowed = ArrayPrototypeJoin(\n      ArrayPrototypeMap(oneOf, (v) => (typeof v === 'string' ? `'${v}'` : String(v))),\n      ', '\n    )\n    const reason = 'must be one of: ' + allowed\n    throw new ERR_INVALID_ARG_VALUE(name, value, reason)\n  }\n})\n\n/**\n * @callback validateBoolean\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is boolean}\n */\n\n/** @type {validateBoolean} */\nfunction validateBoolean(value, name) {\n  if (typeof value !== 'boolean') throw new ERR_INVALID_ARG_TYPE(name, 'boolean', value)\n}\n\n/**\n * @param {any} options\n * @param {string} key\n * @param {boolean} defaultValue\n * @returns {boolean}\n */\nfunction getOwnPropertyValueOrDefault(options, key, defaultValue) {\n  return options == null || !ObjectPrototypeHasOwnProperty(options, key) ? defaultValue : options[key]\n}\n\n/**\n * @callback validateObject\n * @param {*} value\n * @param {string} name\n * @param {{\n *   allowArray?: boolean,\n *   allowFunction?: boolean,\n *   nullable?: boolean\n * }} [options]\n */\n\n/** @type {validateObject} */\nconst validateObject = hideStackFrames((value, name, options = null) => {\n  const allowArray = getOwnPropertyValueOrDefault(options, 'allowArray', false)\n  const allowFunction = getOwnPropertyValueOrDefault(options, 'allowFunction', false)\n  const nullable = getOwnPropertyValueOrDefault(options, 'nullable', false)\n  if (\n    (!nullable && value === null) ||\n    (!allowArray && ArrayIsArray(value)) ||\n    (typeof value !== 'object' && (!allowFunction || typeof value !== 'function'))\n  ) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'Object', value)\n  }\n})\n\n/**\n * @callback validateDictionary - We are using the Web IDL Standard definition\n *                                of \"dictionary\" here, which means any value\n *                                whose Type is either Undefined, Null, or\n *                                Object (which includes functions).\n * @param {*} value\n * @param {string} name\n * @see https://webidl.spec.whatwg.org/#es-dictionary\n * @see https://tc39.es/ecma262/#table-typeof-operator-results\n */\n\n/** @type {validateDictionary} */\nconst validateDictionary = hideStackFrames((value, name) => {\n  if (value != null && typeof value !== 'object' && typeof value !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE(name, 'a dictionary', value)\n  }\n})\n\n/**\n * @callback validateArray\n * @param {*} value\n * @param {string} name\n * @param {number} [minLength]\n * @returns {asserts value is any[]}\n */\n\n/** @type {validateArray} */\nconst validateArray = hideStackFrames((value, name, minLength = 0) => {\n  if (!ArrayIsArray(value)) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'Array', value)\n  }\n  if (value.length < minLength) {\n    const reason = `must be longer than ${minLength}`\n    throw new ERR_INVALID_ARG_VALUE(name, value, reason)\n  }\n})\n\n/**\n * @callback validateStringArray\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is string[]}\n */\n\n/** @type {validateStringArray} */\nfunction validateStringArray(value, name) {\n  validateArray(value, name)\n  for (let i = 0; i < value.length; i++) {\n    validateString(value[i], `${name}[${i}]`)\n  }\n}\n\n/**\n * @callback validateBooleanArray\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is boolean[]}\n */\n\n/** @type {validateBooleanArray} */\nfunction validateBooleanArray(value, name) {\n  validateArray(value, name)\n  for (let i = 0; i < value.length; i++) {\n    validateBoolean(value[i], `${name}[${i}]`)\n  }\n}\n\n/**\n * @callback validateAbortSignalArray\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is AbortSignal[]}\n */\n\n/** @type {validateAbortSignalArray} */\nfunction validateAbortSignalArray(value, name) {\n  validateArray(value, name)\n  for (let i = 0; i < value.length; i++) {\n    const signal = value[i]\n    const indexedName = `${name}[${i}]`\n    if (signal == null) {\n      throw new ERR_INVALID_ARG_TYPE(indexedName, 'AbortSignal', signal)\n    }\n    validateAbortSignal(signal, indexedName)\n  }\n}\n\n/**\n * @param {*} signal\n * @param {string} [name='signal']\n * @returns {asserts signal is keyof signals}\n */\nfunction validateSignalName(signal, name = 'signal') {\n  validateString(signal, name)\n  if (signals[signal] === undefined) {\n    if (signals[StringPrototypeToUpperCase(signal)] !== undefined) {\n      throw new ERR_UNKNOWN_SIGNAL(signal + ' (signals must use all capital letters)')\n    }\n    throw new ERR_UNKNOWN_SIGNAL(signal)\n  }\n}\n\n/**\n * @callback validateBuffer\n * @param {*} buffer\n * @param {string} [name='buffer']\n * @returns {asserts buffer is ArrayBufferView}\n */\n\n/** @type {validateBuffer} */\nconst validateBuffer = hideStackFrames((buffer, name = 'buffer') => {\n  if (!isArrayBufferView(buffer)) {\n    throw new ERR_INVALID_ARG_TYPE(name, ['Buffer', 'TypedArray', 'DataView'], buffer)\n  }\n})\n\n/**\n * @param {string} data\n * @param {string} encoding\n */\nfunction validateEncoding(data, encoding) {\n  const normalizedEncoding = normalizeEncoding(encoding)\n  const length = data.length\n  if (normalizedEncoding === 'hex' && length % 2 !== 0) {\n    throw new ERR_INVALID_ARG_VALUE('encoding', encoding, `is invalid for data of length ${length}`)\n  }\n}\n\n/**\n * Check that the port number is not NaN when coerced to a number,\n * is an integer and that it falls within the legal range of port numbers.\n * @param {*} port\n * @param {string} [name='Port']\n * @param {boolean} [allowZero=true]\n * @returns {number}\n */\nfunction validatePort(port, name = 'Port', allowZero = true) {\n  if (\n    (typeof port !== 'number' && typeof port !== 'string') ||\n    (typeof port === 'string' && StringPrototypeTrim(port).length === 0) ||\n    +port !== +port >>> 0 ||\n    port > 0xffff ||\n    (port === 0 && !allowZero)\n  ) {\n    throw new ERR_SOCKET_BAD_PORT(name, port, allowZero)\n  }\n  return port | 0\n}\n\n/**\n * @callback validateAbortSignal\n * @param {*} signal\n * @param {string} name\n */\n\n/** @type {validateAbortSignal} */\nconst validateAbortSignal = hideStackFrames((signal, name) => {\n  if (signal !== undefined && (signal === null || typeof signal !== 'object' || !('aborted' in signal))) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)\n  }\n})\n\n/**\n * @callback validateFunction\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is Function}\n */\n\n/** @type {validateFunction} */\nconst validateFunction = hideStackFrames((value, name) => {\n  if (typeof value !== 'function') throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)\n})\n\n/**\n * @callback validatePlainFunction\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is Function}\n */\n\n/** @type {validatePlainFunction} */\nconst validatePlainFunction = hideStackFrames((value, name) => {\n  if (typeof value !== 'function' || isAsyncFunction(value)) throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)\n})\n\n/**\n * @callback validateUndefined\n * @param {*} value\n * @param {string} name\n * @returns {asserts value is undefined}\n */\n\n/** @type {validateUndefined} */\nconst validateUndefined = hideStackFrames((value, name) => {\n  if (value !== undefined) throw new ERR_INVALID_ARG_TYPE(name, 'undefined', value)\n})\n\n/**\n * @template T\n * @param {T} value\n * @param {string} name\n * @param {T[]} union\n */\nfunction validateUnion(value, name, union) {\n  if (!ArrayPrototypeIncludes(union, value)) {\n    throw new ERR_INVALID_ARG_TYPE(name, `('${ArrayPrototypeJoin(union, '|')}')`, value)\n  }\n}\n\n/*\n  The rules for the Link header field are described here:\n  https://www.rfc-editor.org/rfc/rfc8288.html#section-3\n\n  This regex validates any string surrounded by angle brackets\n  (not necessarily a valid URI reference) followed by zero or more\n  link-params separated by semicolons.\n*/\nconst linkValueRegExp = /^(?:<[^>]*>)(?:\\s*;\\s*[^;\"\\s]+(?:=(\")?[^;\"\\s]*\\1)?)*$/\n\n/**\n * @param {any} value\n * @param {string} name\n */\nfunction validateLinkHeaderFormat(value, name) {\n  if (typeof value === 'undefined' || !RegExpPrototypeExec(linkValueRegExp, value)) {\n    throw new ERR_INVALID_ARG_VALUE(\n      name,\n      value,\n      'must be an array or string of format \"</styles.css>; rel=preload; as=style\"'\n    )\n  }\n}\n\n/**\n * @param {any} hints\n * @return {string}\n */\nfunction validateLinkHeaderValue(hints) {\n  if (typeof hints === 'string') {\n    validateLinkHeaderFormat(hints, 'hints')\n    return hints\n  } else if (ArrayIsArray(hints)) {\n    const hintsLength = hints.length\n    let result = ''\n    if (hintsLength === 0) {\n      return result\n    }\n    for (let i = 0; i < hintsLength; i++) {\n      const link = hints[i]\n      validateLinkHeaderFormat(link, 'hints')\n      result += link\n      if (i !== hintsLength - 1) {\n        result += ', '\n      }\n    }\n    return result\n  }\n  throw new ERR_INVALID_ARG_VALUE(\n    'hints',\n    hints,\n    'must be an array or string of format \"</styles.css>; rel=preload; as=style\"'\n  )\n}\nmodule.exports = {\n  isInt32,\n  isUint32,\n  parseFileMode,\n  validateArray,\n  validateStringArray,\n  validateBooleanArray,\n  validateAbortSignalArray,\n  validateBoolean,\n  validateBuffer,\n  validateDictionary,\n  validateEncoding,\n  validateFunction,\n  validateInt32,\n  validateInteger,\n  validateNumber,\n  validateObject,\n  validateOneOf,\n  validatePlainFunction,\n  validatePort,\n  validateSignalName,\n  validateString,\n  validateUint32,\n  validateUndefined,\n  validateUnion,\n  validateAbortSignal,\n  validateLinkHeaderValue\n}\n","'use strict'\n\nconst { format, inspect } = require('./util/inspect')\nconst { AggregateError: CustomAggregateError } = require('./primordials')\n\n/*\n  This file is a reduced and adapted version of the main lib/internal/errors.js file defined at\n\n  https://github.com/nodejs/node/blob/main/lib/internal/errors.js\n\n  Don't try to replace with the original file and keep it up to date (starting from E(...) definitions)\n  with the upstream file.\n*/\n\nconst AggregateError = globalThis.AggregateError || CustomAggregateError\nconst kIsNodeError = Symbol('kIsNodeError')\nconst kTypes = [\n  'string',\n  'function',\n  'number',\n  'object',\n  // Accept 'Function' and 'Object' as alternative to the lower cased version.\n  'Function',\n  'Object',\n  'boolean',\n  'bigint',\n  'symbol'\n]\nconst classRegExp = /^([A-Z][a-z0-9]*)+$/\nconst nodeInternalPrefix = '__node_internal_'\nconst codes = {}\nfunction assert(value, message) {\n  if (!value) {\n    throw new codes.ERR_INTERNAL_ASSERTION(message)\n  }\n}\n\n// Only use this for integers! Decimal numbers do not work with this function.\nfunction addNumericalSeparator(val) {\n  let res = ''\n  let i = val.length\n  const start = val[0] === '-' ? 1 : 0\n  for (; i >= start + 4; i -= 3) {\n    res = `_${val.slice(i - 3, i)}${res}`\n  }\n  return `${val.slice(0, i)}${res}`\n}\nfunction getMessage(key, msg, args) {\n  if (typeof msg === 'function') {\n    assert(\n      msg.length <= args.length,\n      // Default options do not count.\n      `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${msg.length}).`\n    )\n    return msg(...args)\n  }\n  const expectedLength = (msg.match(/%[dfijoOs]/g) || []).length\n  assert(\n    expectedLength === args.length,\n    `Code: ${key}; The provided arguments length (${args.length}) does not match the required ones (${expectedLength}).`\n  )\n  if (args.length === 0) {\n    return msg\n  }\n  return format(msg, ...args)\n}\nfunction E(code, message, Base) {\n  if (!Base) {\n    Base = Error\n  }\n  class NodeError extends Base {\n    constructor(...args) {\n      super(getMessage(code, message, args))\n    }\n    toString() {\n      return `${this.name} [${code}]: ${this.message}`\n    }\n  }\n  Object.defineProperties(NodeError.prototype, {\n    name: {\n      value: Base.name,\n      writable: true,\n      enumerable: false,\n      configurable: true\n    },\n    toString: {\n      value() {\n        return `${this.name} [${code}]: ${this.message}`\n      },\n      writable: true,\n      enumerable: false,\n      configurable: true\n    }\n  })\n  NodeError.prototype.code = code\n  NodeError.prototype[kIsNodeError] = true\n  codes[code] = NodeError\n}\nfunction hideStackFrames(fn) {\n  // We rename the functions that will be hidden to cut off the stacktrace\n  // at the outermost one\n  const hidden = nodeInternalPrefix + fn.name\n  Object.defineProperty(fn, 'name', {\n    value: hidden\n  })\n  return fn\n}\nfunction aggregateTwoErrors(innerError, outerError) {\n  if (innerError && outerError && innerError !== outerError) {\n    if (Array.isArray(outerError.errors)) {\n      // If `outerError` is already an `AggregateError`.\n      outerError.errors.push(innerError)\n      return outerError\n    }\n    const err = new AggregateError([outerError, innerError], outerError.message)\n    err.code = outerError.code\n    return err\n  }\n  return innerError || outerError\n}\nclass AbortError extends Error {\n  constructor(message = 'The operation was aborted', options = undefined) {\n    if (options !== undefined && typeof options !== 'object') {\n      throw new codes.ERR_INVALID_ARG_TYPE('options', 'Object', options)\n    }\n    super(message, options)\n    this.code = 'ABORT_ERR'\n    this.name = 'AbortError'\n  }\n}\nE('ERR_ASSERTION', '%s', Error)\nE(\n  'ERR_INVALID_ARG_TYPE',\n  (name, expected, actual) => {\n    assert(typeof name === 'string', \"'name' must be a string\")\n    if (!Array.isArray(expected)) {\n      expected = [expected]\n    }\n    let msg = 'The '\n    if (name.endsWith(' argument')) {\n      // For cases like 'first argument'\n      msg += `${name} `\n    } else {\n      msg += `\"${name}\" ${name.includes('.') ? 'property' : 'argument'} `\n    }\n    msg += 'must be '\n    const types = []\n    const instances = []\n    const other = []\n    for (const value of expected) {\n      assert(typeof value === 'string', 'All expected entries have to be of type string')\n      if (kTypes.includes(value)) {\n        types.push(value.toLowerCase())\n      } else if (classRegExp.test(value)) {\n        instances.push(value)\n      } else {\n        assert(value !== 'object', 'The value \"object\" should be written as \"Object\"')\n        other.push(value)\n      }\n    }\n\n    // Special handle `object` in case other instances are allowed to outline\n    // the differences between each other.\n    if (instances.length > 0) {\n      const pos = types.indexOf('object')\n      if (pos !== -1) {\n        types.splice(types, pos, 1)\n        instances.push('Object')\n      }\n    }\n    if (types.length > 0) {\n      switch (types.length) {\n        case 1:\n          msg += `of type ${types[0]}`\n          break\n        case 2:\n          msg += `one of type ${types[0]} or ${types[1]}`\n          break\n        default: {\n          const last = types.pop()\n          msg += `one of type ${types.join(', ')}, or ${last}`\n        }\n      }\n      if (instances.length > 0 || other.length > 0) {\n        msg += ' or '\n      }\n    }\n    if (instances.length > 0) {\n      switch (instances.length) {\n        case 1:\n          msg += `an instance of ${instances[0]}`\n          break\n        case 2:\n          msg += `an instance of ${instances[0]} or ${instances[1]}`\n          break\n        default: {\n          const last = instances.pop()\n          msg += `an instance of ${instances.join(', ')}, or ${last}`\n        }\n      }\n      if (other.length > 0) {\n        msg += ' or '\n      }\n    }\n    switch (other.length) {\n      case 0:\n        break\n      case 1:\n        if (other[0].toLowerCase() !== other[0]) {\n          msg += 'an '\n        }\n        msg += `${other[0]}`\n        break\n      case 2:\n        msg += `one of ${other[0]} or ${other[1]}`\n        break\n      default: {\n        const last = other.pop()\n        msg += `one of ${other.join(', ')}, or ${last}`\n      }\n    }\n    if (actual == null) {\n      msg += `. Received ${actual}`\n    } else if (typeof actual === 'function' && actual.name) {\n      msg += `. Received function ${actual.name}`\n    } else if (typeof actual === 'object') {\n      var _actual$constructor\n      if (\n        (_actual$constructor = actual.constructor) !== null &&\n        _actual$constructor !== undefined &&\n        _actual$constructor.name\n      ) {\n        msg += `. Received an instance of ${actual.constructor.name}`\n      } else {\n        const inspected = inspect(actual, {\n          depth: -1\n        })\n        msg += `. Received ${inspected}`\n      }\n    } else {\n      let inspected = inspect(actual, {\n        colors: false\n      })\n      if (inspected.length > 25) {\n        inspected = `${inspected.slice(0, 25)}...`\n      }\n      msg += `. Received type ${typeof actual} (${inspected})`\n    }\n    return msg\n  },\n  TypeError\n)\nE(\n  'ERR_INVALID_ARG_VALUE',\n  (name, value, reason = 'is invalid') => {\n    let inspected = inspect(value)\n    if (inspected.length > 128) {\n      inspected = inspected.slice(0, 128) + '...'\n    }\n    const type = name.includes('.') ? 'property' : 'argument'\n    return `The ${type} '${name}' ${reason}. Received ${inspected}`\n  },\n  TypeError\n)\nE(\n  'ERR_INVALID_RETURN_VALUE',\n  (input, name, value) => {\n    var _value$constructor\n    const type =\n      value !== null &&\n      value !== undefined &&\n      (_value$constructor = value.constructor) !== null &&\n      _value$constructor !== undefined &&\n      _value$constructor.name\n        ? `instance of ${value.constructor.name}`\n        : `type ${typeof value}`\n    return `Expected ${input} to be returned from the \"${name}\"` + ` function but got ${type}.`\n  },\n  TypeError\n)\nE(\n  'ERR_MISSING_ARGS',\n  (...args) => {\n    assert(args.length > 0, 'At least one arg needs to be specified')\n    let msg\n    const len = args.length\n    args = (Array.isArray(args) ? args : [args]).map((a) => `\"${a}\"`).join(' or ')\n    switch (len) {\n      case 1:\n        msg += `The ${args[0]} argument`\n        break\n      case 2:\n        msg += `The ${args[0]} and ${args[1]} arguments`\n        break\n      default:\n        {\n          const last = args.pop()\n          msg += `The ${args.join(', ')}, and ${last} arguments`\n        }\n        break\n    }\n    return `${msg} must be specified`\n  },\n  TypeError\n)\nE(\n  'ERR_OUT_OF_RANGE',\n  (str, range, input) => {\n    assert(range, 'Missing \"range\" argument')\n    let received\n    if (Number.isInteger(input) && Math.abs(input) > 2 ** 32) {\n      received = addNumericalSeparator(String(input))\n    } else if (typeof input === 'bigint') {\n      received = String(input)\n      const limit = BigInt(2) ** BigInt(32)\n      if (input > limit || input < -limit) {\n        received = addNumericalSeparator(received)\n      }\n      received += 'n'\n    } else {\n      received = inspect(input)\n    }\n    return `The value of \"${str}\" is out of range. It must be ${range}. Received ${received}`\n  },\n  RangeError\n)\nE('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times', Error)\nE('ERR_METHOD_NOT_IMPLEMENTED', 'The %s method is not implemented', Error)\nE('ERR_STREAM_ALREADY_FINISHED', 'Cannot call %s after a stream was finished', Error)\nE('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable', Error)\nE('ERR_STREAM_DESTROYED', 'Cannot call %s after a stream was destroyed', Error)\nE('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError)\nE('ERR_STREAM_PREMATURE_CLOSE', 'Premature close', Error)\nE('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF', Error)\nE('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event', Error)\nE('ERR_STREAM_WRITE_AFTER_END', 'write after end', Error)\nE('ERR_UNKNOWN_ENCODING', 'Unknown encoding: %s', TypeError)\nmodule.exports = {\n  AbortError,\n  aggregateTwoErrors: hideStackFrames(aggregateTwoErrors),\n  hideStackFrames,\n  codes\n}\n","'use strict'\n\nconst Stream = require('stream')\nif (Stream && process.env.READABLE_STREAM === 'disable') {\n  const promises = Stream.promises\n\n  // Explicit export naming is needed for ESM\n  module.exports._uint8ArrayToBuffer = Stream._uint8ArrayToBuffer\n  module.exports._isUint8Array = Stream._isUint8Array\n  module.exports.isDisturbed = Stream.isDisturbed\n  module.exports.isErrored = Stream.isErrored\n  module.exports.isReadable = Stream.isReadable\n  module.exports.Readable = Stream.Readable\n  module.exports.Writable = Stream.Writable\n  module.exports.Duplex = Stream.Duplex\n  module.exports.Transform = Stream.Transform\n  module.exports.PassThrough = Stream.PassThrough\n  module.exports.addAbortSignal = Stream.addAbortSignal\n  module.exports.finished = Stream.finished\n  module.exports.destroy = Stream.destroy\n  module.exports.pipeline = Stream.pipeline\n  module.exports.compose = Stream.compose\n  Object.defineProperty(Stream, 'promises', {\n    configurable: true,\n    enumerable: true,\n    get() {\n      return promises\n    }\n  })\n  module.exports.Stream = Stream.Stream\n} else {\n  const CustomStream = require('../stream')\n  const promises = require('../stream/promises')\n  const originalDestroy = CustomStream.Readable.destroy\n  module.exports = CustomStream.Readable\n\n  // Explicit export naming is needed for ESM\n  module.exports._uint8ArrayToBuffer = CustomStream._uint8ArrayToBuffer\n  module.exports._isUint8Array = CustomStream._isUint8Array\n  module.exports.isDisturbed = CustomStream.isDisturbed\n  module.exports.isErrored = CustomStream.isErrored\n  module.exports.isReadable = CustomStream.isReadable\n  module.exports.Readable = CustomStream.Readable\n  module.exports.Writable = CustomStream.Writable\n  module.exports.Duplex = CustomStream.Duplex\n  module.exports.Transform = CustomStream.Transform\n  module.exports.PassThrough = CustomStream.PassThrough\n  module.exports.addAbortSignal = CustomStream.addAbortSignal\n  module.exports.finished = CustomStream.finished\n  module.exports.destroy = CustomStream.destroy\n  module.exports.destroy = originalDestroy\n  module.exports.pipeline = CustomStream.pipeline\n  module.exports.compose = CustomStream.compose\n  Object.defineProperty(CustomStream, 'promises', {\n    configurable: true,\n    enumerable: true,\n    get() {\n      return promises\n    }\n  })\n  module.exports.Stream = CustomStream.Stream\n}\n\n// Allow default importing\nmodule.exports.default = module.exports\n","'use strict'\n\n/*\n  This file is a reduced and adapted version of the main lib/internal/per_context/primordials.js file defined at\n\n  https://github.com/nodejs/node/blob/main/lib/internal/per_context/primordials.js\n\n  Don't try to replace with the original file and keep it up to date with the upstream file.\n*/\n\n// This is a simplified version of AggregateError\nclass AggregateError extends Error {\n  constructor(errors) {\n    if (!Array.isArray(errors)) {\n      throw new TypeError(`Expected input to be an Array, got ${typeof errors}`)\n    }\n    let message = ''\n    for (let i = 0; i < errors.length; i++) {\n      message += `    ${errors[i].stack}\\n`\n    }\n    super(message)\n    this.name = 'AggregateError'\n    this.errors = errors\n  }\n}\nmodule.exports = {\n  AggregateError,\n  ArrayIsArray(self) {\n    return Array.isArray(self)\n  },\n  ArrayPrototypeIncludes(self, el) {\n    return self.includes(el)\n  },\n  ArrayPrototypeIndexOf(self, el) {\n    return self.indexOf(el)\n  },\n  ArrayPrototypeJoin(self, sep) {\n    return self.join(sep)\n  },\n  ArrayPrototypeMap(self, fn) {\n    return self.map(fn)\n  },\n  ArrayPrototypePop(self, el) {\n    return self.pop(el)\n  },\n  ArrayPrototypePush(self, el) {\n    return self.push(el)\n  },\n  ArrayPrototypeSlice(self, start, end) {\n    return self.slice(start, end)\n  },\n  Error,\n  FunctionPrototypeCall(fn, thisArgs, ...args) {\n    return fn.call(thisArgs, ...args)\n  },\n  FunctionPrototypeSymbolHasInstance(self, instance) {\n    return Function.prototype[Symbol.hasInstance].call(self, instance)\n  },\n  MathFloor: Math.floor,\n  Number,\n  NumberIsInteger: Number.isInteger,\n  NumberIsNaN: Number.isNaN,\n  NumberMAX_SAFE_INTEGER: Number.MAX_SAFE_INTEGER,\n  NumberMIN_SAFE_INTEGER: Number.MIN_SAFE_INTEGER,\n  NumberParseInt: Number.parseInt,\n  ObjectDefineProperties(self, props) {\n    return Object.defineProperties(self, props)\n  },\n  ObjectDefineProperty(self, name, prop) {\n    return Object.defineProperty(self, name, prop)\n  },\n  ObjectGetOwnPropertyDescriptor(self, name) {\n    return Object.getOwnPropertyDescriptor(self, name)\n  },\n  ObjectKeys(obj) {\n    return Object.keys(obj)\n  },\n  ObjectSetPrototypeOf(target, proto) {\n    return Object.setPrototypeOf(target, proto)\n  },\n  Promise,\n  PromisePrototypeCatch(self, fn) {\n    return self.catch(fn)\n  },\n  PromisePrototypeThen(self, thenFn, catchFn) {\n    return self.then(thenFn, catchFn)\n  },\n  PromiseReject(err) {\n    return Promise.reject(err)\n  },\n  PromiseResolve(val) {\n    return Promise.resolve(val)\n  },\n  ReflectApply: Reflect.apply,\n  RegExpPrototypeTest(self, value) {\n    return self.test(value)\n  },\n  SafeSet: Set,\n  String,\n  StringPrototypeSlice(self, start, end) {\n    return self.slice(start, end)\n  },\n  StringPrototypeToLowerCase(self) {\n    return self.toLowerCase()\n  },\n  StringPrototypeToUpperCase(self) {\n    return self.toUpperCase()\n  },\n  StringPrototypeTrim(self) {\n    return self.trim()\n  },\n  Symbol,\n  SymbolFor: Symbol.for,\n  SymbolAsyncIterator: Symbol.asyncIterator,\n  SymbolHasInstance: Symbol.hasInstance,\n  SymbolIterator: Symbol.iterator,\n  SymbolDispose: Symbol.dispose || Symbol('Symbol.dispose'),\n  SymbolAsyncDispose: Symbol.asyncDispose || Symbol('Symbol.asyncDispose'),\n  TypedArrayPrototypeSet(self, buf, len) {\n    return self.set(buf, len)\n  },\n  Boolean,\n  Uint8Array\n}\n","'use strict'\n\nconst bufferModule = require('buffer')\nconst { format, inspect } = require('./util/inspect')\nconst {\n  codes: { ERR_INVALID_ARG_TYPE }\n} = require('./errors')\nconst { kResistStopPropagation, AggregateError, SymbolDispose } = require('./primordials')\nconst AbortSignal = globalThis.AbortSignal || require('abort-controller').AbortSignal\nconst AbortController = globalThis.AbortController || require('abort-controller').AbortController\nconst AsyncFunction = Object.getPrototypeOf(async function () {}).constructor\nconst Blob = globalThis.Blob || bufferModule.Blob\n/* eslint-disable indent */\nconst isBlob =\n  typeof Blob !== 'undefined'\n    ? function isBlob(b) {\n        // eslint-disable-next-line indent\n        return b instanceof Blob\n      }\n    : function isBlob(b) {\n        return false\n      }\n/* eslint-enable indent */\n\nconst validateAbortSignal = (signal, name) => {\n  if (signal !== undefined && (signal === null || typeof signal !== 'object' || !('aborted' in signal))) {\n    throw new ERR_INVALID_ARG_TYPE(name, 'AbortSignal', signal)\n  }\n}\nconst validateFunction = (value, name) => {\n  if (typeof value !== 'function') {\n    throw new ERR_INVALID_ARG_TYPE(name, 'Function', value)\n  }\n}\nmodule.exports = {\n  AggregateError,\n  kEmptyObject: Object.freeze({}),\n  once(callback) {\n    let called = false\n    return function (...args) {\n      if (called) {\n        return\n      }\n      called = true\n      callback.apply(this, args)\n    }\n  },\n  createDeferredPromise: function () {\n    let resolve\n    let reject\n\n    // eslint-disable-next-line promise/param-names\n    const promise = new Promise((res, rej) => {\n      resolve = res\n      reject = rej\n    })\n    return {\n      promise,\n      resolve,\n      reject\n    }\n  },\n  promisify(fn) {\n    return new Promise((resolve, reject) => {\n      fn((err, ...args) => {\n        if (err) {\n          return reject(err)\n        }\n        return resolve(...args)\n      })\n    })\n  },\n  debuglog() {\n    return function () {}\n  },\n  format,\n  inspect,\n  types: {\n    isAsyncFunction(fn) {\n      return fn instanceof AsyncFunction\n    },\n    isArrayBufferView(arr) {\n      return ArrayBuffer.isView(arr)\n    }\n  },\n  isBlob,\n  deprecate(fn, message) {\n    return fn\n  },\n  addAbortListener:\n    require('events').addAbortListener ||\n    function addAbortListener(signal, listener) {\n      if (signal === undefined) {\n        throw new ERR_INVALID_ARG_TYPE('signal', 'AbortSignal', signal)\n      }\n      validateAbortSignal(signal, 'signal')\n      validateFunction(listener, 'listener')\n      let removeEventListener\n      if (signal.aborted) {\n        queueMicrotask(() => listener())\n      } else {\n        signal.addEventListener('abort', listener, {\n          __proto__: null,\n          once: true,\n          [kResistStopPropagation]: true\n        })\n        removeEventListener = () => {\n          signal.removeEventListener('abort', listener)\n        }\n      }\n      return {\n        __proto__: null,\n        [SymbolDispose]() {\n          var _removeEventListener\n          ;(_removeEventListener = removeEventListener) === null || _removeEventListener === undefined\n            ? undefined\n            : _removeEventListener()\n        }\n      }\n    },\n  AbortSignalAny:\n    AbortSignal.any ||\n    function AbortSignalAny(signals) {\n      // Fast path if there is only one signal.\n      if (signals.length === 1) {\n        return signals[0]\n      }\n      const ac = new AbortController()\n      const abort = () => ac.abort()\n      signals.forEach((signal) => {\n        validateAbortSignal(signal, 'signals')\n        signal.addEventListener('abort', abort, {\n          once: true\n        })\n      })\n      ac.signal.addEventListener(\n        'abort',\n        () => {\n          signals.forEach((signal) => signal.removeEventListener('abort', abort))\n        },\n        {\n          once: true\n        }\n      )\n      return ac.signal\n    }\n}\nmodule.exports.promisify.custom = Symbol.for('nodejs.util.promisify.custom')\n","'use strict'\n\n/*\n  This file is a reduced and adapted version of the main lib/internal/util/inspect.js file defined at\n\n  https://github.com/nodejs/node/blob/main/lib/internal/util/inspect.js\n\n  Don't try to replace with the original file and keep it up to date with the upstream file.\n*/\nmodule.exports = {\n  format(format, ...args) {\n    // Simplified version of https://nodejs.org/api/util.html#utilformatformat-args\n    return format.replace(/%([sdifj])/g, function (...[_unused, type]) {\n      const replacement = args.shift()\n      if (type === 'f') {\n        return replacement.toFixed(6)\n      } else if (type === 'j') {\n        return JSON.stringify(replacement)\n      } else if (type === 's' && typeof replacement === 'object') {\n        const ctor = replacement.constructor !== Object ? replacement.constructor.name : ''\n        return `${ctor} {}`.trim()\n      } else {\n        return replacement.toString()\n      }\n    })\n  },\n  inspect(value) {\n    // Vastly simplified version of https://nodejs.org/api/util.html#utilinspectobject-options\n    switch (typeof value) {\n      case 'string':\n        if (value.includes(\"'\")) {\n          if (!value.includes('\"')) {\n            return `\"${value}\"`\n          } else if (!value.includes('`') && !value.includes('${')) {\n            return `\\`${value}\\``\n          }\n        }\n        return `'${value}'`\n      case 'number':\n        if (isNaN(value)) {\n          return 'NaN'\n        } else if (Object.is(value, -0)) {\n          return String(value)\n        }\n        return value\n      case 'bigint':\n        return `${String(value)}n`\n      case 'boolean':\n      case 'undefined':\n        return String(value)\n      case 'object':\n        return '{}'\n    }\n  }\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict'\n\n/* replacement start */\n\nconst { Buffer } = require('buffer')\n\n/* replacement end */\n\nconst { ObjectDefineProperty, ObjectKeys, ReflectApply } = require('./ours/primordials')\nconst {\n  promisify: { custom: customPromisify }\n} = require('./ours/util')\nconst { streamReturningOperators, promiseReturningOperators } = require('./internal/streams/operators')\nconst {\n  codes: { ERR_ILLEGAL_CONSTRUCTOR }\n} = require('./ours/errors')\nconst compose = require('./internal/streams/compose')\nconst { setDefaultHighWaterMark, getDefaultHighWaterMark } = require('./internal/streams/state')\nconst { pipeline } = require('./internal/streams/pipeline')\nconst { destroyer } = require('./internal/streams/destroy')\nconst eos = require('./internal/streams/end-of-stream')\nconst internalBuffer = {}\nconst promises = require('./stream/promises')\nconst utils = require('./internal/streams/utils')\nconst Stream = (module.exports = require('./internal/streams/legacy').Stream)\nStream.isDestroyed = utils.isDestroyed\nStream.isDisturbed = utils.isDisturbed\nStream.isErrored = utils.isErrored\nStream.isReadable = utils.isReadable\nStream.isWritable = utils.isWritable\nStream.Readable = require('./internal/streams/readable')\nfor (const key of ObjectKeys(streamReturningOperators)) {\n  const op = streamReturningOperators[key]\n  function fn(...args) {\n    if (new.target) {\n      throw ERR_ILLEGAL_CONSTRUCTOR()\n    }\n    return Stream.Readable.from(ReflectApply(op, this, args))\n  }\n  ObjectDefineProperty(fn, 'name', {\n    __proto__: null,\n    value: op.name\n  })\n  ObjectDefineProperty(fn, 'length', {\n    __proto__: null,\n    value: op.length\n  })\n  ObjectDefineProperty(Stream.Readable.prototype, key, {\n    __proto__: null,\n    value: fn,\n    enumerable: false,\n    configurable: true,\n    writable: true\n  })\n}\nfor (const key of ObjectKeys(promiseReturningOperators)) {\n  const op = promiseReturningOperators[key]\n  function fn(...args) {\n    if (new.target) {\n      throw ERR_ILLEGAL_CONSTRUCTOR()\n    }\n    return ReflectApply(op, this, args)\n  }\n  ObjectDefineProperty(fn, 'name', {\n    __proto__: null,\n    value: op.name\n  })\n  ObjectDefineProperty(fn, 'length', {\n    __proto__: null,\n    value: op.length\n  })\n  ObjectDefineProperty(Stream.Readable.prototype, key, {\n    __proto__: null,\n    value: fn,\n    enumerable: false,\n    configurable: true,\n    writable: true\n  })\n}\nStream.Writable = require('./internal/streams/writable')\nStream.Duplex = require('./internal/streams/duplex')\nStream.Transform = require('./internal/streams/transform')\nStream.PassThrough = require('./internal/streams/passthrough')\nStream.pipeline = pipeline\nconst { addAbortSignal } = require('./internal/streams/add-abort-signal')\nStream.addAbortSignal = addAbortSignal\nStream.finished = eos\nStream.destroy = destroyer\nStream.compose = compose\nStream.setDefaultHighWaterMark = setDefaultHighWaterMark\nStream.getDefaultHighWaterMark = getDefaultHighWaterMark\nObjectDefineProperty(Stream, 'promises', {\n  __proto__: null,\n  configurable: true,\n  enumerable: true,\n  get() {\n    return promises\n  }\n})\nObjectDefineProperty(pipeline, customPromisify, {\n  __proto__: null,\n  enumerable: true,\n  get() {\n    return promises.pipeline\n  }\n})\nObjectDefineProperty(eos, customPromisify, {\n  __proto__: null,\n  enumerable: true,\n  get() {\n    return promises.finished\n  }\n})\n\n// Backwards-compat with node 0.4.x\nStream.Stream = Stream\nStream._isUint8Array = function isUint8Array(value) {\n  return value instanceof Uint8Array\n}\nStream._uint8ArrayToBuffer = function _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)\n}\n","'use strict'\n\nconst { ArrayPrototypePop, Promise } = require('../ours/primordials')\nconst { isIterable, isNodeStream, isWebStream } = require('../internal/streams/utils')\nconst { pipelineImpl: pl } = require('../internal/streams/pipeline')\nconst { finished } = require('../internal/streams/end-of-stream')\nrequire('../../lib/stream.js')\nfunction pipeline(...streams) {\n  return new Promise((resolve, reject) => {\n    let signal\n    let end\n    const lastArg = streams[streams.length - 1]\n    if (\n      lastArg &&\n      typeof lastArg === 'object' &&\n      !isNodeStream(lastArg) &&\n      !isIterable(lastArg) &&\n      !isWebStream(lastArg)\n    ) {\n      const options = ArrayPrototypePop(streams)\n      signal = options.signal\n      end = options.end\n    }\n    pl(\n      streams,\n      (err, value) => {\n        if (err) {\n          reject(err)\n        } else {\n          resolve(value)\n        }\n      },\n      {\n        signal,\n        end\n      }\n    )\n  })\n}\nmodule.exports = {\n  finished,\n  pipeline\n}\n","module.exports = readdirGlob;\n\nconst fs = require('fs');\nconst { EventEmitter } = require('events');\nconst { Minimatch } = require('minimatch');\nconst { resolve } = require('path');\n\nfunction readdir(dir, strict) {\n  return new Promise((resolve, reject) => {\n    fs.readdir(dir, {withFileTypes: true} ,(err, files) => {\n      if(err) {\n        switch (err.code) {\n          case 'ENOTDIR':      // Not a directory\n            if(strict) {\n              reject(err);\n            } else {\n              resolve([]);\n            }\n            break;\n          case 'ENOTSUP':      // Operation not supported\n          case 'ENOENT':       // No such file or directory\n          case 'ENAMETOOLONG': // Filename too long\n          case 'UNKNOWN':\n            resolve([]);\n            break;\n          case 'ELOOP':        // Too many levels of symbolic links\n          default:\n            reject(err);\n            break;\n        }\n      } else {\n        resolve(files);\n      }\n    });\n  });\n}\nfunction stat(file, followSymlinks) {\n  return new Promise((resolve, reject) => {\n    const statFunc = followSymlinks ? fs.stat : fs.lstat;\n    statFunc(file, (err, stats) => {\n      if(err) {\n        switch (err.code) {\n          case 'ENOENT':\n            if(followSymlinks) {\n              // Fallback to lstat to handle broken links as files\n              resolve(stat(file, false)); \n            } else {\n              resolve(null);\n            }\n            break;\n          default:\n            resolve(null);\n            break;\n        }\n      } else {\n        resolve(stats);\n      }\n    });\n  });\n}\n\nasync function* exploreWalkAsync(dir, path, followSymlinks, useStat, shouldSkip, strict) {\n  let files = await readdir(path + dir, strict);\n  for(const file of files) {\n    let name = file.name;\n    if(name === undefined) {\n      // undefined file.name means the `withFileTypes` options is not supported by node\n      // we have to call the stat function to know if file is directory or not.\n      name = file;\n      useStat = true;\n    }\n    const filename = dir + '/' + name;\n    const relative = filename.slice(1); // Remove the leading /\n    const absolute = path + '/' + relative;\n    let stats = null;\n    if(useStat || followSymlinks) {\n      stats = await stat(absolute, followSymlinks);\n    }\n    if(!stats && file.name !== undefined) {\n      stats = file;\n    }\n    if(stats === null) {\n      stats = { isDirectory: () => false };\n    }\n\n    if(stats.isDirectory()) {\n      if(!shouldSkip(relative)) {\n        yield {relative, absolute, stats};\n        yield* exploreWalkAsync(filename, path, followSymlinks, useStat, shouldSkip, false);\n      }\n    } else {\n      yield {relative, absolute, stats};\n    }\n  }\n}\nasync function* explore(path, followSymlinks, useStat, shouldSkip) {\n  yield* exploreWalkAsync('', path, followSymlinks, useStat, shouldSkip, true);\n}\n\n\nfunction readOptions(options) {\n  return {\n    pattern: options.pattern,\n    dot: !!options.dot,\n    noglobstar: !!options.noglobstar,\n    matchBase: !!options.matchBase,\n    nocase: !!options.nocase,\n    ignore: options.ignore,\n    skip: options.skip,\n\n    follow: !!options.follow,\n    stat: !!options.stat,\n    nodir: !!options.nodir,\n    mark: !!options.mark,\n    silent: !!options.silent,\n    absolute: !!options.absolute\n  };\n}\n\nclass ReaddirGlob extends EventEmitter {\n  constructor(cwd, options, cb) {\n    super();\n    if(typeof options === 'function') {\n      cb = options;\n      options = null;\n    }\n\n    this.options = readOptions(options ||{});\n  \n    this.matchers = [];\n    if(this.options.pattern) {\n      const matchers = Array.isArray(this.options.pattern) ? this.options.pattern : [this.options.pattern];\n      this.matchers = matchers.map( m =>\n        new Minimatch(m, {\n          dot: this.options.dot,\n          noglobstar:this.options.noglobstar,\n          matchBase:this.options.matchBase,\n          nocase:this.options.nocase\n        })\n      );\n    }\n  \n    this.ignoreMatchers = [];\n    if(this.options.ignore) {\n      const ignorePatterns = Array.isArray(this.options.ignore) ? this.options.ignore : [this.options.ignore];\n      this.ignoreMatchers = ignorePatterns.map( ignore =>\n        new Minimatch(ignore, {dot: true})\n      );\n    }\n  \n    this.skipMatchers = [];\n    if(this.options.skip) {\n      const skipPatterns = Array.isArray(this.options.skip) ? this.options.skip : [this.options.skip];\n      this.skipMatchers = skipPatterns.map( skip =>\n        new Minimatch(skip, {dot: true})\n      );\n    }\n\n    this.iterator = explore(resolve(cwd || '.'), this.options.follow, this.options.stat, this._shouldSkipDirectory.bind(this));\n    this.paused = false;\n    this.inactive = false;\n    this.aborted = false;\n  \n    if(cb) {\n      this._matches = []; \n      this.on('match', match => this._matches.push(this.options.absolute ? match.absolute : match.relative));\n      this.on('error', err => cb(err));\n      this.on('end', () => cb(null, this._matches));\n    }\n\n    setTimeout( () => this._next(), 0);\n  }\n\n  _shouldSkipDirectory(relative) {\n    //console.log(relative, this.skipMatchers.some(m => m.match(relative)));\n    return this.skipMatchers.some(m => m.match(relative));\n  }\n\n  _fileMatches(relative, isDirectory) {\n    const file = relative + (isDirectory ? '/' : '');\n    return (this.matchers.length === 0 || this.matchers.some(m => m.match(file)))\n      && !this.ignoreMatchers.some(m => m.match(file))\n      && (!this.options.nodir || !isDirectory);\n  }\n\n  _next() {\n    if(!this.paused && !this.aborted) {\n      this.iterator.next()\n      .then((obj)=> {\n        if(!obj.done) {\n          const isDirectory = obj.value.stats.isDirectory();\n          if(this._fileMatches(obj.value.relative, isDirectory )) {\n            let relative = obj.value.relative;\n            let absolute = obj.value.absolute;\n            if(this.options.mark && isDirectory) {\n              relative += '/';\n              absolute += '/';\n            }\n            if(this.options.stat) {\n              this.emit('match', {relative, absolute, stat:obj.value.stats});\n            } else {\n              this.emit('match', {relative, absolute});\n            }\n          }\n          this._next(this.iterator);\n        } else {\n          this.emit('end');\n        }\n      })\n      .catch((err) => {\n        this.abort();\n        this.emit('error', err);\n        if(!err.code && !this.options.silent) {\n          console.error(err);\n        }\n      });\n    } else {\n      this.inactive = true;\n    }\n  }\n\n  abort() {\n    this.aborted = true;\n  }\n\n  pause() {\n    this.paused = true;\n  }\n\n  resume() {\n    this.paused = false;\n    if(this.inactive) {\n      this.inactive = false;\n      this._next();\n    }\n  }\n}\n\n\nfunction readdirGlob(pattern, options, cb) {\n  return new ReaddirGlob(pattern, options, cb);\n}\nreaddirGlob.ReaddirGlob = ReaddirGlob;","const isWindows = typeof process === 'object' &&\n  process &&\n  process.platform === 'win32'\nmodule.exports = isWindows ? { sep: '\\\\' } : { sep: '/' }\n","const minimatch = module.exports = (p, pattern, options = {}) => {\n  assertValidPattern(pattern)\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  return new Minimatch(pattern, options).match(p)\n}\n\nmodule.exports = minimatch\n\nconst path = require('./lib/path.js')\nminimatch.sep = path.sep\n\nconst GLOBSTAR = Symbol('globstar **')\nminimatch.GLOBSTAR = GLOBSTAR\nconst expand = require('brace-expansion')\n\nconst plTypes = {\n  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},\n  '?': { open: '(?:', close: ')?' },\n  '+': { open: '(?:', close: ')+' },\n  '*': { open: '(?:', close: ')*' },\n  '@': { open: '(?:', close: ')' }\n}\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nconst qmark = '[^/]'\n\n// * => any number of characters\nconst star = qmark + '*?'\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nconst twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?'\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nconst twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?'\n\n// \"abc\" -> { a:true, b:true, c:true }\nconst charSet = s => s.split('').reduce((set, c) => {\n  set[c] = true\n  return set\n}, {})\n\n// characters that need to be escaped in RegExp.\nconst reSpecials = charSet('().*{}+?[]^$\\\\!')\n\n// characters that indicate we have to add the pattern start\nconst addPatternStartSet = charSet('[.(')\n\n// normalizes slashes.\nconst slashSplit = /\\/+/\n\nminimatch.filter = (pattern, options = {}) =>\n  (p, i, list) => minimatch(p, pattern, options)\n\nconst ext = (a, b = {}) => {\n  const t = {}\n  Object.keys(a).forEach(k => t[k] = a[k])\n  Object.keys(b).forEach(k => t[k] = b[k])\n  return t\n}\n\nminimatch.defaults = def => {\n  if (!def || typeof def !== 'object' || !Object.keys(def).length) {\n    return minimatch\n  }\n\n  const orig = minimatch\n\n  const m = (p, pattern, options) => orig(p, pattern, ext(def, options))\n  m.Minimatch = class Minimatch extends orig.Minimatch {\n    constructor (pattern, options) {\n      super(pattern, ext(def, options))\n    }\n  }\n  m.Minimatch.defaults = options => orig.defaults(ext(def, options)).Minimatch\n  m.filter = (pattern, options) => orig.filter(pattern, ext(def, options))\n  m.defaults = options => orig.defaults(ext(def, options))\n  m.makeRe = (pattern, options) => orig.makeRe(pattern, ext(def, options))\n  m.braceExpand = (pattern, options) => orig.braceExpand(pattern, ext(def, options))\n  m.match = (list, pattern, options) => orig.match(list, pattern, ext(def, options))\n\n  return m\n}\n\n\n\n\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nminimatch.braceExpand = (pattern, options) => braceExpand(pattern, options)\n\nconst braceExpand = (pattern, options = {}) => {\n  assertValidPattern(pattern)\n\n  // Thanks to Yeting Li <https://github.com/yetingli> for\n  // improving this regexp to avoid a ReDOS vulnerability.\n  if (options.nobrace || !/\\{(?:(?!\\{).)*\\}/.test(pattern)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand(pattern)\n}\n\nconst MAX_PATTERN_LENGTH = 1024 * 64\nconst assertValidPattern = pattern => {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('invalid pattern')\n  }\n\n  if (pattern.length > MAX_PATTERN_LENGTH) {\n    throw new TypeError('pattern is too long')\n  }\n}\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nconst SUBPARSE = Symbol('subparse')\n\nminimatch.makeRe = (pattern, options) =>\n  new Minimatch(pattern, options || {}).makeRe()\n\nminimatch.match = (list, pattern, options = {}) => {\n  const mm = new Minimatch(pattern, options)\n  list = list.filter(f => mm.match(f))\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern)\n  }\n  return list\n}\n\n// replace stuff like \\* with *\nconst globUnescape = s => s.replace(/\\\\(.)/g, '$1')\nconst charUnescape = s => s.replace(/\\\\([^-\\]])/g, '$1')\nconst regExpEscape = s => s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\nconst braExpEscape = s => s.replace(/[[\\]\\\\]/g, '\\\\$&')\n\nclass Minimatch {\n  constructor (pattern, options) {\n    assertValidPattern(pattern)\n\n    if (!options) options = {}\n\n    this.options = options\n    this.set = []\n    this.pattern = pattern\n    this.windowsPathsNoEscape = !!options.windowsPathsNoEscape ||\n      options.allowWindowsEscape === false\n    if (this.windowsPathsNoEscape) {\n      this.pattern = this.pattern.replace(/\\\\/g, '/')\n    }\n    this.regexp = null\n    this.negate = false\n    this.comment = false\n    this.empty = false\n    this.partial = !!options.partial\n\n    // make the set of regexps etc.\n    this.make()\n  }\n\n  debug () {}\n\n  make () {\n    const pattern = this.pattern\n    const options = this.options\n\n    // empty patterns and comments match nothing.\n    if (!options.nocomment && pattern.charAt(0) === '#') {\n      this.comment = true\n      return\n    }\n    if (!pattern) {\n      this.empty = true\n      return\n    }\n\n    // step 1: figure out negation, etc.\n    this.parseNegate()\n\n    // step 2: expand braces\n    let set = this.globSet = this.braceExpand()\n\n    if (options.debug) this.debug = (...args) => console.error(...args)\n\n    this.debug(this.pattern, set)\n\n    // step 3: now we have a set, so turn each one into a series of path-portion\n    // matching patterns.\n    // These will be regexps, except in the case of \"**\", which is\n    // set to the GLOBSTAR object for globstar behavior,\n    // and will not contain any / characters\n    set = this.globParts = set.map(s => s.split(slashSplit))\n\n    this.debug(this.pattern, set)\n\n    // glob --> regexps\n    set = set.map((s, si, set) => s.map(this.parse, this))\n\n    this.debug(this.pattern, set)\n\n    // filter out everything that didn't compile properly.\n    set = set.filter(s => s.indexOf(false) === -1)\n\n    this.debug(this.pattern, set)\n\n    this.set = set\n  }\n\n  parseNegate () {\n    if (this.options.nonegate) return\n\n    const pattern = this.pattern\n    let negate = false\n    let negateOffset = 0\n\n    for (let i = 0; i < pattern.length && pattern.charAt(i) === '!'; i++) {\n      negate = !negate\n      negateOffset++\n    }\n\n    if (negateOffset) this.pattern = pattern.slice(negateOffset)\n    this.negate = negate\n  }\n\n  // set partial to true to test if, for example,\n  // \"/a/b\" matches the start of \"/*/b/*/d\"\n  // Partial means, if you run out of file before you run\n  // out of pattern, then that's fine, as long as all\n  // the parts match.\n  matchOne (file, pattern, partial) {\n    var options = this.options\n\n    this.debug('matchOne',\n      { 'this': this, file: file, pattern: pattern })\n\n    this.debug('matchOne', file.length, pattern.length)\n\n    for (var fi = 0,\n        pi = 0,\n        fl = file.length,\n        pl = pattern.length\n        ; (fi < fl) && (pi < pl)\n        ; fi++, pi++) {\n      this.debug('matchOne loop')\n      var p = pattern[pi]\n      var f = file[fi]\n\n      this.debug(pattern, p, f)\n\n      // should be impossible.\n      // some invalid regexp stuff in the set.\n      /* istanbul ignore if */\n      if (p === false) return false\n\n      if (p === GLOBSTAR) {\n        this.debug('GLOBSTAR', [pattern, p, f])\n\n        // \"**\"\n        // a/**/b/**/c would match the following:\n        // a/b/x/y/z/c\n        // a/x/y/z/b/c\n        // a/b/x/b/x/c\n        // a/b/c\n        // To do this, take the rest of the pattern after\n        // the **, and see if it would match the file remainder.\n        // If so, return success.\n        // If not, the ** \"swallows\" a segment, and try again.\n        // This is recursively awful.\n        //\n        // a/**/b/**/c matching a/b/x/y/z/c\n        // - a matches a\n        // - doublestar\n        //   - matchOne(b/x/y/z/c, b/**/c)\n        //     - b matches b\n        //     - doublestar\n        //       - matchOne(x/y/z/c, c) -> no\n        //       - matchOne(y/z/c, c) -> no\n        //       - matchOne(z/c, c) -> no\n        //       - matchOne(c, c) yes, hit\n        var fr = fi\n        var pr = pi + 1\n        if (pr === pl) {\n          this.debug('** at the end')\n          // a ** at the end will just swallow the rest.\n          // We have found a match.\n          // however, it will not swallow /.x, unless\n          // options.dot is set.\n          // . and .. are *never* matched by **, for explosively\n          // exponential reasons.\n          for (; fi < fl; fi++) {\n            if (file[fi] === '.' || file[fi] === '..' ||\n              (!options.dot && file[fi].charAt(0) === '.')) return false\n          }\n          return true\n        }\n\n        // ok, let's see if we can swallow whatever we can.\n        while (fr < fl) {\n          var swallowee = file[fr]\n\n          this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee)\n\n          // XXX remove this slice.  Just pass the start index.\n          if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n            this.debug('globstar found match!', fr, fl, swallowee)\n            // found a match.\n            return true\n          } else {\n            // can't swallow \".\" or \"..\" ever.\n            // can only swallow \".foo\" when explicitly asked.\n            if (swallowee === '.' || swallowee === '..' ||\n              (!options.dot && swallowee.charAt(0) === '.')) {\n              this.debug('dot detected!', file, fr, pattern, pr)\n              break\n            }\n\n            // ** swallows a segment, and continue.\n            this.debug('globstar swallow a segment, and continue')\n            fr++\n          }\n        }\n\n        // no match was found.\n        // However, in partial mode, we can't say this is necessarily over.\n        // If there's more *pattern* left, then\n        /* istanbul ignore if */\n        if (partial) {\n          // ran out of file\n          this.debug('\\n>>> no match, partial?', file, fr, pattern, pr)\n          if (fr === fl) return true\n        }\n        return false\n      }\n\n      // something other than **\n      // non-magic patterns just have to match exactly\n      // patterns with magic have been turned into regexps.\n      var hit\n      if (typeof p === 'string') {\n        hit = f === p\n        this.debug('string match', p, f, hit)\n      } else {\n        hit = f.match(p)\n        this.debug('pattern match', p, f, hit)\n      }\n\n      if (!hit) return false\n    }\n\n    // Note: ending in / means that we'll get a final \"\"\n    // at the end of the pattern.  This can only match a\n    // corresponding \"\" at the end of the file.\n    // If the file ends in /, then it can only match a\n    // a pattern that ends in /, unless the pattern just\n    // doesn't have any more for it. But, a/b/ should *not*\n    // match \"a/b/*\", even though \"\" matches against the\n    // [^/]*? pattern, except in partial mode, where it might\n    // simply not be reached yet.\n    // However, a/b/ should still satisfy a/*\n\n    // now either we fell off the end of the pattern, or we're done.\n    if (fi === fl && pi === pl) {\n      // ran out of pattern and filename at the same time.\n      // an exact hit!\n      return true\n    } else if (fi === fl) {\n      // ran out of file, but still had pattern left.\n      // this is ok if we're doing the match as part of\n      // a glob fs traversal.\n      return partial\n    } else /* istanbul ignore else */ if (pi === pl) {\n      // ran out of pattern, still have file left.\n      // this is only acceptable if we're on the very last\n      // empty segment of a file with a trailing slash.\n      // a/* should match a/b/\n      return (fi === fl - 1) && (file[fi] === '')\n    }\n\n    // should be unreachable.\n    /* istanbul ignore next */\n    throw new Error('wtf?')\n  }\n\n  braceExpand () {\n    return braceExpand(this.pattern, this.options)\n  }\n\n  parse (pattern, isSub) {\n    assertValidPattern(pattern)\n\n    const options = this.options\n\n    // shortcuts\n    if (pattern === '**') {\n      if (!options.noglobstar)\n        return GLOBSTAR\n      else\n        pattern = '*'\n    }\n    if (pattern === '') return ''\n\n    let re = ''\n    let hasMagic = false\n    let escaping = false\n    // ? => one single character\n    const patternListStack = []\n    const negativeLists = []\n    let stateChar\n    let inClass = false\n    let reClassStart = -1\n    let classStart = -1\n    let cs\n    let pl\n    let sp\n    // . and .. never match anything that doesn't start with .,\n    // even when options.dot is set.  However, if the pattern\n    // starts with ., then traversal patterns can match.\n    let dotTravAllowed = pattern.charAt(0) === '.'\n    let dotFileAllowed = options.dot || dotTravAllowed\n    const patternStart = () =>\n      dotTravAllowed\n        ? ''\n        : dotFileAllowed\n        ? '(?!(?:^|\\\\/)\\\\.{1,2}(?:$|\\\\/))'\n        : '(?!\\\\.)'\n    const subPatternStart = (p) =>\n      p.charAt(0) === '.'\n        ? ''\n        : options.dot\n        ? '(?!(?:^|\\\\/)\\\\.{1,2}(?:$|\\\\/))'\n        : '(?!\\\\.)'\n\n\n    const clearStateChar = () => {\n      if (stateChar) {\n        // we had some state-tracking character\n        // that wasn't consumed by this pass.\n        switch (stateChar) {\n          case '*':\n            re += star\n            hasMagic = true\n          break\n          case '?':\n            re += qmark\n            hasMagic = true\n          break\n          default:\n            re += '\\\\' + stateChar\n          break\n        }\n        this.debug('clearStateChar %j %j', stateChar, re)\n        stateChar = false\n      }\n    }\n\n    for (let i = 0, c; (i < pattern.length) && (c = pattern.charAt(i)); i++) {\n      this.debug('%s\\t%s %s %j', pattern, i, re, c)\n\n      // skip over any that are escaped.\n      if (escaping) {\n        /* istanbul ignore next - completely not allowed, even escaped. */\n        if (c === '/') {\n          return false\n        }\n\n        if (reSpecials[c]) {\n          re += '\\\\'\n        }\n        re += c\n        escaping = false\n        continue\n      }\n\n      switch (c) {\n        /* istanbul ignore next */\n        case '/': {\n          // Should already be path-split by now.\n          return false\n        }\n\n        case '\\\\':\n          if (inClass && pattern.charAt(i + 1) === '-') {\n            re += c\n            continue\n          }\n\n          clearStateChar()\n          escaping = true\n        continue\n\n        // the various stateChar values\n        // for the \"extglob\" stuff.\n        case '?':\n        case '*':\n        case '+':\n        case '@':\n        case '!':\n          this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c)\n\n          // all of those are literals inside a class, except that\n          // the glob [!a] means [^a] in regexp\n          if (inClass) {\n            this.debug('  in class')\n            if (c === '!' && i === classStart + 1) c = '^'\n            re += c\n            continue\n          }\n\n          // if we already have a stateChar, then it means\n          // that there was something like ** or +? in there.\n          // Handle the stateChar, then proceed with this one.\n          this.debug('call clearStateChar %j', stateChar)\n          clearStateChar()\n          stateChar = c\n          // if extglob is disabled, then +(asdf|foo) isn't a thing.\n          // just clear the statechar *now*, rather than even diving into\n          // the patternList stuff.\n          if (options.noext) clearStateChar()\n        continue\n\n        case '(': {\n          if (inClass) {\n            re += '('\n            continue\n          }\n\n          if (!stateChar) {\n            re += '\\\\('\n            continue\n          }\n\n          const plEntry = {\n            type: stateChar,\n            start: i - 1,\n            reStart: re.length,\n            open: plTypes[stateChar].open,\n            close: plTypes[stateChar].close,\n          }\n          this.debug(this.pattern, '\\t', plEntry)\n          patternListStack.push(plEntry)\n          // negation is (?:(?!(?:js)(?:<rest>))[^/]*)\n          re += plEntry.open\n          // next entry starts with a dot maybe?\n          if (plEntry.start === 0 && plEntry.type !== '!') {\n            dotTravAllowed = true\n            re += subPatternStart(pattern.slice(i + 1))\n          }\n          this.debug('plType %j %j', stateChar, re)\n          stateChar = false\n          continue\n        }\n\n        case ')': {\n          const plEntry = patternListStack[patternListStack.length - 1]\n          if (inClass || !plEntry) {\n            re += '\\\\)'\n            continue\n          }\n          patternListStack.pop()\n\n          // closing an extglob\n          clearStateChar()\n          hasMagic = true\n          pl = plEntry\n          // negation is (?:(?!js)[^/]*)\n          // The others are (?:<pattern>)<type>\n          re += pl.close\n          if (pl.type === '!') {\n            negativeLists.push(Object.assign(pl, { reEnd: re.length }))\n          }\n          continue\n        }\n\n        case '|': {\n          const plEntry = patternListStack[patternListStack.length - 1]\n          if (inClass || !plEntry) {\n            re += '\\\\|'\n            continue\n          }\n\n          clearStateChar()\n          re += '|'\n          // next subpattern can start with a dot?\n          if (plEntry.start === 0 && plEntry.type !== '!') {\n            dotTravAllowed = true\n            re += subPatternStart(pattern.slice(i + 1))\n          }\n          continue\n        }\n\n        // these are mostly the same in regexp and glob\n        case '[':\n          // swallow any state-tracking char before the [\n          clearStateChar()\n\n          if (inClass) {\n            re += '\\\\' + c\n            continue\n          }\n\n          inClass = true\n          classStart = i\n          reClassStart = re.length\n          re += c\n        continue\n\n        case ']':\n          //  a right bracket shall lose its special\n          //  meaning and represent itself in\n          //  a bracket expression if it occurs\n          //  first in the list.  -- POSIX.2 2.8.3.2\n          if (i === classStart + 1 || !inClass) {\n            re += '\\\\' + c\n            continue\n          }\n\n          // split where the last [ was, make sure we don't have\n          // an invalid re. if so, re-walk the contents of the\n          // would-be class to re-translate any characters that\n          // were passed through as-is\n          // TODO: It would probably be faster to determine this\n          // without a try/catch and a new RegExp, but it's tricky\n          // to do safely.  For now, this is safe and works.\n          cs = pattern.substring(classStart + 1, i)\n          try {\n            RegExp('[' + braExpEscape(charUnescape(cs)) + ']')\n            // looks good, finish up the class.\n            re += c\n          } catch (er) {\n            // out of order ranges in JS are errors, but in glob syntax,\n            // they're just a range that matches nothing.\n            re = re.substring(0, reClassStart) + '(?:$.)' // match nothing ever\n          }\n          hasMagic = true\n          inClass = false\n        continue\n\n        default:\n          // swallow any state char that wasn't consumed\n          clearStateChar()\n\n          if (reSpecials[c] && !(c === '^' && inClass)) {\n            re += '\\\\'\n          }\n\n          re += c\n          break\n\n      } // switch\n    } // for\n\n    // handle the case where we left a class open.\n    // \"[abc\" is valid, equivalent to \"\\[abc\"\n    if (inClass) {\n      // split where the last [ was, and escape it\n      // this is a huge pita.  We now have to re-walk\n      // the contents of the would-be class to re-translate\n      // any characters that were passed through as-is\n      cs = pattern.slice(classStart + 1)\n      sp = this.parse(cs, SUBPARSE)\n      re = re.substring(0, reClassStart) + '\\\\[' + sp[0]\n      hasMagic = hasMagic || sp[1]\n    }\n\n    // handle the case where we had a +( thing at the *end*\n    // of the pattern.\n    // each pattern list stack adds 3 chars, and we need to go through\n    // and escape any | chars that were passed through as-is for the regexp.\n    // Go through and escape them, taking care not to double-escape any\n    // | chars that were already escaped.\n    for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n      let tail\n      tail = re.slice(pl.reStart + pl.open.length)\n      this.debug('setting tail', re, pl)\n      // maybe some even number of \\, then maybe 1 \\, followed by a |\n      tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, (_, $1, $2) => {\n        /* istanbul ignore else - should already be done */\n        if (!$2) {\n          // the | isn't already escaped, so escape it.\n          $2 = '\\\\'\n        }\n\n        // need to escape all those slashes *again*, without escaping the\n        // one that we need for escaping the | character.  As it works out,\n        // escaping an even number of slashes can be done by simply repeating\n        // it exactly after itself.  That's why this trick works.\n        //\n        // I am sorry that you have to see this.\n        return $1 + $1 + $2 + '|'\n      })\n\n      this.debug('tail=%j\\n   %s', tail, tail, pl, re)\n      const t = pl.type === '*' ? star\n        : pl.type === '?' ? qmark\n        : '\\\\' + pl.type\n\n      hasMagic = true\n      re = re.slice(0, pl.reStart) + t + '\\\\(' + tail\n    }\n\n    // handle trailing things that only matter at the very end.\n    clearStateChar()\n    if (escaping) {\n      // trailing \\\\\n      re += '\\\\\\\\'\n    }\n\n    // only need to apply the nodot start if the re starts with\n    // something that could conceivably capture a dot\n    const addPatternStart = addPatternStartSet[re.charAt(0)]\n\n    // Hack to work around lack of negative lookbehind in JS\n    // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n    // like 'a.xyz.yz' doesn't match.  So, the first negative\n    // lookahead, has to look ALL the way ahead, to the end of\n    // the pattern.\n    for (let n = negativeLists.length - 1; n > -1; n--) {\n      const nl = negativeLists[n]\n\n      const nlBefore = re.slice(0, nl.reStart)\n      const nlFirst = re.slice(nl.reStart, nl.reEnd - 8)\n      let nlAfter = re.slice(nl.reEnd)\n      const nlLast = re.slice(nl.reEnd - 8, nl.reEnd) + nlAfter\n\n      // Handle nested stuff like *(*.js|!(*.json)), where open parens\n      // mean that we should *not* include the ) in the bit that is considered\n      // \"after\" the negated section.\n      const closeParensBefore = nlBefore.split(')').length\n      const openParensBefore = nlBefore.split('(').length - closeParensBefore\n      let cleanAfter = nlAfter\n      for (let i = 0; i < openParensBefore; i++) {\n        cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '')\n      }\n      nlAfter = cleanAfter\n\n      const dollar = nlAfter === '' && isSub !== SUBPARSE ? '(?:$|\\\\/)' : ''\n\n      re = nlBefore + nlFirst + nlAfter + dollar + nlLast\n    }\n\n    // if the re is not \"\" at this point, then we need to make sure\n    // it doesn't match against an empty path part.\n    // Otherwise a/* will match a/, which it should not.\n    if (re !== '' && hasMagic) {\n      re = '(?=.)' + re\n    }\n\n    if (addPatternStart) {\n      re = patternStart() + re\n    }\n\n    // parsing just a piece of a larger pattern.\n    if (isSub === SUBPARSE) {\n      return [re, hasMagic]\n    }\n\n    // if it's nocase, and the lcase/uppercase don't match, it's magic\n    if (options.nocase && !hasMagic) {\n      hasMagic = pattern.toUpperCase() !== pattern.toLowerCase()\n    }\n\n    // skip the regexp for non-magical patterns\n    // unescape anything in it, though, so that it'll be\n    // an exact match against a file etc.\n    if (!hasMagic) {\n      return globUnescape(pattern)\n    }\n\n    const flags = options.nocase ? 'i' : ''\n    try {\n      return Object.assign(new RegExp('^' + re + '$', flags), {\n        _glob: pattern,\n        _src: re,\n      })\n    } catch (er) /* istanbul ignore next - should be impossible */ {\n      // If it was an invalid regular expression, then it can't match\n      // anything.  This trick looks for a character after the end of\n      // the string, which is of course impossible, except in multi-line\n      // mode, but it's not a /m regex.\n      return new RegExp('$.')\n    }\n  }\n\n  makeRe () {\n    if (this.regexp || this.regexp === false) return this.regexp\n\n    // at this point, this.set is a 2d array of partial\n    // pattern strings, or \"**\".\n    //\n    // It's better to use .match().  This function shouldn't\n    // be used, really, but it's pretty convenient sometimes,\n    // when you just want to work with a regex.\n    const set = this.set\n\n    if (!set.length) {\n      this.regexp = false\n      return this.regexp\n    }\n    const options = this.options\n\n    const twoStar = options.noglobstar ? star\n      : options.dot ? twoStarDot\n      : twoStarNoDot\n    const flags = options.nocase ? 'i' : ''\n\n    // coalesce globstars and regexpify non-globstar patterns\n    // if it's the only item, then we just do one twoStar\n    // if it's the first, and there are more, prepend (\\/|twoStar\\/)? to next\n    // if it's the last, append (\\/twoStar|) to previous\n    // if it's in the middle, append (\\/|\\/twoStar\\/) to previous\n    // then filter out GLOBSTAR symbols\n    let re = set.map(pattern => {\n      pattern = pattern.map(p =>\n        typeof p === 'string' ? regExpEscape(p)\n        : p === GLOBSTAR ? GLOBSTAR\n        : p._src\n      ).reduce((set, p) => {\n        if (!(set[set.length - 1] === GLOBSTAR && p === GLOBSTAR)) {\n          set.push(p)\n        }\n        return set\n      }, [])\n      pattern.forEach((p, i) => {\n        if (p !== GLOBSTAR || pattern[i-1] === GLOBSTAR) {\n          return\n        }\n        if (i === 0) {\n          if (pattern.length > 1) {\n            pattern[i+1] = '(?:\\\\\\/|' + twoStar + '\\\\\\/)?' + pattern[i+1]\n          } else {\n            pattern[i] = twoStar\n          }\n        } else if (i === pattern.length - 1) {\n          pattern[i-1] += '(?:\\\\\\/|' + twoStar + ')?'\n        } else {\n          pattern[i-1] += '(?:\\\\\\/|\\\\\\/' + twoStar + '\\\\\\/)' + pattern[i+1]\n          pattern[i+1] = GLOBSTAR\n        }\n      })\n      return pattern.filter(p => p !== GLOBSTAR).join('/')\n    }).join('|')\n\n    // must match entire pattern\n    // ending in a * or ** will make it less strict.\n    re = '^(?:' + re + ')$'\n\n    // can match anything, as long as it's not this.\n    if (this.negate) re = '^(?!' + re + ').*$'\n\n    try {\n      this.regexp = new RegExp(re, flags)\n    } catch (ex) /* istanbul ignore next - should be impossible */ {\n      this.regexp = false\n    }\n    return this.regexp\n  }\n\n  match (f, partial = this.partial) {\n    this.debug('match', f, this.pattern)\n    // short-circuit in the case of busted things.\n    // comments, etc.\n    if (this.comment) return false\n    if (this.empty) return f === ''\n\n    if (f === '/' && partial) return true\n\n    const options = this.options\n\n    // windows: need to use /, not \\\n    if (path.sep !== '/') {\n      f = f.split(path.sep).join('/')\n    }\n\n    // treat the test path as a set of pathparts.\n    f = f.split(slashSplit)\n    this.debug(this.pattern, 'split', f)\n\n    // just ONE of the pattern sets in this.set needs to match\n    // in order for it to be valid.  If negating, then just one\n    // match means that we have failed.\n    // Either way, return on the first hit.\n\n    const set = this.set\n    this.debug(this.pattern, 'set', set)\n\n    // Find the basename of the path by looking for the last non-empty segment\n    let filename\n    for (let i = f.length - 1; i >= 0; i--) {\n      filename = f[i]\n      if (filename) break\n    }\n\n    for (let i = 0; i < set.length; i++) {\n      const pattern = set[i]\n      let file = f\n      if (options.matchBase && pattern.length === 1) {\n        file = [filename]\n      }\n      const hit = this.matchOne(file, pattern, partial)\n      if (hit) {\n        if (options.flipNegate) return true\n        return !this.negate\n      }\n    }\n\n    // didn't get any hits.  this is success if it's a negative\n    // pattern, failure otherwise.\n    if (options.flipNegate) return false\n    return this.negate\n  }\n\n  static defaults (def) {\n    return minimatch.defaults(def).Minimatch\n  }\n}\n\nminimatch.Minimatch = Minimatch\n","/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n","const { EventEmitter } = require('events-universal')\nconst STREAM_DESTROYED = new Error('Stream was destroyed')\nconst PREMATURE_CLOSE = new Error('Premature close')\n\nconst FIFO = require('fast-fifo')\nconst TextDecoder = require('text-decoder')\n\n// if we do a future major, expect queue microtask to be there always, for now a bit defensive\nconst qmt = typeof queueMicrotask === 'undefined' ? fn => global.process.nextTick(fn) : queueMicrotask\n\n/* eslint-disable no-multi-spaces */\n\n// 29 bits used total (4 from shared, 14 from read, and 11 from write)\nconst MAX = ((1 << 29) - 1)\n\n// Shared state\nconst OPENING       = 0b0001\nconst PREDESTROYING = 0b0010\nconst DESTROYING    = 0b0100\nconst DESTROYED     = 0b1000\n\nconst NOT_OPENING = MAX ^ OPENING\nconst NOT_PREDESTROYING = MAX ^ PREDESTROYING\n\n// Read state (4 bit offset from shared state)\nconst READ_ACTIVE           = 0b00000000000001 << 4\nconst READ_UPDATING         = 0b00000000000010 << 4\nconst READ_PRIMARY          = 0b00000000000100 << 4\nconst READ_QUEUED           = 0b00000000001000 << 4\nconst READ_RESUMED          = 0b00000000010000 << 4\nconst READ_PIPE_DRAINED     = 0b00000000100000 << 4\nconst READ_ENDING           = 0b00000001000000 << 4\nconst READ_EMIT_DATA        = 0b00000010000000 << 4\nconst READ_EMIT_READABLE    = 0b00000100000000 << 4\nconst READ_EMITTED_READABLE = 0b00001000000000 << 4\nconst READ_DONE             = 0b00010000000000 << 4\nconst READ_NEXT_TICK        = 0b00100000000000 << 4\nconst READ_NEEDS_PUSH       = 0b01000000000000 << 4\nconst READ_READ_AHEAD       = 0b10000000000000 << 4\n\n// Combined read state\nconst READ_FLOWING = READ_RESUMED | READ_PIPE_DRAINED\nconst READ_ACTIVE_AND_NEEDS_PUSH = READ_ACTIVE | READ_NEEDS_PUSH\nconst READ_PRIMARY_AND_ACTIVE = READ_PRIMARY | READ_ACTIVE\nconst READ_EMIT_READABLE_AND_QUEUED = READ_EMIT_READABLE | READ_QUEUED\nconst READ_RESUMED_READ_AHEAD = READ_RESUMED | READ_READ_AHEAD\n\nconst READ_NOT_ACTIVE             = MAX ^ READ_ACTIVE\nconst READ_NON_PRIMARY            = MAX ^ READ_PRIMARY\nconst READ_NON_PRIMARY_AND_PUSHED = MAX ^ (READ_PRIMARY | READ_NEEDS_PUSH)\nconst READ_PUSHED                 = MAX ^ READ_NEEDS_PUSH\nconst READ_PAUSED                 = MAX ^ READ_RESUMED\nconst READ_NOT_QUEUED             = MAX ^ (READ_QUEUED | READ_EMITTED_READABLE)\nconst READ_NOT_ENDING             = MAX ^ READ_ENDING\nconst READ_PIPE_NOT_DRAINED       = MAX ^ READ_FLOWING\nconst READ_NOT_NEXT_TICK          = MAX ^ READ_NEXT_TICK\nconst READ_NOT_UPDATING           = MAX ^ READ_UPDATING\nconst READ_NO_READ_AHEAD          = MAX ^ READ_READ_AHEAD\nconst READ_PAUSED_NO_READ_AHEAD   = MAX ^ READ_RESUMED_READ_AHEAD\n\n// Write state (18 bit offset, 4 bit offset from shared state and 14 from read state)\nconst WRITE_ACTIVE     = 0b00000000001 << 18\nconst WRITE_UPDATING   = 0b00000000010 << 18\nconst WRITE_PRIMARY    = 0b00000000100 << 18\nconst WRITE_QUEUED     = 0b00000001000 << 18\nconst WRITE_UNDRAINED  = 0b00000010000 << 18\nconst WRITE_DONE       = 0b00000100000 << 18\nconst WRITE_EMIT_DRAIN = 0b00001000000 << 18\nconst WRITE_NEXT_TICK  = 0b00010000000 << 18\nconst WRITE_WRITING    = 0b00100000000 << 18\nconst WRITE_FINISHING  = 0b01000000000 << 18\nconst WRITE_CORKED     = 0b10000000000 << 18\n\nconst WRITE_NOT_ACTIVE    = MAX ^ (WRITE_ACTIVE | WRITE_WRITING)\nconst WRITE_NON_PRIMARY   = MAX ^ WRITE_PRIMARY\nconst WRITE_NOT_FINISHING = MAX ^ (WRITE_ACTIVE | WRITE_FINISHING)\nconst WRITE_DRAINED       = MAX ^ WRITE_UNDRAINED\nconst WRITE_NOT_QUEUED    = MAX ^ WRITE_QUEUED\nconst WRITE_NOT_NEXT_TICK = MAX ^ WRITE_NEXT_TICK\nconst WRITE_NOT_UPDATING  = MAX ^ WRITE_UPDATING\nconst WRITE_NOT_CORKED    = MAX ^ WRITE_CORKED\n\n// Combined shared state\nconst ACTIVE = READ_ACTIVE | WRITE_ACTIVE\nconst NOT_ACTIVE = MAX ^ ACTIVE\nconst DONE = READ_DONE | WRITE_DONE\nconst DESTROY_STATUS = DESTROYING | DESTROYED | PREDESTROYING\nconst OPEN_STATUS = DESTROY_STATUS | OPENING\nconst AUTO_DESTROY = DESTROY_STATUS | DONE\nconst NON_PRIMARY = WRITE_NON_PRIMARY & READ_NON_PRIMARY\nconst ACTIVE_OR_TICKING = WRITE_NEXT_TICK | READ_NEXT_TICK\nconst TICKING = ACTIVE_OR_TICKING & NOT_ACTIVE\nconst IS_OPENING = OPEN_STATUS | TICKING\n\n// Combined shared state and read state\nconst READ_PRIMARY_STATUS = OPEN_STATUS | READ_ENDING | READ_DONE\nconst READ_STATUS = OPEN_STATUS | READ_DONE | READ_QUEUED\nconst READ_ENDING_STATUS = OPEN_STATUS | READ_ENDING | READ_QUEUED\nconst READ_READABLE_STATUS = OPEN_STATUS | READ_EMIT_READABLE | READ_QUEUED | READ_EMITTED_READABLE\nconst SHOULD_NOT_READ = OPEN_STATUS | READ_ACTIVE | READ_ENDING | READ_DONE | READ_NEEDS_PUSH | READ_READ_AHEAD\nconst READ_BACKPRESSURE_STATUS = DESTROY_STATUS | READ_ENDING | READ_DONE\nconst READ_UPDATE_SYNC_STATUS = READ_UPDATING | OPEN_STATUS | READ_NEXT_TICK | READ_PRIMARY\nconst READ_NEXT_TICK_OR_OPENING = READ_NEXT_TICK | OPENING\n\n// Combined write state\nconst WRITE_PRIMARY_STATUS = OPEN_STATUS | WRITE_FINISHING | WRITE_DONE\nconst WRITE_QUEUED_AND_UNDRAINED = WRITE_QUEUED | WRITE_UNDRAINED\nconst WRITE_QUEUED_AND_ACTIVE = WRITE_QUEUED | WRITE_ACTIVE\nconst WRITE_DRAIN_STATUS = WRITE_QUEUED | WRITE_UNDRAINED | OPEN_STATUS | WRITE_ACTIVE\nconst WRITE_STATUS = OPEN_STATUS | WRITE_ACTIVE | WRITE_QUEUED | WRITE_CORKED\nconst WRITE_PRIMARY_AND_ACTIVE = WRITE_PRIMARY | WRITE_ACTIVE\nconst WRITE_ACTIVE_AND_WRITING = WRITE_ACTIVE | WRITE_WRITING\nconst WRITE_FINISHING_STATUS = OPEN_STATUS | WRITE_FINISHING | WRITE_QUEUED_AND_ACTIVE | WRITE_DONE\nconst WRITE_BACKPRESSURE_STATUS = WRITE_UNDRAINED | DESTROY_STATUS | WRITE_FINISHING | WRITE_DONE\nconst WRITE_UPDATE_SYNC_STATUS = WRITE_UPDATING | OPEN_STATUS | WRITE_NEXT_TICK | WRITE_PRIMARY\nconst WRITE_DROP_DATA = WRITE_FINISHING | WRITE_DONE | DESTROY_STATUS\n\nconst asyncIterator = Symbol.asyncIterator || Symbol('asyncIterator')\n\nclass WritableState {\n  constructor (stream, { highWaterMark = 16384, map = null, mapWritable, byteLength, byteLengthWritable } = {}) {\n    this.stream = stream\n    this.queue = new FIFO()\n    this.highWaterMark = highWaterMark\n    this.buffered = 0\n    this.error = null\n    this.pipeline = null\n    this.drains = null // if we add more seldomly used helpers we might them into a subobject so its a single ptr\n    this.byteLength = byteLengthWritable || byteLength || defaultByteLength\n    this.map = mapWritable || map\n    this.afterWrite = afterWrite.bind(this)\n    this.afterUpdateNextTick = updateWriteNT.bind(this)\n  }\n\n  get ended () {\n    return (this.stream._duplexState & WRITE_DONE) !== 0\n  }\n\n  push (data) {\n    if ((this.stream._duplexState & WRITE_DROP_DATA) !== 0) return false\n    if (this.map !== null) data = this.map(data)\n\n    this.buffered += this.byteLength(data)\n    this.queue.push(data)\n\n    if (this.buffered < this.highWaterMark) {\n      this.stream._duplexState |= WRITE_QUEUED\n      return true\n    }\n\n    this.stream._duplexState |= WRITE_QUEUED_AND_UNDRAINED\n    return false\n  }\n\n  shift () {\n    const data = this.queue.shift()\n\n    this.buffered -= this.byteLength(data)\n    if (this.buffered === 0) this.stream._duplexState &= WRITE_NOT_QUEUED\n\n    return data\n  }\n\n  end (data) {\n    if (typeof data === 'function') this.stream.once('finish', data)\n    else if (data !== undefined && data !== null) this.push(data)\n    this.stream._duplexState = (this.stream._duplexState | WRITE_FINISHING) & WRITE_NON_PRIMARY\n  }\n\n  autoBatch (data, cb) {\n    const buffer = []\n    const stream = this.stream\n\n    buffer.push(data)\n    while ((stream._duplexState & WRITE_STATUS) === WRITE_QUEUED_AND_ACTIVE) {\n      buffer.push(stream._writableState.shift())\n    }\n\n    if ((stream._duplexState & OPEN_STATUS) !== 0) return cb(null)\n    stream._writev(buffer, cb)\n  }\n\n  update () {\n    const stream = this.stream\n\n    stream._duplexState |= WRITE_UPDATING\n\n    do {\n      while ((stream._duplexState & WRITE_STATUS) === WRITE_QUEUED) {\n        const data = this.shift()\n        stream._duplexState |= WRITE_ACTIVE_AND_WRITING\n        stream._write(data, this.afterWrite)\n      }\n\n      if ((stream._duplexState & WRITE_PRIMARY_AND_ACTIVE) === 0) this.updateNonPrimary()\n    } while (this.continueUpdate() === true)\n\n    stream._duplexState &= WRITE_NOT_UPDATING\n  }\n\n  updateNonPrimary () {\n    const stream = this.stream\n\n    if ((stream._duplexState & WRITE_FINISHING_STATUS) === WRITE_FINISHING) {\n      stream._duplexState = stream._duplexState | WRITE_ACTIVE\n      stream._final(afterFinal.bind(this))\n      return\n    }\n\n    if ((stream._duplexState & DESTROY_STATUS) === DESTROYING) {\n      if ((stream._duplexState & ACTIVE_OR_TICKING) === 0) {\n        stream._duplexState |= ACTIVE\n        stream._destroy(afterDestroy.bind(this))\n      }\n      return\n    }\n\n    if ((stream._duplexState & IS_OPENING) === OPENING) {\n      stream._duplexState = (stream._duplexState | ACTIVE) & NOT_OPENING\n      stream._open(afterOpen.bind(this))\n    }\n  }\n\n  continueUpdate () {\n    if ((this.stream._duplexState & WRITE_NEXT_TICK) === 0) return false\n    this.stream._duplexState &= WRITE_NOT_NEXT_TICK\n    return true\n  }\n\n  updateCallback () {\n    if ((this.stream._duplexState & WRITE_UPDATE_SYNC_STATUS) === WRITE_PRIMARY) this.update()\n    else this.updateNextTick()\n  }\n\n  updateNextTick () {\n    if ((this.stream._duplexState & WRITE_NEXT_TICK) !== 0) return\n    this.stream._duplexState |= WRITE_NEXT_TICK\n    if ((this.stream._duplexState & WRITE_UPDATING) === 0) qmt(this.afterUpdateNextTick)\n  }\n}\n\nclass ReadableState {\n  constructor (stream, { highWaterMark = 16384, map = null, mapReadable, byteLength, byteLengthReadable } = {}) {\n    this.stream = stream\n    this.queue = new FIFO()\n    this.highWaterMark = highWaterMark === 0 ? 1 : highWaterMark\n    this.buffered = 0\n    this.readAhead = highWaterMark > 0\n    this.error = null\n    this.pipeline = null\n    this.byteLength = byteLengthReadable || byteLength || defaultByteLength\n    this.map = mapReadable || map\n    this.pipeTo = null\n    this.afterRead = afterRead.bind(this)\n    this.afterUpdateNextTick = updateReadNT.bind(this)\n  }\n\n  get ended () {\n    return (this.stream._duplexState & READ_DONE) !== 0\n  }\n\n  pipe (pipeTo, cb) {\n    if (this.pipeTo !== null) throw new Error('Can only pipe to one destination')\n    if (typeof cb !== 'function') cb = null\n\n    this.stream._duplexState |= READ_PIPE_DRAINED\n    this.pipeTo = pipeTo\n    this.pipeline = new Pipeline(this.stream, pipeTo, cb)\n\n    if (cb) this.stream.on('error', noop) // We already error handle this so supress crashes\n\n    if (isStreamx(pipeTo)) {\n      pipeTo._writableState.pipeline = this.pipeline\n      if (cb) pipeTo.on('error', noop) // We already error handle this so supress crashes\n      pipeTo.on('finish', this.pipeline.finished.bind(this.pipeline)) // TODO: just call finished from pipeTo itself\n    } else {\n      const onerror = this.pipeline.done.bind(this.pipeline, pipeTo)\n      const onclose = this.pipeline.done.bind(this.pipeline, pipeTo, null) // onclose has a weird bool arg\n      pipeTo.on('error', onerror)\n      pipeTo.on('close', onclose)\n      pipeTo.on('finish', this.pipeline.finished.bind(this.pipeline))\n    }\n\n    pipeTo.on('drain', afterDrain.bind(this))\n    this.stream.emit('piping', pipeTo)\n    pipeTo.emit('pipe', this.stream)\n  }\n\n  push (data) {\n    const stream = this.stream\n\n    if (data === null) {\n      this.highWaterMark = 0\n      stream._duplexState = (stream._duplexState | READ_ENDING) & READ_NON_PRIMARY_AND_PUSHED\n      return false\n    }\n\n    if (this.map !== null) {\n      data = this.map(data)\n      if (data === null) {\n        stream._duplexState &= READ_PUSHED\n        return this.buffered < this.highWaterMark\n      }\n    }\n\n    this.buffered += this.byteLength(data)\n    this.queue.push(data)\n\n    stream._duplexState = (stream._duplexState | READ_QUEUED) & READ_PUSHED\n\n    return this.buffered < this.highWaterMark\n  }\n\n  shift () {\n    const data = this.queue.shift()\n\n    this.buffered -= this.byteLength(data)\n    if (this.buffered === 0) this.stream._duplexState &= READ_NOT_QUEUED\n    return data\n  }\n\n  unshift (data) {\n    const pending = [this.map !== null ? this.map(data) : data]\n    while (this.buffered > 0) pending.push(this.shift())\n\n    for (let i = 0; i < pending.length - 1; i++) {\n      const data = pending[i]\n      this.buffered += this.byteLength(data)\n      this.queue.push(data)\n    }\n\n    this.push(pending[pending.length - 1])\n  }\n\n  read () {\n    const stream = this.stream\n\n    if ((stream._duplexState & READ_STATUS) === READ_QUEUED) {\n      const data = this.shift()\n      if (this.pipeTo !== null && this.pipeTo.write(data) === false) stream._duplexState &= READ_PIPE_NOT_DRAINED\n      if ((stream._duplexState & READ_EMIT_DATA) !== 0) stream.emit('data', data)\n      return data\n    }\n\n    if (this.readAhead === false) {\n      stream._duplexState |= READ_READ_AHEAD\n      this.updateNextTick()\n    }\n\n    return null\n  }\n\n  drain () {\n    const stream = this.stream\n\n    while ((stream._duplexState & READ_STATUS) === READ_QUEUED && (stream._duplexState & READ_FLOWING) !== 0) {\n      const data = this.shift()\n      if (this.pipeTo !== null && this.pipeTo.write(data) === false) stream._duplexState &= READ_PIPE_NOT_DRAINED\n      if ((stream._duplexState & READ_EMIT_DATA) !== 0) stream.emit('data', data)\n    }\n  }\n\n  update () {\n    const stream = this.stream\n\n    stream._duplexState |= READ_UPDATING\n\n    do {\n      this.drain()\n\n      while (this.buffered < this.highWaterMark && (stream._duplexState & SHOULD_NOT_READ) === READ_READ_AHEAD) {\n        stream._duplexState |= READ_ACTIVE_AND_NEEDS_PUSH\n        stream._read(this.afterRead)\n        this.drain()\n      }\n\n      if ((stream._duplexState & READ_READABLE_STATUS) === READ_EMIT_READABLE_AND_QUEUED) {\n        stream._duplexState |= READ_EMITTED_READABLE\n        stream.emit('readable')\n      }\n\n      if ((stream._duplexState & READ_PRIMARY_AND_ACTIVE) === 0) this.updateNonPrimary()\n    } while (this.continueUpdate() === true)\n\n    stream._duplexState &= READ_NOT_UPDATING\n  }\n\n  updateNonPrimary () {\n    const stream = this.stream\n\n    if ((stream._duplexState & READ_ENDING_STATUS) === READ_ENDING) {\n      stream._duplexState = (stream._duplexState | READ_DONE) & READ_NOT_ENDING\n      stream.emit('end')\n      if ((stream._duplexState & AUTO_DESTROY) === DONE) stream._duplexState |= DESTROYING\n      if (this.pipeTo !== null) this.pipeTo.end()\n    }\n\n    if ((stream._duplexState & DESTROY_STATUS) === DESTROYING) {\n      if ((stream._duplexState & ACTIVE_OR_TICKING) === 0) {\n        stream._duplexState |= ACTIVE\n        stream._destroy(afterDestroy.bind(this))\n      }\n      return\n    }\n\n    if ((stream._duplexState & IS_OPENING) === OPENING) {\n      stream._duplexState = (stream._duplexState | ACTIVE) & NOT_OPENING\n      stream._open(afterOpen.bind(this))\n    }\n  }\n\n  continueUpdate () {\n    if ((this.stream._duplexState & READ_NEXT_TICK) === 0) return false\n    this.stream._duplexState &= READ_NOT_NEXT_TICK\n    return true\n  }\n\n  updateCallback () {\n    if ((this.stream._duplexState & READ_UPDATE_SYNC_STATUS) === READ_PRIMARY) this.update()\n    else this.updateNextTick()\n  }\n\n  updateNextTickIfOpen () {\n    if ((this.stream._duplexState & READ_NEXT_TICK_OR_OPENING) !== 0) return\n    this.stream._duplexState |= READ_NEXT_TICK\n    if ((this.stream._duplexState & READ_UPDATING) === 0) qmt(this.afterUpdateNextTick)\n  }\n\n  updateNextTick () {\n    if ((this.stream._duplexState & READ_NEXT_TICK) !== 0) return\n    this.stream._duplexState |= READ_NEXT_TICK\n    if ((this.stream._duplexState & READ_UPDATING) === 0) qmt(this.afterUpdateNextTick)\n  }\n}\n\nclass TransformState {\n  constructor (stream) {\n    this.data = null\n    this.afterTransform = afterTransform.bind(stream)\n    this.afterFinal = null\n  }\n}\n\nclass Pipeline {\n  constructor (src, dst, cb) {\n    this.from = src\n    this.to = dst\n    this.afterPipe = cb\n    this.error = null\n    this.pipeToFinished = false\n  }\n\n  finished () {\n    this.pipeToFinished = true\n  }\n\n  done (stream, err) {\n    if (err) this.error = err\n\n    if (stream === this.to) {\n      this.to = null\n\n      if (this.from !== null) {\n        if ((this.from._duplexState & READ_DONE) === 0 || !this.pipeToFinished) {\n          this.from.destroy(this.error || new Error('Writable stream closed prematurely'))\n        }\n        return\n      }\n    }\n\n    if (stream === this.from) {\n      this.from = null\n\n      if (this.to !== null) {\n        if ((stream._duplexState & READ_DONE) === 0) {\n          this.to.destroy(this.error || new Error('Readable stream closed before ending'))\n        }\n        return\n      }\n    }\n\n    if (this.afterPipe !== null) this.afterPipe(this.error)\n    this.to = this.from = this.afterPipe = null\n  }\n}\n\nfunction afterDrain () {\n  this.stream._duplexState |= READ_PIPE_DRAINED\n  this.updateCallback()\n}\n\nfunction afterFinal (err) {\n  const stream = this.stream\n  if (err) stream.destroy(err)\n  if ((stream._duplexState & DESTROY_STATUS) === 0) {\n    stream._duplexState |= WRITE_DONE\n    stream.emit('finish')\n  }\n  if ((stream._duplexState & AUTO_DESTROY) === DONE) {\n    stream._duplexState |= DESTROYING\n  }\n\n  stream._duplexState &= WRITE_NOT_FINISHING\n\n  // no need to wait the extra tick here, so we short circuit that\n  if ((stream._duplexState & WRITE_UPDATING) === 0) this.update()\n  else this.updateNextTick()\n}\n\nfunction afterDestroy (err) {\n  const stream = this.stream\n\n  if (!err && this.error !== STREAM_DESTROYED) err = this.error\n  if (err) stream.emit('error', err)\n  stream._duplexState |= DESTROYED\n  stream.emit('close')\n\n  const rs = stream._readableState\n  const ws = stream._writableState\n\n  if (rs !== null && rs.pipeline !== null) rs.pipeline.done(stream, err)\n\n  if (ws !== null) {\n    while (ws.drains !== null && ws.drains.length > 0) ws.drains.shift().resolve(false)\n    if (ws.pipeline !== null) ws.pipeline.done(stream, err)\n  }\n}\n\nfunction afterWrite (err) {\n  const stream = this.stream\n\n  if (err) stream.destroy(err)\n  stream._duplexState &= WRITE_NOT_ACTIVE\n\n  if (this.drains !== null) tickDrains(this.drains)\n\n  if ((stream._duplexState & WRITE_DRAIN_STATUS) === WRITE_UNDRAINED) {\n    stream._duplexState &= WRITE_DRAINED\n    if ((stream._duplexState & WRITE_EMIT_DRAIN) === WRITE_EMIT_DRAIN) {\n      stream.emit('drain')\n    }\n  }\n\n  this.updateCallback()\n}\n\nfunction afterRead (err) {\n  if (err) this.stream.destroy(err)\n  this.stream._duplexState &= READ_NOT_ACTIVE\n  if (this.readAhead === false && (this.stream._duplexState & READ_RESUMED) === 0) this.stream._duplexState &= READ_NO_READ_AHEAD\n  this.updateCallback()\n}\n\nfunction updateReadNT () {\n  if ((this.stream._duplexState & READ_UPDATING) === 0) {\n    this.stream._duplexState &= READ_NOT_NEXT_TICK\n    this.update()\n  }\n}\n\nfunction updateWriteNT () {\n  if ((this.stream._duplexState & WRITE_UPDATING) === 0) {\n    this.stream._duplexState &= WRITE_NOT_NEXT_TICK\n    this.update()\n  }\n}\n\nfunction tickDrains (drains) {\n  for (let i = 0; i < drains.length; i++) {\n    // drains.writes are monotonic, so if one is 0 its always the first one\n    if (--drains[i].writes === 0) {\n      drains.shift().resolve(true)\n      i--\n    }\n  }\n}\n\nfunction afterOpen (err) {\n  const stream = this.stream\n\n  if (err) stream.destroy(err)\n\n  if ((stream._duplexState & DESTROYING) === 0) {\n    if ((stream._duplexState & READ_PRIMARY_STATUS) === 0) stream._duplexState |= READ_PRIMARY\n    if ((stream._duplexState & WRITE_PRIMARY_STATUS) === 0) stream._duplexState |= WRITE_PRIMARY\n    stream.emit('open')\n  }\n\n  stream._duplexState &= NOT_ACTIVE\n\n  if (stream._writableState !== null) {\n    stream._writableState.updateCallback()\n  }\n\n  if (stream._readableState !== null) {\n    stream._readableState.updateCallback()\n  }\n}\n\nfunction afterTransform (err, data) {\n  if (data !== undefined && data !== null) this.push(data)\n  this._writableState.afterWrite(err)\n}\n\nfunction newListener (name) {\n  if (this._readableState !== null) {\n    if (name === 'data') {\n      this._duplexState |= (READ_EMIT_DATA | READ_RESUMED_READ_AHEAD)\n      this._readableState.updateNextTick()\n    }\n    if (name === 'readable') {\n      this._duplexState |= READ_EMIT_READABLE\n      this._readableState.updateNextTick()\n    }\n  }\n\n  if (this._writableState !== null) {\n    if (name === 'drain') {\n      this._duplexState |= WRITE_EMIT_DRAIN\n      this._writableState.updateNextTick()\n    }\n  }\n}\n\nclass Stream extends EventEmitter {\n  constructor (opts) {\n    super()\n\n    this._duplexState = 0\n    this._readableState = null\n    this._writableState = null\n\n    if (opts) {\n      if (opts.open) this._open = opts.open\n      if (opts.destroy) this._destroy = opts.destroy\n      if (opts.predestroy) this._predestroy = opts.predestroy\n      if (opts.signal) {\n        opts.signal.addEventListener('abort', abort.bind(this))\n      }\n    }\n\n    this.on('newListener', newListener)\n  }\n\n  _open (cb) {\n    cb(null)\n  }\n\n  _destroy (cb) {\n    cb(null)\n  }\n\n  _predestroy () {\n    // does nothing\n  }\n\n  get readable () {\n    return this._readableState !== null ? true : undefined\n  }\n\n  get writable () {\n    return this._writableState !== null ? true : undefined\n  }\n\n  get destroyed () {\n    return (this._duplexState & DESTROYED) !== 0\n  }\n\n  get destroying () {\n    return (this._duplexState & DESTROY_STATUS) !== 0\n  }\n\n  destroy (err) {\n    if ((this._duplexState & DESTROY_STATUS) === 0) {\n      if (!err) err = STREAM_DESTROYED\n      this._duplexState = (this._duplexState | DESTROYING) & NON_PRIMARY\n\n      if (this._readableState !== null) {\n        this._readableState.highWaterMark = 0\n        this._readableState.error = err\n      }\n      if (this._writableState !== null) {\n        this._writableState.highWaterMark = 0\n        this._writableState.error = err\n      }\n\n      this._duplexState |= PREDESTROYING\n      this._predestroy()\n      this._duplexState &= NOT_PREDESTROYING\n\n      if (this._readableState !== null) this._readableState.updateNextTick()\n      if (this._writableState !== null) this._writableState.updateNextTick()\n    }\n  }\n}\n\nclass Readable extends Stream {\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState |= OPENING | WRITE_DONE | READ_READ_AHEAD\n    this._readableState = new ReadableState(this, opts)\n\n    if (opts) {\n      if (this._readableState.readAhead === false) this._duplexState &= READ_NO_READ_AHEAD\n      if (opts.read) this._read = opts.read\n      if (opts.eagerOpen) this._readableState.updateNextTick()\n      if (opts.encoding) this.setEncoding(opts.encoding)\n    }\n  }\n\n  setEncoding (encoding) {\n    const dec = new TextDecoder(encoding)\n    const map = this._readableState.map || echo\n    this._readableState.map = mapOrSkip\n    return this\n\n    function mapOrSkip (data) {\n      const next = dec.push(data)\n      return next === '' && (data.byteLength !== 0 || dec.remaining > 0) ? null : map(next)\n    }\n  }\n\n  _read (cb) {\n    cb(null)\n  }\n\n  pipe (dest, cb) {\n    this._readableState.updateNextTick()\n    this._readableState.pipe(dest, cb)\n    return dest\n  }\n\n  read () {\n    this._readableState.updateNextTick()\n    return this._readableState.read()\n  }\n\n  push (data) {\n    this._readableState.updateNextTickIfOpen()\n    return this._readableState.push(data)\n  }\n\n  unshift (data) {\n    this._readableState.updateNextTickIfOpen()\n    return this._readableState.unshift(data)\n  }\n\n  resume () {\n    this._duplexState |= READ_RESUMED_READ_AHEAD\n    this._readableState.updateNextTick()\n    return this\n  }\n\n  pause () {\n    this._duplexState &= (this._readableState.readAhead === false ? READ_PAUSED_NO_READ_AHEAD : READ_PAUSED)\n    return this\n  }\n\n  static _fromAsyncIterator (ite, opts) {\n    let destroy\n\n    const rs = new Readable({\n      ...opts,\n      read (cb) {\n        ite.next().then(push).then(cb.bind(null, null)).catch(cb)\n      },\n      predestroy () {\n        destroy = ite.return()\n      },\n      destroy (cb) {\n        if (!destroy) return cb(null)\n        destroy.then(cb.bind(null, null)).catch(cb)\n      }\n    })\n\n    return rs\n\n    function push (data) {\n      if (data.done) rs.push(null)\n      else rs.push(data.value)\n    }\n  }\n\n  static from (data, opts) {\n    if (isReadStreamx(data)) return data\n    if (data[asyncIterator]) return this._fromAsyncIterator(data[asyncIterator](), opts)\n    if (!Array.isArray(data)) data = data === undefined ? [] : [data]\n\n    let i = 0\n    return new Readable({\n      ...opts,\n      read (cb) {\n        this.push(i === data.length ? null : data[i++])\n        cb(null)\n      }\n    })\n  }\n\n  static isBackpressured (rs) {\n    return (rs._duplexState & READ_BACKPRESSURE_STATUS) !== 0 || rs._readableState.buffered >= rs._readableState.highWaterMark\n  }\n\n  static isPaused (rs) {\n    return (rs._duplexState & READ_RESUMED) === 0\n  }\n\n  [asyncIterator] () {\n    const stream = this\n\n    let error = null\n    let promiseResolve = null\n    let promiseReject = null\n\n    this.on('error', (err) => { error = err })\n    this.on('readable', onreadable)\n    this.on('close', onclose)\n\n    return {\n      [asyncIterator] () {\n        return this\n      },\n      next () {\n        return new Promise(function (resolve, reject) {\n          promiseResolve = resolve\n          promiseReject = reject\n          const data = stream.read()\n          if (data !== null) ondata(data)\n          else if ((stream._duplexState & DESTROYED) !== 0) ondata(null)\n        })\n      },\n      return () {\n        return destroy(null)\n      },\n      throw (err) {\n        return destroy(err)\n      }\n    }\n\n    function onreadable () {\n      if (promiseResolve !== null) ondata(stream.read())\n    }\n\n    function onclose () {\n      if (promiseResolve !== null) ondata(null)\n    }\n\n    function ondata (data) {\n      if (promiseReject === null) return\n      if (error) promiseReject(error)\n      else if (data === null && (stream._duplexState & READ_DONE) === 0) promiseReject(STREAM_DESTROYED)\n      else promiseResolve({ value: data, done: data === null })\n      promiseReject = promiseResolve = null\n    }\n\n    function destroy (err) {\n      stream.destroy(err)\n      return new Promise((resolve, reject) => {\n        if (stream._duplexState & DESTROYED) return resolve({ value: undefined, done: true })\n        stream.once('close', function () {\n          if (err) reject(err)\n          else resolve({ value: undefined, done: true })\n        })\n      })\n    }\n  }\n}\n\nclass Writable extends Stream {\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState |= OPENING | READ_DONE\n    this._writableState = new WritableState(this, opts)\n\n    if (opts) {\n      if (opts.writev) this._writev = opts.writev\n      if (opts.write) this._write = opts.write\n      if (opts.final) this._final = opts.final\n      if (opts.eagerOpen) this._writableState.updateNextTick()\n    }\n  }\n\n  cork () {\n    this._duplexState |= WRITE_CORKED\n  }\n\n  uncork () {\n    this._duplexState &= WRITE_NOT_CORKED\n    this._writableState.updateNextTick()\n  }\n\n  _writev (batch, cb) {\n    cb(null)\n  }\n\n  _write (data, cb) {\n    this._writableState.autoBatch(data, cb)\n  }\n\n  _final (cb) {\n    cb(null)\n  }\n\n  static isBackpressured (ws) {\n    return (ws._duplexState & WRITE_BACKPRESSURE_STATUS) !== 0\n  }\n\n  static drained (ws) {\n    if (ws.destroyed) return Promise.resolve(false)\n    const state = ws._writableState\n    const pending = (isWritev(ws) ? Math.min(1, state.queue.length) : state.queue.length)\n    const writes = pending + ((ws._duplexState & WRITE_WRITING) ? 1 : 0)\n    if (writes === 0) return Promise.resolve(true)\n    if (state.drains === null) state.drains = []\n    return new Promise((resolve) => {\n      state.drains.push({ writes, resolve })\n    })\n  }\n\n  write (data) {\n    this._writableState.updateNextTick()\n    return this._writableState.push(data)\n  }\n\n  end (data) {\n    this._writableState.updateNextTick()\n    this._writableState.end(data)\n    return this\n  }\n}\n\nclass Duplex extends Readable { // and Writable\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState = OPENING | (this._duplexState & READ_READ_AHEAD)\n    this._writableState = new WritableState(this, opts)\n\n    if (opts) {\n      if (opts.writev) this._writev = opts.writev\n      if (opts.write) this._write = opts.write\n      if (opts.final) this._final = opts.final\n    }\n  }\n\n  cork () {\n    this._duplexState |= WRITE_CORKED\n  }\n\n  uncork () {\n    this._duplexState &= WRITE_NOT_CORKED\n    this._writableState.updateNextTick()\n  }\n\n  _writev (batch, cb) {\n    cb(null)\n  }\n\n  _write (data, cb) {\n    this._writableState.autoBatch(data, cb)\n  }\n\n  _final (cb) {\n    cb(null)\n  }\n\n  write (data) {\n    this._writableState.updateNextTick()\n    return this._writableState.push(data)\n  }\n\n  end (data) {\n    this._writableState.updateNextTick()\n    this._writableState.end(data)\n    return this\n  }\n}\n\nclass Transform extends Duplex {\n  constructor (opts) {\n    super(opts)\n    this._transformState = new TransformState(this)\n\n    if (opts) {\n      if (opts.transform) this._transform = opts.transform\n      if (opts.flush) this._flush = opts.flush\n    }\n  }\n\n  _write (data, cb) {\n    if (this._readableState.buffered >= this._readableState.highWaterMark) {\n      this._transformState.data = data\n    } else {\n      this._transform(data, this._transformState.afterTransform)\n    }\n  }\n\n  _read (cb) {\n    if (this._transformState.data !== null) {\n      const data = this._transformState.data\n      this._transformState.data = null\n      cb(null)\n      this._transform(data, this._transformState.afterTransform)\n    } else {\n      cb(null)\n    }\n  }\n\n  destroy (err) {\n    super.destroy(err)\n    if (this._transformState.data !== null) {\n      this._transformState.data = null\n      this._transformState.afterTransform()\n    }\n  }\n\n  _transform (data, cb) {\n    cb(null, data)\n  }\n\n  _flush (cb) {\n    cb(null)\n  }\n\n  _final (cb) {\n    this._transformState.afterFinal = cb\n    this._flush(transformAfterFlush.bind(this))\n  }\n}\n\nclass PassThrough extends Transform {}\n\nfunction transformAfterFlush (err, data) {\n  const cb = this._transformState.afterFinal\n  if (err) return cb(err)\n  if (data !== null && data !== undefined) this.push(data)\n  this.push(null)\n  cb(null)\n}\n\nfunction pipelinePromise (...streams) {\n  return new Promise((resolve, reject) => {\n    return pipeline(...streams, (err) => {\n      if (err) return reject(err)\n      resolve()\n    })\n  })\n}\n\nfunction pipeline (stream, ...streams) {\n  const all = Array.isArray(stream) ? [...stream, ...streams] : [stream, ...streams]\n  const done = (all.length && typeof all[all.length - 1] === 'function') ? all.pop() : null\n\n  if (all.length < 2) throw new Error('Pipeline requires at least 2 streams')\n\n  let src = all[0]\n  let dest = null\n  let error = null\n\n  for (let i = 1; i < all.length; i++) {\n    dest = all[i]\n\n    if (isStreamx(src)) {\n      src.pipe(dest, onerror)\n    } else {\n      errorHandle(src, true, i > 1, onerror)\n      src.pipe(dest)\n    }\n\n    src = dest\n  }\n\n  if (done) {\n    let fin = false\n\n    const autoDestroy = isStreamx(dest) || !!(dest._writableState && dest._writableState.autoDestroy)\n\n    dest.on('error', (err) => {\n      if (error === null) error = err\n    })\n\n    dest.on('finish', () => {\n      fin = true\n      if (!autoDestroy) done(error)\n    })\n\n    if (autoDestroy) {\n      dest.on('close', () => done(error || (fin ? null : PREMATURE_CLOSE)))\n    }\n  }\n\n  return dest\n\n  function errorHandle (s, rd, wr, onerror) {\n    s.on('error', onerror)\n    s.on('close', onclose)\n\n    function onclose () {\n      if (rd && s._readableState && !s._readableState.ended) return onerror(PREMATURE_CLOSE)\n      if (wr && s._writableState && !s._writableState.ended) return onerror(PREMATURE_CLOSE)\n    }\n  }\n\n  function onerror (err) {\n    if (!err || error) return\n    error = err\n\n    for (const s of all) {\n      s.destroy(err)\n    }\n  }\n}\n\nfunction echo (s) {\n  return s\n}\n\nfunction isStream (stream) {\n  return !!stream._readableState || !!stream._writableState\n}\n\nfunction isStreamx (stream) {\n  return typeof stream._duplexState === 'number' && isStream(stream)\n}\n\nfunction isEnded (stream) {\n  return !!stream._readableState && stream._readableState.ended\n}\n\nfunction isFinished (stream) {\n  return !!stream._writableState && stream._writableState.ended\n}\n\nfunction getStreamError (stream, opts = {}) {\n  const err = (stream._readableState && stream._readableState.error) || (stream._writableState && stream._writableState.error)\n\n  // avoid implicit errors by default\n  return (!opts.all && err === STREAM_DESTROYED) ? null : err\n}\n\nfunction isReadStreamx (stream) {\n  return isStreamx(stream) && stream.readable\n}\n\nfunction isDisturbed (stream) {\n  return (stream._duplexState & OPENING) !== OPENING || (stream._duplexState & ACTIVE_OR_TICKING) !== 0\n}\n\nfunction isTypedArray (data) {\n  return typeof data === 'object' && data !== null && typeof data.byteLength === 'number'\n}\n\nfunction defaultByteLength (data) {\n  return isTypedArray(data) ? data.byteLength : 1024\n}\n\nfunction noop () {}\n\nfunction abort () {\n  this.destroy(new Error('Stream aborted.'))\n}\n\nfunction isWritev (s) {\n  return s._writev !== Writable.prototype._writev && s._writev !== Duplex.prototype._writev\n}\n\nmodule.exports = {\n  pipeline,\n  pipelinePromise,\n  isStream,\n  isStreamx,\n  isEnded,\n  isFinished,\n  isDisturbed,\n  getStreamError,\n  Stream,\n  Writable,\n  Readable,\n  Duplex,\n  Transform,\n  // Export PassThrough for compatibility with Node.js core's stream module\n  PassThrough\n}\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}","const constants = { // just for envs without fs\n  S_IFMT: 61440,\n  S_IFDIR: 16384,\n  S_IFCHR: 8192,\n  S_IFBLK: 24576,\n  S_IFIFO: 4096,\n  S_IFLNK: 40960\n}\n\ntry {\n  module.exports = require('fs').constants || constants\n} catch {\n  module.exports = constants\n}\n","const { Writable, Readable, getStreamError } = require('streamx')\nconst FIFO = require('fast-fifo')\nconst b4a = require('b4a')\nconst headers = require('./headers')\n\nconst EMPTY = b4a.alloc(0)\n\nclass BufferList {\n  constructor () {\n    this.buffered = 0\n    this.shifted = 0\n    this.queue = new FIFO()\n\n    this._offset = 0\n  }\n\n  push (buffer) {\n    this.buffered += buffer.byteLength\n    this.queue.push(buffer)\n  }\n\n  shiftFirst (size) {\n    return this._buffered === 0 ? null : this._next(size)\n  }\n\n  shift (size) {\n    if (size > this.buffered) return null\n    if (size === 0) return EMPTY\n\n    let chunk = this._next(size)\n\n    if (size === chunk.byteLength) return chunk // likely case\n\n    const chunks = [chunk]\n\n    while ((size -= chunk.byteLength) > 0) {\n      chunk = this._next(size)\n      chunks.push(chunk)\n    }\n\n    return b4a.concat(chunks)\n  }\n\n  _next (size) {\n    const buf = this.queue.peek()\n    const rem = buf.byteLength - this._offset\n\n    if (size >= rem) {\n      const sub = this._offset ? buf.subarray(this._offset, buf.byteLength) : buf\n      this.queue.shift()\n      this._offset = 0\n      this.buffered -= rem\n      this.shifted += rem\n      return sub\n    }\n\n    this.buffered -= size\n    this.shifted += size\n\n    return buf.subarray(this._offset, (this._offset += size))\n  }\n}\n\nclass Source extends Readable {\n  constructor (self, header, offset) {\n    super()\n\n    this.header = header\n    this.offset = offset\n\n    this._parent = self\n  }\n\n  _read (cb) {\n    if (this.header.size === 0) {\n      this.push(null)\n    }\n    if (this._parent._stream === this) {\n      this._parent._update()\n    }\n    cb(null)\n  }\n\n  _predestroy () {\n    this._parent.destroy(getStreamError(this))\n  }\n\n  _detach () {\n    if (this._parent._stream === this) {\n      this._parent._stream = null\n      this._parent._missing = overflow(this.header.size)\n      this._parent._update()\n    }\n  }\n\n  _destroy (cb) {\n    this._detach()\n    cb(null)\n  }\n}\n\nclass Extract extends Writable {\n  constructor (opts) {\n    super(opts)\n\n    if (!opts) opts = {}\n\n    this._buffer = new BufferList()\n    this._offset = 0\n    this._header = null\n    this._stream = null\n    this._missing = 0\n    this._longHeader = false\n    this._callback = noop\n    this._locked = false\n    this._finished = false\n    this._pax = null\n    this._paxGlobal = null\n    this._gnuLongPath = null\n    this._gnuLongLinkPath = null\n    this._filenameEncoding = opts.filenameEncoding || 'utf-8'\n    this._allowUnknownFormat = !!opts.allowUnknownFormat\n    this._unlockBound = this._unlock.bind(this)\n  }\n\n  _unlock (err) {\n    this._locked = false\n\n    if (err) {\n      this.destroy(err)\n      this._continueWrite(err)\n      return\n    }\n\n    this._update()\n  }\n\n  _consumeHeader () {\n    if (this._locked) return false\n\n    this._offset = this._buffer.shifted\n\n    try {\n      this._header = headers.decode(this._buffer.shift(512), this._filenameEncoding, this._allowUnknownFormat)\n    } catch (err) {\n      this._continueWrite(err)\n      return false\n    }\n\n    if (!this._header) return true\n\n    switch (this._header.type) {\n      case 'gnu-long-path':\n      case 'gnu-long-link-path':\n      case 'pax-global-header':\n      case 'pax-header':\n        this._longHeader = true\n        this._missing = this._header.size\n        return true\n    }\n\n    this._locked = true\n    this._applyLongHeaders()\n\n    if (this._header.size === 0 || this._header.type === 'directory') {\n      this.emit('entry', this._header, this._createStream(), this._unlockBound)\n      return true\n    }\n\n    this._stream = this._createStream()\n    this._missing = this._header.size\n\n    this.emit('entry', this._header, this._stream, this._unlockBound)\n    return true\n  }\n\n  _applyLongHeaders () {\n    if (this._gnuLongPath) {\n      this._header.name = this._gnuLongPath\n      this._gnuLongPath = null\n    }\n\n    if (this._gnuLongLinkPath) {\n      this._header.linkname = this._gnuLongLinkPath\n      this._gnuLongLinkPath = null\n    }\n\n    if (this._pax) {\n      if (this._pax.path) this._header.name = this._pax.path\n      if (this._pax.linkpath) this._header.linkname = this._pax.linkpath\n      if (this._pax.size) this._header.size = parseInt(this._pax.size, 10)\n      this._header.pax = this._pax\n      this._pax = null\n    }\n  }\n\n  _decodeLongHeader (buf) {\n    switch (this._header.type) {\n      case 'gnu-long-path':\n        this._gnuLongPath = headers.decodeLongPath(buf, this._filenameEncoding)\n        break\n      case 'gnu-long-link-path':\n        this._gnuLongLinkPath = headers.decodeLongPath(buf, this._filenameEncoding)\n        break\n      case 'pax-global-header':\n        this._paxGlobal = headers.decodePax(buf)\n        break\n      case 'pax-header':\n        this._pax = this._paxGlobal === null\n          ? headers.decodePax(buf)\n          : Object.assign({}, this._paxGlobal, headers.decodePax(buf))\n        break\n    }\n  }\n\n  _consumeLongHeader () {\n    this._longHeader = false\n    this._missing = overflow(this._header.size)\n\n    const buf = this._buffer.shift(this._header.size)\n\n    try {\n      this._decodeLongHeader(buf)\n    } catch (err) {\n      this._continueWrite(err)\n      return false\n    }\n\n    return true\n  }\n\n  _consumeStream () {\n    const buf = this._buffer.shiftFirst(this._missing)\n    if (buf === null) return false\n\n    this._missing -= buf.byteLength\n    const drained = this._stream.push(buf)\n\n    if (this._missing === 0) {\n      this._stream.push(null)\n      if (drained) this._stream._detach()\n      return drained && this._locked === false\n    }\n\n    return drained\n  }\n\n  _createStream () {\n    return new Source(this, this._header, this._offset)\n  }\n\n  _update () {\n    while (this._buffer.buffered > 0 && !this.destroying) {\n      if (this._missing > 0) {\n        if (this._stream !== null) {\n          if (this._consumeStream() === false) return\n          continue\n        }\n\n        if (this._longHeader === true) {\n          if (this._missing > this._buffer.buffered) break\n          if (this._consumeLongHeader() === false) return false\n          continue\n        }\n\n        const ignore = this._buffer.shiftFirst(this._missing)\n        if (ignore !== null) this._missing -= ignore.byteLength\n        continue\n      }\n\n      if (this._buffer.buffered < 512) break\n      if (this._stream !== null || this._consumeHeader() === false) return\n    }\n\n    this._continueWrite(null)\n  }\n\n  _continueWrite (err) {\n    const cb = this._callback\n    this._callback = noop\n    cb(err)\n  }\n\n  _write (data, cb) {\n    this._callback = cb\n    this._buffer.push(data)\n    this._update()\n  }\n\n  _final (cb) {\n    this._finished = this._missing === 0 && this._buffer.buffered === 0\n    cb(this._finished ? null : new Error('Unexpected end of data'))\n  }\n\n  _predestroy () {\n    this._continueWrite(null)\n  }\n\n  _destroy (cb) {\n    if (this._stream) this._stream.destroy(getStreamError(this))\n    cb(null)\n  }\n\n  [Symbol.asyncIterator] () {\n    let error = null\n\n    let promiseResolve = null\n    let promiseReject = null\n\n    let entryStream = null\n    let entryCallback = null\n\n    const extract = this\n\n    this.on('entry', onentry)\n    this.on('error', (err) => { error = err })\n    this.on('close', onclose)\n\n    return {\n      [Symbol.asyncIterator] () {\n        return this\n      },\n      next () {\n        return new Promise(onnext)\n      },\n      return () {\n        return destroy(null)\n      },\n      throw (err) {\n        return destroy(err)\n      }\n    }\n\n    function consumeCallback (err) {\n      if (!entryCallback) return\n      const cb = entryCallback\n      entryCallback = null\n      cb(err)\n    }\n\n    function onnext (resolve, reject) {\n      if (error) {\n        return reject(error)\n      }\n\n      if (entryStream) {\n        resolve({ value: entryStream, done: false })\n        entryStream = null\n        return\n      }\n\n      promiseResolve = resolve\n      promiseReject = reject\n\n      consumeCallback(null)\n\n      if (extract._finished && promiseResolve) {\n        promiseResolve({ value: undefined, done: true })\n        promiseResolve = promiseReject = null\n      }\n    }\n\n    function onentry (header, stream, callback) {\n      entryCallback = callback\n      stream.on('error', noop) // no way around this due to tick sillyness\n\n      if (promiseResolve) {\n        promiseResolve({ value: stream, done: false })\n        promiseResolve = promiseReject = null\n      } else {\n        entryStream = stream\n      }\n    }\n\n    function onclose () {\n      consumeCallback(error)\n      if (!promiseResolve) return\n      if (error) promiseReject(error)\n      else promiseResolve({ value: undefined, done: true })\n      promiseResolve = promiseReject = null\n    }\n\n    function destroy (err) {\n      extract.destroy(err)\n      consumeCallback(err)\n      return new Promise((resolve, reject) => {\n        if (extract.destroyed) return resolve({ value: undefined, done: true })\n        extract.once('close', function () {\n          if (err) reject(err)\n          else resolve({ value: undefined, done: true })\n        })\n      })\n    }\n  }\n}\n\nmodule.exports = function extract (opts) {\n  return new Extract(opts)\n}\n\nfunction noop () {}\n\nfunction overflow (size) {\n  size &= 511\n  return size && 512 - size\n}\n","const b4a = require('b4a')\n\nconst ZEROS = '0000000000000000000'\nconst SEVENS = '7777777777777777777'\nconst ZERO_OFFSET = '0'.charCodeAt(0)\nconst USTAR_MAGIC = b4a.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x00]) // ustar\\x00\nconst USTAR_VER = b4a.from([ZERO_OFFSET, ZERO_OFFSET])\nconst GNU_MAGIC = b4a.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x20]) // ustar\\x20\nconst GNU_VER = b4a.from([0x20, 0x00])\nconst MASK = 0o7777\nconst MAGIC_OFFSET = 257\nconst VERSION_OFFSET = 263\n\nexports.decodeLongPath = function decodeLongPath (buf, encoding) {\n  return decodeStr(buf, 0, buf.length, encoding)\n}\n\nexports.encodePax = function encodePax (opts) { // TODO: encode more stuff in pax\n  let result = ''\n  if (opts.name) result += addLength(' path=' + opts.name + '\\n')\n  if (opts.linkname) result += addLength(' linkpath=' + opts.linkname + '\\n')\n  const pax = opts.pax\n  if (pax) {\n    for (const key in pax) {\n      result += addLength(' ' + key + '=' + pax[key] + '\\n')\n    }\n  }\n  return b4a.from(result)\n}\n\nexports.decodePax = function decodePax (buf) {\n  const result = {}\n\n  while (buf.length) {\n    let i = 0\n    while (i < buf.length && buf[i] !== 32) i++\n    const len = parseInt(b4a.toString(buf.subarray(0, i)), 10)\n    if (!len) return result\n\n    const b = b4a.toString(buf.subarray(i + 1, len - 1))\n    const keyIndex = b.indexOf('=')\n    if (keyIndex === -1) return result\n    result[b.slice(0, keyIndex)] = b.slice(keyIndex + 1)\n\n    buf = buf.subarray(len)\n  }\n\n  return result\n}\n\nexports.encode = function encode (opts) {\n  const buf = b4a.alloc(512)\n  let name = opts.name\n  let prefix = ''\n\n  if (opts.typeflag === 5 && name[name.length - 1] !== '/') name += '/'\n  if (b4a.byteLength(name) !== name.length) return null // utf-8\n\n  while (b4a.byteLength(name) > 100) {\n    const i = name.indexOf('/')\n    if (i === -1) return null\n    prefix += prefix ? '/' + name.slice(0, i) : name.slice(0, i)\n    name = name.slice(i + 1)\n  }\n\n  if (b4a.byteLength(name) > 100 || b4a.byteLength(prefix) > 155) return null\n  if (opts.linkname && b4a.byteLength(opts.linkname) > 100) return null\n\n  b4a.write(buf, name)\n  b4a.write(buf, encodeOct(opts.mode & MASK, 6), 100)\n  b4a.write(buf, encodeOct(opts.uid, 6), 108)\n  b4a.write(buf, encodeOct(opts.gid, 6), 116)\n  encodeSize(opts.size, buf, 124)\n  b4a.write(buf, encodeOct((opts.mtime.getTime() / 1000) | 0, 11), 136)\n\n  buf[156] = ZERO_OFFSET + toTypeflag(opts.type)\n\n  if (opts.linkname) b4a.write(buf, opts.linkname, 157)\n\n  b4a.copy(USTAR_MAGIC, buf, MAGIC_OFFSET)\n  b4a.copy(USTAR_VER, buf, VERSION_OFFSET)\n  if (opts.uname) b4a.write(buf, opts.uname, 265)\n  if (opts.gname) b4a.write(buf, opts.gname, 297)\n  b4a.write(buf, encodeOct(opts.devmajor || 0, 6), 329)\n  b4a.write(buf, encodeOct(opts.devminor || 0, 6), 337)\n\n  if (prefix) b4a.write(buf, prefix, 345)\n\n  b4a.write(buf, encodeOct(cksum(buf), 6), 148)\n\n  return buf\n}\n\nexports.decode = function decode (buf, filenameEncoding, allowUnknownFormat) {\n  let typeflag = buf[156] === 0 ? 0 : buf[156] - ZERO_OFFSET\n\n  let name = decodeStr(buf, 0, 100, filenameEncoding)\n  const mode = decodeOct(buf, 100, 8)\n  const uid = decodeOct(buf, 108, 8)\n  const gid = decodeOct(buf, 116, 8)\n  const size = decodeOct(buf, 124, 12)\n  const mtime = decodeOct(buf, 136, 12)\n  const type = toType(typeflag)\n  const linkname = buf[157] === 0 ? null : decodeStr(buf, 157, 100, filenameEncoding)\n  const uname = decodeStr(buf, 265, 32)\n  const gname = decodeStr(buf, 297, 32)\n  const devmajor = decodeOct(buf, 329, 8)\n  const devminor = decodeOct(buf, 337, 8)\n\n  const c = cksum(buf)\n\n  // checksum is still initial value if header was null.\n  if (c === 8 * 32) return null\n\n  // valid checksum\n  if (c !== decodeOct(buf, 148, 8)) throw new Error('Invalid tar header. Maybe the tar is corrupted or it needs to be gunzipped?')\n\n  if (isUSTAR(buf)) {\n    // ustar (posix) format.\n    // prepend prefix, if present.\n    if (buf[345]) name = decodeStr(buf, 345, 155, filenameEncoding) + '/' + name\n  } else if (isGNU(buf)) {\n    // 'gnu'/'oldgnu' format. Similar to ustar, but has support for incremental and\n    // multi-volume tarballs.\n  } else {\n    if (!allowUnknownFormat) {\n      throw new Error('Invalid tar header: unknown format.')\n    }\n  }\n\n  // to support old tar versions that use trailing / to indicate dirs\n  if (typeflag === 0 && name && name[name.length - 1] === '/') typeflag = 5\n\n  return {\n    name,\n    mode,\n    uid,\n    gid,\n    size,\n    mtime: new Date(1000 * mtime),\n    type,\n    linkname,\n    uname,\n    gname,\n    devmajor,\n    devminor,\n    pax: null\n  }\n}\n\nfunction isUSTAR (buf) {\n  return b4a.equals(USTAR_MAGIC, buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6))\n}\n\nfunction isGNU (buf) {\n  return b4a.equals(GNU_MAGIC, buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6)) &&\n    b4a.equals(GNU_VER, buf.subarray(VERSION_OFFSET, VERSION_OFFSET + 2))\n}\n\nfunction clamp (index, len, defaultValue) {\n  if (typeof index !== 'number') return defaultValue\n  index = ~~index // Coerce to integer.\n  if (index >= len) return len\n  if (index >= 0) return index\n  index += len\n  if (index >= 0) return index\n  return 0\n}\n\nfunction toType (flag) {\n  switch (flag) {\n    case 0:\n      return 'file'\n    case 1:\n      return 'link'\n    case 2:\n      return 'symlink'\n    case 3:\n      return 'character-device'\n    case 4:\n      return 'block-device'\n    case 5:\n      return 'directory'\n    case 6:\n      return 'fifo'\n    case 7:\n      return 'contiguous-file'\n    case 72:\n      return 'pax-header'\n    case 55:\n      return 'pax-global-header'\n    case 27:\n      return 'gnu-long-link-path'\n    case 28:\n    case 30:\n      return 'gnu-long-path'\n  }\n\n  return null\n}\n\nfunction toTypeflag (flag) {\n  switch (flag) {\n    case 'file':\n      return 0\n    case 'link':\n      return 1\n    case 'symlink':\n      return 2\n    case 'character-device':\n      return 3\n    case 'block-device':\n      return 4\n    case 'directory':\n      return 5\n    case 'fifo':\n      return 6\n    case 'contiguous-file':\n      return 7\n    case 'pax-header':\n      return 72\n  }\n\n  return 0\n}\n\nfunction indexOf (block, num, offset, end) {\n  for (; offset < end; offset++) {\n    if (block[offset] === num) return offset\n  }\n  return end\n}\n\nfunction cksum (block) {\n  let sum = 8 * 32\n  for (let i = 0; i < 148; i++) sum += block[i]\n  for (let j = 156; j < 512; j++) sum += block[j]\n  return sum\n}\n\nfunction encodeOct (val, n) {\n  val = val.toString(8)\n  if (val.length > n) return SEVENS.slice(0, n) + ' '\n  return ZEROS.slice(0, n - val.length) + val + ' '\n}\n\nfunction encodeSizeBin (num, buf, off) {\n  buf[off] = 0x80\n  for (let i = 11; i > 0; i--) {\n    buf[off + i] = num & 0xff\n    num = Math.floor(num / 0x100)\n  }\n}\n\nfunction encodeSize (num, buf, off) {\n  if (num.toString(8).length > 11) {\n    encodeSizeBin(num, buf, off)\n  } else {\n    b4a.write(buf, encodeOct(num, 11), off)\n  }\n}\n\n/* Copied from the node-tar repo and modified to meet\n * tar-stream coding standard.\n *\n * Source: https://github.com/npm/node-tar/blob/51b6627a1f357d2eb433e7378e5f05e83b7aa6cd/lib/header.js#L349\n */\nfunction parse256 (buf) {\n  // first byte MUST be either 80 or FF\n  // 80 for positive, FF for 2's comp\n  let positive\n  if (buf[0] === 0x80) positive = true\n  else if (buf[0] === 0xFF) positive = false\n  else return null\n\n  // build up a base-256 tuple from the least sig to the highest\n  const tuple = []\n  let i\n  for (i = buf.length - 1; i > 0; i--) {\n    const byte = buf[i]\n    if (positive) tuple.push(byte)\n    else tuple.push(0xFF - byte)\n  }\n\n  let sum = 0\n  const l = tuple.length\n  for (i = 0; i < l; i++) {\n    sum += tuple[i] * Math.pow(256, i)\n  }\n\n  return positive ? sum : -1 * sum\n}\n\nfunction decodeOct (val, offset, length) {\n  val = val.subarray(offset, offset + length)\n  offset = 0\n\n  // If prefixed with 0x80 then parse as a base-256 integer\n  if (val[offset] & 0x80) {\n    return parse256(val)\n  } else {\n    // Older versions of tar can prefix with spaces\n    while (offset < val.length && val[offset] === 32) offset++\n    const end = clamp(indexOf(val, 32, offset, val.length), val.length, val.length)\n    while (offset < end && val[offset] === 0) offset++\n    if (end === offset) return 0\n    return parseInt(b4a.toString(val.subarray(offset, end)), 8)\n  }\n}\n\nfunction decodeStr (val, offset, length, encoding) {\n  return b4a.toString(val.subarray(offset, indexOf(val, 0, offset, offset + length)), encoding)\n}\n\nfunction addLength (str) {\n  const len = b4a.byteLength(str)\n  let digits = Math.floor(Math.log(len) / Math.log(10)) + 1\n  if (len + digits >= Math.pow(10, digits)) digits++\n\n  return (len + digits) + str\n}\n","exports.extract = require('./extract')\nexports.pack = require('./pack')\n","const { Readable, Writable, getStreamError } = require('streamx')\nconst b4a = require('b4a')\n\nconst constants = require('./constants')\nconst headers = require('./headers')\n\nconst DMODE = 0o755\nconst FMODE = 0o644\n\nconst END_OF_TAR = b4a.alloc(1024)\n\nclass Sink extends Writable {\n  constructor (pack, header, callback) {\n    super({ mapWritable, eagerOpen: true })\n\n    this.written = 0\n    this.header = header\n\n    this._callback = callback\n    this._linkname = null\n    this._isLinkname = header.type === 'symlink' && !header.linkname\n    this._isVoid = header.type !== 'file' && header.type !== 'contiguous-file'\n    this._finished = false\n    this._pack = pack\n    this._openCallback = null\n\n    if (this._pack._stream === null) this._pack._stream = this\n    else this._pack._pending.push(this)\n  }\n\n  _open (cb) {\n    this._openCallback = cb\n    if (this._pack._stream === this) this._continueOpen()\n  }\n\n  _continuePack (err) {\n    if (this._callback === null) return\n\n    const callback = this._callback\n    this._callback = null\n\n    callback(err)\n  }\n\n  _continueOpen () {\n    if (this._pack._stream === null) this._pack._stream = this\n\n    const cb = this._openCallback\n    this._openCallback = null\n    if (cb === null) return\n\n    if (this._pack.destroying) return cb(new Error('pack stream destroyed'))\n    if (this._pack._finalized) return cb(new Error('pack stream is already finalized'))\n\n    this._pack._stream = this\n\n    if (!this._isLinkname) {\n      this._pack._encode(this.header)\n    }\n\n    if (this._isVoid) {\n      this._finish()\n      this._continuePack(null)\n    }\n\n    cb(null)\n  }\n\n  _write (data, cb) {\n    if (this._isLinkname) {\n      this._linkname = this._linkname ? b4a.concat([this._linkname, data]) : data\n      return cb(null)\n    }\n\n    if (this._isVoid) {\n      if (data.byteLength > 0) {\n        return cb(new Error('No body allowed for this entry'))\n      }\n      return cb()\n    }\n\n    this.written += data.byteLength\n    if (this._pack.push(data)) return cb()\n    this._pack._drain = cb\n  }\n\n  _finish () {\n    if (this._finished) return\n    this._finished = true\n\n    if (this._isLinkname) {\n      this.header.linkname = this._linkname ? b4a.toString(this._linkname, 'utf-8') : ''\n      this._pack._encode(this.header)\n    }\n\n    overflow(this._pack, this.header.size)\n\n    this._pack._done(this)\n  }\n\n  _final (cb) {\n    if (this.written !== this.header.size) { // corrupting tar\n      return cb(new Error('Size mismatch'))\n    }\n\n    this._finish()\n    cb(null)\n  }\n\n  _getError () {\n    return getStreamError(this) || new Error('tar entry destroyed')\n  }\n\n  _predestroy () {\n    this._pack.destroy(this._getError())\n  }\n\n  _destroy (cb) {\n    this._pack._done(this)\n\n    this._continuePack(this._finished ? null : this._getError())\n\n    cb()\n  }\n}\n\nclass Pack extends Readable {\n  constructor (opts) {\n    super(opts)\n    this._drain = noop\n    this._finalized = false\n    this._finalizing = false\n    this._pending = []\n    this._stream = null\n  }\n\n  entry (header, buffer, callback) {\n    if (this._finalized || this.destroying) throw new Error('already finalized or destroyed')\n\n    if (typeof buffer === 'function') {\n      callback = buffer\n      buffer = null\n    }\n\n    if (!callback) callback = noop\n\n    if (!header.size || header.type === 'symlink') header.size = 0\n    if (!header.type) header.type = modeToType(header.mode)\n    if (!header.mode) header.mode = header.type === 'directory' ? DMODE : FMODE\n    if (!header.uid) header.uid = 0\n    if (!header.gid) header.gid = 0\n    if (!header.mtime) header.mtime = new Date()\n\n    if (typeof buffer === 'string') buffer = b4a.from(buffer)\n\n    const sink = new Sink(this, header, callback)\n\n    if (b4a.isBuffer(buffer)) {\n      header.size = buffer.byteLength\n      sink.write(buffer)\n      sink.end()\n      return sink\n    }\n\n    if (sink._isVoid) {\n      return sink\n    }\n\n    return sink\n  }\n\n  finalize () {\n    if (this._stream || this._pending.length > 0) {\n      this._finalizing = true\n      return\n    }\n\n    if (this._finalized) return\n    this._finalized = true\n\n    this.push(END_OF_TAR)\n    this.push(null)\n  }\n\n  _done (stream) {\n    if (stream !== this._stream) return\n\n    this._stream = null\n\n    if (this._finalizing) this.finalize()\n    if (this._pending.length) this._pending.shift()._continueOpen()\n  }\n\n  _encode (header) {\n    if (!header.pax) {\n      const buf = headers.encode(header)\n      if (buf) {\n        this.push(buf)\n        return\n      }\n    }\n    this._encodePax(header)\n  }\n\n  _encodePax (header) {\n    const paxHeader = headers.encodePax({\n      name: header.name,\n      linkname: header.linkname,\n      pax: header.pax\n    })\n\n    const newHeader = {\n      name: 'PaxHeader',\n      mode: header.mode,\n      uid: header.uid,\n      gid: header.gid,\n      size: paxHeader.byteLength,\n      mtime: header.mtime,\n      type: 'pax-header',\n      linkname: header.linkname && 'PaxHeader',\n      uname: header.uname,\n      gname: header.gname,\n      devmajor: header.devmajor,\n      devminor: header.devminor\n    }\n\n    this.push(headers.encode(newHeader))\n    this.push(paxHeader)\n    overflow(this, paxHeader.byteLength)\n\n    newHeader.size = header.size\n    newHeader.type = header.type\n    this.push(headers.encode(newHeader))\n  }\n\n  _doDrain () {\n    const drain = this._drain\n    this._drain = noop\n    drain()\n  }\n\n  _predestroy () {\n    const err = getStreamError(this)\n\n    if (this._stream) this._stream.destroy(err)\n\n    while (this._pending.length) {\n      const stream = this._pending.shift()\n      stream.destroy(err)\n      stream._continueOpen()\n    }\n\n    this._doDrain()\n  }\n\n  _read (cb) {\n    this._doDrain()\n    cb()\n  }\n}\n\nmodule.exports = function pack (opts) {\n  return new Pack(opts)\n}\n\nfunction modeToType (mode) {\n  switch (mode & constants.S_IFMT) {\n    case constants.S_IFBLK: return 'block-device'\n    case constants.S_IFCHR: return 'character-device'\n    case constants.S_IFDIR: return 'directory'\n    case constants.S_IFIFO: return 'fifo'\n    case constants.S_IFLNK: return 'symlink'\n  }\n\n  return 'file'\n}\n\nfunction noop () {}\n\nfunction overflow (self, size) {\n  size &= 511\n  if (size) self.push(END_OF_TAR.subarray(0, 512 - size))\n}\n\nfunction mapWritable (buf) {\n  return b4a.isBuffer(buf) ? buf : b4a.from(buf)\n}\n","const PassThroughDecoder = require('./lib/pass-through-decoder')\nconst UTF8Decoder = require('./lib/utf8-decoder')\n\nmodule.exports = class TextDecoder {\n  constructor (encoding = 'utf8') {\n    this.encoding = normalizeEncoding(encoding)\n\n    switch (this.encoding) {\n      case 'utf8':\n        this.decoder = new UTF8Decoder()\n        break\n      case 'utf16le':\n      case 'base64':\n        throw new Error('Unsupported encoding: ' + this.encoding)\n      default:\n        this.decoder = new PassThroughDecoder(this.encoding)\n    }\n  }\n\n  get remaining () {\n    return this.decoder.remaining\n  }\n\n  push (data) {\n    if (typeof data === 'string') return data\n    return this.decoder.decode(data)\n  }\n\n  // For Node.js compatibility\n  write (data) {\n    return this.push(data)\n  }\n\n  end (data) {\n    let result = ''\n    if (data) result = this.push(data)\n    result += this.decoder.flush()\n    return result\n  }\n}\n\nfunction normalizeEncoding (encoding) {\n  encoding = encoding.toLowerCase()\n\n  switch (encoding) {\n    case 'utf8':\n    case 'utf-8':\n      return 'utf8'\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return 'utf16le'\n    case 'latin1':\n    case 'binary':\n      return 'latin1'\n    case 'base64':\n    case 'ascii':\n    case 'hex':\n      return encoding\n    default:\n      throw new Error('Unknown encoding: ' + encoding)\n  }\n};\n","const b4a = require('b4a')\n\nmodule.exports = class PassThroughDecoder {\n  constructor (encoding) {\n    this.encoding = encoding\n  }\n\n  get remaining () {\n    return 0\n  }\n\n  decode (tail) {\n    return b4a.toString(tail, this.encoding)\n  }\n\n  flush () {\n    return ''\n  }\n}\n","const b4a = require('b4a')\n\n/**\n * https://encoding.spec.whatwg.org/#utf-8-decoder\n */\nmodule.exports = class UTF8Decoder {\n  constructor () {\n    this.codePoint = 0\n    this.bytesSeen = 0\n    this.bytesNeeded = 0\n    this.lowerBoundary = 0x80\n    this.upperBoundary = 0xbf\n  }\n\n  get remaining () {\n    return this.bytesSeen\n  }\n\n  decode (data) {\n    // If we have a fast path, just sniff if the last part is a boundary\n    if (this.bytesNeeded === 0) {\n      let isBoundary = true\n\n      for (let i = Math.max(0, data.byteLength - 4), n = data.byteLength; i < n && isBoundary; i++) {\n        isBoundary = data[i] <= 0x7f\n      }\n\n      if (isBoundary) return b4a.toString(data, 'utf8')\n    }\n\n    let result = ''\n\n    for (let i = 0, n = data.byteLength; i < n; i++) {\n      const byte = data[i]\n\n      if (this.bytesNeeded === 0) {\n        if (byte <= 0x7f) {\n          result += String.fromCharCode(byte)\n        } else {\n          this.bytesSeen = 1\n\n          if (byte >= 0xc2 && byte <= 0xdf) {\n            this.bytesNeeded = 2\n            this.codePoint = byte & 0x1f\n          } else if (byte >= 0xe0 && byte <= 0xef) {\n            if (byte === 0xe0) this.lowerBoundary = 0xa0\n            else if (byte === 0xed) this.upperBoundary = 0x9f\n            this.bytesNeeded = 3\n            this.codePoint = byte & 0xf\n          } else if (byte >= 0xf0 && byte <= 0xf4) {\n            if (byte === 0xf0) this.lowerBoundary = 0x90\n            if (byte === 0xf4) this.upperBoundary = 0x8f\n            this.bytesNeeded = 4\n            this.codePoint = byte & 0x7\n          } else {\n            result += '\\ufffd'\n          }\n        }\n\n        continue\n      }\n\n      if (byte < this.lowerBoundary || byte > this.upperBoundary) {\n        this.codePoint = 0\n        this.bytesNeeded = 0\n        this.bytesSeen = 0\n        this.lowerBoundary = 0x80\n        this.upperBoundary = 0xbf\n\n        result += '\\ufffd'\n\n        continue\n      }\n\n      this.lowerBoundary = 0x80\n      this.upperBoundary = 0xbf\n\n      this.codePoint = (this.codePoint << 6) | (byte & 0x3f)\n      this.bytesSeen++\n\n      if (this.bytesSeen !== this.bytesNeeded) continue\n\n      result += String.fromCodePoint(this.codePoint)\n\n      this.codePoint = 0\n      this.bytesNeeded = 0\n      this.bytesSeen = 0\n    }\n\n    return result\n  }\n\n  flush () {\n    const result = this.bytesNeeded > 0 ? '\\ufffd' : ''\n\n    this.codePoint = 0\n    this.bytesNeeded = 0\n    this.bytesSeen = 0\n    this.lowerBoundary = 0x80\n    this.upperBoundary = 0xbf\n\n    return result\n  }\n}\n","/******************************************************************************\r\nCopyright (c) Microsoft Corporation.\r\n\r\nPermission to use, copy, modify, and/or distribute this software for any\r\npurpose with or without fee is hereby granted.\r\n\r\nTHE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH\r\nREGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY\r\nAND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,\r\nINDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM\r\nLOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR\r\nOTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR\r\nPERFORMANCE OF THIS SOFTWARE.\r\n***************************************************************************** */\r\n/* global global, define, Symbol, Reflect, Promise, SuppressedError, Iterator */\r\nvar __extends;\r\nvar __assign;\r\nvar __rest;\r\nvar __decorate;\r\nvar __param;\r\nvar __esDecorate;\r\nvar __runInitializers;\r\nvar __propKey;\r\nvar __setFunctionName;\r\nvar __metadata;\r\nvar __awaiter;\r\nvar __generator;\r\nvar __exportStar;\r\nvar __values;\r\nvar __read;\r\nvar __spread;\r\nvar __spreadArrays;\r\nvar __spreadArray;\r\nvar __await;\r\nvar __asyncGenerator;\r\nvar __asyncDelegator;\r\nvar __asyncValues;\r\nvar __makeTemplateObject;\r\nvar __importStar;\r\nvar __importDefault;\r\nvar __classPrivateFieldGet;\r\nvar __classPrivateFieldSet;\r\nvar __classPrivateFieldIn;\r\nvar __createBinding;\r\nvar __addDisposableResource;\r\nvar __disposeResources;\r\nvar __rewriteRelativeImportExtension;\r\n(function (factory) {\r\n    var root = typeof global === \"object\" ? global : typeof self === \"object\" ? self : typeof this === \"object\" ? this : {};\r\n    if (typeof define === \"function\" && define.amd) {\r\n        define(\"tslib\", [\"exports\"], function (exports) { factory(createExporter(root, createExporter(exports))); });\r\n    }\r\n    else if (typeof module === \"object\" && typeof module.exports === \"object\") {\r\n        factory(createExporter(root, createExporter(module.exports)));\r\n    }\r\n    else {\r\n        factory(createExporter(root));\r\n    }\r\n    function createExporter(exports, previous) {\r\n        if (exports !== root) {\r\n            if (typeof Object.create === \"function\") {\r\n                Object.defineProperty(exports, \"__esModule\", { value: true });\r\n            }\r\n            else {\r\n                exports.__esModule = true;\r\n            }\r\n        }\r\n        return function (id, v) { return exports[id] = previous ? previous(id, v) : v; };\r\n    }\r\n})\r\n(function (exporter) {\r\n    var extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (Object.prototype.hasOwnProperty.call(b, p)) d[p] = b[p]; };\r\n\r\n    __extends = function (d, b) {\r\n        if (typeof b !== \"function\" && b !== null)\r\n            throw new TypeError(\"Class extends value \" + String(b) + \" is not a constructor or null\");\r\n        extendStatics(d, b);\r\n        function __() { this.constructor = d; }\r\n        d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n    };\r\n\r\n    __assign = Object.assign || function (t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    };\r\n\r\n    __rest = function (s, e) {\r\n        var t = {};\r\n        for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\r\n            t[p] = s[p];\r\n        if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\r\n            for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\r\n                if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\r\n                    t[p[i]] = s[p[i]];\r\n            }\r\n        return t;\r\n    };\r\n\r\n    __decorate = function (decorators, target, key, desc) {\r\n        var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\r\n        if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\r\n        else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\r\n        return c > 3 && r && Object.defineProperty(target, key, r), r;\r\n    };\r\n\r\n    __param = function (paramIndex, decorator) {\r\n        return function (target, key) { decorator(target, key, paramIndex); }\r\n    };\r\n\r\n    __esDecorate = function (ctor, descriptorIn, decorators, contextIn, initializers, extraInitializers) {\r\n        function accept(f) { if (f !== void 0 && typeof f !== \"function\") throw new TypeError(\"Function expected\"); return f; }\r\n        var kind = contextIn.kind, key = kind === \"getter\" ? \"get\" : kind === \"setter\" ? \"set\" : \"value\";\r\n        var target = !descriptorIn && ctor ? contextIn[\"static\"] ? ctor : ctor.prototype : null;\r\n        var descriptor = descriptorIn || (target ? Object.getOwnPropertyDescriptor(target, contextIn.name) : {});\r\n        var _, done = false;\r\n        for (var i = decorators.length - 1; i >= 0; i--) {\r\n            var context = {};\r\n            for (var p in contextIn) context[p] = p === \"access\" ? {} : contextIn[p];\r\n            for (var p in contextIn.access) context.access[p] = contextIn.access[p];\r\n            context.addInitializer = function (f) { if (done) throw new TypeError(\"Cannot add initializers after decoration has completed\"); extraInitializers.push(accept(f || null)); };\r\n            var result = (0, decorators[i])(kind === \"accessor\" ? { get: descriptor.get, set: descriptor.set } : descriptor[key], context);\r\n            if (kind === \"accessor\") {\r\n                if (result === void 0) continue;\r\n                if (result === null || typeof result !== \"object\") throw new TypeError(\"Object expected\");\r\n                if (_ = accept(result.get)) descriptor.get = _;\r\n                if (_ = accept(result.set)) descriptor.set = _;\r\n                if (_ = accept(result.init)) initializers.unshift(_);\r\n            }\r\n            else if (_ = accept(result)) {\r\n                if (kind === \"field\") initializers.unshift(_);\r\n                else descriptor[key] = _;\r\n            }\r\n        }\r\n        if (target) Object.defineProperty(target, contextIn.name, descriptor);\r\n        done = true;\r\n    };\r\n\r\n    __runInitializers = function (thisArg, initializers, value) {\r\n        var useValue = arguments.length > 2;\r\n        for (var i = 0; i < initializers.length; i++) {\r\n            value = useValue ? initializers[i].call(thisArg, value) : initializers[i].call(thisArg);\r\n        }\r\n        return useValue ? value : void 0;\r\n    };\r\n\r\n    __propKey = function (x) {\r\n        return typeof x === \"symbol\" ? x : \"\".concat(x);\r\n    };\r\n\r\n    __setFunctionName = function (f, name, prefix) {\r\n        if (typeof name === \"symbol\") name = name.description ? \"[\".concat(name.description, \"]\") : \"\";\r\n        return Object.defineProperty(f, \"name\", { configurable: true, value: prefix ? \"\".concat(prefix, \" \", name) : name });\r\n    };\r\n\r\n    __metadata = function (metadataKey, metadataValue) {\r\n        if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\r\n    };\r\n\r\n    __awaiter = function (thisArg, _arguments, P, generator) {\r\n        function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\r\n        return new (P || (P = Promise))(function (resolve, reject) {\r\n            function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n            function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n            function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\r\n            step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n        });\r\n    };\r\n\r\n    __generator = function (thisArg, body) {\r\n        var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g = Object.create((typeof Iterator === \"function\" ? Iterator : Object).prototype);\r\n        return g.next = verb(0), g[\"throw\"] = verb(1), g[\"return\"] = verb(2), typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n        function verb(n) { return function (v) { return step([n, v]); }; }\r\n        function step(op) {\r\n            if (f) throw new TypeError(\"Generator is already executing.\");\r\n            while (g && (g = 0, op[0] && (_ = 0)), _) try {\r\n                if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n                if (y = 0, t) op = [op[0] & 2, t.value];\r\n                switch (op[0]) {\r\n                    case 0: case 1: t = op; break;\r\n                    case 4: _.label++; return { value: op[1], done: false };\r\n                    case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                    case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                    default:\r\n                        if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                        if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                        if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                        if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                        if (t[2]) _.ops.pop();\r\n                        _.trys.pop(); continue;\r\n                }\r\n                op = body.call(thisArg, _);\r\n            } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n            if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n        }\r\n    };\r\n\r\n    __exportStar = function(m, o) {\r\n        for (var p in m) if (p !== \"default\" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);\r\n    };\r\n\r\n    __createBinding = Object.create ? (function(o, m, k, k2) {\r\n        if (k2 === undefined) k2 = k;\r\n        var desc = Object.getOwnPropertyDescriptor(m, k);\r\n        if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\r\n            desc = { enumerable: true, get: function() { return m[k]; } };\r\n        }\r\n        Object.defineProperty(o, k2, desc);\r\n    }) : (function(o, m, k, k2) {\r\n        if (k2 === undefined) k2 = k;\r\n        o[k2] = m[k];\r\n    });\r\n\r\n    __values = function (o) {\r\n        var s = typeof Symbol === \"function\" && Symbol.iterator, m = s && o[s], i = 0;\r\n        if (m) return m.call(o);\r\n        if (o && typeof o.length === \"number\") return {\r\n            next: function () {\r\n                if (o && i >= o.length) o = void 0;\r\n                return { value: o && o[i++], done: !o };\r\n            }\r\n        };\r\n        throw new TypeError(s ? \"Object is not iterable.\" : \"Symbol.iterator is not defined.\");\r\n    };\r\n\r\n    __read = function (o, n) {\r\n        var m = typeof Symbol === \"function\" && o[Symbol.iterator];\r\n        if (!m) return o;\r\n        var i = m.call(o), r, ar = [], e;\r\n        try {\r\n            while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\r\n        }\r\n        catch (error) { e = { error: error }; }\r\n        finally {\r\n            try {\r\n                if (r && !r.done && (m = i[\"return\"])) m.call(i);\r\n            }\r\n            finally { if (e) throw e.error; }\r\n        }\r\n        return ar;\r\n    };\r\n\r\n    /** @deprecated */\r\n    __spread = function () {\r\n        for (var ar = [], i = 0; i < arguments.length; i++)\r\n            ar = ar.concat(__read(arguments[i]));\r\n        return ar;\r\n    };\r\n\r\n    /** @deprecated */\r\n    __spreadArrays = function () {\r\n        for (var s = 0, i = 0, il = arguments.length; i < il; i++) s += arguments[i].length;\r\n        for (var r = Array(s), k = 0, i = 0; i < il; i++)\r\n            for (var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)\r\n                r[k] = a[j];\r\n        return r;\r\n    };\r\n\r\n    __spreadArray = function (to, from, pack) {\r\n        if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {\r\n            if (ar || !(i in from)) {\r\n                if (!ar) ar = Array.prototype.slice.call(from, 0, i);\r\n                ar[i] = from[i];\r\n            }\r\n        }\r\n        return to.concat(ar || Array.prototype.slice.call(from));\r\n    };\r\n\r\n    __await = function (v) {\r\n        return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n    };\r\n\r\n    __asyncGenerator = function (thisArg, _arguments, generator) {\r\n        if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n        var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n        return i = Object.create((typeof AsyncIterator === \"function\" ? AsyncIterator : Object).prototype), verb(\"next\"), verb(\"throw\"), verb(\"return\", awaitReturn), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n        function awaitReturn(f) { return function (v) { return Promise.resolve(v).then(f, reject); }; }\r\n        function verb(n, f) { if (g[n]) { i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; if (f) i[n] = f(i[n]); } }\r\n        function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n        function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n        function fulfill(value) { resume(\"next\", value); }\r\n        function reject(value) { resume(\"throw\", value); }\r\n        function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n    };\r\n\r\n    __asyncDelegator = function (o) {\r\n        var i, p;\r\n        return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\r\n        function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: false } : f ? f(v) : v; } : f; }\r\n    };\r\n\r\n    __asyncValues = function (o) {\r\n        if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n        var m = o[Symbol.asyncIterator], i;\r\n        return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\r\n        function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\r\n        function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\r\n    };\r\n\r\n    __makeTemplateObject = function (cooked, raw) {\r\n        if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\r\n        return cooked;\r\n    };\r\n\r\n    var __setModuleDefault = Object.create ? (function(o, v) {\r\n        Object.defineProperty(o, \"default\", { enumerable: true, value: v });\r\n    }) : function(o, v) {\r\n        o[\"default\"] = v;\r\n    };\r\n\r\n    var ownKeys = function(o) {\r\n        ownKeys = Object.getOwnPropertyNames || function (o) {\r\n            var ar = [];\r\n            for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;\r\n            return ar;\r\n        };\r\n        return ownKeys(o);\r\n    };\r\n\r\n    __importStar = function (mod) {\r\n        if (mod && mod.__esModule) return mod;\r\n        var result = {};\r\n        if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== \"default\") __createBinding(result, mod, k[i]);\r\n        __setModuleDefault(result, mod);\r\n        return result;\r\n    };\r\n\r\n    __importDefault = function (mod) {\r\n        return (mod && mod.__esModule) ? mod : { \"default\": mod };\r\n    };\r\n\r\n    __classPrivateFieldGet = function (receiver, state, kind, f) {\r\n        if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a getter\");\r\n        if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot read private member from an object whose class did not declare it\");\r\n        return kind === \"m\" ? f : kind === \"a\" ? f.call(receiver) : f ? f.value : state.get(receiver);\r\n    };\r\n\r\n    __classPrivateFieldSet = function (receiver, state, value, kind, f) {\r\n        if (kind === \"m\") throw new TypeError(\"Private method is not writable\");\r\n        if (kind === \"a\" && !f) throw new TypeError(\"Private accessor was defined without a setter\");\r\n        if (typeof state === \"function\" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError(\"Cannot write private member to an object whose class did not declare it\");\r\n        return (kind === \"a\" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value)), value;\r\n    };\r\n\r\n    __classPrivateFieldIn = function (state, receiver) {\r\n        if (receiver === null || (typeof receiver !== \"object\" && typeof receiver !== \"function\")) throw new TypeError(\"Cannot use 'in' operator on non-object\");\r\n        return typeof state === \"function\" ? receiver === state : state.has(receiver);\r\n    };\r\n\r\n    __addDisposableResource = function (env, value, async) {\r\n        if (value !== null && value !== void 0) {\r\n            if (typeof value !== \"object\" && typeof value !== \"function\") throw new TypeError(\"Object expected.\");\r\n            var dispose, inner;\r\n            if (async) {\r\n                if (!Symbol.asyncDispose) throw new TypeError(\"Symbol.asyncDispose is not defined.\");\r\n                dispose = value[Symbol.asyncDispose];\r\n            }\r\n            if (dispose === void 0) {\r\n                if (!Symbol.dispose) throw new TypeError(\"Symbol.dispose is not defined.\");\r\n                dispose = value[Symbol.dispose];\r\n                if (async) inner = dispose;\r\n            }\r\n            if (typeof dispose !== \"function\") throw new TypeError(\"Object not disposable.\");\r\n            if (inner) dispose = function() { try { inner.call(this); } catch (e) { return Promise.reject(e); } };\r\n            env.stack.push({ value: value, dispose: dispose, async: async });\r\n        }\r\n        else if (async) {\r\n            env.stack.push({ async: true });\r\n        }\r\n        return value;\r\n    };\r\n\r\n    var _SuppressedError = typeof SuppressedError === \"function\" ? SuppressedError : function (error, suppressed, message) {\r\n        var e = new Error(message);\r\n        return e.name = \"SuppressedError\", e.error = error, e.suppressed = suppressed, e;\r\n    };\r\n\r\n    __disposeResources = function (env) {\r\n        function fail(e) {\r\n            env.error = env.hasError ? new _SuppressedError(e, env.error, \"An error was suppressed during disposal.\") : e;\r\n            env.hasError = true;\r\n        }\r\n        var r, s = 0;\r\n        function next() {\r\n            while (r = env.stack.pop()) {\r\n                try {\r\n                    if (!r.async && s === 1) return s = 0, env.stack.push(r), Promise.resolve().then(next);\r\n                    if (r.dispose) {\r\n                        var result = r.dispose.call(r.value);\r\n                        if (r.async) return s |= 2, Promise.resolve(result).then(next, function(e) { fail(e); return next(); });\r\n                    }\r\n                    else s |= 1;\r\n                }\r\n                catch (e) {\r\n                    fail(e);\r\n                }\r\n            }\r\n            if (s === 1) return env.hasError ? Promise.reject(env.error) : Promise.resolve();\r\n            if (env.hasError) throw env.error;\r\n        }\r\n        return next();\r\n    };\r\n\r\n    __rewriteRelativeImportExtension = function (path, preserveJsx) {\r\n        if (typeof path === \"string\" && /^\\.\\.?\\//.test(path)) {\r\n            return path.replace(/\\.(tsx)$|((?:\\.d)?)((?:\\.[^./]+?)?)\\.([cm]?)ts$/i, function (m, tsx, d, ext, cm) {\r\n                return tsx ? preserveJsx ? \".jsx\" : \".js\" : d && (!ext || !cm) ? m : (d + ext + \".\" + cm.toLowerCase() + \"js\");\r\n            });\r\n        }\r\n        return path;\r\n    };\r\n\r\n    exporter(\"__extends\", __extends);\r\n    exporter(\"__assign\", __assign);\r\n    exporter(\"__rest\", __rest);\r\n    exporter(\"__decorate\", __decorate);\r\n    exporter(\"__param\", __param);\r\n    exporter(\"__esDecorate\", __esDecorate);\r\n    exporter(\"__runInitializers\", __runInitializers);\r\n    exporter(\"__propKey\", __propKey);\r\n    exporter(\"__setFunctionName\", __setFunctionName);\r\n    exporter(\"__metadata\", __metadata);\r\n    exporter(\"__awaiter\", __awaiter);\r\n    exporter(\"__generator\", __generator);\r\n    exporter(\"__exportStar\", __exportStar);\r\n    exporter(\"__createBinding\", __createBinding);\r\n    exporter(\"__values\", __values);\r\n    exporter(\"__read\", __read);\r\n    exporter(\"__spread\", __spread);\r\n    exporter(\"__spreadArrays\", __spreadArrays);\r\n    exporter(\"__spreadArray\", __spreadArray);\r\n    exporter(\"__await\", __await);\r\n    exporter(\"__asyncGenerator\", __asyncGenerator);\r\n    exporter(\"__asyncDelegator\", __asyncDelegator);\r\n    exporter(\"__asyncValues\", __asyncValues);\r\n    exporter(\"__makeTemplateObject\", __makeTemplateObject);\r\n    exporter(\"__importStar\", __importStar);\r\n    exporter(\"__importDefault\", __importDefault);\r\n    exporter(\"__classPrivateFieldGet\", __classPrivateFieldGet);\r\n    exporter(\"__classPrivateFieldSet\", __classPrivateFieldSet);\r\n    exporter(\"__classPrivateFieldIn\", __classPrivateFieldIn);\r\n    exporter(\"__addDisposableResource\", __addDisposableResource);\r\n    exporter(\"__disposeResources\", __disposeResources);\r\n    exporter(\"__rewriteRelativeImportExtension\", __rewriteRelativeImportExtension);\r\n});\r\n\r\n0 && (module.exports = {\r\n    __extends: __extends,\r\n    __assign: __assign,\r\n    __rest: __rest,\r\n    __decorate: __decorate,\r\n    __param: __param,\r\n    __esDecorate: __esDecorate,\r\n    __runInitializers: __runInitializers,\r\n    __propKey: __propKey,\r\n    __setFunctionName: __setFunctionName,\r\n    __metadata: __metadata,\r\n    __awaiter: __awaiter,\r\n    __generator: __generator,\r\n    __exportStar: __exportStar,\r\n    __createBinding: __createBinding,\r\n    __values: __values,\r\n    __read: __read,\r\n    __spread: __spread,\r\n    __spreadArrays: __spreadArrays,\r\n    __spreadArray: __spreadArray,\r\n    __await: __await,\r\n    __asyncGenerator: __asyncGenerator,\r\n    __asyncDelegator: __asyncDelegator,\r\n    __asyncValues: __asyncValues,\r\n    __makeTemplateObject: __makeTemplateObject,\r\n    __importStar: __importStar,\r\n    __importDefault: __importDefault,\r\n    __classPrivateFieldGet: __classPrivateFieldGet,\r\n    __classPrivateFieldSet: __classPrivateFieldSet,\r\n    __classPrivateFieldIn: __classPrivateFieldIn,\r\n    __addDisposableResource: __addDisposableResource,\r\n    __disposeResources: __disposeResources,\r\n    __rewriteRelativeImportExtension: __rewriteRelativeImportExtension,\r\n});\r\n","module.exports = require('./lib/tunnel');\n","'use strict';\n\nvar net = require('net');\nvar tls = require('tls');\nvar http = require('http');\nvar https = require('https');\nvar events = require('events');\nvar assert = require('assert');\nvar util = require('util');\n\n\nexports.httpOverHttp = httpOverHttp;\nexports.httpsOverHttp = httpsOverHttp;\nexports.httpOverHttps = httpOverHttps;\nexports.httpsOverHttps = httpsOverHttps;\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  return agent;\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  return agent;\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this;\n  self.options = options || {};\n  self.proxyOptions = self.options.proxy || {};\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets;\n  self.requests = [];\n  self.sockets = [];\n\n  self.on('free', function onFree(socket, host, port, localAddress) {\n    var options = toOptions(host, port, localAddress);\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i];\n      if (pending.host === options.host && pending.port === options.port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1);\n        pending.request.onSocket(socket);\n        return;\n      }\n    }\n    socket.destroy();\n    self.removeSocket(socket);\n  });\n}\nutil.inherits(TunnelingAgent, events.EventEmitter);\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port, localAddress) {\n  var self = this;\n  var options = mergeOptions({request: req}, self.options, toOptions(host, port, localAddress));\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push(options);\n    return;\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket(options, function(socket) {\n    socket.on('free', onFree);\n    socket.on('close', onCloseOrRemove);\n    socket.on('agentRemove', onCloseOrRemove);\n    req.onSocket(socket);\n\n    function onFree() {\n      self.emit('free', socket, options);\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket(socket);\n      socket.removeListener('free', onFree);\n      socket.removeListener('close', onCloseOrRemove);\n      socket.removeListener('agentRemove', onCloseOrRemove);\n    }\n  });\n};\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this;\n  var placeholder = {};\n  self.sockets.push(placeholder);\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, {\n    method: 'CONNECT',\n    path: options.host + ':' + options.port,\n    agent: false,\n    headers: {\n      host: options.host + ':' + options.port\n    }\n  });\n  if (options.localAddress) {\n    connectOptions.localAddress = options.localAddress;\n  }\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {};\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64');\n  }\n\n  debug('making CONNECT request');\n  var connectReq = self.request(connectOptions);\n  connectReq.useChunkedEncodingByDefault = false; // for v0.6\n  connectReq.once('response', onResponse); // for v0.6\n  connectReq.once('upgrade', onUpgrade);   // for v0.6\n  connectReq.once('connect', onConnect);   // for v0.7 or later\n  connectReq.once('error', onError);\n  connectReq.end();\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true;\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head);\n    });\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners();\n    socket.removeAllListeners();\n\n    if (res.statusCode !== 200) {\n      debug('tunneling socket could not be established, statusCode=%d',\n        res.statusCode);\n      socket.destroy();\n      var error = new Error('tunneling socket could not be established, ' +\n        'statusCode=' + res.statusCode);\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    if (head.length > 0) {\n      debug('got illegal response body from proxy');\n      socket.destroy();\n      var error = new Error('got illegal response body from proxy');\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    debug('tunneling connection has established');\n    self.sockets[self.sockets.indexOf(placeholder)] = socket;\n    return cb(socket);\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners();\n\n    debug('tunneling socket could not be established, cause=%s\\n',\n          cause.message, cause.stack);\n    var error = new Error('tunneling socket could not be established, ' +\n                          'cause=' + cause.message);\n    error.code = 'ECONNRESET';\n    options.request.emit('error', error);\n    self.removeSocket(placeholder);\n  }\n};\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) {\n    return;\n  }\n  this.sockets.splice(pos, 1);\n\n  var pending = this.requests.shift();\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket);\n    });\n  }\n};\n\nfunction createSecureSocket(options, cb) {\n  var self = this;\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    var hostHeader = options.request.getHeader('host');\n    var tlsOptions = mergeOptions({}, self.options, {\n      socket: socket,\n      servername: hostHeader ? hostHeader.replace(/:.*$/, '') : options.host\n    });\n\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, tlsOptions);\n    self.sockets[self.sockets.indexOf(socket)] = secureSocket;\n    cb(secureSocket);\n  });\n}\n\n\nfunction toOptions(host, port, localAddress) {\n  if (typeof host === 'string') { // since v0.10\n    return {\n      host: host,\n      port: port,\n      localAddress: localAddress\n    };\n  }\n  return host; // for v0.11 or later\n}\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i];\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides);\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j];\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k];\n        }\n      }\n    }\n  }\n  return target;\n}\n\n\nvar debug;\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments);\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0];\n    } else {\n      args.unshift('TUNNEL:');\n    }\n    console.error.apply(console, args);\n  }\n} else {\n  debug = function() {};\n}\nexports.debug = debug; // for test\n","'use strict'\n\nconst Client = require('./lib/dispatcher/client')\nconst Dispatcher = require('./lib/dispatcher/dispatcher')\nconst Pool = require('./lib/dispatcher/pool')\nconst BalancedPool = require('./lib/dispatcher/balanced-pool')\nconst Agent = require('./lib/dispatcher/agent')\nconst ProxyAgent = require('./lib/dispatcher/proxy-agent')\nconst EnvHttpProxyAgent = require('./lib/dispatcher/env-http-proxy-agent')\nconst RetryAgent = require('./lib/dispatcher/retry-agent')\nconst errors = require('./lib/core/errors')\nconst util = require('./lib/core/util')\nconst { InvalidArgumentError } = errors\nconst api = require('./lib/api')\nconst buildConnector = require('./lib/core/connect')\nconst MockClient = require('./lib/mock/mock-client')\nconst MockAgent = require('./lib/mock/mock-agent')\nconst MockPool = require('./lib/mock/mock-pool')\nconst mockErrors = require('./lib/mock/mock-errors')\nconst RetryHandler = require('./lib/handler/retry-handler')\nconst { getGlobalDispatcher, setGlobalDispatcher } = require('./lib/global')\nconst DecoratorHandler = require('./lib/handler/decorator-handler')\nconst RedirectHandler = require('./lib/handler/redirect-handler')\nconst createRedirectInterceptor = require('./lib/interceptor/redirect-interceptor')\n\nObject.assign(Dispatcher.prototype, api)\n\nmodule.exports.Dispatcher = Dispatcher\nmodule.exports.Client = Client\nmodule.exports.Pool = Pool\nmodule.exports.BalancedPool = BalancedPool\nmodule.exports.Agent = Agent\nmodule.exports.ProxyAgent = ProxyAgent\nmodule.exports.EnvHttpProxyAgent = EnvHttpProxyAgent\nmodule.exports.RetryAgent = RetryAgent\nmodule.exports.RetryHandler = RetryHandler\n\nmodule.exports.DecoratorHandler = DecoratorHandler\nmodule.exports.RedirectHandler = RedirectHandler\nmodule.exports.createRedirectInterceptor = createRedirectInterceptor\nmodule.exports.interceptors = {\n  redirect: require('./lib/interceptor/redirect'),\n  retry: require('./lib/interceptor/retry'),\n  dump: require('./lib/interceptor/dump'),\n  dns: require('./lib/interceptor/dns')\n}\n\nmodule.exports.buildConnector = buildConnector\nmodule.exports.errors = errors\nmodule.exports.util = {\n  parseHeaders: util.parseHeaders,\n  headerNameToString: util.headerNameToString\n}\n\nfunction makeDispatcher (fn) {\n  return (url, opts, handler) => {\n    if (typeof opts === 'function') {\n      handler = opts\n      opts = null\n    }\n\n    if (!url || (typeof url !== 'string' && typeof url !== 'object' && !(url instanceof URL))) {\n      throw new InvalidArgumentError('invalid url')\n    }\n\n    if (opts != null && typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (opts && opts.path != null) {\n      if (typeof opts.path !== 'string') {\n        throw new InvalidArgumentError('invalid opts.path')\n      }\n\n      let path = opts.path\n      if (!opts.path.startsWith('/')) {\n        path = `/${path}`\n      }\n\n      url = new URL(util.parseOrigin(url).origin + path)\n    } else {\n      if (!opts) {\n        opts = typeof url === 'object' ? url : {}\n      }\n\n      url = util.parseURL(url)\n    }\n\n    const { agent, dispatcher = getGlobalDispatcher() } = opts\n\n    if (agent) {\n      throw new InvalidArgumentError('unsupported opts.agent. Did you mean opts.client?')\n    }\n\n    return fn.call(dispatcher, {\n      ...opts,\n      origin: url.origin,\n      path: url.search ? `${url.pathname}${url.search}` : url.pathname,\n      method: opts.method || (opts.body ? 'PUT' : 'GET')\n    }, handler)\n  }\n}\n\nmodule.exports.setGlobalDispatcher = setGlobalDispatcher\nmodule.exports.getGlobalDispatcher = getGlobalDispatcher\n\nconst fetchImpl = require('./lib/web/fetch').fetch\nmodule.exports.fetch = async function fetch (init, options = undefined) {\n  try {\n    return await fetchImpl(init, options)\n  } catch (err) {\n    if (err && typeof err === 'object') {\n      Error.captureStackTrace(err)\n    }\n\n    throw err\n  }\n}\nmodule.exports.Headers = require('./lib/web/fetch/headers').Headers\nmodule.exports.Response = require('./lib/web/fetch/response').Response\nmodule.exports.Request = require('./lib/web/fetch/request').Request\nmodule.exports.FormData = require('./lib/web/fetch/formdata').FormData\nmodule.exports.File = globalThis.File ?? require('node:buffer').File\nmodule.exports.FileReader = require('./lib/web/fileapi/filereader').FileReader\n\nconst { setGlobalOrigin, getGlobalOrigin } = require('./lib/web/fetch/global')\n\nmodule.exports.setGlobalOrigin = setGlobalOrigin\nmodule.exports.getGlobalOrigin = getGlobalOrigin\n\nconst { CacheStorage } = require('./lib/web/cache/cachestorage')\nconst { kConstruct } = require('./lib/web/cache/symbols')\n\n// Cache & CacheStorage are tightly coupled with fetch. Even if it may run\n// in an older version of Node, it doesn't have any use without fetch.\nmodule.exports.caches = new CacheStorage(kConstruct)\n\nconst { deleteCookie, getCookies, getSetCookies, setCookie } = require('./lib/web/cookies')\n\nmodule.exports.deleteCookie = deleteCookie\nmodule.exports.getCookies = getCookies\nmodule.exports.getSetCookies = getSetCookies\nmodule.exports.setCookie = setCookie\n\nconst { parseMIMEType, serializeAMimeType } = require('./lib/web/fetch/data-url')\n\nmodule.exports.parseMIMEType = parseMIMEType\nmodule.exports.serializeAMimeType = serializeAMimeType\n\nconst { CloseEvent, ErrorEvent, MessageEvent } = require('./lib/web/websocket/events')\nmodule.exports.WebSocket = require('./lib/web/websocket/websocket').WebSocket\nmodule.exports.CloseEvent = CloseEvent\nmodule.exports.ErrorEvent = ErrorEvent\nmodule.exports.MessageEvent = MessageEvent\n\nmodule.exports.request = makeDispatcher(api.request)\nmodule.exports.stream = makeDispatcher(api.stream)\nmodule.exports.pipeline = makeDispatcher(api.pipeline)\nmodule.exports.connect = makeDispatcher(api.connect)\nmodule.exports.upgrade = makeDispatcher(api.upgrade)\n\nmodule.exports.MockClient = MockClient\nmodule.exports.MockPool = MockPool\nmodule.exports.MockAgent = MockAgent\nmodule.exports.mockErrors = mockErrors\n\nconst { EventSource } = require('./lib/web/eventsource/eventsource')\n\nmodule.exports.EventSource = EventSource\n","const { addAbortListener } = require('../core/util')\nconst { RequestAbortedError } = require('../core/errors')\n\nconst kListener = Symbol('kListener')\nconst kSignal = Symbol('kSignal')\n\nfunction abort (self) {\n  if (self.abort) {\n    self.abort(self[kSignal]?.reason)\n  } else {\n    self.reason = self[kSignal]?.reason ?? new RequestAbortedError()\n  }\n  removeSignal(self)\n}\n\nfunction addSignal (self, signal) {\n  self.reason = null\n\n  self[kSignal] = null\n  self[kListener] = null\n\n  if (!signal) {\n    return\n  }\n\n  if (signal.aborted) {\n    abort(self)\n    return\n  }\n\n  self[kSignal] = signal\n  self[kListener] = () => {\n    abort(self)\n  }\n\n  addAbortListener(self[kSignal], self[kListener])\n}\n\nfunction removeSignal (self) {\n  if (!self[kSignal]) {\n    return\n  }\n\n  if ('removeEventListener' in self[kSignal]) {\n    self[kSignal].removeEventListener('abort', self[kListener])\n  } else {\n    self[kSignal].removeListener('abort', self[kListener])\n  }\n\n  self[kSignal] = null\n  self[kListener] = null\n}\n\nmodule.exports = {\n  addSignal,\n  removeSignal\n}\n","'use strict'\n\nconst assert = require('node:assert')\nconst { AsyncResource } = require('node:async_hooks')\nconst { InvalidArgumentError, SocketError } = require('../core/errors')\nconst util = require('../core/util')\nconst { addSignal, removeSignal } = require('./abort-signal')\n\nclass ConnectHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    const { signal, opaque, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    super('UNDICI_CONNECT')\n\n    this.opaque = opaque || null\n    this.responseHeaders = responseHeaders || null\n    this.callback = callback\n    this.abort = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (this.reason) {\n      abort(this.reason)\n      return\n    }\n\n    assert(this.callback)\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders () {\n    throw new SocketError('bad connect', null)\n  }\n\n  onUpgrade (statusCode, rawHeaders, socket) {\n    const { callback, opaque, context } = this\n\n    removeSignal(this)\n\n    this.callback = null\n\n    let headers = rawHeaders\n    // Indicates is an HTTP2Session\n    if (headers != null) {\n      headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n    }\n\n    this.runInAsyncScope(callback, null, null, {\n      statusCode,\n      headers,\n      socket,\n      opaque,\n      context\n    })\n  }\n\n  onError (err) {\n    const { callback, opaque } = this\n\n    removeSignal(this)\n\n    if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n  }\n}\n\nfunction connect (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      connect.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    const connectHandler = new ConnectHandler(opts, callback)\n    this.dispatch({ ...opts, method: 'CONNECT' }, connectHandler)\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts?.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = connect\n","'use strict'\n\nconst {\n  Readable,\n  Duplex,\n  PassThrough\n} = require('node:stream')\nconst {\n  InvalidArgumentError,\n  InvalidReturnValueError,\n  RequestAbortedError\n} = require('../core/errors')\nconst util = require('../core/util')\nconst { AsyncResource } = require('node:async_hooks')\nconst { addSignal, removeSignal } = require('./abort-signal')\nconst assert = require('node:assert')\n\nconst kResume = Symbol('resume')\n\nclass PipelineRequest extends Readable {\n  constructor () {\n    super({ autoDestroy: true })\n\n    this[kResume] = null\n  }\n\n  _read () {\n    const { [kResume]: resume } = this\n\n    if (resume) {\n      this[kResume] = null\n      resume()\n    }\n  }\n\n  _destroy (err, callback) {\n    this._read()\n\n    callback(err)\n  }\n}\n\nclass PipelineResponse extends Readable {\n  constructor (resume) {\n    super({ autoDestroy: true })\n    this[kResume] = resume\n  }\n\n  _read () {\n    this[kResume]()\n  }\n\n  _destroy (err, callback) {\n    if (!err && !this._readableState.endEmitted) {\n      err = new RequestAbortedError()\n    }\n\n    callback(err)\n  }\n}\n\nclass PipelineHandler extends AsyncResource {\n  constructor (opts, handler) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof handler !== 'function') {\n      throw new InvalidArgumentError('invalid handler')\n    }\n\n    const { signal, method, opaque, onInfo, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    if (method === 'CONNECT') {\n      throw new InvalidArgumentError('invalid method')\n    }\n\n    if (onInfo && typeof onInfo !== 'function') {\n      throw new InvalidArgumentError('invalid onInfo callback')\n    }\n\n    super('UNDICI_PIPELINE')\n\n    this.opaque = opaque || null\n    this.responseHeaders = responseHeaders || null\n    this.handler = handler\n    this.abort = null\n    this.context = null\n    this.onInfo = onInfo || null\n\n    this.req = new PipelineRequest().on('error', util.nop)\n\n    this.ret = new Duplex({\n      readableObjectMode: opts.objectMode,\n      autoDestroy: true,\n      read: () => {\n        const { body } = this\n\n        if (body?.resume) {\n          body.resume()\n        }\n      },\n      write: (chunk, encoding, callback) => {\n        const { req } = this\n\n        if (req.push(chunk, encoding) || req._readableState.destroyed) {\n          callback()\n        } else {\n          req[kResume] = callback\n        }\n      },\n      destroy: (err, callback) => {\n        const { body, req, res, ret, abort } = this\n\n        if (!err && !ret._readableState.endEmitted) {\n          err = new RequestAbortedError()\n        }\n\n        if (abort && err) {\n          abort()\n        }\n\n        util.destroy(body, err)\n        util.destroy(req, err)\n        util.destroy(res, err)\n\n        removeSignal(this)\n\n        callback(err)\n      }\n    }).on('prefinish', () => {\n      const { req } = this\n\n      // Node < 15 does not call _final in same tick.\n      req.push(null)\n    })\n\n    this.res = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    const { ret, res } = this\n\n    if (this.reason) {\n      abort(this.reason)\n      return\n    }\n\n    assert(!res, 'pipeline cannot be retried')\n    assert(!ret.destroyed)\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume) {\n    const { opaque, handler, context } = this\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    this.res = new PipelineResponse(resume)\n\n    let body\n    try {\n      this.handler = null\n      const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n      body = this.runInAsyncScope(handler, null, {\n        statusCode,\n        headers,\n        opaque,\n        body: this.res,\n        context\n      })\n    } catch (err) {\n      this.res.on('error', util.nop)\n      throw err\n    }\n\n    if (!body || typeof body.on !== 'function') {\n      throw new InvalidReturnValueError('expected Readable')\n    }\n\n    body\n      .on('data', (chunk) => {\n        const { ret, body } = this\n\n        if (!ret.push(chunk) && body.pause) {\n          body.pause()\n        }\n      })\n      .on('error', (err) => {\n        const { ret } = this\n\n        util.destroy(ret, err)\n      })\n      .on('end', () => {\n        const { ret } = this\n\n        ret.push(null)\n      })\n      .on('close', () => {\n        const { ret } = this\n\n        if (!ret._readableState.ended) {\n          util.destroy(ret, new RequestAbortedError())\n        }\n      })\n\n    this.body = body\n  }\n\n  onData (chunk) {\n    const { res } = this\n    return res.push(chunk)\n  }\n\n  onComplete (trailers) {\n    const { res } = this\n    res.push(null)\n  }\n\n  onError (err) {\n    const { ret } = this\n    this.handler = null\n    util.destroy(ret, err)\n  }\n}\n\nfunction pipeline (opts, handler) {\n  try {\n    const pipelineHandler = new PipelineHandler(opts, handler)\n    this.dispatch({ ...opts, body: pipelineHandler.req }, pipelineHandler)\n    return pipelineHandler.ret\n  } catch (err) {\n    return new PassThrough().destroy(err)\n  }\n}\n\nmodule.exports = pipeline\n","'use strict'\n\nconst assert = require('node:assert')\nconst { Readable } = require('./readable')\nconst { InvalidArgumentError, RequestAbortedError } = require('../core/errors')\nconst util = require('../core/util')\nconst { getResolveErrorBodyCallback } = require('./util')\nconst { AsyncResource } = require('node:async_hooks')\n\nclass RequestHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError, highWaterMark } = opts\n\n    try {\n      if (typeof callback !== 'function') {\n        throw new InvalidArgumentError('invalid callback')\n      }\n\n      if (highWaterMark && (typeof highWaterMark !== 'number' || highWaterMark < 0)) {\n        throw new InvalidArgumentError('invalid highWaterMark')\n      }\n\n      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n      }\n\n      if (method === 'CONNECT') {\n        throw new InvalidArgumentError('invalid method')\n      }\n\n      if (onInfo && typeof onInfo !== 'function') {\n        throw new InvalidArgumentError('invalid onInfo callback')\n      }\n\n      super('UNDICI_REQUEST')\n    } catch (err) {\n      if (util.isStream(body)) {\n        util.destroy(body.on('error', util.nop), err)\n      }\n      throw err\n    }\n\n    this.method = method\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.callback = callback\n    this.res = null\n    this.abort = null\n    this.body = body\n    this.trailers = {}\n    this.context = null\n    this.onInfo = onInfo || null\n    this.throwOnError = throwOnError\n    this.highWaterMark = highWaterMark\n    this.signal = signal\n    this.reason = null\n    this.removeAbortListener = null\n\n    if (util.isStream(body)) {\n      body.on('error', (err) => {\n        this.onError(err)\n      })\n    }\n\n    if (this.signal) {\n      if (this.signal.aborted) {\n        this.reason = this.signal.reason ?? new RequestAbortedError()\n      } else {\n        this.removeAbortListener = util.addAbortListener(this.signal, () => {\n          this.reason = this.signal.reason ?? new RequestAbortedError()\n          if (this.res) {\n            util.destroy(this.res.on('error', util.nop), this.reason)\n          } else if (this.abort) {\n            this.abort(this.reason)\n          }\n\n          if (this.removeAbortListener) {\n            this.res?.off('close', this.removeAbortListener)\n            this.removeAbortListener()\n            this.removeAbortListener = null\n          }\n        })\n      }\n    }\n  }\n\n  onConnect (abort, context) {\n    if (this.reason) {\n      abort(this.reason)\n      return\n    }\n\n    assert(this.callback)\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const { callback, opaque, abort, context, responseHeaders, highWaterMark } = this\n\n    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers\n    const contentType = parsedHeaders['content-type']\n    const contentLength = parsedHeaders['content-length']\n    const res = new Readable({\n      resume,\n      abort,\n      contentType,\n      contentLength: this.method !== 'HEAD' && contentLength\n        ? Number(contentLength)\n        : null,\n      highWaterMark\n    })\n\n    if (this.removeAbortListener) {\n      res.on('close', this.removeAbortListener)\n    }\n\n    this.callback = null\n    this.res = res\n    if (callback !== null) {\n      if (this.throwOnError && statusCode >= 400) {\n        this.runInAsyncScope(getResolveErrorBodyCallback, null,\n          { callback, body: res, contentType, statusCode, statusMessage, headers }\n        )\n      } else {\n        this.runInAsyncScope(callback, null, null, {\n          statusCode,\n          headers,\n          trailers: this.trailers,\n          opaque,\n          body: res,\n          context\n        })\n      }\n    }\n  }\n\n  onData (chunk) {\n    return this.res.push(chunk)\n  }\n\n  onComplete (trailers) {\n    util.parseHeaders(trailers, this.trailers)\n    this.res.push(null)\n  }\n\n  onError (err) {\n    const { res, callback, body, opaque } = this\n\n    if (callback) {\n      // TODO: Does this need queueMicrotask?\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n\n    if (res) {\n      this.res = null\n      // Ensure all queued handlers are invoked before destroying res.\n      queueMicrotask(() => {\n        util.destroy(res, err)\n      })\n    }\n\n    if (body) {\n      this.body = null\n      util.destroy(body, err)\n    }\n\n    if (this.removeAbortListener) {\n      res?.off('close', this.removeAbortListener)\n      this.removeAbortListener()\n      this.removeAbortListener = null\n    }\n  }\n}\n\nfunction request (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      request.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    this.dispatch(opts, new RequestHandler(opts, callback))\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts?.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = request\nmodule.exports.RequestHandler = RequestHandler\n","'use strict'\n\nconst assert = require('node:assert')\nconst { finished, PassThrough } = require('node:stream')\nconst { InvalidArgumentError, InvalidReturnValueError } = require('../core/errors')\nconst util = require('../core/util')\nconst { getResolveErrorBodyCallback } = require('./util')\nconst { AsyncResource } = require('node:async_hooks')\nconst { addSignal, removeSignal } = require('./abort-signal')\n\nclass StreamHandler extends AsyncResource {\n  constructor (opts, factory, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError } = opts\n\n    try {\n      if (typeof callback !== 'function') {\n        throw new InvalidArgumentError('invalid callback')\n      }\n\n      if (typeof factory !== 'function') {\n        throw new InvalidArgumentError('invalid factory')\n      }\n\n      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n      }\n\n      if (method === 'CONNECT') {\n        throw new InvalidArgumentError('invalid method')\n      }\n\n      if (onInfo && typeof onInfo !== 'function') {\n        throw new InvalidArgumentError('invalid onInfo callback')\n      }\n\n      super('UNDICI_STREAM')\n    } catch (err) {\n      if (util.isStream(body)) {\n        util.destroy(body.on('error', util.nop), err)\n      }\n      throw err\n    }\n\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.factory = factory\n    this.callback = callback\n    this.res = null\n    this.abort = null\n    this.context = null\n    this.trailers = null\n    this.body = body\n    this.onInfo = onInfo || null\n    this.throwOnError = throwOnError || false\n\n    if (util.isStream(body)) {\n      body.on('error', (err) => {\n        this.onError(err)\n      })\n    }\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (this.reason) {\n      abort(this.reason)\n      return\n    }\n\n    assert(this.callback)\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const { factory, opaque, context, callback, responseHeaders } = this\n\n    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    this.factory = null\n\n    let res\n\n    if (this.throwOnError && statusCode >= 400) {\n      const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers\n      const contentType = parsedHeaders['content-type']\n      res = new PassThrough()\n\n      this.callback = null\n      this.runInAsyncScope(getResolveErrorBodyCallback, null,\n        { callback, body: res, contentType, statusCode, statusMessage, headers }\n      )\n    } else {\n      if (factory === null) {\n        return\n      }\n\n      res = this.runInAsyncScope(factory, null, {\n        statusCode,\n        headers,\n        opaque,\n        context\n      })\n\n      if (\n        !res ||\n        typeof res.write !== 'function' ||\n        typeof res.end !== 'function' ||\n        typeof res.on !== 'function'\n      ) {\n        throw new InvalidReturnValueError('expected Writable')\n      }\n\n      // TODO: Avoid finished. It registers an unnecessary amount of listeners.\n      finished(res, { readable: false }, (err) => {\n        const { callback, res, opaque, trailers, abort } = this\n\n        this.res = null\n        if (err || !res.readable) {\n          util.destroy(res, err)\n        }\n\n        this.callback = null\n        this.runInAsyncScope(callback, null, err || null, { opaque, trailers })\n\n        if (err) {\n          abort()\n        }\n      })\n    }\n\n    res.on('drain', resume)\n\n    this.res = res\n\n    const needDrain = res.writableNeedDrain !== undefined\n      ? res.writableNeedDrain\n      : res._writableState?.needDrain\n\n    return needDrain !== true\n  }\n\n  onData (chunk) {\n    const { res } = this\n\n    return res ? res.write(chunk) : true\n  }\n\n  onComplete (trailers) {\n    const { res } = this\n\n    removeSignal(this)\n\n    if (!res) {\n      return\n    }\n\n    this.trailers = util.parseHeaders(trailers)\n\n    res.end()\n  }\n\n  onError (err) {\n    const { res, callback, opaque, body } = this\n\n    removeSignal(this)\n\n    this.factory = null\n\n    if (res) {\n      this.res = null\n      util.destroy(res, err)\n    } else if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n\n    if (body) {\n      this.body = null\n      util.destroy(body, err)\n    }\n  }\n}\n\nfunction stream (opts, factory, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      stream.call(this, opts, factory, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    this.dispatch(opts, new StreamHandler(opts, factory, callback))\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts?.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = stream\n","'use strict'\n\nconst { InvalidArgumentError, SocketError } = require('../core/errors')\nconst { AsyncResource } = require('node:async_hooks')\nconst util = require('../core/util')\nconst { addSignal, removeSignal } = require('./abort-signal')\nconst assert = require('node:assert')\n\nclass UpgradeHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    const { signal, opaque, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    super('UNDICI_UPGRADE')\n\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.callback = callback\n    this.abort = null\n    this.context = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (this.reason) {\n      abort(this.reason)\n      return\n    }\n\n    assert(this.callback)\n\n    this.abort = abort\n    this.context = null\n  }\n\n  onHeaders () {\n    throw new SocketError('bad upgrade', null)\n  }\n\n  onUpgrade (statusCode, rawHeaders, socket) {\n    assert(statusCode === 101)\n\n    const { callback, opaque, context } = this\n\n    removeSignal(this)\n\n    this.callback = null\n    const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n    this.runInAsyncScope(callback, null, null, {\n      headers,\n      socket,\n      opaque,\n      context\n    })\n  }\n\n  onError (err) {\n    const { callback, opaque } = this\n\n    removeSignal(this)\n\n    if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n  }\n}\n\nfunction upgrade (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      upgrade.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    const upgradeHandler = new UpgradeHandler(opts, callback)\n    this.dispatch({\n      ...opts,\n      method: opts.method || 'GET',\n      upgrade: opts.protocol || 'Websocket'\n    }, upgradeHandler)\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts?.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = upgrade\n","'use strict'\n\nmodule.exports.request = require('./api-request')\nmodule.exports.stream = require('./api-stream')\nmodule.exports.pipeline = require('./api-pipeline')\nmodule.exports.upgrade = require('./api-upgrade')\nmodule.exports.connect = require('./api-connect')\n","// Ported from https://github.com/nodejs/undici/pull/907\n\n'use strict'\n\nconst assert = require('node:assert')\nconst { Readable } = require('node:stream')\nconst { RequestAbortedError, NotSupportedError, InvalidArgumentError, AbortError } = require('../core/errors')\nconst util = require('../core/util')\nconst { ReadableStreamFrom } = require('../core/util')\n\nconst kConsume = Symbol('kConsume')\nconst kReading = Symbol('kReading')\nconst kBody = Symbol('kBody')\nconst kAbort = Symbol('kAbort')\nconst kContentType = Symbol('kContentType')\nconst kContentLength = Symbol('kContentLength')\n\nconst noop = () => {}\n\nclass BodyReadable extends Readable {\n  constructor ({\n    resume,\n    abort,\n    contentType = '',\n    contentLength,\n    highWaterMark = 64 * 1024 // Same as nodejs fs streams.\n  }) {\n    super({\n      autoDestroy: true,\n      read: resume,\n      highWaterMark\n    })\n\n    this._readableState.dataEmitted = false\n\n    this[kAbort] = abort\n    this[kConsume] = null\n    this[kBody] = null\n    this[kContentType] = contentType\n    this[kContentLength] = contentLength\n\n    // Is stream being consumed through Readable API?\n    // This is an optimization so that we avoid checking\n    // for 'data' and 'readable' listeners in the hot path\n    // inside push().\n    this[kReading] = false\n  }\n\n  destroy (err) {\n    if (!err && !this._readableState.endEmitted) {\n      err = new RequestAbortedError()\n    }\n\n    if (err) {\n      this[kAbort]()\n    }\n\n    return super.destroy(err)\n  }\n\n  _destroy (err, callback) {\n    // Workaround for Node \"bug\". If the stream is destroyed in same\n    // tick as it is created, then a user who is waiting for a\n    // promise (i.e micro tick) for installing a 'error' listener will\n    // never get a chance and will always encounter an unhandled exception.\n    if (!this[kReading]) {\n      setImmediate(() => {\n        callback(err)\n      })\n    } else {\n      callback(err)\n    }\n  }\n\n  on (ev, ...args) {\n    if (ev === 'data' || ev === 'readable') {\n      this[kReading] = true\n    }\n    return super.on(ev, ...args)\n  }\n\n  addListener (ev, ...args) {\n    return this.on(ev, ...args)\n  }\n\n  off (ev, ...args) {\n    const ret = super.off(ev, ...args)\n    if (ev === 'data' || ev === 'readable') {\n      this[kReading] = (\n        this.listenerCount('data') > 0 ||\n        this.listenerCount('readable') > 0\n      )\n    }\n    return ret\n  }\n\n  removeListener (ev, ...args) {\n    return this.off(ev, ...args)\n  }\n\n  push (chunk) {\n    if (this[kConsume] && chunk !== null) {\n      consumePush(this[kConsume], chunk)\n      return this[kReading] ? super.push(chunk) : true\n    }\n    return super.push(chunk)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-text\n  async text () {\n    return consume(this, 'text')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-json\n  async json () {\n    return consume(this, 'json')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-blob\n  async blob () {\n    return consume(this, 'blob')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-bytes\n  async bytes () {\n    return consume(this, 'bytes')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-arraybuffer\n  async arrayBuffer () {\n    return consume(this, 'arrayBuffer')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-formdata\n  async formData () {\n    // TODO: Implement.\n    throw new NotSupportedError()\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-bodyused\n  get bodyUsed () {\n    return util.isDisturbed(this)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-body\n  get body () {\n    if (!this[kBody]) {\n      this[kBody] = ReadableStreamFrom(this)\n      if (this[kConsume]) {\n        // TODO: Is this the best way to force a lock?\n        this[kBody].getReader() // Ensure stream is locked.\n        assert(this[kBody].locked)\n      }\n    }\n    return this[kBody]\n  }\n\n  async dump (opts) {\n    let limit = Number.isFinite(opts?.limit) ? opts.limit : 128 * 1024\n    const signal = opts?.signal\n\n    if (signal != null && (typeof signal !== 'object' || !('aborted' in signal))) {\n      throw new InvalidArgumentError('signal must be an AbortSignal')\n    }\n\n    signal?.throwIfAborted()\n\n    if (this._readableState.closeEmitted) {\n      return null\n    }\n\n    return await new Promise((resolve, reject) => {\n      if (this[kContentLength] > limit) {\n        this.destroy(new AbortError())\n      }\n\n      const onAbort = () => {\n        this.destroy(signal.reason ?? new AbortError())\n      }\n      signal?.addEventListener('abort', onAbort)\n\n      this\n        .on('close', function () {\n          signal?.removeEventListener('abort', onAbort)\n          if (signal?.aborted) {\n            reject(signal.reason ?? new AbortError())\n          } else {\n            resolve(null)\n          }\n        })\n        .on('error', noop)\n        .on('data', function (chunk) {\n          limit -= chunk.length\n          if (limit <= 0) {\n            this.destroy()\n          }\n        })\n        .resume()\n    })\n  }\n}\n\n// https://streams.spec.whatwg.org/#readablestream-locked\nfunction isLocked (self) {\n  // Consume is an implicit lock.\n  return (self[kBody] && self[kBody].locked === true) || self[kConsume]\n}\n\n// https://fetch.spec.whatwg.org/#body-unusable\nfunction isUnusable (self) {\n  return util.isDisturbed(self) || isLocked(self)\n}\n\nasync function consume (stream, type) {\n  assert(!stream[kConsume])\n\n  return new Promise((resolve, reject) => {\n    if (isUnusable(stream)) {\n      const rState = stream._readableState\n      if (rState.destroyed && rState.closeEmitted === false) {\n        stream\n          .on('error', err => {\n            reject(err)\n          })\n          .on('close', () => {\n            reject(new TypeError('unusable'))\n          })\n      } else {\n        reject(rState.errored ?? new TypeError('unusable'))\n      }\n    } else {\n      queueMicrotask(() => {\n        stream[kConsume] = {\n          type,\n          stream,\n          resolve,\n          reject,\n          length: 0,\n          body: []\n        }\n\n        stream\n          .on('error', function (err) {\n            consumeFinish(this[kConsume], err)\n          })\n          .on('close', function () {\n            if (this[kConsume].body !== null) {\n              consumeFinish(this[kConsume], new RequestAbortedError())\n            }\n          })\n\n        consumeStart(stream[kConsume])\n      })\n    }\n  })\n}\n\nfunction consumeStart (consume) {\n  if (consume.body === null) {\n    return\n  }\n\n  const { _readableState: state } = consume.stream\n\n  if (state.bufferIndex) {\n    const start = state.bufferIndex\n    const end = state.buffer.length\n    for (let n = start; n < end; n++) {\n      consumePush(consume, state.buffer[n])\n    }\n  } else {\n    for (const chunk of state.buffer) {\n      consumePush(consume, chunk)\n    }\n  }\n\n  if (state.endEmitted) {\n    consumeEnd(this[kConsume])\n  } else {\n    consume.stream.on('end', function () {\n      consumeEnd(this[kConsume])\n    })\n  }\n\n  consume.stream.resume()\n\n  while (consume.stream.read() != null) {\n    // Loop\n  }\n}\n\n/**\n * @param {Buffer[]} chunks\n * @param {number} length\n */\nfunction chunksDecode (chunks, length) {\n  if (chunks.length === 0 || length === 0) {\n    return ''\n  }\n  const buffer = chunks.length === 1 ? chunks[0] : Buffer.concat(chunks, length)\n  const bufferLength = buffer.length\n\n  // Skip BOM.\n  const start =\n    bufferLength > 2 &&\n    buffer[0] === 0xef &&\n    buffer[1] === 0xbb &&\n    buffer[2] === 0xbf\n      ? 3\n      : 0\n  return buffer.utf8Slice(start, bufferLength)\n}\n\n/**\n * @param {Buffer[]} chunks\n * @param {number} length\n * @returns {Uint8Array}\n */\nfunction chunksConcat (chunks, length) {\n  if (chunks.length === 0 || length === 0) {\n    return new Uint8Array(0)\n  }\n  if (chunks.length === 1) {\n    // fast-path\n    return new Uint8Array(chunks[0])\n  }\n  const buffer = new Uint8Array(Buffer.allocUnsafeSlow(length).buffer)\n\n  let offset = 0\n  for (let i = 0; i < chunks.length; ++i) {\n    const chunk = chunks[i]\n    buffer.set(chunk, offset)\n    offset += chunk.length\n  }\n\n  return buffer\n}\n\nfunction consumeEnd (consume) {\n  const { type, body, resolve, stream, length } = consume\n\n  try {\n    if (type === 'text') {\n      resolve(chunksDecode(body, length))\n    } else if (type === 'json') {\n      resolve(JSON.parse(chunksDecode(body, length)))\n    } else if (type === 'arrayBuffer') {\n      resolve(chunksConcat(body, length).buffer)\n    } else if (type === 'blob') {\n      resolve(new Blob(body, { type: stream[kContentType] }))\n    } else if (type === 'bytes') {\n      resolve(chunksConcat(body, length))\n    }\n\n    consumeFinish(consume)\n  } catch (err) {\n    stream.destroy(err)\n  }\n}\n\nfunction consumePush (consume, chunk) {\n  consume.length += chunk.length\n  consume.body.push(chunk)\n}\n\nfunction consumeFinish (consume, err) {\n  if (consume.body === null) {\n    return\n  }\n\n  if (err) {\n    consume.reject(err)\n  } else {\n    consume.resolve()\n  }\n\n  consume.type = null\n  consume.stream = null\n  consume.resolve = null\n  consume.reject = null\n  consume.length = 0\n  consume.body = null\n}\n\nmodule.exports = { Readable: BodyReadable, chunksDecode }\n","const assert = require('node:assert')\nconst {\n  ResponseStatusCodeError\n} = require('../core/errors')\n\nconst { chunksDecode } = require('./readable')\nconst CHUNK_LIMIT = 128 * 1024\n\nasync function getResolveErrorBodyCallback ({ callback, body, contentType, statusCode, statusMessage, headers }) {\n  assert(body)\n\n  let chunks = []\n  let length = 0\n\n  try {\n    for await (const chunk of body) {\n      chunks.push(chunk)\n      length += chunk.length\n      if (length > CHUNK_LIMIT) {\n        chunks = []\n        length = 0\n        break\n      }\n    }\n  } catch {\n    chunks = []\n    length = 0\n    // Do nothing....\n  }\n\n  const message = `Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`\n\n  if (statusCode === 204 || !contentType || !length) {\n    queueMicrotask(() => callback(new ResponseStatusCodeError(message, statusCode, headers)))\n    return\n  }\n\n  const stackTraceLimit = Error.stackTraceLimit\n  Error.stackTraceLimit = 0\n  let payload\n\n  try {\n    if (isContentTypeApplicationJson(contentType)) {\n      payload = JSON.parse(chunksDecode(chunks, length))\n    } else if (isContentTypeText(contentType)) {\n      payload = chunksDecode(chunks, length)\n    }\n  } catch {\n    // process in a callback to avoid throwing in the microtask queue\n  } finally {\n    Error.stackTraceLimit = stackTraceLimit\n  }\n  queueMicrotask(() => callback(new ResponseStatusCodeError(message, statusCode, headers, payload)))\n}\n\nconst isContentTypeApplicationJson = (contentType) => {\n  return (\n    contentType.length > 15 &&\n    contentType[11] === '/' &&\n    contentType[0] === 'a' &&\n    contentType[1] === 'p' &&\n    contentType[2] === 'p' &&\n    contentType[3] === 'l' &&\n    contentType[4] === 'i' &&\n    contentType[5] === 'c' &&\n    contentType[6] === 'a' &&\n    contentType[7] === 't' &&\n    contentType[8] === 'i' &&\n    contentType[9] === 'o' &&\n    contentType[10] === 'n' &&\n    contentType[12] === 'j' &&\n    contentType[13] === 's' &&\n    contentType[14] === 'o' &&\n    contentType[15] === 'n'\n  )\n}\n\nconst isContentTypeText = (contentType) => {\n  return (\n    contentType.length > 4 &&\n    contentType[4] === '/' &&\n    contentType[0] === 't' &&\n    contentType[1] === 'e' &&\n    contentType[2] === 'x' &&\n    contentType[3] === 't'\n  )\n}\n\nmodule.exports = {\n  getResolveErrorBodyCallback,\n  isContentTypeApplicationJson,\n  isContentTypeText\n}\n","'use strict'\n\nconst net = require('node:net')\nconst assert = require('node:assert')\nconst util = require('./util')\nconst { InvalidArgumentError, ConnectTimeoutError } = require('./errors')\nconst timers = require('../util/timers')\n\nfunction noop () {}\n\nlet tls // include tls conditionally since it is not always available\n\n// TODO: session re-use does not wait for the first\n// connection to resolve the session and might therefore\n// resolve the same servername multiple times even when\n// re-use is enabled.\n\nlet SessionCache\n// FIXME: remove workaround when the Node bug is fixed\n// https://github.com/nodejs/node/issues/49344#issuecomment-1741776308\nif (global.FinalizationRegistry && !(process.env.NODE_V8_COVERAGE || process.env.UNDICI_NO_FG)) {\n  SessionCache = class WeakSessionCache {\n    constructor (maxCachedSessions) {\n      this._maxCachedSessions = maxCachedSessions\n      this._sessionCache = new Map()\n      this._sessionRegistry = new global.FinalizationRegistry((key) => {\n        if (this._sessionCache.size < this._maxCachedSessions) {\n          return\n        }\n\n        const ref = this._sessionCache.get(key)\n        if (ref !== undefined && ref.deref() === undefined) {\n          this._sessionCache.delete(key)\n        }\n      })\n    }\n\n    get (sessionKey) {\n      const ref = this._sessionCache.get(sessionKey)\n      return ref ? ref.deref() : null\n    }\n\n    set (sessionKey, session) {\n      if (this._maxCachedSessions === 0) {\n        return\n      }\n\n      this._sessionCache.set(sessionKey, new WeakRef(session))\n      this._sessionRegistry.register(session, sessionKey)\n    }\n  }\n} else {\n  SessionCache = class SimpleSessionCache {\n    constructor (maxCachedSessions) {\n      this._maxCachedSessions = maxCachedSessions\n      this._sessionCache = new Map()\n    }\n\n    get (sessionKey) {\n      return this._sessionCache.get(sessionKey)\n    }\n\n    set (sessionKey, session) {\n      if (this._maxCachedSessions === 0) {\n        return\n      }\n\n      if (this._sessionCache.size >= this._maxCachedSessions) {\n        // remove the oldest session\n        const { value: oldestKey } = this._sessionCache.keys().next()\n        this._sessionCache.delete(oldestKey)\n      }\n\n      this._sessionCache.set(sessionKey, session)\n    }\n  }\n}\n\nfunction buildConnector ({ allowH2, maxCachedSessions, socketPath, timeout, session: customSession, ...opts }) {\n  if (maxCachedSessions != null && (!Number.isInteger(maxCachedSessions) || maxCachedSessions < 0)) {\n    throw new InvalidArgumentError('maxCachedSessions must be a positive integer or zero')\n  }\n\n  const options = { path: socketPath, ...opts }\n  const sessionCache = new SessionCache(maxCachedSessions == null ? 100 : maxCachedSessions)\n  timeout = timeout == null ? 10e3 : timeout\n  allowH2 = allowH2 != null ? allowH2 : false\n  return function connect ({ hostname, host, protocol, port, servername, localAddress, httpSocket }, callback) {\n    let socket\n    if (protocol === 'https:') {\n      if (!tls) {\n        tls = require('node:tls')\n      }\n      servername = servername || options.servername || util.getServerName(host) || null\n\n      const sessionKey = servername || hostname\n      assert(sessionKey)\n\n      const session = customSession || sessionCache.get(sessionKey) || null\n\n      port = port || 443\n\n      socket = tls.connect({\n        highWaterMark: 16384, // TLS in node can't have bigger HWM anyway...\n        ...options,\n        servername,\n        session,\n        localAddress,\n        // TODO(HTTP/2): Add support for h2c\n        ALPNProtocols: allowH2 ? ['http/1.1', 'h2'] : ['http/1.1'],\n        socket: httpSocket, // upgrade socket connection\n        port,\n        host: hostname\n      })\n\n      socket\n        .on('session', function (session) {\n          // TODO (fix): Can a session become invalid once established? Don't think so?\n          sessionCache.set(sessionKey, session)\n        })\n    } else {\n      assert(!httpSocket, 'httpSocket can only be sent on TLS update')\n\n      port = port || 80\n\n      socket = net.connect({\n        highWaterMark: 64 * 1024, // Same as nodejs fs streams.\n        ...options,\n        localAddress,\n        port,\n        host: hostname\n      })\n    }\n\n    // Set TCP keep alive options on the socket here instead of in connect() for the case of assigning the socket\n    if (options.keepAlive == null || options.keepAlive) {\n      const keepAliveInitialDelay = options.keepAliveInitialDelay === undefined ? 60e3 : options.keepAliveInitialDelay\n      socket.setKeepAlive(true, keepAliveInitialDelay)\n    }\n\n    const clearConnectTimeout = setupConnectTimeout(new WeakRef(socket), { timeout, hostname, port })\n\n    socket\n      .setNoDelay(true)\n      .once(protocol === 'https:' ? 'secureConnect' : 'connect', function () {\n        queueMicrotask(clearConnectTimeout)\n\n        if (callback) {\n          const cb = callback\n          callback = null\n          cb(null, this)\n        }\n      })\n      .on('error', function (err) {\n        queueMicrotask(clearConnectTimeout)\n\n        if (callback) {\n          const cb = callback\n          callback = null\n          cb(err)\n        }\n      })\n\n    return socket\n  }\n}\n\n/**\n * @param {WeakRef<net.Socket>} socketWeakRef\n * @param {object} opts\n * @param {number} opts.timeout\n * @param {string} opts.hostname\n * @param {number} opts.port\n * @returns {() => void}\n */\nconst setupConnectTimeout = process.platform === 'win32'\n  ? (socketWeakRef, opts) => {\n      if (!opts.timeout) {\n        return noop\n      }\n\n      let s1 = null\n      let s2 = null\n      const fastTimer = timers.setFastTimeout(() => {\n      // setImmediate is added to make sure that we prioritize socket error events over timeouts\n        s1 = setImmediate(() => {\n        // Windows needs an extra setImmediate probably due to implementation differences in the socket logic\n          s2 = setImmediate(() => onConnectTimeout(socketWeakRef.deref(), opts))\n        })\n      }, opts.timeout)\n      return () => {\n        timers.clearFastTimeout(fastTimer)\n        clearImmediate(s1)\n        clearImmediate(s2)\n      }\n    }\n  : (socketWeakRef, opts) => {\n      if (!opts.timeout) {\n        return noop\n      }\n\n      let s1 = null\n      const fastTimer = timers.setFastTimeout(() => {\n      // setImmediate is added to make sure that we prioritize socket error events over timeouts\n        s1 = setImmediate(() => {\n          onConnectTimeout(socketWeakRef.deref(), opts)\n        })\n      }, opts.timeout)\n      return () => {\n        timers.clearFastTimeout(fastTimer)\n        clearImmediate(s1)\n      }\n    }\n\n/**\n * @param {net.Socket} socket\n * @param {object} opts\n * @param {number} opts.timeout\n * @param {string} opts.hostname\n * @param {number} opts.port\n */\nfunction onConnectTimeout (socket, opts) {\n  // The socket could be already garbage collected\n  if (socket == null) {\n    return\n  }\n\n  let message = 'Connect Timeout Error'\n  if (Array.isArray(socket.autoSelectFamilyAttemptedAddresses)) {\n    message += ` (attempted addresses: ${socket.autoSelectFamilyAttemptedAddresses.join(', ')},`\n  } else {\n    message += ` (attempted address: ${opts.hostname}:${opts.port},`\n  }\n\n  message += ` timeout: ${opts.timeout}ms)`\n\n  util.destroy(socket, new ConnectTimeoutError(message))\n}\n\nmodule.exports = buildConnector\n","'use strict'\n\n/** @type {Record<string, string | undefined>} */\nconst headerNameLowerCasedRecord = {}\n\n// https://developer.mozilla.org/docs/Web/HTTP/Headers\nconst wellknownHeaderNames = [\n  'Accept',\n  'Accept-Encoding',\n  'Accept-Language',\n  'Accept-Ranges',\n  'Access-Control-Allow-Credentials',\n  'Access-Control-Allow-Headers',\n  'Access-Control-Allow-Methods',\n  'Access-Control-Allow-Origin',\n  'Access-Control-Expose-Headers',\n  'Access-Control-Max-Age',\n  'Access-Control-Request-Headers',\n  'Access-Control-Request-Method',\n  'Age',\n  'Allow',\n  'Alt-Svc',\n  'Alt-Used',\n  'Authorization',\n  'Cache-Control',\n  'Clear-Site-Data',\n  'Connection',\n  'Content-Disposition',\n  'Content-Encoding',\n  'Content-Language',\n  'Content-Length',\n  'Content-Location',\n  'Content-Range',\n  'Content-Security-Policy',\n  'Content-Security-Policy-Report-Only',\n  'Content-Type',\n  'Cookie',\n  'Cross-Origin-Embedder-Policy',\n  'Cross-Origin-Opener-Policy',\n  'Cross-Origin-Resource-Policy',\n  'Date',\n  'Device-Memory',\n  'Downlink',\n  'ECT',\n  'ETag',\n  'Expect',\n  'Expect-CT',\n  'Expires',\n  'Forwarded',\n  'From',\n  'Host',\n  'If-Match',\n  'If-Modified-Since',\n  'If-None-Match',\n  'If-Range',\n  'If-Unmodified-Since',\n  'Keep-Alive',\n  'Last-Modified',\n  'Link',\n  'Location',\n  'Max-Forwards',\n  'Origin',\n  'Permissions-Policy',\n  'Pragma',\n  'Proxy-Authenticate',\n  'Proxy-Authorization',\n  'RTT',\n  'Range',\n  'Referer',\n  'Referrer-Policy',\n  'Refresh',\n  'Retry-After',\n  'Sec-WebSocket-Accept',\n  'Sec-WebSocket-Extensions',\n  'Sec-WebSocket-Key',\n  'Sec-WebSocket-Protocol',\n  'Sec-WebSocket-Version',\n  'Server',\n  'Server-Timing',\n  'Service-Worker-Allowed',\n  'Service-Worker-Navigation-Preload',\n  'Set-Cookie',\n  'SourceMap',\n  'Strict-Transport-Security',\n  'Supports-Loading-Mode',\n  'TE',\n  'Timing-Allow-Origin',\n  'Trailer',\n  'Transfer-Encoding',\n  'Upgrade',\n  'Upgrade-Insecure-Requests',\n  'User-Agent',\n  'Vary',\n  'Via',\n  'WWW-Authenticate',\n  'X-Content-Type-Options',\n  'X-DNS-Prefetch-Control',\n  'X-Frame-Options',\n  'X-Permitted-Cross-Domain-Policies',\n  'X-Powered-By',\n  'X-Requested-With',\n  'X-XSS-Protection'\n]\n\nfor (let i = 0; i < wellknownHeaderNames.length; ++i) {\n  const key = wellknownHeaderNames[i]\n  const lowerCasedKey = key.toLowerCase()\n  headerNameLowerCasedRecord[key] = headerNameLowerCasedRecord[lowerCasedKey] =\n    lowerCasedKey\n}\n\n// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.\nObject.setPrototypeOf(headerNameLowerCasedRecord, null)\n\nmodule.exports = {\n  wellknownHeaderNames,\n  headerNameLowerCasedRecord\n}\n","'use strict'\nconst diagnosticsChannel = require('node:diagnostics_channel')\nconst util = require('node:util')\n\nconst undiciDebugLog = util.debuglog('undici')\nconst fetchDebuglog = util.debuglog('fetch')\nconst websocketDebuglog = util.debuglog('websocket')\nlet isClientSet = false\nconst channels = {\n  // Client\n  beforeConnect: diagnosticsChannel.channel('undici:client:beforeConnect'),\n  connected: diagnosticsChannel.channel('undici:client:connected'),\n  connectError: diagnosticsChannel.channel('undici:client:connectError'),\n  sendHeaders: diagnosticsChannel.channel('undici:client:sendHeaders'),\n  // Request\n  create: diagnosticsChannel.channel('undici:request:create'),\n  bodySent: diagnosticsChannel.channel('undici:request:bodySent'),\n  headers: diagnosticsChannel.channel('undici:request:headers'),\n  trailers: diagnosticsChannel.channel('undici:request:trailers'),\n  error: diagnosticsChannel.channel('undici:request:error'),\n  // WebSocket\n  open: diagnosticsChannel.channel('undici:websocket:open'),\n  close: diagnosticsChannel.channel('undici:websocket:close'),\n  socketError: diagnosticsChannel.channel('undici:websocket:socket_error'),\n  ping: diagnosticsChannel.channel('undici:websocket:ping'),\n  pong: diagnosticsChannel.channel('undici:websocket:pong')\n}\n\nif (undiciDebugLog.enabled || fetchDebuglog.enabled) {\n  const debuglog = fetchDebuglog.enabled ? fetchDebuglog : undiciDebugLog\n\n  // Track all Client events\n  diagnosticsChannel.channel('undici:client:beforeConnect').subscribe(evt => {\n    const {\n      connectParams: { version, protocol, port, host }\n    } = evt\n    debuglog(\n      'connecting to %s using %s%s',\n      `${host}${port ? `:${port}` : ''}`,\n      protocol,\n      version\n    )\n  })\n\n  diagnosticsChannel.channel('undici:client:connected').subscribe(evt => {\n    const {\n      connectParams: { version, protocol, port, host }\n    } = evt\n    debuglog(\n      'connected to %s using %s%s',\n      `${host}${port ? `:${port}` : ''}`,\n      protocol,\n      version\n    )\n  })\n\n  diagnosticsChannel.channel('undici:client:connectError').subscribe(evt => {\n    const {\n      connectParams: { version, protocol, port, host },\n      error\n    } = evt\n    debuglog(\n      'connection to %s using %s%s errored - %s',\n      `${host}${port ? `:${port}` : ''}`,\n      protocol,\n      version,\n      error.message\n    )\n  })\n\n  diagnosticsChannel.channel('undici:client:sendHeaders').subscribe(evt => {\n    const {\n      request: { method, path, origin }\n    } = evt\n    debuglog('sending request to %s %s/%s', method, origin, path)\n  })\n\n  // Track Request events\n  diagnosticsChannel.channel('undici:request:headers').subscribe(evt => {\n    const {\n      request: { method, path, origin },\n      response: { statusCode }\n    } = evt\n    debuglog(\n      'received response to %s %s/%s - HTTP %d',\n      method,\n      origin,\n      path,\n      statusCode\n    )\n  })\n\n  diagnosticsChannel.channel('undici:request:trailers').subscribe(evt => {\n    const {\n      request: { method, path, origin }\n    } = evt\n    debuglog('trailers received from %s %s/%s', method, origin, path)\n  })\n\n  diagnosticsChannel.channel('undici:request:error').subscribe(evt => {\n    const {\n      request: { method, path, origin },\n      error\n    } = evt\n    debuglog(\n      'request to %s %s/%s errored - %s',\n      method,\n      origin,\n      path,\n      error.message\n    )\n  })\n\n  isClientSet = true\n}\n\nif (websocketDebuglog.enabled) {\n  if (!isClientSet) {\n    const debuglog = undiciDebugLog.enabled ? undiciDebugLog : websocketDebuglog\n    diagnosticsChannel.channel('undici:client:beforeConnect').subscribe(evt => {\n      const {\n        connectParams: { version, protocol, port, host }\n      } = evt\n      debuglog(\n        'connecting to %s%s using %s%s',\n        host,\n        port ? `:${port}` : '',\n        protocol,\n        version\n      )\n    })\n\n    diagnosticsChannel.channel('undici:client:connected').subscribe(evt => {\n      const {\n        connectParams: { version, protocol, port, host }\n      } = evt\n      debuglog(\n        'connected to %s%s using %s%s',\n        host,\n        port ? `:${port}` : '',\n        protocol,\n        version\n      )\n    })\n\n    diagnosticsChannel.channel('undici:client:connectError').subscribe(evt => {\n      const {\n        connectParams: { version, protocol, port, host },\n        error\n      } = evt\n      debuglog(\n        'connection to %s%s using %s%s errored - %s',\n        host,\n        port ? `:${port}` : '',\n        protocol,\n        version,\n        error.message\n      )\n    })\n\n    diagnosticsChannel.channel('undici:client:sendHeaders').subscribe(evt => {\n      const {\n        request: { method, path, origin }\n      } = evt\n      debuglog('sending request to %s %s/%s', method, origin, path)\n    })\n  }\n\n  // Track all WebSocket events\n  diagnosticsChannel.channel('undici:websocket:open').subscribe(evt => {\n    const {\n      address: { address, port }\n    } = evt\n    websocketDebuglog('connection opened %s%s', address, port ? `:${port}` : '')\n  })\n\n  diagnosticsChannel.channel('undici:websocket:close').subscribe(evt => {\n    const { websocket, code, reason } = evt\n    websocketDebuglog(\n      'closed connection to %s - %s %s',\n      websocket.url,\n      code,\n      reason\n    )\n  })\n\n  diagnosticsChannel.channel('undici:websocket:socket_error').subscribe(err => {\n    websocketDebuglog('connection errored - %s', err.message)\n  })\n\n  diagnosticsChannel.channel('undici:websocket:ping').subscribe(evt => {\n    websocketDebuglog('ping received')\n  })\n\n  diagnosticsChannel.channel('undici:websocket:pong').subscribe(evt => {\n    websocketDebuglog('pong received')\n  })\n}\n\nmodule.exports = {\n  channels\n}\n","'use strict'\n\nconst kUndiciError = Symbol.for('undici.error.UND_ERR')\nclass UndiciError extends Error {\n  constructor (message) {\n    super(message)\n    this.name = 'UndiciError'\n    this.code = 'UND_ERR'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kUndiciError] === true\n  }\n\n  [kUndiciError] = true\n}\n\nconst kConnectTimeoutError = Symbol.for('undici.error.UND_ERR_CONNECT_TIMEOUT')\nclass ConnectTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'ConnectTimeoutError'\n    this.message = message || 'Connect Timeout Error'\n    this.code = 'UND_ERR_CONNECT_TIMEOUT'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kConnectTimeoutError] === true\n  }\n\n  [kConnectTimeoutError] = true\n}\n\nconst kHeadersTimeoutError = Symbol.for('undici.error.UND_ERR_HEADERS_TIMEOUT')\nclass HeadersTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'HeadersTimeoutError'\n    this.message = message || 'Headers Timeout Error'\n    this.code = 'UND_ERR_HEADERS_TIMEOUT'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kHeadersTimeoutError] === true\n  }\n\n  [kHeadersTimeoutError] = true\n}\n\nconst kHeadersOverflowError = Symbol.for('undici.error.UND_ERR_HEADERS_OVERFLOW')\nclass HeadersOverflowError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'HeadersOverflowError'\n    this.message = message || 'Headers Overflow Error'\n    this.code = 'UND_ERR_HEADERS_OVERFLOW'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kHeadersOverflowError] === true\n  }\n\n  [kHeadersOverflowError] = true\n}\n\nconst kBodyTimeoutError = Symbol.for('undici.error.UND_ERR_BODY_TIMEOUT')\nclass BodyTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'BodyTimeoutError'\n    this.message = message || 'Body Timeout Error'\n    this.code = 'UND_ERR_BODY_TIMEOUT'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kBodyTimeoutError] === true\n  }\n\n  [kBodyTimeoutError] = true\n}\n\nconst kResponseStatusCodeError = Symbol.for('undici.error.UND_ERR_RESPONSE_STATUS_CODE')\nclass ResponseStatusCodeError extends UndiciError {\n  constructor (message, statusCode, headers, body) {\n    super(message)\n    this.name = 'ResponseStatusCodeError'\n    this.message = message || 'Response Status Code Error'\n    this.code = 'UND_ERR_RESPONSE_STATUS_CODE'\n    this.body = body\n    this.status = statusCode\n    this.statusCode = statusCode\n    this.headers = headers\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kResponseStatusCodeError] === true\n  }\n\n  [kResponseStatusCodeError] = true\n}\n\nconst kInvalidArgumentError = Symbol.for('undici.error.UND_ERR_INVALID_ARG')\nclass InvalidArgumentError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'InvalidArgumentError'\n    this.message = message || 'Invalid Argument Error'\n    this.code = 'UND_ERR_INVALID_ARG'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kInvalidArgumentError] === true\n  }\n\n  [kInvalidArgumentError] = true\n}\n\nconst kInvalidReturnValueError = Symbol.for('undici.error.UND_ERR_INVALID_RETURN_VALUE')\nclass InvalidReturnValueError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'InvalidReturnValueError'\n    this.message = message || 'Invalid Return Value Error'\n    this.code = 'UND_ERR_INVALID_RETURN_VALUE'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kInvalidReturnValueError] === true\n  }\n\n  [kInvalidReturnValueError] = true\n}\n\nconst kAbortError = Symbol.for('undici.error.UND_ERR_ABORT')\nclass AbortError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'AbortError'\n    this.message = message || 'The operation was aborted'\n    this.code = 'UND_ERR_ABORT'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kAbortError] === true\n  }\n\n  [kAbortError] = true\n}\n\nconst kRequestAbortedError = Symbol.for('undici.error.UND_ERR_ABORTED')\nclass RequestAbortedError extends AbortError {\n  constructor (message) {\n    super(message)\n    this.name = 'AbortError'\n    this.message = message || 'Request aborted'\n    this.code = 'UND_ERR_ABORTED'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kRequestAbortedError] === true\n  }\n\n  [kRequestAbortedError] = true\n}\n\nconst kInformationalError = Symbol.for('undici.error.UND_ERR_INFO')\nclass InformationalError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'InformationalError'\n    this.message = message || 'Request information'\n    this.code = 'UND_ERR_INFO'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kInformationalError] === true\n  }\n\n  [kInformationalError] = true\n}\n\nconst kRequestContentLengthMismatchError = Symbol.for('undici.error.UND_ERR_REQ_CONTENT_LENGTH_MISMATCH')\nclass RequestContentLengthMismatchError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'RequestContentLengthMismatchError'\n    this.message = message || 'Request body length does not match content-length header'\n    this.code = 'UND_ERR_REQ_CONTENT_LENGTH_MISMATCH'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kRequestContentLengthMismatchError] === true\n  }\n\n  [kRequestContentLengthMismatchError] = true\n}\n\nconst kResponseContentLengthMismatchError = Symbol.for('undici.error.UND_ERR_RES_CONTENT_LENGTH_MISMATCH')\nclass ResponseContentLengthMismatchError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'ResponseContentLengthMismatchError'\n    this.message = message || 'Response body length does not match content-length header'\n    this.code = 'UND_ERR_RES_CONTENT_LENGTH_MISMATCH'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kResponseContentLengthMismatchError] === true\n  }\n\n  [kResponseContentLengthMismatchError] = true\n}\n\nconst kClientDestroyedError = Symbol.for('undici.error.UND_ERR_DESTROYED')\nclass ClientDestroyedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'ClientDestroyedError'\n    this.message = message || 'The client is destroyed'\n    this.code = 'UND_ERR_DESTROYED'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kClientDestroyedError] === true\n  }\n\n  [kClientDestroyedError] = true\n}\n\nconst kClientClosedError = Symbol.for('undici.error.UND_ERR_CLOSED')\nclass ClientClosedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'ClientClosedError'\n    this.message = message || 'The client is closed'\n    this.code = 'UND_ERR_CLOSED'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kClientClosedError] === true\n  }\n\n  [kClientClosedError] = true\n}\n\nconst kSocketError = Symbol.for('undici.error.UND_ERR_SOCKET')\nclass SocketError extends UndiciError {\n  constructor (message, socket) {\n    super(message)\n    this.name = 'SocketError'\n    this.message = message || 'Socket error'\n    this.code = 'UND_ERR_SOCKET'\n    this.socket = socket\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kSocketError] === true\n  }\n\n  [kSocketError] = true\n}\n\nconst kNotSupportedError = Symbol.for('undici.error.UND_ERR_NOT_SUPPORTED')\nclass NotSupportedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'NotSupportedError'\n    this.message = message || 'Not supported error'\n    this.code = 'UND_ERR_NOT_SUPPORTED'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kNotSupportedError] === true\n  }\n\n  [kNotSupportedError] = true\n}\n\nconst kBalancedPoolMissingUpstreamError = Symbol.for('undici.error.UND_ERR_BPL_MISSING_UPSTREAM')\nclass BalancedPoolMissingUpstreamError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'MissingUpstreamError'\n    this.message = message || 'No upstream has been added to the BalancedPool'\n    this.code = 'UND_ERR_BPL_MISSING_UPSTREAM'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kBalancedPoolMissingUpstreamError] === true\n  }\n\n  [kBalancedPoolMissingUpstreamError] = true\n}\n\nconst kHTTPParserError = Symbol.for('undici.error.UND_ERR_HTTP_PARSER')\nclass HTTPParserError extends Error {\n  constructor (message, code, data) {\n    super(message)\n    this.name = 'HTTPParserError'\n    this.code = code ? `HPE_${code}` : undefined\n    this.data = data ? data.toString() : undefined\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kHTTPParserError] === true\n  }\n\n  [kHTTPParserError] = true\n}\n\nconst kResponseExceededMaxSizeError = Symbol.for('undici.error.UND_ERR_RES_EXCEEDED_MAX_SIZE')\nclass ResponseExceededMaxSizeError extends UndiciError {\n  constructor (message) {\n    super(message)\n    this.name = 'ResponseExceededMaxSizeError'\n    this.message = message || 'Response content exceeded max size'\n    this.code = 'UND_ERR_RES_EXCEEDED_MAX_SIZE'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kResponseExceededMaxSizeError] === true\n  }\n\n  [kResponseExceededMaxSizeError] = true\n}\n\nconst kRequestRetryError = Symbol.for('undici.error.UND_ERR_REQ_RETRY')\nclass RequestRetryError extends UndiciError {\n  constructor (message, code, { headers, data }) {\n    super(message)\n    this.name = 'RequestRetryError'\n    this.message = message || 'Request retry error'\n    this.code = 'UND_ERR_REQ_RETRY'\n    this.statusCode = code\n    this.data = data\n    this.headers = headers\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kRequestRetryError] === true\n  }\n\n  [kRequestRetryError] = true\n}\n\nconst kResponseError = Symbol.for('undici.error.UND_ERR_RESPONSE')\nclass ResponseError extends UndiciError {\n  constructor (message, code, { headers, data }) {\n    super(message)\n    this.name = 'ResponseError'\n    this.message = message || 'Response error'\n    this.code = 'UND_ERR_RESPONSE'\n    this.statusCode = code\n    this.data = data\n    this.headers = headers\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kResponseError] === true\n  }\n\n  [kResponseError] = true\n}\n\nconst kSecureProxyConnectionError = Symbol.for('undici.error.UND_ERR_PRX_TLS')\nclass SecureProxyConnectionError extends UndiciError {\n  constructor (cause, message, options) {\n    super(message, { cause, ...(options ?? {}) })\n    this.name = 'SecureProxyConnectionError'\n    this.message = message || 'Secure Proxy Connection failed'\n    this.code = 'UND_ERR_PRX_TLS'\n    this.cause = cause\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kSecureProxyConnectionError] === true\n  }\n\n  [kSecureProxyConnectionError] = true\n}\n\nmodule.exports = {\n  AbortError,\n  HTTPParserError,\n  UndiciError,\n  HeadersTimeoutError,\n  HeadersOverflowError,\n  BodyTimeoutError,\n  RequestContentLengthMismatchError,\n  ConnectTimeoutError,\n  ResponseStatusCodeError,\n  InvalidArgumentError,\n  InvalidReturnValueError,\n  RequestAbortedError,\n  ClientDestroyedError,\n  ClientClosedError,\n  InformationalError,\n  SocketError,\n  NotSupportedError,\n  ResponseContentLengthMismatchError,\n  BalancedPoolMissingUpstreamError,\n  ResponseExceededMaxSizeError,\n  RequestRetryError,\n  ResponseError,\n  SecureProxyConnectionError\n}\n","'use strict'\n\nconst {\n  InvalidArgumentError,\n  NotSupportedError\n} = require('./errors')\nconst assert = require('node:assert')\nconst {\n  isValidHTTPToken,\n  isValidHeaderValue,\n  isStream,\n  destroy,\n  isBuffer,\n  isFormDataLike,\n  isIterable,\n  isBlobLike,\n  buildURL,\n  validateHandler,\n  getServerName,\n  normalizedMethodRecords\n} = require('./util')\nconst { channels } = require('./diagnostics.js')\nconst { headerNameLowerCasedRecord } = require('./constants')\n\n// Verifies that a given path is valid does not contain control chars \\x00 to \\x20\nconst invalidPathRegex = /[^\\u0021-\\u00ff]/\n\nconst kHandler = Symbol('handler')\n\nclass Request {\n  constructor (origin, {\n    path,\n    method,\n    body,\n    headers,\n    query,\n    idempotent,\n    blocking,\n    upgrade,\n    headersTimeout,\n    bodyTimeout,\n    reset,\n    throwOnError,\n    expectContinue,\n    servername\n  }, handler) {\n    if (typeof path !== 'string') {\n      throw new InvalidArgumentError('path must be a string')\n    } else if (\n      path[0] !== '/' &&\n      !(path.startsWith('http://') || path.startsWith('https://')) &&\n      method !== 'CONNECT'\n    ) {\n      throw new InvalidArgumentError('path must be an absolute URL or start with a slash')\n    } else if (invalidPathRegex.test(path)) {\n      throw new InvalidArgumentError('invalid request path')\n    }\n\n    if (typeof method !== 'string') {\n      throw new InvalidArgumentError('method must be a string')\n    } else if (normalizedMethodRecords[method] === undefined && !isValidHTTPToken(method)) {\n      throw new InvalidArgumentError('invalid request method')\n    }\n\n    if (upgrade && typeof upgrade !== 'string') {\n      throw new InvalidArgumentError('upgrade must be a string')\n    }\n\n    if (headersTimeout != null && (!Number.isFinite(headersTimeout) || headersTimeout < 0)) {\n      throw new InvalidArgumentError('invalid headersTimeout')\n    }\n\n    if (bodyTimeout != null && (!Number.isFinite(bodyTimeout) || bodyTimeout < 0)) {\n      throw new InvalidArgumentError('invalid bodyTimeout')\n    }\n\n    if (reset != null && typeof reset !== 'boolean') {\n      throw new InvalidArgumentError('invalid reset')\n    }\n\n    if (expectContinue != null && typeof expectContinue !== 'boolean') {\n      throw new InvalidArgumentError('invalid expectContinue')\n    }\n\n    this.headersTimeout = headersTimeout\n\n    this.bodyTimeout = bodyTimeout\n\n    this.throwOnError = throwOnError === true\n\n    this.method = method\n\n    this.abort = null\n\n    if (body == null) {\n      this.body = null\n    } else if (isStream(body)) {\n      this.body = body\n\n      const rState = this.body._readableState\n      if (!rState || !rState.autoDestroy) {\n        this.endHandler = function autoDestroy () {\n          destroy(this)\n        }\n        this.body.on('end', this.endHandler)\n      }\n\n      this.errorHandler = err => {\n        if (this.abort) {\n          this.abort(err)\n        } else {\n          this.error = err\n        }\n      }\n      this.body.on('error', this.errorHandler)\n    } else if (isBuffer(body)) {\n      this.body = body.byteLength ? body : null\n    } else if (ArrayBuffer.isView(body)) {\n      this.body = body.buffer.byteLength ? Buffer.from(body.buffer, body.byteOffset, body.byteLength) : null\n    } else if (body instanceof ArrayBuffer) {\n      this.body = body.byteLength ? Buffer.from(body) : null\n    } else if (typeof body === 'string') {\n      this.body = body.length ? Buffer.from(body) : null\n    } else if (isFormDataLike(body) || isIterable(body) || isBlobLike(body)) {\n      this.body = body\n    } else {\n      throw new InvalidArgumentError('body must be a string, a Buffer, a Readable stream, an iterable, or an async iterable')\n    }\n\n    this.completed = false\n\n    this.aborted = false\n\n    this.upgrade = upgrade || null\n\n    this.path = query ? buildURL(path, query) : path\n\n    this.origin = origin\n\n    this.idempotent = idempotent == null\n      ? method === 'HEAD' || method === 'GET'\n      : idempotent\n\n    this.blocking = blocking == null ? false : blocking\n\n    this.reset = reset == null ? null : reset\n\n    this.host = null\n\n    this.contentLength = null\n\n    this.contentType = null\n\n    this.headers = []\n\n    // Only for H2\n    this.expectContinue = expectContinue != null ? expectContinue : false\n\n    if (Array.isArray(headers)) {\n      if (headers.length % 2 !== 0) {\n        throw new InvalidArgumentError('headers array must be even')\n      }\n      for (let i = 0; i < headers.length; i += 2) {\n        processHeader(this, headers[i], headers[i + 1])\n      }\n    } else if (headers && typeof headers === 'object') {\n      if (headers[Symbol.iterator]) {\n        for (const header of headers) {\n          if (!Array.isArray(header) || header.length !== 2) {\n            throw new InvalidArgumentError('headers must be in key-value pair format')\n          }\n          processHeader(this, header[0], header[1])\n        }\n      } else {\n        const keys = Object.keys(headers)\n        for (let i = 0; i < keys.length; ++i) {\n          processHeader(this, keys[i], headers[keys[i]])\n        }\n      }\n    } else if (headers != null) {\n      throw new InvalidArgumentError('headers must be an object or an array')\n    }\n\n    validateHandler(handler, method, upgrade)\n\n    this.servername = servername || getServerName(this.host)\n\n    this[kHandler] = handler\n\n    if (channels.create.hasSubscribers) {\n      channels.create.publish({ request: this })\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this[kHandler].onBodySent) {\n      try {\n        return this[kHandler].onBodySent(chunk)\n      } catch (err) {\n        this.abort(err)\n      }\n    }\n  }\n\n  onRequestSent () {\n    if (channels.bodySent.hasSubscribers) {\n      channels.bodySent.publish({ request: this })\n    }\n\n    if (this[kHandler].onRequestSent) {\n      try {\n        return this[kHandler].onRequestSent()\n      } catch (err) {\n        this.abort(err)\n      }\n    }\n  }\n\n  onConnect (abort) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    if (this.error) {\n      abort(this.error)\n    } else {\n      this.abort = abort\n      return this[kHandler].onConnect(abort)\n    }\n  }\n\n  onResponseStarted () {\n    return this[kHandler].onResponseStarted?.()\n  }\n\n  onHeaders (statusCode, headers, resume, statusText) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    if (channels.headers.hasSubscribers) {\n      channels.headers.publish({ request: this, response: { statusCode, headers, statusText } })\n    }\n\n    try {\n      return this[kHandler].onHeaders(statusCode, headers, resume, statusText)\n    } catch (err) {\n      this.abort(err)\n    }\n  }\n\n  onData (chunk) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    try {\n      return this[kHandler].onData(chunk)\n    } catch (err) {\n      this.abort(err)\n      return false\n    }\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    return this[kHandler].onUpgrade(statusCode, headers, socket)\n  }\n\n  onComplete (trailers) {\n    this.onFinally()\n\n    assert(!this.aborted)\n\n    this.completed = true\n    if (channels.trailers.hasSubscribers) {\n      channels.trailers.publish({ request: this, trailers })\n    }\n\n    try {\n      return this[kHandler].onComplete(trailers)\n    } catch (err) {\n      // TODO (fix): This might be a bad idea?\n      this.onError(err)\n    }\n  }\n\n  onError (error) {\n    this.onFinally()\n\n    if (channels.error.hasSubscribers) {\n      channels.error.publish({ request: this, error })\n    }\n\n    if (this.aborted) {\n      return\n    }\n    this.aborted = true\n\n    return this[kHandler].onError(error)\n  }\n\n  onFinally () {\n    if (this.errorHandler) {\n      this.body.off('error', this.errorHandler)\n      this.errorHandler = null\n    }\n\n    if (this.endHandler) {\n      this.body.off('end', this.endHandler)\n      this.endHandler = null\n    }\n  }\n\n  addHeader (key, value) {\n    processHeader(this, key, value)\n    return this\n  }\n}\n\nfunction processHeader (request, key, val) {\n  if (val && (typeof val === 'object' && !Array.isArray(val))) {\n    throw new InvalidArgumentError(`invalid ${key} header`)\n  } else if (val === undefined) {\n    return\n  }\n\n  let headerName = headerNameLowerCasedRecord[key]\n\n  if (headerName === undefined) {\n    headerName = key.toLowerCase()\n    if (headerNameLowerCasedRecord[headerName] === undefined && !isValidHTTPToken(headerName)) {\n      throw new InvalidArgumentError('invalid header key')\n    }\n  }\n\n  if (Array.isArray(val)) {\n    const arr = []\n    for (let i = 0; i < val.length; i++) {\n      if (typeof val[i] === 'string') {\n        if (!isValidHeaderValue(val[i])) {\n          throw new InvalidArgumentError(`invalid ${key} header`)\n        }\n        arr.push(val[i])\n      } else if (val[i] === null) {\n        arr.push('')\n      } else if (typeof val[i] === 'object') {\n        throw new InvalidArgumentError(`invalid ${key} header`)\n      } else {\n        arr.push(`${val[i]}`)\n      }\n    }\n    val = arr\n  } else if (typeof val === 'string') {\n    if (!isValidHeaderValue(val)) {\n      throw new InvalidArgumentError(`invalid ${key} header`)\n    }\n  } else if (val === null) {\n    val = ''\n  } else {\n    val = `${val}`\n  }\n\n  if (request.host === null && headerName === 'host') {\n    if (typeof val !== 'string') {\n      throw new InvalidArgumentError('invalid host header')\n    }\n    // Consumed by Client\n    request.host = val\n  } else if (request.contentLength === null && headerName === 'content-length') {\n    request.contentLength = parseInt(val, 10)\n    if (!Number.isFinite(request.contentLength)) {\n      throw new InvalidArgumentError('invalid content-length header')\n    }\n  } else if (request.contentType === null && headerName === 'content-type') {\n    request.contentType = val\n    request.headers.push(key, val)\n  } else if (headerName === 'transfer-encoding' || headerName === 'keep-alive' || headerName === 'upgrade') {\n    throw new InvalidArgumentError(`invalid ${headerName} header`)\n  } else if (headerName === 'connection') {\n    const value = typeof val === 'string' ? val.toLowerCase() : null\n    if (value !== 'close' && value !== 'keep-alive') {\n      throw new InvalidArgumentError('invalid connection header')\n    }\n\n    if (value === 'close') {\n      request.reset = true\n    }\n  } else if (headerName === 'expect') {\n    throw new NotSupportedError('expect header not supported')\n  } else {\n    request.headers.push(key, val)\n  }\n}\n\nmodule.exports = Request\n","module.exports = {\n  kClose: Symbol('close'),\n  kDestroy: Symbol('destroy'),\n  kDispatch: Symbol('dispatch'),\n  kUrl: Symbol('url'),\n  kWriting: Symbol('writing'),\n  kResuming: Symbol('resuming'),\n  kQueue: Symbol('queue'),\n  kConnect: Symbol('connect'),\n  kConnecting: Symbol('connecting'),\n  kKeepAliveDefaultTimeout: Symbol('default keep alive timeout'),\n  kKeepAliveMaxTimeout: Symbol('max keep alive timeout'),\n  kKeepAliveTimeoutThreshold: Symbol('keep alive timeout threshold'),\n  kKeepAliveTimeoutValue: Symbol('keep alive timeout'),\n  kKeepAlive: Symbol('keep alive'),\n  kHeadersTimeout: Symbol('headers timeout'),\n  kBodyTimeout: Symbol('body timeout'),\n  kServerName: Symbol('server name'),\n  kLocalAddress: Symbol('local address'),\n  kHost: Symbol('host'),\n  kNoRef: Symbol('no ref'),\n  kBodyUsed: Symbol('used'),\n  kBody: Symbol('abstracted request body'),\n  kRunning: Symbol('running'),\n  kBlocking: Symbol('blocking'),\n  kPending: Symbol('pending'),\n  kSize: Symbol('size'),\n  kBusy: Symbol('busy'),\n  kQueued: Symbol('queued'),\n  kFree: Symbol('free'),\n  kConnected: Symbol('connected'),\n  kClosed: Symbol('closed'),\n  kNeedDrain: Symbol('need drain'),\n  kReset: Symbol('reset'),\n  kDestroyed: Symbol.for('nodejs.stream.destroyed'),\n  kResume: Symbol('resume'),\n  kOnError: Symbol('on error'),\n  kMaxHeadersSize: Symbol('max headers size'),\n  kRunningIdx: Symbol('running index'),\n  kPendingIdx: Symbol('pending index'),\n  kError: Symbol('error'),\n  kClients: Symbol('clients'),\n  kClient: Symbol('client'),\n  kParser: Symbol('parser'),\n  kOnDestroyed: Symbol('destroy callbacks'),\n  kPipelining: Symbol('pipelining'),\n  kSocket: Symbol('socket'),\n  kHostHeader: Symbol('host header'),\n  kConnector: Symbol('connector'),\n  kStrictContentLength: Symbol('strict content length'),\n  kMaxRedirections: Symbol('maxRedirections'),\n  kMaxRequests: Symbol('maxRequestsPerClient'),\n  kProxy: Symbol('proxy agent options'),\n  kCounter: Symbol('socket request counter'),\n  kInterceptors: Symbol('dispatch interceptors'),\n  kMaxResponseSize: Symbol('max response size'),\n  kHTTP2Session: Symbol('http2Session'),\n  kHTTP2SessionState: Symbol('http2Session state'),\n  kRetryHandlerDefaultRetry: Symbol('retry agent default retry'),\n  kConstruct: Symbol('constructable'),\n  kListeners: Symbol('listeners'),\n  kHTTPContext: Symbol('http context'),\n  kMaxConcurrentStreams: Symbol('max concurrent streams'),\n  kNoProxyAgent: Symbol('no proxy agent'),\n  kHttpProxyAgent: Symbol('http proxy agent'),\n  kHttpsProxyAgent: Symbol('https proxy agent')\n}\n","'use strict'\n\nconst {\n  wellknownHeaderNames,\n  headerNameLowerCasedRecord\n} = require('./constants')\n\nclass TstNode {\n  /** @type {any} */\n  value = null\n  /** @type {null | TstNode} */\n  left = null\n  /** @type {null | TstNode} */\n  middle = null\n  /** @type {null | TstNode} */\n  right = null\n  /** @type {number} */\n  code\n  /**\n   * @param {string} key\n   * @param {any} value\n   * @param {number} index\n   */\n  constructor (key, value, index) {\n    if (index === undefined || index >= key.length) {\n      throw new TypeError('Unreachable')\n    }\n    const code = this.code = key.charCodeAt(index)\n    // check code is ascii string\n    if (code > 0x7F) {\n      throw new TypeError('key must be ascii string')\n    }\n    if (key.length !== ++index) {\n      this.middle = new TstNode(key, value, index)\n    } else {\n      this.value = value\n    }\n  }\n\n  /**\n   * @param {string} key\n   * @param {any} value\n   */\n  add (key, value) {\n    const length = key.length\n    if (length === 0) {\n      throw new TypeError('Unreachable')\n    }\n    let index = 0\n    let node = this\n    while (true) {\n      const code = key.charCodeAt(index)\n      // check code is ascii string\n      if (code > 0x7F) {\n        throw new TypeError('key must be ascii string')\n      }\n      if (node.code === code) {\n        if (length === ++index) {\n          node.value = value\n          break\n        } else if (node.middle !== null) {\n          node = node.middle\n        } else {\n          node.middle = new TstNode(key, value, index)\n          break\n        }\n      } else if (node.code < code) {\n        if (node.left !== null) {\n          node = node.left\n        } else {\n          node.left = new TstNode(key, value, index)\n          break\n        }\n      } else if (node.right !== null) {\n        node = node.right\n      } else {\n        node.right = new TstNode(key, value, index)\n        break\n      }\n    }\n  }\n\n  /**\n   * @param {Uint8Array} key\n   * @return {TstNode | null}\n   */\n  search (key) {\n    const keylength = key.length\n    let index = 0\n    let node = this\n    while (node !== null && index < keylength) {\n      let code = key[index]\n      // A-Z\n      // First check if it is bigger than 0x5a.\n      // Lowercase letters have higher char codes than uppercase ones.\n      // Also we assume that headers will mostly contain lowercase characters.\n      if (code <= 0x5a && code >= 0x41) {\n        // Lowercase for uppercase.\n        code |= 32\n      }\n      while (node !== null) {\n        if (code === node.code) {\n          if (keylength === ++index) {\n            // Returns Node since it is the last key.\n            return node\n          }\n          node = node.middle\n          break\n        }\n        node = node.code < code ? node.left : node.right\n      }\n    }\n    return null\n  }\n}\n\nclass TernarySearchTree {\n  /** @type {TstNode | null} */\n  node = null\n\n  /**\n   * @param {string} key\n   * @param {any} value\n   * */\n  insert (key, value) {\n    if (this.node === null) {\n      this.node = new TstNode(key, value, 0)\n    } else {\n      this.node.add(key, value)\n    }\n  }\n\n  /**\n   * @param {Uint8Array} key\n   * @return {any}\n   */\n  lookup (key) {\n    return this.node?.search(key)?.value ?? null\n  }\n}\n\nconst tree = new TernarySearchTree()\n\nfor (let i = 0; i < wellknownHeaderNames.length; ++i) {\n  const key = headerNameLowerCasedRecord[wellknownHeaderNames[i]]\n  tree.insert(key, key)\n}\n\nmodule.exports = {\n  TernarySearchTree,\n  tree\n}\n","'use strict'\n\nconst assert = require('node:assert')\nconst { kDestroyed, kBodyUsed, kListeners, kBody } = require('./symbols')\nconst { IncomingMessage } = require('node:http')\nconst stream = require('node:stream')\nconst net = require('node:net')\nconst { Blob } = require('node:buffer')\nconst nodeUtil = require('node:util')\nconst { stringify } = require('node:querystring')\nconst { EventEmitter: EE } = require('node:events')\nconst { InvalidArgumentError } = require('./errors')\nconst { headerNameLowerCasedRecord } = require('./constants')\nconst { tree } = require('./tree')\n\nconst [nodeMajor, nodeMinor] = process.versions.node.split('.').map(v => Number(v))\n\nclass BodyAsyncIterable {\n  constructor (body) {\n    this[kBody] = body\n    this[kBodyUsed] = false\n  }\n\n  async * [Symbol.asyncIterator] () {\n    assert(!this[kBodyUsed], 'disturbed')\n    this[kBodyUsed] = true\n    yield * this[kBody]\n  }\n}\n\nfunction wrapRequestBody (body) {\n  if (isStream(body)) {\n    // TODO (fix): Provide some way for the user to cache the file to e.g. /tmp\n    // so that it can be dispatched again?\n    // TODO (fix): Do we need 100-expect support to provide a way to do this properly?\n    if (bodyLength(body) === 0) {\n      body\n        .on('data', function () {\n          assert(false)\n        })\n    }\n\n    if (typeof body.readableDidRead !== 'boolean') {\n      body[kBodyUsed] = false\n      EE.prototype.on.call(body, 'data', function () {\n        this[kBodyUsed] = true\n      })\n    }\n\n    return body\n  } else if (body && typeof body.pipeTo === 'function') {\n    // TODO (fix): We can't access ReadableStream internal state\n    // to determine whether or not it has been disturbed. This is just\n    // a workaround.\n    return new BodyAsyncIterable(body)\n  } else if (\n    body &&\n    typeof body !== 'string' &&\n    !ArrayBuffer.isView(body) &&\n    isIterable(body)\n  ) {\n    // TODO: Should we allow re-using iterable if !this.opts.idempotent\n    // or through some other flag?\n    return new BodyAsyncIterable(body)\n  } else {\n    return body\n  }\n}\n\nfunction nop () {}\n\nfunction isStream (obj) {\n  return obj && typeof obj === 'object' && typeof obj.pipe === 'function' && typeof obj.on === 'function'\n}\n\n// based on https://github.com/node-fetch/fetch-blob/blob/8ab587d34080de94140b54f07168451e7d0b655e/index.js#L229-L241 (MIT License)\nfunction isBlobLike (object) {\n  if (object === null) {\n    return false\n  } else if (object instanceof Blob) {\n    return true\n  } else if (typeof object !== 'object') {\n    return false\n  } else {\n    const sTag = object[Symbol.toStringTag]\n\n    return (sTag === 'Blob' || sTag === 'File') && (\n      ('stream' in object && typeof object.stream === 'function') ||\n      ('arrayBuffer' in object && typeof object.arrayBuffer === 'function')\n    )\n  }\n}\n\nfunction buildURL (url, queryParams) {\n  if (url.includes('?') || url.includes('#')) {\n    throw new Error('Query params cannot be passed when url already contains \"?\" or \"#\".')\n  }\n\n  const stringified = stringify(queryParams)\n\n  if (stringified) {\n    url += '?' + stringified\n  }\n\n  return url\n}\n\nfunction isValidPort (port) {\n  const value = parseInt(port, 10)\n  return (\n    value === Number(port) &&\n    value >= 0 &&\n    value <= 65535\n  )\n}\n\nfunction isHttpOrHttpsPrefixed (value) {\n  return (\n    value != null &&\n    value[0] === 'h' &&\n    value[1] === 't' &&\n    value[2] === 't' &&\n    value[3] === 'p' &&\n    (\n      value[4] === ':' ||\n      (\n        value[4] === 's' &&\n        value[5] === ':'\n      )\n    )\n  )\n}\n\nfunction parseURL (url) {\n  if (typeof url === 'string') {\n    url = new URL(url)\n\n    if (!isHttpOrHttpsPrefixed(url.origin || url.protocol)) {\n      throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')\n    }\n\n    return url\n  }\n\n  if (!url || typeof url !== 'object') {\n    throw new InvalidArgumentError('Invalid URL: The URL argument must be a non-null object.')\n  }\n\n  if (!(url instanceof URL)) {\n    if (url.port != null && url.port !== '' && isValidPort(url.port) === false) {\n      throw new InvalidArgumentError('Invalid URL: port must be a valid integer or a string representation of an integer.')\n    }\n\n    if (url.path != null && typeof url.path !== 'string') {\n      throw new InvalidArgumentError('Invalid URL path: the path must be a string or null/undefined.')\n    }\n\n    if (url.pathname != null && typeof url.pathname !== 'string') {\n      throw new InvalidArgumentError('Invalid URL pathname: the pathname must be a string or null/undefined.')\n    }\n\n    if (url.hostname != null && typeof url.hostname !== 'string') {\n      throw new InvalidArgumentError('Invalid URL hostname: the hostname must be a string or null/undefined.')\n    }\n\n    if (url.origin != null && typeof url.origin !== 'string') {\n      throw new InvalidArgumentError('Invalid URL origin: the origin must be a string or null/undefined.')\n    }\n\n    if (!isHttpOrHttpsPrefixed(url.origin || url.protocol)) {\n      throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')\n    }\n\n    const port = url.port != null\n      ? url.port\n      : (url.protocol === 'https:' ? 443 : 80)\n    let origin = url.origin != null\n      ? url.origin\n      : `${url.protocol || ''}//${url.hostname || ''}:${port}`\n    let path = url.path != null\n      ? url.path\n      : `${url.pathname || ''}${url.search || ''}`\n\n    if (origin[origin.length - 1] === '/') {\n      origin = origin.slice(0, origin.length - 1)\n    }\n\n    if (path && path[0] !== '/') {\n      path = `/${path}`\n    }\n    // new URL(path, origin) is unsafe when `path` contains an absolute URL\n    // From https://developer.mozilla.org/en-US/docs/Web/API/URL/URL:\n    // If first parameter is a relative URL, second param is required, and will be used as the base URL.\n    // If first parameter is an absolute URL, a given second param will be ignored.\n    return new URL(`${origin}${path}`)\n  }\n\n  if (!isHttpOrHttpsPrefixed(url.origin || url.protocol)) {\n    throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')\n  }\n\n  return url\n}\n\nfunction parseOrigin (url) {\n  url = parseURL(url)\n\n  if (url.pathname !== '/' || url.search || url.hash) {\n    throw new InvalidArgumentError('invalid url')\n  }\n\n  return url\n}\n\nfunction getHostname (host) {\n  if (host[0] === '[') {\n    const idx = host.indexOf(']')\n\n    assert(idx !== -1)\n    return host.substring(1, idx)\n  }\n\n  const idx = host.indexOf(':')\n  if (idx === -1) return host\n\n  return host.substring(0, idx)\n}\n\n// IP addresses are not valid server names per RFC6066\n// > Currently, the only server names supported are DNS hostnames\nfunction getServerName (host) {\n  if (!host) {\n    return null\n  }\n\n  assert(typeof host === 'string')\n\n  const servername = getHostname(host)\n  if (net.isIP(servername)) {\n    return ''\n  }\n\n  return servername\n}\n\nfunction deepClone (obj) {\n  return JSON.parse(JSON.stringify(obj))\n}\n\nfunction isAsyncIterable (obj) {\n  return !!(obj != null && typeof obj[Symbol.asyncIterator] === 'function')\n}\n\nfunction isIterable (obj) {\n  return !!(obj != null && (typeof obj[Symbol.iterator] === 'function' || typeof obj[Symbol.asyncIterator] === 'function'))\n}\n\nfunction bodyLength (body) {\n  if (body == null) {\n    return 0\n  } else if (isStream(body)) {\n    const state = body._readableState\n    return state && state.objectMode === false && state.ended === true && Number.isFinite(state.length)\n      ? state.length\n      : null\n  } else if (isBlobLike(body)) {\n    return body.size != null ? body.size : null\n  } else if (isBuffer(body)) {\n    return body.byteLength\n  }\n\n  return null\n}\n\nfunction isDestroyed (body) {\n  return body && !!(body.destroyed || body[kDestroyed] || (stream.isDestroyed?.(body)))\n}\n\nfunction destroy (stream, err) {\n  if (stream == null || !isStream(stream) || isDestroyed(stream)) {\n    return\n  }\n\n  if (typeof stream.destroy === 'function') {\n    if (Object.getPrototypeOf(stream).constructor === IncomingMessage) {\n      // See: https://github.com/nodejs/node/pull/38505/files\n      stream.socket = null\n    }\n\n    stream.destroy(err)\n  } else if (err) {\n    queueMicrotask(() => {\n      stream.emit('error', err)\n    })\n  }\n\n  if (stream.destroyed !== true) {\n    stream[kDestroyed] = true\n  }\n}\n\nconst KEEPALIVE_TIMEOUT_EXPR = /timeout=(\\d+)/\nfunction parseKeepAliveTimeout (val) {\n  const m = val.toString().match(KEEPALIVE_TIMEOUT_EXPR)\n  return m ? parseInt(m[1], 10) * 1000 : null\n}\n\n/**\n * Retrieves a header name and returns its lowercase value.\n * @param {string | Buffer} value Header name\n * @returns {string}\n */\nfunction headerNameToString (value) {\n  return typeof value === 'string'\n    ? headerNameLowerCasedRecord[value] ?? value.toLowerCase()\n    : tree.lookup(value) ?? value.toString('latin1').toLowerCase()\n}\n\n/**\n * Receive the buffer as a string and return its lowercase value.\n * @param {Buffer} value Header name\n * @returns {string}\n */\nfunction bufferToLowerCasedHeaderName (value) {\n  return tree.lookup(value) ?? value.toString('latin1').toLowerCase()\n}\n\n/**\n * @param {Record<string, string | string[]> | (Buffer | string | (Buffer | string)[])[]} headers\n * @param {Record<string, string | string[]>} [obj]\n * @returns {Record<string, string | string[]>}\n */\nfunction parseHeaders (headers, obj) {\n  if (obj === undefined) obj = {}\n  for (let i = 0; i < headers.length; i += 2) {\n    const key = headerNameToString(headers[i])\n    let val = obj[key]\n\n    if (val) {\n      if (typeof val === 'string') {\n        val = [val]\n        obj[key] = val\n      }\n      val.push(headers[i + 1].toString('utf8'))\n    } else {\n      const headersValue = headers[i + 1]\n      if (typeof headersValue === 'string') {\n        obj[key] = headersValue\n      } else {\n        obj[key] = Array.isArray(headersValue) ? headersValue.map(x => x.toString('utf8')) : headersValue.toString('utf8')\n      }\n    }\n  }\n\n  // See https://github.com/nodejs/node/pull/46528\n  if ('content-length' in obj && 'content-disposition' in obj) {\n    obj['content-disposition'] = Buffer.from(obj['content-disposition']).toString('latin1')\n  }\n\n  return obj\n}\n\nfunction parseRawHeaders (headers) {\n  const len = headers.length\n  const ret = new Array(len)\n\n  let hasContentLength = false\n  let contentDispositionIdx = -1\n  let key\n  let val\n  let kLen = 0\n\n  for (let n = 0; n < headers.length; n += 2) {\n    key = headers[n]\n    val = headers[n + 1]\n\n    typeof key !== 'string' && (key = key.toString())\n    typeof val !== 'string' && (val = val.toString('utf8'))\n\n    kLen = key.length\n    if (kLen === 14 && key[7] === '-' && (key === 'content-length' || key.toLowerCase() === 'content-length')) {\n      hasContentLength = true\n    } else if (kLen === 19 && key[7] === '-' && (key === 'content-disposition' || key.toLowerCase() === 'content-disposition')) {\n      contentDispositionIdx = n + 1\n    }\n    ret[n] = key\n    ret[n + 1] = val\n  }\n\n  // See https://github.com/nodejs/node/pull/46528\n  if (hasContentLength && contentDispositionIdx !== -1) {\n    ret[contentDispositionIdx] = Buffer.from(ret[contentDispositionIdx]).toString('latin1')\n  }\n\n  return ret\n}\n\nfunction isBuffer (buffer) {\n  // See, https://github.com/mcollina/undici/pull/319\n  return buffer instanceof Uint8Array || Buffer.isBuffer(buffer)\n}\n\nfunction validateHandler (handler, method, upgrade) {\n  if (!handler || typeof handler !== 'object') {\n    throw new InvalidArgumentError('handler must be an object')\n  }\n\n  if (typeof handler.onConnect !== 'function') {\n    throw new InvalidArgumentError('invalid onConnect method')\n  }\n\n  if (typeof handler.onError !== 'function') {\n    throw new InvalidArgumentError('invalid onError method')\n  }\n\n  if (typeof handler.onBodySent !== 'function' && handler.onBodySent !== undefined) {\n    throw new InvalidArgumentError('invalid onBodySent method')\n  }\n\n  if (upgrade || method === 'CONNECT') {\n    if (typeof handler.onUpgrade !== 'function') {\n      throw new InvalidArgumentError('invalid onUpgrade method')\n    }\n  } else {\n    if (typeof handler.onHeaders !== 'function') {\n      throw new InvalidArgumentError('invalid onHeaders method')\n    }\n\n    if (typeof handler.onData !== 'function') {\n      throw new InvalidArgumentError('invalid onData method')\n    }\n\n    if (typeof handler.onComplete !== 'function') {\n      throw new InvalidArgumentError('invalid onComplete method')\n    }\n  }\n}\n\n// A body is disturbed if it has been read from and it cannot\n// be re-used without losing state or data.\nfunction isDisturbed (body) {\n  // TODO (fix): Why is body[kBodyUsed] needed?\n  return !!(body && (stream.isDisturbed(body) || body[kBodyUsed]))\n}\n\nfunction isErrored (body) {\n  return !!(body && stream.isErrored(body))\n}\n\nfunction isReadable (body) {\n  return !!(body && stream.isReadable(body))\n}\n\nfunction getSocketInfo (socket) {\n  return {\n    localAddress: socket.localAddress,\n    localPort: socket.localPort,\n    remoteAddress: socket.remoteAddress,\n    remotePort: socket.remotePort,\n    remoteFamily: socket.remoteFamily,\n    timeout: socket.timeout,\n    bytesWritten: socket.bytesWritten,\n    bytesRead: socket.bytesRead\n  }\n}\n\n/** @type {globalThis['ReadableStream']} */\nfunction ReadableStreamFrom (iterable) {\n  // We cannot use ReadableStream.from here because it does not return a byte stream.\n\n  let iterator\n  return new ReadableStream(\n    {\n      async start () {\n        iterator = iterable[Symbol.asyncIterator]()\n      },\n      async pull (controller) {\n        const { done, value } = await iterator.next()\n        if (done) {\n          queueMicrotask(() => {\n            controller.close()\n            controller.byobRequest?.respond(0)\n          })\n        } else {\n          const buf = Buffer.isBuffer(value) ? value : Buffer.from(value)\n          if (buf.byteLength) {\n            controller.enqueue(new Uint8Array(buf))\n          }\n        }\n        return controller.desiredSize > 0\n      },\n      async cancel (reason) {\n        await iterator.return()\n      },\n      type: 'bytes'\n    }\n  )\n}\n\n// The chunk should be a FormData instance and contains\n// all the required methods.\nfunction isFormDataLike (object) {\n  return (\n    object &&\n    typeof object === 'object' &&\n    typeof object.append === 'function' &&\n    typeof object.delete === 'function' &&\n    typeof object.get === 'function' &&\n    typeof object.getAll === 'function' &&\n    typeof object.has === 'function' &&\n    typeof object.set === 'function' &&\n    object[Symbol.toStringTag] === 'FormData'\n  )\n}\n\nfunction addAbortListener (signal, listener) {\n  if ('addEventListener' in signal) {\n    signal.addEventListener('abort', listener, { once: true })\n    return () => signal.removeEventListener('abort', listener)\n  }\n  signal.addListener('abort', listener)\n  return () => signal.removeListener('abort', listener)\n}\n\nconst hasToWellFormed = typeof String.prototype.toWellFormed === 'function'\nconst hasIsWellFormed = typeof String.prototype.isWellFormed === 'function'\n\n/**\n * @param {string} val\n */\nfunction toUSVString (val) {\n  return hasToWellFormed ? `${val}`.toWellFormed() : nodeUtil.toUSVString(val)\n}\n\n/**\n * @param {string} val\n */\n// TODO: move this to webidl\nfunction isUSVString (val) {\n  return hasIsWellFormed ? `${val}`.isWellFormed() : toUSVString(val) === `${val}`\n}\n\n/**\n * @see https://tools.ietf.org/html/rfc7230#section-3.2.6\n * @param {number} c\n */\nfunction isTokenCharCode (c) {\n  switch (c) {\n    case 0x22:\n    case 0x28:\n    case 0x29:\n    case 0x2c:\n    case 0x2f:\n    case 0x3a:\n    case 0x3b:\n    case 0x3c:\n    case 0x3d:\n    case 0x3e:\n    case 0x3f:\n    case 0x40:\n    case 0x5b:\n    case 0x5c:\n    case 0x5d:\n    case 0x7b:\n    case 0x7d:\n      // DQUOTE and \"(),/:;<=>?@[\\]{}\"\n      return false\n    default:\n      // VCHAR %x21-7E\n      return c >= 0x21 && c <= 0x7e\n  }\n}\n\n/**\n * @param {string} characters\n */\nfunction isValidHTTPToken (characters) {\n  if (characters.length === 0) {\n    return false\n  }\n  for (let i = 0; i < characters.length; ++i) {\n    if (!isTokenCharCode(characters.charCodeAt(i))) {\n      return false\n    }\n  }\n  return true\n}\n\n// headerCharRegex have been lifted from\n// https://github.com/nodejs/node/blob/main/lib/_http_common.js\n\n/**\n * Matches if val contains an invalid field-vchar\n *  field-value    = *( field-content / obs-fold )\n *  field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]\n *  field-vchar    = VCHAR / obs-text\n */\nconst headerCharRegex = /[^\\t\\x20-\\x7e\\x80-\\xff]/\n\n/**\n * @param {string} characters\n */\nfunction isValidHeaderValue (characters) {\n  return !headerCharRegex.test(characters)\n}\n\n// Parsed accordingly to RFC 9110\n// https://www.rfc-editor.org/rfc/rfc9110#field.content-range\nfunction parseRangeHeader (range) {\n  if (range == null || range === '') return { start: 0, end: null, size: null }\n\n  const m = range ? range.match(/^bytes (\\d+)-(\\d+)\\/(\\d+)?$/) : null\n  return m\n    ? {\n        start: parseInt(m[1]),\n        end: m[2] ? parseInt(m[2]) : null,\n        size: m[3] ? parseInt(m[3]) : null\n      }\n    : null\n}\n\nfunction addListener (obj, name, listener) {\n  const listeners = (obj[kListeners] ??= [])\n  listeners.push([name, listener])\n  obj.on(name, listener)\n  return obj\n}\n\nfunction removeAllListeners (obj) {\n  for (const [name, listener] of obj[kListeners] ?? []) {\n    obj.removeListener(name, listener)\n  }\n  obj[kListeners] = null\n}\n\nfunction errorRequest (client, request, err) {\n  try {\n    request.onError(err)\n    assert(request.aborted)\n  } catch (err) {\n    client.emit('error', err)\n  }\n}\n\nconst kEnumerableProperty = Object.create(null)\nkEnumerableProperty.enumerable = true\n\nconst normalizedMethodRecordsBase = {\n  delete: 'DELETE',\n  DELETE: 'DELETE',\n  get: 'GET',\n  GET: 'GET',\n  head: 'HEAD',\n  HEAD: 'HEAD',\n  options: 'OPTIONS',\n  OPTIONS: 'OPTIONS',\n  post: 'POST',\n  POST: 'POST',\n  put: 'PUT',\n  PUT: 'PUT'\n}\n\nconst normalizedMethodRecords = {\n  ...normalizedMethodRecordsBase,\n  patch: 'patch',\n  PATCH: 'PATCH'\n}\n\n// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.\nObject.setPrototypeOf(normalizedMethodRecordsBase, null)\nObject.setPrototypeOf(normalizedMethodRecords, null)\n\nmodule.exports = {\n  kEnumerableProperty,\n  nop,\n  isDisturbed,\n  isErrored,\n  isReadable,\n  toUSVString,\n  isUSVString,\n  isBlobLike,\n  parseOrigin,\n  parseURL,\n  getServerName,\n  isStream,\n  isIterable,\n  isAsyncIterable,\n  isDestroyed,\n  headerNameToString,\n  bufferToLowerCasedHeaderName,\n  addListener,\n  removeAllListeners,\n  errorRequest,\n  parseRawHeaders,\n  parseHeaders,\n  parseKeepAliveTimeout,\n  destroy,\n  bodyLength,\n  deepClone,\n  ReadableStreamFrom,\n  isBuffer,\n  validateHandler,\n  getSocketInfo,\n  isFormDataLike,\n  buildURL,\n  addAbortListener,\n  isValidHTTPToken,\n  isValidHeaderValue,\n  isTokenCharCode,\n  parseRangeHeader,\n  normalizedMethodRecordsBase,\n  normalizedMethodRecords,\n  isValidPort,\n  isHttpOrHttpsPrefixed,\n  nodeMajor,\n  nodeMinor,\n  safeHTTPMethods: ['GET', 'HEAD', 'OPTIONS', 'TRACE'],\n  wrapRequestBody\n}\n","'use strict'\n\nconst { InvalidArgumentError } = require('../core/errors')\nconst { kClients, kRunning, kClose, kDestroy, kDispatch, kInterceptors } = require('../core/symbols')\nconst DispatcherBase = require('./dispatcher-base')\nconst Pool = require('./pool')\nconst Client = require('./client')\nconst util = require('../core/util')\nconst createRedirectInterceptor = require('../interceptor/redirect-interceptor')\n\nconst kOnConnect = Symbol('onConnect')\nconst kOnDisconnect = Symbol('onDisconnect')\nconst kOnConnectionError = Symbol('onConnectionError')\nconst kMaxRedirections = Symbol('maxRedirections')\nconst kOnDrain = Symbol('onDrain')\nconst kFactory = Symbol('factory')\nconst kOptions = Symbol('options')\n\nfunction defaultFactory (origin, opts) {\n  return opts && opts.connections === 1\n    ? new Client(origin, opts)\n    : new Pool(origin, opts)\n}\n\nclass Agent extends DispatcherBase {\n  constructor ({ factory = defaultFactory, maxRedirections = 0, connect, ...options } = {}) {\n    super()\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (!Number.isInteger(maxRedirections) || maxRedirections < 0) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    if (connect && typeof connect !== 'function') {\n      connect = { ...connect }\n    }\n\n    this[kInterceptors] = options.interceptors?.Agent && Array.isArray(options.interceptors.Agent)\n      ? options.interceptors.Agent\n      : [createRedirectInterceptor({ maxRedirections })]\n\n    this[kOptions] = { ...util.deepClone(options), connect }\n    this[kOptions].interceptors = options.interceptors\n      ? { ...options.interceptors }\n      : undefined\n    this[kMaxRedirections] = maxRedirections\n    this[kFactory] = factory\n    this[kClients] = new Map()\n\n    this[kOnDrain] = (origin, targets) => {\n      this.emit('drain', origin, [this, ...targets])\n    }\n\n    this[kOnConnect] = (origin, targets) => {\n      this.emit('connect', origin, [this, ...targets])\n    }\n\n    this[kOnDisconnect] = (origin, targets, err) => {\n      this.emit('disconnect', origin, [this, ...targets], err)\n    }\n\n    this[kOnConnectionError] = (origin, targets, err) => {\n      this.emit('connectionError', origin, [this, ...targets], err)\n    }\n  }\n\n  get [kRunning] () {\n    let ret = 0\n    for (const client of this[kClients].values()) {\n      ret += client[kRunning]\n    }\n    return ret\n  }\n\n  [kDispatch] (opts, handler) {\n    let key\n    if (opts.origin && (typeof opts.origin === 'string' || opts.origin instanceof URL)) {\n      key = String(opts.origin)\n    } else {\n      throw new InvalidArgumentError('opts.origin must be a non-empty string or URL.')\n    }\n\n    let dispatcher = this[kClients].get(key)\n\n    if (!dispatcher) {\n      dispatcher = this[kFactory](opts.origin, this[kOptions])\n        .on('drain', this[kOnDrain])\n        .on('connect', this[kOnConnect])\n        .on('disconnect', this[kOnDisconnect])\n        .on('connectionError', this[kOnConnectionError])\n\n      // This introduces a tiny memory leak, as dispatchers are never removed from the map.\n      // TODO(mcollina): remove te timer when the client/pool do not have any more\n      // active connections.\n      this[kClients].set(key, dispatcher)\n    }\n\n    return dispatcher.dispatch(opts, handler)\n  }\n\n  async [kClose] () {\n    const closePromises = []\n    for (const client of this[kClients].values()) {\n      closePromises.push(client.close())\n    }\n    this[kClients].clear()\n\n    await Promise.all(closePromises)\n  }\n\n  async [kDestroy] (err) {\n    const destroyPromises = []\n    for (const client of this[kClients].values()) {\n      destroyPromises.push(client.destroy(err))\n    }\n    this[kClients].clear()\n\n    await Promise.all(destroyPromises)\n  }\n}\n\nmodule.exports = Agent\n","'use strict'\n\nconst {\n  BalancedPoolMissingUpstreamError,\n  InvalidArgumentError\n} = require('../core/errors')\nconst {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kRemoveClient,\n  kGetDispatcher\n} = require('./pool-base')\nconst Pool = require('./pool')\nconst { kUrl, kInterceptors } = require('../core/symbols')\nconst { parseOrigin } = require('../core/util')\nconst kFactory = Symbol('factory')\n\nconst kOptions = Symbol('options')\nconst kGreatestCommonDivisor = Symbol('kGreatestCommonDivisor')\nconst kCurrentWeight = Symbol('kCurrentWeight')\nconst kIndex = Symbol('kIndex')\nconst kWeight = Symbol('kWeight')\nconst kMaxWeightPerServer = Symbol('kMaxWeightPerServer')\nconst kErrorPenalty = Symbol('kErrorPenalty')\n\n/**\n * Calculate the greatest common divisor of two numbers by\n * using the Euclidean algorithm.\n *\n * @param {number} a\n * @param {number} b\n * @returns {number}\n */\nfunction getGreatestCommonDivisor (a, b) {\n  if (a === 0) return b\n\n  while (b !== 0) {\n    const t = b\n    b = a % b\n    a = t\n  }\n  return a\n}\n\nfunction defaultFactory (origin, opts) {\n  return new Pool(origin, opts)\n}\n\nclass BalancedPool extends PoolBase {\n  constructor (upstreams = [], { factory = defaultFactory, ...opts } = {}) {\n    super()\n\n    this[kOptions] = opts\n    this[kIndex] = -1\n    this[kCurrentWeight] = 0\n\n    this[kMaxWeightPerServer] = this[kOptions].maxWeightPerServer || 100\n    this[kErrorPenalty] = this[kOptions].errorPenalty || 15\n\n    if (!Array.isArray(upstreams)) {\n      upstreams = [upstreams]\n    }\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    this[kInterceptors] = opts.interceptors?.BalancedPool && Array.isArray(opts.interceptors.BalancedPool)\n      ? opts.interceptors.BalancedPool\n      : []\n    this[kFactory] = factory\n\n    for (const upstream of upstreams) {\n      this.addUpstream(upstream)\n    }\n    this._updateBalancedPoolStats()\n  }\n\n  addUpstream (upstream) {\n    const upstreamOrigin = parseOrigin(upstream).origin\n\n    if (this[kClients].find((pool) => (\n      pool[kUrl].origin === upstreamOrigin &&\n      pool.closed !== true &&\n      pool.destroyed !== true\n    ))) {\n      return this\n    }\n    const pool = this[kFactory](upstreamOrigin, Object.assign({}, this[kOptions]))\n\n    this[kAddClient](pool)\n    pool.on('connect', () => {\n      pool[kWeight] = Math.min(this[kMaxWeightPerServer], pool[kWeight] + this[kErrorPenalty])\n    })\n\n    pool.on('connectionError', () => {\n      pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty])\n      this._updateBalancedPoolStats()\n    })\n\n    pool.on('disconnect', (...args) => {\n      const err = args[2]\n      if (err && err.code === 'UND_ERR_SOCKET') {\n        // decrease the weight of the pool.\n        pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty])\n        this._updateBalancedPoolStats()\n      }\n    })\n\n    for (const client of this[kClients]) {\n      client[kWeight] = this[kMaxWeightPerServer]\n    }\n\n    this._updateBalancedPoolStats()\n\n    return this\n  }\n\n  _updateBalancedPoolStats () {\n    let result = 0\n    for (let i = 0; i < this[kClients].length; i++) {\n      result = getGreatestCommonDivisor(this[kClients][i][kWeight], result)\n    }\n\n    this[kGreatestCommonDivisor] = result\n  }\n\n  removeUpstream (upstream) {\n    const upstreamOrigin = parseOrigin(upstream).origin\n\n    const pool = this[kClients].find((pool) => (\n      pool[kUrl].origin === upstreamOrigin &&\n      pool.closed !== true &&\n      pool.destroyed !== true\n    ))\n\n    if (pool) {\n      this[kRemoveClient](pool)\n    }\n\n    return this\n  }\n\n  get upstreams () {\n    return this[kClients]\n      .filter(dispatcher => dispatcher.closed !== true && dispatcher.destroyed !== true)\n      .map((p) => p[kUrl].origin)\n  }\n\n  [kGetDispatcher] () {\n    // We validate that pools is greater than 0,\n    // otherwise we would have to wait until an upstream\n    // is added, which might never happen.\n    if (this[kClients].length === 0) {\n      throw new BalancedPoolMissingUpstreamError()\n    }\n\n    const dispatcher = this[kClients].find(dispatcher => (\n      !dispatcher[kNeedDrain] &&\n      dispatcher.closed !== true &&\n      dispatcher.destroyed !== true\n    ))\n\n    if (!dispatcher) {\n      return\n    }\n\n    const allClientsBusy = this[kClients].map(pool => pool[kNeedDrain]).reduce((a, b) => a && b, true)\n\n    if (allClientsBusy) {\n      return\n    }\n\n    let counter = 0\n\n    let maxWeightIndex = this[kClients].findIndex(pool => !pool[kNeedDrain])\n\n    while (counter++ < this[kClients].length) {\n      this[kIndex] = (this[kIndex] + 1) % this[kClients].length\n      const pool = this[kClients][this[kIndex]]\n\n      // find pool index with the largest weight\n      if (pool[kWeight] > this[kClients][maxWeightIndex][kWeight] && !pool[kNeedDrain]) {\n        maxWeightIndex = this[kIndex]\n      }\n\n      // decrease the current weight every `this[kClients].length`.\n      if (this[kIndex] === 0) {\n        // Set the current weight to the next lower weight.\n        this[kCurrentWeight] = this[kCurrentWeight] - this[kGreatestCommonDivisor]\n\n        if (this[kCurrentWeight] <= 0) {\n          this[kCurrentWeight] = this[kMaxWeightPerServer]\n        }\n      }\n      if (pool[kWeight] >= this[kCurrentWeight] && (!pool[kNeedDrain])) {\n        return pool\n      }\n    }\n\n    this[kCurrentWeight] = this[kClients][maxWeightIndex][kWeight]\n    this[kIndex] = maxWeightIndex\n    return this[kClients][maxWeightIndex]\n  }\n}\n\nmodule.exports = BalancedPool\n","'use strict'\n\n/* global WebAssembly */\n\nconst assert = require('node:assert')\nconst util = require('../core/util.js')\nconst { channels } = require('../core/diagnostics.js')\nconst timers = require('../util/timers.js')\nconst {\n  RequestContentLengthMismatchError,\n  ResponseContentLengthMismatchError,\n  RequestAbortedError,\n  HeadersTimeoutError,\n  HeadersOverflowError,\n  SocketError,\n  InformationalError,\n  BodyTimeoutError,\n  HTTPParserError,\n  ResponseExceededMaxSizeError\n} = require('../core/errors.js')\nconst {\n  kUrl,\n  kReset,\n  kClient,\n  kParser,\n  kBlocking,\n  kRunning,\n  kPending,\n  kSize,\n  kWriting,\n  kQueue,\n  kNoRef,\n  kKeepAliveDefaultTimeout,\n  kHostHeader,\n  kPendingIdx,\n  kRunningIdx,\n  kError,\n  kPipelining,\n  kSocket,\n  kKeepAliveTimeoutValue,\n  kMaxHeadersSize,\n  kKeepAliveMaxTimeout,\n  kKeepAliveTimeoutThreshold,\n  kHeadersTimeout,\n  kBodyTimeout,\n  kStrictContentLength,\n  kMaxRequests,\n  kCounter,\n  kMaxResponseSize,\n  kOnError,\n  kResume,\n  kHTTPContext\n} = require('../core/symbols.js')\n\nconst constants = require('../llhttp/constants.js')\nconst EMPTY_BUF = Buffer.alloc(0)\nconst FastBuffer = Buffer[Symbol.species]\nconst addListener = util.addListener\nconst removeAllListeners = util.removeAllListeners\n\nlet extractBody\n\nasync function lazyllhttp () {\n  const llhttpWasmData = process.env.JEST_WORKER_ID ? require('../llhttp/llhttp-wasm.js') : undefined\n\n  let mod\n  try {\n    mod = await WebAssembly.compile(require('../llhttp/llhttp_simd-wasm.js'))\n  } catch (e) {\n    /* istanbul ignore next */\n\n    // We could check if the error was caused by the simd option not\n    // being enabled, but the occurring of this other error\n    // * https://github.com/emscripten-core/emscripten/issues/11495\n    // got me to remove that check to avoid breaking Node 12.\n    mod = await WebAssembly.compile(llhttpWasmData || require('../llhttp/llhttp-wasm.js'))\n  }\n\n  return await WebAssembly.instantiate(mod, {\n    env: {\n      /* eslint-disable camelcase */\n\n      wasm_on_url: (p, at, len) => {\n        /* istanbul ignore next */\n        return 0\n      },\n      wasm_on_status: (p, at, len) => {\n        assert(currentParser.ptr === p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onStatus(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_message_begin: (p) => {\n        assert(currentParser.ptr === p)\n        return currentParser.onMessageBegin() || 0\n      },\n      wasm_on_header_field: (p, at, len) => {\n        assert(currentParser.ptr === p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onHeaderField(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_header_value: (p, at, len) => {\n        assert(currentParser.ptr === p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onHeaderValue(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_headers_complete: (p, statusCode, upgrade, shouldKeepAlive) => {\n        assert(currentParser.ptr === p)\n        return currentParser.onHeadersComplete(statusCode, Boolean(upgrade), Boolean(shouldKeepAlive)) || 0\n      },\n      wasm_on_body: (p, at, len) => {\n        assert(currentParser.ptr === p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onBody(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_message_complete: (p) => {\n        assert(currentParser.ptr === p)\n        return currentParser.onMessageComplete() || 0\n      }\n\n      /* eslint-enable camelcase */\n    }\n  })\n}\n\nlet llhttpInstance = null\nlet llhttpPromise = lazyllhttp()\nllhttpPromise.catch()\n\nlet currentParser = null\nlet currentBufferRef = null\nlet currentBufferSize = 0\nlet currentBufferPtr = null\n\nconst USE_NATIVE_TIMER = 0\nconst USE_FAST_TIMER = 1\n\n// Use fast timers for headers and body to take eventual event loop\n// latency into account.\nconst TIMEOUT_HEADERS = 2 | USE_FAST_TIMER\nconst TIMEOUT_BODY = 4 | USE_FAST_TIMER\n\n// Use native timers to ignore event loop latency for keep-alive\n// handling.\nconst TIMEOUT_KEEP_ALIVE = 8 | USE_NATIVE_TIMER\n\nclass Parser {\n  constructor (client, socket, { exports }) {\n    assert(Number.isFinite(client[kMaxHeadersSize]) && client[kMaxHeadersSize] > 0)\n\n    this.llhttp = exports\n    this.ptr = this.llhttp.llhttp_alloc(constants.TYPE.RESPONSE)\n    this.client = client\n    this.socket = socket\n    this.timeout = null\n    this.timeoutValue = null\n    this.timeoutType = null\n    this.statusCode = null\n    this.statusText = ''\n    this.upgrade = false\n    this.headers = []\n    this.headersSize = 0\n    this.headersMaxSize = client[kMaxHeadersSize]\n    this.shouldKeepAlive = false\n    this.paused = false\n    this.resume = this.resume.bind(this)\n\n    this.bytesRead = 0\n\n    this.keepAlive = ''\n    this.contentLength = ''\n    this.connection = ''\n    this.maxResponseSize = client[kMaxResponseSize]\n  }\n\n  setTimeout (delay, type) {\n    // If the existing timer and the new timer are of different timer type\n    // (fast or native) or have different delay, we need to clear the existing\n    // timer and set a new one.\n    if (\n      delay !== this.timeoutValue ||\n      (type & USE_FAST_TIMER) ^ (this.timeoutType & USE_FAST_TIMER)\n    ) {\n      // If a timeout is already set, clear it with clearTimeout of the fast\n      // timer implementation, as it can clear fast and native timers.\n      if (this.timeout) {\n        timers.clearTimeout(this.timeout)\n        this.timeout = null\n      }\n\n      if (delay) {\n        if (type & USE_FAST_TIMER) {\n          this.timeout = timers.setFastTimeout(onParserTimeout, delay, new WeakRef(this))\n        } else {\n          this.timeout = setTimeout(onParserTimeout, delay, new WeakRef(this))\n          this.timeout.unref()\n        }\n      }\n\n      this.timeoutValue = delay\n    } else if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    this.timeoutType = type\n  }\n\n  resume () {\n    if (this.socket.destroyed || !this.paused) {\n      return\n    }\n\n    assert(this.ptr != null)\n    assert(currentParser == null)\n\n    this.llhttp.llhttp_resume(this.ptr)\n\n    assert(this.timeoutType === TIMEOUT_BODY)\n    if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    this.paused = false\n    this.execute(this.socket.read() || EMPTY_BUF) // Flush parser.\n    this.readMore()\n  }\n\n  readMore () {\n    while (!this.paused && this.ptr) {\n      const chunk = this.socket.read()\n      if (chunk === null) {\n        break\n      }\n      this.execute(chunk)\n    }\n  }\n\n  execute (data) {\n    assert(this.ptr != null)\n    assert(currentParser == null)\n    assert(!this.paused)\n\n    const { socket, llhttp } = this\n\n    if (data.length > currentBufferSize) {\n      if (currentBufferPtr) {\n        llhttp.free(currentBufferPtr)\n      }\n      currentBufferSize = Math.ceil(data.length / 4096) * 4096\n      currentBufferPtr = llhttp.malloc(currentBufferSize)\n    }\n\n    new Uint8Array(llhttp.memory.buffer, currentBufferPtr, currentBufferSize).set(data)\n\n    // Call `execute` on the wasm parser.\n    // We pass the `llhttp_parser` pointer address, the pointer address of buffer view data,\n    // and finally the length of bytes to parse.\n    // The return value is an error code or `constants.ERROR.OK`.\n    try {\n      let ret\n\n      try {\n        currentBufferRef = data\n        currentParser = this\n        ret = llhttp.llhttp_execute(this.ptr, currentBufferPtr, data.length)\n        /* eslint-disable-next-line no-useless-catch */\n      } catch (err) {\n        /* istanbul ignore next: difficult to make a test case for */\n        throw err\n      } finally {\n        currentParser = null\n        currentBufferRef = null\n      }\n\n      const offset = llhttp.llhttp_get_error_pos(this.ptr) - currentBufferPtr\n\n      if (ret === constants.ERROR.PAUSED_UPGRADE) {\n        this.onUpgrade(data.slice(offset))\n      } else if (ret === constants.ERROR.PAUSED) {\n        this.paused = true\n        socket.unshift(data.slice(offset))\n      } else if (ret !== constants.ERROR.OK) {\n        const ptr = llhttp.llhttp_get_error_reason(this.ptr)\n        let message = ''\n        /* istanbul ignore else: difficult to make a test case for */\n        if (ptr) {\n          const len = new Uint8Array(llhttp.memory.buffer, ptr).indexOf(0)\n          message =\n            'Response does not match the HTTP/1.1 protocol (' +\n            Buffer.from(llhttp.memory.buffer, ptr, len).toString() +\n            ')'\n        }\n        throw new HTTPParserError(message, constants.ERROR[ret], data.slice(offset))\n      }\n    } catch (err) {\n      util.destroy(socket, err)\n    }\n  }\n\n  destroy () {\n    assert(this.ptr != null)\n    assert(currentParser == null)\n\n    this.llhttp.llhttp_free(this.ptr)\n    this.ptr = null\n\n    this.timeout && timers.clearTimeout(this.timeout)\n    this.timeout = null\n    this.timeoutValue = null\n    this.timeoutType = null\n\n    this.paused = false\n  }\n\n  onStatus (buf) {\n    this.statusText = buf.toString()\n  }\n\n  onMessageBegin () {\n    const { socket, client } = this\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n    if (!request) {\n      return -1\n    }\n    request.onResponseStarted()\n  }\n\n  onHeaderField (buf) {\n    const len = this.headers.length\n\n    if ((len & 1) === 0) {\n      this.headers.push(buf)\n    } else {\n      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf])\n    }\n\n    this.trackHeader(buf.length)\n  }\n\n  onHeaderValue (buf) {\n    let len = this.headers.length\n\n    if ((len & 1) === 1) {\n      this.headers.push(buf)\n      len += 1\n    } else {\n      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf])\n    }\n\n    const key = this.headers[len - 2]\n    if (key.length === 10) {\n      const headerName = util.bufferToLowerCasedHeaderName(key)\n      if (headerName === 'keep-alive') {\n        this.keepAlive += buf.toString()\n      } else if (headerName === 'connection') {\n        this.connection += buf.toString()\n      }\n    } else if (key.length === 14 && util.bufferToLowerCasedHeaderName(key) === 'content-length') {\n      this.contentLength += buf.toString()\n    }\n\n    this.trackHeader(buf.length)\n  }\n\n  trackHeader (len) {\n    this.headersSize += len\n    if (this.headersSize >= this.headersMaxSize) {\n      util.destroy(this.socket, new HeadersOverflowError())\n    }\n  }\n\n  onUpgrade (head) {\n    const { upgrade, client, socket, headers, statusCode } = this\n\n    assert(upgrade)\n    assert(client[kSocket] === socket)\n    assert(!socket.destroyed)\n    assert(!this.paused)\n    assert((headers.length & 1) === 0)\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n    assert(request.upgrade || request.method === 'CONNECT')\n\n    this.statusCode = null\n    this.statusText = ''\n    this.shouldKeepAlive = null\n\n    this.headers = []\n    this.headersSize = 0\n\n    socket.unshift(head)\n\n    socket[kParser].destroy()\n    socket[kParser] = null\n\n    socket[kClient] = null\n    socket[kError] = null\n\n    removeAllListeners(socket)\n\n    client[kSocket] = null\n    client[kHTTPContext] = null // TODO (fix): This is hacky...\n    client[kQueue][client[kRunningIdx]++] = null\n    client.emit('disconnect', client[kUrl], [client], new InformationalError('upgrade'))\n\n    try {\n      request.onUpgrade(statusCode, headers, socket)\n    } catch (err) {\n      util.destroy(socket, err)\n    }\n\n    client[kResume]()\n  }\n\n  onHeadersComplete (statusCode, upgrade, shouldKeepAlive) {\n    const { client, socket, headers, statusText } = this\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (!request) {\n      return -1\n    }\n\n    assert(!this.upgrade)\n    assert(this.statusCode < 200)\n\n    if (statusCode === 100) {\n      util.destroy(socket, new SocketError('bad response', util.getSocketInfo(socket)))\n      return -1\n    }\n\n    /* this can only happen if server is misbehaving */\n    if (upgrade && !request.upgrade) {\n      util.destroy(socket, new SocketError('bad upgrade', util.getSocketInfo(socket)))\n      return -1\n    }\n\n    assert(this.timeoutType === TIMEOUT_HEADERS)\n\n    this.statusCode = statusCode\n    this.shouldKeepAlive = (\n      shouldKeepAlive ||\n      // Override llhttp value which does not allow keepAlive for HEAD.\n      (request.method === 'HEAD' && !socket[kReset] && this.connection.toLowerCase() === 'keep-alive')\n    )\n\n    if (this.statusCode >= 200) {\n      const bodyTimeout = request.bodyTimeout != null\n        ? request.bodyTimeout\n        : client[kBodyTimeout]\n      this.setTimeout(bodyTimeout, TIMEOUT_BODY)\n    } else if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    if (request.method === 'CONNECT') {\n      assert(client[kRunning] === 1)\n      this.upgrade = true\n      return 2\n    }\n\n    if (upgrade) {\n      assert(client[kRunning] === 1)\n      this.upgrade = true\n      return 2\n    }\n\n    assert((this.headers.length & 1) === 0)\n    this.headers = []\n    this.headersSize = 0\n\n    if (this.shouldKeepAlive && client[kPipelining]) {\n      const keepAliveTimeout = this.keepAlive ? util.parseKeepAliveTimeout(this.keepAlive) : null\n\n      if (keepAliveTimeout != null) {\n        const timeout = Math.min(\n          keepAliveTimeout - client[kKeepAliveTimeoutThreshold],\n          client[kKeepAliveMaxTimeout]\n        )\n        if (timeout <= 0) {\n          socket[kReset] = true\n        } else {\n          client[kKeepAliveTimeoutValue] = timeout\n        }\n      } else {\n        client[kKeepAliveTimeoutValue] = client[kKeepAliveDefaultTimeout]\n      }\n    } else {\n      // Stop more requests from being dispatched.\n      socket[kReset] = true\n    }\n\n    const pause = request.onHeaders(statusCode, headers, this.resume, statusText) === false\n\n    if (request.aborted) {\n      return -1\n    }\n\n    if (request.method === 'HEAD') {\n      return 1\n    }\n\n    if (statusCode < 200) {\n      return 1\n    }\n\n    if (socket[kBlocking]) {\n      socket[kBlocking] = false\n      client[kResume]()\n    }\n\n    return pause ? constants.ERROR.PAUSED : 0\n  }\n\n  onBody (buf) {\n    const { client, socket, statusCode, maxResponseSize } = this\n\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n\n    assert(this.timeoutType === TIMEOUT_BODY)\n    if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    assert(statusCode >= 200)\n\n    if (maxResponseSize > -1 && this.bytesRead + buf.length > maxResponseSize) {\n      util.destroy(socket, new ResponseExceededMaxSizeError())\n      return -1\n    }\n\n    this.bytesRead += buf.length\n\n    if (request.onData(buf) === false) {\n      return constants.ERROR.PAUSED\n    }\n  }\n\n  onMessageComplete () {\n    const { client, socket, statusCode, upgrade, headers, contentLength, bytesRead, shouldKeepAlive } = this\n\n    if (socket.destroyed && (!statusCode || shouldKeepAlive)) {\n      return -1\n    }\n\n    if (upgrade) {\n      return\n    }\n\n    assert(statusCode >= 100)\n    assert((this.headers.length & 1) === 0)\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n\n    this.statusCode = null\n    this.statusText = ''\n    this.bytesRead = 0\n    this.contentLength = ''\n    this.keepAlive = ''\n    this.connection = ''\n\n    this.headers = []\n    this.headersSize = 0\n\n    if (statusCode < 200) {\n      return\n    }\n\n    /* istanbul ignore next: should be handled by llhttp? */\n    if (request.method !== 'HEAD' && contentLength && bytesRead !== parseInt(contentLength, 10)) {\n      util.destroy(socket, new ResponseContentLengthMismatchError())\n      return -1\n    }\n\n    request.onComplete(headers)\n\n    client[kQueue][client[kRunningIdx]++] = null\n\n    if (socket[kWriting]) {\n      assert(client[kRunning] === 0)\n      // Response completed before request.\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (!shouldKeepAlive) {\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (socket[kReset] && client[kRunning] === 0) {\n      // Destroy socket once all requests have completed.\n      // The request at the tail of the pipeline is the one\n      // that requested reset and no further requests should\n      // have been queued since then.\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (client[kPipelining] == null || client[kPipelining] === 1) {\n      // We must wait a full event loop cycle to reuse this socket to make sure\n      // that non-spec compliant servers are not closing the connection even if they\n      // said they won't.\n      setImmediate(() => client[kResume]())\n    } else {\n      client[kResume]()\n    }\n  }\n}\n\nfunction onParserTimeout (parser) {\n  const { socket, timeoutType, client, paused } = parser.deref()\n\n  /* istanbul ignore else */\n  if (timeoutType === TIMEOUT_HEADERS) {\n    if (!socket[kWriting] || socket.writableNeedDrain || client[kRunning] > 1) {\n      assert(!paused, 'cannot be paused while waiting for headers')\n      util.destroy(socket, new HeadersTimeoutError())\n    }\n  } else if (timeoutType === TIMEOUT_BODY) {\n    if (!paused) {\n      util.destroy(socket, new BodyTimeoutError())\n    }\n  } else if (timeoutType === TIMEOUT_KEEP_ALIVE) {\n    assert(client[kRunning] === 0 && client[kKeepAliveTimeoutValue])\n    util.destroy(socket, new InformationalError('socket idle timeout'))\n  }\n}\n\nasync function connectH1 (client, socket) {\n  client[kSocket] = socket\n\n  if (!llhttpInstance) {\n    llhttpInstance = await llhttpPromise\n    llhttpPromise = null\n  }\n\n  socket[kNoRef] = false\n  socket[kWriting] = false\n  socket[kReset] = false\n  socket[kBlocking] = false\n  socket[kParser] = new Parser(client, socket, llhttpInstance)\n\n  addListener(socket, 'error', function (err) {\n    assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')\n\n    const parser = this[kParser]\n\n    // On Mac OS, we get an ECONNRESET even if there is a full body to be forwarded\n    // to the user.\n    if (err.code === 'ECONNRESET' && parser.statusCode && !parser.shouldKeepAlive) {\n      // We treat all incoming data so for as a valid response.\n      parser.onMessageComplete()\n      return\n    }\n\n    this[kError] = err\n\n    this[kClient][kOnError](err)\n  })\n  addListener(socket, 'readable', function () {\n    const parser = this[kParser]\n\n    if (parser) {\n      parser.readMore()\n    }\n  })\n  addListener(socket, 'end', function () {\n    const parser = this[kParser]\n\n    if (parser.statusCode && !parser.shouldKeepAlive) {\n      // We treat all incoming data so far as a valid response.\n      parser.onMessageComplete()\n      return\n    }\n\n    util.destroy(this, new SocketError('other side closed', util.getSocketInfo(this)))\n  })\n  addListener(socket, 'close', function () {\n    const client = this[kClient]\n    const parser = this[kParser]\n\n    if (parser) {\n      if (!this[kError] && parser.statusCode && !parser.shouldKeepAlive) {\n        // We treat all incoming data so far as a valid response.\n        parser.onMessageComplete()\n      }\n\n      this[kParser].destroy()\n      this[kParser] = null\n    }\n\n    const err = this[kError] || new SocketError('closed', util.getSocketInfo(this))\n\n    client[kSocket] = null\n    client[kHTTPContext] = null // TODO (fix): This is hacky...\n\n    if (client.destroyed) {\n      assert(client[kPending] === 0)\n\n      // Fail entire queue.\n      const requests = client[kQueue].splice(client[kRunningIdx])\n      for (let i = 0; i < requests.length; i++) {\n        const request = requests[i]\n        util.errorRequest(client, request, err)\n      }\n    } else if (client[kRunning] > 0 && err.code !== 'UND_ERR_INFO') {\n      // Fail head of pipeline.\n      const request = client[kQueue][client[kRunningIdx]]\n      client[kQueue][client[kRunningIdx]++] = null\n\n      util.errorRequest(client, request, err)\n    }\n\n    client[kPendingIdx] = client[kRunningIdx]\n\n    assert(client[kRunning] === 0)\n\n    client.emit('disconnect', client[kUrl], [client], err)\n\n    client[kResume]()\n  })\n\n  let closed = false\n  socket.on('close', () => {\n    closed = true\n  })\n\n  return {\n    version: 'h1',\n    defaultPipelining: 1,\n    write (...args) {\n      return writeH1(client, ...args)\n    },\n    resume () {\n      resumeH1(client)\n    },\n    destroy (err, callback) {\n      if (closed) {\n        queueMicrotask(callback)\n      } else {\n        socket.destroy(err).on('close', callback)\n      }\n    },\n    get destroyed () {\n      return socket.destroyed\n    },\n    busy (request) {\n      if (socket[kWriting] || socket[kReset] || socket[kBlocking]) {\n        return true\n      }\n\n      if (request) {\n        if (client[kRunning] > 0 && !request.idempotent) {\n          // Non-idempotent request cannot be retried.\n          // Ensure that no other requests are inflight and\n          // could cause failure.\n          return true\n        }\n\n        if (client[kRunning] > 0 && (request.upgrade || request.method === 'CONNECT')) {\n          // Don't dispatch an upgrade until all preceding requests have completed.\n          // A misbehaving server might upgrade the connection before all pipelined\n          // request has completed.\n          return true\n        }\n\n        if (client[kRunning] > 0 && util.bodyLength(request.body) !== 0 &&\n          (util.isStream(request.body) || util.isAsyncIterable(request.body) || util.isFormDataLike(request.body))) {\n          // Request with stream or iterator body can error while other requests\n          // are inflight and indirectly error those as well.\n          // Ensure this doesn't happen by waiting for inflight\n          // to complete before dispatching.\n\n          // Request with stream or iterator body cannot be retried.\n          // Ensure that no other requests are inflight and\n          // could cause failure.\n          return true\n        }\n      }\n\n      return false\n    }\n  }\n}\n\nfunction resumeH1 (client) {\n  const socket = client[kSocket]\n\n  if (socket && !socket.destroyed) {\n    if (client[kSize] === 0) {\n      if (!socket[kNoRef] && socket.unref) {\n        socket.unref()\n        socket[kNoRef] = true\n      }\n    } else if (socket[kNoRef] && socket.ref) {\n      socket.ref()\n      socket[kNoRef] = false\n    }\n\n    if (client[kSize] === 0) {\n      if (socket[kParser].timeoutType !== TIMEOUT_KEEP_ALIVE) {\n        socket[kParser].setTimeout(client[kKeepAliveTimeoutValue], TIMEOUT_KEEP_ALIVE)\n      }\n    } else if (client[kRunning] > 0 && socket[kParser].statusCode < 200) {\n      if (socket[kParser].timeoutType !== TIMEOUT_HEADERS) {\n        const request = client[kQueue][client[kRunningIdx]]\n        const headersTimeout = request.headersTimeout != null\n          ? request.headersTimeout\n          : client[kHeadersTimeout]\n        socket[kParser].setTimeout(headersTimeout, TIMEOUT_HEADERS)\n      }\n    }\n  }\n}\n\n// https://www.rfc-editor.org/rfc/rfc7230#section-3.3.2\nfunction shouldSendContentLength (method) {\n  return method !== 'GET' && method !== 'HEAD' && method !== 'OPTIONS' && method !== 'TRACE' && method !== 'CONNECT'\n}\n\nfunction writeH1 (client, request) {\n  const { method, path, host, upgrade, blocking, reset } = request\n\n  let { body, headers, contentLength } = request\n\n  // https://tools.ietf.org/html/rfc7231#section-4.3.1\n  // https://tools.ietf.org/html/rfc7231#section-4.3.2\n  // https://tools.ietf.org/html/rfc7231#section-4.3.5\n\n  // Sending a payload body on a request that does not\n  // expect it can cause undefined behavior on some\n  // servers and corrupt connection state. Do not\n  // re-use the connection for further requests.\n\n  const expectsPayload = (\n    method === 'PUT' ||\n    method === 'POST' ||\n    method === 'PATCH' ||\n    method === 'QUERY' ||\n    method === 'PROPFIND' ||\n    method === 'PROPPATCH'\n  )\n\n  if (util.isFormDataLike(body)) {\n    if (!extractBody) {\n      extractBody = require('../web/fetch/body.js').extractBody\n    }\n\n    const [bodyStream, contentType] = extractBody(body)\n    if (request.contentType == null) {\n      headers.push('content-type', contentType)\n    }\n    body = bodyStream.stream\n    contentLength = bodyStream.length\n  } else if (util.isBlobLike(body) && request.contentType == null && body.type) {\n    headers.push('content-type', body.type)\n  }\n\n  if (body && typeof body.read === 'function') {\n    // Try to read EOF in order to get length.\n    body.read(0)\n  }\n\n  const bodyLength = util.bodyLength(body)\n\n  contentLength = bodyLength ?? contentLength\n\n  if (contentLength === null) {\n    contentLength = request.contentLength\n  }\n\n  if (contentLength === 0 && !expectsPayload) {\n    // https://tools.ietf.org/html/rfc7230#section-3.3.2\n    // A user agent SHOULD NOT send a Content-Length header field when\n    // the request message does not contain a payload body and the method\n    // semantics do not anticipate such a body.\n\n    contentLength = null\n  }\n\n  // https://github.com/nodejs/undici/issues/2046\n  // A user agent may send a Content-Length header with 0 value, this should be allowed.\n  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength !== null && request.contentLength !== contentLength) {\n    if (client[kStrictContentLength]) {\n      util.errorRequest(client, request, new RequestContentLengthMismatchError())\n      return false\n    }\n\n    process.emitWarning(new RequestContentLengthMismatchError())\n  }\n\n  const socket = client[kSocket]\n\n  const abort = (err) => {\n    if (request.aborted || request.completed) {\n      return\n    }\n\n    util.errorRequest(client, request, err || new RequestAbortedError())\n\n    util.destroy(body)\n    util.destroy(socket, new InformationalError('aborted'))\n  }\n\n  try {\n    request.onConnect(abort)\n  } catch (err) {\n    util.errorRequest(client, request, err)\n  }\n\n  if (request.aborted) {\n    return false\n  }\n\n  if (method === 'HEAD') {\n    // https://github.com/mcollina/undici/issues/258\n    // Close after a HEAD request to interop with misbehaving servers\n    // that may send a body in the response.\n\n    socket[kReset] = true\n  }\n\n  if (upgrade || method === 'CONNECT') {\n    // On CONNECT or upgrade, block pipeline from dispatching further\n    // requests on this connection.\n\n    socket[kReset] = true\n  }\n\n  if (reset != null) {\n    socket[kReset] = reset\n  }\n\n  if (client[kMaxRequests] && socket[kCounter]++ >= client[kMaxRequests]) {\n    socket[kReset] = true\n  }\n\n  if (blocking) {\n    socket[kBlocking] = true\n  }\n\n  let header = `${method} ${path} HTTP/1.1\\r\\n`\n\n  if (typeof host === 'string') {\n    header += `host: ${host}\\r\\n`\n  } else {\n    header += client[kHostHeader]\n  }\n\n  if (upgrade) {\n    header += `connection: upgrade\\r\\nupgrade: ${upgrade}\\r\\n`\n  } else if (client[kPipelining] && !socket[kReset]) {\n    header += 'connection: keep-alive\\r\\n'\n  } else {\n    header += 'connection: close\\r\\n'\n  }\n\n  if (Array.isArray(headers)) {\n    for (let n = 0; n < headers.length; n += 2) {\n      const key = headers[n + 0]\n      const val = headers[n + 1]\n\n      if (Array.isArray(val)) {\n        for (let i = 0; i < val.length; i++) {\n          header += `${key}: ${val[i]}\\r\\n`\n        }\n      } else {\n        header += `${key}: ${val}\\r\\n`\n      }\n    }\n  }\n\n  if (channels.sendHeaders.hasSubscribers) {\n    channels.sendHeaders.publish({ request, headers: header, socket })\n  }\n\n  /* istanbul ignore else: assertion */\n  if (!body || bodyLength === 0) {\n    writeBuffer(abort, null, client, request, socket, contentLength, header, expectsPayload)\n  } else if (util.isBuffer(body)) {\n    writeBuffer(abort, body, client, request, socket, contentLength, header, expectsPayload)\n  } else if (util.isBlobLike(body)) {\n    if (typeof body.stream === 'function') {\n      writeIterable(abort, body.stream(), client, request, socket, contentLength, header, expectsPayload)\n    } else {\n      writeBlob(abort, body, client, request, socket, contentLength, header, expectsPayload)\n    }\n  } else if (util.isStream(body)) {\n    writeStream(abort, body, client, request, socket, contentLength, header, expectsPayload)\n  } else if (util.isIterable(body)) {\n    writeIterable(abort, body, client, request, socket, contentLength, header, expectsPayload)\n  } else {\n    assert(false)\n  }\n\n  return true\n}\n\nfunction writeStream (abort, body, client, request, socket, contentLength, header, expectsPayload) {\n  assert(contentLength !== 0 || client[kRunning] === 0, 'stream body cannot be pipelined')\n\n  let finished = false\n\n  const writer = new AsyncWriter({ abort, socket, request, contentLength, client, expectsPayload, header })\n\n  const onData = function (chunk) {\n    if (finished) {\n      return\n    }\n\n    try {\n      if (!writer.write(chunk) && this.pause) {\n        this.pause()\n      }\n    } catch (err) {\n      util.destroy(this, err)\n    }\n  }\n  const onDrain = function () {\n    if (finished) {\n      return\n    }\n\n    if (body.resume) {\n      body.resume()\n    }\n  }\n  const onClose = function () {\n    // 'close' might be emitted *before* 'error' for\n    // broken streams. Wait a tick to avoid this case.\n    queueMicrotask(() => {\n      // It's only safe to remove 'error' listener after\n      // 'close'.\n      body.removeListener('error', onFinished)\n    })\n\n    if (!finished) {\n      const err = new RequestAbortedError()\n      queueMicrotask(() => onFinished(err))\n    }\n  }\n  const onFinished = function (err) {\n    if (finished) {\n      return\n    }\n\n    finished = true\n\n    assert(socket.destroyed || (socket[kWriting] && client[kRunning] <= 1))\n\n    socket\n      .off('drain', onDrain)\n      .off('error', onFinished)\n\n    body\n      .removeListener('data', onData)\n      .removeListener('end', onFinished)\n      .removeListener('close', onClose)\n\n    if (!err) {\n      try {\n        writer.end()\n      } catch (er) {\n        err = er\n      }\n    }\n\n    writer.destroy(err)\n\n    if (err && (err.code !== 'UND_ERR_INFO' || err.message !== 'reset')) {\n      util.destroy(body, err)\n    } else {\n      util.destroy(body)\n    }\n  }\n\n  body\n    .on('data', onData)\n    .on('end', onFinished)\n    .on('error', onFinished)\n    .on('close', onClose)\n\n  if (body.resume) {\n    body.resume()\n  }\n\n  socket\n    .on('drain', onDrain)\n    .on('error', onFinished)\n\n  if (body.errorEmitted ?? body.errored) {\n    setImmediate(() => onFinished(body.errored))\n  } else if (body.endEmitted ?? body.readableEnded) {\n    setImmediate(() => onFinished(null))\n  }\n\n  if (body.closeEmitted ?? body.closed) {\n    setImmediate(onClose)\n  }\n}\n\nfunction writeBuffer (abort, body, client, request, socket, contentLength, header, expectsPayload) {\n  try {\n    if (!body) {\n      if (contentLength === 0) {\n        socket.write(`${header}content-length: 0\\r\\n\\r\\n`, 'latin1')\n      } else {\n        assert(contentLength === null, 'no body must not have content length')\n        socket.write(`${header}\\r\\n`, 'latin1')\n      }\n    } else if (util.isBuffer(body)) {\n      assert(contentLength === body.byteLength, 'buffer body must have content length')\n\n      socket.cork()\n      socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n      socket.write(body)\n      socket.uncork()\n      request.onBodySent(body)\n\n      if (!expectsPayload && request.reset !== false) {\n        socket[kReset] = true\n      }\n    }\n    request.onRequestSent()\n\n    client[kResume]()\n  } catch (err) {\n    abort(err)\n  }\n}\n\nasync function writeBlob (abort, body, client, request, socket, contentLength, header, expectsPayload) {\n  assert(contentLength === body.size, 'blob body must have content length')\n\n  try {\n    if (contentLength != null && contentLength !== body.size) {\n      throw new RequestContentLengthMismatchError()\n    }\n\n    const buffer = Buffer.from(await body.arrayBuffer())\n\n    socket.cork()\n    socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n    socket.write(buffer)\n    socket.uncork()\n\n    request.onBodySent(buffer)\n    request.onRequestSent()\n\n    if (!expectsPayload && request.reset !== false) {\n      socket[kReset] = true\n    }\n\n    client[kResume]()\n  } catch (err) {\n    abort(err)\n  }\n}\n\nasync function writeIterable (abort, body, client, request, socket, contentLength, header, expectsPayload) {\n  assert(contentLength !== 0 || client[kRunning] === 0, 'iterator body cannot be pipelined')\n\n  let callback = null\n  function onDrain () {\n    if (callback) {\n      const cb = callback\n      callback = null\n      cb()\n    }\n  }\n\n  const waitForDrain = () => new Promise((resolve, reject) => {\n    assert(callback === null)\n\n    if (socket[kError]) {\n      reject(socket[kError])\n    } else {\n      callback = resolve\n    }\n  })\n\n  socket\n    .on('close', onDrain)\n    .on('drain', onDrain)\n\n  const writer = new AsyncWriter({ abort, socket, request, contentLength, client, expectsPayload, header })\n  try {\n    // It's up to the user to somehow abort the async iterable.\n    for await (const chunk of body) {\n      if (socket[kError]) {\n        throw socket[kError]\n      }\n\n      if (!writer.write(chunk)) {\n        await waitForDrain()\n      }\n    }\n\n    writer.end()\n  } catch (err) {\n    writer.destroy(err)\n  } finally {\n    socket\n      .off('close', onDrain)\n      .off('drain', onDrain)\n  }\n}\n\nclass AsyncWriter {\n  constructor ({ abort, socket, request, contentLength, client, expectsPayload, header }) {\n    this.socket = socket\n    this.request = request\n    this.contentLength = contentLength\n    this.client = client\n    this.bytesWritten = 0\n    this.expectsPayload = expectsPayload\n    this.header = header\n    this.abort = abort\n\n    socket[kWriting] = true\n  }\n\n  write (chunk) {\n    const { socket, request, contentLength, client, bytesWritten, expectsPayload, header } = this\n\n    if (socket[kError]) {\n      throw socket[kError]\n    }\n\n    if (socket.destroyed) {\n      return false\n    }\n\n    const len = Buffer.byteLength(chunk)\n    if (!len) {\n      return true\n    }\n\n    // We should defer writing chunks.\n    if (contentLength !== null && bytesWritten + len > contentLength) {\n      if (client[kStrictContentLength]) {\n        throw new RequestContentLengthMismatchError()\n      }\n\n      process.emitWarning(new RequestContentLengthMismatchError())\n    }\n\n    socket.cork()\n\n    if (bytesWritten === 0) {\n      if (!expectsPayload && request.reset !== false) {\n        socket[kReset] = true\n      }\n\n      if (contentLength === null) {\n        socket.write(`${header}transfer-encoding: chunked\\r\\n`, 'latin1')\n      } else {\n        socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n      }\n    }\n\n    if (contentLength === null) {\n      socket.write(`\\r\\n${len.toString(16)}\\r\\n`, 'latin1')\n    }\n\n    this.bytesWritten += len\n\n    const ret = socket.write(chunk)\n\n    socket.uncork()\n\n    request.onBodySent(chunk)\n\n    if (!ret) {\n      if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {\n        // istanbul ignore else: only for jest\n        if (socket[kParser].timeout.refresh) {\n          socket[kParser].timeout.refresh()\n        }\n      }\n    }\n\n    return ret\n  }\n\n  end () {\n    const { socket, contentLength, client, bytesWritten, expectsPayload, header, request } = this\n    request.onRequestSent()\n\n    socket[kWriting] = false\n\n    if (socket[kError]) {\n      throw socket[kError]\n    }\n\n    if (socket.destroyed) {\n      return\n    }\n\n    if (bytesWritten === 0) {\n      if (expectsPayload) {\n        // https://tools.ietf.org/html/rfc7230#section-3.3.2\n        // A user agent SHOULD send a Content-Length in a request message when\n        // no Transfer-Encoding is sent and the request method defines a meaning\n        // for an enclosed payload body.\n\n        socket.write(`${header}content-length: 0\\r\\n\\r\\n`, 'latin1')\n      } else {\n        socket.write(`${header}\\r\\n`, 'latin1')\n      }\n    } else if (contentLength === null) {\n      socket.write('\\r\\n0\\r\\n\\r\\n', 'latin1')\n    }\n\n    if (contentLength !== null && bytesWritten !== contentLength) {\n      if (client[kStrictContentLength]) {\n        throw new RequestContentLengthMismatchError()\n      } else {\n        process.emitWarning(new RequestContentLengthMismatchError())\n      }\n    }\n\n    if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {\n      // istanbul ignore else: only for jest\n      if (socket[kParser].timeout.refresh) {\n        socket[kParser].timeout.refresh()\n      }\n    }\n\n    client[kResume]()\n  }\n\n  destroy (err) {\n    const { socket, client, abort } = this\n\n    socket[kWriting] = false\n\n    if (err) {\n      assert(client[kRunning] <= 1, 'pipeline should only contain this request')\n      abort(err)\n    }\n  }\n}\n\nmodule.exports = connectH1\n","'use strict'\n\nconst assert = require('node:assert')\nconst { pipeline } = require('node:stream')\nconst util = require('../core/util.js')\nconst {\n  RequestContentLengthMismatchError,\n  RequestAbortedError,\n  SocketError,\n  InformationalError\n} = require('../core/errors.js')\nconst {\n  kUrl,\n  kReset,\n  kClient,\n  kRunning,\n  kPending,\n  kQueue,\n  kPendingIdx,\n  kRunningIdx,\n  kError,\n  kSocket,\n  kStrictContentLength,\n  kOnError,\n  kMaxConcurrentStreams,\n  kHTTP2Session,\n  kResume,\n  kSize,\n  kHTTPContext\n} = require('../core/symbols.js')\n\nconst kOpenStreams = Symbol('open streams')\n\nlet extractBody\n\n// Experimental\nlet h2ExperimentalWarned = false\n\n/** @type {import('http2')} */\nlet http2\ntry {\n  http2 = require('node:http2')\n} catch {\n  // @ts-ignore\n  http2 = { constants: {} }\n}\n\nconst {\n  constants: {\n    HTTP2_HEADER_AUTHORITY,\n    HTTP2_HEADER_METHOD,\n    HTTP2_HEADER_PATH,\n    HTTP2_HEADER_SCHEME,\n    HTTP2_HEADER_CONTENT_LENGTH,\n    HTTP2_HEADER_EXPECT,\n    HTTP2_HEADER_STATUS\n  }\n} = http2\n\nfunction parseH2Headers (headers) {\n  const result = []\n\n  for (const [name, value] of Object.entries(headers)) {\n    // h2 may concat the header value by array\n    // e.g. Set-Cookie\n    if (Array.isArray(value)) {\n      for (const subvalue of value) {\n        // we need to provide each header value of header name\n        // because the headers handler expect name-value pair\n        result.push(Buffer.from(name), Buffer.from(subvalue))\n      }\n    } else {\n      result.push(Buffer.from(name), Buffer.from(value))\n    }\n  }\n\n  return result\n}\n\nasync function connectH2 (client, socket) {\n  client[kSocket] = socket\n\n  if (!h2ExperimentalWarned) {\n    h2ExperimentalWarned = true\n    process.emitWarning('H2 support is experimental, expect them to change at any time.', {\n      code: 'UNDICI-H2'\n    })\n  }\n\n  const session = http2.connect(client[kUrl], {\n    createConnection: () => socket,\n    peerMaxConcurrentStreams: client[kMaxConcurrentStreams]\n  })\n\n  session[kOpenStreams] = 0\n  session[kClient] = client\n  session[kSocket] = socket\n\n  util.addListener(session, 'error', onHttp2SessionError)\n  util.addListener(session, 'frameError', onHttp2FrameError)\n  util.addListener(session, 'end', onHttp2SessionEnd)\n  util.addListener(session, 'goaway', onHTTP2GoAway)\n  util.addListener(session, 'close', function () {\n    const { [kClient]: client } = this\n    const { [kSocket]: socket } = client\n\n    const err = this[kSocket][kError] || this[kError] || new SocketError('closed', util.getSocketInfo(socket))\n\n    client[kHTTP2Session] = null\n\n    if (client.destroyed) {\n      assert(client[kPending] === 0)\n\n      // Fail entire queue.\n      const requests = client[kQueue].splice(client[kRunningIdx])\n      for (let i = 0; i < requests.length; i++) {\n        const request = requests[i]\n        util.errorRequest(client, request, err)\n      }\n    }\n  })\n\n  session.unref()\n\n  client[kHTTP2Session] = session\n  socket[kHTTP2Session] = session\n\n  util.addListener(socket, 'error', function (err) {\n    assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')\n\n    this[kError] = err\n\n    this[kClient][kOnError](err)\n  })\n\n  util.addListener(socket, 'end', function () {\n    util.destroy(this, new SocketError('other side closed', util.getSocketInfo(this)))\n  })\n\n  util.addListener(socket, 'close', function () {\n    const err = this[kError] || new SocketError('closed', util.getSocketInfo(this))\n\n    client[kSocket] = null\n\n    if (this[kHTTP2Session] != null) {\n      this[kHTTP2Session].destroy(err)\n    }\n\n    client[kPendingIdx] = client[kRunningIdx]\n\n    assert(client[kRunning] === 0)\n\n    client.emit('disconnect', client[kUrl], [client], err)\n\n    client[kResume]()\n  })\n\n  let closed = false\n  socket.on('close', () => {\n    closed = true\n  })\n\n  return {\n    version: 'h2',\n    defaultPipelining: Infinity,\n    write (...args) {\n      return writeH2(client, ...args)\n    },\n    resume () {\n      resumeH2(client)\n    },\n    destroy (err, callback) {\n      if (closed) {\n        queueMicrotask(callback)\n      } else {\n        // Destroying the socket will trigger the session close\n        socket.destroy(err).on('close', callback)\n      }\n    },\n    get destroyed () {\n      return socket.destroyed\n    },\n    busy () {\n      return false\n    }\n  }\n}\n\nfunction resumeH2 (client) {\n  const socket = client[kSocket]\n\n  if (socket?.destroyed === false) {\n    if (client[kSize] === 0 && client[kMaxConcurrentStreams] === 0) {\n      socket.unref()\n      client[kHTTP2Session].unref()\n    } else {\n      socket.ref()\n      client[kHTTP2Session].ref()\n    }\n  }\n}\n\nfunction onHttp2SessionError (err) {\n  assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')\n\n  this[kSocket][kError] = err\n  this[kClient][kOnError](err)\n}\n\nfunction onHttp2FrameError (type, code, id) {\n  if (id === 0) {\n    const err = new InformationalError(`HTTP/2: \"frameError\" received - type ${type}, code ${code}`)\n    this[kSocket][kError] = err\n    this[kClient][kOnError](err)\n  }\n}\n\nfunction onHttp2SessionEnd () {\n  const err = new SocketError('other side closed', util.getSocketInfo(this[kSocket]))\n  this.destroy(err)\n  util.destroy(this[kSocket], err)\n}\n\n/**\n * This is the root cause of #3011\n * We need to handle GOAWAY frames properly, and trigger the session close\n * along with the socket right away\n */\nfunction onHTTP2GoAway (code) {\n  // We cannot recover, so best to close the session and the socket\n  const err = this[kError] || new SocketError(`HTTP/2: \"GOAWAY\" frame received with code ${code}`, util.getSocketInfo(this))\n  const client = this[kClient]\n\n  client[kSocket] = null\n  client[kHTTPContext] = null\n\n  if (this[kHTTP2Session] != null) {\n    this[kHTTP2Session].destroy(err)\n    this[kHTTP2Session] = null\n  }\n\n  util.destroy(this[kSocket], err)\n\n  // Fail head of pipeline.\n  if (client[kRunningIdx] < client[kQueue].length) {\n    const request = client[kQueue][client[kRunningIdx]]\n    client[kQueue][client[kRunningIdx]++] = null\n    util.errorRequest(client, request, err)\n    client[kPendingIdx] = client[kRunningIdx]\n  }\n\n  assert(client[kRunning] === 0)\n\n  client.emit('disconnect', client[kUrl], [client], err)\n\n  client[kResume]()\n}\n\n// https://www.rfc-editor.org/rfc/rfc7230#section-3.3.2\nfunction shouldSendContentLength (method) {\n  return method !== 'GET' && method !== 'HEAD' && method !== 'OPTIONS' && method !== 'TRACE' && method !== 'CONNECT'\n}\n\nfunction writeH2 (client, request) {\n  const session = client[kHTTP2Session]\n  const { method, path, host, upgrade, expectContinue, signal, headers: reqHeaders } = request\n  let { body } = request\n\n  if (upgrade) {\n    util.errorRequest(client, request, new Error('Upgrade not supported for H2'))\n    return false\n  }\n\n  const headers = {}\n  for (let n = 0; n < reqHeaders.length; n += 2) {\n    const key = reqHeaders[n + 0]\n    const val = reqHeaders[n + 1]\n\n    if (Array.isArray(val)) {\n      for (let i = 0; i < val.length; i++) {\n        if (headers[key]) {\n          headers[key] += `,${val[i]}`\n        } else {\n          headers[key] = val[i]\n        }\n      }\n    } else {\n      headers[key] = val\n    }\n  }\n\n  /** @type {import('node:http2').ClientHttp2Stream} */\n  let stream\n\n  const { hostname, port } = client[kUrl]\n\n  headers[HTTP2_HEADER_AUTHORITY] = host || `${hostname}${port ? `:${port}` : ''}`\n  headers[HTTP2_HEADER_METHOD] = method\n\n  const abort = (err) => {\n    if (request.aborted || request.completed) {\n      return\n    }\n\n    err = err || new RequestAbortedError()\n\n    util.errorRequest(client, request, err)\n\n    if (stream != null) {\n      util.destroy(stream, err)\n    }\n\n    // We do not destroy the socket as we can continue using the session\n    // the stream get's destroyed and the session remains to create new streams\n    util.destroy(body, err)\n    client[kQueue][client[kRunningIdx]++] = null\n    client[kResume]()\n  }\n\n  try {\n    // We are already connected, streams are pending.\n    // We can call on connect, and wait for abort\n    request.onConnect(abort)\n  } catch (err) {\n    util.errorRequest(client, request, err)\n  }\n\n  if (request.aborted) {\n    return false\n  }\n\n  if (method === 'CONNECT') {\n    session.ref()\n    // We are already connected, streams are pending, first request\n    // will create a new stream. We trigger a request to create the stream and wait until\n    // `ready` event is triggered\n    // We disabled endStream to allow the user to write to the stream\n    stream = session.request(headers, { endStream: false, signal })\n\n    if (stream.id && !stream.pending) {\n      request.onUpgrade(null, null, stream)\n      ++session[kOpenStreams]\n      client[kQueue][client[kRunningIdx]++] = null\n    } else {\n      stream.once('ready', () => {\n        request.onUpgrade(null, null, stream)\n        ++session[kOpenStreams]\n        client[kQueue][client[kRunningIdx]++] = null\n      })\n    }\n\n    stream.once('close', () => {\n      session[kOpenStreams] -= 1\n      if (session[kOpenStreams] === 0) session.unref()\n    })\n\n    return true\n  }\n\n  // https://tools.ietf.org/html/rfc7540#section-8.3\n  // :path and :scheme headers must be omitted when sending CONNECT\n\n  headers[HTTP2_HEADER_PATH] = path\n  headers[HTTP2_HEADER_SCHEME] = 'https'\n\n  // https://tools.ietf.org/html/rfc7231#section-4.3.1\n  // https://tools.ietf.org/html/rfc7231#section-4.3.2\n  // https://tools.ietf.org/html/rfc7231#section-4.3.5\n\n  // Sending a payload body on a request that does not\n  // expect it can cause undefined behavior on some\n  // servers and corrupt connection state. Do not\n  // re-use the connection for further requests.\n\n  const expectsPayload = (\n    method === 'PUT' ||\n    method === 'POST' ||\n    method === 'PATCH'\n  )\n\n  if (body && typeof body.read === 'function') {\n    // Try to read EOF in order to get length.\n    body.read(0)\n  }\n\n  let contentLength = util.bodyLength(body)\n\n  if (util.isFormDataLike(body)) {\n    extractBody ??= require('../web/fetch/body.js').extractBody\n\n    const [bodyStream, contentType] = extractBody(body)\n    headers['content-type'] = contentType\n\n    body = bodyStream.stream\n    contentLength = bodyStream.length\n  }\n\n  if (contentLength == null) {\n    contentLength = request.contentLength\n  }\n\n  if (contentLength === 0 || !expectsPayload) {\n    // https://tools.ietf.org/html/rfc7230#section-3.3.2\n    // A user agent SHOULD NOT send a Content-Length header field when\n    // the request message does not contain a payload body and the method\n    // semantics do not anticipate such a body.\n\n    contentLength = null\n  }\n\n  // https://github.com/nodejs/undici/issues/2046\n  // A user agent may send a Content-Length header with 0 value, this should be allowed.\n  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength != null && request.contentLength !== contentLength) {\n    if (client[kStrictContentLength]) {\n      util.errorRequest(client, request, new RequestContentLengthMismatchError())\n      return false\n    }\n\n    process.emitWarning(new RequestContentLengthMismatchError())\n  }\n\n  if (contentLength != null) {\n    assert(body, 'no body must not have content length')\n    headers[HTTP2_HEADER_CONTENT_LENGTH] = `${contentLength}`\n  }\n\n  session.ref()\n\n  const shouldEndStream = method === 'GET' || method === 'HEAD' || body === null\n  if (expectContinue) {\n    headers[HTTP2_HEADER_EXPECT] = '100-continue'\n    stream = session.request(headers, { endStream: shouldEndStream, signal })\n\n    stream.once('continue', writeBodyH2)\n  } else {\n    stream = session.request(headers, {\n      endStream: shouldEndStream,\n      signal\n    })\n    writeBodyH2()\n  }\n\n  // Increment counter as we have new streams open\n  ++session[kOpenStreams]\n\n  stream.once('response', headers => {\n    const { [HTTP2_HEADER_STATUS]: statusCode, ...realHeaders } = headers\n    request.onResponseStarted()\n\n    // Due to the stream nature, it is possible we face a race condition\n    // where the stream has been assigned, but the request has been aborted\n    // the request remains in-flight and headers hasn't been received yet\n    // for those scenarios, best effort is to destroy the stream immediately\n    // as there's no value to keep it open.\n    if (request.aborted) {\n      const err = new RequestAbortedError()\n      util.errorRequest(client, request, err)\n      util.destroy(stream, err)\n      return\n    }\n\n    if (request.onHeaders(Number(statusCode), parseH2Headers(realHeaders), stream.resume.bind(stream), '') === false) {\n      stream.pause()\n    }\n\n    stream.on('data', (chunk) => {\n      if (request.onData(chunk) === false) {\n        stream.pause()\n      }\n    })\n  })\n\n  stream.once('end', () => {\n    // When state is null, it means we haven't consumed body and the stream still do not have\n    // a state.\n    // Present specially when using pipeline or stream\n    if (stream.state?.state == null || stream.state.state < 6) {\n      request.onComplete([])\n    }\n\n    if (session[kOpenStreams] === 0) {\n      // Stream is closed or half-closed-remote (6), decrement counter and cleanup\n      // It does not have sense to continue working with the stream as we do not\n      // have yet RST_STREAM support on client-side\n\n      session.unref()\n    }\n\n    abort(new InformationalError('HTTP/2: stream half-closed (remote)'))\n    client[kQueue][client[kRunningIdx]++] = null\n    client[kPendingIdx] = client[kRunningIdx]\n    client[kResume]()\n  })\n\n  stream.once('close', () => {\n    session[kOpenStreams] -= 1\n    if (session[kOpenStreams] === 0) {\n      session.unref()\n    }\n  })\n\n  stream.once('error', function (err) {\n    abort(err)\n  })\n\n  stream.once('frameError', (type, code) => {\n    abort(new InformationalError(`HTTP/2: \"frameError\" received - type ${type}, code ${code}`))\n  })\n\n  // stream.on('aborted', () => {\n  //   // TODO(HTTP/2): Support aborted\n  // })\n\n  // stream.on('timeout', () => {\n  //   // TODO(HTTP/2): Support timeout\n  // })\n\n  // stream.on('push', headers => {\n  //   // TODO(HTTP/2): Support push\n  // })\n\n  // stream.on('trailers', headers => {\n  //   // TODO(HTTP/2): Support trailers\n  // })\n\n  return true\n\n  function writeBodyH2 () {\n    /* istanbul ignore else: assertion */\n    if (!body || contentLength === 0) {\n      writeBuffer(\n        abort,\n        stream,\n        null,\n        client,\n        request,\n        client[kSocket],\n        contentLength,\n        expectsPayload\n      )\n    } else if (util.isBuffer(body)) {\n      writeBuffer(\n        abort,\n        stream,\n        body,\n        client,\n        request,\n        client[kSocket],\n        contentLength,\n        expectsPayload\n      )\n    } else if (util.isBlobLike(body)) {\n      if (typeof body.stream === 'function') {\n        writeIterable(\n          abort,\n          stream,\n          body.stream(),\n          client,\n          request,\n          client[kSocket],\n          contentLength,\n          expectsPayload\n        )\n      } else {\n        writeBlob(\n          abort,\n          stream,\n          body,\n          client,\n          request,\n          client[kSocket],\n          contentLength,\n          expectsPayload\n        )\n      }\n    } else if (util.isStream(body)) {\n      writeStream(\n        abort,\n        client[kSocket],\n        expectsPayload,\n        stream,\n        body,\n        client,\n        request,\n        contentLength\n      )\n    } else if (util.isIterable(body)) {\n      writeIterable(\n        abort,\n        stream,\n        body,\n        client,\n        request,\n        client[kSocket],\n        contentLength,\n        expectsPayload\n      )\n    } else {\n      assert(false)\n    }\n  }\n}\n\nfunction writeBuffer (abort, h2stream, body, client, request, socket, contentLength, expectsPayload) {\n  try {\n    if (body != null && util.isBuffer(body)) {\n      assert(contentLength === body.byteLength, 'buffer body must have content length')\n      h2stream.cork()\n      h2stream.write(body)\n      h2stream.uncork()\n      h2stream.end()\n\n      request.onBodySent(body)\n    }\n\n    if (!expectsPayload) {\n      socket[kReset] = true\n    }\n\n    request.onRequestSent()\n    client[kResume]()\n  } catch (error) {\n    abort(error)\n  }\n}\n\nfunction writeStream (abort, socket, expectsPayload, h2stream, body, client, request, contentLength) {\n  assert(contentLength !== 0 || client[kRunning] === 0, 'stream body cannot be pipelined')\n\n  // For HTTP/2, is enough to pipe the stream\n  const pipe = pipeline(\n    body,\n    h2stream,\n    (err) => {\n      if (err) {\n        util.destroy(pipe, err)\n        abort(err)\n      } else {\n        util.removeAllListeners(pipe)\n        request.onRequestSent()\n\n        if (!expectsPayload) {\n          socket[kReset] = true\n        }\n\n        client[kResume]()\n      }\n    }\n  )\n\n  util.addListener(pipe, 'data', onPipeData)\n\n  function onPipeData (chunk) {\n    request.onBodySent(chunk)\n  }\n}\n\nasync function writeBlob (abort, h2stream, body, client, request, socket, contentLength, expectsPayload) {\n  assert(contentLength === body.size, 'blob body must have content length')\n\n  try {\n    if (contentLength != null && contentLength !== body.size) {\n      throw new RequestContentLengthMismatchError()\n    }\n\n    const buffer = Buffer.from(await body.arrayBuffer())\n\n    h2stream.cork()\n    h2stream.write(buffer)\n    h2stream.uncork()\n    h2stream.end()\n\n    request.onBodySent(buffer)\n    request.onRequestSent()\n\n    if (!expectsPayload) {\n      socket[kReset] = true\n    }\n\n    client[kResume]()\n  } catch (err) {\n    abort(err)\n  }\n}\n\nasync function writeIterable (abort, h2stream, body, client, request, socket, contentLength, expectsPayload) {\n  assert(contentLength !== 0 || client[kRunning] === 0, 'iterator body cannot be pipelined')\n\n  let callback = null\n  function onDrain () {\n    if (callback) {\n      const cb = callback\n      callback = null\n      cb()\n    }\n  }\n\n  const waitForDrain = () => new Promise((resolve, reject) => {\n    assert(callback === null)\n\n    if (socket[kError]) {\n      reject(socket[kError])\n    } else {\n      callback = resolve\n    }\n  })\n\n  h2stream\n    .on('close', onDrain)\n    .on('drain', onDrain)\n\n  try {\n    // It's up to the user to somehow abort the async iterable.\n    for await (const chunk of body) {\n      if (socket[kError]) {\n        throw socket[kError]\n      }\n\n      const res = h2stream.write(chunk)\n      request.onBodySent(chunk)\n      if (!res) {\n        await waitForDrain()\n      }\n    }\n\n    h2stream.end()\n\n    request.onRequestSent()\n\n    if (!expectsPayload) {\n      socket[kReset] = true\n    }\n\n    client[kResume]()\n  } catch (err) {\n    abort(err)\n  } finally {\n    h2stream\n      .off('close', onDrain)\n      .off('drain', onDrain)\n  }\n}\n\nmodule.exports = connectH2\n","// @ts-check\n\n'use strict'\n\nconst assert = require('node:assert')\nconst net = require('node:net')\nconst http = require('node:http')\nconst util = require('../core/util.js')\nconst { channels } = require('../core/diagnostics.js')\nconst Request = require('../core/request.js')\nconst DispatcherBase = require('./dispatcher-base')\nconst {\n  InvalidArgumentError,\n  InformationalError,\n  ClientDestroyedError\n} = require('../core/errors.js')\nconst buildConnector = require('../core/connect.js')\nconst {\n  kUrl,\n  kServerName,\n  kClient,\n  kBusy,\n  kConnect,\n  kResuming,\n  kRunning,\n  kPending,\n  kSize,\n  kQueue,\n  kConnected,\n  kConnecting,\n  kNeedDrain,\n  kKeepAliveDefaultTimeout,\n  kHostHeader,\n  kPendingIdx,\n  kRunningIdx,\n  kError,\n  kPipelining,\n  kKeepAliveTimeoutValue,\n  kMaxHeadersSize,\n  kKeepAliveMaxTimeout,\n  kKeepAliveTimeoutThreshold,\n  kHeadersTimeout,\n  kBodyTimeout,\n  kStrictContentLength,\n  kConnector,\n  kMaxRedirections,\n  kMaxRequests,\n  kCounter,\n  kClose,\n  kDestroy,\n  kDispatch,\n  kInterceptors,\n  kLocalAddress,\n  kMaxResponseSize,\n  kOnError,\n  kHTTPContext,\n  kMaxConcurrentStreams,\n  kResume\n} = require('../core/symbols.js')\nconst connectH1 = require('./client-h1.js')\nconst connectH2 = require('./client-h2.js')\nlet deprecatedInterceptorWarned = false\n\nconst kClosedResolve = Symbol('kClosedResolve')\n\nconst noop = () => {}\n\nfunction getPipelining (client) {\n  return client[kPipelining] ?? client[kHTTPContext]?.defaultPipelining ?? 1\n}\n\n/**\n * @type {import('../../types/client.js').default}\n */\nclass Client extends DispatcherBase {\n  /**\n   *\n   * @param {string|URL} url\n   * @param {import('../../types/client.js').Client.Options} options\n   */\n  constructor (url, {\n    interceptors,\n    maxHeaderSize,\n    headersTimeout,\n    socketTimeout,\n    requestTimeout,\n    connectTimeout,\n    bodyTimeout,\n    idleTimeout,\n    keepAlive,\n    keepAliveTimeout,\n    maxKeepAliveTimeout,\n    keepAliveMaxTimeout,\n    keepAliveTimeoutThreshold,\n    socketPath,\n    pipelining,\n    tls,\n    strictContentLength,\n    maxCachedSessions,\n    maxRedirections,\n    connect,\n    maxRequestsPerClient,\n    localAddress,\n    maxResponseSize,\n    autoSelectFamily,\n    autoSelectFamilyAttemptTimeout,\n    // h2\n    maxConcurrentStreams,\n    allowH2\n  } = {}) {\n    super()\n\n    if (keepAlive !== undefined) {\n      throw new InvalidArgumentError('unsupported keepAlive, use pipelining=0 instead')\n    }\n\n    if (socketTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported socketTimeout, use headersTimeout & bodyTimeout instead')\n    }\n\n    if (requestTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported requestTimeout, use headersTimeout & bodyTimeout instead')\n    }\n\n    if (idleTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported idleTimeout, use keepAliveTimeout instead')\n    }\n\n    if (maxKeepAliveTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported maxKeepAliveTimeout, use keepAliveMaxTimeout instead')\n    }\n\n    if (maxHeaderSize != null && !Number.isFinite(maxHeaderSize)) {\n      throw new InvalidArgumentError('invalid maxHeaderSize')\n    }\n\n    if (socketPath != null && typeof socketPath !== 'string') {\n      throw new InvalidArgumentError('invalid socketPath')\n    }\n\n    if (connectTimeout != null && (!Number.isFinite(connectTimeout) || connectTimeout < 0)) {\n      throw new InvalidArgumentError('invalid connectTimeout')\n    }\n\n    if (keepAliveTimeout != null && (!Number.isFinite(keepAliveTimeout) || keepAliveTimeout <= 0)) {\n      throw new InvalidArgumentError('invalid keepAliveTimeout')\n    }\n\n    if (keepAliveMaxTimeout != null && (!Number.isFinite(keepAliveMaxTimeout) || keepAliveMaxTimeout <= 0)) {\n      throw new InvalidArgumentError('invalid keepAliveMaxTimeout')\n    }\n\n    if (keepAliveTimeoutThreshold != null && !Number.isFinite(keepAliveTimeoutThreshold)) {\n      throw new InvalidArgumentError('invalid keepAliveTimeoutThreshold')\n    }\n\n    if (headersTimeout != null && (!Number.isInteger(headersTimeout) || headersTimeout < 0)) {\n      throw new InvalidArgumentError('headersTimeout must be a positive integer or zero')\n    }\n\n    if (bodyTimeout != null && (!Number.isInteger(bodyTimeout) || bodyTimeout < 0)) {\n      throw new InvalidArgumentError('bodyTimeout must be a positive integer or zero')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    if (maxRequestsPerClient != null && (!Number.isInteger(maxRequestsPerClient) || maxRequestsPerClient < 0)) {\n      throw new InvalidArgumentError('maxRequestsPerClient must be a positive number')\n    }\n\n    if (localAddress != null && (typeof localAddress !== 'string' || net.isIP(localAddress) === 0)) {\n      throw new InvalidArgumentError('localAddress must be valid string IP address')\n    }\n\n    if (maxResponseSize != null && (!Number.isInteger(maxResponseSize) || maxResponseSize < -1)) {\n      throw new InvalidArgumentError('maxResponseSize must be a positive number')\n    }\n\n    if (\n      autoSelectFamilyAttemptTimeout != null &&\n      (!Number.isInteger(autoSelectFamilyAttemptTimeout) || autoSelectFamilyAttemptTimeout < -1)\n    ) {\n      throw new InvalidArgumentError('autoSelectFamilyAttemptTimeout must be a positive number')\n    }\n\n    // h2\n    if (allowH2 != null && typeof allowH2 !== 'boolean') {\n      throw new InvalidArgumentError('allowH2 must be a valid boolean value')\n    }\n\n    if (maxConcurrentStreams != null && (typeof maxConcurrentStreams !== 'number' || maxConcurrentStreams < 1)) {\n      throw new InvalidArgumentError('maxConcurrentStreams must be a positive integer, greater than 0')\n    }\n\n    if (typeof connect !== 'function') {\n      connect = buildConnector({\n        ...tls,\n        maxCachedSessions,\n        allowH2,\n        socketPath,\n        timeout: connectTimeout,\n        ...(autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),\n        ...connect\n      })\n    }\n\n    if (interceptors?.Client && Array.isArray(interceptors.Client)) {\n      this[kInterceptors] = interceptors.Client\n      if (!deprecatedInterceptorWarned) {\n        deprecatedInterceptorWarned = true\n        process.emitWarning('Client.Options#interceptor is deprecated. Use Dispatcher#compose instead.', {\n          code: 'UNDICI-CLIENT-INTERCEPTOR-DEPRECATED'\n        })\n      }\n    } else {\n      this[kInterceptors] = [createRedirectInterceptor({ maxRedirections })]\n    }\n\n    this[kUrl] = util.parseOrigin(url)\n    this[kConnector] = connect\n    this[kPipelining] = pipelining != null ? pipelining : 1\n    this[kMaxHeadersSize] = maxHeaderSize || http.maxHeaderSize\n    this[kKeepAliveDefaultTimeout] = keepAliveTimeout == null ? 4e3 : keepAliveTimeout\n    this[kKeepAliveMaxTimeout] = keepAliveMaxTimeout == null ? 600e3 : keepAliveMaxTimeout\n    this[kKeepAliveTimeoutThreshold] = keepAliveTimeoutThreshold == null ? 2e3 : keepAliveTimeoutThreshold\n    this[kKeepAliveTimeoutValue] = this[kKeepAliveDefaultTimeout]\n    this[kServerName] = null\n    this[kLocalAddress] = localAddress != null ? localAddress : null\n    this[kResuming] = 0 // 0, idle, 1, scheduled, 2 resuming\n    this[kNeedDrain] = 0 // 0, idle, 1, scheduled, 2 resuming\n    this[kHostHeader] = `host: ${this[kUrl].hostname}${this[kUrl].port ? `:${this[kUrl].port}` : ''}\\r\\n`\n    this[kBodyTimeout] = bodyTimeout != null ? bodyTimeout : 300e3\n    this[kHeadersTimeout] = headersTimeout != null ? headersTimeout : 300e3\n    this[kStrictContentLength] = strictContentLength == null ? true : strictContentLength\n    this[kMaxRedirections] = maxRedirections\n    this[kMaxRequests] = maxRequestsPerClient\n    this[kClosedResolve] = null\n    this[kMaxResponseSize] = maxResponseSize > -1 ? maxResponseSize : -1\n    this[kMaxConcurrentStreams] = maxConcurrentStreams != null ? maxConcurrentStreams : 100 // Max peerConcurrentStreams for a Node h2 server\n    this[kHTTPContext] = null\n\n    // kQueue is built up of 3 sections separated by\n    // the kRunningIdx and kPendingIdx indices.\n    // |   complete   |   running   |   pending   |\n    //                ^ kRunningIdx ^ kPendingIdx ^ kQueue.length\n    // kRunningIdx points to the first running element.\n    // kPendingIdx points to the first pending element.\n    // This implements a fast queue with an amortized\n    // time of O(1).\n\n    this[kQueue] = []\n    this[kRunningIdx] = 0\n    this[kPendingIdx] = 0\n\n    this[kResume] = (sync) => resume(this, sync)\n    this[kOnError] = (err) => onError(this, err)\n  }\n\n  get pipelining () {\n    return this[kPipelining]\n  }\n\n  set pipelining (value) {\n    this[kPipelining] = value\n    this[kResume](true)\n  }\n\n  get [kPending] () {\n    return this[kQueue].length - this[kPendingIdx]\n  }\n\n  get [kRunning] () {\n    return this[kPendingIdx] - this[kRunningIdx]\n  }\n\n  get [kSize] () {\n    return this[kQueue].length - this[kRunningIdx]\n  }\n\n  get [kConnected] () {\n    return !!this[kHTTPContext] && !this[kConnecting] && !this[kHTTPContext].destroyed\n  }\n\n  get [kBusy] () {\n    return Boolean(\n      this[kHTTPContext]?.busy(null) ||\n      (this[kSize] >= (getPipelining(this) || 1)) ||\n      this[kPending] > 0\n    )\n  }\n\n  /* istanbul ignore: only used for test */\n  [kConnect] (cb) {\n    connect(this)\n    this.once('connect', cb)\n  }\n\n  [kDispatch] (opts, handler) {\n    const origin = opts.origin || this[kUrl].origin\n    const request = new Request(origin, opts, handler)\n\n    this[kQueue].push(request)\n    if (this[kResuming]) {\n      // Do nothing.\n    } else if (util.bodyLength(request.body) == null && util.isIterable(request.body)) {\n      // Wait a tick in case stream/iterator is ended in the same tick.\n      this[kResuming] = 1\n      queueMicrotask(() => resume(this))\n    } else {\n      this[kResume](true)\n    }\n\n    if (this[kResuming] && this[kNeedDrain] !== 2 && this[kBusy]) {\n      this[kNeedDrain] = 2\n    }\n\n    return this[kNeedDrain] < 2\n  }\n\n  async [kClose] () {\n    // TODO: for H2 we need to gracefully flush the remaining enqueued\n    // request and close each stream.\n    return new Promise((resolve) => {\n      if (this[kSize]) {\n        this[kClosedResolve] = resolve\n      } else {\n        resolve(null)\n      }\n    })\n  }\n\n  async [kDestroy] (err) {\n    return new Promise((resolve) => {\n      const requests = this[kQueue].splice(this[kPendingIdx])\n      for (let i = 0; i < requests.length; i++) {\n        const request = requests[i]\n        util.errorRequest(this, request, err)\n      }\n\n      const callback = () => {\n        if (this[kClosedResolve]) {\n          // TODO (fix): Should we error here with ClientDestroyedError?\n          this[kClosedResolve]()\n          this[kClosedResolve] = null\n        }\n        resolve(null)\n      }\n\n      if (this[kHTTPContext]) {\n        this[kHTTPContext].destroy(err, callback)\n        this[kHTTPContext] = null\n      } else {\n        queueMicrotask(callback)\n      }\n\n      this[kResume]()\n    })\n  }\n}\n\nconst createRedirectInterceptor = require('../interceptor/redirect-interceptor.js')\n\nfunction onError (client, err) {\n  if (\n    client[kRunning] === 0 &&\n    err.code !== 'UND_ERR_INFO' &&\n    err.code !== 'UND_ERR_SOCKET'\n  ) {\n    // Error is not caused by running request and not a recoverable\n    // socket error.\n\n    assert(client[kPendingIdx] === client[kRunningIdx])\n\n    const requests = client[kQueue].splice(client[kRunningIdx])\n\n    for (let i = 0; i < requests.length; i++) {\n      const request = requests[i]\n      util.errorRequest(client, request, err)\n    }\n    assert(client[kSize] === 0)\n  }\n}\n\n/**\n * @param {Client} client\n * @returns\n */\nasync function connect (client) {\n  assert(!client[kConnecting])\n  assert(!client[kHTTPContext])\n\n  let { host, hostname, protocol, port } = client[kUrl]\n\n  // Resolve ipv6\n  if (hostname[0] === '[') {\n    const idx = hostname.indexOf(']')\n\n    assert(idx !== -1)\n    const ip = hostname.substring(1, idx)\n\n    assert(net.isIP(ip))\n    hostname = ip\n  }\n\n  client[kConnecting] = true\n\n  if (channels.beforeConnect.hasSubscribers) {\n    channels.beforeConnect.publish({\n      connectParams: {\n        host,\n        hostname,\n        protocol,\n        port,\n        version: client[kHTTPContext]?.version,\n        servername: client[kServerName],\n        localAddress: client[kLocalAddress]\n      },\n      connector: client[kConnector]\n    })\n  }\n\n  try {\n    const socket = await new Promise((resolve, reject) => {\n      client[kConnector]({\n        host,\n        hostname,\n        protocol,\n        port,\n        servername: client[kServerName],\n        localAddress: client[kLocalAddress]\n      }, (err, socket) => {\n        if (err) {\n          reject(err)\n        } else {\n          resolve(socket)\n        }\n      })\n    })\n\n    if (client.destroyed) {\n      util.destroy(socket.on('error', noop), new ClientDestroyedError())\n      return\n    }\n\n    assert(socket)\n\n    try {\n      client[kHTTPContext] = socket.alpnProtocol === 'h2'\n        ? await connectH2(client, socket)\n        : await connectH1(client, socket)\n    } catch (err) {\n      socket.destroy().on('error', noop)\n      throw err\n    }\n\n    client[kConnecting] = false\n\n    socket[kCounter] = 0\n    socket[kMaxRequests] = client[kMaxRequests]\n    socket[kClient] = client\n    socket[kError] = null\n\n    if (channels.connected.hasSubscribers) {\n      channels.connected.publish({\n        connectParams: {\n          host,\n          hostname,\n          protocol,\n          port,\n          version: client[kHTTPContext]?.version,\n          servername: client[kServerName],\n          localAddress: client[kLocalAddress]\n        },\n        connector: client[kConnector],\n        socket\n      })\n    }\n    client.emit('connect', client[kUrl], [client])\n  } catch (err) {\n    if (client.destroyed) {\n      return\n    }\n\n    client[kConnecting] = false\n\n    if (channels.connectError.hasSubscribers) {\n      channels.connectError.publish({\n        connectParams: {\n          host,\n          hostname,\n          protocol,\n          port,\n          version: client[kHTTPContext]?.version,\n          servername: client[kServerName],\n          localAddress: client[kLocalAddress]\n        },\n        connector: client[kConnector],\n        error: err\n      })\n    }\n\n    if (err.code === 'ERR_TLS_CERT_ALTNAME_INVALID') {\n      assert(client[kRunning] === 0)\n      while (client[kPending] > 0 && client[kQueue][client[kPendingIdx]].servername === client[kServerName]) {\n        const request = client[kQueue][client[kPendingIdx]++]\n        util.errorRequest(client, request, err)\n      }\n    } else {\n      onError(client, err)\n    }\n\n    client.emit('connectionError', client[kUrl], [client], err)\n  }\n\n  client[kResume]()\n}\n\nfunction emitDrain (client) {\n  client[kNeedDrain] = 0\n  client.emit('drain', client[kUrl], [client])\n}\n\nfunction resume (client, sync) {\n  if (client[kResuming] === 2) {\n    return\n  }\n\n  client[kResuming] = 2\n\n  _resume(client, sync)\n  client[kResuming] = 0\n\n  if (client[kRunningIdx] > 256) {\n    client[kQueue].splice(0, client[kRunningIdx])\n    client[kPendingIdx] -= client[kRunningIdx]\n    client[kRunningIdx] = 0\n  }\n}\n\nfunction _resume (client, sync) {\n  while (true) {\n    if (client.destroyed) {\n      assert(client[kPending] === 0)\n      return\n    }\n\n    if (client[kClosedResolve] && !client[kSize]) {\n      client[kClosedResolve]()\n      client[kClosedResolve] = null\n      return\n    }\n\n    if (client[kHTTPContext]) {\n      client[kHTTPContext].resume()\n    }\n\n    if (client[kBusy]) {\n      client[kNeedDrain] = 2\n    } else if (client[kNeedDrain] === 2) {\n      if (sync) {\n        client[kNeedDrain] = 1\n        queueMicrotask(() => emitDrain(client))\n      } else {\n        emitDrain(client)\n      }\n      continue\n    }\n\n    if (client[kPending] === 0) {\n      return\n    }\n\n    if (client[kRunning] >= (getPipelining(client) || 1)) {\n      return\n    }\n\n    const request = client[kQueue][client[kPendingIdx]]\n\n    if (client[kUrl].protocol === 'https:' && client[kServerName] !== request.servername) {\n      if (client[kRunning] > 0) {\n        return\n      }\n\n      client[kServerName] = request.servername\n      client[kHTTPContext]?.destroy(new InformationalError('servername changed'), () => {\n        client[kHTTPContext] = null\n        resume(client)\n      })\n    }\n\n    if (client[kConnecting]) {\n      return\n    }\n\n    if (!client[kHTTPContext]) {\n      connect(client)\n      return\n    }\n\n    if (client[kHTTPContext].destroyed) {\n      return\n    }\n\n    if (client[kHTTPContext].busy(request)) {\n      return\n    }\n\n    if (!request.aborted && client[kHTTPContext].write(request)) {\n      client[kPendingIdx]++\n    } else {\n      client[kQueue].splice(client[kPendingIdx], 1)\n    }\n  }\n}\n\nmodule.exports = Client\n","'use strict'\n\nconst Dispatcher = require('./dispatcher')\nconst {\n  ClientDestroyedError,\n  ClientClosedError,\n  InvalidArgumentError\n} = require('../core/errors')\nconst { kDestroy, kClose, kClosed, kDestroyed, kDispatch, kInterceptors } = require('../core/symbols')\n\nconst kOnDestroyed = Symbol('onDestroyed')\nconst kOnClosed = Symbol('onClosed')\nconst kInterceptedDispatch = Symbol('Intercepted Dispatch')\n\nclass DispatcherBase extends Dispatcher {\n  constructor () {\n    super()\n\n    this[kDestroyed] = false\n    this[kOnDestroyed] = null\n    this[kClosed] = false\n    this[kOnClosed] = []\n  }\n\n  get destroyed () {\n    return this[kDestroyed]\n  }\n\n  get closed () {\n    return this[kClosed]\n  }\n\n  get interceptors () {\n    return this[kInterceptors]\n  }\n\n  set interceptors (newInterceptors) {\n    if (newInterceptors) {\n      for (let i = newInterceptors.length - 1; i >= 0; i--) {\n        const interceptor = this[kInterceptors][i]\n        if (typeof interceptor !== 'function') {\n          throw new InvalidArgumentError('interceptor must be an function')\n        }\n      }\n    }\n\n    this[kInterceptors] = newInterceptors\n  }\n\n  close (callback) {\n    if (callback === undefined) {\n      return new Promise((resolve, reject) => {\n        this.close((err, data) => {\n          return err ? reject(err) : resolve(data)\n        })\n      })\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    if (this[kDestroyed]) {\n      queueMicrotask(() => callback(new ClientDestroyedError(), null))\n      return\n    }\n\n    if (this[kClosed]) {\n      if (this[kOnClosed]) {\n        this[kOnClosed].push(callback)\n      } else {\n        queueMicrotask(() => callback(null, null))\n      }\n      return\n    }\n\n    this[kClosed] = true\n    this[kOnClosed].push(callback)\n\n    const onClosed = () => {\n      const callbacks = this[kOnClosed]\n      this[kOnClosed] = null\n      for (let i = 0; i < callbacks.length; i++) {\n        callbacks[i](null, null)\n      }\n    }\n\n    // Should not error.\n    this[kClose]()\n      .then(() => this.destroy())\n      .then(() => {\n        queueMicrotask(onClosed)\n      })\n  }\n\n  destroy (err, callback) {\n    if (typeof err === 'function') {\n      callback = err\n      err = null\n    }\n\n    if (callback === undefined) {\n      return new Promise((resolve, reject) => {\n        this.destroy(err, (err, data) => {\n          return err ? /* istanbul ignore next: should never error */ reject(err) : resolve(data)\n        })\n      })\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    if (this[kDestroyed]) {\n      if (this[kOnDestroyed]) {\n        this[kOnDestroyed].push(callback)\n      } else {\n        queueMicrotask(() => callback(null, null))\n      }\n      return\n    }\n\n    if (!err) {\n      err = new ClientDestroyedError()\n    }\n\n    this[kDestroyed] = true\n    this[kOnDestroyed] = this[kOnDestroyed] || []\n    this[kOnDestroyed].push(callback)\n\n    const onDestroyed = () => {\n      const callbacks = this[kOnDestroyed]\n      this[kOnDestroyed] = null\n      for (let i = 0; i < callbacks.length; i++) {\n        callbacks[i](null, null)\n      }\n    }\n\n    // Should not error.\n    this[kDestroy](err).then(() => {\n      queueMicrotask(onDestroyed)\n    })\n  }\n\n  [kInterceptedDispatch] (opts, handler) {\n    if (!this[kInterceptors] || this[kInterceptors].length === 0) {\n      this[kInterceptedDispatch] = this[kDispatch]\n      return this[kDispatch](opts, handler)\n    }\n\n    let dispatch = this[kDispatch].bind(this)\n    for (let i = this[kInterceptors].length - 1; i >= 0; i--) {\n      dispatch = this[kInterceptors][i](dispatch)\n    }\n    this[kInterceptedDispatch] = dispatch\n    return dispatch(opts, handler)\n  }\n\n  dispatch (opts, handler) {\n    if (!handler || typeof handler !== 'object') {\n      throw new InvalidArgumentError('handler must be an object')\n    }\n\n    try {\n      if (!opts || typeof opts !== 'object') {\n        throw new InvalidArgumentError('opts must be an object.')\n      }\n\n      if (this[kDestroyed] || this[kOnDestroyed]) {\n        throw new ClientDestroyedError()\n      }\n\n      if (this[kClosed]) {\n        throw new ClientClosedError()\n      }\n\n      return this[kInterceptedDispatch](opts, handler)\n    } catch (err) {\n      if (typeof handler.onError !== 'function') {\n        throw new InvalidArgumentError('invalid onError method')\n      }\n\n      handler.onError(err)\n\n      return false\n    }\n  }\n}\n\nmodule.exports = DispatcherBase\n","'use strict'\nconst EventEmitter = require('node:events')\n\nclass Dispatcher extends EventEmitter {\n  dispatch () {\n    throw new Error('not implemented')\n  }\n\n  close () {\n    throw new Error('not implemented')\n  }\n\n  destroy () {\n    throw new Error('not implemented')\n  }\n\n  compose (...args) {\n    // So we handle [interceptor1, interceptor2] or interceptor1, interceptor2, ...\n    const interceptors = Array.isArray(args[0]) ? args[0] : args\n    let dispatch = this.dispatch.bind(this)\n\n    for (const interceptor of interceptors) {\n      if (interceptor == null) {\n        continue\n      }\n\n      if (typeof interceptor !== 'function') {\n        throw new TypeError(`invalid interceptor, expected function received ${typeof interceptor}`)\n      }\n\n      dispatch = interceptor(dispatch)\n\n      if (dispatch == null || typeof dispatch !== 'function' || dispatch.length !== 2) {\n        throw new TypeError('invalid interceptor')\n      }\n    }\n\n    return new ComposedDispatcher(this, dispatch)\n  }\n}\n\nclass ComposedDispatcher extends Dispatcher {\n  #dispatcher = null\n  #dispatch = null\n\n  constructor (dispatcher, dispatch) {\n    super()\n    this.#dispatcher = dispatcher\n    this.#dispatch = dispatch\n  }\n\n  dispatch (...args) {\n    this.#dispatch(...args)\n  }\n\n  close (...args) {\n    return this.#dispatcher.close(...args)\n  }\n\n  destroy (...args) {\n    return this.#dispatcher.destroy(...args)\n  }\n}\n\nmodule.exports = Dispatcher\n","'use strict'\n\nconst DispatcherBase = require('./dispatcher-base')\nconst { kClose, kDestroy, kClosed, kDestroyed, kDispatch, kNoProxyAgent, kHttpProxyAgent, kHttpsProxyAgent } = require('../core/symbols')\nconst ProxyAgent = require('./proxy-agent')\nconst Agent = require('./agent')\n\nconst DEFAULT_PORTS = {\n  'http:': 80,\n  'https:': 443\n}\n\nlet experimentalWarned = false\n\nclass EnvHttpProxyAgent extends DispatcherBase {\n  #noProxyValue = null\n  #noProxyEntries = null\n  #opts = null\n\n  constructor (opts = {}) {\n    super()\n    this.#opts = opts\n\n    if (!experimentalWarned) {\n      experimentalWarned = true\n      process.emitWarning('EnvHttpProxyAgent is experimental, expect them to change at any time.', {\n        code: 'UNDICI-EHPA'\n      })\n    }\n\n    const { httpProxy, httpsProxy, noProxy, ...agentOpts } = opts\n\n    this[kNoProxyAgent] = new Agent(agentOpts)\n\n    const HTTP_PROXY = httpProxy ?? process.env.http_proxy ?? process.env.HTTP_PROXY\n    if (HTTP_PROXY) {\n      this[kHttpProxyAgent] = new ProxyAgent({ ...agentOpts, uri: HTTP_PROXY })\n    } else {\n      this[kHttpProxyAgent] = this[kNoProxyAgent]\n    }\n\n    const HTTPS_PROXY = httpsProxy ?? process.env.https_proxy ?? process.env.HTTPS_PROXY\n    if (HTTPS_PROXY) {\n      this[kHttpsProxyAgent] = new ProxyAgent({ ...agentOpts, uri: HTTPS_PROXY })\n    } else {\n      this[kHttpsProxyAgent] = this[kHttpProxyAgent]\n    }\n\n    this.#parseNoProxy()\n  }\n\n  [kDispatch] (opts, handler) {\n    const url = new URL(opts.origin)\n    const agent = this.#getProxyAgentForUrl(url)\n    return agent.dispatch(opts, handler)\n  }\n\n  async [kClose] () {\n    await this[kNoProxyAgent].close()\n    if (!this[kHttpProxyAgent][kClosed]) {\n      await this[kHttpProxyAgent].close()\n    }\n    if (!this[kHttpsProxyAgent][kClosed]) {\n      await this[kHttpsProxyAgent].close()\n    }\n  }\n\n  async [kDestroy] (err) {\n    await this[kNoProxyAgent].destroy(err)\n    if (!this[kHttpProxyAgent][kDestroyed]) {\n      await this[kHttpProxyAgent].destroy(err)\n    }\n    if (!this[kHttpsProxyAgent][kDestroyed]) {\n      await this[kHttpsProxyAgent].destroy(err)\n    }\n  }\n\n  #getProxyAgentForUrl (url) {\n    let { protocol, host: hostname, port } = url\n\n    // Stripping ports in this way instead of using parsedUrl.hostname to make\n    // sure that the brackets around IPv6 addresses are kept.\n    hostname = hostname.replace(/:\\d*$/, '').toLowerCase()\n    port = Number.parseInt(port, 10) || DEFAULT_PORTS[protocol] || 0\n    if (!this.#shouldProxy(hostname, port)) {\n      return this[kNoProxyAgent]\n    }\n    if (protocol === 'https:') {\n      return this[kHttpsProxyAgent]\n    }\n    return this[kHttpProxyAgent]\n  }\n\n  #shouldProxy (hostname, port) {\n    if (this.#noProxyChanged) {\n      this.#parseNoProxy()\n    }\n\n    if (this.#noProxyEntries.length === 0) {\n      return true // Always proxy if NO_PROXY is not set or empty.\n    }\n    if (this.#noProxyValue === '*') {\n      return false // Never proxy if wildcard is set.\n    }\n\n    for (let i = 0; i < this.#noProxyEntries.length; i++) {\n      const entry = this.#noProxyEntries[i]\n      if (entry.port && entry.port !== port) {\n        continue // Skip if ports don't match.\n      }\n      if (!/^[.*]/.test(entry.hostname)) {\n        // No wildcards, so don't proxy only if there is not an exact match.\n        if (hostname === entry.hostname) {\n          return false\n        }\n      } else {\n        // Don't proxy if the hostname ends with the no_proxy host.\n        if (hostname.endsWith(entry.hostname.replace(/^\\*/, ''))) {\n          return false\n        }\n      }\n    }\n\n    return true\n  }\n\n  #parseNoProxy () {\n    const noProxyValue = this.#opts.noProxy ?? this.#noProxyEnv\n    const noProxySplit = noProxyValue.split(/[,\\s]/)\n    const noProxyEntries = []\n\n    for (let i = 0; i < noProxySplit.length; i++) {\n      const entry = noProxySplit[i]\n      if (!entry) {\n        continue\n      }\n      const parsed = entry.match(/^(.+):(\\d+)$/)\n      noProxyEntries.push({\n        hostname: (parsed ? parsed[1] : entry).toLowerCase(),\n        port: parsed ? Number.parseInt(parsed[2], 10) : 0\n      })\n    }\n\n    this.#noProxyValue = noProxyValue\n    this.#noProxyEntries = noProxyEntries\n  }\n\n  get #noProxyChanged () {\n    if (this.#opts.noProxy !== undefined) {\n      return false\n    }\n    return this.#noProxyValue !== this.#noProxyEnv\n  }\n\n  get #noProxyEnv () {\n    return process.env.no_proxy ?? process.env.NO_PROXY ?? ''\n  }\n}\n\nmodule.exports = EnvHttpProxyAgent\n","/* eslint-disable */\n\n'use strict'\n\n// Extracted from node/lib/internal/fixed_queue.js\n\n// Currently optimal queue size, tested on V8 6.0 - 6.6. Must be power of two.\nconst kSize = 2048;\nconst kMask = kSize - 1;\n\n// The FixedQueue is implemented as a singly-linked list of fixed-size\n// circular buffers. It looks something like this:\n//\n//  head                                                       tail\n//    |                                                          |\n//    v                                                          v\n// +-----------+ <-----\\       +-----------+ <------\\         +-----------+\n// |  [null]   |        \\----- |   next    |         \\------- |   next    |\n// +-----------+               +-----------+                  +-----------+\n// |   item    | <-- bottom    |   item    | <-- bottom       |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |       bottom --> |   item    |\n// |   item    |               |   item    |                  |   item    |\n// |    ...    |               |    ...    |                  |    ...    |\n// |   item    |               |   item    |                  |   item    |\n// |   item    |               |   item    |                  |   item    |\n// |  [empty]  | <-- top       |   item    |                  |   item    |\n// |  [empty]  |               |   item    |                  |   item    |\n// |  [empty]  |               |  [empty]  | <-- top  top --> |  [empty]  |\n// +-----------+               +-----------+                  +-----------+\n//\n// Or, if there is only one circular buffer, it looks something\n// like either of these:\n//\n//  head   tail                                 head   tail\n//    |     |                                     |     |\n//    v     v                                     v     v\n// +-----------+                               +-----------+\n// |  [null]   |                               |  [null]   |\n// +-----------+                               +-----------+\n// |  [empty]  |                               |   item    |\n// |  [empty]  |                               |   item    |\n// |   item    | <-- bottom            top --> |  [empty]  |\n// |   item    |                               |  [empty]  |\n// |  [empty]  | <-- top            bottom --> |   item    |\n// |  [empty]  |                               |   item    |\n// +-----------+                               +-----------+\n//\n// Adding a value means moving `top` forward by one, removing means\n// moving `bottom` forward by one. After reaching the end, the queue\n// wraps around.\n//\n// When `top === bottom` the current queue is empty and when\n// `top + 1 === bottom` it's full. This wastes a single space of storage\n// but allows much quicker checks.\n\nclass FixedCircularBuffer {\n  constructor() {\n    this.bottom = 0;\n    this.top = 0;\n    this.list = new Array(kSize);\n    this.next = null;\n  }\n\n  isEmpty() {\n    return this.top === this.bottom;\n  }\n\n  isFull() {\n    return ((this.top + 1) & kMask) === this.bottom;\n  }\n\n  push(data) {\n    this.list[this.top] = data;\n    this.top = (this.top + 1) & kMask;\n  }\n\n  shift() {\n    const nextItem = this.list[this.bottom];\n    if (nextItem === undefined)\n      return null;\n    this.list[this.bottom] = undefined;\n    this.bottom = (this.bottom + 1) & kMask;\n    return nextItem;\n  }\n}\n\nmodule.exports = class FixedQueue {\n  constructor() {\n    this.head = this.tail = new FixedCircularBuffer();\n  }\n\n  isEmpty() {\n    return this.head.isEmpty();\n  }\n\n  push(data) {\n    if (this.head.isFull()) {\n      // Head is full: Creates a new queue, sets the old queue's `.next` to it,\n      // and sets it as the new main queue.\n      this.head = this.head.next = new FixedCircularBuffer();\n    }\n    this.head.push(data);\n  }\n\n  shift() {\n    const tail = this.tail;\n    const next = tail.shift();\n    if (tail.isEmpty() && tail.next !== null) {\n      // If there is another queue, it forms the new tail.\n      this.tail = tail.next;\n    }\n    return next;\n  }\n};\n","'use strict'\n\nconst DispatcherBase = require('./dispatcher-base')\nconst FixedQueue = require('./fixed-queue')\nconst { kConnected, kSize, kRunning, kPending, kQueued, kBusy, kFree, kUrl, kClose, kDestroy, kDispatch } = require('../core/symbols')\nconst PoolStats = require('./pool-stats')\n\nconst kClients = Symbol('clients')\nconst kNeedDrain = Symbol('needDrain')\nconst kQueue = Symbol('queue')\nconst kClosedResolve = Symbol('closed resolve')\nconst kOnDrain = Symbol('onDrain')\nconst kOnConnect = Symbol('onConnect')\nconst kOnDisconnect = Symbol('onDisconnect')\nconst kOnConnectionError = Symbol('onConnectionError')\nconst kGetDispatcher = Symbol('get dispatcher')\nconst kAddClient = Symbol('add client')\nconst kRemoveClient = Symbol('remove client')\nconst kStats = Symbol('stats')\n\nclass PoolBase extends DispatcherBase {\n  constructor () {\n    super()\n\n    this[kQueue] = new FixedQueue()\n    this[kClients] = []\n    this[kQueued] = 0\n\n    const pool = this\n\n    this[kOnDrain] = function onDrain (origin, targets) {\n      const queue = pool[kQueue]\n\n      let needDrain = false\n\n      while (!needDrain) {\n        const item = queue.shift()\n        if (!item) {\n          break\n        }\n        pool[kQueued]--\n        needDrain = !this.dispatch(item.opts, item.handler)\n      }\n\n      this[kNeedDrain] = needDrain\n\n      if (!this[kNeedDrain] && pool[kNeedDrain]) {\n        pool[kNeedDrain] = false\n        pool.emit('drain', origin, [pool, ...targets])\n      }\n\n      if (pool[kClosedResolve] && queue.isEmpty()) {\n        Promise\n          .all(pool[kClients].map(c => c.close()))\n          .then(pool[kClosedResolve])\n      }\n    }\n\n    this[kOnConnect] = (origin, targets) => {\n      pool.emit('connect', origin, [pool, ...targets])\n    }\n\n    this[kOnDisconnect] = (origin, targets, err) => {\n      pool.emit('disconnect', origin, [pool, ...targets], err)\n    }\n\n    this[kOnConnectionError] = (origin, targets, err) => {\n      pool.emit('connectionError', origin, [pool, ...targets], err)\n    }\n\n    this[kStats] = new PoolStats(this)\n  }\n\n  get [kBusy] () {\n    return this[kNeedDrain]\n  }\n\n  get [kConnected] () {\n    return this[kClients].filter(client => client[kConnected]).length\n  }\n\n  get [kFree] () {\n    return this[kClients].filter(client => client[kConnected] && !client[kNeedDrain]).length\n  }\n\n  get [kPending] () {\n    let ret = this[kQueued]\n    for (const { [kPending]: pending } of this[kClients]) {\n      ret += pending\n    }\n    return ret\n  }\n\n  get [kRunning] () {\n    let ret = 0\n    for (const { [kRunning]: running } of this[kClients]) {\n      ret += running\n    }\n    return ret\n  }\n\n  get [kSize] () {\n    let ret = this[kQueued]\n    for (const { [kSize]: size } of this[kClients]) {\n      ret += size\n    }\n    return ret\n  }\n\n  get stats () {\n    return this[kStats]\n  }\n\n  async [kClose] () {\n    if (this[kQueue].isEmpty()) {\n      await Promise.all(this[kClients].map(c => c.close()))\n    } else {\n      await new Promise((resolve) => {\n        this[kClosedResolve] = resolve\n      })\n    }\n  }\n\n  async [kDestroy] (err) {\n    while (true) {\n      const item = this[kQueue].shift()\n      if (!item) {\n        break\n      }\n      item.handler.onError(err)\n    }\n\n    await Promise.all(this[kClients].map(c => c.destroy(err)))\n  }\n\n  [kDispatch] (opts, handler) {\n    const dispatcher = this[kGetDispatcher]()\n\n    if (!dispatcher) {\n      this[kNeedDrain] = true\n      this[kQueue].push({ opts, handler })\n      this[kQueued]++\n    } else if (!dispatcher.dispatch(opts, handler)) {\n      dispatcher[kNeedDrain] = true\n      this[kNeedDrain] = !this[kGetDispatcher]()\n    }\n\n    return !this[kNeedDrain]\n  }\n\n  [kAddClient] (client) {\n    client\n      .on('drain', this[kOnDrain])\n      .on('connect', this[kOnConnect])\n      .on('disconnect', this[kOnDisconnect])\n      .on('connectionError', this[kOnConnectionError])\n\n    this[kClients].push(client)\n\n    if (this[kNeedDrain]) {\n      queueMicrotask(() => {\n        if (this[kNeedDrain]) {\n          this[kOnDrain](client[kUrl], [this, client])\n        }\n      })\n    }\n\n    return this\n  }\n\n  [kRemoveClient] (client) {\n    client.close(() => {\n      const idx = this[kClients].indexOf(client)\n      if (idx !== -1) {\n        this[kClients].splice(idx, 1)\n      }\n    })\n\n    this[kNeedDrain] = this[kClients].some(dispatcher => (\n      !dispatcher[kNeedDrain] &&\n      dispatcher.closed !== true &&\n      dispatcher.destroyed !== true\n    ))\n  }\n}\n\nmodule.exports = {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kRemoveClient,\n  kGetDispatcher\n}\n","const { kFree, kConnected, kPending, kQueued, kRunning, kSize } = require('../core/symbols')\nconst kPool = Symbol('pool')\n\nclass PoolStats {\n  constructor (pool) {\n    this[kPool] = pool\n  }\n\n  get connected () {\n    return this[kPool][kConnected]\n  }\n\n  get free () {\n    return this[kPool][kFree]\n  }\n\n  get pending () {\n    return this[kPool][kPending]\n  }\n\n  get queued () {\n    return this[kPool][kQueued]\n  }\n\n  get running () {\n    return this[kPool][kRunning]\n  }\n\n  get size () {\n    return this[kPool][kSize]\n  }\n}\n\nmodule.exports = PoolStats\n","'use strict'\n\nconst {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kGetDispatcher\n} = require('./pool-base')\nconst Client = require('./client')\nconst {\n  InvalidArgumentError\n} = require('../core/errors')\nconst util = require('../core/util')\nconst { kUrl, kInterceptors } = require('../core/symbols')\nconst buildConnector = require('../core/connect')\n\nconst kOptions = Symbol('options')\nconst kConnections = Symbol('connections')\nconst kFactory = Symbol('factory')\n\nfunction defaultFactory (origin, opts) {\n  return new Client(origin, opts)\n}\n\nclass Pool extends PoolBase {\n  constructor (origin, {\n    connections,\n    factory = defaultFactory,\n    connect,\n    connectTimeout,\n    tls,\n    maxCachedSessions,\n    socketPath,\n    autoSelectFamily,\n    autoSelectFamilyAttemptTimeout,\n    allowH2,\n    ...options\n  } = {}) {\n    super()\n\n    if (connections != null && (!Number.isFinite(connections) || connections < 0)) {\n      throw new InvalidArgumentError('invalid connections')\n    }\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (typeof connect !== 'function') {\n      connect = buildConnector({\n        ...tls,\n        maxCachedSessions,\n        allowH2,\n        socketPath,\n        timeout: connectTimeout,\n        ...(autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),\n        ...connect\n      })\n    }\n\n    this[kInterceptors] = options.interceptors?.Pool && Array.isArray(options.interceptors.Pool)\n      ? options.interceptors.Pool\n      : []\n    this[kConnections] = connections || null\n    this[kUrl] = util.parseOrigin(origin)\n    this[kOptions] = { ...util.deepClone(options), connect, allowH2 }\n    this[kOptions].interceptors = options.interceptors\n      ? { ...options.interceptors }\n      : undefined\n    this[kFactory] = factory\n\n    this.on('connectionError', (origin, targets, error) => {\n      // If a connection error occurs, we remove the client from the pool,\n      // and emit a connectionError event. They will not be re-used.\n      // Fixes https://github.com/nodejs/undici/issues/3895\n      for (const target of targets) {\n        // Do not use kRemoveClient here, as it will close the client,\n        // but the client cannot be closed in this state.\n        const idx = this[kClients].indexOf(target)\n        if (idx !== -1) {\n          this[kClients].splice(idx, 1)\n        }\n      }\n    })\n  }\n\n  [kGetDispatcher] () {\n    for (const client of this[kClients]) {\n      if (!client[kNeedDrain]) {\n        return client\n      }\n    }\n\n    if (!this[kConnections] || this[kClients].length < this[kConnections]) {\n      const dispatcher = this[kFactory](this[kUrl], this[kOptions])\n      this[kAddClient](dispatcher)\n      return dispatcher\n    }\n  }\n}\n\nmodule.exports = Pool\n","'use strict'\n\nconst { kProxy, kClose, kDestroy, kDispatch, kInterceptors } = require('../core/symbols')\nconst { URL } = require('node:url')\nconst Agent = require('./agent')\nconst Pool = require('./pool')\nconst DispatcherBase = require('./dispatcher-base')\nconst { InvalidArgumentError, RequestAbortedError, SecureProxyConnectionError } = require('../core/errors')\nconst buildConnector = require('../core/connect')\nconst Client = require('./client')\n\nconst kAgent = Symbol('proxy agent')\nconst kClient = Symbol('proxy client')\nconst kProxyHeaders = Symbol('proxy headers')\nconst kRequestTls = Symbol('request tls settings')\nconst kProxyTls = Symbol('proxy tls settings')\nconst kConnectEndpoint = Symbol('connect endpoint function')\nconst kTunnelProxy = Symbol('tunnel proxy')\n\nfunction defaultProtocolPort (protocol) {\n  return protocol === 'https:' ? 443 : 80\n}\n\nfunction defaultFactory (origin, opts) {\n  return new Pool(origin, opts)\n}\n\nconst noop = () => {}\n\nfunction defaultAgentFactory (origin, opts) {\n  if (opts.connections === 1) {\n    return new Client(origin, opts)\n  }\n  return new Pool(origin, opts)\n}\n\nclass Http1ProxyWrapper extends DispatcherBase {\n  #client\n\n  constructor (proxyUrl, { headers = {}, connect, factory }) {\n    super()\n    if (!proxyUrl) {\n      throw new InvalidArgumentError('Proxy URL is mandatory')\n    }\n\n    this[kProxyHeaders] = headers\n    if (factory) {\n      this.#client = factory(proxyUrl, { connect })\n    } else {\n      this.#client = new Client(proxyUrl, { connect })\n    }\n  }\n\n  [kDispatch] (opts, handler) {\n    const onHeaders = handler.onHeaders\n    handler.onHeaders = function (statusCode, data, resume) {\n      if (statusCode === 407) {\n        if (typeof handler.onError === 'function') {\n          handler.onError(new InvalidArgumentError('Proxy Authentication Required (407)'))\n        }\n        return\n      }\n      if (onHeaders) onHeaders.call(this, statusCode, data, resume)\n    }\n\n    // Rewrite request as an HTTP1 Proxy request, without tunneling.\n    const {\n      origin,\n      path = '/',\n      headers = {}\n    } = opts\n\n    opts.path = origin + path\n\n    if (!('host' in headers) && !('Host' in headers)) {\n      const { host } = new URL(origin)\n      headers.host = host\n    }\n    opts.headers = { ...this[kProxyHeaders], ...headers }\n\n    return this.#client[kDispatch](opts, handler)\n  }\n\n  async [kClose] () {\n    return this.#client.close()\n  }\n\n  async [kDestroy] (err) {\n    return this.#client.destroy(err)\n  }\n}\n\nclass ProxyAgent extends DispatcherBase {\n  constructor (opts) {\n    super()\n\n    if (!opts || (typeof opts === 'object' && !(opts instanceof URL) && !opts.uri)) {\n      throw new InvalidArgumentError('Proxy uri is mandatory')\n    }\n\n    const { clientFactory = defaultFactory } = opts\n    if (typeof clientFactory !== 'function') {\n      throw new InvalidArgumentError('Proxy opts.clientFactory must be a function.')\n    }\n\n    const { proxyTunnel = true } = opts\n\n    const url = this.#getUrl(opts)\n    const { href, origin, port, protocol, username, password, hostname: proxyHostname } = url\n\n    this[kProxy] = { uri: href, protocol }\n    this[kInterceptors] = opts.interceptors?.ProxyAgent && Array.isArray(opts.interceptors.ProxyAgent)\n      ? opts.interceptors.ProxyAgent\n      : []\n    this[kRequestTls] = opts.requestTls\n    this[kProxyTls] = opts.proxyTls\n    this[kProxyHeaders] = opts.headers || {}\n    this[kTunnelProxy] = proxyTunnel\n\n    if (opts.auth && opts.token) {\n      throw new InvalidArgumentError('opts.auth cannot be used in combination with opts.token')\n    } else if (opts.auth) {\n      /* @deprecated in favour of opts.token */\n      this[kProxyHeaders]['proxy-authorization'] = `Basic ${opts.auth}`\n    } else if (opts.token) {\n      this[kProxyHeaders]['proxy-authorization'] = opts.token\n    } else if (username && password) {\n      this[kProxyHeaders]['proxy-authorization'] = `Basic ${Buffer.from(`${decodeURIComponent(username)}:${decodeURIComponent(password)}`).toString('base64')}`\n    }\n\n    const connect = buildConnector({ ...opts.proxyTls })\n    this[kConnectEndpoint] = buildConnector({ ...opts.requestTls })\n\n    const agentFactory = opts.factory || defaultAgentFactory\n    const factory = (origin, options) => {\n      const { protocol } = new URL(origin)\n      if (!this[kTunnelProxy] && protocol === 'http:' && this[kProxy].protocol === 'http:') {\n        return new Http1ProxyWrapper(this[kProxy].uri, {\n          headers: this[kProxyHeaders],\n          connect,\n          factory: agentFactory\n        })\n      }\n      return agentFactory(origin, options)\n    }\n    this[kClient] = clientFactory(url, { connect })\n    this[kAgent] = new Agent({\n      ...opts,\n      factory,\n      connect: async (opts, callback) => {\n        let requestedPath = opts.host\n        if (!opts.port) {\n          requestedPath += `:${defaultProtocolPort(opts.protocol)}`\n        }\n        try {\n          const { socket, statusCode } = await this[kClient].connect({\n            origin,\n            port,\n            path: requestedPath,\n            signal: opts.signal,\n            headers: {\n              ...this[kProxyHeaders],\n              host: opts.host\n            },\n            servername: this[kProxyTls]?.servername || proxyHostname\n          })\n          if (statusCode !== 200) {\n            socket.on('error', noop).destroy()\n            callback(new RequestAbortedError(`Proxy response (${statusCode}) !== 200 when HTTP Tunneling`))\n          }\n          if (opts.protocol !== 'https:') {\n            callback(null, socket)\n            return\n          }\n          let servername\n          if (this[kRequestTls]) {\n            servername = this[kRequestTls].servername\n          } else {\n            servername = opts.servername\n          }\n          this[kConnectEndpoint]({ ...opts, servername, httpSocket: socket }, callback)\n        } catch (err) {\n          if (err.code === 'ERR_TLS_CERT_ALTNAME_INVALID') {\n            // Throw a custom error to avoid loop in client.js#connect\n            callback(new SecureProxyConnectionError(err))\n          } else {\n            callback(err)\n          }\n        }\n      }\n    })\n  }\n\n  dispatch (opts, handler) {\n    const headers = buildHeaders(opts.headers)\n    throwIfProxyAuthIsSent(headers)\n\n    if (headers && !('host' in headers) && !('Host' in headers)) {\n      const { host } = new URL(opts.origin)\n      headers.host = host\n    }\n\n    return this[kAgent].dispatch(\n      {\n        ...opts,\n        headers\n      },\n      handler\n    )\n  }\n\n  /**\n   * @param {import('../types/proxy-agent').ProxyAgent.Options | string | URL} opts\n   * @returns {URL}\n   */\n  #getUrl (opts) {\n    if (typeof opts === 'string') {\n      return new URL(opts)\n    } else if (opts instanceof URL) {\n      return opts\n    } else {\n      return new URL(opts.uri)\n    }\n  }\n\n  async [kClose] () {\n    await this[kAgent].close()\n    await this[kClient].close()\n  }\n\n  async [kDestroy] () {\n    await this[kAgent].destroy()\n    await this[kClient].destroy()\n  }\n}\n\n/**\n * @param {string[] | Record<string, string>} headers\n * @returns {Record<string, string>}\n */\nfunction buildHeaders (headers) {\n  // When using undici.fetch, the headers list is stored\n  // as an array.\n  if (Array.isArray(headers)) {\n    /** @type {Record<string, string>} */\n    const headersPair = {}\n\n    for (let i = 0; i < headers.length; i += 2) {\n      headersPair[headers[i]] = headers[i + 1]\n    }\n\n    return headersPair\n  }\n\n  return headers\n}\n\n/**\n * @param {Record<string, string>} headers\n *\n * Previous versions of ProxyAgent suggests the Proxy-Authorization in request headers\n * Nevertheless, it was changed and to avoid a security vulnerability by end users\n * this check was created.\n * It should be removed in the next major version for performance reasons\n */\nfunction throwIfProxyAuthIsSent (headers) {\n  const existProxyAuth = headers && Object.keys(headers)\n    .find((key) => key.toLowerCase() === 'proxy-authorization')\n  if (existProxyAuth) {\n    throw new InvalidArgumentError('Proxy-Authorization should be sent in ProxyAgent constructor')\n  }\n}\n\nmodule.exports = ProxyAgent\n","'use strict'\n\nconst Dispatcher = require('./dispatcher')\nconst RetryHandler = require('../handler/retry-handler')\n\nclass RetryAgent extends Dispatcher {\n  #agent = null\n  #options = null\n  constructor (agent, options = {}) {\n    super(options)\n    this.#agent = agent\n    this.#options = options\n  }\n\n  dispatch (opts, handler) {\n    const retry = new RetryHandler({\n      ...opts,\n      retryOptions: this.#options\n    }, {\n      dispatch: this.#agent.dispatch.bind(this.#agent),\n      handler\n    })\n    return this.#agent.dispatch(opts, retry)\n  }\n\n  close () {\n    return this.#agent.close()\n  }\n\n  destroy () {\n    return this.#agent.destroy()\n  }\n}\n\nmodule.exports = RetryAgent\n","'use strict'\n\n// We include a version number for the Dispatcher API. In case of breaking changes,\n// this version number must be increased to avoid conflicts.\nconst globalDispatcher = Symbol.for('undici.globalDispatcher.1')\nconst { InvalidArgumentError } = require('./core/errors')\nconst Agent = require('./dispatcher/agent')\n\nif (getGlobalDispatcher() === undefined) {\n  setGlobalDispatcher(new Agent())\n}\n\nfunction setGlobalDispatcher (agent) {\n  if (!agent || typeof agent.dispatch !== 'function') {\n    throw new InvalidArgumentError('Argument agent must implement Agent')\n  }\n  Object.defineProperty(globalThis, globalDispatcher, {\n    value: agent,\n    writable: true,\n    enumerable: false,\n    configurable: false\n  })\n}\n\nfunction getGlobalDispatcher () {\n  return globalThis[globalDispatcher]\n}\n\nmodule.exports = {\n  setGlobalDispatcher,\n  getGlobalDispatcher\n}\n","'use strict'\n\nmodule.exports = class DecoratorHandler {\n  #handler\n\n  constructor (handler) {\n    if (typeof handler !== 'object' || handler === null) {\n      throw new TypeError('handler must be an object')\n    }\n    this.#handler = handler\n  }\n\n  onConnect (...args) {\n    return this.#handler.onConnect?.(...args)\n  }\n\n  onError (...args) {\n    return this.#handler.onError?.(...args)\n  }\n\n  onUpgrade (...args) {\n    return this.#handler.onUpgrade?.(...args)\n  }\n\n  onResponseStarted (...args) {\n    return this.#handler.onResponseStarted?.(...args)\n  }\n\n  onHeaders (...args) {\n    return this.#handler.onHeaders?.(...args)\n  }\n\n  onData (...args) {\n    return this.#handler.onData?.(...args)\n  }\n\n  onComplete (...args) {\n    return this.#handler.onComplete?.(...args)\n  }\n\n  onBodySent (...args) {\n    return this.#handler.onBodySent?.(...args)\n  }\n}\n","'use strict'\n\nconst util = require('../core/util')\nconst { kBodyUsed } = require('../core/symbols')\nconst assert = require('node:assert')\nconst { InvalidArgumentError } = require('../core/errors')\nconst EE = require('node:events')\n\nconst redirectableStatusCodes = [300, 301, 302, 303, 307, 308]\n\nconst kBody = Symbol('body')\n\nclass BodyAsyncIterable {\n  constructor (body) {\n    this[kBody] = body\n    this[kBodyUsed] = false\n  }\n\n  async * [Symbol.asyncIterator] () {\n    assert(!this[kBodyUsed], 'disturbed')\n    this[kBodyUsed] = true\n    yield * this[kBody]\n  }\n}\n\nclass RedirectHandler {\n  constructor (dispatch, maxRedirections, opts, handler) {\n    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    util.validateHandler(handler, opts.method, opts.upgrade)\n\n    this.dispatch = dispatch\n    this.location = null\n    this.abort = null\n    this.opts = { ...opts, maxRedirections: 0 } // opts must be a copy\n    this.maxRedirections = maxRedirections\n    this.handler = handler\n    this.history = []\n    this.redirectionLimitReached = false\n\n    if (util.isStream(this.opts.body)) {\n      // TODO (fix): Provide some way for the user to cache the file to e.g. /tmp\n      // so that it can be dispatched again?\n      // TODO (fix): Do we need 100-expect support to provide a way to do this properly?\n      if (util.bodyLength(this.opts.body) === 0) {\n        this.opts.body\n          .on('data', function () {\n            assert(false)\n          })\n      }\n\n      if (typeof this.opts.body.readableDidRead !== 'boolean') {\n        this.opts.body[kBodyUsed] = false\n        EE.prototype.on.call(this.opts.body, 'data', function () {\n          this[kBodyUsed] = true\n        })\n      }\n    } else if (this.opts.body && typeof this.opts.body.pipeTo === 'function') {\n      // TODO (fix): We can't access ReadableStream internal state\n      // to determine whether or not it has been disturbed. This is just\n      // a workaround.\n      this.opts.body = new BodyAsyncIterable(this.opts.body)\n    } else if (\n      this.opts.body &&\n      typeof this.opts.body !== 'string' &&\n      !ArrayBuffer.isView(this.opts.body) &&\n      util.isIterable(this.opts.body)\n    ) {\n      // TODO: Should we allow re-using iterable if !this.opts.idempotent\n      // or through some other flag?\n      this.opts.body = new BodyAsyncIterable(this.opts.body)\n    }\n  }\n\n  onConnect (abort) {\n    this.abort = abort\n    this.handler.onConnect(abort, { history: this.history })\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    this.handler.onUpgrade(statusCode, headers, socket)\n  }\n\n  onError (error) {\n    this.handler.onError(error)\n  }\n\n  onHeaders (statusCode, headers, resume, statusText) {\n    this.location = this.history.length >= this.maxRedirections || util.isDisturbed(this.opts.body)\n      ? null\n      : parseLocation(statusCode, headers)\n\n    if (this.opts.throwOnMaxRedirect && this.history.length >= this.maxRedirections) {\n      if (this.request) {\n        this.request.abort(new Error('max redirects'))\n      }\n\n      this.redirectionLimitReached = true\n      this.abort(new Error('max redirects'))\n      return\n    }\n\n    if (this.opts.origin) {\n      this.history.push(new URL(this.opts.path, this.opts.origin))\n    }\n\n    if (!this.location) {\n      return this.handler.onHeaders(statusCode, headers, resume, statusText)\n    }\n\n    const { origin, pathname, search } = util.parseURL(new URL(this.location, this.opts.origin && new URL(this.opts.path, this.opts.origin)))\n    const path = search ? `${pathname}${search}` : pathname\n\n    // Remove headers referring to the original URL.\n    // By default it is Host only, unless it's a 303 (see below), which removes also all Content-* headers.\n    // https://tools.ietf.org/html/rfc7231#section-6.4\n    this.opts.headers = cleanRequestHeaders(this.opts.headers, statusCode === 303, this.opts.origin !== origin)\n    this.opts.path = path\n    this.opts.origin = origin\n    this.opts.maxRedirections = 0\n    this.opts.query = null\n\n    // https://tools.ietf.org/html/rfc7231#section-6.4.4\n    // In case of HTTP 303, always replace method to be either HEAD or GET\n    if (statusCode === 303 && this.opts.method !== 'HEAD') {\n      this.opts.method = 'GET'\n      this.opts.body = null\n    }\n  }\n\n  onData (chunk) {\n    if (this.location) {\n      /*\n        https://tools.ietf.org/html/rfc7231#section-6.4\n\n        TLDR: undici always ignores 3xx response bodies.\n\n        Redirection is used to serve the requested resource from another URL, so it is assumes that\n        no body is generated (and thus can be ignored). Even though generating a body is not prohibited.\n\n        For status 301, 302, 303, 307 and 308 (the latter from RFC 7238), the specs mention that the body usually\n        (which means it's optional and not mandated) contain just an hyperlink to the value of\n        the Location response header, so the body can be ignored safely.\n\n        For status 300, which is \"Multiple Choices\", the spec mentions both generating a Location\n        response header AND a response body with the other possible location to follow.\n        Since the spec explicitly chooses not to specify a format for such body and leave it to\n        servers and browsers implementors, we ignore the body as there is no specified way to eventually parse it.\n      */\n    } else {\n      return this.handler.onData(chunk)\n    }\n  }\n\n  onComplete (trailers) {\n    if (this.location) {\n      /*\n        https://tools.ietf.org/html/rfc7231#section-6.4\n\n        TLDR: undici always ignores 3xx response trailers as they are not expected in case of redirections\n        and neither are useful if present.\n\n        See comment on onData method above for more detailed information.\n      */\n\n      this.location = null\n      this.abort = null\n\n      this.dispatch(this.opts, this)\n    } else {\n      this.handler.onComplete(trailers)\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this.handler.onBodySent) {\n      this.handler.onBodySent(chunk)\n    }\n  }\n}\n\nfunction parseLocation (statusCode, headers) {\n  if (redirectableStatusCodes.indexOf(statusCode) === -1) {\n    return null\n  }\n\n  for (let i = 0; i < headers.length; i += 2) {\n    if (headers[i].length === 8 && util.headerNameToString(headers[i]) === 'location') {\n      return headers[i + 1]\n    }\n  }\n}\n\n// https://tools.ietf.org/html/rfc7231#section-6.4.4\nfunction shouldRemoveHeader (header, removeContent, unknownOrigin) {\n  if (header.length === 4) {\n    return util.headerNameToString(header) === 'host'\n  }\n  if (removeContent && util.headerNameToString(header).startsWith('content-')) {\n    return true\n  }\n  if (unknownOrigin && (header.length === 13 || header.length === 6 || header.length === 19)) {\n    const name = util.headerNameToString(header)\n    return name === 'authorization' || name === 'cookie' || name === 'proxy-authorization'\n  }\n  return false\n}\n\n// https://tools.ietf.org/html/rfc7231#section-6.4\nfunction cleanRequestHeaders (headers, removeContent, unknownOrigin) {\n  const ret = []\n  if (Array.isArray(headers)) {\n    for (let i = 0; i < headers.length; i += 2) {\n      if (!shouldRemoveHeader(headers[i], removeContent, unknownOrigin)) {\n        ret.push(headers[i], headers[i + 1])\n      }\n    }\n  } else if (headers && typeof headers === 'object') {\n    for (const key of Object.keys(headers)) {\n      if (!shouldRemoveHeader(key, removeContent, unknownOrigin)) {\n        ret.push(key, headers[key])\n      }\n    }\n  } else {\n    assert(headers == null, 'headers must be an object or an array')\n  }\n  return ret\n}\n\nmodule.exports = RedirectHandler\n","'use strict'\nconst assert = require('node:assert')\n\nconst { kRetryHandlerDefaultRetry } = require('../core/symbols')\nconst { RequestRetryError } = require('../core/errors')\nconst {\n  isDisturbed,\n  parseHeaders,\n  parseRangeHeader,\n  wrapRequestBody\n} = require('../core/util')\n\nfunction calculateRetryAfterHeader (retryAfter) {\n  const current = Date.now()\n  return new Date(retryAfter).getTime() - current\n}\n\nclass RetryHandler {\n  constructor (opts, handlers) {\n    const { retryOptions, ...dispatchOpts } = opts\n    const {\n      // Retry scoped\n      retry: retryFn,\n      maxRetries,\n      maxTimeout,\n      minTimeout,\n      timeoutFactor,\n      // Response scoped\n      methods,\n      errorCodes,\n      retryAfter,\n      statusCodes\n    } = retryOptions ?? {}\n\n    this.dispatch = handlers.dispatch\n    this.handler = handlers.handler\n    this.opts = { ...dispatchOpts, body: wrapRequestBody(opts.body) }\n    this.abort = null\n    this.aborted = false\n    this.retryOpts = {\n      retry: retryFn ?? RetryHandler[kRetryHandlerDefaultRetry],\n      retryAfter: retryAfter ?? true,\n      maxTimeout: maxTimeout ?? 30 * 1000, // 30s,\n      minTimeout: minTimeout ?? 500, // .5s\n      timeoutFactor: timeoutFactor ?? 2,\n      maxRetries: maxRetries ?? 5,\n      // What errors we should retry\n      methods: methods ?? ['GET', 'HEAD', 'OPTIONS', 'PUT', 'DELETE', 'TRACE'],\n      // Indicates which errors to retry\n      statusCodes: statusCodes ?? [500, 502, 503, 504, 429],\n      // List of errors to retry\n      errorCodes: errorCodes ?? [\n        'ECONNRESET',\n        'ECONNREFUSED',\n        'ENOTFOUND',\n        'ENETDOWN',\n        'ENETUNREACH',\n        'EHOSTDOWN',\n        'EHOSTUNREACH',\n        'EPIPE',\n        'UND_ERR_SOCKET'\n      ]\n    }\n\n    this.retryCount = 0\n    this.retryCountCheckpoint = 0\n    this.start = 0\n    this.end = null\n    this.etag = null\n    this.resume = null\n\n    // Handle possible onConnect duplication\n    this.handler.onConnect(reason => {\n      this.aborted = true\n      if (this.abort) {\n        this.abort(reason)\n      } else {\n        this.reason = reason\n      }\n    })\n  }\n\n  onRequestSent () {\n    if (this.handler.onRequestSent) {\n      this.handler.onRequestSent()\n    }\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    if (this.handler.onUpgrade) {\n      this.handler.onUpgrade(statusCode, headers, socket)\n    }\n  }\n\n  onConnect (abort) {\n    if (this.aborted) {\n      abort(this.reason)\n    } else {\n      this.abort = abort\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this.handler.onBodySent) return this.handler.onBodySent(chunk)\n  }\n\n  static [kRetryHandlerDefaultRetry] (err, { state, opts }, cb) {\n    const { statusCode, code, headers } = err\n    const { method, retryOptions } = opts\n    const {\n      maxRetries,\n      minTimeout,\n      maxTimeout,\n      timeoutFactor,\n      statusCodes,\n      errorCodes,\n      methods\n    } = retryOptions\n    const { counter } = state\n\n    // Any code that is not a Undici's originated and allowed to retry\n    if (code && code !== 'UND_ERR_REQ_RETRY' && !errorCodes.includes(code)) {\n      cb(err)\n      return\n    }\n\n    // If a set of method are provided and the current method is not in the list\n    if (Array.isArray(methods) && !methods.includes(method)) {\n      cb(err)\n      return\n    }\n\n    // If a set of status code are provided and the current status code is not in the list\n    if (\n      statusCode != null &&\n      Array.isArray(statusCodes) &&\n      !statusCodes.includes(statusCode)\n    ) {\n      cb(err)\n      return\n    }\n\n    // If we reached the max number of retries\n    if (counter > maxRetries) {\n      cb(err)\n      return\n    }\n\n    let retryAfterHeader = headers?.['retry-after']\n    if (retryAfterHeader) {\n      retryAfterHeader = Number(retryAfterHeader)\n      retryAfterHeader = Number.isNaN(retryAfterHeader)\n        ? calculateRetryAfterHeader(retryAfterHeader)\n        : retryAfterHeader * 1e3 // Retry-After is in seconds\n    }\n\n    const retryTimeout =\n      retryAfterHeader > 0\n        ? Math.min(retryAfterHeader, maxTimeout)\n        : Math.min(minTimeout * timeoutFactor ** (counter - 1), maxTimeout)\n\n    setTimeout(() => cb(null), retryTimeout)\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const headers = parseHeaders(rawHeaders)\n\n    this.retryCount += 1\n\n    if (statusCode >= 300) {\n      if (this.retryOpts.statusCodes.includes(statusCode) === false) {\n        return this.handler.onHeaders(\n          statusCode,\n          rawHeaders,\n          resume,\n          statusMessage\n        )\n      } else {\n        this.abort(\n          new RequestRetryError('Request failed', statusCode, {\n            headers,\n            data: {\n              count: this.retryCount\n            }\n          })\n        )\n        return false\n      }\n    }\n\n    // Checkpoint for resume from where we left it\n    if (this.resume != null) {\n      this.resume = null\n\n      // Only Partial Content 206 supposed to provide Content-Range,\n      // any other status code that partially consumed the payload\n      // should not be retry because it would result in downstream\n      // wrongly concatanete multiple responses.\n      if (statusCode !== 206 && (this.start > 0 || statusCode !== 200)) {\n        this.abort(\n          new RequestRetryError('server does not support the range header and the payload was partially consumed', statusCode, {\n            headers,\n            data: { count: this.retryCount }\n          })\n        )\n        return false\n      }\n\n      const contentRange = parseRangeHeader(headers['content-range'])\n      // If no content range\n      if (!contentRange) {\n        this.abort(\n          new RequestRetryError('Content-Range mismatch', statusCode, {\n            headers,\n            data: { count: this.retryCount }\n          })\n        )\n        return false\n      }\n\n      // Let's start with a weak etag check\n      if (this.etag != null && this.etag !== headers.etag) {\n        this.abort(\n          new RequestRetryError('ETag mismatch', statusCode, {\n            headers,\n            data: { count: this.retryCount }\n          })\n        )\n        return false\n      }\n\n      const { start, size, end = size - 1 } = contentRange\n\n      assert(this.start === start, 'content-range mismatch')\n      assert(this.end == null || this.end === end, 'content-range mismatch')\n\n      this.resume = resume\n      return true\n    }\n\n    if (this.end == null) {\n      if (statusCode === 206) {\n        // First time we receive 206\n        const range = parseRangeHeader(headers['content-range'])\n\n        if (range == null) {\n          return this.handler.onHeaders(\n            statusCode,\n            rawHeaders,\n            resume,\n            statusMessage\n          )\n        }\n\n        const { start, size, end = size - 1 } = range\n        assert(\n          start != null && Number.isFinite(start),\n          'content-range mismatch'\n        )\n        assert(end != null && Number.isFinite(end), 'invalid content-length')\n\n        this.start = start\n        this.end = end\n      }\n\n      // We make our best to checkpoint the body for further range headers\n      if (this.end == null) {\n        const contentLength = headers['content-length']\n        this.end = contentLength != null ? Number(contentLength) - 1 : null\n      }\n\n      assert(Number.isFinite(this.start))\n      assert(\n        this.end == null || Number.isFinite(this.end),\n        'invalid content-length'\n      )\n\n      this.resume = resume\n      this.etag = headers.etag != null ? headers.etag : null\n\n      // Weak etags are not useful for comparison nor cache\n      // for instance not safe to assume if the response is byte-per-byte\n      // equal\n      if (this.etag != null && this.etag.startsWith('W/')) {\n        this.etag = null\n      }\n\n      return this.handler.onHeaders(\n        statusCode,\n        rawHeaders,\n        resume,\n        statusMessage\n      )\n    }\n\n    const err = new RequestRetryError('Request failed', statusCode, {\n      headers,\n      data: { count: this.retryCount }\n    })\n\n    this.abort(err)\n\n    return false\n  }\n\n  onData (chunk) {\n    this.start += chunk.length\n\n    return this.handler.onData(chunk)\n  }\n\n  onComplete (rawTrailers) {\n    this.retryCount = 0\n    return this.handler.onComplete(rawTrailers)\n  }\n\n  onError (err) {\n    if (this.aborted || isDisturbed(this.opts.body)) {\n      return this.handler.onError(err)\n    }\n\n    // We reconcile in case of a mix between network errors\n    // and server error response\n    if (this.retryCount - this.retryCountCheckpoint > 0) {\n      // We count the difference between the last checkpoint and the current retry count\n      this.retryCount =\n        this.retryCountCheckpoint +\n        (this.retryCount - this.retryCountCheckpoint)\n    } else {\n      this.retryCount += 1\n    }\n\n    this.retryOpts.retry(\n      err,\n      {\n        state: { counter: this.retryCount },\n        opts: { retryOptions: this.retryOpts, ...this.opts }\n      },\n      onRetry.bind(this)\n    )\n\n    function onRetry (err) {\n      if (err != null || this.aborted || isDisturbed(this.opts.body)) {\n        return this.handler.onError(err)\n      }\n\n      if (this.start !== 0) {\n        const headers = { range: `bytes=${this.start}-${this.end ?? ''}` }\n\n        // Weak etag check - weak etags will make comparison algorithms never match\n        if (this.etag != null) {\n          headers['if-match'] = this.etag\n        }\n\n        this.opts = {\n          ...this.opts,\n          headers: {\n            ...this.opts.headers,\n            ...headers\n          }\n        }\n      }\n\n      try {\n        this.retryCountCheckpoint = this.retryCount\n        this.dispatch(this.opts, this)\n      } catch (err) {\n        this.handler.onError(err)\n      }\n    }\n  }\n}\n\nmodule.exports = RetryHandler\n","'use strict'\nconst { isIP } = require('node:net')\nconst { lookup } = require('node:dns')\nconst DecoratorHandler = require('../handler/decorator-handler')\nconst { InvalidArgumentError, InformationalError } = require('../core/errors')\nconst maxInt = Math.pow(2, 31) - 1\n\nclass DNSInstance {\n  #maxTTL = 0\n  #maxItems = 0\n  #records = new Map()\n  dualStack = true\n  affinity = null\n  lookup = null\n  pick = null\n\n  constructor (opts) {\n    this.#maxTTL = opts.maxTTL\n    this.#maxItems = opts.maxItems\n    this.dualStack = opts.dualStack\n    this.affinity = opts.affinity\n    this.lookup = opts.lookup ?? this.#defaultLookup\n    this.pick = opts.pick ?? this.#defaultPick\n  }\n\n  get full () {\n    return this.#records.size === this.#maxItems\n  }\n\n  runLookup (origin, opts, cb) {\n    const ips = this.#records.get(origin.hostname)\n\n    // If full, we just return the origin\n    if (ips == null && this.full) {\n      cb(null, origin.origin)\n      return\n    }\n\n    const newOpts = {\n      affinity: this.affinity,\n      dualStack: this.dualStack,\n      lookup: this.lookup,\n      pick: this.pick,\n      ...opts.dns,\n      maxTTL: this.#maxTTL,\n      maxItems: this.#maxItems\n    }\n\n    // If no IPs we lookup\n    if (ips == null) {\n      this.lookup(origin, newOpts, (err, addresses) => {\n        if (err || addresses == null || addresses.length === 0) {\n          cb(err ?? new InformationalError('No DNS entries found'))\n          return\n        }\n\n        this.setRecords(origin, addresses)\n        const records = this.#records.get(origin.hostname)\n\n        const ip = this.pick(\n          origin,\n          records,\n          newOpts.affinity\n        )\n\n        let port\n        if (typeof ip.port === 'number') {\n          port = `:${ip.port}`\n        } else if (origin.port !== '') {\n          port = `:${origin.port}`\n        } else {\n          port = ''\n        }\n\n        cb(\n          null,\n          `${origin.protocol}//${\n            ip.family === 6 ? `[${ip.address}]` : ip.address\n          }${port}`\n        )\n      })\n    } else {\n      // If there's IPs we pick\n      const ip = this.pick(\n        origin,\n        ips,\n        newOpts.affinity\n      )\n\n      // If no IPs we lookup - deleting old records\n      if (ip == null) {\n        this.#records.delete(origin.hostname)\n        this.runLookup(origin, opts, cb)\n        return\n      }\n\n      let port\n      if (typeof ip.port === 'number') {\n        port = `:${ip.port}`\n      } else if (origin.port !== '') {\n        port = `:${origin.port}`\n      } else {\n        port = ''\n      }\n\n      cb(\n        null,\n        `${origin.protocol}//${\n          ip.family === 6 ? `[${ip.address}]` : ip.address\n        }${port}`\n      )\n    }\n  }\n\n  #defaultLookup (origin, opts, cb) {\n    lookup(\n      origin.hostname,\n      {\n        all: true,\n        family: this.dualStack === false ? this.affinity : 0,\n        order: 'ipv4first'\n      },\n      (err, addresses) => {\n        if (err) {\n          return cb(err)\n        }\n\n        const results = new Map()\n\n        for (const addr of addresses) {\n          // On linux we found duplicates, we attempt to remove them with\n          // the latest record\n          results.set(`${addr.address}:${addr.family}`, addr)\n        }\n\n        cb(null, results.values())\n      }\n    )\n  }\n\n  #defaultPick (origin, hostnameRecords, affinity) {\n    let ip = null\n    const { records, offset } = hostnameRecords\n\n    let family\n    if (this.dualStack) {\n      if (affinity == null) {\n        // Balance between ip families\n        if (offset == null || offset === maxInt) {\n          hostnameRecords.offset = 0\n          affinity = 4\n        } else {\n          hostnameRecords.offset++\n          affinity = (hostnameRecords.offset & 1) === 1 ? 6 : 4\n        }\n      }\n\n      if (records[affinity] != null && records[affinity].ips.length > 0) {\n        family = records[affinity]\n      } else {\n        family = records[affinity === 4 ? 6 : 4]\n      }\n    } else {\n      family = records[affinity]\n    }\n\n    // If no IPs we return null\n    if (family == null || family.ips.length === 0) {\n      return ip\n    }\n\n    if (family.offset == null || family.offset === maxInt) {\n      family.offset = 0\n    } else {\n      family.offset++\n    }\n\n    const position = family.offset % family.ips.length\n    ip = family.ips[position] ?? null\n\n    if (ip == null) {\n      return ip\n    }\n\n    if (Date.now() - ip.timestamp > ip.ttl) { // record TTL is already in ms\n      // We delete expired records\n      // It is possible that they have different TTL, so we manage them individually\n      family.ips.splice(position, 1)\n      return this.pick(origin, hostnameRecords, affinity)\n    }\n\n    return ip\n  }\n\n  setRecords (origin, addresses) {\n    const timestamp = Date.now()\n    const records = { records: { 4: null, 6: null } }\n    for (const record of addresses) {\n      record.timestamp = timestamp\n      if (typeof record.ttl === 'number') {\n        // The record TTL is expected to be in ms\n        record.ttl = Math.min(record.ttl, this.#maxTTL)\n      } else {\n        record.ttl = this.#maxTTL\n      }\n\n      const familyRecords = records.records[record.family] ?? { ips: [] }\n\n      familyRecords.ips.push(record)\n      records.records[record.family] = familyRecords\n    }\n\n    this.#records.set(origin.hostname, records)\n  }\n\n  getHandler (meta, opts) {\n    return new DNSDispatchHandler(this, meta, opts)\n  }\n}\n\nclass DNSDispatchHandler extends DecoratorHandler {\n  #state = null\n  #opts = null\n  #dispatch = null\n  #handler = null\n  #origin = null\n\n  constructor (state, { origin, handler, dispatch }, opts) {\n    super(handler)\n    this.#origin = origin\n    this.#handler = handler\n    this.#opts = { ...opts }\n    this.#state = state\n    this.#dispatch = dispatch\n  }\n\n  onError (err) {\n    switch (err.code) {\n      case 'ETIMEDOUT':\n      case 'ECONNREFUSED': {\n        if (this.#state.dualStack) {\n          // We delete the record and retry\n          this.#state.runLookup(this.#origin, this.#opts, (err, newOrigin) => {\n            if (err) {\n              return this.#handler.onError(err)\n            }\n\n            const dispatchOpts = {\n              ...this.#opts,\n              origin: newOrigin\n            }\n\n            this.#dispatch(dispatchOpts, this)\n          })\n\n          // if dual-stack disabled, we error out\n          return\n        }\n\n        this.#handler.onError(err)\n        return\n      }\n      case 'ENOTFOUND':\n        this.#state.deleteRecord(this.#origin)\n      // eslint-disable-next-line no-fallthrough\n      default:\n        this.#handler.onError(err)\n        break\n    }\n  }\n}\n\nmodule.exports = interceptorOpts => {\n  if (\n    interceptorOpts?.maxTTL != null &&\n    (typeof interceptorOpts?.maxTTL !== 'number' || interceptorOpts?.maxTTL < 0)\n  ) {\n    throw new InvalidArgumentError('Invalid maxTTL. Must be a positive number')\n  }\n\n  if (\n    interceptorOpts?.maxItems != null &&\n    (typeof interceptorOpts?.maxItems !== 'number' ||\n      interceptorOpts?.maxItems < 1)\n  ) {\n    throw new InvalidArgumentError(\n      'Invalid maxItems. Must be a positive number and greater than zero'\n    )\n  }\n\n  if (\n    interceptorOpts?.affinity != null &&\n    interceptorOpts?.affinity !== 4 &&\n    interceptorOpts?.affinity !== 6\n  ) {\n    throw new InvalidArgumentError('Invalid affinity. Must be either 4 or 6')\n  }\n\n  if (\n    interceptorOpts?.dualStack != null &&\n    typeof interceptorOpts?.dualStack !== 'boolean'\n  ) {\n    throw new InvalidArgumentError('Invalid dualStack. Must be a boolean')\n  }\n\n  if (\n    interceptorOpts?.lookup != null &&\n    typeof interceptorOpts?.lookup !== 'function'\n  ) {\n    throw new InvalidArgumentError('Invalid lookup. Must be a function')\n  }\n\n  if (\n    interceptorOpts?.pick != null &&\n    typeof interceptorOpts?.pick !== 'function'\n  ) {\n    throw new InvalidArgumentError('Invalid pick. Must be a function')\n  }\n\n  const dualStack = interceptorOpts?.dualStack ?? true\n  let affinity\n  if (dualStack) {\n    affinity = interceptorOpts?.affinity ?? null\n  } else {\n    affinity = interceptorOpts?.affinity ?? 4\n  }\n\n  const opts = {\n    maxTTL: interceptorOpts?.maxTTL ?? 10e3, // Expressed in ms\n    lookup: interceptorOpts?.lookup ?? null,\n    pick: interceptorOpts?.pick ?? null,\n    dualStack,\n    affinity,\n    maxItems: interceptorOpts?.maxItems ?? Infinity\n  }\n\n  const instance = new DNSInstance(opts)\n\n  return dispatch => {\n    return function dnsInterceptor (origDispatchOpts, handler) {\n      const origin =\n        origDispatchOpts.origin.constructor === URL\n          ? origDispatchOpts.origin\n          : new URL(origDispatchOpts.origin)\n\n      if (isIP(origin.hostname) !== 0) {\n        return dispatch(origDispatchOpts, handler)\n      }\n\n      instance.runLookup(origin, origDispatchOpts, (err, newOrigin) => {\n        if (err) {\n          return handler.onError(err)\n        }\n\n        let dispatchOpts = null\n        dispatchOpts = {\n          ...origDispatchOpts,\n          servername: origin.hostname, // For SNI on TLS\n          origin: newOrigin,\n          headers: {\n            host: origin.hostname,\n            ...origDispatchOpts.headers\n          }\n        }\n\n        dispatch(\n          dispatchOpts,\n          instance.getHandler({ origin, dispatch, handler }, origDispatchOpts)\n        )\n      })\n\n      return true\n    }\n  }\n}\n","'use strict'\n\nconst util = require('../core/util')\nconst { InvalidArgumentError, RequestAbortedError } = require('../core/errors')\nconst DecoratorHandler = require('../handler/decorator-handler')\n\nclass DumpHandler extends DecoratorHandler {\n  #maxSize = 1024 * 1024\n  #abort = null\n  #dumped = false\n  #aborted = false\n  #size = 0\n  #reason = null\n  #handler = null\n\n  constructor ({ maxSize }, handler) {\n    super(handler)\n\n    if (maxSize != null && (!Number.isFinite(maxSize) || maxSize < 1)) {\n      throw new InvalidArgumentError('maxSize must be a number greater than 0')\n    }\n\n    this.#maxSize = maxSize ?? this.#maxSize\n    this.#handler = handler\n  }\n\n  onConnect (abort) {\n    this.#abort = abort\n\n    this.#handler.onConnect(this.#customAbort.bind(this))\n  }\n\n  #customAbort (reason) {\n    this.#aborted = true\n    this.#reason = reason\n  }\n\n  // TODO: will require adjustment after new hooks are out\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const headers = util.parseHeaders(rawHeaders)\n    const contentLength = headers['content-length']\n\n    if (contentLength != null && contentLength > this.#maxSize) {\n      throw new RequestAbortedError(\n        `Response size (${contentLength}) larger than maxSize (${\n          this.#maxSize\n        })`\n      )\n    }\n\n    if (this.#aborted) {\n      return true\n    }\n\n    return this.#handler.onHeaders(\n      statusCode,\n      rawHeaders,\n      resume,\n      statusMessage\n    )\n  }\n\n  onError (err) {\n    if (this.#dumped) {\n      return\n    }\n\n    err = this.#reason ?? err\n\n    this.#handler.onError(err)\n  }\n\n  onData (chunk) {\n    this.#size = this.#size + chunk.length\n\n    if (this.#size >= this.#maxSize) {\n      this.#dumped = true\n\n      if (this.#aborted) {\n        this.#handler.onError(this.#reason)\n      } else {\n        this.#handler.onComplete([])\n      }\n    }\n\n    return true\n  }\n\n  onComplete (trailers) {\n    if (this.#dumped) {\n      return\n    }\n\n    if (this.#aborted) {\n      this.#handler.onError(this.reason)\n      return\n    }\n\n    this.#handler.onComplete(trailers)\n  }\n}\n\nfunction createDumpInterceptor (\n  { maxSize: defaultMaxSize } = {\n    maxSize: 1024 * 1024\n  }\n) {\n  return dispatch => {\n    return function Intercept (opts, handler) {\n      const { dumpMaxSize = defaultMaxSize } =\n        opts\n\n      const dumpHandler = new DumpHandler(\n        { maxSize: dumpMaxSize },\n        handler\n      )\n\n      return dispatch(opts, dumpHandler)\n    }\n  }\n}\n\nmodule.exports = createDumpInterceptor\n","'use strict'\n\nconst RedirectHandler = require('../handler/redirect-handler')\n\nfunction createRedirectInterceptor ({ maxRedirections: defaultMaxRedirections }) {\n  return (dispatch) => {\n    return function Intercept (opts, handler) {\n      const { maxRedirections = defaultMaxRedirections } = opts\n\n      if (!maxRedirections) {\n        return dispatch(opts, handler)\n      }\n\n      const redirectHandler = new RedirectHandler(dispatch, maxRedirections, opts, handler)\n      opts = { ...opts, maxRedirections: 0 } // Stop sub dispatcher from also redirecting.\n      return dispatch(opts, redirectHandler)\n    }\n  }\n}\n\nmodule.exports = createRedirectInterceptor\n","'use strict'\nconst RedirectHandler = require('../handler/redirect-handler')\n\nmodule.exports = opts => {\n  const globalMaxRedirections = opts?.maxRedirections\n  return dispatch => {\n    return function redirectInterceptor (opts, handler) {\n      const { maxRedirections = globalMaxRedirections, ...baseOpts } = opts\n\n      if (!maxRedirections) {\n        return dispatch(opts, handler)\n      }\n\n      const redirectHandler = new RedirectHandler(\n        dispatch,\n        maxRedirections,\n        opts,\n        handler\n      )\n\n      return dispatch(baseOpts, redirectHandler)\n    }\n  }\n}\n","'use strict'\nconst RetryHandler = require('../handler/retry-handler')\n\nmodule.exports = globalOpts => {\n  return dispatch => {\n    return function retryInterceptor (opts, handler) {\n      return dispatch(\n        opts,\n        new RetryHandler(\n          { ...opts, retryOptions: { ...globalOpts, ...opts.retryOptions } },\n          {\n            handler,\n            dispatch\n          }\n        )\n      )\n    }\n  }\n}\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SPECIAL_HEADERS = exports.HEADER_STATE = exports.MINOR = exports.MAJOR = exports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS = exports.TOKEN = exports.STRICT_TOKEN = exports.HEX = exports.URL_CHAR = exports.STRICT_URL_CHAR = exports.USERINFO_CHARS = exports.MARK = exports.ALPHANUM = exports.NUM = exports.HEX_MAP = exports.NUM_MAP = exports.ALPHA = exports.FINISH = exports.H_METHOD_MAP = exports.METHOD_MAP = exports.METHODS_RTSP = exports.METHODS_ICE = exports.METHODS_HTTP = exports.METHODS = exports.LENIENT_FLAGS = exports.FLAGS = exports.TYPE = exports.ERROR = void 0;\nconst utils_1 = require(\"./utils\");\n// C headers\nvar ERROR;\n(function (ERROR) {\n    ERROR[ERROR[\"OK\"] = 0] = \"OK\";\n    ERROR[ERROR[\"INTERNAL\"] = 1] = \"INTERNAL\";\n    ERROR[ERROR[\"STRICT\"] = 2] = \"STRICT\";\n    ERROR[ERROR[\"LF_EXPECTED\"] = 3] = \"LF_EXPECTED\";\n    ERROR[ERROR[\"UNEXPECTED_CONTENT_LENGTH\"] = 4] = \"UNEXPECTED_CONTENT_LENGTH\";\n    ERROR[ERROR[\"CLOSED_CONNECTION\"] = 5] = \"CLOSED_CONNECTION\";\n    ERROR[ERROR[\"INVALID_METHOD\"] = 6] = \"INVALID_METHOD\";\n    ERROR[ERROR[\"INVALID_URL\"] = 7] = \"INVALID_URL\";\n    ERROR[ERROR[\"INVALID_CONSTANT\"] = 8] = \"INVALID_CONSTANT\";\n    ERROR[ERROR[\"INVALID_VERSION\"] = 9] = \"INVALID_VERSION\";\n    ERROR[ERROR[\"INVALID_HEADER_TOKEN\"] = 10] = \"INVALID_HEADER_TOKEN\";\n    ERROR[ERROR[\"INVALID_CONTENT_LENGTH\"] = 11] = \"INVALID_CONTENT_LENGTH\";\n    ERROR[ERROR[\"INVALID_CHUNK_SIZE\"] = 12] = \"INVALID_CHUNK_SIZE\";\n    ERROR[ERROR[\"INVALID_STATUS\"] = 13] = \"INVALID_STATUS\";\n    ERROR[ERROR[\"INVALID_EOF_STATE\"] = 14] = \"INVALID_EOF_STATE\";\n    ERROR[ERROR[\"INVALID_TRANSFER_ENCODING\"] = 15] = \"INVALID_TRANSFER_ENCODING\";\n    ERROR[ERROR[\"CB_MESSAGE_BEGIN\"] = 16] = \"CB_MESSAGE_BEGIN\";\n    ERROR[ERROR[\"CB_HEADERS_COMPLETE\"] = 17] = \"CB_HEADERS_COMPLETE\";\n    ERROR[ERROR[\"CB_MESSAGE_COMPLETE\"] = 18] = \"CB_MESSAGE_COMPLETE\";\n    ERROR[ERROR[\"CB_CHUNK_HEADER\"] = 19] = \"CB_CHUNK_HEADER\";\n    ERROR[ERROR[\"CB_CHUNK_COMPLETE\"] = 20] = \"CB_CHUNK_COMPLETE\";\n    ERROR[ERROR[\"PAUSED\"] = 21] = \"PAUSED\";\n    ERROR[ERROR[\"PAUSED_UPGRADE\"] = 22] = \"PAUSED_UPGRADE\";\n    ERROR[ERROR[\"PAUSED_H2_UPGRADE\"] = 23] = \"PAUSED_H2_UPGRADE\";\n    ERROR[ERROR[\"USER\"] = 24] = \"USER\";\n})(ERROR = exports.ERROR || (exports.ERROR = {}));\nvar TYPE;\n(function (TYPE) {\n    TYPE[TYPE[\"BOTH\"] = 0] = \"BOTH\";\n    TYPE[TYPE[\"REQUEST\"] = 1] = \"REQUEST\";\n    TYPE[TYPE[\"RESPONSE\"] = 2] = \"RESPONSE\";\n})(TYPE = exports.TYPE || (exports.TYPE = {}));\nvar FLAGS;\n(function (FLAGS) {\n    FLAGS[FLAGS[\"CONNECTION_KEEP_ALIVE\"] = 1] = \"CONNECTION_KEEP_ALIVE\";\n    FLAGS[FLAGS[\"CONNECTION_CLOSE\"] = 2] = \"CONNECTION_CLOSE\";\n    FLAGS[FLAGS[\"CONNECTION_UPGRADE\"] = 4] = \"CONNECTION_UPGRADE\";\n    FLAGS[FLAGS[\"CHUNKED\"] = 8] = \"CHUNKED\";\n    FLAGS[FLAGS[\"UPGRADE\"] = 16] = \"UPGRADE\";\n    FLAGS[FLAGS[\"CONTENT_LENGTH\"] = 32] = \"CONTENT_LENGTH\";\n    FLAGS[FLAGS[\"SKIPBODY\"] = 64] = \"SKIPBODY\";\n    FLAGS[FLAGS[\"TRAILING\"] = 128] = \"TRAILING\";\n    // 1 << 8 is unused\n    FLAGS[FLAGS[\"TRANSFER_ENCODING\"] = 512] = \"TRANSFER_ENCODING\";\n})(FLAGS = exports.FLAGS || (exports.FLAGS = {}));\nvar LENIENT_FLAGS;\n(function (LENIENT_FLAGS) {\n    LENIENT_FLAGS[LENIENT_FLAGS[\"HEADERS\"] = 1] = \"HEADERS\";\n    LENIENT_FLAGS[LENIENT_FLAGS[\"CHUNKED_LENGTH\"] = 2] = \"CHUNKED_LENGTH\";\n    LENIENT_FLAGS[LENIENT_FLAGS[\"KEEP_ALIVE\"] = 4] = \"KEEP_ALIVE\";\n})(LENIENT_FLAGS = exports.LENIENT_FLAGS || (exports.LENIENT_FLAGS = {}));\nvar METHODS;\n(function (METHODS) {\n    METHODS[METHODS[\"DELETE\"] = 0] = \"DELETE\";\n    METHODS[METHODS[\"GET\"] = 1] = \"GET\";\n    METHODS[METHODS[\"HEAD\"] = 2] = \"HEAD\";\n    METHODS[METHODS[\"POST\"] = 3] = \"POST\";\n    METHODS[METHODS[\"PUT\"] = 4] = \"PUT\";\n    /* pathological */\n    METHODS[METHODS[\"CONNECT\"] = 5] = \"CONNECT\";\n    METHODS[METHODS[\"OPTIONS\"] = 6] = \"OPTIONS\";\n    METHODS[METHODS[\"TRACE\"] = 7] = \"TRACE\";\n    /* WebDAV */\n    METHODS[METHODS[\"COPY\"] = 8] = \"COPY\";\n    METHODS[METHODS[\"LOCK\"] = 9] = \"LOCK\";\n    METHODS[METHODS[\"MKCOL\"] = 10] = \"MKCOL\";\n    METHODS[METHODS[\"MOVE\"] = 11] = \"MOVE\";\n    METHODS[METHODS[\"PROPFIND\"] = 12] = \"PROPFIND\";\n    METHODS[METHODS[\"PROPPATCH\"] = 13] = \"PROPPATCH\";\n    METHODS[METHODS[\"SEARCH\"] = 14] = \"SEARCH\";\n    METHODS[METHODS[\"UNLOCK\"] = 15] = \"UNLOCK\";\n    METHODS[METHODS[\"BIND\"] = 16] = \"BIND\";\n    METHODS[METHODS[\"REBIND\"] = 17] = \"REBIND\";\n    METHODS[METHODS[\"UNBIND\"] = 18] = \"UNBIND\";\n    METHODS[METHODS[\"ACL\"] = 19] = \"ACL\";\n    /* subversion */\n    METHODS[METHODS[\"REPORT\"] = 20] = \"REPORT\";\n    METHODS[METHODS[\"MKACTIVITY\"] = 21] = \"MKACTIVITY\";\n    METHODS[METHODS[\"CHECKOUT\"] = 22] = \"CHECKOUT\";\n    METHODS[METHODS[\"MERGE\"] = 23] = \"MERGE\";\n    /* upnp */\n    METHODS[METHODS[\"M-SEARCH\"] = 24] = \"M-SEARCH\";\n    METHODS[METHODS[\"NOTIFY\"] = 25] = \"NOTIFY\";\n    METHODS[METHODS[\"SUBSCRIBE\"] = 26] = \"SUBSCRIBE\";\n    METHODS[METHODS[\"UNSUBSCRIBE\"] = 27] = \"UNSUBSCRIBE\";\n    /* RFC-5789 */\n    METHODS[METHODS[\"PATCH\"] = 28] = \"PATCH\";\n    METHODS[METHODS[\"PURGE\"] = 29] = \"PURGE\";\n    /* CalDAV */\n    METHODS[METHODS[\"MKCALENDAR\"] = 30] = \"MKCALENDAR\";\n    /* RFC-2068, section 19.6.1.2 */\n    METHODS[METHODS[\"LINK\"] = 31] = \"LINK\";\n    METHODS[METHODS[\"UNLINK\"] = 32] = \"UNLINK\";\n    /* icecast */\n    METHODS[METHODS[\"SOURCE\"] = 33] = \"SOURCE\";\n    /* RFC-7540, section 11.6 */\n    METHODS[METHODS[\"PRI\"] = 34] = \"PRI\";\n    /* RFC-2326 RTSP */\n    METHODS[METHODS[\"DESCRIBE\"] = 35] = \"DESCRIBE\";\n    METHODS[METHODS[\"ANNOUNCE\"] = 36] = \"ANNOUNCE\";\n    METHODS[METHODS[\"SETUP\"] = 37] = \"SETUP\";\n    METHODS[METHODS[\"PLAY\"] = 38] = \"PLAY\";\n    METHODS[METHODS[\"PAUSE\"] = 39] = \"PAUSE\";\n    METHODS[METHODS[\"TEARDOWN\"] = 40] = \"TEARDOWN\";\n    METHODS[METHODS[\"GET_PARAMETER\"] = 41] = \"GET_PARAMETER\";\n    METHODS[METHODS[\"SET_PARAMETER\"] = 42] = \"SET_PARAMETER\";\n    METHODS[METHODS[\"REDIRECT\"] = 43] = \"REDIRECT\";\n    METHODS[METHODS[\"RECORD\"] = 44] = \"RECORD\";\n    /* RAOP */\n    METHODS[METHODS[\"FLUSH\"] = 45] = \"FLUSH\";\n})(METHODS = exports.METHODS || (exports.METHODS = {}));\nexports.METHODS_HTTP = [\n    METHODS.DELETE,\n    METHODS.GET,\n    METHODS.HEAD,\n    METHODS.POST,\n    METHODS.PUT,\n    METHODS.CONNECT,\n    METHODS.OPTIONS,\n    METHODS.TRACE,\n    METHODS.COPY,\n    METHODS.LOCK,\n    METHODS.MKCOL,\n    METHODS.MOVE,\n    METHODS.PROPFIND,\n    METHODS.PROPPATCH,\n    METHODS.SEARCH,\n    METHODS.UNLOCK,\n    METHODS.BIND,\n    METHODS.REBIND,\n    METHODS.UNBIND,\n    METHODS.ACL,\n    METHODS.REPORT,\n    METHODS.MKACTIVITY,\n    METHODS.CHECKOUT,\n    METHODS.MERGE,\n    METHODS['M-SEARCH'],\n    METHODS.NOTIFY,\n    METHODS.SUBSCRIBE,\n    METHODS.UNSUBSCRIBE,\n    METHODS.PATCH,\n    METHODS.PURGE,\n    METHODS.MKCALENDAR,\n    METHODS.LINK,\n    METHODS.UNLINK,\n    METHODS.PRI,\n    // TODO(indutny): should we allow it with HTTP?\n    METHODS.SOURCE,\n];\nexports.METHODS_ICE = [\n    METHODS.SOURCE,\n];\nexports.METHODS_RTSP = [\n    METHODS.OPTIONS,\n    METHODS.DESCRIBE,\n    METHODS.ANNOUNCE,\n    METHODS.SETUP,\n    METHODS.PLAY,\n    METHODS.PAUSE,\n    METHODS.TEARDOWN,\n    METHODS.GET_PARAMETER,\n    METHODS.SET_PARAMETER,\n    METHODS.REDIRECT,\n    METHODS.RECORD,\n    METHODS.FLUSH,\n    // For AirPlay\n    METHODS.GET,\n    METHODS.POST,\n];\nexports.METHOD_MAP = utils_1.enumToMap(METHODS);\nexports.H_METHOD_MAP = {};\nObject.keys(exports.METHOD_MAP).forEach((key) => {\n    if (/^H/.test(key)) {\n        exports.H_METHOD_MAP[key] = exports.METHOD_MAP[key];\n    }\n});\nvar FINISH;\n(function (FINISH) {\n    FINISH[FINISH[\"SAFE\"] = 0] = \"SAFE\";\n    FINISH[FINISH[\"SAFE_WITH_CB\"] = 1] = \"SAFE_WITH_CB\";\n    FINISH[FINISH[\"UNSAFE\"] = 2] = \"UNSAFE\";\n})(FINISH = exports.FINISH || (exports.FINISH = {}));\nexports.ALPHA = [];\nfor (let i = 'A'.charCodeAt(0); i <= 'Z'.charCodeAt(0); i++) {\n    // Upper case\n    exports.ALPHA.push(String.fromCharCode(i));\n    // Lower case\n    exports.ALPHA.push(String.fromCharCode(i + 0x20));\n}\nexports.NUM_MAP = {\n    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,\n    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,\n};\nexports.HEX_MAP = {\n    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,\n    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,\n    A: 0XA, B: 0XB, C: 0XC, D: 0XD, E: 0XE, F: 0XF,\n    a: 0xa, b: 0xb, c: 0xc, d: 0xd, e: 0xe, f: 0xf,\n};\nexports.NUM = [\n    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n];\nexports.ALPHANUM = exports.ALPHA.concat(exports.NUM);\nexports.MARK = ['-', '_', '.', '!', '~', '*', '\\'', '(', ')'];\nexports.USERINFO_CHARS = exports.ALPHANUM\n    .concat(exports.MARK)\n    .concat(['%', ';', ':', '&', '=', '+', '$', ',']);\n// TODO(indutny): use RFC\nexports.STRICT_URL_CHAR = [\n    '!', '\"', '$', '%', '&', '\\'',\n    '(', ')', '*', '+', ',', '-', '.', '/',\n    ':', ';', '<', '=', '>',\n    '@', '[', '\\\\', ']', '^', '_',\n    '`',\n    '{', '|', '}', '~',\n].concat(exports.ALPHANUM);\nexports.URL_CHAR = exports.STRICT_URL_CHAR\n    .concat(['\\t', '\\f']);\n// All characters with 0x80 bit set to 1\nfor (let i = 0x80; i <= 0xff; i++) {\n    exports.URL_CHAR.push(i);\n}\nexports.HEX = exports.NUM.concat(['a', 'b', 'c', 'd', 'e', 'f', 'A', 'B', 'C', 'D', 'E', 'F']);\n/* Tokens as defined by rfc 2616. Also lowercases them.\n *        token       = 1*<any CHAR except CTLs or separators>\n *     separators     = \"(\" | \")\" | \"<\" | \">\" | \"@\"\n *                    | \",\" | \";\" | \":\" | \"\\\" | <\">\n *                    | \"/\" | \"[\" | \"]\" | \"?\" | \"=\"\n *                    | \"{\" | \"}\" | SP | HT\n */\nexports.STRICT_TOKEN = [\n    '!', '#', '$', '%', '&', '\\'',\n    '*', '+', '-', '.',\n    '^', '_', '`',\n    '|', '~',\n].concat(exports.ALPHANUM);\nexports.TOKEN = exports.STRICT_TOKEN.concat([' ']);\n/*\n * Verify that a char is a valid visible (printable) US-ASCII\n * character or %x80-FF\n */\nexports.HEADER_CHARS = ['\\t'];\nfor (let i = 32; i <= 255; i++) {\n    if (i !== 127) {\n        exports.HEADER_CHARS.push(i);\n    }\n}\n// ',' = \\x44\nexports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS.filter((c) => c !== 44);\nexports.MAJOR = exports.NUM_MAP;\nexports.MINOR = exports.MAJOR;\nvar HEADER_STATE;\n(function (HEADER_STATE) {\n    HEADER_STATE[HEADER_STATE[\"GENERAL\"] = 0] = \"GENERAL\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION\"] = 1] = \"CONNECTION\";\n    HEADER_STATE[HEADER_STATE[\"CONTENT_LENGTH\"] = 2] = \"CONTENT_LENGTH\";\n    HEADER_STATE[HEADER_STATE[\"TRANSFER_ENCODING\"] = 3] = \"TRANSFER_ENCODING\";\n    HEADER_STATE[HEADER_STATE[\"UPGRADE\"] = 4] = \"UPGRADE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_KEEP_ALIVE\"] = 5] = \"CONNECTION_KEEP_ALIVE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_CLOSE\"] = 6] = \"CONNECTION_CLOSE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_UPGRADE\"] = 7] = \"CONNECTION_UPGRADE\";\n    HEADER_STATE[HEADER_STATE[\"TRANSFER_ENCODING_CHUNKED\"] = 8] = \"TRANSFER_ENCODING_CHUNKED\";\n})(HEADER_STATE = exports.HEADER_STATE || (exports.HEADER_STATE = {}));\nexports.SPECIAL_HEADERS = {\n    'connection': HEADER_STATE.CONNECTION,\n    'content-length': HEADER_STATE.CONTENT_LENGTH,\n    'proxy-connection': HEADER_STATE.CONNECTION,\n    'transfer-encoding': HEADER_STATE.TRANSFER_ENCODING,\n    'upgrade': HEADER_STATE.UPGRADE,\n};\n//# sourceMappingURL=constants.js.map","'use strict'\n\nconst { Buffer } = require('node:buffer')\n\nmodule.exports = Buffer.from('AGFzbQEAAAABJwdgAX8Bf2ADf39/AX9gAX8AYAJ/fwBgBH9/f38Bf2AAAGADf39/AALLAQgDZW52GHdhc21fb25faGVhZGVyc19jb21wbGV0ZQAEA2VudhV3YXNtX29uX21lc3NhZ2VfYmVnaW4AAANlbnYLd2FzbV9vbl91cmwAAQNlbnYOd2FzbV9vbl9zdGF0dXMAAQNlbnYUd2FzbV9vbl9oZWFkZXJfZmllbGQAAQNlbnYUd2FzbV9vbl9oZWFkZXJfdmFsdWUAAQNlbnYMd2FzbV9vbl9ib2R5AAEDZW52GHdhc21fb25fbWVzc2FnZV9jb21wbGV0ZQAAAy0sBQYAAAIAAAAAAAACAQIAAgICAAADAAAAAAMDAwMBAQEBAQEBAQEAAAIAAAAEBQFwARISBQMBAAIGCAF/AUGA1AQLB9EFIgZtZW1vcnkCAAtfaW5pdGlhbGl6ZQAIGV9faW5kaXJlY3RfZnVuY3Rpb25fdGFibGUBAAtsbGh0dHBfaW5pdAAJGGxsaHR0cF9zaG91bGRfa2VlcF9hbGl2ZQAvDGxsaHR0cF9hbGxvYwALBm1hbGxvYwAxC2xsaHR0cF9mcmVlAAwEZnJlZQAMD2xsaHR0cF9nZXRfdHlwZQANFWxsaHR0cF9nZXRfaHR0cF9tYWpvcgAOFWxsaHR0cF9nZXRfaHR0cF9taW5vcgAPEWxsaHR0cF9nZXRfbWV0aG9kABAWbGxodHRwX2dldF9zdGF0dXNfY29kZQAREmxsaHR0cF9nZXRfdXBncmFkZQASDGxsaHR0cF9yZXNldAATDmxsaHR0cF9leGVjdXRlABQUbGxodHRwX3NldHRpbmdzX2luaXQAFQ1sbGh0dHBfZmluaXNoABYMbGxodHRwX3BhdXNlABcNbGxodHRwX3Jlc3VtZQAYG2xsaHR0cF9yZXN1bWVfYWZ0ZXJfdXBncmFkZQAZEGxsaHR0cF9nZXRfZXJybm8AGhdsbGh0dHBfZ2V0X2Vycm9yX3JlYXNvbgAbF2xsaHR0cF9zZXRfZXJyb3JfcmVhc29uABwUbGxodHRwX2dldF9lcnJvcl9wb3MAHRFsbGh0dHBfZXJybm9fbmFtZQAeEmxsaHR0cF9tZXRob2RfbmFtZQAfEmxsaHR0cF9zdGF0dXNfbmFtZQAgGmxsaHR0cF9zZXRfbGVuaWVudF9oZWFkZXJzACEhbGxodHRwX3NldF9sZW5pZW50X2NodW5rZWRfbGVuZ3RoACIdbGxodHRwX3NldF9sZW5pZW50X2tlZXBfYWxpdmUAIyRsbGh0dHBfc2V0X2xlbmllbnRfdHJhbnNmZXJfZW5jb2RpbmcAJBhsbGh0dHBfbWVzc2FnZV9uZWVkc19lb2YALgkXAQBBAQsRAQIDBAUKBgcrLSwqKSglJyYK07MCLBYAQYjQACgCAARAAAtBiNAAQQE2AgALFAAgABAwIAAgAjYCOCAAIAE6ACgLFAAgACAALwEyIAAtAC4gABAvEAALHgEBf0HAABAyIgEQMCABQYAINgI4IAEgADoAKCABC48MAQd/AkAgAEUNACAAQQhrIgEgAEEEaygCACIAQXhxIgRqIQUCQCAAQQFxDQAgAEEDcUUNASABIAEoAgAiAGsiAUGc0AAoAgBJDQEgACAEaiEEAkACQEGg0AAoAgAgAUcEQCAAQf8BTQRAIABBA3YhAyABKAIIIgAgASgCDCICRgRAQYzQAEGM0AAoAgBBfiADd3E2AgAMBQsgAiAANgIIIAAgAjYCDAwECyABKAIYIQYgASABKAIMIgBHBEAgACABKAIIIgI2AgggAiAANgIMDAMLIAFBFGoiAygCACICRQRAIAEoAhAiAkUNAiABQRBqIQMLA0AgAyEHIAIiAEEUaiIDKAIAIgINACAAQRBqIQMgACgCECICDQALIAdBADYCAAwCCyAFKAIEIgBBA3FBA0cNAiAFIABBfnE2AgRBlNAAIAQ2AgAgBSAENgIAIAEgBEEBcjYCBAwDC0EAIQALIAZFDQACQCABKAIcIgJBAnRBvNIAaiIDKAIAIAFGBEAgAyAANgIAIAANAUGQ0ABBkNAAKAIAQX4gAndxNgIADAILIAZBEEEUIAYoAhAgAUYbaiAANgIAIABFDQELIAAgBjYCGCABKAIQIgIEQCAAIAI2AhAgAiAANgIYCyABQRRqKAIAIgJFDQAgAEEUaiACNgIAIAIgADYCGAsgASAFTw0AIAUoAgQiAEEBcUUNAAJAAkACQAJAIABBAnFFBEBBpNAAKAIAIAVGBEBBpNAAIAE2AgBBmNAAQZjQACgCACAEaiIANgIAIAEgAEEBcjYCBCABQaDQACgCAEcNBkGU0ABBADYCAEGg0ABBADYCAAwGC0Gg0AAoAgAgBUYEQEGg0AAgATYCAEGU0ABBlNAAKAIAIARqIgA2AgAgASAAQQFyNgIEIAAgAWogADYCAAwGCyAAQXhxIARqIQQgAEH/AU0EQCAAQQN2IQMgBSgCCCIAIAUoAgwiAkYEQEGM0ABBjNAAKAIAQX4gA3dxNgIADAULIAIgADYCCCAAIAI2AgwMBAsgBSgCGCEGIAUgBSgCDCIARwRAQZzQACgCABogACAFKAIIIgI2AgggAiAANgIMDAMLIAVBFGoiAygCACICRQRAIAUoAhAiAkUNAiAFQRBqIQMLA0AgAyEHIAIiAEEUaiIDKAIAIgINACAAQRBqIQMgACgCECICDQALIAdBADYCAAwCCyAFIABBfnE2AgQgASAEaiAENgIAIAEgBEEBcjYCBAwDC0EAIQALIAZFDQACQCAFKAIcIgJBAnRBvNIAaiIDKAIAIAVGBEAgAyAANgIAIAANAUGQ0ABBkNAAKAIAQX4gAndxNgIADAILIAZBEEEUIAYoAhAgBUYbaiAANgIAIABFDQELIAAgBjYCGCAFKAIQIgIEQCAAIAI2AhAgAiAANgIYCyAFQRRqKAIAIgJFDQAgAEEUaiACNgIAIAIgADYCGAsgASAEaiAENgIAIAEgBEEBcjYCBCABQaDQACgCAEcNAEGU0AAgBDYCAAwBCyAEQf8BTQRAIARBeHFBtNAAaiEAAn9BjNAAKAIAIgJBASAEQQN2dCIDcUUEQEGM0AAgAiADcjYCACAADAELIAAoAggLIgIgATYCDCAAIAE2AgggASAANgIMIAEgAjYCCAwBC0EfIQIgBEH///8HTQRAIARBJiAEQQh2ZyIAa3ZBAXEgAEEBdGtBPmohAgsgASACNgIcIAFCADcCECACQQJ0QbzSAGohAAJAQZDQACgCACIDQQEgAnQiB3FFBEAgACABNgIAQZDQACADIAdyNgIAIAEgADYCGCABIAE2AgggASABNgIMDAELIARBGSACQQF2a0EAIAJBH0cbdCECIAAoAgAhAAJAA0AgACIDKAIEQXhxIARGDQEgAkEddiEAIAJBAXQhAiADIABBBHFqQRBqIgcoAgAiAA0ACyAHIAE2AgAgASADNgIYIAEgATYCDCABIAE2AggMAQsgAygCCCIAIAE2AgwgAyABNgIIIAFBADYCGCABIAM2AgwgASAANgIIC0Gs0ABBrNAAKAIAQQFrIgBBfyAAGzYCAAsLBwAgAC0AKAsHACAALQAqCwcAIAAtACsLBwAgAC0AKQsHACAALwEyCwcAIAAtAC4LQAEEfyAAKAIYIQEgAC0ALSECIAAtACghAyAAKAI4IQQgABAwIAAgBDYCOCAAIAM6ACggACACOgAtIAAgATYCGAu74gECB38DfiABIAJqIQQCQCAAIgIoAgwiAA0AIAIoAgQEQCACIAE2AgQLIwBBEGsiCCQAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACfwJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAIAIoAhwiA0EBaw7dAdoBAdkBAgMEBQYHCAkKCwwNDtgBDxDXARES1gETFBUWFxgZGhvgAd8BHB0e1QEfICEiIyQl1AEmJygpKiss0wHSAS0u0QHQAS8wMTIzNDU2Nzg5Ojs8PT4/QEFCQ0RFRtsBR0hJSs8BzgFLzQFMzAFNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3eHl6e3x9fn+AAYEBggGDAYQBhQGGAYcBiAGJAYoBiwGMAY0BjgGPAZABkQGSAZMBlAGVAZYBlwGYAZkBmgGbAZwBnQGeAZ8BoAGhAaIBowGkAaUBpgGnAagBqQGqAasBrAGtAa4BrwGwAbEBsgGzAbQBtQG2AbcBywHKAbgByQG5AcgBugG7AbwBvQG+Ab8BwAHBAcIBwwHEAcUBxgEA3AELQQAMxgELQQ4MxQELQQ0MxAELQQ8MwwELQRAMwgELQRMMwQELQRQMwAELQRUMvwELQRYMvgELQRgMvQELQRkMvAELQRoMuwELQRsMugELQRwMuQELQR0MuAELQQgMtwELQR4MtgELQSAMtQELQR8MtAELQQcMswELQSEMsgELQSIMsQELQSMMsAELQSQMrwELQRIMrgELQREMrQELQSUMrAELQSYMqwELQScMqgELQSgMqQELQcMBDKgBC0EqDKcBC0ErDKYBC0EsDKUBC0EtDKQBC0EuDKMBC0EvDKIBC0HEAQyhAQtBMAygAQtBNAyfAQtBDAyeAQtBMQydAQtBMgycAQtBMwybAQtBOQyaAQtBNQyZAQtBxQEMmAELQQsMlwELQToMlgELQTYMlQELQQoMlAELQTcMkwELQTgMkgELQTwMkQELQTsMkAELQT0MjwELQQkMjgELQSkMjQELQT4MjAELQT8MiwELQcAADIoBC0HBAAyJAQtBwgAMiAELQcMADIcBC0HEAAyGAQtBxQAMhQELQcYADIQBC0EXDIMBC0HHAAyCAQtByAAMgQELQckADIABC0HKAAx/C0HLAAx+C0HNAAx9C0HMAAx8C0HOAAx7C0HPAAx6C0HQAAx5C0HRAAx4C0HSAAx3C0HTAAx2C0HUAAx1C0HWAAx0C0HVAAxzC0EGDHILQdcADHELQQUMcAtB2AAMbwtBBAxuC0HZAAxtC0HaAAxsC0HbAAxrC0HcAAxqC0EDDGkLQd0ADGgLQd4ADGcLQd8ADGYLQeEADGULQeAADGQLQeIADGMLQeMADGILQQIMYQtB5AAMYAtB5QAMXwtB5gAMXgtB5wAMXQtB6AAMXAtB6QAMWwtB6gAMWgtB6wAMWQtB7AAMWAtB7QAMVwtB7gAMVgtB7wAMVQtB8AAMVAtB8QAMUwtB8gAMUgtB8wAMUQtB9AAMUAtB9QAMTwtB9gAMTgtB9wAMTQtB+AAMTAtB+QAMSwtB+gAMSgtB+wAMSQtB/AAMSAtB/QAMRwtB/gAMRgtB/wAMRQtBgAEMRAtBgQEMQwtBggEMQgtBgwEMQQtBhAEMQAtBhQEMPwtBhgEMPgtBhwEMPQtBiAEMPAtBiQEMOwtBigEMOgtBiwEMOQtBjAEMOAtBjQEMNwtBjgEMNgtBjwEMNQtBkAEMNAtBkQEMMwtBkgEMMgtBkwEMMQtBlAEMMAtBlQEMLwtBlgEMLgtBlwEMLQtBmAEMLAtBmQEMKwtBmgEMKgtBmwEMKQtBnAEMKAtBnQEMJwtBngEMJgtBnwEMJQtBoAEMJAtBoQEMIwtBogEMIgtBowEMIQtBpAEMIAtBpQEMHwtBpgEMHgtBpwEMHQtBqAEMHAtBqQEMGwtBqgEMGgtBqwEMGQtBrAEMGAtBrQEMFwtBrgEMFgtBAQwVC0GvAQwUC0GwAQwTC0GxAQwSC0GzAQwRC0GyAQwQC0G0AQwPC0G1AQwOC0G2AQwNC0G3AQwMC0G4AQwLC0G5AQwKC0G6AQwJC0G7AQwIC0HGAQwHC0G8AQwGC0G9AQwFC0G+AQwEC0G/AQwDC0HAAQwCC0HCAQwBC0HBAQshAwNAAkACQAJAAkACQAJAAkACQAJAIAICfwJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJ/AkACQAJAAkACQAJAAkACQAJAAkACQAJAAkAgAgJ/AkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACfwJAAkACfwJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACfwJAAkACQAJAAn8CQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQCADDsYBAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHyAhIyUmKCorLC8wMTIzNDU2Nzk6Ozw9lANAQkRFRklLTk9QUVJTVFVWWFpbXF1eX2BhYmNkZWZnaGpsb3Bxc3V2eHl6e3x/gAGBAYIBgwGEAYUBhgGHAYgBiQGKAYsBjAGNAY4BjwGQAZEBkgGTAZQBlQGWAZcBmAGZAZoBmwGcAZ0BngGfAaABoQGiAaMBpAGlAaYBpwGoAakBqgGrAawBrQGuAa8BsAGxAbIBswG0AbUBtgG3AbgBuQG6AbsBvAG9Ab4BvwHAAcEBwgHDAcQBxQHGAccByAHJAcsBzAHNAc4BzwGKA4kDiAOHA4QDgwOAA/sC+gL5AvgC9wL0AvMC8gLLAsECsALZAQsgASAERw3wAkHdASEDDLMDCyABIARHDcgBQcMBIQMMsgMLIAEgBEcNe0H3ACEDDLEDCyABIARHDXBB7wAhAwywAwsgASAERw1pQeoAIQMMrwMLIAEgBEcNZUHoACEDDK4DCyABIARHDWJB5gAhAwytAwsgASAERw0aQRghAwysAwsgASAERw0VQRIhAwyrAwsgASAERw1CQcUAIQMMqgMLIAEgBEcNNEE/IQMMqQMLIAEgBEcNMkE8IQMMqAMLIAEgBEcNK0ExIQMMpwMLIAItAC5BAUYNnwMMwQILQQAhAAJAAkACQCACLQAqRQ0AIAItACtFDQAgAi8BMCIDQQJxRQ0BDAILIAIvATAiA0EBcUUNAQtBASEAIAItAChBAUYNACACLwEyIgVB5ABrQeQASQ0AIAVBzAFGDQAgBUGwAkYNACADQcAAcQ0AQQAhACADQYgEcUGABEYNACADQShxQQBHIQALIAJBADsBMCACQQA6AC8gAEUN3wIgAkIANwMgDOACC0EAIQACQCACKAI4IgNFDQAgAygCLCIDRQ0AIAIgAxEAACEACyAARQ3MASAAQRVHDd0CIAJBBDYCHCACIAE2AhQgAkGwGDYCECACQRU2AgxBACEDDKQDCyABIARGBEBBBiEDDKQDCyABQQFqIQFBACEAAkAgAigCOCIDRQ0AIAMoAlQiA0UNACACIAMRAAAhAAsgAA3ZAgwcCyACQgA3AyBBEiEDDIkDCyABIARHDRZBHSEDDKEDCyABIARHBEAgAUEBaiEBQRAhAwyIAwtBByEDDKADCyACIAIpAyAiCiAEIAFrrSILfSIMQgAgCiAMWhs3AyAgCiALWA3UAkEIIQMMnwMLIAEgBEcEQCACQQk2AgggAiABNgIEQRQhAwyGAwtBCSEDDJ4DCyACKQMgQgBSDccBIAIgAi8BMEGAAXI7ATAMQgsgASAERw0/QdAAIQMMnAMLIAEgBEYEQEELIQMMnAMLIAFBAWohAUEAIQACQCACKAI4IgNFDQAgAygCUCIDRQ0AIAIgAxEAACEACyAADc8CDMYBC0EAIQACQCACKAI4IgNFDQAgAygCSCIDRQ0AIAIgAxEAACEACyAARQ3GASAAQRVHDc0CIAJBCzYCHCACIAE2AhQgAkGCGTYCECACQRU2AgxBACEDDJoDC0EAIQACQCACKAI4IgNFDQAgAygCSCIDRQ0AIAIgAxEAACEACyAARQ0MIABBFUcNygIgAkEaNgIcIAIgATYCFCACQYIZNgIQIAJBFTYCDEEAIQMMmQMLQQAhAAJAIAIoAjgiA0UNACADKAJMIgNFDQAgAiADEQAAIQALIABFDcQBIABBFUcNxwIgAkELNgIcIAIgATYCFCACQZEXNgIQIAJBFTYCDEEAIQMMmAMLIAEgBEYEQEEPIQMMmAMLIAEtAAAiAEE7Rg0HIABBDUcNxAIgAUEBaiEBDMMBC0EAIQACQCACKAI4IgNFDQAgAygCTCIDRQ0AIAIgAxEAACEACyAARQ3DASAAQRVHDcICIAJBDzYCHCACIAE2AhQgAkGRFzYCECACQRU2AgxBACEDDJYDCwNAIAEtAABB8DVqLQAAIgBBAUcEQCAAQQJHDcECIAIoAgQhAEEAIQMgAkEANgIEIAIgACABQQFqIgEQLSIADcICDMUBCyAEIAFBAWoiAUcNAAtBEiEDDJUDC0EAIQACQCACKAI4IgNFDQAgAygCTCIDRQ0AIAIgAxEAACEACyAARQ3FASAAQRVHDb0CIAJBGzYCHCACIAE2AhQgAkGRFzYCECACQRU2AgxBACEDDJQDCyABIARGBEBBFiEDDJQDCyACQQo2AgggAiABNgIEQQAhAAJAIAIoAjgiA0UNACADKAJIIgNFDQAgAiADEQAAIQALIABFDcIBIABBFUcNuQIgAkEVNgIcIAIgATYCFCACQYIZNgIQIAJBFTYCDEEAIQMMkwMLIAEgBEcEQANAIAEtAABB8DdqLQAAIgBBAkcEQAJAIABBAWsOBMQCvQIAvgK9AgsgAUEBaiEBQQghAwz8AgsgBCABQQFqIgFHDQALQRUhAwyTAwtBFSEDDJIDCwNAIAEtAABB8DlqLQAAIgBBAkcEQCAAQQFrDgTFArcCwwK4ArcCCyAEIAFBAWoiAUcNAAtBGCEDDJEDCyABIARHBEAgAkELNgIIIAIgATYCBEEHIQMM+AILQRkhAwyQAwsgAUEBaiEBDAILIAEgBEYEQEEaIQMMjwMLAkAgAS0AAEENaw4UtQG/Ab8BvwG/Ab8BvwG/Ab8BvwG/Ab8BvwG/Ab8BvwG/Ab8BvwEAvwELQQAhAyACQQA2AhwgAkGvCzYCECACQQI2AgwgAiABQQFqNgIUDI4DCyABIARGBEBBGyEDDI4DCyABLQAAIgBBO0cEQCAAQQ1HDbECIAFBAWohAQy6AQsgAUEBaiEBC0EiIQMM8wILIAEgBEYEQEEcIQMMjAMLQgAhCgJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkAgAS0AAEEwaw43wQLAAgABAgMEBQYH0AHQAdAB0AHQAdAB0AEICQoLDA3QAdAB0AHQAdAB0AHQAdAB0AHQAdAB0AHQAdAB0AHQAdAB0AHQAdAB0AHQAdAB0AHQAdABDg8QERIT0AELQgIhCgzAAgtCAyEKDL8CC0IEIQoMvgILQgUhCgy9AgtCBiEKDLwCC0IHIQoMuwILQgghCgy6AgtCCSEKDLkCC0IKIQoMuAILQgshCgy3AgtCDCEKDLYCC0INIQoMtQILQg4hCgy0AgtCDyEKDLMCC0IKIQoMsgILQgshCgyxAgtCDCEKDLACC0INIQoMrwILQg4hCgyuAgtCDyEKDK0CC0IAIQoCQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAIAEtAABBMGsON8ACvwIAAQIDBAUGB74CvgK+Ar4CvgK+Ar4CCAkKCwwNvgK+Ar4CvgK+Ar4CvgK+Ar4CvgK+Ar4CvgK+Ar4CvgK+Ar4CvgK+Ar4CvgK+Ar4CvgK+Ag4PEBESE74CC0ICIQoMvwILQgMhCgy+AgtCBCEKDL0CC0IFIQoMvAILQgYhCgy7AgtCByEKDLoCC0IIIQoMuQILQgkhCgy4AgtCCiEKDLcCC0ILIQoMtgILQgwhCgy1AgtCDSEKDLQCC0IOIQoMswILQg8hCgyyAgtCCiEKDLECC0ILIQoMsAILQgwhCgyvAgtCDSEKDK4CC0IOIQoMrQILQg8hCgysAgsgAiACKQMgIgogBCABa60iC30iDEIAIAogDFobNwMgIAogC1gNpwJBHyEDDIkDCyABIARHBEAgAkEJNgIIIAIgATYCBEElIQMM8AILQSAhAwyIAwtBASEFIAIvATAiA0EIcUUEQCACKQMgQgBSIQULAkAgAi0ALgRAQQEhACACLQApQQVGDQEgA0HAAHFFIAVxRQ0BC0EAIQAgA0HAAHENAEECIQAgA0EIcQ0AIANBgARxBEACQCACLQAoQQFHDQAgAi0ALUEKcQ0AQQUhAAwCC0EEIQAMAQsgA0EgcUUEQAJAIAItAChBAUYNACACLwEyIgBB5ABrQeQASQ0AIABBzAFGDQAgAEGwAkYNAEEEIQAgA0EocUUNAiADQYgEcUGABEYNAgtBACEADAELQQBBAyACKQMgUBshAAsgAEEBaw4FvgIAsAEBpAKhAgtBESEDDO0CCyACQQE6AC8MhAMLIAEgBEcNnQJBJCEDDIQDCyABIARHDRxBxgAhAwyDAwtBACEAAkAgAigCOCIDRQ0AIAMoAkQiA0UNACACIAMRAAAhAAsgAEUNJyAAQRVHDZgCIAJB0AA2AhwgAiABNgIUIAJBkRg2AhAgAkEVNgIMQQAhAwyCAwsgASAERgRAQSghAwyCAwtBACEDIAJBADYCBCACQQw2AgggAiABIAEQKiIARQ2UAiACQSc2AhwgAiABNgIUIAIgADYCDAyBAwsgASAERgRAQSkhAwyBAwsgAS0AACIAQSBGDRMgAEEJRw2VAiABQQFqIQEMFAsgASAERwRAIAFBAWohAQwWC0EqIQMM/wILIAEgBEYEQEErIQMM/wILIAEtAAAiAEEJRyAAQSBHcQ2QAiACLQAsQQhHDd0CIAJBADoALAzdAgsgASAERgRAQSwhAwz+AgsgAS0AAEEKRw2OAiABQQFqIQEMsAELIAEgBEcNigJBLyEDDPwCCwNAIAEtAAAiAEEgRwRAIABBCmsOBIQCiAKIAoQChgILIAQgAUEBaiIBRw0AC0ExIQMM+wILQTIhAyABIARGDfoCIAIoAgAiACAEIAFraiEHIAEgAGtBA2ohBgJAA0AgAEHwO2otAAAgAS0AACIFQSByIAUgBUHBAGtB/wFxQRpJG0H/AXFHDQEgAEEDRgRAQQYhAQziAgsgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAc2AgAM+wILIAJBADYCAAyGAgtBMyEDIAQgASIARg35AiAEIAFrIAIoAgAiAWohByAAIAFrQQhqIQYCQANAIAFB9DtqLQAAIAAtAAAiBUEgciAFIAVBwQBrQf8BcUEaSRtB/wFxRw0BIAFBCEYEQEEFIQEM4QILIAFBAWohASAEIABBAWoiAEcNAAsgAiAHNgIADPoCCyACQQA2AgAgACEBDIUCC0E0IQMgBCABIgBGDfgCIAQgAWsgAigCACIBaiEHIAAgAWtBBWohBgJAA0AgAUHQwgBqLQAAIAAtAAAiBUEgciAFIAVBwQBrQf8BcUEaSRtB/wFxRw0BIAFBBUYEQEEHIQEM4AILIAFBAWohASAEIABBAWoiAEcNAAsgAiAHNgIADPkCCyACQQA2AgAgACEBDIQCCyABIARHBEADQCABLQAAQYA+ai0AACIAQQFHBEAgAEECRg0JDIECCyAEIAFBAWoiAUcNAAtBMCEDDPgCC0EwIQMM9wILIAEgBEcEQANAIAEtAAAiAEEgRwRAIABBCmsOBP8B/gH+Af8B/gELIAQgAUEBaiIBRw0AC0E4IQMM9wILQTghAwz2AgsDQCABLQAAIgBBIEcgAEEJR3EN9gEgBCABQQFqIgFHDQALQTwhAwz1AgsDQCABLQAAIgBBIEcEQAJAIABBCmsOBPkBBAT5AQALIABBLEYN9QEMAwsgBCABQQFqIgFHDQALQT8hAwz0AgtBwAAhAyABIARGDfMCIAIoAgAiACAEIAFraiEFIAEgAGtBBmohBgJAA0AgAEGAQGstAAAgAS0AAEEgckcNASAAQQZGDdsCIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADPQCCyACQQA2AgALQTYhAwzZAgsgASAERgRAQcEAIQMM8gILIAJBDDYCCCACIAE2AgQgAi0ALEEBaw4E+wHuAewB6wHUAgsgAUEBaiEBDPoBCyABIARHBEADQAJAIAEtAAAiAEEgciAAIABBwQBrQf8BcUEaSRtB/wFxIgBBCUYNACAAQSBGDQACQAJAAkACQCAAQeMAaw4TAAMDAwMDAwMBAwMDAwMDAwMDAgMLIAFBAWohAUExIQMM3AILIAFBAWohAUEyIQMM2wILIAFBAWohAUEzIQMM2gILDP4BCyAEIAFBAWoiAUcNAAtBNSEDDPACC0E1IQMM7wILIAEgBEcEQANAIAEtAABBgDxqLQAAQQFHDfcBIAQgAUEBaiIBRw0AC0E9IQMM7wILQT0hAwzuAgtBACEAAkAgAigCOCIDRQ0AIAMoAkAiA0UNACACIAMRAAAhAAsgAEUNASAAQRVHDeYBIAJBwgA2AhwgAiABNgIUIAJB4xg2AhAgAkEVNgIMQQAhAwztAgsgAUEBaiEBC0E8IQMM0gILIAEgBEYEQEHCACEDDOsCCwJAA0ACQCABLQAAQQlrDhgAAswCzALRAswCzALMAswCzALMAswCzALMAswCzALMAswCzALMAswCzALMAgDMAgsgBCABQQFqIgFHDQALQcIAIQMM6wILIAFBAWohASACLQAtQQFxRQ3+AQtBLCEDDNACCyABIARHDd4BQcQAIQMM6AILA0AgAS0AAEGQwABqLQAAQQFHDZwBIAQgAUEBaiIBRw0AC0HFACEDDOcCCyABLQAAIgBBIEYN/gEgAEE6Rw3AAiACKAIEIQBBACEDIAJBADYCBCACIAAgARApIgAN3gEM3QELQccAIQMgBCABIgBGDeUCIAQgAWsgAigCACIBaiEHIAAgAWtBBWohBgNAIAFBkMIAai0AACAALQAAIgVBIHIgBSAFQcEAa0H/AXFBGkkbQf8BcUcNvwIgAUEFRg3CAiABQQFqIQEgBCAAQQFqIgBHDQALIAIgBzYCAAzlAgtByAAhAyAEIAEiAEYN5AIgBCABayACKAIAIgFqIQcgACABa0EJaiEGA0AgAUGWwgBqLQAAIAAtAAAiBUEgciAFIAVBwQBrQf8BcUEaSRtB/wFxRw2+AkECIAFBCUYNwgIaIAFBAWohASAEIABBAWoiAEcNAAsgAiAHNgIADOQCCyABIARGBEBByQAhAwzkAgsCQAJAIAEtAAAiAEEgciAAIABBwQBrQf8BcUEaSRtB/wFxQe4Aaw4HAL8CvwK/Ar8CvwIBvwILIAFBAWohAUE+IQMMywILIAFBAWohAUE/IQMMygILQcoAIQMgBCABIgBGDeICIAQgAWsgAigCACIBaiEGIAAgAWtBAWohBwNAIAFBoMIAai0AACAALQAAIgVBIHIgBSAFQcEAa0H/AXFBGkkbQf8BcUcNvAIgAUEBRg2+AiABQQFqIQEgBCAAQQFqIgBHDQALIAIgBjYCAAziAgtBywAhAyAEIAEiAEYN4QIgBCABayACKAIAIgFqIQcgACABa0EOaiEGA0AgAUGiwgBqLQAAIAAtAAAiBUEgciAFIAVBwQBrQf8BcUEaSRtB/wFxRw27AiABQQ5GDb4CIAFBAWohASAEIABBAWoiAEcNAAsgAiAHNgIADOECC0HMACEDIAQgASIARg3gAiAEIAFrIAIoAgAiAWohByAAIAFrQQ9qIQYDQCABQcDCAGotAAAgAC0AACIFQSByIAUgBUHBAGtB/wFxQRpJG0H/AXFHDboCQQMgAUEPRg2+AhogAUEBaiEBIAQgAEEBaiIARw0ACyACIAc2AgAM4AILQc0AIQMgBCABIgBGDd8CIAQgAWsgAigCACIBaiEHIAAgAWtBBWohBgNAIAFB0MIAai0AACAALQAAIgVBIHIgBSAFQcEAa0H/AXFBGkkbQf8BcUcNuQJBBCABQQVGDb0CGiABQQFqIQEgBCAAQQFqIgBHDQALIAIgBzYCAAzfAgsgASAERgRAQc4AIQMM3wILAkACQAJAAkAgAS0AACIAQSByIAAgAEHBAGtB/wFxQRpJG0H/AXFB4wBrDhMAvAK8ArwCvAK8ArwCvAK8ArwCvAK8ArwCAbwCvAK8AgIDvAILIAFBAWohAUHBACEDDMgCCyABQQFqIQFBwgAhAwzHAgsgAUEBaiEBQcMAIQMMxgILIAFBAWohAUHEACEDDMUCCyABIARHBEAgAkENNgIIIAIgATYCBEHFACEDDMUCC0HPACEDDN0CCwJAAkAgAS0AAEEKaw4EAZABkAEAkAELIAFBAWohAQtBKCEDDMMCCyABIARGBEBB0QAhAwzcAgsgAS0AAEEgRw0AIAFBAWohASACLQAtQQFxRQ3QAQtBFyEDDMECCyABIARHDcsBQdIAIQMM2QILQdMAIQMgASAERg3YAiACKAIAIgAgBCABa2ohBiABIABrQQFqIQUDQCABLQAAIABB1sIAai0AAEcNxwEgAEEBRg3KASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBjYCAAzYAgsgASAERgRAQdUAIQMM2AILIAEtAABBCkcNwgEgAUEBaiEBDMoBCyABIARGBEBB1gAhAwzXAgsCQAJAIAEtAABBCmsOBADDAcMBAcMBCyABQQFqIQEMygELIAFBAWohAUHKACEDDL0CC0EAIQACQCACKAI4IgNFDQAgAygCPCIDRQ0AIAIgAxEAACEACyAADb8BQc0AIQMMvAILIAItAClBIkYNzwIMiQELIAQgASIFRgRAQdsAIQMM1AILQQAhAEEBIQFBASEGQQAhAwJAAn8CQAJAAkACQAJAAkACQCAFLQAAQTBrDgrFAcQBAAECAwQFBgjDAQtBAgwGC0EDDAULQQQMBAtBBQwDC0EGDAILQQcMAQtBCAshA0EAIQFBACEGDL0BC0EJIQNBASEAQQAhAUEAIQYMvAELIAEgBEYEQEHdACEDDNMCCyABLQAAQS5HDbgBIAFBAWohAQyIAQsgASAERw22AUHfACEDDNECCyABIARHBEAgAkEONgIIIAIgATYCBEHQACEDDLgCC0HgACEDDNACC0HhACEDIAEgBEYNzwIgAigCACIAIAQgAWtqIQUgASAAa0EDaiEGA0AgAS0AACAAQeLCAGotAABHDbEBIABBA0YNswEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMzwILQeIAIQMgASAERg3OAiACKAIAIgAgBCABa2ohBSABIABrQQJqIQYDQCABLQAAIABB5sIAai0AAEcNsAEgAEECRg2vASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAzOAgtB4wAhAyABIARGDc0CIAIoAgAiACAEIAFraiEFIAEgAGtBA2ohBgNAIAEtAAAgAEHpwgBqLQAARw2vASAAQQNGDa0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADM0CCyABIARGBEBB5QAhAwzNAgsgAUEBaiEBQQAhAAJAIAIoAjgiA0UNACADKAIwIgNFDQAgAiADEQAAIQALIAANqgFB1gAhAwyzAgsgASAERwRAA0AgAS0AACIAQSBHBEACQAJAAkAgAEHIAGsOCwABswGzAbMBswGzAbMBswGzAQKzAQsgAUEBaiEBQdIAIQMMtwILIAFBAWohAUHTACEDDLYCCyABQQFqIQFB1AAhAwy1AgsgBCABQQFqIgFHDQALQeQAIQMMzAILQeQAIQMMywILA0AgAS0AAEHwwgBqLQAAIgBBAUcEQCAAQQJrDgOnAaYBpQGkAQsgBCABQQFqIgFHDQALQeYAIQMMygILIAFBAWogASAERw0CGkHnACEDDMkCCwNAIAEtAABB8MQAai0AACIAQQFHBEACQCAAQQJrDgSiAaEBoAEAnwELQdcAIQMMsQILIAQgAUEBaiIBRw0AC0HoACEDDMgCCyABIARGBEBB6QAhAwzIAgsCQCABLQAAIgBBCmsOGrcBmwGbAbQBmwGbAZsBmwGbAZsBmwGbAZsBmwGbAZsBmwGbAZsBmwGbAZsBpAGbAZsBAJkBCyABQQFqCyEBQQYhAwytAgsDQCABLQAAQfDGAGotAABBAUcNfSAEIAFBAWoiAUcNAAtB6gAhAwzFAgsgAUEBaiABIARHDQIaQesAIQMMxAILIAEgBEYEQEHsACEDDMQCCyABQQFqDAELIAEgBEYEQEHtACEDDMMCCyABQQFqCyEBQQQhAwyoAgsgASAERgRAQe4AIQMMwQILAkACQAJAIAEtAABB8MgAai0AAEEBaw4HkAGPAY4BAHwBAo0BCyABQQFqIQEMCwsgAUEBagyTAQtBACEDIAJBADYCHCACQZsSNgIQIAJBBzYCDCACIAFBAWo2AhQMwAILAkADQCABLQAAQfDIAGotAAAiAEEERwRAAkACQCAAQQFrDgeUAZMBkgGNAQAEAY0BC0HaACEDDKoCCyABQQFqIQFB3AAhAwypAgsgBCABQQFqIgFHDQALQe8AIQMMwAILIAFBAWoMkQELIAQgASIARgRAQfAAIQMMvwILIAAtAABBL0cNASAAQQFqIQEMBwsgBCABIgBGBEBB8QAhAwy+AgsgAC0AACIBQS9GBEAgAEEBaiEBQd0AIQMMpQILIAFBCmsiA0EWSw0AIAAhAUEBIAN0QYmAgAJxDfkBC0EAIQMgAkEANgIcIAIgADYCFCACQYwcNgIQIAJBBzYCDAy8AgsgASAERwRAIAFBAWohAUHeACEDDKMCC0HyACEDDLsCCyABIARGBEBB9AAhAwy7AgsCQCABLQAAQfDMAGotAABBAWsOA/cBcwCCAQtB4QAhAwyhAgsgASAERwRAA0AgAS0AAEHwygBqLQAAIgBBA0cEQAJAIABBAWsOAvkBAIUBC0HfACEDDKMCCyAEIAFBAWoiAUcNAAtB8wAhAwy6AgtB8wAhAwy5AgsgASAERwRAIAJBDzYCCCACIAE2AgRB4AAhAwygAgtB9QAhAwy4AgsgASAERgRAQfYAIQMMuAILIAJBDzYCCCACIAE2AgQLQQMhAwydAgsDQCABLQAAQSBHDY4CIAQgAUEBaiIBRw0AC0H3ACEDDLUCCyABIARGBEBB+AAhAwy1AgsgAS0AAEEgRw16IAFBAWohAQxbC0EAIQACQCACKAI4IgNFDQAgAygCOCIDRQ0AIAIgAxEAACEACyAADXgMgAILIAEgBEYEQEH6ACEDDLMCCyABLQAAQcwARw10IAFBAWohAUETDHYLQfsAIQMgASAERg2xAiACKAIAIgAgBCABa2ohBSABIABrQQVqIQYDQCABLQAAIABB8M4Aai0AAEcNcyAAQQVGDXUgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMsQILIAEgBEYEQEH8ACEDDLECCwJAAkAgAS0AAEHDAGsODAB0dHR0dHR0dHR0AXQLIAFBAWohAUHmACEDDJgCCyABQQFqIQFB5wAhAwyXAgtB/QAhAyABIARGDa8CIAIoAgAiACAEIAFraiEFIAEgAGtBAmohBgJAA0AgAS0AACAAQe3PAGotAABHDXIgAEECRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADLACCyACQQA2AgAgBkEBaiEBQRAMcwtB/gAhAyABIARGDa4CIAIoAgAiACAEIAFraiEFIAEgAGtBBWohBgJAA0AgAS0AACAAQfbOAGotAABHDXEgAEEFRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADK8CCyACQQA2AgAgBkEBaiEBQRYMcgtB/wAhAyABIARGDa0CIAIoAgAiACAEIAFraiEFIAEgAGtBA2ohBgJAA0AgAS0AACAAQfzOAGotAABHDXAgAEEDRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADK4CCyACQQA2AgAgBkEBaiEBQQUMcQsgASAERgRAQYABIQMMrQILIAEtAABB2QBHDW4gAUEBaiEBQQgMcAsgASAERgRAQYEBIQMMrAILAkACQCABLQAAQc4Aaw4DAG8BbwsgAUEBaiEBQesAIQMMkwILIAFBAWohAUHsACEDDJICCyABIARGBEBBggEhAwyrAgsCQAJAIAEtAABByABrDggAbm5ubm5uAW4LIAFBAWohAUHqACEDDJICCyABQQFqIQFB7QAhAwyRAgtBgwEhAyABIARGDakCIAIoAgAiACAEIAFraiEFIAEgAGtBAmohBgJAA0AgAS0AACAAQYDPAGotAABHDWwgAEECRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADKoCCyACQQA2AgAgBkEBaiEBQQAMbQtBhAEhAyABIARGDagCIAIoAgAiACAEIAFraiEFIAEgAGtBBGohBgJAA0AgAS0AACAAQYPPAGotAABHDWsgAEEERg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADKkCCyACQQA2AgAgBkEBaiEBQSMMbAsgASAERgRAQYUBIQMMqAILAkACQCABLQAAQcwAaw4IAGtra2trawFrCyABQQFqIQFB7wAhAwyPAgsgAUEBaiEBQfAAIQMMjgILIAEgBEYEQEGGASEDDKcCCyABLQAAQcUARw1oIAFBAWohAQxgC0GHASEDIAEgBEYNpQIgAigCACIAIAQgAWtqIQUgASAAa0EDaiEGAkADQCABLQAAIABBiM8Aai0AAEcNaCAAQQNGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMpgILIAJBADYCACAGQQFqIQFBLQxpC0GIASEDIAEgBEYNpAIgAigCACIAIAQgAWtqIQUgASAAa0EIaiEGAkADQCABLQAAIABB0M8Aai0AAEcNZyAAQQhGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMpQILIAJBADYCACAGQQFqIQFBKQxoCyABIARGBEBBiQEhAwykAgtBASABLQAAQd8ARw1nGiABQQFqIQEMXgtBigEhAyABIARGDaICIAIoAgAiACAEIAFraiEFIAEgAGtBAWohBgNAIAEtAAAgAEGMzwBqLQAARw1kIABBAUYN+gEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMogILQYsBIQMgASAERg2hAiACKAIAIgAgBCABa2ohBSABIABrQQJqIQYCQANAIAEtAAAgAEGOzwBqLQAARw1kIABBAkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyiAgsgAkEANgIAIAZBAWohAUECDGULQYwBIQMgASAERg2gAiACKAIAIgAgBCABa2ohBSABIABrQQFqIQYCQANAIAEtAAAgAEHwzwBqLQAARw1jIABBAUYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyhAgsgAkEANgIAIAZBAWohAUEfDGQLQY0BIQMgASAERg2fAiACKAIAIgAgBCABa2ohBSABIABrQQFqIQYCQANAIAEtAAAgAEHyzwBqLQAARw1iIABBAUYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAygAgsgAkEANgIAIAZBAWohAUEJDGMLIAEgBEYEQEGOASEDDJ8CCwJAAkAgAS0AAEHJAGsOBwBiYmJiYgFiCyABQQFqIQFB+AAhAwyGAgsgAUEBaiEBQfkAIQMMhQILQY8BIQMgASAERg2dAiACKAIAIgAgBCABa2ohBSABIABrQQVqIQYCQANAIAEtAAAgAEGRzwBqLQAARw1gIABBBUYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyeAgsgAkEANgIAIAZBAWohAUEYDGELQZABIQMgASAERg2cAiACKAIAIgAgBCABa2ohBSABIABrQQJqIQYCQANAIAEtAAAgAEGXzwBqLQAARw1fIABBAkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAydAgsgAkEANgIAIAZBAWohAUEXDGALQZEBIQMgASAERg2bAiACKAIAIgAgBCABa2ohBSABIABrQQZqIQYCQANAIAEtAAAgAEGazwBqLQAARw1eIABBBkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAycAgsgAkEANgIAIAZBAWohAUEVDF8LQZIBIQMgASAERg2aAiACKAIAIgAgBCABa2ohBSABIABrQQVqIQYCQANAIAEtAAAgAEGhzwBqLQAARw1dIABBBUYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAybAgsgAkEANgIAIAZBAWohAUEeDF4LIAEgBEYEQEGTASEDDJoCCyABLQAAQcwARw1bIAFBAWohAUEKDF0LIAEgBEYEQEGUASEDDJkCCwJAAkAgAS0AAEHBAGsODwBcXFxcXFxcXFxcXFxcAVwLIAFBAWohAUH+ACEDDIACCyABQQFqIQFB/wAhAwz/AQsgASAERgRAQZUBIQMMmAILAkACQCABLQAAQcEAaw4DAFsBWwsgAUEBaiEBQf0AIQMM/wELIAFBAWohAUGAASEDDP4BC0GWASEDIAEgBEYNlgIgAigCACIAIAQgAWtqIQUgASAAa0EBaiEGAkADQCABLQAAIABBp88Aai0AAEcNWSAAQQFGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMlwILIAJBADYCACAGQQFqIQFBCwxaCyABIARGBEBBlwEhAwyWAgsCQAJAAkACQCABLQAAQS1rDiMAW1tbW1tbW1tbW1tbW1tbW1tbW1tbW1sBW1tbW1sCW1tbA1sLIAFBAWohAUH7ACEDDP8BCyABQQFqIQFB/AAhAwz+AQsgAUEBaiEBQYEBIQMM/QELIAFBAWohAUGCASEDDPwBC0GYASEDIAEgBEYNlAIgAigCACIAIAQgAWtqIQUgASAAa0EEaiEGAkADQCABLQAAIABBqc8Aai0AAEcNVyAAQQRGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMlQILIAJBADYCACAGQQFqIQFBGQxYC0GZASEDIAEgBEYNkwIgAigCACIAIAQgAWtqIQUgASAAa0EFaiEGAkADQCABLQAAIABBrs8Aai0AAEcNViAAQQVGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMlAILIAJBADYCACAGQQFqIQFBBgxXC0GaASEDIAEgBEYNkgIgAigCACIAIAQgAWtqIQUgASAAa0EBaiEGAkADQCABLQAAIABBtM8Aai0AAEcNVSAAQQFGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMkwILIAJBADYCACAGQQFqIQFBHAxWC0GbASEDIAEgBEYNkQIgAigCACIAIAQgAWtqIQUgASAAa0EBaiEGAkADQCABLQAAIABBts8Aai0AAEcNVCAAQQFGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAMkgILIAJBADYCACAGQQFqIQFBJwxVCyABIARGBEBBnAEhAwyRAgsCQAJAIAEtAABB1ABrDgIAAVQLIAFBAWohAUGGASEDDPgBCyABQQFqIQFBhwEhAwz3AQtBnQEhAyABIARGDY8CIAIoAgAiACAEIAFraiEFIAEgAGtBAWohBgJAA0AgAS0AACAAQbjPAGotAABHDVIgAEEBRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADJACCyACQQA2AgAgBkEBaiEBQSYMUwtBngEhAyABIARGDY4CIAIoAgAiACAEIAFraiEFIAEgAGtBAWohBgJAA0AgAS0AACAAQbrPAGotAABHDVEgAEEBRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADI8CCyACQQA2AgAgBkEBaiEBQQMMUgtBnwEhAyABIARGDY0CIAIoAgAiACAEIAFraiEFIAEgAGtBAmohBgJAA0AgAS0AACAAQe3PAGotAABHDVAgAEECRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADI4CCyACQQA2AgAgBkEBaiEBQQwMUQtBoAEhAyABIARGDYwCIAIoAgAiACAEIAFraiEFIAEgAGtBA2ohBgJAA0AgAS0AACAAQbzPAGotAABHDU8gAEEDRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADI0CCyACQQA2AgAgBkEBaiEBQQ0MUAsgASAERgRAQaEBIQMMjAILAkACQCABLQAAQcYAaw4LAE9PT09PT09PTwFPCyABQQFqIQFBiwEhAwzzAQsgAUEBaiEBQYwBIQMM8gELIAEgBEYEQEGiASEDDIsCCyABLQAAQdAARw1MIAFBAWohAQxGCyABIARGBEBBowEhAwyKAgsCQAJAIAEtAABByQBrDgcBTU1NTU0ATQsgAUEBaiEBQY4BIQMM8QELIAFBAWohAUEiDE0LQaQBIQMgASAERg2IAiACKAIAIgAgBCABa2ohBSABIABrQQFqIQYCQANAIAEtAAAgAEHAzwBqLQAARw1LIABBAUYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyJAgsgAkEANgIAIAZBAWohAUEdDEwLIAEgBEYEQEGlASEDDIgCCwJAAkAgAS0AAEHSAGsOAwBLAUsLIAFBAWohAUGQASEDDO8BCyABQQFqIQFBBAxLCyABIARGBEBBpgEhAwyHAgsCQAJAAkACQAJAIAEtAABBwQBrDhUATU1NTU1NTU1NTQFNTQJNTQNNTQRNCyABQQFqIQFBiAEhAwzxAQsgAUEBaiEBQYkBIQMM8AELIAFBAWohAUGKASEDDO8BCyABQQFqIQFBjwEhAwzuAQsgAUEBaiEBQZEBIQMM7QELQacBIQMgASAERg2FAiACKAIAIgAgBCABa2ohBSABIABrQQJqIQYCQANAIAEtAAAgAEHtzwBqLQAARw1IIABBAkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyGAgsgAkEANgIAIAZBAWohAUERDEkLQagBIQMgASAERg2EAiACKAIAIgAgBCABa2ohBSABIABrQQJqIQYCQANAIAEtAAAgAEHCzwBqLQAARw1HIABBAkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyFAgsgAkEANgIAIAZBAWohAUEsDEgLQakBIQMgASAERg2DAiACKAIAIgAgBCABa2ohBSABIABrQQRqIQYCQANAIAEtAAAgAEHFzwBqLQAARw1GIABBBEYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyEAgsgAkEANgIAIAZBAWohAUErDEcLQaoBIQMgASAERg2CAiACKAIAIgAgBCABa2ohBSABIABrQQJqIQYCQANAIAEtAAAgAEHKzwBqLQAARw1FIABBAkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyDAgsgAkEANgIAIAZBAWohAUEUDEYLIAEgBEYEQEGrASEDDIICCwJAAkACQAJAIAEtAABBwgBrDg8AAQJHR0dHR0dHR0dHRwNHCyABQQFqIQFBkwEhAwzrAQsgAUEBaiEBQZQBIQMM6gELIAFBAWohAUGVASEDDOkBCyABQQFqIQFBlgEhAwzoAQsgASAERgRAQawBIQMMgQILIAEtAABBxQBHDUIgAUEBaiEBDD0LQa0BIQMgASAERg3/ASACKAIAIgAgBCABa2ohBSABIABrQQJqIQYCQANAIAEtAAAgAEHNzwBqLQAARw1CIABBAkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAyAAgsgAkEANgIAIAZBAWohAUEODEMLIAEgBEYEQEGuASEDDP8BCyABLQAAQdAARw1AIAFBAWohAUElDEILQa8BIQMgASAERg39ASACKAIAIgAgBCABa2ohBSABIABrQQhqIQYCQANAIAEtAAAgAEHQzwBqLQAARw1AIABBCEYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAz+AQsgAkEANgIAIAZBAWohAUEqDEELIAEgBEYEQEGwASEDDP0BCwJAAkAgAS0AAEHVAGsOCwBAQEBAQEBAQEABQAsgAUEBaiEBQZoBIQMM5AELIAFBAWohAUGbASEDDOMBCyABIARGBEBBsQEhAwz8AQsCQAJAIAEtAABBwQBrDhQAPz8/Pz8/Pz8/Pz8/Pz8/Pz8/AT8LIAFBAWohAUGZASEDDOMBCyABQQFqIQFBnAEhAwziAQtBsgEhAyABIARGDfoBIAIoAgAiACAEIAFraiEFIAEgAGtBA2ohBgJAA0AgAS0AACAAQdnPAGotAABHDT0gAEEDRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADPsBCyACQQA2AgAgBkEBaiEBQSEMPgtBswEhAyABIARGDfkBIAIoAgAiACAEIAFraiEFIAEgAGtBBmohBgJAA0AgAS0AACAAQd3PAGotAABHDTwgAEEGRg0BIABBAWohACAEIAFBAWoiAUcNAAsgAiAFNgIADPoBCyACQQA2AgAgBkEBaiEBQRoMPQsgASAERgRAQbQBIQMM+QELAkACQAJAIAEtAABBxQBrDhEAPT09PT09PT09AT09PT09Aj0LIAFBAWohAUGdASEDDOEBCyABQQFqIQFBngEhAwzgAQsgAUEBaiEBQZ8BIQMM3wELQbUBIQMgASAERg33ASACKAIAIgAgBCABa2ohBSABIABrQQVqIQYCQANAIAEtAAAgAEHkzwBqLQAARw06IABBBUYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAz4AQsgAkEANgIAIAZBAWohAUEoDDsLQbYBIQMgASAERg32ASACKAIAIgAgBCABa2ohBSABIABrQQJqIQYCQANAIAEtAAAgAEHqzwBqLQAARw05IABBAkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAz3AQsgAkEANgIAIAZBAWohAUEHDDoLIAEgBEYEQEG3ASEDDPYBCwJAAkAgAS0AAEHFAGsODgA5OTk5OTk5OTk5OTkBOQsgAUEBaiEBQaEBIQMM3QELIAFBAWohAUGiASEDDNwBC0G4ASEDIAEgBEYN9AEgAigCACIAIAQgAWtqIQUgASAAa0ECaiEGAkADQCABLQAAIABB7c8Aai0AAEcNNyAAQQJGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAM9QELIAJBADYCACAGQQFqIQFBEgw4C0G5ASEDIAEgBEYN8wEgAigCACIAIAQgAWtqIQUgASAAa0EBaiEGAkADQCABLQAAIABB8M8Aai0AAEcNNiAAQQFGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAM9AELIAJBADYCACAGQQFqIQFBIAw3C0G6ASEDIAEgBEYN8gEgAigCACIAIAQgAWtqIQUgASAAa0EBaiEGAkADQCABLQAAIABB8s8Aai0AAEcNNSAAQQFGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAM8wELIAJBADYCACAGQQFqIQFBDww2CyABIARGBEBBuwEhAwzyAQsCQAJAIAEtAABByQBrDgcANTU1NTUBNQsgAUEBaiEBQaUBIQMM2QELIAFBAWohAUGmASEDDNgBC0G8ASEDIAEgBEYN8AEgAigCACIAIAQgAWtqIQUgASAAa0EHaiEGAkADQCABLQAAIABB9M8Aai0AAEcNMyAAQQdGDQEgAEEBaiEAIAQgAUEBaiIBRw0ACyACIAU2AgAM8QELIAJBADYCACAGQQFqIQFBGww0CyABIARGBEBBvQEhAwzwAQsCQAJAAkAgAS0AAEHCAGsOEgA0NDQ0NDQ0NDQBNDQ0NDQ0AjQLIAFBAWohAUGkASEDDNgBCyABQQFqIQFBpwEhAwzXAQsgAUEBaiEBQagBIQMM1gELIAEgBEYEQEG+ASEDDO8BCyABLQAAQc4ARw0wIAFBAWohAQwsCyABIARGBEBBvwEhAwzuAQsCQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQCABLQAAQcEAaw4VAAECAz8EBQY/Pz8HCAkKCz8MDQ4PPwsgAUEBaiEBQegAIQMM4wELIAFBAWohAUHpACEDDOIBCyABQQFqIQFB7gAhAwzhAQsgAUEBaiEBQfIAIQMM4AELIAFBAWohAUHzACEDDN8BCyABQQFqIQFB9gAhAwzeAQsgAUEBaiEBQfcAIQMM3QELIAFBAWohAUH6ACEDDNwBCyABQQFqIQFBgwEhAwzbAQsgAUEBaiEBQYQBIQMM2gELIAFBAWohAUGFASEDDNkBCyABQQFqIQFBkgEhAwzYAQsgAUEBaiEBQZgBIQMM1wELIAFBAWohAUGgASEDDNYBCyABQQFqIQFBowEhAwzVAQsgAUEBaiEBQaoBIQMM1AELIAEgBEcEQCACQRA2AgggAiABNgIEQasBIQMM1AELQcABIQMM7AELQQAhAAJAIAIoAjgiA0UNACADKAI0IgNFDQAgAiADEQAAIQALIABFDV4gAEEVRw0HIAJB0QA2AhwgAiABNgIUIAJBsBc2AhAgAkEVNgIMQQAhAwzrAQsgAUEBaiABIARHDQgaQcIBIQMM6gELA0ACQCABLQAAQQprDgQIAAALAAsgBCABQQFqIgFHDQALQcMBIQMM6QELIAEgBEcEQCACQRE2AgggAiABNgIEQQEhAwzQAQtBxAEhAwzoAQsgASAERgRAQcUBIQMM6AELAkACQCABLQAAQQprDgQBKCgAKAsgAUEBagwJCyABQQFqDAULIAEgBEYEQEHGASEDDOcBCwJAAkAgAS0AAEEKaw4XAQsLAQsLCwsLCwsLCwsLCwsLCwsLCwALCyABQQFqIQELQbABIQMMzQELIAEgBEYEQEHIASEDDOYBCyABLQAAQSBHDQkgAkEAOwEyIAFBAWohAUGzASEDDMwBCwNAIAEhAAJAIAEgBEcEQCABLQAAQTBrQf8BcSIDQQpJDQEMJwtBxwEhAwzmAQsCQCACLwEyIgFBmTNLDQAgAiABQQpsIgU7ATIgBUH+/wNxIANB//8Dc0sNACAAQQFqIQEgAiADIAVqIgM7ATIgA0H//wNxQegHSQ0BCwtBACEDIAJBADYCHCACQcEJNgIQIAJBDTYCDCACIABBAWo2AhQM5AELIAJBADYCHCACIAE2AhQgAkHwDDYCECACQRs2AgxBACEDDOMBCyACKAIEIQAgAkEANgIEIAIgACABECYiAA0BIAFBAWoLIQFBrQEhAwzIAQsgAkHBATYCHCACIAA2AgwgAiABQQFqNgIUQQAhAwzgAQsgAigCBCEAIAJBADYCBCACIAAgARAmIgANASABQQFqCyEBQa4BIQMMxQELIAJBwgE2AhwgAiAANgIMIAIgAUEBajYCFEEAIQMM3QELIAJBADYCHCACIAE2AhQgAkGXCzYCECACQQ02AgxBACEDDNwBCyACQQA2AhwgAiABNgIUIAJB4xA2AhAgAkEJNgIMQQAhAwzbAQsgAkECOgAoDKwBC0EAIQMgAkEANgIcIAJBrws2AhAgAkECNgIMIAIgAUEBajYCFAzZAQtBAiEDDL8BC0ENIQMMvgELQSYhAwy9AQtBFSEDDLwBC0EWIQMMuwELQRghAwy6AQtBHCEDDLkBC0EdIQMMuAELQSAhAwy3AQtBISEDDLYBC0EjIQMMtQELQcYAIQMMtAELQS4hAwyzAQtBPSEDDLIBC0HLACEDDLEBC0HOACEDDLABC0HYACEDDK8BC0HZACEDDK4BC0HbACEDDK0BC0HxACEDDKwBC0H0ACEDDKsBC0GNASEDDKoBC0GXASEDDKkBC0GpASEDDKgBC0GvASEDDKcBC0GxASEDDKYBCyACQQA2AgALQQAhAyACQQA2AhwgAiABNgIUIAJB8Rs2AhAgAkEGNgIMDL0BCyACQQA2AgAgBkEBaiEBQSQLOgApIAIoAgQhACACQQA2AgQgAiAAIAEQJyIARQRAQeUAIQMMowELIAJB+QA2AhwgAiABNgIUIAIgADYCDEEAIQMMuwELIABBFUcEQCACQQA2AhwgAiABNgIUIAJBzA42AhAgAkEgNgIMQQAhAwy7AQsgAkH4ADYCHCACIAE2AhQgAkHKGDYCECACQRU2AgxBACEDDLoBCyACQQA2AhwgAiABNgIUIAJBjhs2AhAgAkEGNgIMQQAhAwy5AQsgAkEANgIcIAIgATYCFCACQf4RNgIQIAJBBzYCDEEAIQMMuAELIAJBADYCHCACIAE2AhQgAkGMHDYCECACQQc2AgxBACEDDLcBCyACQQA2AhwgAiABNgIUIAJBww82AhAgAkEHNgIMQQAhAwy2AQsgAkEANgIcIAIgATYCFCACQcMPNgIQIAJBBzYCDEEAIQMMtQELIAIoAgQhACACQQA2AgQgAiAAIAEQJSIARQ0RIAJB5QA2AhwgAiABNgIUIAIgADYCDEEAIQMMtAELIAIoAgQhACACQQA2AgQgAiAAIAEQJSIARQ0gIAJB0wA2AhwgAiABNgIUIAIgADYCDEEAIQMMswELIAIoAgQhACACQQA2AgQgAiAAIAEQJSIARQ0iIAJB0gA2AhwgAiABNgIUIAIgADYCDEEAIQMMsgELIAIoAgQhACACQQA2AgQgAiAAIAEQJSIARQ0OIAJB5QA2AhwgAiABNgIUIAIgADYCDEEAIQMMsQELIAIoAgQhACACQQA2AgQgAiAAIAEQJSIARQ0dIAJB0wA2AhwgAiABNgIUIAIgADYCDEEAIQMMsAELIAIoAgQhACACQQA2AgQgAiAAIAEQJSIARQ0fIAJB0gA2AhwgAiABNgIUIAIgADYCDEEAIQMMrwELIABBP0cNASABQQFqCyEBQQUhAwyUAQtBACEDIAJBADYCHCACIAE2AhQgAkH9EjYCECACQQc2AgwMrAELIAJBADYCHCACIAE2AhQgAkHcCDYCECACQQc2AgxBACEDDKsBCyACKAIEIQAgAkEANgIEIAIgACABECUiAEUNByACQeUANgIcIAIgATYCFCACIAA2AgxBACEDDKoBCyACKAIEIQAgAkEANgIEIAIgACABECUiAEUNFiACQdMANgIcIAIgATYCFCACIAA2AgxBACEDDKkBCyACKAIEIQAgAkEANgIEIAIgACABECUiAEUNGCACQdIANgIcIAIgATYCFCACIAA2AgxBACEDDKgBCyACQQA2AhwgAiABNgIUIAJBxgo2AhAgAkEHNgIMQQAhAwynAQsgAigCBCEAIAJBADYCBCACIAAgARAlIgBFDQMgAkHlADYCHCACIAE2AhQgAiAANgIMQQAhAwymAQsgAigCBCEAIAJBADYCBCACIAAgARAlIgBFDRIgAkHTADYCHCACIAE2AhQgAiAANgIMQQAhAwylAQsgAigCBCEAIAJBADYCBCACIAAgARAlIgBFDRQgAkHSADYCHCACIAE2AhQgAiAANgIMQQAhAwykAQsgAigCBCEAIAJBADYCBCACIAAgARAlIgBFDQAgAkHlADYCHCACIAE2AhQgAiAANgIMQQAhAwyjAQtB1QAhAwyJAQsgAEEVRwRAIAJBADYCHCACIAE2AhQgAkG5DTYCECACQRo2AgxBACEDDKIBCyACQeQANgIcIAIgATYCFCACQeMXNgIQIAJBFTYCDEEAIQMMoQELIAJBADYCACAGQQFqIQEgAi0AKSIAQSNrQQtJDQQCQCAAQQZLDQBBASAAdEHKAHFFDQAMBQtBACEDIAJBADYCHCACIAE2AhQgAkH3CTYCECACQQg2AgwMoAELIAJBADYCACAGQQFqIQEgAi0AKUEhRg0DIAJBADYCHCACIAE2AhQgAkGbCjYCECACQQg2AgxBACEDDJ8BCyACQQA2AgALQQAhAyACQQA2AhwgAiABNgIUIAJBkDM2AhAgAkEINgIMDJ0BCyACQQA2AgAgBkEBaiEBIAItAClBI0kNACACQQA2AhwgAiABNgIUIAJB0wk2AhAgAkEINgIMQQAhAwycAQtB0QAhAwyCAQsgAS0AAEEwayIAQf8BcUEKSQRAIAIgADoAKiABQQFqIQFBzwAhAwyCAQsgAigCBCEAIAJBADYCBCACIAAgARAoIgBFDYYBIAJB3gA2AhwgAiABNgIUIAIgADYCDEEAIQMMmgELIAIoAgQhACACQQA2AgQgAiAAIAEQKCIARQ2GASACQdwANgIcIAIgATYCFCACIAA2AgxBACEDDJkBCyACKAIEIQAgAkEANgIEIAIgACAFECgiAEUEQCAFIQEMhwELIAJB2gA2AhwgAiAFNgIUIAIgADYCDAyYAQtBACEBQQEhAwsgAiADOgArIAVBAWohAwJAAkACQCACLQAtQRBxDQACQAJAAkAgAi0AKg4DAQACBAsgBkUNAwwCCyAADQEMAgsgAUUNAQsgAigCBCEAIAJBADYCBCACIAAgAxAoIgBFBEAgAyEBDAILIAJB2AA2AhwgAiADNgIUIAIgADYCDEEAIQMMmAELIAIoAgQhACACQQA2AgQgAiAAIAMQKCIARQRAIAMhAQyHAQsgAkHZADYCHCACIAM2AhQgAiAANgIMQQAhAwyXAQtBzAAhAwx9CyAAQRVHBEAgAkEANgIcIAIgATYCFCACQZQNNgIQIAJBITYCDEEAIQMMlgELIAJB1wA2AhwgAiABNgIUIAJByRc2AhAgAkEVNgIMQQAhAwyVAQtBACEDIAJBADYCHCACIAE2AhQgAkGAETYCECACQQk2AgwMlAELIAIoAgQhACACQQA2AgQgAiAAIAEQJSIARQ0AIAJB0wA2AhwgAiABNgIUIAIgADYCDEEAIQMMkwELQckAIQMMeQsgAkEANgIcIAIgATYCFCACQcEoNgIQIAJBBzYCDCACQQA2AgBBACEDDJEBCyACKAIEIQBBACEDIAJBADYCBCACIAAgARAlIgBFDQAgAkHSADYCHCACIAE2AhQgAiAANgIMDJABC0HIACEDDHYLIAJBADYCACAFIQELIAJBgBI7ASogAUEBaiEBQQAhAAJAIAIoAjgiA0UNACADKAIwIgNFDQAgAiADEQAAIQALIAANAQtBxwAhAwxzCyAAQRVGBEAgAkHRADYCHCACIAE2AhQgAkHjFzYCECACQRU2AgxBACEDDIwBC0EAIQMgAkEANgIcIAIgATYCFCACQbkNNgIQIAJBGjYCDAyLAQtBACEDIAJBADYCHCACIAE2AhQgAkGgGTYCECACQR42AgwMigELIAEtAABBOkYEQCACKAIEIQBBACEDIAJBADYCBCACIAAgARApIgBFDQEgAkHDADYCHCACIAA2AgwgAiABQQFqNgIUDIoBC0EAIQMgAkEANgIcIAIgATYCFCACQbERNgIQIAJBCjYCDAyJAQsgAUEBaiEBQTshAwxvCyACQcMANgIcIAIgADYCDCACIAFBAWo2AhQMhwELQQAhAyACQQA2AhwgAiABNgIUIAJB8A42AhAgAkEcNgIMDIYBCyACIAIvATBBEHI7ATAMZgsCQCACLwEwIgBBCHFFDQAgAi0AKEEBRw0AIAItAC1BCHFFDQMLIAIgAEH3+wNxQYAEcjsBMAwECyABIARHBEACQANAIAEtAABBMGsiAEH/AXFBCk8EQEE1IQMMbgsgAikDICIKQpmz5syZs+bMGVYNASACIApCCn4iCjcDICAKIACtQv8BgyILQn+FVg0BIAIgCiALfDcDICAEIAFBAWoiAUcNAAtBOSEDDIUBCyACKAIEIQBBACEDIAJBADYCBCACIAAgAUEBaiIBECoiAA0MDHcLQTkhAwyDAQsgAi0AMEEgcQ0GQcUBIQMMaQtBACEDIAJBADYCBCACIAEgARAqIgBFDQQgAkE6NgIcIAIgADYCDCACIAFBAWo2AhQMgQELIAItAChBAUcNACACLQAtQQhxRQ0BC0E3IQMMZgsgAigCBCEAQQAhAyACQQA2AgQgAiAAIAEQKiIABEAgAkE7NgIcIAIgADYCDCACIAFBAWo2AhQMfwsgAUEBaiEBDG4LIAJBCDoALAwECyABQQFqIQEMbQtBACEDIAJBADYCHCACIAE2AhQgAkHkEjYCECACQQQ2AgwMewsgAigCBCEAQQAhAyACQQA2AgQgAiAAIAEQKiIARQ1sIAJBNzYCHCACIAE2AhQgAiAANgIMDHoLIAIgAi8BMEEgcjsBMAtBMCEDDF8LIAJBNjYCHCACIAE2AhQgAiAANgIMDHcLIABBLEcNASABQQFqIQBBASEBAkACQAJAAkACQCACLQAsQQVrDgQDAQIEAAsgACEBDAQLQQIhAQwBC0EEIQELIAJBAToALCACIAIvATAgAXI7ATAgACEBDAELIAIgAi8BMEEIcjsBMCAAIQELQTkhAwxcCyACQQA6ACwLQTQhAwxaCyABIARGBEBBLSEDDHMLAkACQANAAkAgAS0AAEEKaw4EAgAAAwALIAQgAUEBaiIBRw0AC0EtIQMMdAsgAigCBCEAQQAhAyACQQA2AgQgAiAAIAEQKiIARQ0CIAJBLDYCHCACIAE2AhQgAiAANgIMDHMLIAIoAgQhAEEAIQMgAkEANgIEIAIgACABECoiAEUEQCABQQFqIQEMAgsgAkEsNgIcIAIgADYCDCACIAFBAWo2AhQMcgsgAS0AAEENRgRAIAIoAgQhAEEAIQMgAkEANgIEIAIgACABECoiAEUEQCABQQFqIQEMAgsgAkEsNgIcIAIgADYCDCACIAFBAWo2AhQMcgsgAi0ALUEBcQRAQcQBIQMMWQsgAigCBCEAQQAhAyACQQA2AgQgAiAAIAEQKiIADQEMZQtBLyEDDFcLIAJBLjYCHCACIAE2AhQgAiAANgIMDG8LQQAhAyACQQA2AhwgAiABNgIUIAJB8BQ2AhAgAkEDNgIMDG4LQQEhAwJAAkACQAJAIAItACxBBWsOBAMBAgAECyACIAIvATBBCHI7ATAMAwtBAiEDDAELQQQhAwsgAkEBOgAsIAIgAi8BMCADcjsBMAtBKiEDDFMLQQAhAyACQQA2AhwgAiABNgIUIAJB4Q82AhAgAkEKNgIMDGsLQQEhAwJAAkACQAJAAkACQCACLQAsQQJrDgcFBAQDAQIABAsgAiACLwEwQQhyOwEwDAMLQQIhAwwBC0EEIQMLIAJBAToALCACIAIvATAgA3I7ATALQSshAwxSC0EAIQMgAkEANgIcIAIgATYCFCACQasSNgIQIAJBCzYCDAxqC0EAIQMgAkEANgIcIAIgATYCFCACQf0NNgIQIAJBHTYCDAxpCyABIARHBEADQCABLQAAQSBHDUggBCABQQFqIgFHDQALQSUhAwxpC0ElIQMMaAsgAi0ALUEBcQRAQcMBIQMMTwsgAigCBCEAQQAhAyACQQA2AgQgAiAAIAEQKSIABEAgAkEmNgIcIAIgADYCDCACIAFBAWo2AhQMaAsgAUEBaiEBDFwLIAFBAWohASACLwEwIgBBgAFxBEBBACEAAkAgAigCOCIDRQ0AIAMoAlQiA0UNACACIAMRAAAhAAsgAEUNBiAAQRVHDR8gAkEFNgIcIAIgATYCFCACQfkXNgIQIAJBFTYCDEEAIQMMZwsCQCAAQaAEcUGgBEcNACACLQAtQQJxDQBBACEDIAJBADYCHCACIAE2AhQgAkGWEzYCECACQQQ2AgwMZwsgAgJ/IAIvATBBFHFBFEYEQEEBIAItAChBAUYNARogAi8BMkHlAEYMAQsgAi0AKUEFRgs6AC5BACEAAkAgAigCOCIDRQ0AIAMoAiQiA0UNACACIAMRAAAhAAsCQAJAAkACQAJAIAAOFgIBAAQEBAQEBAQEBAQEBAQEBAQEBAMECyACQQE6AC4LIAIgAi8BMEHAAHI7ATALQSchAwxPCyACQSM2AhwgAiABNgIUIAJBpRY2AhAgAkEVNgIMQQAhAwxnC0EAIQMgAkEANgIcIAIgATYCFCACQdULNgIQIAJBETYCDAxmC0EAIQACQCACKAI4IgNFDQAgAygCLCIDRQ0AIAIgAxEAACEACyAADQELQQ4hAwxLCyAAQRVGBEAgAkECNgIcIAIgATYCFCACQbAYNgIQIAJBFTYCDEEAIQMMZAtBACEDIAJBADYCHCACIAE2AhQgAkGnDjYCECACQRI2AgwMYwtBACEDIAJBADYCHCACIAE2AhQgAkGqHDYCECACQQ82AgwMYgsgAigCBCEAQQAhAyACQQA2AgQgAiAAIAEgCqdqIgEQKyIARQ0AIAJBBTYCHCACIAE2AhQgAiAANgIMDGELQQ8hAwxHC0EAIQMgAkEANgIcIAIgATYCFCACQc0TNgIQIAJBDDYCDAxfC0IBIQoLIAFBAWohAQJAIAIpAyAiC0L//////////w9YBEAgAiALQgSGIAqENwMgDAELQQAhAyACQQA2AhwgAiABNgIUIAJBrQk2AhAgAkEMNgIMDF4LQSQhAwxEC0EAIQMgAkEANgIcIAIgATYCFCACQc0TNgIQIAJBDDYCDAxcCyACKAIEIQBBACEDIAJBADYCBCACIAAgARAsIgBFBEAgAUEBaiEBDFILIAJBFzYCHCACIAA2AgwgAiABQQFqNgIUDFsLIAIoAgQhAEEAIQMgAkEANgIEAkAgAiAAIAEQLCIARQRAIAFBAWohAQwBCyACQRY2AhwgAiAANgIMIAIgAUEBajYCFAxbC0EfIQMMQQtBACEDIAJBADYCHCACIAE2AhQgAkGaDzYCECACQSI2AgwMWQsgAigCBCEAQQAhAyACQQA2AgQgAiAAIAEQLSIARQRAIAFBAWohAQxQCyACQRQ2AhwgAiAANgIMIAIgAUEBajYCFAxYCyACKAIEIQBBACEDIAJBADYCBAJAIAIgACABEC0iAEUEQCABQQFqIQEMAQsgAkETNgIcIAIgADYCDCACIAFBAWo2AhQMWAtBHiEDDD4LQQAhAyACQQA2AhwgAiABNgIUIAJBxgw2AhAgAkEjNgIMDFYLIAIoAgQhAEEAIQMgAkEANgIEIAIgACABEC0iAEUEQCABQQFqIQEMTgsgAkERNgIcIAIgADYCDCACIAFBAWo2AhQMVQsgAkEQNgIcIAIgATYCFCACIAA2AgwMVAtBACEDIAJBADYCHCACIAE2AhQgAkHGDDYCECACQSM2AgwMUwtBACEDIAJBADYCHCACIAE2AhQgAkHAFTYCECACQQI2AgwMUgsgAigCBCEAQQAhAyACQQA2AgQCQCACIAAgARAtIgBFBEAgAUEBaiEBDAELIAJBDjYCHCACIAA2AgwgAiABQQFqNgIUDFILQRshAww4C0EAIQMgAkEANgIcIAIgATYCFCACQcYMNgIQIAJBIzYCDAxQCyACKAIEIQBBACEDIAJBADYCBAJAIAIgACABECwiAEUEQCABQQFqIQEMAQsgAkENNgIcIAIgADYCDCACIAFBAWo2AhQMUAtBGiEDDDYLQQAhAyACQQA2AhwgAiABNgIUIAJBmg82AhAgAkEiNgIMDE4LIAIoAgQhAEEAIQMgAkEANgIEAkAgAiAAIAEQLCIARQRAIAFBAWohAQwBCyACQQw2AhwgAiAANgIMIAIgAUEBajYCFAxOC0EZIQMMNAtBACEDIAJBADYCHCACIAE2AhQgAkGaDzYCECACQSI2AgwMTAsgAEEVRwRAQQAhAyACQQA2AhwgAiABNgIUIAJBgww2AhAgAkETNgIMDEwLIAJBCjYCHCACIAE2AhQgAkHkFjYCECACQRU2AgxBACEDDEsLIAIoAgQhAEEAIQMgAkEANgIEIAIgACABIAqnaiIBECsiAARAIAJBBzYCHCACIAE2AhQgAiAANgIMDEsLQRMhAwwxCyAAQRVHBEBBACEDIAJBADYCHCACIAE2AhQgAkHaDTYCECACQRQ2AgwMSgsgAkEeNgIcIAIgATYCFCACQfkXNgIQIAJBFTYCDEEAIQMMSQtBACEAAkAgAigCOCIDRQ0AIAMoAiwiA0UNACACIAMRAAAhAAsgAEUNQSAAQRVGBEAgAkEDNgIcIAIgATYCFCACQbAYNgIQIAJBFTYCDEEAIQMMSQtBACEDIAJBADYCHCACIAE2AhQgAkGnDjYCECACQRI2AgwMSAtBACEDIAJBADYCHCACIAE2AhQgAkHaDTYCECACQRQ2AgwMRwtBACEDIAJBADYCHCACIAE2AhQgAkGnDjYCECACQRI2AgwMRgsgAkEAOgAvIAItAC1BBHFFDT8LIAJBADoALyACQQE6ADRBACEDDCsLQQAhAyACQQA2AhwgAkHkETYCECACQQc2AgwgAiABQQFqNgIUDEMLAkADQAJAIAEtAABBCmsOBAACAgACCyAEIAFBAWoiAUcNAAtB3QEhAwxDCwJAAkAgAi0ANEEBRw0AQQAhAAJAIAIoAjgiA0UNACADKAJYIgNFDQAgAiADEQAAIQALIABFDQAgAEEVRw0BIAJB3AE2AhwgAiABNgIUIAJB1RY2AhAgAkEVNgIMQQAhAwxEC0HBASEDDCoLIAJBADYCHCACIAE2AhQgAkHpCzYCECACQR82AgxBACEDDEILAkACQCACLQAoQQFrDgIEAQALQcABIQMMKQtBuQEhAwwoCyACQQI6AC9BACEAAkAgAigCOCIDRQ0AIAMoAgAiA0UNACACIAMRAAAhAAsgAEUEQEHCASEDDCgLIABBFUcEQCACQQA2AhwgAiABNgIUIAJBpAw2AhAgAkEQNgIMQQAhAwxBCyACQdsBNgIcIAIgATYCFCACQfoWNgIQIAJBFTYCDEEAIQMMQAsgASAERgRAQdoBIQMMQAsgAS0AAEHIAEYNASACQQE6ACgLQawBIQMMJQtBvwEhAwwkCyABIARHBEAgAkEQNgIIIAIgATYCBEG+ASEDDCQLQdkBIQMMPAsgASAERgRAQdgBIQMMPAsgAS0AAEHIAEcNBCABQQFqIQFBvQEhAwwiCyABIARGBEBB1wEhAww7CwJAAkAgAS0AAEHFAGsOEAAFBQUFBQUFBQUFBQUFBQEFCyABQQFqIQFBuwEhAwwiCyABQQFqIQFBvAEhAwwhC0HWASEDIAEgBEYNOSACKAIAIgAgBCABa2ohBSABIABrQQJqIQYCQANAIAEtAAAgAEGD0ABqLQAARw0DIABBAkYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAw6CyACKAIEIQAgAkIANwMAIAIgACAGQQFqIgEQJyIARQRAQcYBIQMMIQsgAkHVATYCHCACIAE2AhQgAiAANgIMQQAhAww5C0HUASEDIAEgBEYNOCACKAIAIgAgBCABa2ohBSABIABrQQFqIQYCQANAIAEtAAAgAEGB0ABqLQAARw0CIABBAUYNASAAQQFqIQAgBCABQQFqIgFHDQALIAIgBTYCAAw5CyACQYEEOwEoIAIoAgQhACACQgA3AwAgAiAAIAZBAWoiARAnIgANAwwCCyACQQA2AgALQQAhAyACQQA2AhwgAiABNgIUIAJB2Bs2AhAgAkEINgIMDDYLQboBIQMMHAsgAkHTATYCHCACIAE2AhQgAiAANgIMQQAhAww0C0EAIQACQCACKAI4IgNFDQAgAygCOCIDRQ0AIAIgAxEAACEACyAARQ0AIABBFUYNASACQQA2AhwgAiABNgIUIAJBzA42AhAgAkEgNgIMQQAhAwwzC0HkACEDDBkLIAJB+AA2AhwgAiABNgIUIAJByhg2AhAgAkEVNgIMQQAhAwwxC0HSASEDIAQgASIARg0wIAQgAWsgAigCACIBaiEFIAAgAWtBBGohBgJAA0AgAC0AACABQfzPAGotAABHDQEgAUEERg0DIAFBAWohASAEIABBAWoiAEcNAAsgAiAFNgIADDELIAJBADYCHCACIAA2AhQgAkGQMzYCECACQQg2AgwgAkEANgIAQQAhAwwwCyABIARHBEAgAkEONgIIIAIgATYCBEG3ASEDDBcLQdEBIQMMLwsgAkEANgIAIAZBAWohAQtBuAEhAwwUCyABIARGBEBB0AEhAwwtCyABLQAAQTBrIgBB/wFxQQpJBEAgAiAAOgAqIAFBAWohAUG2ASEDDBQLIAIoAgQhACACQQA2AgQgAiAAIAEQKCIARQ0UIAJBzwE2AhwgAiABNgIUIAIgADYCDEEAIQMMLAsgASAERgRAQc4BIQMMLAsCQCABLQAAQS5GBEAgAUEBaiEBDAELIAIoAgQhACACQQA2AgQgAiAAIAEQKCIARQ0VIAJBzQE2AhwgAiABNgIUIAIgADYCDEEAIQMMLAtBtQEhAwwSCyAEIAEiBUYEQEHMASEDDCsLQQAhAEEBIQFBASEGQQAhAwJAAkACQAJAAkACfwJAAkACQAJAAkACQAJAIAUtAABBMGsOCgoJAAECAwQFBggLC0ECDAYLQQMMBQtBBAwEC0EFDAMLQQYMAgtBBwwBC0EICyEDQQAhAUEAIQYMAgtBCSEDQQEhAEEAIQFBACEGDAELQQAhAUEBIQMLIAIgAzoAKyAFQQFqIQMCQAJAIAItAC1BEHENAAJAAkACQCACLQAqDgMBAAIECyAGRQ0DDAILIAANAQwCCyABRQ0BCyACKAIEIQAgAkEANgIEIAIgACADECgiAEUEQCADIQEMAwsgAkHJATYCHCACIAM2AhQgAiAANgIMQQAhAwwtCyACKAIEIQAgAkEANgIEIAIgACADECgiAEUEQCADIQEMGAsgAkHKATYCHCACIAM2AhQgAiAANgIMQQAhAwwsCyACKAIEIQAgAkEANgIEIAIgACAFECgiAEUEQCAFIQEMFgsgAkHLATYCHCACIAU2AhQgAiAANgIMDCsLQbQBIQMMEQtBACEAAkAgAigCOCIDRQ0AIAMoAjwiA0UNACACIAMRAAAhAAsCQCAABEAgAEEVRg0BIAJBADYCHCACIAE2AhQgAkGUDTYCECACQSE2AgxBACEDDCsLQbIBIQMMEQsgAkHIATYCHCACIAE2AhQgAkHJFzYCECACQRU2AgxBACEDDCkLIAJBADYCACAGQQFqIQFB9QAhAwwPCyACLQApQQVGBEBB4wAhAwwPC0HiACEDDA4LIAAhASACQQA2AgALIAJBADoALEEJIQMMDAsgAkEANgIAIAdBAWohAUHAACEDDAsLQQELOgAsIAJBADYCACAGQQFqIQELQSkhAwwIC0E4IQMMBwsCQCABIARHBEADQCABLQAAQYA+ai0AACIAQQFHBEAgAEECRw0DIAFBAWohAQwFCyAEIAFBAWoiAUcNAAtBPiEDDCELQT4hAwwgCwsgAkEAOgAsDAELQQshAwwEC0E6IQMMAwsgAUEBaiEBQS0hAwwCCyACIAE6ACwgAkEANgIAIAZBAWohAUEMIQMMAQsgAkEANgIAIAZBAWohAUEKIQMMAAsAC0EAIQMgAkEANgIcIAIgATYCFCACQc0QNgIQIAJBCTYCDAwXC0EAIQMgAkEANgIcIAIgATYCFCACQekKNgIQIAJBCTYCDAwWC0EAIQMgAkEANgIcIAIgATYCFCACQbcQNgIQIAJBCTYCDAwVC0EAIQMgAkEANgIcIAIgATYCFCACQZwRNgIQIAJBCTYCDAwUC0EAIQMgAkEANgIcIAIgATYCFCACQc0QNgIQIAJBCTYCDAwTC0EAIQMgAkEANgIcIAIgATYCFCACQekKNgIQIAJBCTYCDAwSC0EAIQMgAkEANgIcIAIgATYCFCACQbcQNgIQIAJBCTYCDAwRC0EAIQMgAkEANgIcIAIgATYCFCACQZwRNgIQIAJBCTYCDAwQC0EAIQMgAkEANgIcIAIgATYCFCACQZcVNgIQIAJBDzYCDAwPC0EAIQMgAkEANgIcIAIgATYCFCACQZcVNgIQIAJBDzYCDAwOC0EAIQMgAkEANgIcIAIgATYCFCACQcASNgIQIAJBCzYCDAwNC0EAIQMgAkEANgIcIAIgATYCFCACQZUJNgIQIAJBCzYCDAwMC0EAIQMgAkEANgIcIAIgATYCFCACQeEPNgIQIAJBCjYCDAwLC0EAIQMgAkEANgIcIAIgATYCFCACQfsPNgIQIAJBCjYCDAwKC0EAIQMgAkEANgIcIAIgATYCFCACQfEZNgIQIAJBAjYCDAwJC0EAIQMgAkEANgIcIAIgATYCFCACQcQUNgIQIAJBAjYCDAwIC0EAIQMgAkEANgIcIAIgATYCFCACQfIVNgIQIAJBAjYCDAwHCyACQQI2AhwgAiABNgIUIAJBnBo2AhAgAkEWNgIMQQAhAwwGC0EBIQMMBQtB1AAhAyABIARGDQQgCEEIaiEJIAIoAgAhBQJAAkAgASAERwRAIAVB2MIAaiEHIAQgBWogAWshACAFQX9zQQpqIgUgAWohBgNAIAEtAAAgBy0AAEcEQEECIQcMAwsgBUUEQEEAIQcgBiEBDAMLIAVBAWshBSAHQQFqIQcgBCABQQFqIgFHDQALIAAhBSAEIQELIAlBATYCACACIAU2AgAMAQsgAkEANgIAIAkgBzYCAAsgCSABNgIEIAgoAgwhACAIKAIIDgMBBAIACwALIAJBADYCHCACQbUaNgIQIAJBFzYCDCACIABBAWo2AhRBACEDDAILIAJBADYCHCACIAA2AhQgAkHKGjYCECACQQk2AgxBACEDDAELIAEgBEYEQEEiIQMMAQsgAkEJNgIIIAIgATYCBEEhIQMLIAhBEGokACADRQRAIAIoAgwhAAwBCyACIAM2AhxBACEAIAIoAgQiAUUNACACIAEgBCACKAIIEQEAIgFFDQAgAiAENgIUIAIgATYCDCABIQALIAALvgIBAn8gAEEAOgAAIABB3ABqIgFBAWtBADoAACAAQQA6AAIgAEEAOgABIAFBA2tBADoAACABQQJrQQA6AAAgAEEAOgADIAFBBGtBADoAAEEAIABrQQNxIgEgAGoiAEEANgIAQdwAIAFrQXxxIgIgAGoiAUEEa0EANgIAAkAgAkEJSQ0AIABBADYCCCAAQQA2AgQgAUEIa0EANgIAIAFBDGtBADYCACACQRlJDQAgAEEANgIYIABBADYCFCAAQQA2AhAgAEEANgIMIAFBEGtBADYCACABQRRrQQA2AgAgAUEYa0EANgIAIAFBHGtBADYCACACIABBBHFBGHIiAmsiAUEgSQ0AIAAgAmohAANAIABCADcDGCAAQgA3AxAgAEIANwMIIABCADcDACAAQSBqIQAgAUEgayIBQR9LDQALCwtWAQF/AkAgACgCDA0AAkACQAJAAkAgAC0ALw4DAQADAgsgACgCOCIBRQ0AIAEoAiwiAUUNACAAIAERAAAiAQ0DC0EADwsACyAAQcMWNgIQQQ4hAQsgAQsaACAAKAIMRQRAIABB0Rs2AhAgAEEVNgIMCwsUACAAKAIMQRVGBEAgAEEANgIMCwsUACAAKAIMQRZGBEAgAEEANgIMCwsHACAAKAIMCwcAIAAoAhALCQAgACABNgIQCwcAIAAoAhQLFwAgAEEkTwRAAAsgAEECdEGgM2ooAgALFwAgAEEuTwRAAAsgAEECdEGwNGooAgALvwkBAX9B6yghAQJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAIABB5ABrDvQDY2IAAWFhYWFhYQIDBAVhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhBgcICQoLDA0OD2FhYWFhEGFhYWFhYWFhYWFhEWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYRITFBUWFxgZGhthYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhHB0eHyAhIiMkJSYnKCkqKywtLi8wMTIzNDU2YTc4OTphYWFhYWFhYTthYWE8YWFhYT0+P2FhYWFhYWFhQGFhQWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYUJDREVGR0hJSktMTU5PUFFSU2FhYWFhYWFhVFVWV1hZWlthXF1hYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFeYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhX2BhC0HhJw8LQaQhDwtByywPC0H+MQ8LQcAkDwtBqyQPC0GNKA8LQeImDwtBgDAPC0G5Lw8LQdckDwtB7x8PC0HhHw8LQfofDwtB8iAPC0GoLw8LQa4yDwtBiDAPC0HsJw8LQYIiDwtBjh0PC0HQLg8LQcojDwtBxTIPC0HfHA8LQdIcDwtBxCAPC0HXIA8LQaIfDwtB7S4PC0GrMA8LQdQlDwtBzC4PC0H6Lg8LQfwrDwtB0jAPC0HxHQ8LQbsgDwtB9ysPC0GQMQ8LQdcxDwtBoi0PC0HUJw8LQeArDwtBnywPC0HrMQ8LQdUfDwtByjEPC0HeJQ8LQdQeDwtB9BwPC0GnMg8LQbEdDwtBoB0PC0G5MQ8LQbwwDwtBkiEPC0GzJg8LQeksDwtBrB4PC0HUKw8LQfcmDwtBgCYPC0GwIQ8LQf4eDwtBjSMPC0GJLQ8LQfciDwtBoDEPC0GuHw8LQcYlDwtB6B4PC0GTIg8LQcIvDwtBwx0PC0GLLA8LQeEdDwtBjS8PC0HqIQ8LQbQtDwtB0i8PC0HfMg8LQdIyDwtB8DAPC0GpIg8LQfkjDwtBmR4PC0G1LA8LQZswDwtBkjIPC0G2Kw8LQcIiDwtB+DIPC0GeJQ8LQdAiDwtBuh4PC0GBHg8LAAtB1iEhAQsgAQsWACAAIAAtAC1B/gFxIAFBAEdyOgAtCxkAIAAgAC0ALUH9AXEgAUEAR0EBdHI6AC0LGQAgACAALQAtQfsBcSABQQBHQQJ0cjoALQsZACAAIAAtAC1B9wFxIAFBAEdBA3RyOgAtCz4BAn8CQCAAKAI4IgNFDQAgAygCBCIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABBxhE2AhBBGCEECyAECz4BAn8CQCAAKAI4IgNFDQAgAygCCCIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABB9go2AhBBGCEECyAECz4BAn8CQCAAKAI4IgNFDQAgAygCDCIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABB7Ro2AhBBGCEECyAECz4BAn8CQCAAKAI4IgNFDQAgAygCECIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABBlRA2AhBBGCEECyAECz4BAn8CQCAAKAI4IgNFDQAgAygCFCIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABBqhs2AhBBGCEECyAECz4BAn8CQCAAKAI4IgNFDQAgAygCGCIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABB7RM2AhBBGCEECyAECz4BAn8CQCAAKAI4IgNFDQAgAygCKCIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABB9gg2AhBBGCEECyAECz4BAn8CQCAAKAI4IgNFDQAgAygCHCIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABBwhk2AhBBGCEECyAECz4BAn8CQCAAKAI4IgNFDQAgAygCICIDRQ0AIAAgASACIAFrIAMRAQAiBEF/Rw0AIABBlBQ2AhBBGCEECyAEC1kBAn8CQCAALQAoQQFGDQAgAC8BMiIBQeQAa0HkAEkNACABQcwBRg0AIAFBsAJGDQAgAC8BMCIAQcAAcQ0AQQEhAiAAQYgEcUGABEYNACAAQShxRSECCyACC4wBAQJ/AkACQAJAIAAtACpFDQAgAC0AK0UNACAALwEwIgFBAnFFDQEMAgsgAC8BMCIBQQFxRQ0BC0EBIQIgAC0AKEEBRg0AIAAvATIiAEHkAGtB5ABJDQAgAEHMAUYNACAAQbACRg0AIAFBwABxDQBBACECIAFBiARxQYAERg0AIAFBKHFBAEchAgsgAgtXACAAQRhqQgA3AwAgAEIANwMAIABBOGpCADcDACAAQTBqQgA3AwAgAEEoakIANwMAIABBIGpCADcDACAAQRBqQgA3AwAgAEEIakIANwMAIABB3QE2AhwLBgAgABAyC5otAQt/IwBBEGsiCiQAQaTQACgCACIJRQRAQeTTACgCACIFRQRAQfDTAEJ/NwIAQejTAEKAgISAgIDAADcCAEHk0wAgCkEIakFwcUHYqtWqBXMiBTYCAEH40wBBADYCAEHI0wBBADYCAAtBzNMAQYDUBDYCAEGc0ABBgNQENgIAQbDQACAFNgIAQazQAEF/NgIAQdDTAEGArAM2AgADQCABQcjQAGogAUG80ABqIgI2AgAgAiABQbTQAGoiAzYCACABQcDQAGogAzYCACABQdDQAGogAUHE0ABqIgM2AgAgAyACNgIAIAFB2NAAaiABQczQAGoiAjYCACACIAM2AgAgAUHU0ABqIAI2AgAgAUEgaiIBQYACRw0AC0GM1ARBwasDNgIAQajQAEH00wAoAgA2AgBBmNAAQcCrAzYCAEGk0ABBiNQENgIAQcz/B0E4NgIAQYjUBCEJCwJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAAkACQAJAIABB7AFNBEBBjNAAKAIAIgZBECAAQRNqQXBxIABBC0kbIgRBA3YiAHYiAUEDcQRAAkAgAUEBcSAAckEBcyICQQN0IgBBtNAAaiIBIABBvNAAaigCACIAKAIIIgNGBEBBjNAAIAZBfiACd3E2AgAMAQsgASADNgIIIAMgATYCDAsgAEEIaiEBIAAgAkEDdCICQQNyNgIEIAAgAmoiACAAKAIEQQFyNgIEDBELQZTQACgCACIIIARPDQEgAQRAAkBBAiAAdCICQQAgAmtyIAEgAHRxaCIAQQN0IgJBtNAAaiIBIAJBvNAAaigCACICKAIIIgNGBEBBjNAAIAZBfiAAd3EiBjYCAAwBCyABIAM2AgggAyABNgIMCyACIARBA3I2AgQgAEEDdCIAIARrIQUgACACaiAFNgIAIAIgBGoiBCAFQQFyNgIEIAgEQCAIQXhxQbTQAGohAEGg0AAoAgAhAwJ/QQEgCEEDdnQiASAGcUUEQEGM0AAgASAGcjYCACAADAELIAAoAggLIgEgAzYCDCAAIAM2AgggAyAANgIMIAMgATYCCAsgAkEIaiEBQaDQACAENgIAQZTQACAFNgIADBELQZDQACgCACILRQ0BIAtoQQJ0QbzSAGooAgAiACgCBEF4cSAEayEFIAAhAgNAAkAgAigCECIBRQRAIAJBFGooAgAiAUUNAQsgASgCBEF4cSAEayIDIAVJIQIgAyAFIAIbIQUgASAAIAIbIQAgASECDAELCyAAKAIYIQkgACgCDCIDIABHBEBBnNAAKAIAGiADIAAoAggiATYCCCABIAM2AgwMEAsgAEEUaiICKAIAIgFFBEAgACgCECIBRQ0DIABBEGohAgsDQCACIQcgASIDQRRqIgIoAgAiAQ0AIANBEGohAiADKAIQIgENAAsgB0EANgIADA8LQX8hBCAAQb9/Sw0AIABBE2oiAUFwcSEEQZDQACgCACIIRQ0AQQAgBGshBQJAAkACQAJ/QQAgBEGAAkkNABpBHyAEQf///wdLDQAaIARBJiABQQh2ZyIAa3ZBAXEgAEEBdGtBPmoLIgZBAnRBvNIAaigCACICRQRAQQAhAUEAIQMMAQtBACEBIARBGSAGQQF2a0EAIAZBH0cbdCEAQQAhAwNAAkAgAigCBEF4cSAEayIHIAVPDQAgAiEDIAciBQ0AQQAhBSACIQEMAwsgASACQRRqKAIAIgcgByACIABBHXZBBHFqQRBqKAIAIgJGGyABIAcbIQEgAEEBdCEAIAINAAsLIAEgA3JFBEBBACEDQQIgBnQiAEEAIABrciAIcSIARQ0DIABoQQJ0QbzSAGooAgAhAQsgAUUNAQsDQCABKAIEQXhxIARrIgIgBUkhACACIAUgABshBSABIAMgABshAyABKAIQIgAEfyAABSABQRRqKAIACyIBDQALCyADRQ0AIAVBlNAAKAIAIARrTw0AIAMoAhghByADIAMoAgwiAEcEQEGc0AAoAgAaIAAgAygCCCIBNgIIIAEgADYCDAwOCyADQRRqIgIoAgAiAUUEQCADKAIQIgFFDQMgA0EQaiECCwNAIAIhBiABIgBBFGoiAigCACIBDQAgAEEQaiECIAAoAhAiAQ0ACyAGQQA2AgAMDQtBlNAAKAIAIgMgBE8EQEGg0AAoAgAhAQJAIAMgBGsiAkEQTwRAIAEgBGoiACACQQFyNgIEIAEgA2ogAjYCACABIARBA3I2AgQMAQsgASADQQNyNgIEIAEgA2oiACAAKAIEQQFyNgIEQQAhAEEAIQILQZTQACACNgIAQaDQACAANgIAIAFBCGohAQwPC0GY0AAoAgAiAyAESwRAIAQgCWoiACADIARrIgFBAXI2AgRBpNAAIAA2AgBBmNAAIAE2AgAgCSAEQQNyNgIEIAlBCGohAQwPC0EAIQEgBAJ/QeTTACgCAARAQezTACgCAAwBC0Hw0wBCfzcCAEHo0wBCgICEgICAwAA3AgBB5NMAIApBDGpBcHFB2KrVqgVzNgIAQfjTAEEANgIAQcjTAEEANgIAQYCABAsiACAEQccAaiIFaiIGQQAgAGsiB3EiAk8EQEH80wBBMDYCAAwPCwJAQcTTACgCACIBRQ0AQbzTACgCACIIIAJqIQAgACABTSAAIAhLcQ0AQQAhAUH80wBBMDYCAAwPC0HI0wAtAABBBHENBAJAAkAgCQRAQczTACEBA0AgASgCACIAIAlNBEAgACABKAIEaiAJSw0DCyABKAIIIgENAAsLQQAQMyIAQX9GDQUgAiEGQejTACgCACIBQQFrIgMgAHEEQCACIABrIAAgA2pBACABa3FqIQYLIAQgBk8NBSAGQf7///8HSw0FQcTTACgCACIDBEBBvNMAKAIAIgcgBmohASABIAdNDQYgASADSw0GCyAGEDMiASAARw0BDAcLIAYgA2sgB3EiBkH+////B0sNBCAGEDMhACAAIAEoAgAgASgCBGpGDQMgACEBCwJAIAYgBEHIAGpPDQAgAUF/Rg0AQezTACgCACIAIAUgBmtqQQAgAGtxIgBB/v///wdLBEAgASEADAcLIAAQM0F/RwRAIAAgBmohBiABIQAMBwtBACAGaxAzGgwECyABIgBBf0cNBQwDC0EAIQMMDAtBACEADAoLIABBf0cNAgtByNMAQcjTACgCAEEEcjYCAAsgAkH+////B0sNASACEDMhAEEAEDMhASAAQX9GDQEgAUF/Rg0BIAAgAU8NASABIABrIgYgBEE4ak0NAQtBvNMAQbzTACgCACAGaiIBNgIAQcDTACgCACABSQRAQcDTACABNgIACwJAAkACQEGk0AAoAgAiAgRAQczTACEBA0AgACABKAIAIgMgASgCBCIFakYNAiABKAIIIgENAAsMAgtBnNAAKAIAIgFBAEcgACABT3FFBEBBnNAAIAA2AgALQQAhAUHQ0wAgBjYCAEHM0wAgADYCAEGs0ABBfzYCAEGw0ABB5NMAKAIANgIAQdjTAEEANgIAA0AgAUHI0ABqIAFBvNAAaiICNgIAIAIgAUG00ABqIgM2AgAgAUHA0ABqIAM2AgAgAUHQ0ABqIAFBxNAAaiIDNgIAIAMgAjYCACABQdjQAGogAUHM0ABqIgI2AgAgAiADNgIAIAFB1NAAaiACNgIAIAFBIGoiAUGAAkcNAAtBeCAAa0EPcSIBIABqIgIgBkE4ayIDIAFrIgFBAXI2AgRBqNAAQfTTACgCADYCAEGY0AAgATYCAEGk0AAgAjYCACAAIANqQTg2AgQMAgsgACACTQ0AIAIgA0kNACABKAIMQQhxDQBBeCACa0EPcSIAIAJqIgNBmNAAKAIAIAZqIgcgAGsiAEEBcjYCBCABIAUgBmo2AgRBqNAAQfTTACgCADYCAEGY0AAgADYCAEGk0AAgAzYCACACIAdqQTg2AgQMAQsgAEGc0AAoAgBJBEBBnNAAIAA2AgALIAAgBmohA0HM0wAhAQJAAkACQANAIAMgASgCAEcEQCABKAIIIgENAQwCCwsgAS0ADEEIcUUNAQtBzNMAIQEDQCABKAIAIgMgAk0EQCADIAEoAgRqIgUgAksNAwsgASgCCCEBDAALAAsgASAANgIAIAEgASgCBCAGajYCBCAAQXggAGtBD3FqIgkgBEEDcjYCBCADQXggA2tBD3FqIgYgBCAJaiIEayEBIAIgBkYEQEGk0AAgBDYCAEGY0ABBmNAAKAIAIAFqIgA2AgAgBCAAQQFyNgIEDAgLQaDQACgCACAGRgRAQaDQACAENgIAQZTQAEGU0AAoAgAgAWoiADYCACAEIABBAXI2AgQgACAEaiAANgIADAgLIAYoAgQiBUEDcUEBRw0GIAVBeHEhCCAFQf8BTQRAIAVBA3YhAyAGKAIIIgAgBigCDCICRgRAQYzQAEGM0AAoAgBBfiADd3E2AgAMBwsgAiAANgIIIAAgAjYCDAwGCyAGKAIYIQcgBiAGKAIMIgBHBEAgACAGKAIIIgI2AgggAiAANgIMDAULIAZBFGoiAigCACIFRQRAIAYoAhAiBUUNBCAGQRBqIQILA0AgAiEDIAUiAEEUaiICKAIAIgUNACAAQRBqIQIgACgCECIFDQALIANBADYCAAwEC0F4IABrQQ9xIgEgAGoiByAGQThrIgMgAWsiAUEBcjYCBCAAIANqQTg2AgQgAiAFQTcgBWtBD3FqQT9rIgMgAyACQRBqSRsiA0EjNgIEQajQAEH00wAoAgA2AgBBmNAAIAE2AgBBpNAAIAc2AgAgA0EQakHU0wApAgA3AgAgA0HM0wApAgA3AghB1NMAIANBCGo2AgBB0NMAIAY2AgBBzNMAIAA2AgBB2NMAQQA2AgAgA0EkaiEBA0AgAUEHNgIAIAUgAUEEaiIBSw0ACyACIANGDQAgAyADKAIEQX5xNgIEIAMgAyACayIFNgIAIAIgBUEBcjYCBCAFQf8BTQRAIAVBeHFBtNAAaiEAAn9BjNAAKAIAIgFBASAFQQN2dCIDcUUEQEGM0AAgASADcjYCACAADAELIAAoAggLIgEgAjYCDCAAIAI2AgggAiAANgIMIAIgATYCCAwBC0EfIQEgBUH///8HTQRAIAVBJiAFQQh2ZyIAa3ZBAXEgAEEBdGtBPmohAQsgAiABNgIcIAJCADcCECABQQJ0QbzSAGohAEGQ0AAoAgAiA0EBIAF0IgZxRQRAIAAgAjYCAEGQ0AAgAyAGcjYCACACIAA2AhggAiACNgIIIAIgAjYCDAwBCyAFQRkgAUEBdmtBACABQR9HG3QhASAAKAIAIQMCQANAIAMiACgCBEF4cSAFRg0BIAFBHXYhAyABQQF0IQEgACADQQRxakEQaiIGKAIAIgMNAAsgBiACNgIAIAIgADYCGCACIAI2AgwgAiACNgIIDAELIAAoAggiASACNgIMIAAgAjYCCCACQQA2AhggAiAANgIMIAIgATYCCAtBmNAAKAIAIgEgBE0NAEGk0AAoAgAiACAEaiICIAEgBGsiAUEBcjYCBEGY0AAgATYCAEGk0AAgAjYCACAAIARBA3I2AgQgAEEIaiEBDAgLQQAhAUH80wBBMDYCAAwHC0EAIQALIAdFDQACQCAGKAIcIgJBAnRBvNIAaiIDKAIAIAZGBEAgAyAANgIAIAANAUGQ0ABBkNAAKAIAQX4gAndxNgIADAILIAdBEEEUIAcoAhAgBkYbaiAANgIAIABFDQELIAAgBzYCGCAGKAIQIgIEQCAAIAI2AhAgAiAANgIYCyAGQRRqKAIAIgJFDQAgAEEUaiACNgIAIAIgADYCGAsgASAIaiEBIAYgCGoiBigCBCEFCyAGIAVBfnE2AgQgASAEaiABNgIAIAQgAUEBcjYCBCABQf8BTQRAIAFBeHFBtNAAaiEAAn9BjNAAKAIAIgJBASABQQN2dCIBcUUEQEGM0AAgASACcjYCACAADAELIAAoAggLIgEgBDYCDCAAIAQ2AgggBCAANgIMIAQgATYCCAwBC0EfIQUgAUH///8HTQRAIAFBJiABQQh2ZyIAa3ZBAXEgAEEBdGtBPmohBQsgBCAFNgIcIARCADcCECAFQQJ0QbzSAGohAEGQ0AAoAgAiAkEBIAV0IgNxRQRAIAAgBDYCAEGQ0AAgAiADcjYCACAEIAA2AhggBCAENgIIIAQgBDYCDAwBCyABQRkgBUEBdmtBACAFQR9HG3QhBSAAKAIAIQACQANAIAAiAigCBEF4cSABRg0BIAVBHXYhACAFQQF0IQUgAiAAQQRxakEQaiIDKAIAIgANAAsgAyAENgIAIAQgAjYCGCAEIAQ2AgwgBCAENgIIDAELIAIoAggiACAENgIMIAIgBDYCCCAEQQA2AhggBCACNgIMIAQgADYCCAsgCUEIaiEBDAILAkAgB0UNAAJAIAMoAhwiAUECdEG80gBqIgIoAgAgA0YEQCACIAA2AgAgAA0BQZDQACAIQX4gAXdxIgg2AgAMAgsgB0EQQRQgBygCECADRhtqIAA2AgAgAEUNAQsgACAHNgIYIAMoAhAiAQRAIAAgATYCECABIAA2AhgLIANBFGooAgAiAUUNACAAQRRqIAE2AgAgASAANgIYCwJAIAVBD00EQCADIAQgBWoiAEEDcjYCBCAAIANqIgAgACgCBEEBcjYCBAwBCyADIARqIgIgBUEBcjYCBCADIARBA3I2AgQgAiAFaiAFNgIAIAVB/wFNBEAgBUF4cUG00ABqIQACf0GM0AAoAgAiAUEBIAVBA3Z0IgVxRQRAQYzQACABIAVyNgIAIAAMAQsgACgCCAsiASACNgIMIAAgAjYCCCACIAA2AgwgAiABNgIIDAELQR8hASAFQf///wdNBEAgBUEmIAVBCHZnIgBrdkEBcSAAQQF0a0E+aiEBCyACIAE2AhwgAkIANwIQIAFBAnRBvNIAaiEAQQEgAXQiBCAIcUUEQCAAIAI2AgBBkNAAIAQgCHI2AgAgAiAANgIYIAIgAjYCCCACIAI2AgwMAQsgBUEZIAFBAXZrQQAgAUEfRxt0IQEgACgCACEEAkADQCAEIgAoAgRBeHEgBUYNASABQR12IQQgAUEBdCEBIAAgBEEEcWpBEGoiBigCACIEDQALIAYgAjYCACACIAA2AhggAiACNgIMIAIgAjYCCAwBCyAAKAIIIgEgAjYCDCAAIAI2AgggAkEANgIYIAIgADYCDCACIAE2AggLIANBCGohAQwBCwJAIAlFDQACQCAAKAIcIgFBAnRBvNIAaiICKAIAIABGBEAgAiADNgIAIAMNAUGQ0AAgC0F+IAF3cTYCAAwCCyAJQRBBFCAJKAIQIABGG2ogAzYCACADRQ0BCyADIAk2AhggACgCECIBBEAgAyABNgIQIAEgAzYCGAsgAEEUaigCACIBRQ0AIANBFGogATYCACABIAM2AhgLAkAgBUEPTQRAIAAgBCAFaiIBQQNyNgIEIAAgAWoiASABKAIEQQFyNgIEDAELIAAgBGoiByAFQQFyNgIEIAAgBEEDcjYCBCAFIAdqIAU2AgAgCARAIAhBeHFBtNAAaiEBQaDQACgCACEDAn9BASAIQQN2dCICIAZxRQRAQYzQACACIAZyNgIAIAEMAQsgASgCCAsiAiADNgIMIAEgAzYCCCADIAE2AgwgAyACNgIIC0Gg0AAgBzYCAEGU0AAgBTYCAAsgAEEIaiEBCyAKQRBqJAAgAQtDACAARQRAPwBBEHQPCwJAIABB//8DcQ0AIABBAEgNACAAQRB2QAAiAEF/RgRAQfzTAEEwNgIAQX8PCyAAQRB0DwsACwvcPyIAQYAICwkBAAAAAgAAAAMAQZQICwUEAAAABQBBpAgLCQYAAAAHAAAACABB3AgLii1JbnZhbGlkIGNoYXIgaW4gdXJsIHF1ZXJ5AFNwYW4gY2FsbGJhY2sgZXJyb3IgaW4gb25fYm9keQBDb250ZW50LUxlbmd0aCBvdmVyZmxvdwBDaHVuayBzaXplIG92ZXJmbG93AFJlc3BvbnNlIG92ZXJmbG93AEludmFsaWQgbWV0aG9kIGZvciBIVFRQL3gueCByZXF1ZXN0AEludmFsaWQgbWV0aG9kIGZvciBSVFNQL3gueCByZXF1ZXN0AEV4cGVjdGVkIFNPVVJDRSBtZXRob2QgZm9yIElDRS94LnggcmVxdWVzdABJbnZhbGlkIGNoYXIgaW4gdXJsIGZyYWdtZW50IHN0YXJ0AEV4cGVjdGVkIGRvdABTcGFuIGNhbGxiYWNrIGVycm9yIGluIG9uX3N0YXR1cwBJbnZhbGlkIHJlc3BvbnNlIHN0YXR1cwBJbnZhbGlkIGNoYXJhY3RlciBpbiBjaHVuayBleHRlbnNpb25zAFVzZXIgY2FsbGJhY2sgZXJyb3IAYG9uX3Jlc2V0YCBjYWxsYmFjayBlcnJvcgBgb25fY2h1bmtfaGVhZGVyYCBjYWxsYmFjayBlcnJvcgBgb25fbWVzc2FnZV9iZWdpbmAgY2FsbGJhY2sgZXJyb3IAYG9uX2NodW5rX2V4dGVuc2lvbl92YWx1ZWAgY2FsbGJhY2sgZXJyb3IAYG9uX3N0YXR1c19jb21wbGV0ZWAgY2FsbGJhY2sgZXJyb3IAYG9uX3ZlcnNpb25fY29tcGxldGVgIGNhbGxiYWNrIGVycm9yAGBvbl91cmxfY29tcGxldGVgIGNhbGxiYWNrIGVycm9yAGBvbl9jaHVua19jb21wbGV0ZWAgY2FsbGJhY2sgZXJyb3IAYG9uX2hlYWRlcl92YWx1ZV9jb21wbGV0ZWAgY2FsbGJhY2sgZXJyb3IAYG9uX21lc3NhZ2VfY29tcGxldGVgIGNhbGxiYWNrIGVycm9yAGBvbl9tZXRob2RfY29tcGxldGVgIGNhbGxiYWNrIGVycm9yAGBvbl9oZWFkZXJfZmllbGRfY29tcGxldGVgIGNhbGxiYWNrIGVycm9yAGBvbl9jaHVua19leHRlbnNpb25fbmFtZWAgY2FsbGJhY2sgZXJyb3IAVW5leHBlY3RlZCBjaGFyIGluIHVybCBzZXJ2ZXIASW52YWxpZCBoZWFkZXIgdmFsdWUgY2hhcgBJbnZhbGlkIGhlYWRlciBmaWVsZCBjaGFyAFNwYW4gY2FsbGJhY2sgZXJyb3IgaW4gb25fdmVyc2lvbgBJbnZhbGlkIG1pbm9yIHZlcnNpb24ASW52YWxpZCBtYWpvciB2ZXJzaW9uAEV4cGVjdGVkIHNwYWNlIGFmdGVyIHZlcnNpb24ARXhwZWN0ZWQgQ1JMRiBhZnRlciB2ZXJzaW9uAEludmFsaWQgSFRUUCB2ZXJzaW9uAEludmFsaWQgaGVhZGVyIHRva2VuAFNwYW4gY2FsbGJhY2sgZXJyb3IgaW4gb25fdXJsAEludmFsaWQgY2hhcmFjdGVycyBpbiB1cmwAVW5leHBlY3RlZCBzdGFydCBjaGFyIGluIHVybABEb3VibGUgQCBpbiB1cmwARW1wdHkgQ29udGVudC1MZW5ndGgASW52YWxpZCBjaGFyYWN0ZXIgaW4gQ29udGVudC1MZW5ndGgARHVwbGljYXRlIENvbnRlbnQtTGVuZ3RoAEludmFsaWQgY2hhciBpbiB1cmwgcGF0aABDb250ZW50LUxlbmd0aCBjYW4ndCBiZSBwcmVzZW50IHdpdGggVHJhbnNmZXItRW5jb2RpbmcASW52YWxpZCBjaGFyYWN0ZXIgaW4gY2h1bmsgc2l6ZQBTcGFuIGNhbGxiYWNrIGVycm9yIGluIG9uX2hlYWRlcl92YWx1ZQBTcGFuIGNhbGxiYWNrIGVycm9yIGluIG9uX2NodW5rX2V4dGVuc2lvbl92YWx1ZQBJbnZhbGlkIGNoYXJhY3RlciBpbiBjaHVuayBleHRlbnNpb25zIHZhbHVlAE1pc3NpbmcgZXhwZWN0ZWQgTEYgYWZ0ZXIgaGVhZGVyIHZhbHVlAEludmFsaWQgYFRyYW5zZmVyLUVuY29kaW5nYCBoZWFkZXIgdmFsdWUASW52YWxpZCBjaGFyYWN0ZXIgaW4gY2h1bmsgZXh0ZW5zaW9ucyBxdW90ZSB2YWx1ZQBJbnZhbGlkIGNoYXJhY3RlciBpbiBjaHVuayBleHRlbnNpb25zIHF1b3RlZCB2YWx1ZQBQYXVzZWQgYnkgb25faGVhZGVyc19jb21wbGV0ZQBJbnZhbGlkIEVPRiBzdGF0ZQBvbl9yZXNldCBwYXVzZQBvbl9jaHVua19oZWFkZXIgcGF1c2UAb25fbWVzc2FnZV9iZWdpbiBwYXVzZQBvbl9jaHVua19leHRlbnNpb25fdmFsdWUgcGF1c2UAb25fc3RhdHVzX2NvbXBsZXRlIHBhdXNlAG9uX3ZlcnNpb25fY29tcGxldGUgcGF1c2UAb25fdXJsX2NvbXBsZXRlIHBhdXNlAG9uX2NodW5rX2NvbXBsZXRlIHBhdXNlAG9uX2hlYWRlcl92YWx1ZV9jb21wbGV0ZSBwYXVzZQBvbl9tZXNzYWdlX2NvbXBsZXRlIHBhdXNlAG9uX21ldGhvZF9jb21wbGV0ZSBwYXVzZQBvbl9oZWFkZXJfZmllbGRfY29tcGxldGUgcGF1c2UAb25fY2h1bmtfZXh0ZW5zaW9uX25hbWUgcGF1c2UAVW5leHBlY3RlZCBzcGFjZSBhZnRlciBzdGFydCBsaW5lAFNwYW4gY2FsbGJhY2sgZXJyb3IgaW4gb25fY2h1bmtfZXh0ZW5zaW9uX25hbWUASW52YWxpZCBjaGFyYWN0ZXIgaW4gY2h1bmsgZXh0ZW5zaW9ucyBuYW1lAFBhdXNlIG9uIENPTk5FQ1QvVXBncmFkZQBQYXVzZSBvbiBQUkkvVXBncmFkZQBFeHBlY3RlZCBIVFRQLzIgQ29ubmVjdGlvbiBQcmVmYWNlAFNwYW4gY2FsbGJhY2sgZXJyb3IgaW4gb25fbWV0aG9kAEV4cGVjdGVkIHNwYWNlIGFmdGVyIG1ldGhvZABTcGFuIGNhbGxiYWNrIGVycm9yIGluIG9uX2hlYWRlcl9maWVsZABQYXVzZWQASW52YWxpZCB3b3JkIGVuY291bnRlcmVkAEludmFsaWQgbWV0aG9kIGVuY291bnRlcmVkAFVuZXhwZWN0ZWQgY2hhciBpbiB1cmwgc2NoZW1hAFJlcXVlc3QgaGFzIGludmFsaWQgYFRyYW5zZmVyLUVuY29kaW5nYABTV0lUQ0hfUFJPWFkAVVNFX1BST1hZAE1LQUNUSVZJVFkAVU5QUk9DRVNTQUJMRV9FTlRJVFkAQ09QWQBNT1ZFRF9QRVJNQU5FTlRMWQBUT09fRUFSTFkATk9USUZZAEZBSUxFRF9ERVBFTkRFTkNZAEJBRF9HQVRFV0FZAFBMQVkAUFVUAENIRUNLT1VUAEdBVEVXQVlfVElNRU9VVABSRVFVRVNUX1RJTUVPVVQATkVUV09SS19DT05ORUNUX1RJTUVPVVQAQ09OTkVDVElPTl9USU1FT1VUAExPR0lOX1RJTUVPVVQATkVUV09SS19SRUFEX1RJTUVPVVQAUE9TVABNSVNESVJFQ1RFRF9SRVFVRVNUAENMSUVOVF9DTE9TRURfUkVRVUVTVABDTElFTlRfQ0xPU0VEX0xPQURfQkFMQU5DRURfUkVRVUVTVABCQURfUkVRVUVTVABIVFRQX1JFUVVFU1RfU0VOVF9UT19IVFRQU19QT1JUAFJFUE9SVABJTV9BX1RFQVBPVABSRVNFVF9DT05URU5UAE5PX0NPTlRFTlQAUEFSVElBTF9DT05URU5UAEhQRV9JTlZBTElEX0NPTlNUQU5UAEhQRV9DQl9SRVNFVABHRVQASFBFX1NUUklDVABDT05GTElDVABURU1QT1JBUllfUkVESVJFQ1QAUEVSTUFORU5UX1JFRElSRUNUAENPTk5FQ1QATVVMVElfU1RBVFVTAEhQRV9JTlZBTElEX1NUQVRVUwBUT09fTUFOWV9SRVFVRVNUUwBFQVJMWV9ISU5UUwBVTkFWQUlMQUJMRV9GT1JfTEVHQUxfUkVBU09OUwBPUFRJT05TAFNXSVRDSElOR19QUk9UT0NPTFMAVkFSSUFOVF9BTFNPX05FR09USUFURVMATVVMVElQTEVfQ0hPSUNFUwBJTlRFUk5BTF9TRVJWRVJfRVJST1IAV0VCX1NFUlZFUl9VTktOT1dOX0VSUk9SAFJBSUxHVU5fRVJST1IASURFTlRJVFlfUFJPVklERVJfQVVUSEVOVElDQVRJT05fRVJST1IAU1NMX0NFUlRJRklDQVRFX0VSUk9SAElOVkFMSURfWF9GT1JXQVJERURfRk9SAFNFVF9QQVJBTUVURVIAR0VUX1BBUkFNRVRFUgBIUEVfVVNFUgBTRUVfT1RIRVIASFBFX0NCX0NIVU5LX0hFQURFUgBNS0NBTEVOREFSAFNFVFVQAFdFQl9TRVJWRVJfSVNfRE9XTgBURUFSRE9XTgBIUEVfQ0xPU0VEX0NPTk5FQ1RJT04ASEVVUklTVElDX0VYUElSQVRJT04ARElTQ09OTkVDVEVEX09QRVJBVElPTgBOT05fQVVUSE9SSVRBVElWRV9JTkZPUk1BVElPTgBIUEVfSU5WQUxJRF9WRVJTSU9OAEhQRV9DQl9NRVNTQUdFX0JFR0lOAFNJVEVfSVNfRlJPWkVOAEhQRV9JTlZBTElEX0hFQURFUl9UT0tFTgBJTlZBTElEX1RPS0VOAEZPUkJJRERFTgBFTkhBTkNFX1lPVVJfQ0FMTQBIUEVfSU5WQUxJRF9VUkwAQkxPQ0tFRF9CWV9QQVJFTlRBTF9DT05UUk9MAE1LQ09MAEFDTABIUEVfSU5URVJOQUwAUkVRVUVTVF9IRUFERVJfRklFTERTX1RPT19MQVJHRV9VTk9GRklDSUFMAEhQRV9PSwBVTkxJTksAVU5MT0NLAFBSSQBSRVRSWV9XSVRIAEhQRV9JTlZBTElEX0NPTlRFTlRfTEVOR1RIAEhQRV9VTkVYUEVDVEVEX0NPTlRFTlRfTEVOR1RIAEZMVVNIAFBST1BQQVRDSABNLVNFQVJDSABVUklfVE9PX0xPTkcAUFJPQ0VTU0lORwBNSVNDRUxMQU5FT1VTX1BFUlNJU1RFTlRfV0FSTklORwBNSVNDRUxMQU5FT1VTX1dBUk5JTkcASFBFX0lOVkFMSURfVFJBTlNGRVJfRU5DT0RJTkcARXhwZWN0ZWQgQ1JMRgBIUEVfSU5WQUxJRF9DSFVOS19TSVpFAE1PVkUAQ09OVElOVUUASFBFX0NCX1NUQVRVU19DT01QTEVURQBIUEVfQ0JfSEVBREVSU19DT01QTEVURQBIUEVfQ0JfVkVSU0lPTl9DT01QTEVURQBIUEVfQ0JfVVJMX0NPTVBMRVRFAEhQRV9DQl9DSFVOS19DT01QTEVURQBIUEVfQ0JfSEVBREVSX1ZBTFVFX0NPTVBMRVRFAEhQRV9DQl9DSFVOS19FWFRFTlNJT05fVkFMVUVfQ09NUExFVEUASFBFX0NCX0NIVU5LX0VYVEVOU0lPTl9OQU1FX0NPTVBMRVRFAEhQRV9DQl9NRVNTQUdFX0NPTVBMRVRFAEhQRV9DQl9NRVRIT0RfQ09NUExFVEUASFBFX0NCX0hFQURFUl9GSUVMRF9DT01QTEVURQBERUxFVEUASFBFX0lOVkFMSURfRU9GX1NUQVRFAElOVkFMSURfU1NMX0NFUlRJRklDQVRFAFBBVVNFAE5PX1JFU1BPTlNFAFVOU1VQUE9SVEVEX01FRElBX1RZUEUAR09ORQBOT1RfQUNDRVBUQUJMRQBTRVJWSUNFX1VOQVZBSUxBQkxFAFJBTkdFX05PVF9TQVRJU0ZJQUJMRQBPUklHSU5fSVNfVU5SRUFDSEFCTEUAUkVTUE9OU0VfSVNfU1RBTEUAUFVSR0UATUVSR0UAUkVRVUVTVF9IRUFERVJfRklFTERTX1RPT19MQVJHRQBSRVFVRVNUX0hFQURFUl9UT09fTEFSR0UAUEFZTE9BRF9UT09fTEFSR0UASU5TVUZGSUNJRU5UX1NUT1JBR0UASFBFX1BBVVNFRF9VUEdSQURFAEhQRV9QQVVTRURfSDJfVVBHUkFERQBTT1VSQ0UAQU5OT1VOQ0UAVFJBQ0UASFBFX1VORVhQRUNURURfU1BBQ0UAREVTQ1JJQkUAVU5TVUJTQ1JJQkUAUkVDT1JEAEhQRV9JTlZBTElEX01FVEhPRABOT1RfRk9VTkQAUFJPUEZJTkQAVU5CSU5EAFJFQklORABVTkFVVEhPUklaRUQATUVUSE9EX05PVF9BTExPV0VEAEhUVFBfVkVSU0lPTl9OT1RfU1VQUE9SVEVEAEFMUkVBRFlfUkVQT1JURUQAQUNDRVBURUQATk9UX0lNUExFTUVOVEVEAExPT1BfREVURUNURUQASFBFX0NSX0VYUEVDVEVEAEhQRV9MRl9FWFBFQ1RFRABDUkVBVEVEAElNX1VTRUQASFBFX1BBVVNFRABUSU1FT1VUX09DQ1VSRUQAUEFZTUVOVF9SRVFVSVJFRABQUkVDT05ESVRJT05fUkVRVUlSRUQAUFJPWFlfQVVUSEVOVElDQVRJT05fUkVRVUlSRUQATkVUV09SS19BVVRIRU5USUNBVElPTl9SRVFVSVJFRABMRU5HVEhfUkVRVUlSRUQAU1NMX0NFUlRJRklDQVRFX1JFUVVJUkVEAFVQR1JBREVfUkVRVUlSRUQAUEFHRV9FWFBJUkVEAFBSRUNPTkRJVElPTl9GQUlMRUQARVhQRUNUQVRJT05fRkFJTEVEAFJFVkFMSURBVElPTl9GQUlMRUQAU1NMX0hBTkRTSEFLRV9GQUlMRUQATE9DS0VEAFRSQU5TRk9STUFUSU9OX0FQUExJRUQATk9UX01PRElGSUVEAE5PVF9FWFRFTkRFRABCQU5EV0lEVEhfTElNSVRfRVhDRUVERUQAU0lURV9JU19PVkVSTE9BREVEAEhFQUQARXhwZWN0ZWQgSFRUUC8AAF4TAAAmEwAAMBAAAPAXAACdEwAAFRIAADkXAADwEgAAChAAAHUSAACtEgAAghMAAE8UAAB/EAAAoBUAACMUAACJEgAAixQAAE0VAADUEQAAzxQAABAYAADJFgAA3BYAAMERAADgFwAAuxQAAHQUAAB8FQAA5RQAAAgXAAAfEAAAZRUAAKMUAAAoFQAAAhUAAJkVAAAsEAAAixkAAE8PAADUDgAAahAAAM4QAAACFwAAiQ4AAG4TAAAcEwAAZhQAAFYXAADBEwAAzRMAAGwTAABoFwAAZhcAAF8XAAAiEwAAzg8AAGkOAADYDgAAYxYAAMsTAACqDgAAKBcAACYXAADFEwAAXRYAAOgRAABnEwAAZRMAAPIWAABzEwAAHRcAAPkWAADzEQAAzw4AAM4VAAAMEgAAsxEAAKURAABhEAAAMhcAALsTAEH5NQsBAQBBkDYL4AEBAQIBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEAAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQBB/TcLAQEAQZE4C14CAwICAgICAAACAgACAgACAgICAgICAgICAAQAAAAAAAICAgICAgICAgICAgICAgICAgICAgICAgICAAAAAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAAgACAEH9OQsBAQBBkToLXgIAAgICAgIAAAICAAICAAICAgICAgICAgIAAwAEAAAAAgICAgICAgICAgICAgICAgICAgICAgICAgIAAAACAgICAgICAgICAgICAgICAgICAgICAgICAgICAgACAAIAQfA7Cw1sb3NlZWVwLWFsaXZlAEGJPAsBAQBBoDwL4AEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQBBiT4LAQEAQaA+C+cBAQEBAQEBAQEBAQEBAgEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEAAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQFjaHVua2VkAEGwwAALXwEBAAEBAQEBAAABAQABAQABAQEBAQEBAQEBAAAAAAAAAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAAAAAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEAAQABAEGQwgALIWVjdGlvbmVudC1sZW5ndGhvbnJveHktY29ubmVjdGlvbgBBwMIACy1yYW5zZmVyLWVuY29kaW5ncGdyYWRlDQoNCg0KU00NCg0KVFRQL0NFL1RTUC8AQfnCAAsFAQIAAQMAQZDDAAvgAQQBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAEH5xAALBQECAAEDAEGQxQAL4AEEAQEFAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQBB+cYACwQBAAABAEGRxwAL3wEBAQABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEAAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAEH6yAALBAEAAAIAQZDJAAtfAwQAAAQEBAQEBAQEBAQEBQQEBAQEBAQEBAQEBAAEAAYHBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEAAQABAAEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAAAAAQAQfrKAAsEAQAAAQBBkMsACwEBAEGqywALQQIAAAAAAAADAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwAAAAAAAAMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAEH6zAALBAEAAAEAQZDNAAsBAQBBms0ACwYCAAAAAAIAQbHNAAs6AwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMAAAAAAAADAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwBB8M4AC5YBTk9VTkNFRUNLT1VUTkVDVEVURUNSSUJFTFVTSEVURUFEU0VBUkNIUkdFQ1RJVklUWUxFTkRBUlZFT1RJRllQVElPTlNDSFNFQVlTVEFUQ0hHRU9SRElSRUNUT1JUUkNIUEFSQU1FVEVSVVJDRUJTQ1JJQkVBUkRPV05BQ0VJTkROS0NLVUJTQ1JJQkVIVFRQL0FEVFAv', 'base64')\n","'use strict'\n\nconst { Buffer } = require('node:buffer')\n\nmodule.exports = Buffer.from('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', 'base64')\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.enumToMap = void 0;\nfunction enumToMap(obj) {\n    const res = {};\n    Object.keys(obj).forEach((key) => {\n        const value = obj[key];\n        if (typeof value === 'number') {\n            res[key] = value;\n        }\n    });\n    return res;\n}\nexports.enumToMap = enumToMap;\n//# sourceMappingURL=utils.js.map","'use strict'\n\nconst { kClients } = require('../core/symbols')\nconst Agent = require('../dispatcher/agent')\nconst {\n  kAgent,\n  kMockAgentSet,\n  kMockAgentGet,\n  kDispatches,\n  kIsMockActive,\n  kNetConnect,\n  kGetNetConnect,\n  kOptions,\n  kFactory\n} = require('./mock-symbols')\nconst MockClient = require('./mock-client')\nconst MockPool = require('./mock-pool')\nconst { matchValue, buildMockOptions } = require('./mock-utils')\nconst { InvalidArgumentError, UndiciError } = require('../core/errors')\nconst Dispatcher = require('../dispatcher/dispatcher')\nconst Pluralizer = require('./pluralizer')\nconst PendingInterceptorsFormatter = require('./pending-interceptors-formatter')\n\nclass MockAgent extends Dispatcher {\n  constructor (opts) {\n    super(opts)\n\n    this[kNetConnect] = true\n    this[kIsMockActive] = true\n\n    // Instantiate Agent and encapsulate\n    if ((opts?.agent && typeof opts.agent.dispatch !== 'function')) {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n    const agent = opts?.agent ? opts.agent : new Agent(opts)\n    this[kAgent] = agent\n\n    this[kClients] = agent[kClients]\n    this[kOptions] = buildMockOptions(opts)\n  }\n\n  get (origin) {\n    let dispatcher = this[kMockAgentGet](origin)\n\n    if (!dispatcher) {\n      dispatcher = this[kFactory](origin)\n      this[kMockAgentSet](origin, dispatcher)\n    }\n    return dispatcher\n  }\n\n  dispatch (opts, handler) {\n    // Call MockAgent.get to perform additional setup before dispatching as normal\n    this.get(opts.origin)\n    return this[kAgent].dispatch(opts, handler)\n  }\n\n  async close () {\n    await this[kAgent].close()\n    this[kClients].clear()\n  }\n\n  deactivate () {\n    this[kIsMockActive] = false\n  }\n\n  activate () {\n    this[kIsMockActive] = true\n  }\n\n  enableNetConnect (matcher) {\n    if (typeof matcher === 'string' || typeof matcher === 'function' || matcher instanceof RegExp) {\n      if (Array.isArray(this[kNetConnect])) {\n        this[kNetConnect].push(matcher)\n      } else {\n        this[kNetConnect] = [matcher]\n      }\n    } else if (typeof matcher === 'undefined') {\n      this[kNetConnect] = true\n    } else {\n      throw new InvalidArgumentError('Unsupported matcher. Must be one of String|Function|RegExp.')\n    }\n  }\n\n  disableNetConnect () {\n    this[kNetConnect] = false\n  }\n\n  // This is required to bypass issues caused by using global symbols - see:\n  // https://github.com/nodejs/undici/issues/1447\n  get isMockActive () {\n    return this[kIsMockActive]\n  }\n\n  [kMockAgentSet] (origin, dispatcher) {\n    this[kClients].set(origin, dispatcher)\n  }\n\n  [kFactory] (origin) {\n    const mockOptions = Object.assign({ agent: this }, this[kOptions])\n    return this[kOptions] && this[kOptions].connections === 1\n      ? new MockClient(origin, mockOptions)\n      : new MockPool(origin, mockOptions)\n  }\n\n  [kMockAgentGet] (origin) {\n    // First check if we can immediately find it\n    const client = this[kClients].get(origin)\n    if (client) {\n      return client\n    }\n\n    // If the origin is not a string create a dummy parent pool and return to user\n    if (typeof origin !== 'string') {\n      const dispatcher = this[kFactory]('http://localhost:9999')\n      this[kMockAgentSet](origin, dispatcher)\n      return dispatcher\n    }\n\n    // If we match, create a pool and assign the same dispatches\n    for (const [keyMatcher, nonExplicitDispatcher] of Array.from(this[kClients])) {\n      if (nonExplicitDispatcher && typeof keyMatcher !== 'string' && matchValue(keyMatcher, origin)) {\n        const dispatcher = this[kFactory](origin)\n        this[kMockAgentSet](origin, dispatcher)\n        dispatcher[kDispatches] = nonExplicitDispatcher[kDispatches]\n        return dispatcher\n      }\n    }\n  }\n\n  [kGetNetConnect] () {\n    return this[kNetConnect]\n  }\n\n  pendingInterceptors () {\n    const mockAgentClients = this[kClients]\n\n    return Array.from(mockAgentClients.entries())\n      .flatMap(([origin, scope]) => scope[kDispatches].map(dispatch => ({ ...dispatch, origin })))\n      .filter(({ pending }) => pending)\n  }\n\n  assertNoPendingInterceptors ({ pendingInterceptorsFormatter = new PendingInterceptorsFormatter() } = {}) {\n    const pending = this.pendingInterceptors()\n\n    if (pending.length === 0) {\n      return\n    }\n\n    const pluralizer = new Pluralizer('interceptor', 'interceptors').pluralize(pending.length)\n\n    throw new UndiciError(`\n${pluralizer.count} ${pluralizer.noun} ${pluralizer.is} pending:\n\n${pendingInterceptorsFormatter.format(pending)}\n`.trim())\n  }\n}\n\nmodule.exports = MockAgent\n","'use strict'\n\nconst { promisify } = require('node:util')\nconst Client = require('../dispatcher/client')\nconst { buildMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kMockAgent,\n  kClose,\n  kOriginalClose,\n  kOrigin,\n  kOriginalDispatch,\n  kConnected\n} = require('./mock-symbols')\nconst { MockInterceptor } = require('./mock-interceptor')\nconst Symbols = require('../core/symbols')\nconst { InvalidArgumentError } = require('../core/errors')\n\n/**\n * MockClient provides an API that extends the Client to influence the mockDispatches.\n */\nclass MockClient extends Client {\n  constructor (origin, opts) {\n    super(origin, opts)\n\n    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n\n    this[kMockAgent] = opts.agent\n    this[kOrigin] = origin\n    this[kDispatches] = []\n    this[kConnected] = 1\n    this[kOriginalDispatch] = this.dispatch\n    this[kOriginalClose] = this.close.bind(this)\n\n    this.dispatch = buildMockDispatch.call(this)\n    this.close = this[kClose]\n  }\n\n  get [Symbols.kConnected] () {\n    return this[kConnected]\n  }\n\n  /**\n   * Sets up the base interceptor for mocking replies from undici.\n   */\n  intercept (opts) {\n    return new MockInterceptor(opts, this[kDispatches])\n  }\n\n  async [kClose] () {\n    await promisify(this[kOriginalClose])()\n    this[kConnected] = 0\n    this[kMockAgent][Symbols.kClients].delete(this[kOrigin])\n  }\n}\n\nmodule.exports = MockClient\n","'use strict'\n\nconst { UndiciError } = require('../core/errors')\n\nconst kMockNotMatchedError = Symbol.for('undici.error.UND_MOCK_ERR_MOCK_NOT_MATCHED')\n\n/**\n * The request does not match any registered mock dispatches.\n */\nclass MockNotMatchedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, MockNotMatchedError)\n    this.name = 'MockNotMatchedError'\n    this.message = message || 'The request does not match any registered mock dispatches'\n    this.code = 'UND_MOCK_ERR_MOCK_NOT_MATCHED'\n  }\n\n  static [Symbol.hasInstance] (instance) {\n    return instance && instance[kMockNotMatchedError] === true\n  }\n\n  [kMockNotMatchedError] = true\n}\n\nmodule.exports = {\n  MockNotMatchedError\n}\n","'use strict'\n\nconst { getResponseData, buildKey, addMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kDispatchKey,\n  kDefaultHeaders,\n  kDefaultTrailers,\n  kContentLength,\n  kMockDispatch\n} = require('./mock-symbols')\nconst { InvalidArgumentError } = require('../core/errors')\nconst { buildURL } = require('../core/util')\n\n/**\n * Defines the scope API for an interceptor reply\n */\nclass MockScope {\n  constructor (mockDispatch) {\n    this[kMockDispatch] = mockDispatch\n  }\n\n  /**\n   * Delay a reply by a set amount in ms.\n   */\n  delay (waitInMs) {\n    if (typeof waitInMs !== 'number' || !Number.isInteger(waitInMs) || waitInMs <= 0) {\n      throw new InvalidArgumentError('waitInMs must be a valid integer > 0')\n    }\n\n    this[kMockDispatch].delay = waitInMs\n    return this\n  }\n\n  /**\n   * For a defined reply, never mark as consumed.\n   */\n  persist () {\n    this[kMockDispatch].persist = true\n    return this\n  }\n\n  /**\n   * Allow one to define a reply for a set amount of matching requests.\n   */\n  times (repeatTimes) {\n    if (typeof repeatTimes !== 'number' || !Number.isInteger(repeatTimes) || repeatTimes <= 0) {\n      throw new InvalidArgumentError('repeatTimes must be a valid integer > 0')\n    }\n\n    this[kMockDispatch].times = repeatTimes\n    return this\n  }\n}\n\n/**\n * Defines an interceptor for a Mock\n */\nclass MockInterceptor {\n  constructor (opts, mockDispatches) {\n    if (typeof opts !== 'object') {\n      throw new InvalidArgumentError('opts must be an object')\n    }\n    if (typeof opts.path === 'undefined') {\n      throw new InvalidArgumentError('opts.path must be defined')\n    }\n    if (typeof opts.method === 'undefined') {\n      opts.method = 'GET'\n    }\n    // See https://github.com/nodejs/undici/issues/1245\n    // As per RFC 3986, clients are not supposed to send URI\n    // fragments to servers when they retrieve a document,\n    if (typeof opts.path === 'string') {\n      if (opts.query) {\n        opts.path = buildURL(opts.path, opts.query)\n      } else {\n        // Matches https://github.com/nodejs/undici/blob/main/lib/web/fetch/index.js#L1811\n        const parsedURL = new URL(opts.path, 'data://')\n        opts.path = parsedURL.pathname + parsedURL.search\n      }\n    }\n    if (typeof opts.method === 'string') {\n      opts.method = opts.method.toUpperCase()\n    }\n\n    this[kDispatchKey] = buildKey(opts)\n    this[kDispatches] = mockDispatches\n    this[kDefaultHeaders] = {}\n    this[kDefaultTrailers] = {}\n    this[kContentLength] = false\n  }\n\n  createMockScopeDispatchData ({ statusCode, data, responseOptions }) {\n    const responseData = getResponseData(data)\n    const contentLength = this[kContentLength] ? { 'content-length': responseData.length } : {}\n    const headers = { ...this[kDefaultHeaders], ...contentLength, ...responseOptions.headers }\n    const trailers = { ...this[kDefaultTrailers], ...responseOptions.trailers }\n\n    return { statusCode, data, headers, trailers }\n  }\n\n  validateReplyParameters (replyParameters) {\n    if (typeof replyParameters.statusCode === 'undefined') {\n      throw new InvalidArgumentError('statusCode must be defined')\n    }\n    if (typeof replyParameters.responseOptions !== 'object' || replyParameters.responseOptions === null) {\n      throw new InvalidArgumentError('responseOptions must be an object')\n    }\n  }\n\n  /**\n   * Mock an undici request with a defined reply.\n   */\n  reply (replyOptionsCallbackOrStatusCode) {\n    // Values of reply aren't available right now as they\n    // can only be available when the reply callback is invoked.\n    if (typeof replyOptionsCallbackOrStatusCode === 'function') {\n      // We'll first wrap the provided callback in another function,\n      // this function will properly resolve the data from the callback\n      // when invoked.\n      const wrappedDefaultsCallback = (opts) => {\n        // Our reply options callback contains the parameter for statusCode, data and options.\n        const resolvedData = replyOptionsCallbackOrStatusCode(opts)\n\n        // Check if it is in the right format\n        if (typeof resolvedData !== 'object' || resolvedData === null) {\n          throw new InvalidArgumentError('reply options callback must return an object')\n        }\n\n        const replyParameters = { data: '', responseOptions: {}, ...resolvedData }\n        this.validateReplyParameters(replyParameters)\n        // Since the values can be obtained immediately we return them\n        // from this higher order function that will be resolved later.\n        return {\n          ...this.createMockScopeDispatchData(replyParameters)\n        }\n      }\n\n      // Add usual dispatch data, but this time set the data parameter to function that will eventually provide data.\n      const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], wrappedDefaultsCallback)\n      return new MockScope(newMockDispatch)\n    }\n\n    // We can have either one or three parameters, if we get here,\n    // we should have 1-3 parameters. So we spread the arguments of\n    // this function to obtain the parameters, since replyData will always\n    // just be the statusCode.\n    const replyParameters = {\n      statusCode: replyOptionsCallbackOrStatusCode,\n      data: arguments[1] === undefined ? '' : arguments[1],\n      responseOptions: arguments[2] === undefined ? {} : arguments[2]\n    }\n    this.validateReplyParameters(replyParameters)\n\n    // Send in-already provided data like usual\n    const dispatchData = this.createMockScopeDispatchData(replyParameters)\n    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], dispatchData)\n    return new MockScope(newMockDispatch)\n  }\n\n  /**\n   * Mock an undici request with a defined error.\n   */\n  replyWithError (error) {\n    if (typeof error === 'undefined') {\n      throw new InvalidArgumentError('error must be defined')\n    }\n\n    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], { error })\n    return new MockScope(newMockDispatch)\n  }\n\n  /**\n   * Set default reply headers on the interceptor for subsequent replies\n   */\n  defaultReplyHeaders (headers) {\n    if (typeof headers === 'undefined') {\n      throw new InvalidArgumentError('headers must be defined')\n    }\n\n    this[kDefaultHeaders] = headers\n    return this\n  }\n\n  /**\n   * Set default reply trailers on the interceptor for subsequent replies\n   */\n  defaultReplyTrailers (trailers) {\n    if (typeof trailers === 'undefined') {\n      throw new InvalidArgumentError('trailers must be defined')\n    }\n\n    this[kDefaultTrailers] = trailers\n    return this\n  }\n\n  /**\n   * Set reply content length header for replies on the interceptor\n   */\n  replyContentLength () {\n    this[kContentLength] = true\n    return this\n  }\n}\n\nmodule.exports.MockInterceptor = MockInterceptor\nmodule.exports.MockScope = MockScope\n","'use strict'\n\nconst { promisify } = require('node:util')\nconst Pool = require('../dispatcher/pool')\nconst { buildMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kMockAgent,\n  kClose,\n  kOriginalClose,\n  kOrigin,\n  kOriginalDispatch,\n  kConnected\n} = require('./mock-symbols')\nconst { MockInterceptor } = require('./mock-interceptor')\nconst Symbols = require('../core/symbols')\nconst { InvalidArgumentError } = require('../core/errors')\n\n/**\n * MockPool provides an API that extends the Pool to influence the mockDispatches.\n */\nclass MockPool extends Pool {\n  constructor (origin, opts) {\n    super(origin, opts)\n\n    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n\n    this[kMockAgent] = opts.agent\n    this[kOrigin] = origin\n    this[kDispatches] = []\n    this[kConnected] = 1\n    this[kOriginalDispatch] = this.dispatch\n    this[kOriginalClose] = this.close.bind(this)\n\n    this.dispatch = buildMockDispatch.call(this)\n    this.close = this[kClose]\n  }\n\n  get [Symbols.kConnected] () {\n    return this[kConnected]\n  }\n\n  /**\n   * Sets up the base interceptor for mocking replies from undici.\n   */\n  intercept (opts) {\n    return new MockInterceptor(opts, this[kDispatches])\n  }\n\n  async [kClose] () {\n    await promisify(this[kOriginalClose])()\n    this[kConnected] = 0\n    this[kMockAgent][Symbols.kClients].delete(this[kOrigin])\n  }\n}\n\nmodule.exports = MockPool\n","'use strict'\n\nmodule.exports = {\n  kAgent: Symbol('agent'),\n  kOptions: Symbol('options'),\n  kFactory: Symbol('factory'),\n  kDispatches: Symbol('dispatches'),\n  kDispatchKey: Symbol('dispatch key'),\n  kDefaultHeaders: Symbol('default headers'),\n  kDefaultTrailers: Symbol('default trailers'),\n  kContentLength: Symbol('content length'),\n  kMockAgent: Symbol('mock agent'),\n  kMockAgentSet: Symbol('mock agent set'),\n  kMockAgentGet: Symbol('mock agent get'),\n  kMockDispatch: Symbol('mock dispatch'),\n  kClose: Symbol('close'),\n  kOriginalClose: Symbol('original agent close'),\n  kOrigin: Symbol('origin'),\n  kIsMockActive: Symbol('is mock active'),\n  kNetConnect: Symbol('net connect'),\n  kGetNetConnect: Symbol('get net connect'),\n  kConnected: Symbol('connected')\n}\n","'use strict'\n\nconst { MockNotMatchedError } = require('./mock-errors')\nconst {\n  kDispatches,\n  kMockAgent,\n  kOriginalDispatch,\n  kOrigin,\n  kGetNetConnect\n} = require('./mock-symbols')\nconst { buildURL } = require('../core/util')\nconst { STATUS_CODES } = require('node:http')\nconst {\n  types: {\n    isPromise\n  }\n} = require('node:util')\n\nfunction matchValue (match, value) {\n  if (typeof match === 'string') {\n    return match === value\n  }\n  if (match instanceof RegExp) {\n    return match.test(value)\n  }\n  if (typeof match === 'function') {\n    return match(value) === true\n  }\n  return false\n}\n\nfunction lowerCaseEntries (headers) {\n  return Object.fromEntries(\n    Object.entries(headers).map(([headerName, headerValue]) => {\n      return [headerName.toLocaleLowerCase(), headerValue]\n    })\n  )\n}\n\n/**\n * @param {import('../../index').Headers|string[]|Record<string, string>} headers\n * @param {string} key\n */\nfunction getHeaderByName (headers, key) {\n  if (Array.isArray(headers)) {\n    for (let i = 0; i < headers.length; i += 2) {\n      if (headers[i].toLocaleLowerCase() === key.toLocaleLowerCase()) {\n        return headers[i + 1]\n      }\n    }\n\n    return undefined\n  } else if (typeof headers.get === 'function') {\n    return headers.get(key)\n  } else {\n    return lowerCaseEntries(headers)[key.toLocaleLowerCase()]\n  }\n}\n\n/** @param {string[]} headers */\nfunction buildHeadersFromArray (headers) { // fetch HeadersList\n  const clone = headers.slice()\n  const entries = []\n  for (let index = 0; index < clone.length; index += 2) {\n    entries.push([clone[index], clone[index + 1]])\n  }\n  return Object.fromEntries(entries)\n}\n\nfunction matchHeaders (mockDispatch, headers) {\n  if (typeof mockDispatch.headers === 'function') {\n    if (Array.isArray(headers)) { // fetch HeadersList\n      headers = buildHeadersFromArray(headers)\n    }\n    return mockDispatch.headers(headers ? lowerCaseEntries(headers) : {})\n  }\n  if (typeof mockDispatch.headers === 'undefined') {\n    return true\n  }\n  if (typeof headers !== 'object' || typeof mockDispatch.headers !== 'object') {\n    return false\n  }\n\n  for (const [matchHeaderName, matchHeaderValue] of Object.entries(mockDispatch.headers)) {\n    const headerValue = getHeaderByName(headers, matchHeaderName)\n\n    if (!matchValue(matchHeaderValue, headerValue)) {\n      return false\n    }\n  }\n  return true\n}\n\nfunction safeUrl (path) {\n  if (typeof path !== 'string') {\n    return path\n  }\n\n  const pathSegments = path.split('?')\n\n  if (pathSegments.length !== 2) {\n    return path\n  }\n\n  const qp = new URLSearchParams(pathSegments.pop())\n  qp.sort()\n  return [...pathSegments, qp.toString()].join('?')\n}\n\nfunction matchKey (mockDispatch, { path, method, body, headers }) {\n  const pathMatch = matchValue(mockDispatch.path, path)\n  const methodMatch = matchValue(mockDispatch.method, method)\n  const bodyMatch = typeof mockDispatch.body !== 'undefined' ? matchValue(mockDispatch.body, body) : true\n  const headersMatch = matchHeaders(mockDispatch, headers)\n  return pathMatch && methodMatch && bodyMatch && headersMatch\n}\n\nfunction getResponseData (data) {\n  if (Buffer.isBuffer(data)) {\n    return data\n  } else if (data instanceof Uint8Array) {\n    return data\n  } else if (data instanceof ArrayBuffer) {\n    return data\n  } else if (typeof data === 'object') {\n    return JSON.stringify(data)\n  } else {\n    return data.toString()\n  }\n}\n\nfunction getMockDispatch (mockDispatches, key) {\n  const basePath = key.query ? buildURL(key.path, key.query) : key.path\n  const resolvedPath = typeof basePath === 'string' ? safeUrl(basePath) : basePath\n\n  // Match path\n  let matchedMockDispatches = mockDispatches.filter(({ consumed }) => !consumed).filter(({ path }) => matchValue(safeUrl(path), resolvedPath))\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for path '${resolvedPath}'`)\n  }\n\n  // Match method\n  matchedMockDispatches = matchedMockDispatches.filter(({ method }) => matchValue(method, key.method))\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for method '${key.method}' on path '${resolvedPath}'`)\n  }\n\n  // Match body\n  matchedMockDispatches = matchedMockDispatches.filter(({ body }) => typeof body !== 'undefined' ? matchValue(body, key.body) : true)\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for body '${key.body}' on path '${resolvedPath}'`)\n  }\n\n  // Match headers\n  matchedMockDispatches = matchedMockDispatches.filter((mockDispatch) => matchHeaders(mockDispatch, key.headers))\n  if (matchedMockDispatches.length === 0) {\n    const headers = typeof key.headers === 'object' ? JSON.stringify(key.headers) : key.headers\n    throw new MockNotMatchedError(`Mock dispatch not matched for headers '${headers}' on path '${resolvedPath}'`)\n  }\n\n  return matchedMockDispatches[0]\n}\n\nfunction addMockDispatch (mockDispatches, key, data) {\n  const baseData = { timesInvoked: 0, times: 1, persist: false, consumed: false }\n  const replyData = typeof data === 'function' ? { callback: data } : { ...data }\n  const newMockDispatch = { ...baseData, ...key, pending: true, data: { error: null, ...replyData } }\n  mockDispatches.push(newMockDispatch)\n  return newMockDispatch\n}\n\nfunction deleteMockDispatch (mockDispatches, key) {\n  const index = mockDispatches.findIndex(dispatch => {\n    if (!dispatch.consumed) {\n      return false\n    }\n    return matchKey(dispatch, key)\n  })\n  if (index !== -1) {\n    mockDispatches.splice(index, 1)\n  }\n}\n\nfunction buildKey (opts) {\n  const { path, method, body, headers, query } = opts\n  return {\n    path,\n    method,\n    body,\n    headers,\n    query\n  }\n}\n\nfunction generateKeyValues (data) {\n  const keys = Object.keys(data)\n  const result = []\n  for (let i = 0; i < keys.length; ++i) {\n    const key = keys[i]\n    const value = data[key]\n    const name = Buffer.from(`${key}`)\n    if (Array.isArray(value)) {\n      for (let j = 0; j < value.length; ++j) {\n        result.push(name, Buffer.from(`${value[j]}`))\n      }\n    } else {\n      result.push(name, Buffer.from(`${value}`))\n    }\n  }\n  return result\n}\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\n * @param {number} statusCode\n */\nfunction getStatusText (statusCode) {\n  return STATUS_CODES[statusCode] || 'unknown'\n}\n\nasync function getResponse (body) {\n  const buffers = []\n  for await (const data of body) {\n    buffers.push(data)\n  }\n  return Buffer.concat(buffers).toString('utf8')\n}\n\n/**\n * Mock dispatch function used to simulate undici dispatches\n */\nfunction mockDispatch (opts, handler) {\n  // Get mock dispatch from built key\n  const key = buildKey(opts)\n  const mockDispatch = getMockDispatch(this[kDispatches], key)\n\n  mockDispatch.timesInvoked++\n\n  // Here's where we resolve a callback if a callback is present for the dispatch data.\n  if (mockDispatch.data.callback) {\n    mockDispatch.data = { ...mockDispatch.data, ...mockDispatch.data.callback(opts) }\n  }\n\n  // Parse mockDispatch data\n  const { data: { statusCode, data, headers, trailers, error }, delay, persist } = mockDispatch\n  const { timesInvoked, times } = mockDispatch\n\n  // If it's used up and not persistent, mark as consumed\n  mockDispatch.consumed = !persist && timesInvoked >= times\n  mockDispatch.pending = timesInvoked < times\n\n  // If specified, trigger dispatch error\n  if (error !== null) {\n    deleteMockDispatch(this[kDispatches], key)\n    handler.onError(error)\n    return true\n  }\n\n  // Handle the request with a delay if necessary\n  if (typeof delay === 'number' && delay > 0) {\n    setTimeout(() => {\n      handleReply(this[kDispatches])\n    }, delay)\n  } else {\n    handleReply(this[kDispatches])\n  }\n\n  function handleReply (mockDispatches, _data = data) {\n    // fetch's HeadersList is a 1D string array\n    const optsHeaders = Array.isArray(opts.headers)\n      ? buildHeadersFromArray(opts.headers)\n      : opts.headers\n    const body = typeof _data === 'function'\n      ? _data({ ...opts, headers: optsHeaders })\n      : _data\n\n    // util.types.isPromise is likely needed for jest.\n    if (isPromise(body)) {\n      // If handleReply is asynchronous, throwing an error\n      // in the callback will reject the promise, rather than\n      // synchronously throw the error, which breaks some tests.\n      // Rather, we wait for the callback to resolve if it is a\n      // promise, and then re-run handleReply with the new body.\n      body.then((newData) => handleReply(mockDispatches, newData))\n      return\n    }\n\n    const responseData = getResponseData(body)\n    const responseHeaders = generateKeyValues(headers)\n    const responseTrailers = generateKeyValues(trailers)\n\n    handler.onConnect?.(err => handler.onError(err), null)\n    handler.onHeaders?.(statusCode, responseHeaders, resume, getStatusText(statusCode))\n    handler.onData?.(Buffer.from(responseData))\n    handler.onComplete?.(responseTrailers)\n    deleteMockDispatch(mockDispatches, key)\n  }\n\n  function resume () {}\n\n  return true\n}\n\nfunction buildMockDispatch () {\n  const agent = this[kMockAgent]\n  const origin = this[kOrigin]\n  const originalDispatch = this[kOriginalDispatch]\n\n  return function dispatch (opts, handler) {\n    if (agent.isMockActive) {\n      try {\n        mockDispatch.call(this, opts, handler)\n      } catch (error) {\n        if (error instanceof MockNotMatchedError) {\n          const netConnect = agent[kGetNetConnect]()\n          if (netConnect === false) {\n            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect disabled)`)\n          }\n          if (checkNetConnect(netConnect, origin)) {\n            originalDispatch.call(this, opts, handler)\n          } else {\n            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect is not enabled for this origin)`)\n          }\n        } else {\n          throw error\n        }\n      }\n    } else {\n      originalDispatch.call(this, opts, handler)\n    }\n  }\n}\n\nfunction checkNetConnect (netConnect, origin) {\n  const url = new URL(origin)\n  if (netConnect === true) {\n    return true\n  } else if (Array.isArray(netConnect) && netConnect.some((matcher) => matchValue(matcher, url.host))) {\n    return true\n  }\n  return false\n}\n\nfunction buildMockOptions (opts) {\n  if (opts) {\n    const { agent, ...mockOptions } = opts\n    return mockOptions\n  }\n}\n\nmodule.exports = {\n  getResponseData,\n  getMockDispatch,\n  addMockDispatch,\n  deleteMockDispatch,\n  buildKey,\n  generateKeyValues,\n  matchValue,\n  getResponse,\n  getStatusText,\n  mockDispatch,\n  buildMockDispatch,\n  checkNetConnect,\n  buildMockOptions,\n  getHeaderByName,\n  buildHeadersFromArray\n}\n","'use strict'\n\nconst { Transform } = require('node:stream')\nconst { Console } = require('node:console')\n\nconst PERSISTENT = process.versions.icu ? '' : 'Y '\nconst NOT_PERSISTENT = process.versions.icu ? '' : 'N '\n\n/**\n * Gets the output of `console.table()` as a string.\n */\nmodule.exports = class PendingInterceptorsFormatter {\n  constructor ({ disableColors } = {}) {\n    this.transform = new Transform({\n      transform (chunk, _enc, cb) {\n        cb(null, chunk)\n      }\n    })\n\n    this.logger = new Console({\n      stdout: this.transform,\n      inspectOptions: {\n        colors: !disableColors && !process.env.CI\n      }\n    })\n  }\n\n  format (pendingInterceptors) {\n    const withPrettyHeaders = pendingInterceptors.map(\n      ({ method, path, data: { statusCode }, persist, times, timesInvoked, origin }) => ({\n        Method: method,\n        Origin: origin,\n        Path: path,\n        'Status code': statusCode,\n        Persistent: persist ? PERSISTENT : NOT_PERSISTENT,\n        Invocations: timesInvoked,\n        Remaining: persist ? Infinity : times - timesInvoked\n      }))\n\n    this.logger.table(withPrettyHeaders)\n    return this.transform.read().toString()\n  }\n}\n","'use strict'\n\nconst singulars = {\n  pronoun: 'it',\n  is: 'is',\n  was: 'was',\n  this: 'this'\n}\n\nconst plurals = {\n  pronoun: 'they',\n  is: 'are',\n  was: 'were',\n  this: 'these'\n}\n\nmodule.exports = class Pluralizer {\n  constructor (singular, plural) {\n    this.singular = singular\n    this.plural = plural\n  }\n\n  pluralize (count) {\n    const one = count === 1\n    const keys = one ? singulars : plurals\n    const noun = one ? this.singular : this.plural\n    return { ...keys, count, noun }\n  }\n}\n","'use strict'\n\n/**\n * This module offers an optimized timer implementation designed for scenarios\n * where high precision is not critical.\n *\n * The timer achieves faster performance by using a low-resolution approach,\n * with an accuracy target of within 500ms. This makes it particularly useful\n * for timers with delays of 1 second or more, where exact timing is less\n * crucial.\n *\n * It's important to note that Node.js timers are inherently imprecise, as\n * delays can occur due to the event loop being blocked by other operations.\n * Consequently, timers may trigger later than their scheduled time.\n */\n\n/**\n * The fastNow variable contains the internal fast timer clock value.\n *\n * @type {number}\n */\nlet fastNow = 0\n\n/**\n * RESOLUTION_MS represents the target resolution time in milliseconds.\n *\n * @type {number}\n * @default 1000\n */\nconst RESOLUTION_MS = 1e3\n\n/**\n * TICK_MS defines the desired interval in milliseconds between each tick.\n * The target value is set to half the resolution time, minus 1 ms, to account\n * for potential event loop overhead.\n *\n * @type {number}\n * @default 499\n */\nconst TICK_MS = (RESOLUTION_MS >> 1) - 1\n\n/**\n * fastNowTimeout is a Node.js timer used to manage and process\n * the FastTimers stored in the `fastTimers` array.\n *\n * @type {NodeJS.Timeout}\n */\nlet fastNowTimeout\n\n/**\n * The kFastTimer symbol is used to identify FastTimer instances.\n *\n * @type {Symbol}\n */\nconst kFastTimer = Symbol('kFastTimer')\n\n/**\n * The fastTimers array contains all active FastTimers.\n *\n * @type {FastTimer[]}\n */\nconst fastTimers = []\n\n/**\n * These constants represent the various states of a FastTimer.\n */\n\n/**\n * The `NOT_IN_LIST` constant indicates that the FastTimer is not included\n * in the `fastTimers` array. Timers with this status will not be processed\n * during the next tick by the `onTick` function.\n *\n * A FastTimer can be re-added to the `fastTimers` array by invoking the\n * `refresh` method on the FastTimer instance.\n *\n * @type {-2}\n */\nconst NOT_IN_LIST = -2\n\n/**\n * The `TO_BE_CLEARED` constant indicates that the FastTimer is scheduled\n * for removal from the `fastTimers` array. A FastTimer in this state will\n * be removed in the next tick by the `onTick` function and will no longer\n * be processed.\n *\n * This status is also set when the `clear` method is called on the FastTimer instance.\n *\n * @type {-1}\n */\nconst TO_BE_CLEARED = -1\n\n/**\n * The `PENDING` constant signifies that the FastTimer is awaiting processing\n * in the next tick by the `onTick` function. Timers with this status will have\n * their `_idleStart` value set and their status updated to `ACTIVE` in the next tick.\n *\n * @type {0}\n */\nconst PENDING = 0\n\n/**\n * The `ACTIVE` constant indicates that the FastTimer is active and waiting\n * for its timer to expire. During the next tick, the `onTick` function will\n * check if the timer has expired, and if so, it will execute the associated callback.\n *\n * @type {1}\n */\nconst ACTIVE = 1\n\n/**\n * The onTick function processes the fastTimers array.\n *\n * @returns {void}\n */\nfunction onTick () {\n  /**\n   * Increment the fastNow value by the TICK_MS value, despite the actual time\n   * that has passed since the last tick. This approach ensures independence\n   * from the system clock and delays caused by a blocked event loop.\n   *\n   * @type {number}\n   */\n  fastNow += TICK_MS\n\n  /**\n   * The `idx` variable is used to iterate over the `fastTimers` array.\n   * Expired timers are removed by replacing them with the last element in the array.\n   * Consequently, `idx` is only incremented when the current element is not removed.\n   *\n   * @type {number}\n   */\n  let idx = 0\n\n  /**\n   * The len variable will contain the length of the fastTimers array\n   * and will be decremented when a FastTimer should be removed from the\n   * fastTimers array.\n   *\n   * @type {number}\n   */\n  let len = fastTimers.length\n\n  while (idx < len) {\n    /**\n     * @type {FastTimer}\n     */\n    const timer = fastTimers[idx]\n\n    // If the timer is in the ACTIVE state and the timer has expired, it will\n    // be processed in the next tick.\n    if (timer._state === PENDING) {\n      // Set the _idleStart value to the fastNow value minus the TICK_MS value\n      // to account for the time the timer was in the PENDING state.\n      timer._idleStart = fastNow - TICK_MS\n      timer._state = ACTIVE\n    } else if (\n      timer._state === ACTIVE &&\n      fastNow >= timer._idleStart + timer._idleTimeout\n    ) {\n      timer._state = TO_BE_CLEARED\n      timer._idleStart = -1\n      timer._onTimeout(timer._timerArg)\n    }\n\n    if (timer._state === TO_BE_CLEARED) {\n      timer._state = NOT_IN_LIST\n\n      // Move the last element to the current index and decrement len if it is\n      // not the only element in the array.\n      if (--len !== 0) {\n        fastTimers[idx] = fastTimers[len]\n      }\n    } else {\n      ++idx\n    }\n  }\n\n  // Set the length of the fastTimers array to the new length and thus\n  // removing the excess FastTimers elements from the array.\n  fastTimers.length = len\n\n  // If there are still active FastTimers in the array, refresh the Timer.\n  // If there are no active FastTimers, the timer will be refreshed again\n  // when a new FastTimer is instantiated.\n  if (fastTimers.length !== 0) {\n    refreshTimeout()\n  }\n}\n\nfunction refreshTimeout () {\n  // If the fastNowTimeout is already set, refresh it.\n  if (fastNowTimeout) {\n    fastNowTimeout.refresh()\n  // fastNowTimeout is not instantiated yet, create a new Timer.\n  } else {\n    clearTimeout(fastNowTimeout)\n    fastNowTimeout = setTimeout(onTick, TICK_MS)\n\n    // If the Timer has an unref method, call it to allow the process to exit if\n    // there are no other active handles.\n    if (fastNowTimeout.unref) {\n      fastNowTimeout.unref()\n    }\n  }\n}\n\n/**\n * The `FastTimer` class is a data structure designed to store and manage\n * timer information.\n */\nclass FastTimer {\n  [kFastTimer] = true\n\n  /**\n   * The state of the timer, which can be one of the following:\n   * - NOT_IN_LIST (-2)\n   * - TO_BE_CLEARED (-1)\n   * - PENDING (0)\n   * - ACTIVE (1)\n   *\n   * @type {-2|-1|0|1}\n   * @private\n   */\n  _state = NOT_IN_LIST\n\n  /**\n   * The number of milliseconds to wait before calling the callback.\n   *\n   * @type {number}\n   * @private\n   */\n  _idleTimeout = -1\n\n  /**\n   * The time in milliseconds when the timer was started. This value is used to\n   * calculate when the timer should expire.\n   *\n   * @type {number}\n   * @default -1\n   * @private\n   */\n  _idleStart = -1\n\n  /**\n   * The function to be executed when the timer expires.\n   * @type {Function}\n   * @private\n   */\n  _onTimeout\n\n  /**\n   * The argument to be passed to the callback when the timer expires.\n   *\n   * @type {*}\n   * @private\n   */\n  _timerArg\n\n  /**\n   * @constructor\n   * @param {Function} callback A function to be executed after the timer\n   * expires.\n   * @param {number} delay The time, in milliseconds that the timer should wait\n   * before the specified function or code is executed.\n   * @param {*} arg\n   */\n  constructor (callback, delay, arg) {\n    this._onTimeout = callback\n    this._idleTimeout = delay\n    this._timerArg = arg\n\n    this.refresh()\n  }\n\n  /**\n   * Sets the timer's start time to the current time, and reschedules the timer\n   * to call its callback at the previously specified duration adjusted to the\n   * current time.\n   * Using this on a timer that has already called its callback will reactivate\n   * the timer.\n   *\n   * @returns {void}\n   */\n  refresh () {\n    // In the special case that the timer is not in the list of active timers,\n    // add it back to the array to be processed in the next tick by the onTick\n    // function.\n    if (this._state === NOT_IN_LIST) {\n      fastTimers.push(this)\n    }\n\n    // If the timer is the only active timer, refresh the fastNowTimeout for\n    // better resolution.\n    if (!fastNowTimeout || fastTimers.length === 1) {\n      refreshTimeout()\n    }\n\n    // Setting the state to PENDING will cause the timer to be reset in the\n    // next tick by the onTick function.\n    this._state = PENDING\n  }\n\n  /**\n   * The `clear` method cancels the timer, preventing it from executing.\n   *\n   * @returns {void}\n   * @private\n   */\n  clear () {\n    // Set the state to TO_BE_CLEARED to mark the timer for removal in the next\n    // tick by the onTick function.\n    this._state = TO_BE_CLEARED\n\n    // Reset the _idleStart value to -1 to indicate that the timer is no longer\n    // active.\n    this._idleStart = -1\n  }\n}\n\n/**\n * This module exports a setTimeout and clearTimeout function that can be\n * used as a drop-in replacement for the native functions.\n */\nmodule.exports = {\n  /**\n   * The setTimeout() method sets a timer which executes a function once the\n   * timer expires.\n   * @param {Function} callback A function to be executed after the timer\n   * expires.\n   * @param {number} delay The time, in milliseconds that the timer should\n   * wait before the specified function or code is executed.\n   * @param {*} [arg] An optional argument to be passed to the callback function\n   * when the timer expires.\n   * @returns {NodeJS.Timeout|FastTimer}\n   */\n  setTimeout (callback, delay, arg) {\n    // If the delay is less than or equal to the RESOLUTION_MS value return a\n    // native Node.js Timer instance.\n    return delay <= RESOLUTION_MS\n      ? setTimeout(callback, delay, arg)\n      : new FastTimer(callback, delay, arg)\n  },\n  /**\n   * The clearTimeout method cancels an instantiated Timer previously created\n   * by calling setTimeout.\n   *\n   * @param {NodeJS.Timeout|FastTimer} timeout\n   */\n  clearTimeout (timeout) {\n    // If the timeout is a FastTimer, call its own clear method.\n    if (timeout[kFastTimer]) {\n      /**\n       * @type {FastTimer}\n       */\n      timeout.clear()\n      // Otherwise it is an instance of a native NodeJS.Timeout, so call the\n      // Node.js native clearTimeout function.\n    } else {\n      clearTimeout(timeout)\n    }\n  },\n  /**\n   * The setFastTimeout() method sets a fastTimer which executes a function once\n   * the timer expires.\n   * @param {Function} callback A function to be executed after the timer\n   * expires.\n   * @param {number} delay The time, in milliseconds that the timer should\n   * wait before the specified function or code is executed.\n   * @param {*} [arg] An optional argument to be passed to the callback function\n   * when the timer expires.\n   * @returns {FastTimer}\n   */\n  setFastTimeout (callback, delay, arg) {\n    return new FastTimer(callback, delay, arg)\n  },\n  /**\n   * The clearTimeout method cancels an instantiated FastTimer previously\n   * created by calling setFastTimeout.\n   *\n   * @param {FastTimer} timeout\n   */\n  clearFastTimeout (timeout) {\n    timeout.clear()\n  },\n  /**\n   * The now method returns the value of the internal fast timer clock.\n   *\n   * @returns {number}\n   */\n  now () {\n    return fastNow\n  },\n  /**\n   * Trigger the onTick function to process the fastTimers array.\n   * Exported for testing purposes only.\n   * Marking as deprecated to discourage any use outside of testing.\n   * @deprecated\n   * @param {number} [delay=0] The delay in milliseconds to add to the now value.\n   */\n  tick (delay = 0) {\n    fastNow += delay - RESOLUTION_MS + 1\n    onTick()\n    onTick()\n  },\n  /**\n   * Reset FastTimers.\n   * Exported for testing purposes only.\n   * Marking as deprecated to discourage any use outside of testing.\n   * @deprecated\n   */\n  reset () {\n    fastNow = 0\n    fastTimers.length = 0\n    clearTimeout(fastNowTimeout)\n    fastNowTimeout = null\n  },\n  /**\n   * Exporting for testing purposes only.\n   * Marking as deprecated to discourage any use outside of testing.\n   * @deprecated\n   */\n  kFastTimer\n}\n","'use strict'\n\nconst { kConstruct } = require('./symbols')\nconst { urlEquals, getFieldValues } = require('./util')\nconst { kEnumerableProperty, isDisturbed } = require('../../core/util')\nconst { webidl } = require('../fetch/webidl')\nconst { Response, cloneResponse, fromInnerResponse } = require('../fetch/response')\nconst { Request, fromInnerRequest } = require('../fetch/request')\nconst { kState } = require('../fetch/symbols')\nconst { fetching } = require('../fetch/index')\nconst { urlIsHttpHttpsScheme, createDeferredPromise, readAllBytes } = require('../fetch/util')\nconst assert = require('node:assert')\n\n/**\n * @see https://w3c.github.io/ServiceWorker/#dfn-cache-batch-operation\n * @typedef {Object} CacheBatchOperation\n * @property {'delete' | 'put'} type\n * @property {any} request\n * @property {any} response\n * @property {import('../../types/cache').CacheQueryOptions} options\n */\n\n/**\n * @see https://w3c.github.io/ServiceWorker/#dfn-request-response-list\n * @typedef {[any, any][]} requestResponseList\n */\n\nclass Cache {\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-request-response-list\n   * @type {requestResponseList}\n   */\n  #relevantRequestResponseList\n\n  constructor () {\n    if (arguments[0] !== kConstruct) {\n      webidl.illegalConstructor()\n    }\n\n    webidl.util.markAsUncloneable(this)\n    this.#relevantRequestResponseList = arguments[1]\n  }\n\n  async match (request, options = {}) {\n    webidl.brandCheck(this, Cache)\n\n    const prefix = 'Cache.match'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    request = webidl.converters.RequestInfo(request, prefix, 'request')\n    options = webidl.converters.CacheQueryOptions(options, prefix, 'options')\n\n    const p = this.#internalMatchAll(request, options, 1)\n\n    if (p.length === 0) {\n      return\n    }\n\n    return p[0]\n  }\n\n  async matchAll (request = undefined, options = {}) {\n    webidl.brandCheck(this, Cache)\n\n    const prefix = 'Cache.matchAll'\n    if (request !== undefined) request = webidl.converters.RequestInfo(request, prefix, 'request')\n    options = webidl.converters.CacheQueryOptions(options, prefix, 'options')\n\n    return this.#internalMatchAll(request, options)\n  }\n\n  async add (request) {\n    webidl.brandCheck(this, Cache)\n\n    const prefix = 'Cache.add'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    request = webidl.converters.RequestInfo(request, prefix, 'request')\n\n    // 1.\n    const requests = [request]\n\n    // 2.\n    const responseArrayPromise = this.addAll(requests)\n\n    // 3.\n    return await responseArrayPromise\n  }\n\n  async addAll (requests) {\n    webidl.brandCheck(this, Cache)\n\n    const prefix = 'Cache.addAll'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    // 1.\n    const responsePromises = []\n\n    // 2.\n    const requestList = []\n\n    // 3.\n    for (let request of requests) {\n      if (request === undefined) {\n        throw webidl.errors.conversionFailed({\n          prefix,\n          argument: 'Argument 1',\n          types: ['undefined is not allowed']\n        })\n      }\n\n      request = webidl.converters.RequestInfo(request)\n\n      if (typeof request === 'string') {\n        continue\n      }\n\n      // 3.1\n      const r = request[kState]\n\n      // 3.2\n      if (!urlIsHttpHttpsScheme(r.url) || r.method !== 'GET') {\n        throw webidl.errors.exception({\n          header: prefix,\n          message: 'Expected http/s scheme when method is not GET.'\n        })\n      }\n    }\n\n    // 4.\n    /** @type {ReturnType<typeof fetching>[]} */\n    const fetchControllers = []\n\n    // 5.\n    for (const request of requests) {\n      // 5.1\n      const r = new Request(request)[kState]\n\n      // 5.2\n      if (!urlIsHttpHttpsScheme(r.url)) {\n        throw webidl.errors.exception({\n          header: prefix,\n          message: 'Expected http/s scheme.'\n        })\n      }\n\n      // 5.4\n      r.initiator = 'fetch'\n      r.destination = 'subresource'\n\n      // 5.5\n      requestList.push(r)\n\n      // 5.6\n      const responsePromise = createDeferredPromise()\n\n      // 5.7\n      fetchControllers.push(fetching({\n        request: r,\n        processResponse (response) {\n          // 1.\n          if (response.type === 'error' || response.status === 206 || response.status < 200 || response.status > 299) {\n            responsePromise.reject(webidl.errors.exception({\n              header: 'Cache.addAll',\n              message: 'Received an invalid status code or the request failed.'\n            }))\n          } else if (response.headersList.contains('vary')) { // 2.\n            // 2.1\n            const fieldValues = getFieldValues(response.headersList.get('vary'))\n\n            // 2.2\n            for (const fieldValue of fieldValues) {\n              // 2.2.1\n              if (fieldValue === '*') {\n                responsePromise.reject(webidl.errors.exception({\n                  header: 'Cache.addAll',\n                  message: 'invalid vary field value'\n                }))\n\n                for (const controller of fetchControllers) {\n                  controller.abort()\n                }\n\n                return\n              }\n            }\n          }\n        },\n        processResponseEndOfBody (response) {\n          // 1.\n          if (response.aborted) {\n            responsePromise.reject(new DOMException('aborted', 'AbortError'))\n            return\n          }\n\n          // 2.\n          responsePromise.resolve(response)\n        }\n      }))\n\n      // 5.8\n      responsePromises.push(responsePromise.promise)\n    }\n\n    // 6.\n    const p = Promise.all(responsePromises)\n\n    // 7.\n    const responses = await p\n\n    // 7.1\n    const operations = []\n\n    // 7.2\n    let index = 0\n\n    // 7.3\n    for (const response of responses) {\n      // 7.3.1\n      /** @type {CacheBatchOperation} */\n      const operation = {\n        type: 'put', // 7.3.2\n        request: requestList[index], // 7.3.3\n        response // 7.3.4\n      }\n\n      operations.push(operation) // 7.3.5\n\n      index++ // 7.3.6\n    }\n\n    // 7.5\n    const cacheJobPromise = createDeferredPromise()\n\n    // 7.6.1\n    let errorData = null\n\n    // 7.6.2\n    try {\n      this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    // 7.6.3\n    queueMicrotask(() => {\n      // 7.6.3.1\n      if (errorData === null) {\n        cacheJobPromise.resolve(undefined)\n      } else {\n        // 7.6.3.2\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    // 7.7\n    return cacheJobPromise.promise\n  }\n\n  async put (request, response) {\n    webidl.brandCheck(this, Cache)\n\n    const prefix = 'Cache.put'\n    webidl.argumentLengthCheck(arguments, 2, prefix)\n\n    request = webidl.converters.RequestInfo(request, prefix, 'request')\n    response = webidl.converters.Response(response, prefix, 'response')\n\n    // 1.\n    let innerRequest = null\n\n    // 2.\n    if (request instanceof Request) {\n      innerRequest = request[kState]\n    } else { // 3.\n      innerRequest = new Request(request)[kState]\n    }\n\n    // 4.\n    if (!urlIsHttpHttpsScheme(innerRequest.url) || innerRequest.method !== 'GET') {\n      throw webidl.errors.exception({\n        header: prefix,\n        message: 'Expected an http/s scheme when method is not GET'\n      })\n    }\n\n    // 5.\n    const innerResponse = response[kState]\n\n    // 6.\n    if (innerResponse.status === 206) {\n      throw webidl.errors.exception({\n        header: prefix,\n        message: 'Got 206 status'\n      })\n    }\n\n    // 7.\n    if (innerResponse.headersList.contains('vary')) {\n      // 7.1.\n      const fieldValues = getFieldValues(innerResponse.headersList.get('vary'))\n\n      // 7.2.\n      for (const fieldValue of fieldValues) {\n        // 7.2.1\n        if (fieldValue === '*') {\n          throw webidl.errors.exception({\n            header: prefix,\n            message: 'Got * vary field value'\n          })\n        }\n      }\n    }\n\n    // 8.\n    if (innerResponse.body && (isDisturbed(innerResponse.body.stream) || innerResponse.body.stream.locked)) {\n      throw webidl.errors.exception({\n        header: prefix,\n        message: 'Response body is locked or disturbed'\n      })\n    }\n\n    // 9.\n    const clonedResponse = cloneResponse(innerResponse)\n\n    // 10.\n    const bodyReadPromise = createDeferredPromise()\n\n    // 11.\n    if (innerResponse.body != null) {\n      // 11.1\n      const stream = innerResponse.body.stream\n\n      // 11.2\n      const reader = stream.getReader()\n\n      // 11.3\n      readAllBytes(reader).then(bodyReadPromise.resolve, bodyReadPromise.reject)\n    } else {\n      bodyReadPromise.resolve(undefined)\n    }\n\n    // 12.\n    /** @type {CacheBatchOperation[]} */\n    const operations = []\n\n    // 13.\n    /** @type {CacheBatchOperation} */\n    const operation = {\n      type: 'put', // 14.\n      request: innerRequest, // 15.\n      response: clonedResponse // 16.\n    }\n\n    // 17.\n    operations.push(operation)\n\n    // 19.\n    const bytes = await bodyReadPromise.promise\n\n    if (clonedResponse.body != null) {\n      clonedResponse.body.source = bytes\n    }\n\n    // 19.1\n    const cacheJobPromise = createDeferredPromise()\n\n    // 19.2.1\n    let errorData = null\n\n    // 19.2.2\n    try {\n      this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    // 19.2.3\n    queueMicrotask(() => {\n      // 19.2.3.1\n      if (errorData === null) {\n        cacheJobPromise.resolve()\n      } else { // 19.2.3.2\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    return cacheJobPromise.promise\n  }\n\n  async delete (request, options = {}) {\n    webidl.brandCheck(this, Cache)\n\n    const prefix = 'Cache.delete'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    request = webidl.converters.RequestInfo(request, prefix, 'request')\n    options = webidl.converters.CacheQueryOptions(options, prefix, 'options')\n\n    /**\n     * @type {Request}\n     */\n    let r = null\n\n    if (request instanceof Request) {\n      r = request[kState]\n\n      if (r.method !== 'GET' && !options.ignoreMethod) {\n        return false\n      }\n    } else {\n      assert(typeof request === 'string')\n\n      r = new Request(request)[kState]\n    }\n\n    /** @type {CacheBatchOperation[]} */\n    const operations = []\n\n    /** @type {CacheBatchOperation} */\n    const operation = {\n      type: 'delete',\n      request: r,\n      options\n    }\n\n    operations.push(operation)\n\n    const cacheJobPromise = createDeferredPromise()\n\n    let errorData = null\n    let requestResponses\n\n    try {\n      requestResponses = this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    queueMicrotask(() => {\n      if (errorData === null) {\n        cacheJobPromise.resolve(!!requestResponses?.length)\n      } else {\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    return cacheJobPromise.promise\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dom-cache-keys\n   * @param {any} request\n   * @param {import('../../types/cache').CacheQueryOptions} options\n   * @returns {Promise<readonly Request[]>}\n   */\n  async keys (request = undefined, options = {}) {\n    webidl.brandCheck(this, Cache)\n\n    const prefix = 'Cache.keys'\n\n    if (request !== undefined) request = webidl.converters.RequestInfo(request, prefix, 'request')\n    options = webidl.converters.CacheQueryOptions(options, prefix, 'options')\n\n    // 1.\n    let r = null\n\n    // 2.\n    if (request !== undefined) {\n      // 2.1\n      if (request instanceof Request) {\n        // 2.1.1\n        r = request[kState]\n\n        // 2.1.2\n        if (r.method !== 'GET' && !options.ignoreMethod) {\n          return []\n        }\n      } else if (typeof request === 'string') { // 2.2\n        r = new Request(request)[kState]\n      }\n    }\n\n    // 4.\n    const promise = createDeferredPromise()\n\n    // 5.\n    // 5.1\n    const requests = []\n\n    // 5.2\n    if (request === undefined) {\n      // 5.2.1\n      for (const requestResponse of this.#relevantRequestResponseList) {\n        // 5.2.1.1\n        requests.push(requestResponse[0])\n      }\n    } else { // 5.3\n      // 5.3.1\n      const requestResponses = this.#queryCache(r, options)\n\n      // 5.3.2\n      for (const requestResponse of requestResponses) {\n        // 5.3.2.1\n        requests.push(requestResponse[0])\n      }\n    }\n\n    // 5.4\n    queueMicrotask(() => {\n      // 5.4.1\n      const requestList = []\n\n      // 5.4.2\n      for (const request of requests) {\n        const requestObject = fromInnerRequest(\n          request,\n          new AbortController().signal,\n          'immutable'\n        )\n        // 5.4.2.1\n        requestList.push(requestObject)\n      }\n\n      // 5.4.3\n      promise.resolve(Object.freeze(requestList))\n    })\n\n    return promise.promise\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#batch-cache-operations-algorithm\n   * @param {CacheBatchOperation[]} operations\n   * @returns {requestResponseList}\n   */\n  #batchCacheOperations (operations) {\n    // 1.\n    const cache = this.#relevantRequestResponseList\n\n    // 2.\n    const backupCache = [...cache]\n\n    // 3.\n    const addedItems = []\n\n    // 4.1\n    const resultList = []\n\n    try {\n      // 4.2\n      for (const operation of operations) {\n        // 4.2.1\n        if (operation.type !== 'delete' && operation.type !== 'put') {\n          throw webidl.errors.exception({\n            header: 'Cache.#batchCacheOperations',\n            message: 'operation type does not match \"delete\" or \"put\"'\n          })\n        }\n\n        // 4.2.2\n        if (operation.type === 'delete' && operation.response != null) {\n          throw webidl.errors.exception({\n            header: 'Cache.#batchCacheOperations',\n            message: 'delete operation should not have an associated response'\n          })\n        }\n\n        // 4.2.3\n        if (this.#queryCache(operation.request, operation.options, addedItems).length) {\n          throw new DOMException('???', 'InvalidStateError')\n        }\n\n        // 4.2.4\n        let requestResponses\n\n        // 4.2.5\n        if (operation.type === 'delete') {\n          // 4.2.5.1\n          requestResponses = this.#queryCache(operation.request, operation.options)\n\n          // TODO: the spec is wrong, this is needed to pass WPTs\n          if (requestResponses.length === 0) {\n            return []\n          }\n\n          // 4.2.5.2\n          for (const requestResponse of requestResponses) {\n            const idx = cache.indexOf(requestResponse)\n            assert(idx !== -1)\n\n            // 4.2.5.2.1\n            cache.splice(idx, 1)\n          }\n        } else if (operation.type === 'put') { // 4.2.6\n          // 4.2.6.1\n          if (operation.response == null) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'put operation should have an associated response'\n            })\n          }\n\n          // 4.2.6.2\n          const r = operation.request\n\n          // 4.2.6.3\n          if (!urlIsHttpHttpsScheme(r.url)) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'expected http or https scheme'\n            })\n          }\n\n          // 4.2.6.4\n          if (r.method !== 'GET') {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'not get method'\n            })\n          }\n\n          // 4.2.6.5\n          if (operation.options != null) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'options must not be defined'\n            })\n          }\n\n          // 4.2.6.6\n          requestResponses = this.#queryCache(operation.request)\n\n          // 4.2.6.7\n          for (const requestResponse of requestResponses) {\n            const idx = cache.indexOf(requestResponse)\n            assert(idx !== -1)\n\n            // 4.2.6.7.1\n            cache.splice(idx, 1)\n          }\n\n          // 4.2.6.8\n          cache.push([operation.request, operation.response])\n\n          // 4.2.6.10\n          addedItems.push([operation.request, operation.response])\n        }\n\n        // 4.2.7\n        resultList.push([operation.request, operation.response])\n      }\n\n      // 4.3\n      return resultList\n    } catch (e) { // 5.\n      // 5.1\n      this.#relevantRequestResponseList.length = 0\n\n      // 5.2\n      this.#relevantRequestResponseList = backupCache\n\n      // 5.3\n      throw e\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#query-cache\n   * @param {any} requestQuery\n   * @param {import('../../types/cache').CacheQueryOptions} options\n   * @param {requestResponseList} targetStorage\n   * @returns {requestResponseList}\n   */\n  #queryCache (requestQuery, options, targetStorage) {\n    /** @type {requestResponseList} */\n    const resultList = []\n\n    const storage = targetStorage ?? this.#relevantRequestResponseList\n\n    for (const requestResponse of storage) {\n      const [cachedRequest, cachedResponse] = requestResponse\n      if (this.#requestMatchesCachedItem(requestQuery, cachedRequest, cachedResponse, options)) {\n        resultList.push(requestResponse)\n      }\n    }\n\n    return resultList\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#request-matches-cached-item-algorithm\n   * @param {any} requestQuery\n   * @param {any} request\n   * @param {any | null} response\n   * @param {import('../../types/cache').CacheQueryOptions | undefined} options\n   * @returns {boolean}\n   */\n  #requestMatchesCachedItem (requestQuery, request, response = null, options) {\n    // if (options?.ignoreMethod === false && request.method === 'GET') {\n    //   return false\n    // }\n\n    const queryURL = new URL(requestQuery.url)\n\n    const cachedURL = new URL(request.url)\n\n    if (options?.ignoreSearch) {\n      cachedURL.search = ''\n\n      queryURL.search = ''\n    }\n\n    if (!urlEquals(queryURL, cachedURL, true)) {\n      return false\n    }\n\n    if (\n      response == null ||\n      options?.ignoreVary ||\n      !response.headersList.contains('vary')\n    ) {\n      return true\n    }\n\n    const fieldValues = getFieldValues(response.headersList.get('vary'))\n\n    for (const fieldValue of fieldValues) {\n      if (fieldValue === '*') {\n        return false\n      }\n\n      const requestValue = request.headersList.get(fieldValue)\n      const queryValue = requestQuery.headersList.get(fieldValue)\n\n      // If one has the header and the other doesn't, or one has\n      // a different value than the other, return false\n      if (requestValue !== queryValue) {\n        return false\n      }\n    }\n\n    return true\n  }\n\n  #internalMatchAll (request, options, maxResponses = Infinity) {\n    // 1.\n    let r = null\n\n    // 2.\n    if (request !== undefined) {\n      if (request instanceof Request) {\n        // 2.1.1\n        r = request[kState]\n\n        // 2.1.2\n        if (r.method !== 'GET' && !options.ignoreMethod) {\n          return []\n        }\n      } else if (typeof request === 'string') {\n        // 2.2.1\n        r = new Request(request)[kState]\n      }\n    }\n\n    // 5.\n    // 5.1\n    const responses = []\n\n    // 5.2\n    if (request === undefined) {\n      // 5.2.1\n      for (const requestResponse of this.#relevantRequestResponseList) {\n        responses.push(requestResponse[1])\n      }\n    } else { // 5.3\n      // 5.3.1\n      const requestResponses = this.#queryCache(r, options)\n\n      // 5.3.2\n      for (const requestResponse of requestResponses) {\n        responses.push(requestResponse[1])\n      }\n    }\n\n    // 5.4\n    // We don't implement CORs so we don't need to loop over the responses, yay!\n\n    // 5.5.1\n    const responseList = []\n\n    // 5.5.2\n    for (const response of responses) {\n      // 5.5.2.1\n      const responseObject = fromInnerResponse(response, 'immutable')\n\n      responseList.push(responseObject.clone())\n\n      if (responseList.length >= maxResponses) {\n        break\n      }\n    }\n\n    // 6.\n    return Object.freeze(responseList)\n  }\n}\n\nObject.defineProperties(Cache.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'Cache',\n    configurable: true\n  },\n  match: kEnumerableProperty,\n  matchAll: kEnumerableProperty,\n  add: kEnumerableProperty,\n  addAll: kEnumerableProperty,\n  put: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  keys: kEnumerableProperty\n})\n\nconst cacheQueryOptionConverters = [\n  {\n    key: 'ignoreSearch',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'ignoreMethod',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'ignoreVary',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  }\n]\n\nwebidl.converters.CacheQueryOptions = webidl.dictionaryConverter(cacheQueryOptionConverters)\n\nwebidl.converters.MultiCacheQueryOptions = webidl.dictionaryConverter([\n  ...cacheQueryOptionConverters,\n  {\n    key: 'cacheName',\n    converter: webidl.converters.DOMString\n  }\n])\n\nwebidl.converters.Response = webidl.interfaceConverter(Response)\n\nwebidl.converters['sequence<RequestInfo>'] = webidl.sequenceConverter(\n  webidl.converters.RequestInfo\n)\n\nmodule.exports = {\n  Cache\n}\n","'use strict'\n\nconst { kConstruct } = require('./symbols')\nconst { Cache } = require('./cache')\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../../core/util')\n\nclass CacheStorage {\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-name-to-cache-map\n   * @type {Map<string, import('./cache').requestResponseList}\n   */\n  #caches = new Map()\n\n  constructor () {\n    if (arguments[0] !== kConstruct) {\n      webidl.illegalConstructor()\n    }\n\n    webidl.util.markAsUncloneable(this)\n  }\n\n  async match (request, options = {}) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, 'CacheStorage.match')\n\n    request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.MultiCacheQueryOptions(options)\n\n    // 1.\n    if (options.cacheName != null) {\n      // 1.1.1.1\n      if (this.#caches.has(options.cacheName)) {\n        // 1.1.1.1.1\n        const cacheList = this.#caches.get(options.cacheName)\n        const cache = new Cache(kConstruct, cacheList)\n\n        return await cache.match(request, options)\n      }\n    } else { // 2.\n      // 2.2\n      for (const cacheList of this.#caches.values()) {\n        const cache = new Cache(kConstruct, cacheList)\n\n        // 2.2.1.2\n        const response = await cache.match(request, options)\n\n        if (response !== undefined) {\n          return response\n        }\n      }\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-has\n   * @param {string} cacheName\n   * @returns {Promise<boolean>}\n   */\n  async has (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n\n    const prefix = 'CacheStorage.has'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    cacheName = webidl.converters.DOMString(cacheName, prefix, 'cacheName')\n\n    // 2.1.1\n    // 2.2\n    return this.#caches.has(cacheName)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dom-cachestorage-open\n   * @param {string} cacheName\n   * @returns {Promise<Cache>}\n   */\n  async open (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n\n    const prefix = 'CacheStorage.open'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    cacheName = webidl.converters.DOMString(cacheName, prefix, 'cacheName')\n\n    // 2.1\n    if (this.#caches.has(cacheName)) {\n      // await caches.open('v1') !== await caches.open('v1')\n\n      // 2.1.1\n      const cache = this.#caches.get(cacheName)\n\n      // 2.1.1.1\n      return new Cache(kConstruct, cache)\n    }\n\n    // 2.2\n    const cache = []\n\n    // 2.3\n    this.#caches.set(cacheName, cache)\n\n    // 2.4\n    return new Cache(kConstruct, cache)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-delete\n   * @param {string} cacheName\n   * @returns {Promise<boolean>}\n   */\n  async delete (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n\n    const prefix = 'CacheStorage.delete'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    cacheName = webidl.converters.DOMString(cacheName, prefix, 'cacheName')\n\n    return this.#caches.delete(cacheName)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-keys\n   * @returns {Promise<string[]>}\n   */\n  async keys () {\n    webidl.brandCheck(this, CacheStorage)\n\n    // 2.1\n    const keys = this.#caches.keys()\n\n    // 2.2\n    return [...keys]\n  }\n}\n\nObject.defineProperties(CacheStorage.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'CacheStorage',\n    configurable: true\n  },\n  match: kEnumerableProperty,\n  has: kEnumerableProperty,\n  open: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  keys: kEnumerableProperty\n})\n\nmodule.exports = {\n  CacheStorage\n}\n","'use strict'\n\nmodule.exports = {\n  kConstruct: require('../../core/symbols').kConstruct\n}\n","'use strict'\n\nconst assert = require('node:assert')\nconst { URLSerializer } = require('../fetch/data-url')\nconst { isValidHeaderName } = require('../fetch/util')\n\n/**\n * @see https://url.spec.whatwg.org/#concept-url-equals\n * @param {URL} A\n * @param {URL} B\n * @param {boolean | undefined} excludeFragment\n * @returns {boolean}\n */\nfunction urlEquals (A, B, excludeFragment = false) {\n  const serializedA = URLSerializer(A, excludeFragment)\n\n  const serializedB = URLSerializer(B, excludeFragment)\n\n  return serializedA === serializedB\n}\n\n/**\n * @see https://github.com/chromium/chromium/blob/694d20d134cb553d8d89e5500b9148012b1ba299/content/browser/cache_storage/cache_storage_cache.cc#L260-L262\n * @param {string} header\n */\nfunction getFieldValues (header) {\n  assert(header !== null)\n\n  const values = []\n\n  for (let value of header.split(',')) {\n    value = value.trim()\n\n    if (isValidHeaderName(value)) {\n      values.push(value)\n    }\n  }\n\n  return values\n}\n\nmodule.exports = {\n  urlEquals,\n  getFieldValues\n}\n","'use strict'\n\n// https://wicg.github.io/cookie-store/#cookie-maximum-attribute-value-size\nconst maxAttributeValueSize = 1024\n\n// https://wicg.github.io/cookie-store/#cookie-maximum-name-value-pair-size\nconst maxNameValuePairSize = 4096\n\nmodule.exports = {\n  maxAttributeValueSize,\n  maxNameValuePairSize\n}\n","'use strict'\n\nconst { parseSetCookie } = require('./parse')\nconst { stringify } = require('./util')\nconst { webidl } = require('../fetch/webidl')\nconst { Headers } = require('../fetch/headers')\n\n/**\n * @typedef {Object} Cookie\n * @property {string} name\n * @property {string} value\n * @property {Date|number|undefined} expires\n * @property {number|undefined} maxAge\n * @property {string|undefined} domain\n * @property {string|undefined} path\n * @property {boolean|undefined} secure\n * @property {boolean|undefined} httpOnly\n * @property {'Strict'|'Lax'|'None'} sameSite\n * @property {string[]} unparsed\n */\n\n/**\n * @param {Headers} headers\n * @returns {Record<string, string>}\n */\nfunction getCookies (headers) {\n  webidl.argumentLengthCheck(arguments, 1, 'getCookies')\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  const cookie = headers.get('cookie')\n  const out = {}\n\n  if (!cookie) {\n    return out\n  }\n\n  for (const piece of cookie.split(';')) {\n    const [name, ...value] = piece.split('=')\n\n    out[name.trim()] = value.join('=')\n  }\n\n  return out\n}\n\n/**\n * @param {Headers} headers\n * @param {string} name\n * @param {{ path?: string, domain?: string }|undefined} attributes\n * @returns {void}\n */\nfunction deleteCookie (headers, name, attributes) {\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  const prefix = 'deleteCookie'\n  webidl.argumentLengthCheck(arguments, 2, prefix)\n\n  name = webidl.converters.DOMString(name, prefix, 'name')\n  attributes = webidl.converters.DeleteCookieAttributes(attributes)\n\n  // Matches behavior of\n  // https://github.com/denoland/deno_std/blob/63827b16330b82489a04614027c33b7904e08be5/http/cookie.ts#L278\n  setCookie(headers, {\n    name,\n    value: '',\n    expires: new Date(0),\n    ...attributes\n  })\n}\n\n/**\n * @param {Headers} headers\n * @returns {Cookie[]}\n */\nfunction getSetCookies (headers) {\n  webidl.argumentLengthCheck(arguments, 1, 'getSetCookies')\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  const cookies = headers.getSetCookie()\n\n  if (!cookies) {\n    return []\n  }\n\n  return cookies.map((pair) => parseSetCookie(pair))\n}\n\n/**\n * @param {Headers} headers\n * @param {Cookie} cookie\n * @returns {void}\n */\nfunction setCookie (headers, cookie) {\n  webidl.argumentLengthCheck(arguments, 2, 'setCookie')\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  cookie = webidl.converters.Cookie(cookie)\n\n  const str = stringify(cookie)\n\n  if (str) {\n    headers.append('Set-Cookie', str)\n  }\n}\n\nwebidl.converters.DeleteCookieAttributes = webidl.dictionaryConverter([\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'path',\n    defaultValue: () => null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'domain',\n    defaultValue: () => null\n  }\n])\n\nwebidl.converters.Cookie = webidl.dictionaryConverter([\n  {\n    converter: webidl.converters.DOMString,\n    key: 'name'\n  },\n  {\n    converter: webidl.converters.DOMString,\n    key: 'value'\n  },\n  {\n    converter: webidl.nullableConverter((value) => {\n      if (typeof value === 'number') {\n        return webidl.converters['unsigned long long'](value)\n      }\n\n      return new Date(value)\n    }),\n    key: 'expires',\n    defaultValue: () => null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters['long long']),\n    key: 'maxAge',\n    defaultValue: () => null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'domain',\n    defaultValue: () => null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'path',\n    defaultValue: () => null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.boolean),\n    key: 'secure',\n    defaultValue: () => null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.boolean),\n    key: 'httpOnly',\n    defaultValue: () => null\n  },\n  {\n    converter: webidl.converters.USVString,\n    key: 'sameSite',\n    allowedValues: ['Strict', 'Lax', 'None']\n  },\n  {\n    converter: webidl.sequenceConverter(webidl.converters.DOMString),\n    key: 'unparsed',\n    defaultValue: () => new Array(0)\n  }\n])\n\nmodule.exports = {\n  getCookies,\n  deleteCookie,\n  getSetCookies,\n  setCookie\n}\n","'use strict'\n\nconst { maxNameValuePairSize, maxAttributeValueSize } = require('./constants')\nconst { isCTLExcludingHtab } = require('./util')\nconst { collectASequenceOfCodePointsFast } = require('../fetch/data-url')\nconst assert = require('node:assert')\n\n/**\n * @description Parses the field-value attributes of a set-cookie header string.\n * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4\n * @param {string} header\n * @returns if the header is invalid, null will be returned\n */\nfunction parseSetCookie (header) {\n  // 1. If the set-cookie-string contains a %x00-08 / %x0A-1F / %x7F\n  //    character (CTL characters excluding HTAB): Abort these steps and\n  //    ignore the set-cookie-string entirely.\n  if (isCTLExcludingHtab(header)) {\n    return null\n  }\n\n  let nameValuePair = ''\n  let unparsedAttributes = ''\n  let name = ''\n  let value = ''\n\n  // 2. If the set-cookie-string contains a %x3B (\";\") character:\n  if (header.includes(';')) {\n    // 1. The name-value-pair string consists of the characters up to,\n    //    but not including, the first %x3B (\";\"), and the unparsed-\n    //    attributes consist of the remainder of the set-cookie-string\n    //    (including the %x3B (\";\") in question).\n    const position = { position: 0 }\n\n    nameValuePair = collectASequenceOfCodePointsFast(';', header, position)\n    unparsedAttributes = header.slice(position.position)\n  } else {\n    // Otherwise:\n\n    // 1. The name-value-pair string consists of all the characters\n    //    contained in the set-cookie-string, and the unparsed-\n    //    attributes is the empty string.\n    nameValuePair = header\n  }\n\n  // 3. If the name-value-pair string lacks a %x3D (\"=\") character, then\n  //    the name string is empty, and the value string is the value of\n  //    name-value-pair.\n  if (!nameValuePair.includes('=')) {\n    value = nameValuePair\n  } else {\n    //    Otherwise, the name string consists of the characters up to, but\n    //    not including, the first %x3D (\"=\") character, and the (possibly\n    //    empty) value string consists of the characters after the first\n    //    %x3D (\"=\") character.\n    const position = { position: 0 }\n    name = collectASequenceOfCodePointsFast(\n      '=',\n      nameValuePair,\n      position\n    )\n    value = nameValuePair.slice(position.position + 1)\n  }\n\n  // 4. Remove any leading or trailing WSP characters from the name\n  //    string and the value string.\n  name = name.trim()\n  value = value.trim()\n\n  // 5. If the sum of the lengths of the name string and the value string\n  //    is more than 4096 octets, abort these steps and ignore the set-\n  //    cookie-string entirely.\n  if (name.length + value.length > maxNameValuePairSize) {\n    return null\n  }\n\n  // 6. The cookie-name is the name string, and the cookie-value is the\n  //    value string.\n  return {\n    name, value, ...parseUnparsedAttributes(unparsedAttributes)\n  }\n}\n\n/**\n * Parses the remaining attributes of a set-cookie header\n * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4\n * @param {string} unparsedAttributes\n * @param {[Object.<string, unknown>]={}} cookieAttributeList\n */\nfunction parseUnparsedAttributes (unparsedAttributes, cookieAttributeList = {}) {\n  // 1. If the unparsed-attributes string is empty, skip the rest of\n  //    these steps.\n  if (unparsedAttributes.length === 0) {\n    return cookieAttributeList\n  }\n\n  // 2. Discard the first character of the unparsed-attributes (which\n  //    will be a %x3B (\";\") character).\n  assert(unparsedAttributes[0] === ';')\n  unparsedAttributes = unparsedAttributes.slice(1)\n\n  let cookieAv = ''\n\n  // 3. If the remaining unparsed-attributes contains a %x3B (\";\")\n  //    character:\n  if (unparsedAttributes.includes(';')) {\n    // 1. Consume the characters of the unparsed-attributes up to, but\n    //    not including, the first %x3B (\";\") character.\n    cookieAv = collectASequenceOfCodePointsFast(\n      ';',\n      unparsedAttributes,\n      { position: 0 }\n    )\n    unparsedAttributes = unparsedAttributes.slice(cookieAv.length)\n  } else {\n    // Otherwise:\n\n    // 1. Consume the remainder of the unparsed-attributes.\n    cookieAv = unparsedAttributes\n    unparsedAttributes = ''\n  }\n\n  // Let the cookie-av string be the characters consumed in this step.\n\n  let attributeName = ''\n  let attributeValue = ''\n\n  // 4. If the cookie-av string contains a %x3D (\"=\") character:\n  if (cookieAv.includes('=')) {\n    // 1. The (possibly empty) attribute-name string consists of the\n    //    characters up to, but not including, the first %x3D (\"=\")\n    //    character, and the (possibly empty) attribute-value string\n    //    consists of the characters after the first %x3D (\"=\")\n    //    character.\n    const position = { position: 0 }\n\n    attributeName = collectASequenceOfCodePointsFast(\n      '=',\n      cookieAv,\n      position\n    )\n    attributeValue = cookieAv.slice(position.position + 1)\n  } else {\n    // Otherwise:\n\n    // 1. The attribute-name string consists of the entire cookie-av\n    //    string, and the attribute-value string is empty.\n    attributeName = cookieAv\n  }\n\n  // 5. Remove any leading or trailing WSP characters from the attribute-\n  //    name string and the attribute-value string.\n  attributeName = attributeName.trim()\n  attributeValue = attributeValue.trim()\n\n  // 6. If the attribute-value is longer than 1024 octets, ignore the\n  //    cookie-av string and return to Step 1 of this algorithm.\n  if (attributeValue.length > maxAttributeValueSize) {\n    return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n  }\n\n  // 7. Process the attribute-name and attribute-value according to the\n  //    requirements in the following subsections.  (Notice that\n  //    attributes with unrecognized attribute-names are ignored.)\n  const attributeNameLowercase = attributeName.toLowerCase()\n\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.1\n  // If the attribute-name case-insensitively matches the string\n  // \"Expires\", the user agent MUST process the cookie-av as follows.\n  if (attributeNameLowercase === 'expires') {\n    // 1. Let the expiry-time be the result of parsing the attribute-value\n    //    as cookie-date (see Section 5.1.1).\n    const expiryTime = new Date(attributeValue)\n\n    // 2. If the attribute-value failed to parse as a cookie date, ignore\n    //    the cookie-av.\n\n    cookieAttributeList.expires = expiryTime\n  } else if (attributeNameLowercase === 'max-age') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.2\n    // If the attribute-name case-insensitively matches the string \"Max-\n    // Age\", the user agent MUST process the cookie-av as follows.\n\n    // 1. If the first character of the attribute-value is not a DIGIT or a\n    //    \"-\" character, ignore the cookie-av.\n    const charCode = attributeValue.charCodeAt(0)\n\n    if ((charCode < 48 || charCode > 57) && attributeValue[0] !== '-') {\n      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n    }\n\n    // 2. If the remainder of attribute-value contains a non-DIGIT\n    //    character, ignore the cookie-av.\n    if (!/^\\d+$/.test(attributeValue)) {\n      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n    }\n\n    // 3. Let delta-seconds be the attribute-value converted to an integer.\n    const deltaSeconds = Number(attributeValue)\n\n    // 4. Let cookie-age-limit be the maximum age of the cookie (which\n    //    SHOULD be 400 days or less, see Section 4.1.2.2).\n\n    // 5. Set delta-seconds to the smaller of its present value and cookie-\n    //    age-limit.\n    // deltaSeconds = Math.min(deltaSeconds * 1000, maxExpiresMs)\n\n    // 6. If delta-seconds is less than or equal to zero (0), let expiry-\n    //    time be the earliest representable date and time.  Otherwise, let\n    //    the expiry-time be the current date and time plus delta-seconds\n    //    seconds.\n    // const expiryTime = deltaSeconds <= 0 ? Date.now() : Date.now() + deltaSeconds\n\n    // 7. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Max-Age and an attribute-value of expiry-time.\n    cookieAttributeList.maxAge = deltaSeconds\n  } else if (attributeNameLowercase === 'domain') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.3\n    // If the attribute-name case-insensitively matches the string \"Domain\",\n    // the user agent MUST process the cookie-av as follows.\n\n    // 1. Let cookie-domain be the attribute-value.\n    let cookieDomain = attributeValue\n\n    // 2. If cookie-domain starts with %x2E (\".\"), let cookie-domain be\n    //    cookie-domain without its leading %x2E (\".\").\n    if (cookieDomain[0] === '.') {\n      cookieDomain = cookieDomain.slice(1)\n    }\n\n    // 3. Convert the cookie-domain to lower case.\n    cookieDomain = cookieDomain.toLowerCase()\n\n    // 4. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Domain and an attribute-value of cookie-domain.\n    cookieAttributeList.domain = cookieDomain\n  } else if (attributeNameLowercase === 'path') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.4\n    // If the attribute-name case-insensitively matches the string \"Path\",\n    // the user agent MUST process the cookie-av as follows.\n\n    // 1. If the attribute-value is empty or if the first character of the\n    //    attribute-value is not %x2F (\"/\"):\n    let cookiePath = ''\n    if (attributeValue.length === 0 || attributeValue[0] !== '/') {\n      // 1. Let cookie-path be the default-path.\n      cookiePath = '/'\n    } else {\n      // Otherwise:\n\n      // 1. Let cookie-path be the attribute-value.\n      cookiePath = attributeValue\n    }\n\n    // 2. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Path and an attribute-value of cookie-path.\n    cookieAttributeList.path = cookiePath\n  } else if (attributeNameLowercase === 'secure') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.5\n    // If the attribute-name case-insensitively matches the string \"Secure\",\n    // the user agent MUST append an attribute to the cookie-attribute-list\n    // with an attribute-name of Secure and an empty attribute-value.\n\n    cookieAttributeList.secure = true\n  } else if (attributeNameLowercase === 'httponly') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.6\n    // If the attribute-name case-insensitively matches the string\n    // \"HttpOnly\", the user agent MUST append an attribute to the cookie-\n    // attribute-list with an attribute-name of HttpOnly and an empty\n    // attribute-value.\n\n    cookieAttributeList.httpOnly = true\n  } else if (attributeNameLowercase === 'samesite') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.7\n    // If the attribute-name case-insensitively matches the string\n    // \"SameSite\", the user agent MUST process the cookie-av as follows:\n\n    // 1. Let enforcement be \"Default\".\n    let enforcement = 'Default'\n\n    const attributeValueLowercase = attributeValue.toLowerCase()\n    // 2. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"None\", set enforcement to \"None\".\n    if (attributeValueLowercase.includes('none')) {\n      enforcement = 'None'\n    }\n\n    // 3. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"Strict\", set enforcement to \"Strict\".\n    if (attributeValueLowercase.includes('strict')) {\n      enforcement = 'Strict'\n    }\n\n    // 4. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"Lax\", set enforcement to \"Lax\".\n    if (attributeValueLowercase.includes('lax')) {\n      enforcement = 'Lax'\n    }\n\n    // 5. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of \"SameSite\" and an attribute-value of\n    //    enforcement.\n    cookieAttributeList.sameSite = enforcement\n  } else {\n    cookieAttributeList.unparsed ??= []\n\n    cookieAttributeList.unparsed.push(`${attributeName}=${attributeValue}`)\n  }\n\n  // 8. Return to Step 1 of this algorithm.\n  return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n}\n\nmodule.exports = {\n  parseSetCookie,\n  parseUnparsedAttributes\n}\n","'use strict'\n\n/**\n * @param {string} value\n * @returns {boolean}\n */\nfunction isCTLExcludingHtab (value) {\n  for (let i = 0; i < value.length; ++i) {\n    const code = value.charCodeAt(i)\n\n    if (\n      (code >= 0x00 && code <= 0x08) ||\n      (code >= 0x0A && code <= 0x1F) ||\n      code === 0x7F\n    ) {\n      return true\n    }\n  }\n  return false\n}\n\n/**\n CHAR           = <any US-ASCII character (octets 0 - 127)>\n token          = 1*<any CHAR except CTLs or separators>\n separators     = \"(\" | \")\" | \"<\" | \">\" | \"@\"\n                | \",\" | \";\" | \":\" | \"\\\" | <\">\n                | \"/\" | \"[\" | \"]\" | \"?\" | \"=\"\n                | \"{\" | \"}\" | SP | HT\n * @param {string} name\n */\nfunction validateCookieName (name) {\n  for (let i = 0; i < name.length; ++i) {\n    const code = name.charCodeAt(i)\n\n    if (\n      code < 0x21 || // exclude CTLs (0-31), SP and HT\n      code > 0x7E || // exclude non-ascii and DEL\n      code === 0x22 || // \"\n      code === 0x28 || // (\n      code === 0x29 || // )\n      code === 0x3C || // <\n      code === 0x3E || // >\n      code === 0x40 || // @\n      code === 0x2C || // ,\n      code === 0x3B || // ;\n      code === 0x3A || // :\n      code === 0x5C || // \\\n      code === 0x2F || // /\n      code === 0x5B || // [\n      code === 0x5D || // ]\n      code === 0x3F || // ?\n      code === 0x3D || // =\n      code === 0x7B || // {\n      code === 0x7D // }\n    ) {\n      throw new Error('Invalid cookie name')\n    }\n  }\n}\n\n/**\n cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )\n cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E\n                       ; US-ASCII characters excluding CTLs,\n                       ; whitespace DQUOTE, comma, semicolon,\n                       ; and backslash\n * @param {string} value\n */\nfunction validateCookieValue (value) {\n  let len = value.length\n  let i = 0\n\n  // if the value is wrapped in DQUOTE\n  if (value[0] === '\"') {\n    if (len === 1 || value[len - 1] !== '\"') {\n      throw new Error('Invalid cookie value')\n    }\n    --len\n    ++i\n  }\n\n  while (i < len) {\n    const code = value.charCodeAt(i++)\n\n    if (\n      code < 0x21 || // exclude CTLs (0-31)\n      code > 0x7E || // non-ascii and DEL (127)\n      code === 0x22 || // \"\n      code === 0x2C || // ,\n      code === 0x3B || // ;\n      code === 0x5C // \\\n    ) {\n      throw new Error('Invalid cookie value')\n    }\n  }\n}\n\n/**\n * path-value        = <any CHAR except CTLs or \";\">\n * @param {string} path\n */\nfunction validateCookiePath (path) {\n  for (let i = 0; i < path.length; ++i) {\n    const code = path.charCodeAt(i)\n\n    if (\n      code < 0x20 || // exclude CTLs (0-31)\n      code === 0x7F || // DEL\n      code === 0x3B // ;\n    ) {\n      throw new Error('Invalid cookie path')\n    }\n  }\n}\n\n/**\n * I have no idea why these values aren't allowed to be honest,\n * but Deno tests these. - Khafra\n * @param {string} domain\n */\nfunction validateCookieDomain (domain) {\n  if (\n    domain.startsWith('-') ||\n    domain.endsWith('.') ||\n    domain.endsWith('-')\n  ) {\n    throw new Error('Invalid cookie domain')\n  }\n}\n\nconst IMFDays = [\n  'Sun', 'Mon', 'Tue', 'Wed',\n  'Thu', 'Fri', 'Sat'\n]\n\nconst IMFMonths = [\n  'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n  'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n]\n\nconst IMFPaddedNumbers = Array(61).fill(0).map((_, i) => i.toString().padStart(2, '0'))\n\n/**\n * @see https://www.rfc-editor.org/rfc/rfc7231#section-7.1.1.1\n * @param {number|Date} date\n  IMF-fixdate  = day-name \",\" SP date1 SP time-of-day SP GMT\n  ; fixed length/zone/capitalization subset of the format\n  ; see Section 3.3 of [RFC5322]\n\n  day-name     = %x4D.6F.6E ; \"Mon\", case-sensitive\n              / %x54.75.65 ; \"Tue\", case-sensitive\n              / %x57.65.64 ; \"Wed\", case-sensitive\n              / %x54.68.75 ; \"Thu\", case-sensitive\n              / %x46.72.69 ; \"Fri\", case-sensitive\n              / %x53.61.74 ; \"Sat\", case-sensitive\n              / %x53.75.6E ; \"Sun\", case-sensitive\n  date1        = day SP month SP year\n                  ; e.g., 02 Jun 1982\n\n  day          = 2DIGIT\n  month        = %x4A.61.6E ; \"Jan\", case-sensitive\n              / %x46.65.62 ; \"Feb\", case-sensitive\n              / %x4D.61.72 ; \"Mar\", case-sensitive\n              / %x41.70.72 ; \"Apr\", case-sensitive\n              / %x4D.61.79 ; \"May\", case-sensitive\n              / %x4A.75.6E ; \"Jun\", case-sensitive\n              / %x4A.75.6C ; \"Jul\", case-sensitive\n              / %x41.75.67 ; \"Aug\", case-sensitive\n              / %x53.65.70 ; \"Sep\", case-sensitive\n              / %x4F.63.74 ; \"Oct\", case-sensitive\n              / %x4E.6F.76 ; \"Nov\", case-sensitive\n              / %x44.65.63 ; \"Dec\", case-sensitive\n  year         = 4DIGIT\n\n  GMT          = %x47.4D.54 ; \"GMT\", case-sensitive\n\n  time-of-day  = hour \":\" minute \":\" second\n              ; 00:00:00 - 23:59:60 (leap second)\n\n  hour         = 2DIGIT\n  minute       = 2DIGIT\n  second       = 2DIGIT\n */\nfunction toIMFDate (date) {\n  if (typeof date === 'number') {\n    date = new Date(date)\n  }\n\n  return `${IMFDays[date.getUTCDay()]}, ${IMFPaddedNumbers[date.getUTCDate()]} ${IMFMonths[date.getUTCMonth()]} ${date.getUTCFullYear()} ${IMFPaddedNumbers[date.getUTCHours()]}:${IMFPaddedNumbers[date.getUTCMinutes()]}:${IMFPaddedNumbers[date.getUTCSeconds()]} GMT`\n}\n\n/**\n max-age-av        = \"Max-Age=\" non-zero-digit *DIGIT\n                       ; In practice, both expires-av and max-age-av\n                       ; are limited to dates representable by the\n                       ; user agent.\n * @param {number} maxAge\n */\nfunction validateCookieMaxAge (maxAge) {\n  if (maxAge < 0) {\n    throw new Error('Invalid cookie max-age')\n  }\n}\n\n/**\n * @see https://www.rfc-editor.org/rfc/rfc6265#section-4.1.1\n * @param {import('./index').Cookie} cookie\n */\nfunction stringify (cookie) {\n  if (cookie.name.length === 0) {\n    return null\n  }\n\n  validateCookieName(cookie.name)\n  validateCookieValue(cookie.value)\n\n  const out = [`${cookie.name}=${cookie.value}`]\n\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.1\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.2\n  if (cookie.name.startsWith('__Secure-')) {\n    cookie.secure = true\n  }\n\n  if (cookie.name.startsWith('__Host-')) {\n    cookie.secure = true\n    cookie.domain = null\n    cookie.path = '/'\n  }\n\n  if (cookie.secure) {\n    out.push('Secure')\n  }\n\n  if (cookie.httpOnly) {\n    out.push('HttpOnly')\n  }\n\n  if (typeof cookie.maxAge === 'number') {\n    validateCookieMaxAge(cookie.maxAge)\n    out.push(`Max-Age=${cookie.maxAge}`)\n  }\n\n  if (cookie.domain) {\n    validateCookieDomain(cookie.domain)\n    out.push(`Domain=${cookie.domain}`)\n  }\n\n  if (cookie.path) {\n    validateCookiePath(cookie.path)\n    out.push(`Path=${cookie.path}`)\n  }\n\n  if (cookie.expires && cookie.expires.toString() !== 'Invalid Date') {\n    out.push(`Expires=${toIMFDate(cookie.expires)}`)\n  }\n\n  if (cookie.sameSite) {\n    out.push(`SameSite=${cookie.sameSite}`)\n  }\n\n  for (const part of cookie.unparsed) {\n    if (!part.includes('=')) {\n      throw new Error('Invalid unparsed')\n    }\n\n    const [key, ...value] = part.split('=')\n\n    out.push(`${key.trim()}=${value.join('=')}`)\n  }\n\n  return out.join('; ')\n}\n\nmodule.exports = {\n  isCTLExcludingHtab,\n  validateCookieName,\n  validateCookiePath,\n  validateCookieValue,\n  toIMFDate,\n  stringify\n}\n","'use strict'\nconst { Transform } = require('node:stream')\nconst { isASCIINumber, isValidLastEventId } = require('./util')\n\n/**\n * @type {number[]} BOM\n */\nconst BOM = [0xEF, 0xBB, 0xBF]\n/**\n * @type {10} LF\n */\nconst LF = 0x0A\n/**\n * @type {13} CR\n */\nconst CR = 0x0D\n/**\n * @type {58} COLON\n */\nconst COLON = 0x3A\n/**\n * @type {32} SPACE\n */\nconst SPACE = 0x20\n\n/**\n * @typedef {object} EventSourceStreamEvent\n * @type {object}\n * @property {string} [event] The event type.\n * @property {string} [data] The data of the message.\n * @property {string} [id] A unique ID for the event.\n * @property {string} [retry] The reconnection time, in milliseconds.\n */\n\n/**\n * @typedef eventSourceSettings\n * @type {object}\n * @property {string} lastEventId The last event ID received from the server.\n * @property {string} origin The origin of the event source.\n * @property {number} reconnectionTime The reconnection time, in milliseconds.\n */\n\nclass EventSourceStream extends Transform {\n  /**\n   * @type {eventSourceSettings}\n   */\n  state = null\n\n  /**\n   * Leading byte-order-mark check.\n   * @type {boolean}\n   */\n  checkBOM = true\n\n  /**\n   * @type {boolean}\n   */\n  crlfCheck = false\n\n  /**\n   * @type {boolean}\n   */\n  eventEndCheck = false\n\n  /**\n   * @type {Buffer}\n   */\n  buffer = null\n\n  pos = 0\n\n  event = {\n    data: undefined,\n    event: undefined,\n    id: undefined,\n    retry: undefined\n  }\n\n  /**\n   * @param {object} options\n   * @param {eventSourceSettings} options.eventSourceSettings\n   * @param {Function} [options.push]\n   */\n  constructor (options = {}) {\n    // Enable object mode as EventSourceStream emits objects of shape\n    // EventSourceStreamEvent\n    options.readableObjectMode = true\n\n    super(options)\n\n    this.state = options.eventSourceSettings || {}\n    if (options.push) {\n      this.push = options.push\n    }\n  }\n\n  /**\n   * @param {Buffer} chunk\n   * @param {string} _encoding\n   * @param {Function} callback\n   * @returns {void}\n   */\n  _transform (chunk, _encoding, callback) {\n    if (chunk.length === 0) {\n      callback()\n      return\n    }\n\n    // Cache the chunk in the buffer, as the data might not be complete while\n    // processing it\n    // TODO: Investigate if there is a more performant way to handle\n    // incoming chunks\n    // see: https://github.com/nodejs/undici/issues/2630\n    if (this.buffer) {\n      this.buffer = Buffer.concat([this.buffer, chunk])\n    } else {\n      this.buffer = chunk\n    }\n\n    // Strip leading byte-order-mark if we opened the stream and started\n    // the processing of the incoming data\n    if (this.checkBOM) {\n      switch (this.buffer.length) {\n        case 1:\n          // Check if the first byte is the same as the first byte of the BOM\n          if (this.buffer[0] === BOM[0]) {\n            // If it is, we need to wait for more data\n            callback()\n            return\n          }\n          // Set the checkBOM flag to false as we don't need to check for the\n          // BOM anymore\n          this.checkBOM = false\n\n          // The buffer only contains one byte so we need to wait for more data\n          callback()\n          return\n        case 2:\n          // Check if the first two bytes are the same as the first two bytes\n          // of the BOM\n          if (\n            this.buffer[0] === BOM[0] &&\n            this.buffer[1] === BOM[1]\n          ) {\n            // If it is, we need to wait for more data, because the third byte\n            // is needed to determine if it is the BOM or not\n            callback()\n            return\n          }\n\n          // Set the checkBOM flag to false as we don't need to check for the\n          // BOM anymore\n          this.checkBOM = false\n          break\n        case 3:\n          // Check if the first three bytes are the same as the first three\n          // bytes of the BOM\n          if (\n            this.buffer[0] === BOM[0] &&\n            this.buffer[1] === BOM[1] &&\n            this.buffer[2] === BOM[2]\n          ) {\n            // If it is, we can drop the buffered data, as it is only the BOM\n            this.buffer = Buffer.alloc(0)\n            // Set the checkBOM flag to false as we don't need to check for the\n            // BOM anymore\n            this.checkBOM = false\n\n            // Await more data\n            callback()\n            return\n          }\n          // If it is not the BOM, we can start processing the data\n          this.checkBOM = false\n          break\n        default:\n          // The buffer is longer than 3 bytes, so we can drop the BOM if it is\n          // present\n          if (\n            this.buffer[0] === BOM[0] &&\n            this.buffer[1] === BOM[1] &&\n            this.buffer[2] === BOM[2]\n          ) {\n            // Remove the BOM from the buffer\n            this.buffer = this.buffer.subarray(3)\n          }\n\n          // Set the checkBOM flag to false as we don't need to check for the\n          this.checkBOM = false\n          break\n      }\n    }\n\n    while (this.pos < this.buffer.length) {\n      // If the previous line ended with an end-of-line, we need to check\n      // if the next character is also an end-of-line.\n      if (this.eventEndCheck) {\n        // If the the current character is an end-of-line, then the event\n        // is finished and we can process it\n\n        // If the previous line ended with a carriage return, we need to\n        // check if the current character is a line feed and remove it\n        // from the buffer.\n        if (this.crlfCheck) {\n          // If the current character is a line feed, we can remove it\n          // from the buffer and reset the crlfCheck flag\n          if (this.buffer[this.pos] === LF) {\n            this.buffer = this.buffer.subarray(this.pos + 1)\n            this.pos = 0\n            this.crlfCheck = false\n\n            // It is possible that the line feed is not the end of the\n            // event. We need to check if the next character is an\n            // end-of-line character to determine if the event is\n            // finished. We simply continue the loop to check the next\n            // character.\n\n            // As we removed the line feed from the buffer and set the\n            // crlfCheck flag to false, we basically don't make any\n            // distinction between a line feed and a carriage return.\n            continue\n          }\n          this.crlfCheck = false\n        }\n\n        if (this.buffer[this.pos] === LF || this.buffer[this.pos] === CR) {\n          // If the current character is a carriage return, we need to\n          // set the crlfCheck flag to true, as we need to check if the\n          // next character is a line feed so we can remove it from the\n          // buffer\n          if (this.buffer[this.pos] === CR) {\n            this.crlfCheck = true\n          }\n\n          this.buffer = this.buffer.subarray(this.pos + 1)\n          this.pos = 0\n          if (\n            this.event.data !== undefined || this.event.event || this.event.id || this.event.retry) {\n            this.processEvent(this.event)\n          }\n          this.clearEvent()\n          continue\n        }\n        // If the current character is not an end-of-line, then the event\n        // is not finished and we have to reset the eventEndCheck flag\n        this.eventEndCheck = false\n        continue\n      }\n\n      // If the current character is an end-of-line, we can process the\n      // line\n      if (this.buffer[this.pos] === LF || this.buffer[this.pos] === CR) {\n        // If the current character is a carriage return, we need to\n        // set the crlfCheck flag to true, as we need to check if the\n        // next character is a line feed\n        if (this.buffer[this.pos] === CR) {\n          this.crlfCheck = true\n        }\n\n        // In any case, we can process the line as we reached an\n        // end-of-line character\n        this.parseLine(this.buffer.subarray(0, this.pos), this.event)\n\n        // Remove the processed line from the buffer\n        this.buffer = this.buffer.subarray(this.pos + 1)\n        // Reset the position as we removed the processed line from the buffer\n        this.pos = 0\n        // A line was processed and this could be the end of the event. We need\n        // to check if the next line is empty to determine if the event is\n        // finished.\n        this.eventEndCheck = true\n        continue\n      }\n\n      this.pos++\n    }\n\n    callback()\n  }\n\n  /**\n   * @param {Buffer} line\n   * @param {EventStreamEvent} event\n   */\n  parseLine (line, event) {\n    // If the line is empty (a blank line)\n    // Dispatch the event, as defined below.\n    // This will be handled in the _transform method\n    if (line.length === 0) {\n      return\n    }\n\n    // If the line starts with a U+003A COLON character (:)\n    // Ignore the line.\n    const colonPosition = line.indexOf(COLON)\n    if (colonPosition === 0) {\n      return\n    }\n\n    let field = ''\n    let value = ''\n\n    // If the line contains a U+003A COLON character (:)\n    if (colonPosition !== -1) {\n      // Collect the characters on the line before the first U+003A COLON\n      // character (:), and let field be that string.\n      // TODO: Investigate if there is a more performant way to extract the\n      // field\n      // see: https://github.com/nodejs/undici/issues/2630\n      field = line.subarray(0, colonPosition).toString('utf8')\n\n      // Collect the characters on the line after the first U+003A COLON\n      // character (:), and let value be that string.\n      // If value starts with a U+0020 SPACE character, remove it from value.\n      let valueStart = colonPosition + 1\n      if (line[valueStart] === SPACE) {\n        ++valueStart\n      }\n      // TODO: Investigate if there is a more performant way to extract the\n      // value\n      // see: https://github.com/nodejs/undici/issues/2630\n      value = line.subarray(valueStart).toString('utf8')\n\n      // Otherwise, the string is not empty but does not contain a U+003A COLON\n      // character (:)\n    } else {\n      // Process the field using the steps described below, using the whole\n      // line as the field name, and the empty string as the field value.\n      field = line.toString('utf8')\n      value = ''\n    }\n\n    // Modify the event with the field name and value. The value is also\n    // decoded as UTF-8\n    switch (field) {\n      case 'data':\n        if (event[field] === undefined) {\n          event[field] = value\n        } else {\n          event[field] += `\\n${value}`\n        }\n        break\n      case 'retry':\n        if (isASCIINumber(value)) {\n          event[field] = value\n        }\n        break\n      case 'id':\n        if (isValidLastEventId(value)) {\n          event[field] = value\n        }\n        break\n      case 'event':\n        if (value.length > 0) {\n          event[field] = value\n        }\n        break\n    }\n  }\n\n  /**\n   * @param {EventSourceStreamEvent} event\n   */\n  processEvent (event) {\n    if (event.retry && isASCIINumber(event.retry)) {\n      this.state.reconnectionTime = parseInt(event.retry, 10)\n    }\n\n    if (event.id && isValidLastEventId(event.id)) {\n      this.state.lastEventId = event.id\n    }\n\n    // only dispatch event, when data is provided\n    if (event.data !== undefined) {\n      this.push({\n        type: event.event || 'message',\n        options: {\n          data: event.data,\n          lastEventId: this.state.lastEventId,\n          origin: this.state.origin\n        }\n      })\n    }\n  }\n\n  clearEvent () {\n    this.event = {\n      data: undefined,\n      event: undefined,\n      id: undefined,\n      retry: undefined\n    }\n  }\n}\n\nmodule.exports = {\n  EventSourceStream\n}\n","'use strict'\n\nconst { pipeline } = require('node:stream')\nconst { fetching } = require('../fetch')\nconst { makeRequest } = require('../fetch/request')\nconst { webidl } = require('../fetch/webidl')\nconst { EventSourceStream } = require('./eventsource-stream')\nconst { parseMIMEType } = require('../fetch/data-url')\nconst { createFastMessageEvent } = require('../websocket/events')\nconst { isNetworkError } = require('../fetch/response')\nconst { delay } = require('./util')\nconst { kEnumerableProperty } = require('../../core/util')\nconst { environmentSettingsObject } = require('../fetch/util')\n\nlet experimentalWarned = false\n\n/**\n * A reconnection time, in milliseconds. This must initially be an implementation-defined value,\n * probably in the region of a few seconds.\n *\n * In Comparison:\n * - Chrome uses 3000ms.\n * - Deno uses 5000ms.\n *\n * @type {3000}\n */\nconst defaultReconnectionTime = 3000\n\n/**\n * The readyState attribute represents the state of the connection.\n * @enum\n * @readonly\n * @see https://html.spec.whatwg.org/multipage/server-sent-events.html#dom-eventsource-readystate-dev\n */\n\n/**\n * The connection has not yet been established, or it was closed and the user\n * agent is reconnecting.\n * @type {0}\n */\nconst CONNECTING = 0\n\n/**\n * The user agent has an open connection and is dispatching events as it\n * receives them.\n * @type {1}\n */\nconst OPEN = 1\n\n/**\n * The connection is not open, and the user agent is not trying to reconnect.\n * @type {2}\n */\nconst CLOSED = 2\n\n/**\n * Requests for the element will have their mode set to \"cors\" and their credentials mode set to \"same-origin\".\n * @type {'anonymous'}\n */\nconst ANONYMOUS = 'anonymous'\n\n/**\n * Requests for the element will have their mode set to \"cors\" and their credentials mode set to \"include\".\n * @type {'use-credentials'}\n */\nconst USE_CREDENTIALS = 'use-credentials'\n\n/**\n * The EventSource interface is used to receive server-sent events. It\n * connects to a server over HTTP and receives events in text/event-stream\n * format without closing the connection.\n * @extends {EventTarget}\n * @see https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events\n * @api public\n */\nclass EventSource extends EventTarget {\n  #events = {\n    open: null,\n    error: null,\n    message: null\n  }\n\n  #url = null\n  #withCredentials = false\n\n  #readyState = CONNECTING\n\n  #request = null\n  #controller = null\n\n  #dispatcher\n\n  /**\n   * @type {import('./eventsource-stream').eventSourceSettings}\n   */\n  #state\n\n  /**\n   * Creates a new EventSource object.\n   * @param {string} url\n   * @param {EventSourceInit} [eventSourceInitDict]\n   * @see https://html.spec.whatwg.org/multipage/server-sent-events.html#the-eventsource-interface\n   */\n  constructor (url, eventSourceInitDict = {}) {\n    // 1. Let ev be a new EventSource object.\n    super()\n\n    webidl.util.markAsUncloneable(this)\n\n    const prefix = 'EventSource constructor'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    if (!experimentalWarned) {\n      experimentalWarned = true\n      process.emitWarning('EventSource is experimental, expect them to change at any time.', {\n        code: 'UNDICI-ES'\n      })\n    }\n\n    url = webidl.converters.USVString(url, prefix, 'url')\n    eventSourceInitDict = webidl.converters.EventSourceInitDict(eventSourceInitDict, prefix, 'eventSourceInitDict')\n\n    this.#dispatcher = eventSourceInitDict.dispatcher\n    this.#state = {\n      lastEventId: '',\n      reconnectionTime: defaultReconnectionTime\n    }\n\n    // 2. Let settings be ev's relevant settings object.\n    // https://html.spec.whatwg.org/multipage/webappapis.html#environment-settings-object\n    const settings = environmentSettingsObject\n\n    let urlRecord\n\n    try {\n      // 3. Let urlRecord be the result of encoding-parsing a URL given url, relative to settings.\n      urlRecord = new URL(url, settings.settingsObject.baseUrl)\n      this.#state.origin = urlRecord.origin\n    } catch (e) {\n      // 4. If urlRecord is failure, then throw a \"SyntaxError\" DOMException.\n      throw new DOMException(e, 'SyntaxError')\n    }\n\n    // 5. Set ev's url to urlRecord.\n    this.#url = urlRecord.href\n\n    // 6. Let corsAttributeState be Anonymous.\n    let corsAttributeState = ANONYMOUS\n\n    // 7. If the value of eventSourceInitDict's withCredentials member is true,\n    // then set corsAttributeState to Use Credentials and set ev's\n    // withCredentials attribute to true.\n    if (eventSourceInitDict.withCredentials) {\n      corsAttributeState = USE_CREDENTIALS\n      this.#withCredentials = true\n    }\n\n    // 8. Let request be the result of creating a potential-CORS request given\n    // urlRecord, the empty string, and corsAttributeState.\n    const initRequest = {\n      redirect: 'follow',\n      keepalive: true,\n      // @see https://html.spec.whatwg.org/multipage/urls-and-fetching.html#cors-settings-attributes\n      mode: 'cors',\n      credentials: corsAttributeState === 'anonymous'\n        ? 'same-origin'\n        : 'omit',\n      referrer: 'no-referrer'\n    }\n\n    // 9. Set request's client to settings.\n    initRequest.client = environmentSettingsObject.settingsObject\n\n    // 10. User agents may set (`Accept`, `text/event-stream`) in request's header list.\n    initRequest.headersList = [['accept', { name: 'accept', value: 'text/event-stream' }]]\n\n    // 11. Set request's cache mode to \"no-store\".\n    initRequest.cache = 'no-store'\n\n    // 12. Set request's initiator type to \"other\".\n    initRequest.initiator = 'other'\n\n    initRequest.urlList = [new URL(this.#url)]\n\n    // 13. Set ev's request to request.\n    this.#request = makeRequest(initRequest)\n\n    this.#connect()\n  }\n\n  /**\n   * Returns the state of this EventSource object's connection. It can have the\n   * values described below.\n   * @returns {0|1|2}\n   * @readonly\n   */\n  get readyState () {\n    return this.#readyState\n  }\n\n  /**\n   * Returns the URL providing the event stream.\n   * @readonly\n   * @returns {string}\n   */\n  get url () {\n    return this.#url\n  }\n\n  /**\n   * Returns a boolean indicating whether the EventSource object was\n   * instantiated with CORS credentials set (true), or not (false, the default).\n   */\n  get withCredentials () {\n    return this.#withCredentials\n  }\n\n  #connect () {\n    if (this.#readyState === CLOSED) return\n\n    this.#readyState = CONNECTING\n\n    const fetchParams = {\n      request: this.#request,\n      dispatcher: this.#dispatcher\n    }\n\n    // 14. Let processEventSourceEndOfBody given response res be the following step: if res is not a network error, then reestablish the connection.\n    const processEventSourceEndOfBody = (response) => {\n      if (isNetworkError(response)) {\n        this.dispatchEvent(new Event('error'))\n        this.close()\n      }\n\n      this.#reconnect()\n    }\n\n    // 15. Fetch request, with processResponseEndOfBody set to processEventSourceEndOfBody...\n    fetchParams.processResponseEndOfBody = processEventSourceEndOfBody\n\n    // and processResponse set to the following steps given response res:\n    fetchParams.processResponse = (response) => {\n      // 1. If res is an aborted network error, then fail the connection.\n\n      if (isNetworkError(response)) {\n        // 1. When a user agent is to fail the connection, the user agent\n        // must queue a task which, if the readyState attribute is set to a\n        // value other than CLOSED, sets the readyState attribute to CLOSED\n        // and fires an event named error at the EventSource object. Once the\n        // user agent has failed the connection, it does not attempt to\n        // reconnect.\n        if (response.aborted) {\n          this.close()\n          this.dispatchEvent(new Event('error'))\n          return\n          // 2. Otherwise, if res is a network error, then reestablish the\n          // connection, unless the user agent knows that to be futile, in\n          // which case the user agent may fail the connection.\n        } else {\n          this.#reconnect()\n          return\n        }\n      }\n\n      // 3. Otherwise, if res's status is not 200, or if res's `Content-Type`\n      // is not `text/event-stream`, then fail the connection.\n      const contentType = response.headersList.get('content-type', true)\n      const mimeType = contentType !== null ? parseMIMEType(contentType) : 'failure'\n      const contentTypeValid = mimeType !== 'failure' && mimeType.essence === 'text/event-stream'\n      if (\n        response.status !== 200 ||\n        contentTypeValid === false\n      ) {\n        this.close()\n        this.dispatchEvent(new Event('error'))\n        return\n      }\n\n      // 4. Otherwise, announce the connection and interpret res's body\n      // line by line.\n\n      // When a user agent is to announce the connection, the user agent\n      // must queue a task which, if the readyState attribute is set to a\n      // value other than CLOSED, sets the readyState attribute to OPEN\n      // and fires an event named open at the EventSource object.\n      // @see https://html.spec.whatwg.org/multipage/server-sent-events.html#sse-processing-model\n      this.#readyState = OPEN\n      this.dispatchEvent(new Event('open'))\n\n      // If redirected to a different origin, set the origin to the new origin.\n      this.#state.origin = response.urlList[response.urlList.length - 1].origin\n\n      const eventSourceStream = new EventSourceStream({\n        eventSourceSettings: this.#state,\n        push: (event) => {\n          this.dispatchEvent(createFastMessageEvent(\n            event.type,\n            event.options\n          ))\n        }\n      })\n\n      pipeline(response.body.stream,\n        eventSourceStream,\n        (error) => {\n          if (\n            error?.aborted === false\n          ) {\n            this.close()\n            this.dispatchEvent(new Event('error'))\n          }\n        })\n    }\n\n    this.#controller = fetching(fetchParams)\n  }\n\n  /**\n   * @see https://html.spec.whatwg.org/multipage/server-sent-events.html#sse-processing-model\n   * @returns {Promise<void>}\n   */\n  async #reconnect () {\n    // When a user agent is to reestablish the connection, the user agent must\n    // run the following steps. These steps are run in parallel, not as part of\n    // a task. (The tasks that it queues, of course, are run like normal tasks\n    // and not themselves in parallel.)\n\n    // 1. Queue a task to run the following steps:\n\n    //   1. If the readyState attribute is set to CLOSED, abort the task.\n    if (this.#readyState === CLOSED) return\n\n    //   2. Set the readyState attribute to CONNECTING.\n    this.#readyState = CONNECTING\n\n    //   3. Fire an event named error at the EventSource object.\n    this.dispatchEvent(new Event('error'))\n\n    // 2. Wait a delay equal to the reconnection time of the event source.\n    await delay(this.#state.reconnectionTime)\n\n    // 5. Queue a task to run the following steps:\n\n    //   1. If the EventSource object's readyState attribute is not set to\n    //      CONNECTING, then return.\n    if (this.#readyState !== CONNECTING) return\n\n    //   2. Let request be the EventSource object's request.\n    //   3. If the EventSource object's last event ID string is not the empty\n    //      string, then:\n    //      1. Let lastEventIDValue be the EventSource object's last event ID\n    //         string, encoded as UTF-8.\n    //      2. Set (`Last-Event-ID`, lastEventIDValue) in request's header\n    //         list.\n    if (this.#state.lastEventId.length) {\n      this.#request.headersList.set('last-event-id', this.#state.lastEventId, true)\n    }\n\n    //   4. Fetch request and process the response obtained in this fashion, if any, as described earlier in this section.\n    this.#connect()\n  }\n\n  /**\n   * Closes the connection, if any, and sets the readyState attribute to\n   * CLOSED.\n   */\n  close () {\n    webidl.brandCheck(this, EventSource)\n\n    if (this.#readyState === CLOSED) return\n    this.#readyState = CLOSED\n    this.#controller.abort()\n    this.#request = null\n  }\n\n  get onopen () {\n    return this.#events.open\n  }\n\n  set onopen (fn) {\n    if (this.#events.open) {\n      this.removeEventListener('open', this.#events.open)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.open = fn\n      this.addEventListener('open', fn)\n    } else {\n      this.#events.open = null\n    }\n  }\n\n  get onmessage () {\n    return this.#events.message\n  }\n\n  set onmessage (fn) {\n    if (this.#events.message) {\n      this.removeEventListener('message', this.#events.message)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.message = fn\n      this.addEventListener('message', fn)\n    } else {\n      this.#events.message = null\n    }\n  }\n\n  get onerror () {\n    return this.#events.error\n  }\n\n  set onerror (fn) {\n    if (this.#events.error) {\n      this.removeEventListener('error', this.#events.error)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.error = fn\n      this.addEventListener('error', fn)\n    } else {\n      this.#events.error = null\n    }\n  }\n}\n\nconst constantsPropertyDescriptors = {\n  CONNECTING: {\n    __proto__: null,\n    configurable: false,\n    enumerable: true,\n    value: CONNECTING,\n    writable: false\n  },\n  OPEN: {\n    __proto__: null,\n    configurable: false,\n    enumerable: true,\n    value: OPEN,\n    writable: false\n  },\n  CLOSED: {\n    __proto__: null,\n    configurable: false,\n    enumerable: true,\n    value: CLOSED,\n    writable: false\n  }\n}\n\nObject.defineProperties(EventSource, constantsPropertyDescriptors)\nObject.defineProperties(EventSource.prototype, constantsPropertyDescriptors)\n\nObject.defineProperties(EventSource.prototype, {\n  close: kEnumerableProperty,\n  onerror: kEnumerableProperty,\n  onmessage: kEnumerableProperty,\n  onopen: kEnumerableProperty,\n  readyState: kEnumerableProperty,\n  url: kEnumerableProperty,\n  withCredentials: kEnumerableProperty\n})\n\nwebidl.converters.EventSourceInitDict = webidl.dictionaryConverter([\n  {\n    key: 'withCredentials',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'dispatcher', // undici only\n    converter: webidl.converters.any\n  }\n])\n\nmodule.exports = {\n  EventSource,\n  defaultReconnectionTime\n}\n","'use strict'\n\n/**\n * Checks if the given value is a valid LastEventId.\n * @param {string} value\n * @returns {boolean}\n */\nfunction isValidLastEventId (value) {\n  // LastEventId should not contain U+0000 NULL\n  return value.indexOf('\\u0000') === -1\n}\n\n/**\n * Checks if the given value is a base 10 digit.\n * @param {string} value\n * @returns {boolean}\n */\nfunction isASCIINumber (value) {\n  if (value.length === 0) return false\n  for (let i = 0; i < value.length; i++) {\n    if (value.charCodeAt(i) < 0x30 || value.charCodeAt(i) > 0x39) return false\n  }\n  return true\n}\n\n// https://github.com/nodejs/undici/issues/2664\nfunction delay (ms) {\n  return new Promise((resolve) => {\n    setTimeout(resolve, ms).unref()\n  })\n}\n\nmodule.exports = {\n  isValidLastEventId,\n  isASCIINumber,\n  delay\n}\n","'use strict'\n\nconst util = require('../../core/util')\nconst {\n  ReadableStreamFrom,\n  isBlobLike,\n  isReadableStreamLike,\n  readableStreamClose,\n  createDeferredPromise,\n  fullyReadBody,\n  extractMimeType,\n  utf8DecodeBytes\n} = require('./util')\nconst { FormData } = require('./formdata')\nconst { kState } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { Blob } = require('node:buffer')\nconst assert = require('node:assert')\nconst { isErrored, isDisturbed } = require('node:stream')\nconst { isArrayBuffer } = require('node:util/types')\nconst { serializeAMimeType } = require('./data-url')\nconst { multipartFormDataParser } = require('./formdata-parser')\nlet random\n\ntry {\n  const crypto = require('node:crypto')\n  random = (max) => crypto.randomInt(0, max)\n} catch {\n  random = (max) => Math.floor(Math.random(max))\n}\n\nconst textEncoder = new TextEncoder()\nfunction noop () {}\n\nconst hasFinalizationRegistry = globalThis.FinalizationRegistry && process.version.indexOf('v18') !== 0\nlet streamRegistry\n\nif (hasFinalizationRegistry) {\n  streamRegistry = new FinalizationRegistry((weakRef) => {\n    const stream = weakRef.deref()\n    if (stream && !stream.locked && !isDisturbed(stream) && !isErrored(stream)) {\n      stream.cancel('Response object has been garbage collected').catch(noop)\n    }\n  })\n}\n\n// https://fetch.spec.whatwg.org/#concept-bodyinit-extract\nfunction extractBody (object, keepalive = false) {\n  // 1. Let stream be null.\n  let stream = null\n\n  // 2. If object is a ReadableStream object, then set stream to object.\n  if (object instanceof ReadableStream) {\n    stream = object\n  } else if (isBlobLike(object)) {\n    // 3. Otherwise, if object is a Blob object, set stream to the\n    //    result of running objects get stream.\n    stream = object.stream()\n  } else {\n    // 4. Otherwise, set stream to a new ReadableStream object, and set\n    //    up stream with byte reading support.\n    stream = new ReadableStream({\n      async pull (controller) {\n        const buffer = typeof source === 'string' ? textEncoder.encode(source) : source\n\n        if (buffer.byteLength) {\n          controller.enqueue(buffer)\n        }\n\n        queueMicrotask(() => readableStreamClose(controller))\n      },\n      start () {},\n      type: 'bytes'\n    })\n  }\n\n  // 5. Assert: stream is a ReadableStream object.\n  assert(isReadableStreamLike(stream))\n\n  // 6. Let action be null.\n  let action = null\n\n  // 7. Let source be null.\n  let source = null\n\n  // 8. Let length be null.\n  let length = null\n\n  // 9. Let type be null.\n  let type = null\n\n  // 10. Switch on object:\n  if (typeof object === 'string') {\n    // Set source to the UTF-8 encoding of object.\n    // Note: setting source to a Uint8Array here breaks some mocking assumptions.\n    source = object\n\n    // Set type to `text/plain;charset=UTF-8`.\n    type = 'text/plain;charset=UTF-8'\n  } else if (object instanceof URLSearchParams) {\n    // URLSearchParams\n\n    // spec says to run application/x-www-form-urlencoded on body.list\n    // this is implemented in Node.js as apart of an URLSearchParams instance toString method\n    // See: https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L490\n    // and https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L1100\n\n    // Set source to the result of running the application/x-www-form-urlencoded serializer with objects list.\n    source = object.toString()\n\n    // Set type to `application/x-www-form-urlencoded;charset=UTF-8`.\n    type = 'application/x-www-form-urlencoded;charset=UTF-8'\n  } else if (isArrayBuffer(object)) {\n    // BufferSource/ArrayBuffer\n\n    // Set source to a copy of the bytes held by object.\n    source = new Uint8Array(object.slice())\n  } else if (ArrayBuffer.isView(object)) {\n    // BufferSource/ArrayBufferView\n\n    // Set source to a copy of the bytes held by object.\n    source = new Uint8Array(object.buffer.slice(object.byteOffset, object.byteOffset + object.byteLength))\n  } else if (util.isFormDataLike(object)) {\n    const boundary = `----formdata-undici-0${`${random(1e11)}`.padStart(11, '0')}`\n    const prefix = `--${boundary}\\r\\nContent-Disposition: form-data`\n\n    /*! formdata-polyfill. MIT License. Jimmy Wrting <https://jimmy.warting.se/opensource> */\n    const escape = (str) =>\n      str.replace(/\\n/g, '%0A').replace(/\\r/g, '%0D').replace(/\"/g, '%22')\n    const normalizeLinefeeds = (value) => value.replace(/\\r?\\n|\\r/g, '\\r\\n')\n\n    // Set action to this step: run the multipart/form-data\n    // encoding algorithm, with objects entry list and UTF-8.\n    // - This ensures that the body is immutable and can't be changed afterwords\n    // - That the content-length is calculated in advance.\n    // - And that all parts are pre-encoded and ready to be sent.\n\n    const blobParts = []\n    const rn = new Uint8Array([13, 10]) // '\\r\\n'\n    length = 0\n    let hasUnknownSizeValue = false\n\n    for (const [name, value] of object) {\n      if (typeof value === 'string') {\n        const chunk = textEncoder.encode(prefix +\n          `; name=\"${escape(normalizeLinefeeds(name))}\"` +\n          `\\r\\n\\r\\n${normalizeLinefeeds(value)}\\r\\n`)\n        blobParts.push(chunk)\n        length += chunk.byteLength\n      } else {\n        const chunk = textEncoder.encode(`${prefix}; name=\"${escape(normalizeLinefeeds(name))}\"` +\n          (value.name ? `; filename=\"${escape(value.name)}\"` : '') + '\\r\\n' +\n          `Content-Type: ${\n            value.type || 'application/octet-stream'\n          }\\r\\n\\r\\n`)\n        blobParts.push(chunk, value, rn)\n        if (typeof value.size === 'number') {\n          length += chunk.byteLength + value.size + rn.byteLength\n        } else {\n          hasUnknownSizeValue = true\n        }\n      }\n    }\n\n    // CRLF is appended to the body to function with legacy servers and match other implementations.\n    // https://github.com/curl/curl/blob/3434c6b46e682452973972e8313613dfa58cd690/lib/mime.c#L1029-L1030\n    // https://github.com/form-data/form-data/issues/63\n    const chunk = textEncoder.encode(`--${boundary}--\\r\\n`)\n    blobParts.push(chunk)\n    length += chunk.byteLength\n    if (hasUnknownSizeValue) {\n      length = null\n    }\n\n    // Set source to object.\n    source = object\n\n    action = async function * () {\n      for (const part of blobParts) {\n        if (part.stream) {\n          yield * part.stream()\n        } else {\n          yield part\n        }\n      }\n    }\n\n    // Set type to `multipart/form-data; boundary=`,\n    // followed by the multipart/form-data boundary string generated\n    // by the multipart/form-data encoding algorithm.\n    type = `multipart/form-data; boundary=${boundary}`\n  } else if (isBlobLike(object)) {\n    // Blob\n\n    // Set source to object.\n    source = object\n\n    // Set length to objects size.\n    length = object.size\n\n    // If objects type attribute is not the empty byte sequence, set\n    // type to its value.\n    if (object.type) {\n      type = object.type\n    }\n  } else if (typeof object[Symbol.asyncIterator] === 'function') {\n    // If keepalive is true, then throw a TypeError.\n    if (keepalive) {\n      throw new TypeError('keepalive')\n    }\n\n    // If object is disturbed or locked, then throw a TypeError.\n    if (util.isDisturbed(object) || object.locked) {\n      throw new TypeError(\n        'Response body object should not be disturbed or locked'\n      )\n    }\n\n    stream =\n      object instanceof ReadableStream ? object : ReadableStreamFrom(object)\n  }\n\n  // 11. If source is a byte sequence, then set action to a\n  // step that returns source and length to sources length.\n  if (typeof source === 'string' || util.isBuffer(source)) {\n    length = Buffer.byteLength(source)\n  }\n\n  // 12. If action is non-null, then run these steps in in parallel:\n  if (action != null) {\n    // Run action.\n    let iterator\n    stream = new ReadableStream({\n      async start () {\n        iterator = action(object)[Symbol.asyncIterator]()\n      },\n      async pull (controller) {\n        const { value, done } = await iterator.next()\n        if (done) {\n          // When running action is done, close stream.\n          queueMicrotask(() => {\n            controller.close()\n            controller.byobRequest?.respond(0)\n          })\n        } else {\n          // Whenever one or more bytes are available and stream is not errored,\n          // enqueue a Uint8Array wrapping an ArrayBuffer containing the available\n          // bytes into stream.\n          if (!isErrored(stream)) {\n            const buffer = new Uint8Array(value)\n            if (buffer.byteLength) {\n              controller.enqueue(buffer)\n            }\n          }\n        }\n        return controller.desiredSize > 0\n      },\n      async cancel (reason) {\n        await iterator.return()\n      },\n      type: 'bytes'\n    })\n  }\n\n  // 13. Let body be a body whose stream is stream, source is source,\n  // and length is length.\n  const body = { stream, source, length }\n\n  // 14. Return (body, type).\n  return [body, type]\n}\n\n// https://fetch.spec.whatwg.org/#bodyinit-safely-extract\nfunction safelyExtractBody (object, keepalive = false) {\n  // To safely extract a body and a `Content-Type` value from\n  // a byte sequence or BodyInit object object, run these steps:\n\n  // 1. If object is a ReadableStream object, then:\n  if (object instanceof ReadableStream) {\n    // Assert: object is neither disturbed nor locked.\n    // istanbul ignore next\n    assert(!util.isDisturbed(object), 'The body has already been consumed.')\n    // istanbul ignore next\n    assert(!object.locked, 'The stream is locked.')\n  }\n\n  // 2. Return the results of extracting object.\n  return extractBody(object, keepalive)\n}\n\nfunction cloneBody (instance, body) {\n  // To clone a body body, run these steps:\n\n  // https://fetch.spec.whatwg.org/#concept-body-clone\n\n  // 1. Let  out1, out2  be the result of teeing bodys stream.\n  const [out1, out2] = body.stream.tee()\n\n  // 2. Set bodys stream to out1.\n  body.stream = out1\n\n  // 3. Return a body whose stream is out2 and other members are copied from body.\n  return {\n    stream: out2,\n    length: body.length,\n    source: body.source\n  }\n}\n\nfunction throwIfAborted (state) {\n  if (state.aborted) {\n    throw new DOMException('The operation was aborted.', 'AbortError')\n  }\n}\n\nfunction bodyMixinMethods (instance) {\n  const methods = {\n    blob () {\n      // The blob() method steps are to return the result of\n      // running consume body with this and the following step\n      // given a byte sequence bytes: return a Blob whose\n      // contents are bytes and whose type attribute is thiss\n      // MIME type.\n      return consumeBody(this, (bytes) => {\n        let mimeType = bodyMimeType(this)\n\n        if (mimeType === null) {\n          mimeType = ''\n        } else if (mimeType) {\n          mimeType = serializeAMimeType(mimeType)\n        }\n\n        // Return a Blob whose contents are bytes and type attribute\n        // is mimeType.\n        return new Blob([bytes], { type: mimeType })\n      }, instance)\n    },\n\n    arrayBuffer () {\n      // The arrayBuffer() method steps are to return the result\n      // of running consume body with this and the following step\n      // given a byte sequence bytes: return a new ArrayBuffer\n      // whose contents are bytes.\n      return consumeBody(this, (bytes) => {\n        return new Uint8Array(bytes).buffer\n      }, instance)\n    },\n\n    text () {\n      // The text() method steps are to return the result of running\n      // consume body with this and UTF-8 decode.\n      return consumeBody(this, utf8DecodeBytes, instance)\n    },\n\n    json () {\n      // The json() method steps are to return the result of running\n      // consume body with this and parse JSON from bytes.\n      return consumeBody(this, parseJSONFromBytes, instance)\n    },\n\n    formData () {\n      // The formData() method steps are to return the result of running\n      // consume body with this and the following step given a byte sequence bytes:\n      return consumeBody(this, (value) => {\n        // 1. Let mimeType be the result of get the MIME type with this.\n        const mimeType = bodyMimeType(this)\n\n        // 2. If mimeType is non-null, then switch on mimeTypes essence and run\n        //    the corresponding steps:\n        if (mimeType !== null) {\n          switch (mimeType.essence) {\n            case 'multipart/form-data': {\n              // 1. ... [long step]\n              const parsed = multipartFormDataParser(value, mimeType)\n\n              // 2. If that fails for some reason, then throw a TypeError.\n              if (parsed === 'failure') {\n                throw new TypeError('Failed to parse body as FormData.')\n              }\n\n              // 3. Return a new FormData object, appending each entry,\n              //    resulting from the parsing operation, to its entry list.\n              const fd = new FormData()\n              fd[kState] = parsed\n\n              return fd\n            }\n            case 'application/x-www-form-urlencoded': {\n              // 1. Let entries be the result of parsing bytes.\n              const entries = new URLSearchParams(value.toString())\n\n              // 2. If entries is failure, then throw a TypeError.\n\n              // 3. Return a new FormData object whose entry list is entries.\n              const fd = new FormData()\n\n              for (const [name, value] of entries) {\n                fd.append(name, value)\n              }\n\n              return fd\n            }\n          }\n        }\n\n        // 3. Throw a TypeError.\n        throw new TypeError(\n          'Content-Type was not one of \"multipart/form-data\" or \"application/x-www-form-urlencoded\".'\n        )\n      }, instance)\n    },\n\n    bytes () {\n      // The bytes() method steps are to return the result of running consume body\n      // with this and the following step given a byte sequence bytes: return the\n      // result of creating a Uint8Array from bytes in thiss relevant realm.\n      return consumeBody(this, (bytes) => {\n        return new Uint8Array(bytes)\n      }, instance)\n    }\n  }\n\n  return methods\n}\n\nfunction mixinBody (prototype) {\n  Object.assign(prototype.prototype, bodyMixinMethods(prototype))\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-body-consume-body\n * @param {Response|Request} object\n * @param {(value: unknown) => unknown} convertBytesToJSValue\n * @param {Response|Request} instance\n */\nasync function consumeBody (object, convertBytesToJSValue, instance) {\n  webidl.brandCheck(object, instance)\n\n  // 1. If object is unusable, then return a promise rejected\n  //    with a TypeError.\n  if (bodyUnusable(object)) {\n    throw new TypeError('Body is unusable: Body has already been read')\n  }\n\n  throwIfAborted(object[kState])\n\n  // 2. Let promise be a new promise.\n  const promise = createDeferredPromise()\n\n  // 3. Let errorSteps given error be to reject promise with error.\n  const errorSteps = (error) => promise.reject(error)\n\n  // 4. Let successSteps given a byte sequence data be to resolve\n  //    promise with the result of running convertBytesToJSValue\n  //    with data. If that threw an exception, then run errorSteps\n  //    with that exception.\n  const successSteps = (data) => {\n    try {\n      promise.resolve(convertBytesToJSValue(data))\n    } catch (e) {\n      errorSteps(e)\n    }\n  }\n\n  // 5. If objects body is null, then run successSteps with an\n  //    empty byte sequence.\n  if (object[kState].body == null) {\n    successSteps(Buffer.allocUnsafe(0))\n    return promise.promise\n  }\n\n  // 6. Otherwise, fully read objects body given successSteps,\n  //    errorSteps, and objects relevant global object.\n  await fullyReadBody(object[kState].body, successSteps, errorSteps)\n\n  // 7. Return promise.\n  return promise.promise\n}\n\n// https://fetch.spec.whatwg.org/#body-unusable\nfunction bodyUnusable (object) {\n  const body = object[kState].body\n\n  // An object including the Body interface mixin is\n  // said to be unusable if its body is non-null and\n  // its bodys stream is disturbed or locked.\n  return body != null && (body.stream.locked || util.isDisturbed(body.stream))\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#parse-json-bytes-to-a-javascript-value\n * @param {Uint8Array} bytes\n */\nfunction parseJSONFromBytes (bytes) {\n  return JSON.parse(utf8DecodeBytes(bytes))\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-body-mime-type\n * @param {import('./response').Response|import('./request').Request} requestOrResponse\n */\nfunction bodyMimeType (requestOrResponse) {\n  // 1. Let headers be null.\n  // 2. If requestOrResponse is a Request object, then set headers to requestOrResponses requests header list.\n  // 3. Otherwise, set headers to requestOrResponses responses header list.\n  /** @type {import('./headers').HeadersList} */\n  const headers = requestOrResponse[kState].headersList\n\n  // 4. Let mimeType be the result of extracting a MIME type from headers.\n  const mimeType = extractMimeType(headers)\n\n  // 5. If mimeType is failure, then return null.\n  if (mimeType === 'failure') {\n    return null\n  }\n\n  // 6. Return mimeType.\n  return mimeType\n}\n\nmodule.exports = {\n  extractBody,\n  safelyExtractBody,\n  cloneBody,\n  mixinBody,\n  streamRegistry,\n  hasFinalizationRegistry,\n  bodyUnusable\n}\n","'use strict'\n\nconst corsSafeListedMethods = /** @type {const} */ (['GET', 'HEAD', 'POST'])\nconst corsSafeListedMethodsSet = new Set(corsSafeListedMethods)\n\nconst nullBodyStatus = /** @type {const} */ ([101, 204, 205, 304])\n\nconst redirectStatus = /** @type {const} */ ([301, 302, 303, 307, 308])\nconst redirectStatusSet = new Set(redirectStatus)\n\n/**\n * @see https://fetch.spec.whatwg.org/#block-bad-port\n */\nconst badPorts = /** @type {const} */ ([\n  '1', '7', '9', '11', '13', '15', '17', '19', '20', '21', '22', '23', '25', '37', '42', '43', '53', '69', '77', '79',\n  '87', '95', '101', '102', '103', '104', '109', '110', '111', '113', '115', '117', '119', '123', '135', '137',\n  '139', '143', '161', '179', '389', '427', '465', '512', '513', '514', '515', '526', '530', '531', '532',\n  '540', '548', '554', '556', '563', '587', '601', '636', '989', '990', '993', '995', '1719', '1720', '1723',\n  '2049', '3659', '4045', '4190', '5060', '5061', '6000', '6566', '6665', '6666', '6667', '6668', '6669', '6679',\n  '6697', '10080'\n])\nconst badPortsSet = new Set(badPorts)\n\n/**\n * @see https://w3c.github.io/webappsec-referrer-policy/#referrer-policies\n */\nconst referrerPolicy = /** @type {const} */ ([\n  '',\n  'no-referrer',\n  'no-referrer-when-downgrade',\n  'same-origin',\n  'origin',\n  'strict-origin',\n  'origin-when-cross-origin',\n  'strict-origin-when-cross-origin',\n  'unsafe-url'\n])\nconst referrerPolicySet = new Set(referrerPolicy)\n\nconst requestRedirect = /** @type {const} */ (['follow', 'manual', 'error'])\n\nconst safeMethods = /** @type {const} */ (['GET', 'HEAD', 'OPTIONS', 'TRACE'])\nconst safeMethodsSet = new Set(safeMethods)\n\nconst requestMode = /** @type {const} */ (['navigate', 'same-origin', 'no-cors', 'cors'])\n\nconst requestCredentials = /** @type {const} */ (['omit', 'same-origin', 'include'])\n\nconst requestCache = /** @type {const} */ ([\n  'default',\n  'no-store',\n  'reload',\n  'no-cache',\n  'force-cache',\n  'only-if-cached'\n])\n\n/**\n * @see https://fetch.spec.whatwg.org/#request-body-header-name\n */\nconst requestBodyHeader = /** @type {const} */ ([\n  'content-encoding',\n  'content-language',\n  'content-location',\n  'content-type',\n  // See https://github.com/nodejs/undici/issues/2021\n  // 'Content-Length' is a forbidden header name, which is typically\n  // removed in the Headers implementation. However, undici doesn't\n  // filter out headers, so we add it here.\n  'content-length'\n])\n\n/**\n * @see https://fetch.spec.whatwg.org/#enumdef-requestduplex\n */\nconst requestDuplex = /** @type {const} */ ([\n  'half'\n])\n\n/**\n * @see http://fetch.spec.whatwg.org/#forbidden-method\n */\nconst forbiddenMethods = /** @type {const} */ (['CONNECT', 'TRACE', 'TRACK'])\nconst forbiddenMethodsSet = new Set(forbiddenMethods)\n\nconst subresource = /** @type {const} */ ([\n  'audio',\n  'audioworklet',\n  'font',\n  'image',\n  'manifest',\n  'paintworklet',\n  'script',\n  'style',\n  'track',\n  'video',\n  'xslt',\n  ''\n])\nconst subresourceSet = new Set(subresource)\n\nmodule.exports = {\n  subresource,\n  forbiddenMethods,\n  requestBodyHeader,\n  referrerPolicy,\n  requestRedirect,\n  requestMode,\n  requestCredentials,\n  requestCache,\n  redirectStatus,\n  corsSafeListedMethods,\n  nullBodyStatus,\n  safeMethods,\n  badPorts,\n  requestDuplex,\n  subresourceSet,\n  badPortsSet,\n  redirectStatusSet,\n  corsSafeListedMethodsSet,\n  safeMethodsSet,\n  forbiddenMethodsSet,\n  referrerPolicySet\n}\n","'use strict'\n\nconst assert = require('node:assert')\n\nconst encoder = new TextEncoder()\n\n/**\n * @see https://mimesniff.spec.whatwg.org/#http-token-code-point\n */\nconst HTTP_TOKEN_CODEPOINTS = /^[!#$%&'*+\\-.^_|~A-Za-z0-9]+$/\nconst HTTP_WHITESPACE_REGEX = /[\\u000A\\u000D\\u0009\\u0020]/ // eslint-disable-line\nconst ASCII_WHITESPACE_REPLACE_REGEX = /[\\u0009\\u000A\\u000C\\u000D\\u0020]/g // eslint-disable-line\n/**\n * @see https://mimesniff.spec.whatwg.org/#http-quoted-string-token-code-point\n */\nconst HTTP_QUOTED_STRING_TOKENS = /^[\\u0009\\u0020-\\u007E\\u0080-\\u00FF]+$/ // eslint-disable-line\n\n// https://fetch.spec.whatwg.org/#data-url-processor\n/** @param {URL} dataURL */\nfunction dataURLProcessor (dataURL) {\n  // 1. Assert: dataURLs scheme is \"data\".\n  assert(dataURL.protocol === 'data:')\n\n  // 2. Let input be the result of running the URL\n  // serializer on dataURL with exclude fragment\n  // set to true.\n  let input = URLSerializer(dataURL, true)\n\n  // 3. Remove the leading \"data:\" string from input.\n  input = input.slice(5)\n\n  // 4. Let position point at the start of input.\n  const position = { position: 0 }\n\n  // 5. Let mimeType be the result of collecting a\n  // sequence of code points that are not equal\n  // to U+002C (,), given position.\n  let mimeType = collectASequenceOfCodePointsFast(\n    ',',\n    input,\n    position\n  )\n\n  // 6. Strip leading and trailing ASCII whitespace\n  // from mimeType.\n  // Undici implementation note: we need to store the\n  // length because if the mimetype has spaces removed,\n  // the wrong amount will be sliced from the input in\n  // step #9\n  const mimeTypeLength = mimeType.length\n  mimeType = removeASCIIWhitespace(mimeType, true, true)\n\n  // 7. If position is past the end of input, then\n  // return failure\n  if (position.position >= input.length) {\n    return 'failure'\n  }\n\n  // 8. Advance position by 1.\n  position.position++\n\n  // 9. Let encodedBody be the remainder of input.\n  const encodedBody = input.slice(mimeTypeLength + 1)\n\n  // 10. Let body be the percent-decoding of encodedBody.\n  let body = stringPercentDecode(encodedBody)\n\n  // 11. If mimeType ends with U+003B (;), followed by\n  // zero or more U+0020 SPACE, followed by an ASCII\n  // case-insensitive match for \"base64\", then:\n  if (/;(\\u0020){0,}base64$/i.test(mimeType)) {\n    // 1. Let stringBody be the isomorphic decode of body.\n    const stringBody = isomorphicDecode(body)\n\n    // 2. Set body to the forgiving-base64 decode of\n    // stringBody.\n    body = forgivingBase64(stringBody)\n\n    // 3. If body is failure, then return failure.\n    if (body === 'failure') {\n      return 'failure'\n    }\n\n    // 4. Remove the last 6 code points from mimeType.\n    mimeType = mimeType.slice(0, -6)\n\n    // 5. Remove trailing U+0020 SPACE code points from mimeType,\n    // if any.\n    mimeType = mimeType.replace(/(\\u0020)+$/, '')\n\n    // 6. Remove the last U+003B (;) code point from mimeType.\n    mimeType = mimeType.slice(0, -1)\n  }\n\n  // 12. If mimeType starts with U+003B (;), then prepend\n  // \"text/plain\" to mimeType.\n  if (mimeType.startsWith(';')) {\n    mimeType = 'text/plain' + mimeType\n  }\n\n  // 13. Let mimeTypeRecord be the result of parsing\n  // mimeType.\n  let mimeTypeRecord = parseMIMEType(mimeType)\n\n  // 14. If mimeTypeRecord is failure, then set\n  // mimeTypeRecord to text/plain;charset=US-ASCII.\n  if (mimeTypeRecord === 'failure') {\n    mimeTypeRecord = parseMIMEType('text/plain;charset=US-ASCII')\n  }\n\n  // 15. Return a new data: URL struct whose MIME\n  // type is mimeTypeRecord and body is body.\n  // https://fetch.spec.whatwg.org/#data-url-struct\n  return { mimeType: mimeTypeRecord, body }\n}\n\n// https://url.spec.whatwg.org/#concept-url-serializer\n/**\n * @param {URL} url\n * @param {boolean} excludeFragment\n */\nfunction URLSerializer (url, excludeFragment = false) {\n  if (!excludeFragment) {\n    return url.href\n  }\n\n  const href = url.href\n  const hashLength = url.hash.length\n\n  const serialized = hashLength === 0 ? href : href.substring(0, href.length - hashLength)\n\n  if (!hashLength && href.endsWith('#')) {\n    return serialized.slice(0, -1)\n  }\n\n  return serialized\n}\n\n// https://infra.spec.whatwg.org/#collect-a-sequence-of-code-points\n/**\n * @param {(char: string) => boolean} condition\n * @param {string} input\n * @param {{ position: number }} position\n */\nfunction collectASequenceOfCodePoints (condition, input, position) {\n  // 1. Let result be the empty string.\n  let result = ''\n\n  // 2. While position doesnt point past the end of input and the\n  // code point at position within input meets the condition condition:\n  while (position.position < input.length && condition(input[position.position])) {\n    // 1. Append that code point to the end of result.\n    result += input[position.position]\n\n    // 2. Advance position by 1.\n    position.position++\n  }\n\n  // 3. Return result.\n  return result\n}\n\n/**\n * A faster collectASequenceOfCodePoints that only works when comparing a single character.\n * @param {string} char\n * @param {string} input\n * @param {{ position: number }} position\n */\nfunction collectASequenceOfCodePointsFast (char, input, position) {\n  const idx = input.indexOf(char, position.position)\n  const start = position.position\n\n  if (idx === -1) {\n    position.position = input.length\n    return input.slice(start)\n  }\n\n  position.position = idx\n  return input.slice(start, position.position)\n}\n\n// https://url.spec.whatwg.org/#string-percent-decode\n/** @param {string} input */\nfunction stringPercentDecode (input) {\n  // 1. Let bytes be the UTF-8 encoding of input.\n  const bytes = encoder.encode(input)\n\n  // 2. Return the percent-decoding of bytes.\n  return percentDecode(bytes)\n}\n\n/**\n * @param {number} byte\n */\nfunction isHexCharByte (byte) {\n  // 0-9 A-F a-f\n  return (byte >= 0x30 && byte <= 0x39) || (byte >= 0x41 && byte <= 0x46) || (byte >= 0x61 && byte <= 0x66)\n}\n\n/**\n * @param {number} byte\n */\nfunction hexByteToNumber (byte) {\n  return (\n    // 0-9\n    byte >= 0x30 && byte <= 0x39\n      ? (byte - 48)\n    // Convert to uppercase\n    // ((byte & 0xDF) - 65) + 10\n      : ((byte & 0xDF) - 55)\n  )\n}\n\n// https://url.spec.whatwg.org/#percent-decode\n/** @param {Uint8Array} input */\nfunction percentDecode (input) {\n  const length = input.length\n  // 1. Let output be an empty byte sequence.\n  /** @type {Uint8Array} */\n  const output = new Uint8Array(length)\n  let j = 0\n  // 2. For each byte byte in input:\n  for (let i = 0; i < length; ++i) {\n    const byte = input[i]\n\n    // 1. If byte is not 0x25 (%), then append byte to output.\n    if (byte !== 0x25) {\n      output[j++] = byte\n\n    // 2. Otherwise, if byte is 0x25 (%) and the next two bytes\n    // after byte in input are not in the ranges\n    // 0x30 (0) to 0x39 (9), 0x41 (A) to 0x46 (F),\n    // and 0x61 (a) to 0x66 (f), all inclusive, append byte\n    // to output.\n    } else if (\n      byte === 0x25 &&\n      !(isHexCharByte(input[i + 1]) && isHexCharByte(input[i + 2]))\n    ) {\n      output[j++] = 0x25\n\n    // 3. Otherwise:\n    } else {\n      // 1. Let bytePoint be the two bytes after byte in input,\n      // decoded, and then interpreted as hexadecimal number.\n      // 2. Append a byte whose value is bytePoint to output.\n      output[j++] = (hexByteToNumber(input[i + 1]) << 4) | hexByteToNumber(input[i + 2])\n\n      // 3. Skip the next two bytes in input.\n      i += 2\n    }\n  }\n\n  // 3. Return output.\n  return length === j ? output : output.subarray(0, j)\n}\n\n// https://mimesniff.spec.whatwg.org/#parse-a-mime-type\n/** @param {string} input */\nfunction parseMIMEType (input) {\n  // 1. Remove any leading and trailing HTTP whitespace\n  // from input.\n  input = removeHTTPWhitespace(input, true, true)\n\n  // 2. Let position be a position variable for input,\n  // initially pointing at the start of input.\n  const position = { position: 0 }\n\n  // 3. Let type be the result of collecting a sequence\n  // of code points that are not U+002F (/) from\n  // input, given position.\n  const type = collectASequenceOfCodePointsFast(\n    '/',\n    input,\n    position\n  )\n\n  // 4. If type is the empty string or does not solely\n  // contain HTTP token code points, then return failure.\n  // https://mimesniff.spec.whatwg.org/#http-token-code-point\n  if (type.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(type)) {\n    return 'failure'\n  }\n\n  // 5. If position is past the end of input, then return\n  // failure\n  if (position.position > input.length) {\n    return 'failure'\n  }\n\n  // 6. Advance position by 1. (This skips past U+002F (/).)\n  position.position++\n\n  // 7. Let subtype be the result of collecting a sequence of\n  // code points that are not U+003B (;) from input, given\n  // position.\n  let subtype = collectASequenceOfCodePointsFast(\n    ';',\n    input,\n    position\n  )\n\n  // 8. Remove any trailing HTTP whitespace from subtype.\n  subtype = removeHTTPWhitespace(subtype, false, true)\n\n  // 9. If subtype is the empty string or does not solely\n  // contain HTTP token code points, then return failure.\n  if (subtype.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(subtype)) {\n    return 'failure'\n  }\n\n  const typeLowercase = type.toLowerCase()\n  const subtypeLowercase = subtype.toLowerCase()\n\n  // 10. Let mimeType be a new MIME type record whose type\n  // is type, in ASCII lowercase, and subtype is subtype,\n  // in ASCII lowercase.\n  // https://mimesniff.spec.whatwg.org/#mime-type\n  const mimeType = {\n    type: typeLowercase,\n    subtype: subtypeLowercase,\n    /** @type {Map<string, string>} */\n    parameters: new Map(),\n    // https://mimesniff.spec.whatwg.org/#mime-type-essence\n    essence: `${typeLowercase}/${subtypeLowercase}`\n  }\n\n  // 11. While position is not past the end of input:\n  while (position.position < input.length) {\n    // 1. Advance position by 1. (This skips past U+003B (;).)\n    position.position++\n\n    // 2. Collect a sequence of code points that are HTTP\n    // whitespace from input given position.\n    collectASequenceOfCodePoints(\n      // https://fetch.spec.whatwg.org/#http-whitespace\n      char => HTTP_WHITESPACE_REGEX.test(char),\n      input,\n      position\n    )\n\n    // 3. Let parameterName be the result of collecting a\n    // sequence of code points that are not U+003B (;)\n    // or U+003D (=) from input, given position.\n    let parameterName = collectASequenceOfCodePoints(\n      (char) => char !== ';' && char !== '=',\n      input,\n      position\n    )\n\n    // 4. Set parameterName to parameterName, in ASCII\n    // lowercase.\n    parameterName = parameterName.toLowerCase()\n\n    // 5. If position is not past the end of input, then:\n    if (position.position < input.length) {\n      // 1. If the code point at position within input is\n      // U+003B (;), then continue.\n      if (input[position.position] === ';') {\n        continue\n      }\n\n      // 2. Advance position by 1. (This skips past U+003D (=).)\n      position.position++\n    }\n\n    // 6. If position is past the end of input, then break.\n    if (position.position > input.length) {\n      break\n    }\n\n    // 7. Let parameterValue be null.\n    let parameterValue = null\n\n    // 8. If the code point at position within input is\n    // U+0022 (\"), then:\n    if (input[position.position] === '\"') {\n      // 1. Set parameterValue to the result of collecting\n      // an HTTP quoted string from input, given position\n      // and the extract-value flag.\n      parameterValue = collectAnHTTPQuotedString(input, position, true)\n\n      // 2. Collect a sequence of code points that are not\n      // U+003B (;) from input, given position.\n      collectASequenceOfCodePointsFast(\n        ';',\n        input,\n        position\n      )\n\n    // 9. Otherwise:\n    } else {\n      // 1. Set parameterValue to the result of collecting\n      // a sequence of code points that are not U+003B (;)\n      // from input, given position.\n      parameterValue = collectASequenceOfCodePointsFast(\n        ';',\n        input,\n        position\n      )\n\n      // 2. Remove any trailing HTTP whitespace from parameterValue.\n      parameterValue = removeHTTPWhitespace(parameterValue, false, true)\n\n      // 3. If parameterValue is the empty string, then continue.\n      if (parameterValue.length === 0) {\n        continue\n      }\n    }\n\n    // 10. If all of the following are true\n    // - parameterName is not the empty string\n    // - parameterName solely contains HTTP token code points\n    // - parameterValue solely contains HTTP quoted-string token code points\n    // - mimeTypes parameters[parameterName] does not exist\n    // then set mimeTypes parameters[parameterName] to parameterValue.\n    if (\n      parameterName.length !== 0 &&\n      HTTP_TOKEN_CODEPOINTS.test(parameterName) &&\n      (parameterValue.length === 0 || HTTP_QUOTED_STRING_TOKENS.test(parameterValue)) &&\n      !mimeType.parameters.has(parameterName)\n    ) {\n      mimeType.parameters.set(parameterName, parameterValue)\n    }\n  }\n\n  // 12. Return mimeType.\n  return mimeType\n}\n\n// https://infra.spec.whatwg.org/#forgiving-base64-decode\n/** @param {string} data */\nfunction forgivingBase64 (data) {\n  // 1. Remove all ASCII whitespace from data.\n  data = data.replace(ASCII_WHITESPACE_REPLACE_REGEX, '')  // eslint-disable-line\n\n  let dataLength = data.length\n  // 2. If datas code point length divides by 4 leaving\n  // no remainder, then:\n  if (dataLength % 4 === 0) {\n    // 1. If data ends with one or two U+003D (=) code points,\n    // then remove them from data.\n    if (data.charCodeAt(dataLength - 1) === 0x003D) {\n      --dataLength\n      if (data.charCodeAt(dataLength - 1) === 0x003D) {\n        --dataLength\n      }\n    }\n  }\n\n  // 3. If datas code point length divides by 4 leaving\n  // a remainder of 1, then return failure.\n  if (dataLength % 4 === 1) {\n    return 'failure'\n  }\n\n  // 4. If data contains a code point that is not one of\n  //  U+002B (+)\n  //  U+002F (/)\n  //  ASCII alphanumeric\n  // then return failure.\n  if (/[^+/0-9A-Za-z]/.test(data.length === dataLength ? data : data.substring(0, dataLength))) {\n    return 'failure'\n  }\n\n  const buffer = Buffer.from(data, 'base64')\n  return new Uint8Array(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n}\n\n// https://fetch.spec.whatwg.org/#collect-an-http-quoted-string\n// tests: https://fetch.spec.whatwg.org/#example-http-quoted-string\n/**\n * @param {string} input\n * @param {{ position: number }} position\n * @param {boolean?} extractValue\n */\nfunction collectAnHTTPQuotedString (input, position, extractValue) {\n  // 1. Let positionStart be position.\n  const positionStart = position.position\n\n  // 2. Let value be the empty string.\n  let value = ''\n\n  // 3. Assert: the code point at position within input\n  // is U+0022 (\").\n  assert(input[position.position] === '\"')\n\n  // 4. Advance position by 1.\n  position.position++\n\n  // 5. While true:\n  while (true) {\n    // 1. Append the result of collecting a sequence of code points\n    // that are not U+0022 (\") or U+005C (\\) from input, given\n    // position, to value.\n    value += collectASequenceOfCodePoints(\n      (char) => char !== '\"' && char !== '\\\\',\n      input,\n      position\n    )\n\n    // 2. If position is past the end of input, then break.\n    if (position.position >= input.length) {\n      break\n    }\n\n    // 3. Let quoteOrBackslash be the code point at position within\n    // input.\n    const quoteOrBackslash = input[position.position]\n\n    // 4. Advance position by 1.\n    position.position++\n\n    // 5. If quoteOrBackslash is U+005C (\\), then:\n    if (quoteOrBackslash === '\\\\') {\n      // 1. If position is past the end of input, then append\n      // U+005C (\\) to value and break.\n      if (position.position >= input.length) {\n        value += '\\\\'\n        break\n      }\n\n      // 2. Append the code point at position within input to value.\n      value += input[position.position]\n\n      // 3. Advance position by 1.\n      position.position++\n\n    // 6. Otherwise:\n    } else {\n      // 1. Assert: quoteOrBackslash is U+0022 (\").\n      assert(quoteOrBackslash === '\"')\n\n      // 2. Break.\n      break\n    }\n  }\n\n  // 6. If the extract-value flag is set, then return value.\n  if (extractValue) {\n    return value\n  }\n\n  // 7. Return the code points from positionStart to position,\n  // inclusive, within input.\n  return input.slice(positionStart, position.position)\n}\n\n/**\n * @see https://mimesniff.spec.whatwg.org/#serialize-a-mime-type\n */\nfunction serializeAMimeType (mimeType) {\n  assert(mimeType !== 'failure')\n  const { parameters, essence } = mimeType\n\n  // 1. Let serialization be the concatenation of mimeTypes\n  //    type, U+002F (/), and mimeTypes subtype.\n  let serialization = essence\n\n  // 2. For each name  value of mimeTypes parameters:\n  for (let [name, value] of parameters.entries()) {\n    // 1. Append U+003B (;) to serialization.\n    serialization += ';'\n\n    // 2. Append name to serialization.\n    serialization += name\n\n    // 3. Append U+003D (=) to serialization.\n    serialization += '='\n\n    // 4. If value does not solely contain HTTP token code\n    //    points or value is the empty string, then:\n    if (!HTTP_TOKEN_CODEPOINTS.test(value)) {\n      // 1. Precede each occurrence of U+0022 (\") or\n      //    U+005C (\\) in value with U+005C (\\).\n      value = value.replace(/(\\\\|\")/g, '\\\\$1')\n\n      // 2. Prepend U+0022 (\") to value.\n      value = '\"' + value\n\n      // 3. Append U+0022 (\") to value.\n      value += '\"'\n    }\n\n    // 5. Append value to serialization.\n    serialization += value\n  }\n\n  // 3. Return serialization.\n  return serialization\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-whitespace\n * @param {number} char\n */\nfunction isHTTPWhiteSpace (char) {\n  // \"\\r\\n\\t \"\n  return char === 0x00d || char === 0x00a || char === 0x009 || char === 0x020\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-whitespace\n * @param {string} str\n * @param {boolean} [leading=true]\n * @param {boolean} [trailing=true]\n */\nfunction removeHTTPWhitespace (str, leading = true, trailing = true) {\n  return removeChars(str, leading, trailing, isHTTPWhiteSpace)\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#ascii-whitespace\n * @param {number} char\n */\nfunction isASCIIWhitespace (char) {\n  // \"\\r\\n\\t\\f \"\n  return char === 0x00d || char === 0x00a || char === 0x009 || char === 0x00c || char === 0x020\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#strip-leading-and-trailing-ascii-whitespace\n * @param {string} str\n * @param {boolean} [leading=true]\n * @param {boolean} [trailing=true]\n */\nfunction removeASCIIWhitespace (str, leading = true, trailing = true) {\n  return removeChars(str, leading, trailing, isASCIIWhitespace)\n}\n\n/**\n * @param {string} str\n * @param {boolean} leading\n * @param {boolean} trailing\n * @param {(charCode: number) => boolean} predicate\n * @returns\n */\nfunction removeChars (str, leading, trailing, predicate) {\n  let lead = 0\n  let trail = str.length - 1\n\n  if (leading) {\n    while (lead < str.length && predicate(str.charCodeAt(lead))) lead++\n  }\n\n  if (trailing) {\n    while (trail > 0 && predicate(str.charCodeAt(trail))) trail--\n  }\n\n  return lead === 0 && trail === str.length - 1 ? str : str.slice(lead, trail + 1)\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#isomorphic-decode\n * @param {Uint8Array} input\n * @returns {string}\n */\nfunction isomorphicDecode (input) {\n  // 1. To isomorphic decode a byte sequence input, return a string whose code point\n  //    length is equal to inputs length and whose code points have the same values\n  //    as the values of inputs bytes, in the same order.\n  const length = input.length\n  if ((2 << 15) - 1 > length) {\n    return String.fromCharCode.apply(null, input)\n  }\n  let result = ''; let i = 0\n  let addition = (2 << 15) - 1\n  while (i < length) {\n    if (i + addition > length) {\n      addition = length - i\n    }\n    result += String.fromCharCode.apply(null, input.subarray(i, i += addition))\n  }\n  return result\n}\n\n/**\n * @see https://mimesniff.spec.whatwg.org/#minimize-a-supported-mime-type\n * @param {Exclude<ReturnType<typeof parseMIMEType>, 'failure'>} mimeType\n */\nfunction minimizeSupportedMimeType (mimeType) {\n  switch (mimeType.essence) {\n    case 'application/ecmascript':\n    case 'application/javascript':\n    case 'application/x-ecmascript':\n    case 'application/x-javascript':\n    case 'text/ecmascript':\n    case 'text/javascript':\n    case 'text/javascript1.0':\n    case 'text/javascript1.1':\n    case 'text/javascript1.2':\n    case 'text/javascript1.3':\n    case 'text/javascript1.4':\n    case 'text/javascript1.5':\n    case 'text/jscript':\n    case 'text/livescript':\n    case 'text/x-ecmascript':\n    case 'text/x-javascript':\n      // 1. If mimeType is a JavaScript MIME type, then return \"text/javascript\".\n      return 'text/javascript'\n    case 'application/json':\n    case 'text/json':\n      // 2. If mimeType is a JSON MIME type, then return \"application/json\".\n      return 'application/json'\n    case 'image/svg+xml':\n      // 3. If mimeTypes essence is \"image/svg+xml\", then return \"image/svg+xml\".\n      return 'image/svg+xml'\n    case 'text/xml':\n    case 'application/xml':\n      // 4. If mimeType is an XML MIME type, then return \"application/xml\".\n      return 'application/xml'\n  }\n\n  // 2. If mimeType is a JSON MIME type, then return \"application/json\".\n  if (mimeType.subtype.endsWith('+json')) {\n    return 'application/json'\n  }\n\n  // 4. If mimeType is an XML MIME type, then return \"application/xml\".\n  if (mimeType.subtype.endsWith('+xml')) {\n    return 'application/xml'\n  }\n\n  // 5. If mimeType is supported by the user agent, then return mimeTypes essence.\n  // Technically, node doesn't support any mimetypes.\n\n  // 6. Return the empty string.\n  return ''\n}\n\nmodule.exports = {\n  dataURLProcessor,\n  URLSerializer,\n  collectASequenceOfCodePoints,\n  collectASequenceOfCodePointsFast,\n  stringPercentDecode,\n  parseMIMEType,\n  collectAnHTTPQuotedString,\n  serializeAMimeType,\n  removeChars,\n  removeHTTPWhitespace,\n  minimizeSupportedMimeType,\n  HTTP_TOKEN_CODEPOINTS,\n  isomorphicDecode\n}\n","'use strict'\n\nconst { kConnected, kSize } = require('../../core/symbols')\n\nclass CompatWeakRef {\n  constructor (value) {\n    this.value = value\n  }\n\n  deref () {\n    return this.value[kConnected] === 0 && this.value[kSize] === 0\n      ? undefined\n      : this.value\n  }\n}\n\nclass CompatFinalizer {\n  constructor (finalizer) {\n    this.finalizer = finalizer\n  }\n\n  register (dispatcher, key) {\n    if (dispatcher.on) {\n      dispatcher.on('disconnect', () => {\n        if (dispatcher[kConnected] === 0 && dispatcher[kSize] === 0) {\n          this.finalizer(key)\n        }\n      })\n    }\n  }\n\n  unregister (key) {}\n}\n\nmodule.exports = function () {\n  // FIXME: remove workaround when the Node bug is backported to v18\n  // https://github.com/nodejs/node/issues/49344#issuecomment-1741776308\n  if (process.env.NODE_V8_COVERAGE && process.version.startsWith('v18')) {\n    process._rawDebug('Using compatibility WeakRef and FinalizationRegistry')\n    return {\n      WeakRef: CompatWeakRef,\n      FinalizationRegistry: CompatFinalizer\n    }\n  }\n  return { WeakRef, FinalizationRegistry }\n}\n","'use strict'\n\nconst { Blob, File } = require('node:buffer')\nconst { kState } = require('./symbols')\nconst { webidl } = require('./webidl')\n\n// TODO(@KhafraDev): remove\nclass FileLike {\n  constructor (blobLike, fileName, options = {}) {\n    // TODO: argument idl type check\n\n    // The File constructor is invoked with two or three parameters, depending\n    // on whether the optional dictionary parameter is used. When the File()\n    // constructor is invoked, user agents must run the following steps:\n\n    // 1. Let bytes be the result of processing blob parts given fileBits and\n    // options.\n\n    // 2. Let n be the fileName argument to the constructor.\n    const n = fileName\n\n    // 3. Process FilePropertyBag dictionary argument by running the following\n    // substeps:\n\n    //    1. If the type member is provided and is not the empty string, let t\n    //    be set to the type dictionary member. If t contains any characters\n    //    outside the range U+0020 to U+007E, then set t to the empty string\n    //    and return from these substeps.\n    //    TODO\n    const t = options.type\n\n    //    2. Convert every character in t to ASCII lowercase.\n    //    TODO\n\n    //    3. If the lastModified member is provided, let d be set to the\n    //    lastModified dictionary member. If it is not provided, set d to the\n    //    current date and time represented as the number of milliseconds since\n    //    the Unix Epoch (which is the equivalent of Date.now() [ECMA-262]).\n    const d = options.lastModified ?? Date.now()\n\n    // 4. Return a new File object F such that:\n    // F refers to the bytes byte sequence.\n    // F.size is set to the number of total bytes in bytes.\n    // F.name is set to n.\n    // F.type is set to t.\n    // F.lastModified is set to d.\n\n    this[kState] = {\n      blobLike,\n      name: n,\n      type: t,\n      lastModified: d\n    }\n  }\n\n  stream (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.stream(...args)\n  }\n\n  arrayBuffer (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.arrayBuffer(...args)\n  }\n\n  slice (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.slice(...args)\n  }\n\n  text (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.text(...args)\n  }\n\n  get size () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.size\n  }\n\n  get type () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.type\n  }\n\n  get name () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].name\n  }\n\n  get lastModified () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].lastModified\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'File'\n  }\n}\n\nwebidl.converters.Blob = webidl.interfaceConverter(Blob)\n\n// If this function is moved to ./util.js, some tools (such as\n// rollup) will warn about circular dependencies. See:\n// https://github.com/nodejs/undici/issues/1629\nfunction isFileLike (object) {\n  return (\n    (object instanceof File) ||\n    (\n      object &&\n      (typeof object.stream === 'function' ||\n      typeof object.arrayBuffer === 'function') &&\n      object[Symbol.toStringTag] === 'File'\n    )\n  )\n}\n\nmodule.exports = { FileLike, isFileLike }\n","'use strict'\n\nconst { isUSVString, bufferToLowerCasedHeaderName } = require('../../core/util')\nconst { utf8DecodeBytes } = require('./util')\nconst { HTTP_TOKEN_CODEPOINTS, isomorphicDecode } = require('./data-url')\nconst { isFileLike } = require('./file')\nconst { makeEntry } = require('./formdata')\nconst assert = require('node:assert')\nconst { File: NodeFile } = require('node:buffer')\n\nconst File = globalThis.File ?? NodeFile\n\nconst formDataNameBuffer = Buffer.from('form-data; name=\"')\nconst filenameBuffer = Buffer.from('; filename')\nconst dd = Buffer.from('--')\nconst ddcrlf = Buffer.from('--\\r\\n')\n\n/**\n * @param {string} chars\n */\nfunction isAsciiString (chars) {\n  for (let i = 0; i < chars.length; ++i) {\n    if ((chars.charCodeAt(i) & ~0x7F) !== 0) {\n      return false\n    }\n  }\n  return true\n}\n\n/**\n * @see https://andreubotella.github.io/multipart-form-data/#multipart-form-data-boundary\n * @param {string} boundary\n */\nfunction validateBoundary (boundary) {\n  const length = boundary.length\n\n  // - its length is greater or equal to 27 and lesser or equal to 70, and\n  if (length < 27 || length > 70) {\n    return false\n  }\n\n  // - it is composed by bytes in the ranges 0x30 to 0x39, 0x41 to 0x5A, or\n  //   0x61 to 0x7A, inclusive (ASCII alphanumeric), or which are 0x27 ('),\n  //   0x2D (-) or 0x5F (_).\n  for (let i = 0; i < length; ++i) {\n    const cp = boundary.charCodeAt(i)\n\n    if (!(\n      (cp >= 0x30 && cp <= 0x39) ||\n      (cp >= 0x41 && cp <= 0x5a) ||\n      (cp >= 0x61 && cp <= 0x7a) ||\n      cp === 0x27 ||\n      cp === 0x2d ||\n      cp === 0x5f\n    )) {\n      return false\n    }\n  }\n\n  return true\n}\n\n/**\n * @see https://andreubotella.github.io/multipart-form-data/#multipart-form-data-parser\n * @param {Buffer} input\n * @param {ReturnType<import('./data-url')['parseMIMEType']>} mimeType\n */\nfunction multipartFormDataParser (input, mimeType) {\n  // 1. Assert: mimeTypes essence is \"multipart/form-data\".\n  assert(mimeType !== 'failure' && mimeType.essence === 'multipart/form-data')\n\n  const boundaryString = mimeType.parameters.get('boundary')\n\n  // 2. If mimeTypes parameters[\"boundary\"] does not exist, return failure.\n  //    Otherwise, let boundary be the result of UTF-8 decoding mimeTypes\n  //    parameters[\"boundary\"].\n  if (boundaryString === undefined) {\n    return 'failure'\n  }\n\n  const boundary = Buffer.from(`--${boundaryString}`, 'utf8')\n\n  // 3. Let entry list be an empty entry list.\n  const entryList = []\n\n  // 4. Let position be a pointer to a byte in input, initially pointing at\n  //    the first byte.\n  const position = { position: 0 }\n\n  // Note: undici addition, allows leading and trailing CRLFs.\n  while (input[position.position] === 0x0d && input[position.position + 1] === 0x0a) {\n    position.position += 2\n  }\n\n  let trailing = input.length\n\n  while (input[trailing - 1] === 0x0a && input[trailing - 2] === 0x0d) {\n    trailing -= 2\n  }\n\n  if (trailing !== input.length) {\n    input = input.subarray(0, trailing)\n  }\n\n  // 5. While true:\n  while (true) {\n    // 5.1. If position points to a sequence of bytes starting with 0x2D 0x2D\n    //      (`--`) followed by boundary, advance position by 2 + the length of\n    //      boundary. Otherwise, return failure.\n    // Note: boundary is padded with 2 dashes already, no need to add 2.\n    if (input.subarray(position.position, position.position + boundary.length).equals(boundary)) {\n      position.position += boundary.length\n    } else {\n      return 'failure'\n    }\n\n    // 5.2. If position points to the sequence of bytes 0x2D 0x2D 0x0D 0x0A\n    //      (`--` followed by CR LF) followed by the end of input, return entry list.\n    // Note: a body does NOT need to end with CRLF. It can end with --.\n    if (\n      (position.position === input.length - 2 && bufferStartsWith(input, dd, position)) ||\n      (position.position === input.length - 4 && bufferStartsWith(input, ddcrlf, position))\n    ) {\n      return entryList\n    }\n\n    // 5.3. If position does not point to a sequence of bytes starting with 0x0D\n    //      0x0A (CR LF), return failure.\n    if (input[position.position] !== 0x0d || input[position.position + 1] !== 0x0a) {\n      return 'failure'\n    }\n\n    // 5.4. Advance position by 2. (This skips past the newline.)\n    position.position += 2\n\n    // 5.5. Let name, filename and contentType be the result of parsing\n    //      multipart/form-data headers on input and position, if the result\n    //      is not failure. Otherwise, return failure.\n    const result = parseMultipartFormDataHeaders(input, position)\n\n    if (result === 'failure') {\n      return 'failure'\n    }\n\n    let { name, filename, contentType, encoding } = result\n\n    // 5.6. Advance position by 2. (This skips past the empty line that marks\n    //      the end of the headers.)\n    position.position += 2\n\n    // 5.7. Let body be the empty byte sequence.\n    let body\n\n    // 5.8. Body loop: While position is not past the end of input:\n    // TODO: the steps here are completely wrong\n    {\n      const boundaryIndex = input.indexOf(boundary.subarray(2), position.position)\n\n      if (boundaryIndex === -1) {\n        return 'failure'\n      }\n\n      body = input.subarray(position.position, boundaryIndex - 4)\n\n      position.position += body.length\n\n      // Note: position must be advanced by the body's length before being\n      // decoded, otherwise the parsing will fail.\n      if (encoding === 'base64') {\n        body = Buffer.from(body.toString(), 'base64')\n      }\n    }\n\n    // 5.9. If position does not point to a sequence of bytes starting with\n    //      0x0D 0x0A (CR LF), return failure. Otherwise, advance position by 2.\n    if (input[position.position] !== 0x0d || input[position.position + 1] !== 0x0a) {\n      return 'failure'\n    } else {\n      position.position += 2\n    }\n\n    // 5.10. If filename is not null:\n    let value\n\n    if (filename !== null) {\n      // 5.10.1. If contentType is null, set contentType to \"text/plain\".\n      contentType ??= 'text/plain'\n\n      // 5.10.2. If contentType is not an ASCII string, set contentType to the empty string.\n\n      // Note: `buffer.isAscii` can be used at zero-cost, but converting a string to a buffer is a high overhead.\n      // Content-Type is a relatively small string, so it is faster to use `String#charCodeAt`.\n      if (!isAsciiString(contentType)) {\n        contentType = ''\n      }\n\n      // 5.10.3. Let value be a new File object with name filename, type contentType, and body body.\n      value = new File([body], filename, { type: contentType })\n    } else {\n      // 5.11. Otherwise:\n\n      // 5.11.1. Let value be the UTF-8 decoding without BOM of body.\n      value = utf8DecodeBytes(Buffer.from(body))\n    }\n\n    // 5.12. Assert: name is a scalar value string and value is either a scalar value string or a File object.\n    assert(isUSVString(name))\n    assert((typeof value === 'string' && isUSVString(value)) || isFileLike(value))\n\n    // 5.13. Create an entry with name and value, and append it to entry list.\n    entryList.push(makeEntry(name, value, filename))\n  }\n}\n\n/**\n * @see https://andreubotella.github.io/multipart-form-data/#parse-multipart-form-data-headers\n * @param {Buffer} input\n * @param {{ position: number }} position\n */\nfunction parseMultipartFormDataHeaders (input, position) {\n  // 1. Let name, filename and contentType be null.\n  let name = null\n  let filename = null\n  let contentType = null\n  let encoding = null\n\n  // 2. While true:\n  while (true) {\n    // 2.1. If position points to a sequence of bytes starting with 0x0D 0x0A (CR LF):\n    if (input[position.position] === 0x0d && input[position.position + 1] === 0x0a) {\n      // 2.1.1. If name is null, return failure.\n      if (name === null) {\n        return 'failure'\n      }\n\n      // 2.1.2. Return name, filename and contentType.\n      return { name, filename, contentType, encoding }\n    }\n\n    // 2.2. Let header name be the result of collecting a sequence of bytes that are\n    //      not 0x0A (LF), 0x0D (CR) or 0x3A (:), given position.\n    let headerName = collectASequenceOfBytes(\n      (char) => char !== 0x0a && char !== 0x0d && char !== 0x3a,\n      input,\n      position\n    )\n\n    // 2.3. Remove any HTTP tab or space bytes from the start or end of header name.\n    headerName = removeChars(headerName, true, true, (char) => char === 0x9 || char === 0x20)\n\n    // 2.4. If header name does not match the field-name token production, return failure.\n    if (!HTTP_TOKEN_CODEPOINTS.test(headerName.toString())) {\n      return 'failure'\n    }\n\n    // 2.5. If the byte at position is not 0x3A (:), return failure.\n    if (input[position.position] !== 0x3a) {\n      return 'failure'\n    }\n\n    // 2.6. Advance position by 1.\n    position.position++\n\n    // 2.7. Collect a sequence of bytes that are HTTP tab or space bytes given position.\n    //      (Do nothing with those bytes.)\n    collectASequenceOfBytes(\n      (char) => char === 0x20 || char === 0x09,\n      input,\n      position\n    )\n\n    // 2.8. Byte-lowercase header name and switch on the result:\n    switch (bufferToLowerCasedHeaderName(headerName)) {\n      case 'content-disposition': {\n        // 1. Set name and filename to null.\n        name = filename = null\n\n        // 2. If position does not point to a sequence of bytes starting with\n        //    `form-data; name=\"`, return failure.\n        if (!bufferStartsWith(input, formDataNameBuffer, position)) {\n          return 'failure'\n        }\n\n        // 3. Advance position so it points at the byte after the next 0x22 (\")\n        //    byte (the one in the sequence of bytes matched above).\n        position.position += 17\n\n        // 4. Set name to the result of parsing a multipart/form-data name given\n        //    input and position, if the result is not failure. Otherwise, return\n        //    failure.\n        name = parseMultipartFormDataName(input, position)\n\n        if (name === null) {\n          return 'failure'\n        }\n\n        // 5. If position points to a sequence of bytes starting with `; filename=\"`:\n        if (bufferStartsWith(input, filenameBuffer, position)) {\n          // Note: undici also handles filename*\n          let check = position.position + filenameBuffer.length\n\n          if (input[check] === 0x2a) {\n            position.position += 1\n            check += 1\n          }\n\n          if (input[check] !== 0x3d || input[check + 1] !== 0x22) { // =\"\n            return 'failure'\n          }\n\n          // 1. Advance position so it points at the byte after the next 0x22 (\") byte\n          //    (the one in the sequence of bytes matched above).\n          position.position += 12\n\n          // 2. Set filename to the result of parsing a multipart/form-data name given\n          //    input and position, if the result is not failure. Otherwise, return failure.\n          filename = parseMultipartFormDataName(input, position)\n\n          if (filename === null) {\n            return 'failure'\n          }\n        }\n\n        break\n      }\n      case 'content-type': {\n        // 1. Let header value be the result of collecting a sequence of bytes that are\n        //    not 0x0A (LF) or 0x0D (CR), given position.\n        let headerValue = collectASequenceOfBytes(\n          (char) => char !== 0x0a && char !== 0x0d,\n          input,\n          position\n        )\n\n        // 2. Remove any HTTP tab or space bytes from the end of header value.\n        headerValue = removeChars(headerValue, false, true, (char) => char === 0x9 || char === 0x20)\n\n        // 3. Set contentType to the isomorphic decoding of header value.\n        contentType = isomorphicDecode(headerValue)\n\n        break\n      }\n      case 'content-transfer-encoding': {\n        let headerValue = collectASequenceOfBytes(\n          (char) => char !== 0x0a && char !== 0x0d,\n          input,\n          position\n        )\n\n        headerValue = removeChars(headerValue, false, true, (char) => char === 0x9 || char === 0x20)\n\n        encoding = isomorphicDecode(headerValue)\n\n        break\n      }\n      default: {\n        // Collect a sequence of bytes that are not 0x0A (LF) or 0x0D (CR), given position.\n        // (Do nothing with those bytes.)\n        collectASequenceOfBytes(\n          (char) => char !== 0x0a && char !== 0x0d,\n          input,\n          position\n        )\n      }\n    }\n\n    // 2.9. If position does not point to a sequence of bytes starting with 0x0D 0x0A\n    //      (CR LF), return failure. Otherwise, advance position by 2 (past the newline).\n    if (input[position.position] !== 0x0d && input[position.position + 1] !== 0x0a) {\n      return 'failure'\n    } else {\n      position.position += 2\n    }\n  }\n}\n\n/**\n * @see https://andreubotella.github.io/multipart-form-data/#parse-a-multipart-form-data-name\n * @param {Buffer} input\n * @param {{ position: number }} position\n */\nfunction parseMultipartFormDataName (input, position) {\n  // 1. Assert: The byte at (position - 1) is 0x22 (\").\n  assert(input[position.position - 1] === 0x22)\n\n  // 2. Let name be the result of collecting a sequence of bytes that are not 0x0A (LF), 0x0D (CR) or 0x22 (\"), given position.\n  /** @type {string | Buffer} */\n  let name = collectASequenceOfBytes(\n    (char) => char !== 0x0a && char !== 0x0d && char !== 0x22,\n    input,\n    position\n  )\n\n  // 3. If the byte at position is not 0x22 (\"), return failure. Otherwise, advance position by 1.\n  if (input[position.position] !== 0x22) {\n    return null // name could be 'failure'\n  } else {\n    position.position++\n  }\n\n  // 4. Replace any occurrence of the following subsequences in name with the given byte:\n  // - `%0A`: 0x0A (LF)\n  // - `%0D`: 0x0D (CR)\n  // - `%22`: 0x22 (\")\n  name = new TextDecoder().decode(name)\n    .replace(/%0A/ig, '\\n')\n    .replace(/%0D/ig, '\\r')\n    .replace(/%22/g, '\"')\n\n  // 5. Return the UTF-8 decoding without BOM of name.\n  return name\n}\n\n/**\n * @param {(char: number) => boolean} condition\n * @param {Buffer} input\n * @param {{ position: number }} position\n */\nfunction collectASequenceOfBytes (condition, input, position) {\n  let start = position.position\n\n  while (start < input.length && condition(input[start])) {\n    ++start\n  }\n\n  return input.subarray(position.position, (position.position = start))\n}\n\n/**\n * @param {Buffer} buf\n * @param {boolean} leading\n * @param {boolean} trailing\n * @param {(charCode: number) => boolean} predicate\n * @returns {Buffer}\n */\nfunction removeChars (buf, leading, trailing, predicate) {\n  let lead = 0\n  let trail = buf.length - 1\n\n  if (leading) {\n    while (lead < buf.length && predicate(buf[lead])) lead++\n  }\n\n  if (trailing) {\n    while (trail > 0 && predicate(buf[trail])) trail--\n  }\n\n  return lead === 0 && trail === buf.length - 1 ? buf : buf.subarray(lead, trail + 1)\n}\n\n/**\n * Checks if {@param buffer} starts with {@param start}\n * @param {Buffer} buffer\n * @param {Buffer} start\n * @param {{ position: number }} position\n */\nfunction bufferStartsWith (buffer, start, position) {\n  if (buffer.length < start.length) {\n    return false\n  }\n\n  for (let i = 0; i < start.length; i++) {\n    if (start[i] !== buffer[position.position + i]) {\n      return false\n    }\n  }\n\n  return true\n}\n\nmodule.exports = {\n  multipartFormDataParser,\n  validateBoundary\n}\n","'use strict'\n\nconst { isBlobLike, iteratorMixin } = require('./util')\nconst { kState } = require('./symbols')\nconst { kEnumerableProperty } = require('../../core/util')\nconst { FileLike, isFileLike } = require('./file')\nconst { webidl } = require('./webidl')\nconst { File: NativeFile } = require('node:buffer')\nconst nodeUtil = require('node:util')\n\n/** @type {globalThis['File']} */\nconst File = globalThis.File ?? NativeFile\n\n// https://xhr.spec.whatwg.org/#formdata\nclass FormData {\n  constructor (form) {\n    webidl.util.markAsUncloneable(this)\n\n    if (form !== undefined) {\n      throw webidl.errors.conversionFailed({\n        prefix: 'FormData constructor',\n        argument: 'Argument 1',\n        types: ['undefined']\n      })\n    }\n\n    this[kState] = []\n  }\n\n  append (name, value, filename = undefined) {\n    webidl.brandCheck(this, FormData)\n\n    const prefix = 'FormData.append'\n    webidl.argumentLengthCheck(arguments, 2, prefix)\n\n    if (arguments.length === 3 && !isBlobLike(value)) {\n      throw new TypeError(\n        \"Failed to execute 'append' on 'FormData': parameter 2 is not of type 'Blob'\"\n      )\n    }\n\n    // 1. Let value be value if given; otherwise blobValue.\n\n    name = webidl.converters.USVString(name, prefix, 'name')\n    value = isBlobLike(value)\n      ? webidl.converters.Blob(value, prefix, 'value', { strict: false })\n      : webidl.converters.USVString(value, prefix, 'value')\n    filename = arguments.length === 3\n      ? webidl.converters.USVString(filename, prefix, 'filename')\n      : undefined\n\n    // 2. Let entry be the result of creating an entry with\n    // name, value, and filename if given.\n    const entry = makeEntry(name, value, filename)\n\n    // 3. Append entry to thiss entry list.\n    this[kState].push(entry)\n  }\n\n  delete (name) {\n    webidl.brandCheck(this, FormData)\n\n    const prefix = 'FormData.delete'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    name = webidl.converters.USVString(name, prefix, 'name')\n\n    // The delete(name) method steps are to remove all entries whose name\n    // is name from thiss entry list.\n    this[kState] = this[kState].filter(entry => entry.name !== name)\n  }\n\n  get (name) {\n    webidl.brandCheck(this, FormData)\n\n    const prefix = 'FormData.get'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    name = webidl.converters.USVString(name, prefix, 'name')\n\n    // 1. If there is no entry whose name is name in thiss entry list,\n    // then return null.\n    const idx = this[kState].findIndex((entry) => entry.name === name)\n    if (idx === -1) {\n      return null\n    }\n\n    // 2. Return the value of the first entry whose name is name from\n    // thiss entry list.\n    return this[kState][idx].value\n  }\n\n  getAll (name) {\n    webidl.brandCheck(this, FormData)\n\n    const prefix = 'FormData.getAll'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    name = webidl.converters.USVString(name, prefix, 'name')\n\n    // 1. If there is no entry whose name is name in thiss entry list,\n    // then return the empty list.\n    // 2. Return the values of all entries whose name is name, in order,\n    // from thiss entry list.\n    return this[kState]\n      .filter((entry) => entry.name === name)\n      .map((entry) => entry.value)\n  }\n\n  has (name) {\n    webidl.brandCheck(this, FormData)\n\n    const prefix = 'FormData.has'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    name = webidl.converters.USVString(name, prefix, 'name')\n\n    // The has(name) method steps are to return true if there is an entry\n    // whose name is name in thiss entry list; otherwise false.\n    return this[kState].findIndex((entry) => entry.name === name) !== -1\n  }\n\n  set (name, value, filename = undefined) {\n    webidl.brandCheck(this, FormData)\n\n    const prefix = 'FormData.set'\n    webidl.argumentLengthCheck(arguments, 2, prefix)\n\n    if (arguments.length === 3 && !isBlobLike(value)) {\n      throw new TypeError(\n        \"Failed to execute 'set' on 'FormData': parameter 2 is not of type 'Blob'\"\n      )\n    }\n\n    // The set(name, value) and set(name, blobValue, filename) method steps\n    // are:\n\n    // 1. Let value be value if given; otherwise blobValue.\n\n    name = webidl.converters.USVString(name, prefix, 'name')\n    value = isBlobLike(value)\n      ? webidl.converters.Blob(value, prefix, 'name', { strict: false })\n      : webidl.converters.USVString(value, prefix, 'name')\n    filename = arguments.length === 3\n      ? webidl.converters.USVString(filename, prefix, 'name')\n      : undefined\n\n    // 2. Let entry be the result of creating an entry with name, value, and\n    // filename if given.\n    const entry = makeEntry(name, value, filename)\n\n    // 3. If there are entries in thiss entry list whose name is name, then\n    // replace the first such entry with entry and remove the others.\n    const idx = this[kState].findIndex((entry) => entry.name === name)\n    if (idx !== -1) {\n      this[kState] = [\n        ...this[kState].slice(0, idx),\n        entry,\n        ...this[kState].slice(idx + 1).filter((entry) => entry.name !== name)\n      ]\n    } else {\n      // 4. Otherwise, append entry to thiss entry list.\n      this[kState].push(entry)\n    }\n  }\n\n  [nodeUtil.inspect.custom] (depth, options) {\n    const state = this[kState].reduce((a, b) => {\n      if (a[b.name]) {\n        if (Array.isArray(a[b.name])) {\n          a[b.name].push(b.value)\n        } else {\n          a[b.name] = [a[b.name], b.value]\n        }\n      } else {\n        a[b.name] = b.value\n      }\n\n      return a\n    }, { __proto__: null })\n\n    options.depth ??= depth\n    options.colors ??= true\n\n    const output = nodeUtil.formatWithOptions(options, state)\n\n    // remove [Object null prototype]\n    return `FormData ${output.slice(output.indexOf(']') + 2)}`\n  }\n}\n\niteratorMixin('FormData', FormData, kState, 'name', 'value')\n\nObject.defineProperties(FormData.prototype, {\n  append: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  get: kEnumerableProperty,\n  getAll: kEnumerableProperty,\n  has: kEnumerableProperty,\n  set: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'FormData',\n    configurable: true\n  }\n})\n\n/**\n * @see https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#create-an-entry\n * @param {string} name\n * @param {string|Blob} value\n * @param {?string} filename\n * @returns\n */\nfunction makeEntry (name, value, filename) {\n  // 1. Set name to the result of converting name into a scalar value string.\n  // Note: This operation was done by the webidl converter USVString.\n\n  // 2. If value is a string, then set value to the result of converting\n  //    value into a scalar value string.\n  if (typeof value === 'string') {\n    // Note: This operation was done by the webidl converter USVString.\n  } else {\n    // 3. Otherwise:\n\n    // 1. If value is not a File object, then set value to a new File object,\n    //    representing the same bytes, whose name attribute value is \"blob\"\n    if (!isFileLike(value)) {\n      value = value instanceof Blob\n        ? new File([value], 'blob', { type: value.type })\n        : new FileLike(value, 'blob', { type: value.type })\n    }\n\n    // 2. If filename is given, then set value to a new File object,\n    //    representing the same bytes, whose name attribute is filename.\n    if (filename !== undefined) {\n      /** @type {FilePropertyBag} */\n      const options = {\n        type: value.type,\n        lastModified: value.lastModified\n      }\n\n      value = value instanceof NativeFile\n        ? new File([value], filename, options)\n        : new FileLike(value, filename, options)\n    }\n  }\n\n  // 4. Return an entry whose name is name and whose value is value.\n  return { name, value }\n}\n\nmodule.exports = { FormData, makeEntry }\n","'use strict'\n\n// In case of breaking changes, increase the version\n// number to avoid conflicts.\nconst globalOrigin = Symbol.for('undici.globalOrigin.1')\n\nfunction getGlobalOrigin () {\n  return globalThis[globalOrigin]\n}\n\nfunction setGlobalOrigin (newOrigin) {\n  if (newOrigin === undefined) {\n    Object.defineProperty(globalThis, globalOrigin, {\n      value: undefined,\n      writable: true,\n      enumerable: false,\n      configurable: false\n    })\n\n    return\n  }\n\n  const parsedURL = new URL(newOrigin)\n\n  if (parsedURL.protocol !== 'http:' && parsedURL.protocol !== 'https:') {\n    throw new TypeError(`Only http & https urls are allowed, received ${parsedURL.protocol}`)\n  }\n\n  Object.defineProperty(globalThis, globalOrigin, {\n    value: parsedURL,\n    writable: true,\n    enumerable: false,\n    configurable: false\n  })\n}\n\nmodule.exports = {\n  getGlobalOrigin,\n  setGlobalOrigin\n}\n","// https://github.com/Ethan-Arrowood/undici-fetch\n\n'use strict'\n\nconst { kConstruct } = require('../../core/symbols')\nconst { kEnumerableProperty } = require('../../core/util')\nconst {\n  iteratorMixin,\n  isValidHeaderName,\n  isValidHeaderValue\n} = require('./util')\nconst { webidl } = require('./webidl')\nconst assert = require('node:assert')\nconst util = require('node:util')\n\nconst kHeadersMap = Symbol('headers map')\nconst kHeadersSortedMap = Symbol('headers map sorted')\n\n/**\n * @param {number} code\n */\nfunction isHTTPWhiteSpaceCharCode (code) {\n  return code === 0x00a || code === 0x00d || code === 0x009 || code === 0x020\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-header-value-normalize\n * @param {string} potentialValue\n */\nfunction headerValueNormalize (potentialValue) {\n  //  To normalize a byte sequence potentialValue, remove\n  //  any leading and trailing HTTP whitespace bytes from\n  //  potentialValue.\n  let i = 0; let j = potentialValue.length\n\n  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(j - 1))) --j\n  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(i))) ++i\n\n  return i === 0 && j === potentialValue.length ? potentialValue : potentialValue.substring(i, j)\n}\n\nfunction fill (headers, object) {\n  // To fill a Headers object headers with a given object object, run these steps:\n\n  // 1. If object is a sequence, then for each header in object:\n  // Note: webidl conversion to array has already been done.\n  if (Array.isArray(object)) {\n    for (let i = 0; i < object.length; ++i) {\n      const header = object[i]\n      // 1. If header does not contain exactly two items, then throw a TypeError.\n      if (header.length !== 2) {\n        throw webidl.errors.exception({\n          header: 'Headers constructor',\n          message: `expected name/value pair to be length 2, found ${header.length}.`\n        })\n      }\n\n      // 2. Append (headers first item, headers second item) to headers.\n      appendHeader(headers, header[0], header[1])\n    }\n  } else if (typeof object === 'object' && object !== null) {\n    // Note: null should throw\n\n    // 2. Otherwise, object is a record, then for each key  value in object,\n    //    append (key, value) to headers\n    const keys = Object.keys(object)\n    for (let i = 0; i < keys.length; ++i) {\n      appendHeader(headers, keys[i], object[keys[i]])\n    }\n  } else {\n    throw webidl.errors.conversionFailed({\n      prefix: 'Headers constructor',\n      argument: 'Argument 1',\n      types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']\n    })\n  }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-headers-append\n */\nfunction appendHeader (headers, name, value) {\n  // 1. Normalize value.\n  value = headerValueNormalize(value)\n\n  // 2. If name is not a header name or value is not a\n  //    header value, then throw a TypeError.\n  if (!isValidHeaderName(name)) {\n    throw webidl.errors.invalidArgument({\n      prefix: 'Headers.append',\n      value: name,\n      type: 'header name'\n    })\n  } else if (!isValidHeaderValue(value)) {\n    throw webidl.errors.invalidArgument({\n      prefix: 'Headers.append',\n      value,\n      type: 'header value'\n    })\n  }\n\n  // 3. If headerss guard is \"immutable\", then throw a TypeError.\n  // 4. Otherwise, if headerss guard is \"request\" and name is a\n  //    forbidden header name, return.\n  // 5. Otherwise, if headerss guard is \"request-no-cors\":\n  //    TODO\n  // Note: undici does not implement forbidden header names\n  if (getHeadersGuard(headers) === 'immutable') {\n    throw new TypeError('immutable')\n  }\n\n  // 6. Otherwise, if headerss guard is \"response\" and name is a\n  //    forbidden response-header name, return.\n\n  // 7. Append (name, value) to headerss header list.\n  return getHeadersList(headers).append(name, value, false)\n\n  // 8. If headerss guard is \"request-no-cors\", then remove\n  //    privileged no-CORS request headers from headers\n}\n\nfunction compareHeaderName (a, b) {\n  return a[0] < b[0] ? -1 : 1\n}\n\nclass HeadersList {\n  /** @type {[string, string][]|null} */\n  cookies = null\n\n  constructor (init) {\n    if (init instanceof HeadersList) {\n      this[kHeadersMap] = new Map(init[kHeadersMap])\n      this[kHeadersSortedMap] = init[kHeadersSortedMap]\n      this.cookies = init.cookies === null ? null : [...init.cookies]\n    } else {\n      this[kHeadersMap] = new Map(init)\n      this[kHeadersSortedMap] = null\n    }\n  }\n\n  /**\n   * @see https://fetch.spec.whatwg.org/#header-list-contains\n   * @param {string} name\n   * @param {boolean} isLowerCase\n   */\n  contains (name, isLowerCase) {\n    // A header list list contains a header name name if list\n    // contains a header whose name is a byte-case-insensitive\n    // match for name.\n\n    return this[kHeadersMap].has(isLowerCase ? name : name.toLowerCase())\n  }\n\n  clear () {\n    this[kHeadersMap].clear()\n    this[kHeadersSortedMap] = null\n    this.cookies = null\n  }\n\n  /**\n   * @see https://fetch.spec.whatwg.org/#concept-header-list-append\n   * @param {string} name\n   * @param {string} value\n   * @param {boolean} isLowerCase\n   */\n  append (name, value, isLowerCase) {\n    this[kHeadersSortedMap] = null\n\n    // 1. If list contains name, then set name to the first such\n    //    headers name.\n    const lowercaseName = isLowerCase ? name : name.toLowerCase()\n    const exists = this[kHeadersMap].get(lowercaseName)\n\n    // 2. Append (name, value) to list.\n    if (exists) {\n      const delimiter = lowercaseName === 'cookie' ? '; ' : ', '\n      this[kHeadersMap].set(lowercaseName, {\n        name: exists.name,\n        value: `${exists.value}${delimiter}${value}`\n      })\n    } else {\n      this[kHeadersMap].set(lowercaseName, { name, value })\n    }\n\n    if (lowercaseName === 'set-cookie') {\n      (this.cookies ??= []).push(value)\n    }\n  }\n\n  /**\n   * @see https://fetch.spec.whatwg.org/#concept-header-list-set\n   * @param {string} name\n   * @param {string} value\n   * @param {boolean} isLowerCase\n   */\n  set (name, value, isLowerCase) {\n    this[kHeadersSortedMap] = null\n    const lowercaseName = isLowerCase ? name : name.toLowerCase()\n\n    if (lowercaseName === 'set-cookie') {\n      this.cookies = [value]\n    }\n\n    // 1. If list contains name, then set the value of\n    //    the first such header to value and remove the\n    //    others.\n    // 2. Otherwise, append header (name, value) to list.\n    this[kHeadersMap].set(lowercaseName, { name, value })\n  }\n\n  /**\n   * @see https://fetch.spec.whatwg.org/#concept-header-list-delete\n   * @param {string} name\n   * @param {boolean} isLowerCase\n   */\n  delete (name, isLowerCase) {\n    this[kHeadersSortedMap] = null\n    if (!isLowerCase) name = name.toLowerCase()\n\n    if (name === 'set-cookie') {\n      this.cookies = null\n    }\n\n    this[kHeadersMap].delete(name)\n  }\n\n  /**\n   * @see https://fetch.spec.whatwg.org/#concept-header-list-get\n   * @param {string} name\n   * @param {boolean} isLowerCase\n   * @returns {string | null}\n   */\n  get (name, isLowerCase) {\n    // 1. If list does not contain name, then return null.\n    // 2. Return the values of all headers in list whose name\n    //    is a byte-case-insensitive match for name,\n    //    separated from each other by 0x2C 0x20, in order.\n    return this[kHeadersMap].get(isLowerCase ? name : name.toLowerCase())?.value ?? null\n  }\n\n  * [Symbol.iterator] () {\n    // use the lowercased name\n    for (const { 0: name, 1: { value } } of this[kHeadersMap]) {\n      yield [name, value]\n    }\n  }\n\n  get entries () {\n    const headers = {}\n\n    if (this[kHeadersMap].size !== 0) {\n      for (const { name, value } of this[kHeadersMap].values()) {\n        headers[name] = value\n      }\n    }\n\n    return headers\n  }\n\n  rawValues () {\n    return this[kHeadersMap].values()\n  }\n\n  get entriesList () {\n    const headers = []\n\n    if (this[kHeadersMap].size !== 0) {\n      for (const { 0: lowerName, 1: { name, value } } of this[kHeadersMap]) {\n        if (lowerName === 'set-cookie') {\n          for (const cookie of this.cookies) {\n            headers.push([name, cookie])\n          }\n        } else {\n          headers.push([name, value])\n        }\n      }\n    }\n\n    return headers\n  }\n\n  // https://fetch.spec.whatwg.org/#convert-header-names-to-a-sorted-lowercase-set\n  toSortedArray () {\n    const size = this[kHeadersMap].size\n    const array = new Array(size)\n    // In most cases, you will use the fast-path.\n    // fast-path: Use binary insertion sort for small arrays.\n    if (size <= 32) {\n      if (size === 0) {\n        // If empty, it is an empty array. To avoid the first index assignment.\n        return array\n      }\n      // Improve performance by unrolling loop and avoiding double-loop.\n      // Double-loop-less version of the binary insertion sort.\n      const iterator = this[kHeadersMap][Symbol.iterator]()\n      const firstValue = iterator.next().value\n      // set [name, value] to first index.\n      array[0] = [firstValue[0], firstValue[1].value]\n      // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine\n      // 3.2.2. Assert: value is non-null.\n      assert(firstValue[1].value !== null)\n      for (\n        let i = 1, j = 0, right = 0, left = 0, pivot = 0, x, value;\n        i < size;\n        ++i\n      ) {\n        // get next value\n        value = iterator.next().value\n        // set [name, value] to current index.\n        x = array[i] = [value[0], value[1].value]\n        // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine\n        // 3.2.2. Assert: value is non-null.\n        assert(x[1] !== null)\n        left = 0\n        right = i\n        // binary search\n        while (left < right) {\n          // middle index\n          pivot = left + ((right - left) >> 1)\n          // compare header name\n          if (array[pivot][0] <= x[0]) {\n            left = pivot + 1\n          } else {\n            right = pivot\n          }\n        }\n        if (i !== pivot) {\n          j = i\n          while (j > left) {\n            array[j] = array[--j]\n          }\n          array[left] = x\n        }\n      }\n      /* c8 ignore next 4 */\n      if (!iterator.next().done) {\n        // This is for debugging and will never be called.\n        throw new TypeError('Unreachable')\n      }\n      return array\n    } else {\n      // This case would be a rare occurrence.\n      // slow-path: fallback\n      let i = 0\n      for (const { 0: name, 1: { value } } of this[kHeadersMap]) {\n        array[i++] = [name, value]\n        // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine\n        // 3.2.2. Assert: value is non-null.\n        assert(value !== null)\n      }\n      return array.sort(compareHeaderName)\n    }\n  }\n}\n\n// https://fetch.spec.whatwg.org/#headers-class\nclass Headers {\n  #guard\n  #headersList\n\n  constructor (init = undefined) {\n    webidl.util.markAsUncloneable(this)\n\n    if (init === kConstruct) {\n      return\n    }\n\n    this.#headersList = new HeadersList()\n\n    // The new Headers(init) constructor steps are:\n\n    // 1. Set thiss guard to \"none\".\n    this.#guard = 'none'\n\n    // 2. If init is given, then fill this with init.\n    if (init !== undefined) {\n      init = webidl.converters.HeadersInit(init, 'Headers contructor', 'init')\n      fill(this, init)\n    }\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-append\n  append (name, value) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 2, 'Headers.append')\n\n    const prefix = 'Headers.append'\n    name = webidl.converters.ByteString(name, prefix, 'name')\n    value = webidl.converters.ByteString(value, prefix, 'value')\n\n    return appendHeader(this, name, value)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-delete\n  delete (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, 'Headers.delete')\n\n    const prefix = 'Headers.delete'\n    name = webidl.converters.ByteString(name, prefix, 'name')\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.delete',\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. If thiss guard is \"immutable\", then throw a TypeError.\n    // 3. Otherwise, if thiss guard is \"request\" and name is a\n    //    forbidden header name, return.\n    // 4. Otherwise, if thiss guard is \"request-no-cors\", name\n    //    is not a no-CORS-safelisted request-header name, and\n    //    name is not a privileged no-CORS request-header name,\n    //    return.\n    // 5. Otherwise, if thiss guard is \"response\" and name is\n    //    a forbidden response-header name, return.\n    // Note: undici does not implement forbidden header names\n    if (this.#guard === 'immutable') {\n      throw new TypeError('immutable')\n    }\n\n    // 6. If thiss header list does not contain name, then\n    //    return.\n    if (!this.#headersList.contains(name, false)) {\n      return\n    }\n\n    // 7. Delete name from thiss header list.\n    // 8. If thiss guard is \"request-no-cors\", then remove\n    //    privileged no-CORS request headers from this.\n    this.#headersList.delete(name, false)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-get\n  get (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, 'Headers.get')\n\n    const prefix = 'Headers.get'\n    name = webidl.converters.ByteString(name, prefix, 'name')\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix,\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. Return the result of getting name from thiss header\n    //    list.\n    return this.#headersList.get(name, false)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-has\n  has (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, 'Headers.has')\n\n    const prefix = 'Headers.has'\n    name = webidl.converters.ByteString(name, prefix, 'name')\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix,\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. Return true if thiss header list contains name;\n    //    otherwise false.\n    return this.#headersList.contains(name, false)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-set\n  set (name, value) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 2, 'Headers.set')\n\n    const prefix = 'Headers.set'\n    name = webidl.converters.ByteString(name, prefix, 'name')\n    value = webidl.converters.ByteString(value, prefix, 'value')\n\n    // 1. Normalize value.\n    value = headerValueNormalize(value)\n\n    // 2. If name is not a header name or value is not a\n    //    header value, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix,\n        value: name,\n        type: 'header name'\n      })\n    } else if (!isValidHeaderValue(value)) {\n      throw webidl.errors.invalidArgument({\n        prefix,\n        value,\n        type: 'header value'\n      })\n    }\n\n    // 3. If thiss guard is \"immutable\", then throw a TypeError.\n    // 4. Otherwise, if thiss guard is \"request\" and name is a\n    //    forbidden header name, return.\n    // 5. Otherwise, if thiss guard is \"request-no-cors\" and\n    //    name/value is not a no-CORS-safelisted request-header,\n    //    return.\n    // 6. Otherwise, if thiss guard is \"response\" and name is a\n    //    forbidden response-header name, return.\n    // Note: undici does not implement forbidden header names\n    if (this.#guard === 'immutable') {\n      throw new TypeError('immutable')\n    }\n\n    // 7. Set (name, value) in thiss header list.\n    // 8. If thiss guard is \"request-no-cors\", then remove\n    //    privileged no-CORS request headers from this\n    this.#headersList.set(name, value, false)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-getsetcookie\n  getSetCookie () {\n    webidl.brandCheck(this, Headers)\n\n    // 1. If thiss header list does not contain `Set-Cookie`, then return  .\n    // 2. Return the values of all headers in thiss header list whose name is\n    //    a byte-case-insensitive match for `Set-Cookie`, in order.\n\n    const list = this.#headersList.cookies\n\n    if (list) {\n      return [...list]\n    }\n\n    return []\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine\n  get [kHeadersSortedMap] () {\n    if (this.#headersList[kHeadersSortedMap]) {\n      return this.#headersList[kHeadersSortedMap]\n    }\n\n    // 1. Let headers be an empty list of headers with the key being the name\n    //    and value the value.\n    const headers = []\n\n    // 2. Let names be the result of convert header names to a sorted-lowercase\n    //    set with all the names of the headers in list.\n    const names = this.#headersList.toSortedArray()\n\n    const cookies = this.#headersList.cookies\n\n    // fast-path\n    if (cookies === null || cookies.length === 1) {\n      // Note: The non-null assertion of value has already been done by `HeadersList#toSortedArray`\n      return (this.#headersList[kHeadersSortedMap] = names)\n    }\n\n    // 3. For each name of names:\n    for (let i = 0; i < names.length; ++i) {\n      const { 0: name, 1: value } = names[i]\n      // 1. If name is `set-cookie`, then:\n      if (name === 'set-cookie') {\n        // 1. Let values be a list of all values of headers in list whose name\n        //    is a byte-case-insensitive match for name, in order.\n\n        // 2. For each value of values:\n        // 1. Append (name, value) to headers.\n        for (let j = 0; j < cookies.length; ++j) {\n          headers.push([name, cookies[j]])\n        }\n      } else {\n        // 2. Otherwise:\n\n        // 1. Let value be the result of getting name from list.\n\n        // 2. Assert: value is non-null.\n        // Note: This operation was done by `HeadersList#toSortedArray`.\n\n        // 3. Append (name, value) to headers.\n        headers.push([name, value])\n      }\n    }\n\n    // 4. Return headers.\n    return (this.#headersList[kHeadersSortedMap] = headers)\n  }\n\n  [util.inspect.custom] (depth, options) {\n    options.depth ??= depth\n\n    return `Headers ${util.formatWithOptions(options, this.#headersList.entries)}`\n  }\n\n  static getHeadersGuard (o) {\n    return o.#guard\n  }\n\n  static setHeadersGuard (o, guard) {\n    o.#guard = guard\n  }\n\n  static getHeadersList (o) {\n    return o.#headersList\n  }\n\n  static setHeadersList (o, list) {\n    o.#headersList = list\n  }\n}\n\nconst { getHeadersGuard, setHeadersGuard, getHeadersList, setHeadersList } = Headers\nReflect.deleteProperty(Headers, 'getHeadersGuard')\nReflect.deleteProperty(Headers, 'setHeadersGuard')\nReflect.deleteProperty(Headers, 'getHeadersList')\nReflect.deleteProperty(Headers, 'setHeadersList')\n\niteratorMixin('Headers', Headers, kHeadersSortedMap, 0, 1)\n\nObject.defineProperties(Headers.prototype, {\n  append: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  get: kEnumerableProperty,\n  has: kEnumerableProperty,\n  set: kEnumerableProperty,\n  getSetCookie: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'Headers',\n    configurable: true\n  },\n  [util.inspect.custom]: {\n    enumerable: false\n  }\n})\n\nwebidl.converters.HeadersInit = function (V, prefix, argument) {\n  if (webidl.util.Type(V) === 'Object') {\n    const iterator = Reflect.get(V, Symbol.iterator)\n\n    // A work-around to ensure we send the properly-cased Headers when V is a Headers object.\n    // Read https://github.com/nodejs/undici/pull/3159#issuecomment-2075537226 before touching, please.\n    if (!util.types.isProxy(V) && iterator === Headers.prototype.entries) { // Headers object\n      try {\n        return getHeadersList(V).entriesList\n      } catch {\n        // fall-through\n      }\n    }\n\n    if (typeof iterator === 'function') {\n      return webidl.converters['sequence<sequence<ByteString>>'](V, prefix, argument, iterator.bind(V))\n    }\n\n    return webidl.converters['record<ByteString, ByteString>'](V, prefix, argument)\n  }\n\n  throw webidl.errors.conversionFailed({\n    prefix: 'Headers constructor',\n    argument: 'Argument 1',\n    types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']\n  })\n}\n\nmodule.exports = {\n  fill,\n  // for test.\n  compareHeaderName,\n  Headers,\n  HeadersList,\n  getHeadersGuard,\n  setHeadersGuard,\n  setHeadersList,\n  getHeadersList\n}\n","// https://github.com/Ethan-Arrowood/undici-fetch\n\n'use strict'\n\nconst {\n  makeNetworkError,\n  makeAppropriateNetworkError,\n  filterResponse,\n  makeResponse,\n  fromInnerResponse\n} = require('./response')\nconst { HeadersList } = require('./headers')\nconst { Request, cloneRequest } = require('./request')\nconst zlib = require('node:zlib')\nconst {\n  bytesMatch,\n  makePolicyContainer,\n  clonePolicyContainer,\n  requestBadPort,\n  TAOCheck,\n  appendRequestOriginHeader,\n  responseLocationURL,\n  requestCurrentURL,\n  setRequestReferrerPolicyOnRedirect,\n  tryUpgradeRequestToAPotentiallyTrustworthyURL,\n  createOpaqueTimingInfo,\n  appendFetchMetadata,\n  corsCheck,\n  crossOriginResourcePolicyCheck,\n  determineRequestsReferrer,\n  coarsenedSharedCurrentTime,\n  createDeferredPromise,\n  isBlobLike,\n  sameOrigin,\n  isCancelled,\n  isAborted,\n  isErrorLike,\n  fullyReadBody,\n  readableStreamClose,\n  isomorphicEncode,\n  urlIsLocal,\n  urlIsHttpHttpsScheme,\n  urlHasHttpsScheme,\n  clampAndCoarsenConnectionTimingInfo,\n  simpleRangeHeaderValue,\n  buildContentRange,\n  createInflate,\n  extractMimeType\n} = require('./util')\nconst { kState, kDispatcher } = require('./symbols')\nconst assert = require('node:assert')\nconst { safelyExtractBody, extractBody } = require('./body')\nconst {\n  redirectStatusSet,\n  nullBodyStatus,\n  safeMethodsSet,\n  requestBodyHeader,\n  subresourceSet\n} = require('./constants')\nconst EE = require('node:events')\nconst { Readable, pipeline, finished } = require('node:stream')\nconst { addAbortListener, isErrored, isReadable, bufferToLowerCasedHeaderName } = require('../../core/util')\nconst { dataURLProcessor, serializeAMimeType, minimizeSupportedMimeType } = require('./data-url')\nconst { getGlobalDispatcher } = require('../../global')\nconst { webidl } = require('./webidl')\nconst { STATUS_CODES } = require('node:http')\nconst GET_OR_HEAD = ['GET', 'HEAD']\n\nconst defaultUserAgent = typeof __UNDICI_IS_NODE__ !== 'undefined' || typeof esbuildDetection !== 'undefined'\n  ? 'node'\n  : 'undici'\n\n/** @type {import('buffer').resolveObjectURL} */\nlet resolveObjectURL\n\nclass Fetch extends EE {\n  constructor (dispatcher) {\n    super()\n\n    this.dispatcher = dispatcher\n    this.connection = null\n    this.dump = false\n    this.state = 'ongoing'\n  }\n\n  terminate (reason) {\n    if (this.state !== 'ongoing') {\n      return\n    }\n\n    this.state = 'terminated'\n    this.connection?.destroy(reason)\n    this.emit('terminated', reason)\n  }\n\n  // https://fetch.spec.whatwg.org/#fetch-controller-abort\n  abort (error) {\n    if (this.state !== 'ongoing') {\n      return\n    }\n\n    // 1. Set controllers state to \"aborted\".\n    this.state = 'aborted'\n\n    // 2. Let fallbackError be an \"AbortError\" DOMException.\n    // 3. Set error to fallbackError if it is not given.\n    if (!error) {\n      error = new DOMException('The operation was aborted.', 'AbortError')\n    }\n\n    // 4. Let serializedError be StructuredSerialize(error).\n    //    If that threw an exception, catch it, and let\n    //    serializedError be StructuredSerialize(fallbackError).\n\n    // 5. Set controllers serialized abort reason to serializedError.\n    this.serializedAbortReason = error\n\n    this.connection?.destroy(error)\n    this.emit('terminated', error)\n  }\n}\n\nfunction handleFetchDone (response) {\n  finalizeAndReportTiming(response, 'fetch')\n}\n\n// https://fetch.spec.whatwg.org/#fetch-method\nfunction fetch (input, init = undefined) {\n  webidl.argumentLengthCheck(arguments, 1, 'globalThis.fetch')\n\n  // 1. Let p be a new promise.\n  let p = createDeferredPromise()\n\n  // 2. Let requestObject be the result of invoking the initial value of\n  // Request as constructor with input and init as arguments. If this throws\n  // an exception, reject p with it and return p.\n  let requestObject\n\n  try {\n    requestObject = new Request(input, init)\n  } catch (e) {\n    p.reject(e)\n    return p.promise\n  }\n\n  // 3. Let request be requestObjects request.\n  const request = requestObject[kState]\n\n  // 4. If requestObjects signals aborted flag is set, then:\n  if (requestObject.signal.aborted) {\n    // 1. Abort the fetch() call with p, request, null, and\n    //    requestObjects signals abort reason.\n    abortFetch(p, request, null, requestObject.signal.reason)\n\n    // 2. Return p.\n    return p.promise\n  }\n\n  // 5. Let globalObject be requests clients global object.\n  const globalObject = request.client.globalObject\n\n  // 6. If globalObject is a ServiceWorkerGlobalScope object, then set\n  // requests service-workers mode to \"none\".\n  if (globalObject?.constructor?.name === 'ServiceWorkerGlobalScope') {\n    request.serviceWorkers = 'none'\n  }\n\n  // 7. Let responseObject be null.\n  let responseObject = null\n\n  // 8. Let relevantRealm be thiss relevant Realm.\n\n  // 9. Let locallyAborted be false.\n  let locallyAborted = false\n\n  // 10. Let controller be null.\n  let controller = null\n\n  // 11. Add the following abort steps to requestObjects signal:\n  addAbortListener(\n    requestObject.signal,\n    () => {\n      // 1. Set locallyAborted to true.\n      locallyAborted = true\n\n      // 2. Assert: controller is non-null.\n      assert(controller != null)\n\n      // 3. Abort controller with requestObjects signals abort reason.\n      controller.abort(requestObject.signal.reason)\n\n      const realResponse = responseObject?.deref()\n\n      // 4. Abort the fetch() call with p, request, responseObject,\n      //    and requestObjects signals abort reason.\n      abortFetch(p, request, realResponse, requestObject.signal.reason)\n    }\n  )\n\n  // 12. Let handleFetchDone given response response be to finalize and\n  // report timing with response, globalObject, and \"fetch\".\n  // see function handleFetchDone\n\n  // 13. Set controller to the result of calling fetch given request,\n  // with processResponseEndOfBody set to handleFetchDone, and processResponse\n  // given response being these substeps:\n\n  const processResponse = (response) => {\n    // 1. If locallyAborted is true, terminate these substeps.\n    if (locallyAborted) {\n      return\n    }\n\n    // 2. If responses aborted flag is set, then:\n    if (response.aborted) {\n      // 1. Let deserializedError be the result of deserialize a serialized\n      //    abort reason given controllers serialized abort reason and\n      //    relevantRealm.\n\n      // 2. Abort the fetch() call with p, request, responseObject, and\n      //    deserializedError.\n\n      abortFetch(p, request, responseObject, controller.serializedAbortReason)\n      return\n    }\n\n    // 3. If response is a network error, then reject p with a TypeError\n    // and terminate these substeps.\n    if (response.type === 'error') {\n      p.reject(new TypeError('fetch failed', { cause: response.error }))\n      return\n    }\n\n    // 4. Set responseObject to the result of creating a Response object,\n    // given response, \"immutable\", and relevantRealm.\n    responseObject = new WeakRef(fromInnerResponse(response, 'immutable'))\n\n    // 5. Resolve p with responseObject.\n    p.resolve(responseObject.deref())\n    p = null\n  }\n\n  controller = fetching({\n    request,\n    processResponseEndOfBody: handleFetchDone,\n    processResponse,\n    dispatcher: requestObject[kDispatcher] // undici\n  })\n\n  // 14. Return p.\n  return p.promise\n}\n\n// https://fetch.spec.whatwg.org/#finalize-and-report-timing\nfunction finalizeAndReportTiming (response, initiatorType = 'other') {\n  // 1. If response is an aborted network error, then return.\n  if (response.type === 'error' && response.aborted) {\n    return\n  }\n\n  // 2. If responses URL list is null or empty, then return.\n  if (!response.urlList?.length) {\n    return\n  }\n\n  // 3. Let originalURL be responses URL list[0].\n  const originalURL = response.urlList[0]\n\n  // 4. Let timingInfo be responses timing info.\n  let timingInfo = response.timingInfo\n\n  // 5. Let cacheState be responses cache state.\n  let cacheState = response.cacheState\n\n  // 6. If originalURLs scheme is not an HTTP(S) scheme, then return.\n  if (!urlIsHttpHttpsScheme(originalURL)) {\n    return\n  }\n\n  // 7. If timingInfo is null, then return.\n  if (timingInfo === null) {\n    return\n  }\n\n  // 8. If responses timing allow passed flag is not set, then:\n  if (!response.timingAllowPassed) {\n    //  1. Set timingInfo to a the result of creating an opaque timing info for timingInfo.\n    timingInfo = createOpaqueTimingInfo({\n      startTime: timingInfo.startTime\n    })\n\n    //  2. Set cacheState to the empty string.\n    cacheState = ''\n  }\n\n  // 9. Set timingInfos end time to the coarsened shared current time\n  // given globals relevant settings objects cross-origin isolated\n  // capability.\n  // TODO: given globals relevant settings objects cross-origin isolated\n  // capability?\n  timingInfo.endTime = coarsenedSharedCurrentTime()\n\n  // 10. Set responses timing info to timingInfo.\n  response.timingInfo = timingInfo\n\n  // 11. Mark resource timing for timingInfo, originalURL, initiatorType,\n  // global, and cacheState.\n  markResourceTiming(\n    timingInfo,\n    originalURL.href,\n    initiatorType,\n    globalThis,\n    cacheState\n  )\n}\n\n// https://w3c.github.io/resource-timing/#dfn-mark-resource-timing\nconst markResourceTiming = performance.markResourceTiming\n\n// https://fetch.spec.whatwg.org/#abort-fetch\nfunction abortFetch (p, request, responseObject, error) {\n  // 1. Reject promise with error.\n  if (p) {\n    // We might have already resolved the promise at this stage\n    p.reject(error)\n  }\n\n  // 2. If requests body is not null and is readable, then cancel requests\n  // body with error.\n  if (request.body != null && isReadable(request.body?.stream)) {\n    request.body.stream.cancel(error).catch((err) => {\n      if (err.code === 'ERR_INVALID_STATE') {\n        // Node bug?\n        return\n      }\n      throw err\n    })\n  }\n\n  // 3. If responseObject is null, then return.\n  if (responseObject == null) {\n    return\n  }\n\n  // 4. Let response be responseObjects response.\n  const response = responseObject[kState]\n\n  // 5. If responses body is not null and is readable, then error responses\n  // body with error.\n  if (response.body != null && isReadable(response.body?.stream)) {\n    response.body.stream.cancel(error).catch((err) => {\n      if (err.code === 'ERR_INVALID_STATE') {\n        // Node bug?\n        return\n      }\n      throw err\n    })\n  }\n}\n\n// https://fetch.spec.whatwg.org/#fetching\nfunction fetching ({\n  request,\n  processRequestBodyChunkLength,\n  processRequestEndOfBody,\n  processResponse,\n  processResponseEndOfBody,\n  processResponseConsumeBody,\n  useParallelQueue = false,\n  dispatcher = getGlobalDispatcher() // undici\n}) {\n  // Ensure that the dispatcher is set accordingly\n  assert(dispatcher)\n\n  // 1. Let taskDestination be null.\n  let taskDestination = null\n\n  // 2. Let crossOriginIsolatedCapability be false.\n  let crossOriginIsolatedCapability = false\n\n  // 3. If requests client is non-null, then:\n  if (request.client != null) {\n    // 1. Set taskDestination to requests clients global object.\n    taskDestination = request.client.globalObject\n\n    // 2. Set crossOriginIsolatedCapability to requests clients cross-origin\n    // isolated capability.\n    crossOriginIsolatedCapability =\n      request.client.crossOriginIsolatedCapability\n  }\n\n  // 4. If useParallelQueue is true, then set taskDestination to the result of\n  // starting a new parallel queue.\n  // TODO\n\n  // 5. Let timingInfo be a new fetch timing info whose start time and\n  // post-redirect start time are the coarsened shared current time given\n  // crossOriginIsolatedCapability.\n  const currentTime = coarsenedSharedCurrentTime(crossOriginIsolatedCapability)\n  const timingInfo = createOpaqueTimingInfo({\n    startTime: currentTime\n  })\n\n  // 6. Let fetchParams be a new fetch params whose\n  // request is request,\n  // timing info is timingInfo,\n  // process request body chunk length is processRequestBodyChunkLength,\n  // process request end-of-body is processRequestEndOfBody,\n  // process response is processResponse,\n  // process response consume body is processResponseConsumeBody,\n  // process response end-of-body is processResponseEndOfBody,\n  // task destination is taskDestination,\n  // and cross-origin isolated capability is crossOriginIsolatedCapability.\n  const fetchParams = {\n    controller: new Fetch(dispatcher),\n    request,\n    timingInfo,\n    processRequestBodyChunkLength,\n    processRequestEndOfBody,\n    processResponse,\n    processResponseConsumeBody,\n    processResponseEndOfBody,\n    taskDestination,\n    crossOriginIsolatedCapability\n  }\n\n  // 7. If requests body is a byte sequence, then set requests body to\n  //    requests body as a body.\n  // NOTE: Since fetching is only called from fetch, body should already be\n  // extracted.\n  assert(!request.body || request.body.stream)\n\n  // 8. If requests window is \"client\", then set requests window to requests\n  // client, if requests clients global object is a Window object; otherwise\n  // \"no-window\".\n  if (request.window === 'client') {\n    // TODO: What if request.client is null?\n    request.window =\n      request.client?.globalObject?.constructor?.name === 'Window'\n        ? request.client\n        : 'no-window'\n  }\n\n  // 9. If requests origin is \"client\", then set requests origin to requests\n  // clients origin.\n  if (request.origin === 'client') {\n    request.origin = request.client.origin\n  }\n\n  // 10. If all of the following conditions are true:\n  // TODO\n\n  // 11. If requests policy container is \"client\", then:\n  if (request.policyContainer === 'client') {\n    // 1. If requests client is non-null, then set requests policy\n    // container to a clone of requests clients policy container. [HTML]\n    if (request.client != null) {\n      request.policyContainer = clonePolicyContainer(\n        request.client.policyContainer\n      )\n    } else {\n      // 2. Otherwise, set requests policy container to a new policy\n      // container.\n      request.policyContainer = makePolicyContainer()\n    }\n  }\n\n  // 12. If requests header list does not contain `Accept`, then:\n  if (!request.headersList.contains('accept', true)) {\n    // 1. Let value be `*/*`.\n    const value = '*/*'\n\n    // 2. A user agent should set value to the first matching statement, if\n    // any, switching on requests destination:\n    // \"document\"\n    // \"frame\"\n    // \"iframe\"\n    // `text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8`\n    // \"image\"\n    // `image/png,image/svg+xml,image/*;q=0.8,*/*;q=0.5`\n    // \"style\"\n    // `text/css,*/*;q=0.1`\n    // TODO\n\n    // 3. Append `Accept`/value to requests header list.\n    request.headersList.append('accept', value, true)\n  }\n\n  // 13. If requests header list does not contain `Accept-Language`, then\n  // user agents should append `Accept-Language`/an appropriate value to\n  // requests header list.\n  if (!request.headersList.contains('accept-language', true)) {\n    request.headersList.append('accept-language', '*', true)\n  }\n\n  // 14. If requests priority is null, then use requests initiator and\n  // destination appropriately in setting requests priority to a\n  // user-agent-defined object.\n  if (request.priority === null) {\n    // TODO\n  }\n\n  // 15. If request is a subresource request, then:\n  if (subresourceSet.has(request.destination)) {\n    // TODO\n  }\n\n  // 16. Run main fetch given fetchParams.\n  mainFetch(fetchParams)\n    .catch(err => {\n      fetchParams.controller.terminate(err)\n    })\n\n  // 17. Return fetchParam's controller\n  return fetchParams.controller\n}\n\n// https://fetch.spec.whatwg.org/#concept-main-fetch\nasync function mainFetch (fetchParams, recursive = false) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. If requests local-URLs-only flag is set and requests current URL is\n  // not local, then set response to a network error.\n  if (request.localURLsOnly && !urlIsLocal(requestCurrentURL(request))) {\n    response = makeNetworkError('local URLs only')\n  }\n\n  // 4. Run report Content Security Policy violations for request.\n  // TODO\n\n  // 5. Upgrade request to a potentially trustworthy URL, if appropriate.\n  tryUpgradeRequestToAPotentiallyTrustworthyURL(request)\n\n  // 6. If should request be blocked due to a bad port, should fetching request\n  // be blocked as mixed content, or should request be blocked by Content\n  // Security Policy returns blocked, then set response to a network error.\n  if (requestBadPort(request) === 'blocked') {\n    response = makeNetworkError('bad port')\n  }\n  // TODO: should fetching request be blocked as mixed content?\n  // TODO: should request be blocked by Content Security Policy?\n\n  // 7. If requests referrer policy is the empty string, then set requests\n  // referrer policy to requests policy containers referrer policy.\n  if (request.referrerPolicy === '') {\n    request.referrerPolicy = request.policyContainer.referrerPolicy\n  }\n\n  // 8. If requests referrer is not \"no-referrer\", then set requests\n  // referrer to the result of invoking determine requests referrer.\n  if (request.referrer !== 'no-referrer') {\n    request.referrer = determineRequestsReferrer(request)\n  }\n\n  // 9. Set requests current URLs scheme to \"https\" if all of the following\n  // conditions are true:\n  // - requests current URLs scheme is \"http\"\n  // - requests current URLs host is a domain\n  // - Matching requests current URLs host per Known HSTS Host Domain Name\n  //   Matching results in either a superdomain match with an asserted\n  //   includeSubDomains directive or a congruent match (with or without an\n  //   asserted includeSubDomains directive). [HSTS]\n  // TODO\n\n  // 10. If recursive is false, then run the remaining steps in parallel.\n  // TODO\n\n  // 11. If response is null, then set response to the result of running\n  // the steps corresponding to the first matching statement:\n  if (response === null) {\n    response = await (async () => {\n      const currentURL = requestCurrentURL(request)\n\n      if (\n        // - requests current URLs origin is same origin with requests origin,\n        //   and requests response tainting is \"basic\"\n        (sameOrigin(currentURL, request.url) && request.responseTainting === 'basic') ||\n        // requests current URLs scheme is \"data\"\n        (currentURL.protocol === 'data:') ||\n        // - requests mode is \"navigate\" or \"websocket\"\n        (request.mode === 'navigate' || request.mode === 'websocket')\n      ) {\n        // 1. Set requests response tainting to \"basic\".\n        request.responseTainting = 'basic'\n\n        // 2. Return the result of running scheme fetch given fetchParams.\n        return await schemeFetch(fetchParams)\n      }\n\n      // requests mode is \"same-origin\"\n      if (request.mode === 'same-origin') {\n        // 1. Return a network error.\n        return makeNetworkError('request mode cannot be \"same-origin\"')\n      }\n\n      // requests mode is \"no-cors\"\n      if (request.mode === 'no-cors') {\n        // 1. If requests redirect mode is not \"follow\", then return a network\n        // error.\n        if (request.redirect !== 'follow') {\n          return makeNetworkError(\n            'redirect mode cannot be \"follow\" for \"no-cors\" request'\n          )\n        }\n\n        // 2. Set requests response tainting to \"opaque\".\n        request.responseTainting = 'opaque'\n\n        // 3. Return the result of running scheme fetch given fetchParams.\n        return await schemeFetch(fetchParams)\n      }\n\n      // requests current URLs scheme is not an HTTP(S) scheme\n      if (!urlIsHttpHttpsScheme(requestCurrentURL(request))) {\n        // Return a network error.\n        return makeNetworkError('URL scheme must be a HTTP(S) scheme')\n      }\n\n      // - requests use-CORS-preflight flag is set\n      // - requests unsafe-request flag is set and either requests method is\n      //   not a CORS-safelisted method or CORS-unsafe request-header names with\n      //   requests header list is not empty\n      //    1. Set requests response tainting to \"cors\".\n      //    2. Let corsWithPreflightResponse be the result of running HTTP fetch\n      //    given fetchParams and true.\n      //    3. If corsWithPreflightResponse is a network error, then clear cache\n      //    entries using request.\n      //    4. Return corsWithPreflightResponse.\n      // TODO\n\n      // Otherwise\n      //    1. Set requests response tainting to \"cors\".\n      request.responseTainting = 'cors'\n\n      //    2. Return the result of running HTTP fetch given fetchParams.\n      return await httpFetch(fetchParams)\n    })()\n  }\n\n  // 12. If recursive is true, then return response.\n  if (recursive) {\n    return response\n  }\n\n  // 13. If response is not a network error and response is not a filtered\n  // response, then:\n  if (response.status !== 0 && !response.internalResponse) {\n    // If requests response tainting is \"cors\", then:\n    if (request.responseTainting === 'cors') {\n      // 1. Let headerNames be the result of extracting header list values\n      // given `Access-Control-Expose-Headers` and responses header list.\n      // TODO\n      // 2. If requests credentials mode is not \"include\" and headerNames\n      // contains `*`, then set responses CORS-exposed header-name list to\n      // all unique header names in responses header list.\n      // TODO\n      // 3. Otherwise, if headerNames is not null or failure, then set\n      // responses CORS-exposed header-name list to headerNames.\n      // TODO\n    }\n\n    // Set response to the following filtered response with response as its\n    // internal response, depending on requests response tainting:\n    if (request.responseTainting === 'basic') {\n      response = filterResponse(response, 'basic')\n    } else if (request.responseTainting === 'cors') {\n      response = filterResponse(response, 'cors')\n    } else if (request.responseTainting === 'opaque') {\n      response = filterResponse(response, 'opaque')\n    } else {\n      assert(false)\n    }\n  }\n\n  // 14. Let internalResponse be response, if response is a network error,\n  // and responses internal response otherwise.\n  let internalResponse =\n    response.status === 0 ? response : response.internalResponse\n\n  // 15. If internalResponses URL list is empty, then set it to a clone of\n  // requests URL list.\n  if (internalResponse.urlList.length === 0) {\n    internalResponse.urlList.push(...request.urlList)\n  }\n\n  // 16. If requests timing allow failed flag is unset, then set\n  // internalResponses timing allow passed flag.\n  if (!request.timingAllowFailed) {\n    response.timingAllowPassed = true\n  }\n\n  // 17. If response is not a network error and any of the following returns\n  // blocked\n  // - should internalResponse to request be blocked as mixed content\n  // - should internalResponse to request be blocked by Content Security Policy\n  // - should internalResponse to request be blocked due to its MIME type\n  // - should internalResponse to request be blocked due to nosniff\n  // TODO\n\n  // 18. If responses type is \"opaque\", internalResponses status is 206,\n  // internalResponses range-requested flag is set, and requests header\n  // list does not contain `Range`, then set response and internalResponse\n  // to a network error.\n  if (\n    response.type === 'opaque' &&\n    internalResponse.status === 206 &&\n    internalResponse.rangeRequested &&\n    !request.headers.contains('range', true)\n  ) {\n    response = internalResponse = makeNetworkError()\n  }\n\n  // 19. If response is not a network error and either requests method is\n  // `HEAD` or `CONNECT`, or internalResponses status is a null body status,\n  // set internalResponses body to null and disregard any enqueuing toward\n  // it (if any).\n  if (\n    response.status !== 0 &&\n    (request.method === 'HEAD' ||\n      request.method === 'CONNECT' ||\n      nullBodyStatus.includes(internalResponse.status))\n  ) {\n    internalResponse.body = null\n    fetchParams.controller.dump = true\n  }\n\n  // 20. If requests integrity metadata is not the empty string, then:\n  if (request.integrity) {\n    // 1. Let processBodyError be this step: run fetch finale given fetchParams\n    // and a network error.\n    const processBodyError = (reason) =>\n      fetchFinale(fetchParams, makeNetworkError(reason))\n\n    // 2. If requests response tainting is \"opaque\", or responses body is null,\n    // then run processBodyError and abort these steps.\n    if (request.responseTainting === 'opaque' || response.body == null) {\n      processBodyError(response.error)\n      return\n    }\n\n    // 3. Let processBody given bytes be these steps:\n    const processBody = (bytes) => {\n      // 1. If bytes do not match requests integrity metadata,\n      // then run processBodyError and abort these steps. [SRI]\n      if (!bytesMatch(bytes, request.integrity)) {\n        processBodyError('integrity mismatch')\n        return\n      }\n\n      // 2. Set responses body to bytes as a body.\n      response.body = safelyExtractBody(bytes)[0]\n\n      // 3. Run fetch finale given fetchParams and response.\n      fetchFinale(fetchParams, response)\n    }\n\n    // 4. Fully read responses body given processBody and processBodyError.\n    await fullyReadBody(response.body, processBody, processBodyError)\n  } else {\n    // 21. Otherwise, run fetch finale given fetchParams and response.\n    fetchFinale(fetchParams, response)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#concept-scheme-fetch\n// given a fetch params fetchParams\nfunction schemeFetch (fetchParams) {\n  // Note: since the connection is destroyed on redirect, which sets fetchParams to a\n  // cancelled state, we do not want this condition to trigger *unless* there have been\n  // no redirects. See https://github.com/nodejs/undici/issues/1776\n  // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n  if (isCancelled(fetchParams) && fetchParams.request.redirectCount === 0) {\n    return Promise.resolve(makeAppropriateNetworkError(fetchParams))\n  }\n\n  // 2. Let request be fetchParamss request.\n  const { request } = fetchParams\n\n  const { protocol: scheme } = requestCurrentURL(request)\n\n  // 3. Switch on requests current URLs scheme and run the associated steps:\n  switch (scheme) {\n    case 'about:': {\n      // If requests current URLs path is the string \"blank\", then return a new response\n      // whose status message is `OK`, header list is  (`Content-Type`, `text/html;charset=utf-8`) ,\n      // and body is the empty byte sequence as a body.\n\n      // Otherwise, return a network error.\n      return Promise.resolve(makeNetworkError('about scheme is not supported'))\n    }\n    case 'blob:': {\n      if (!resolveObjectURL) {\n        resolveObjectURL = require('node:buffer').resolveObjectURL\n      }\n\n      // 1. Let blobURLEntry be requests current URLs blob URL entry.\n      const blobURLEntry = requestCurrentURL(request)\n\n      // https://github.com/web-platform-tests/wpt/blob/7b0ebaccc62b566a1965396e5be7bb2bc06f841f/FileAPI/url/resources/fetch-tests.js#L52-L56\n      // Buffer.resolveObjectURL does not ignore URL queries.\n      if (blobURLEntry.search.length !== 0) {\n        return Promise.resolve(makeNetworkError('NetworkError when attempting to fetch resource.'))\n      }\n\n      const blob = resolveObjectURL(blobURLEntry.toString())\n\n      // 2. If requests method is not `GET`, blobURLEntry is null, or blobURLEntrys\n      //    object is not a Blob object, then return a network error.\n      if (request.method !== 'GET' || !isBlobLike(blob)) {\n        return Promise.resolve(makeNetworkError('invalid method'))\n      }\n\n      // 3. Let blob be blobURLEntrys object.\n      // Note: done above\n\n      // 4. Let response be a new response.\n      const response = makeResponse()\n\n      // 5. Let fullLength be blobs size.\n      const fullLength = blob.size\n\n      // 6. Let serializedFullLength be fullLength, serialized and isomorphic encoded.\n      const serializedFullLength = isomorphicEncode(`${fullLength}`)\n\n      // 7. Let type be blobs type.\n      const type = blob.type\n\n      // 8. If requests header list does not contain `Range`:\n      // 9. Otherwise:\n      if (!request.headersList.contains('range', true)) {\n        // 1. Let bodyWithType be the result of safely extracting blob.\n        // Note: in the FileAPI a blob \"object\" is a Blob *or* a MediaSource.\n        // In node, this can only ever be a Blob. Therefore we can safely\n        // use extractBody directly.\n        const bodyWithType = extractBody(blob)\n\n        // 2. Set responses status message to `OK`.\n        response.statusText = 'OK'\n\n        // 3. Set responses body to bodyWithTypes body.\n        response.body = bodyWithType[0]\n\n        // 4. Set responses header list to  (`Content-Length`, serializedFullLength), (`Content-Type`, type) .\n        response.headersList.set('content-length', serializedFullLength, true)\n        response.headersList.set('content-type', type, true)\n      } else {\n        // 1. Set responses range-requested flag.\n        response.rangeRequested = true\n\n        // 2. Let rangeHeader be the result of getting `Range` from requests header list.\n        const rangeHeader = request.headersList.get('range', true)\n\n        // 3. Let rangeValue be the result of parsing a single range header value given rangeHeader and true.\n        const rangeValue = simpleRangeHeaderValue(rangeHeader, true)\n\n        // 4. If rangeValue is failure, then return a network error.\n        if (rangeValue === 'failure') {\n          return Promise.resolve(makeNetworkError('failed to fetch the data URL'))\n        }\n\n        // 5. Let (rangeStart, rangeEnd) be rangeValue.\n        let { rangeStartValue: rangeStart, rangeEndValue: rangeEnd } = rangeValue\n\n        // 6. If rangeStart is null:\n        // 7. Otherwise:\n        if (rangeStart === null) {\n          // 1. Set rangeStart to fullLength  rangeEnd.\n          rangeStart = fullLength - rangeEnd\n\n          // 2. Set rangeEnd to rangeStart + rangeEnd  1.\n          rangeEnd = rangeStart + rangeEnd - 1\n        } else {\n          // 1. If rangeStart is greater than or equal to fullLength, then return a network error.\n          if (rangeStart >= fullLength) {\n            return Promise.resolve(makeNetworkError('Range start is greater than the blob\\'s size.'))\n          }\n\n          // 2. If rangeEnd is null or rangeEnd is greater than or equal to fullLength, then set\n          //    rangeEnd to fullLength  1.\n          if (rangeEnd === null || rangeEnd >= fullLength) {\n            rangeEnd = fullLength - 1\n          }\n        }\n\n        // 8. Let slicedBlob be the result of invoking slice blob given blob, rangeStart,\n        //    rangeEnd + 1, and type.\n        const slicedBlob = blob.slice(rangeStart, rangeEnd, type)\n\n        // 9. Let slicedBodyWithType be the result of safely extracting slicedBlob.\n        // Note: same reason as mentioned above as to why we use extractBody\n        const slicedBodyWithType = extractBody(slicedBlob)\n\n        // 10. Set responses body to slicedBodyWithTypes body.\n        response.body = slicedBodyWithType[0]\n\n        // 11. Let serializedSlicedLength be slicedBlobs size, serialized and isomorphic encoded.\n        const serializedSlicedLength = isomorphicEncode(`${slicedBlob.size}`)\n\n        // 12. Let contentRange be the result of invoking build a content range given rangeStart,\n        //     rangeEnd, and fullLength.\n        const contentRange = buildContentRange(rangeStart, rangeEnd, fullLength)\n\n        // 13. Set responses status to 206.\n        response.status = 206\n\n        // 14. Set responses status message to `Partial Content`.\n        response.statusText = 'Partial Content'\n\n        // 15. Set responses header list to  (`Content-Length`, serializedSlicedLength),\n        //     (`Content-Type`, type), (`Content-Range`, contentRange) .\n        response.headersList.set('content-length', serializedSlicedLength, true)\n        response.headersList.set('content-type', type, true)\n        response.headersList.set('content-range', contentRange, true)\n      }\n\n      // 10. Return response.\n      return Promise.resolve(response)\n    }\n    case 'data:': {\n      // 1. Let dataURLStruct be the result of running the\n      //    data: URL processor on requests current URL.\n      const currentURL = requestCurrentURL(request)\n      const dataURLStruct = dataURLProcessor(currentURL)\n\n      // 2. If dataURLStruct is failure, then return a\n      //    network error.\n      if (dataURLStruct === 'failure') {\n        return Promise.resolve(makeNetworkError('failed to fetch the data URL'))\n      }\n\n      // 3. Let mimeType be dataURLStructs MIME type, serialized.\n      const mimeType = serializeAMimeType(dataURLStruct.mimeType)\n\n      // 4. Return a response whose status message is `OK`,\n      //    header list is  (`Content-Type`, mimeType) ,\n      //    and body is dataURLStructs body as a body.\n      return Promise.resolve(makeResponse({\n        statusText: 'OK',\n        headersList: [\n          ['content-type', { name: 'Content-Type', value: mimeType }]\n        ],\n        body: safelyExtractBody(dataURLStruct.body)[0]\n      }))\n    }\n    case 'file:': {\n      // For now, unfortunate as it is, file URLs are left as an exercise for the reader.\n      // When in doubt, return a network error.\n      return Promise.resolve(makeNetworkError('not implemented... yet...'))\n    }\n    case 'http:':\n    case 'https:': {\n      // Return the result of running HTTP fetch given fetchParams.\n\n      return httpFetch(fetchParams)\n        .catch((err) => makeNetworkError(err))\n    }\n    default: {\n      return Promise.resolve(makeNetworkError('unknown scheme'))\n    }\n  }\n}\n\n// https://fetch.spec.whatwg.org/#finalize-response\nfunction finalizeResponse (fetchParams, response) {\n  // 1. Set fetchParamss requests done flag.\n  fetchParams.request.done = true\n\n  // 2, If fetchParamss process response done is not null, then queue a fetch\n  // task to run fetchParamss process response done given response, with\n  // fetchParamss task destination.\n  if (fetchParams.processResponseDone != null) {\n    queueMicrotask(() => fetchParams.processResponseDone(response))\n  }\n}\n\n// https://fetch.spec.whatwg.org/#fetch-finale\nfunction fetchFinale (fetchParams, response) {\n  // 1. Let timingInfo be fetchParamss timing info.\n  let timingInfo = fetchParams.timingInfo\n\n  // 2. If response is not a network error and fetchParamss requests client is a secure context,\n  //    then set timingInfos server-timing headers to the result of getting, decoding, and splitting\n  //    `Server-Timing` from responses internal responses header list.\n  // TODO\n\n  // 3. Let processResponseEndOfBody be the following steps:\n  const processResponseEndOfBody = () => {\n    // 1. Let unsafeEndTime be the unsafe shared current time.\n    const unsafeEndTime = Date.now() // ?\n\n    // 2. If fetchParamss requests destination is \"document\", then set fetchParamss controllers\n    //    full timing info to fetchParamss timing info.\n    if (fetchParams.request.destination === 'document') {\n      fetchParams.controller.fullTimingInfo = timingInfo\n    }\n\n    // 3. Set fetchParamss controllers report timing steps to the following steps given a global object global:\n    fetchParams.controller.reportTimingSteps = () => {\n      // 1. If fetchParamss requests URLs scheme is not an HTTP(S) scheme, then return.\n      if (fetchParams.request.url.protocol !== 'https:') {\n        return\n      }\n\n      // 2. Set timingInfos end time to the relative high resolution time given unsafeEndTime and global.\n      timingInfo.endTime = unsafeEndTime\n\n      // 3. Let cacheState be responses cache state.\n      let cacheState = response.cacheState\n\n      // 4. Let bodyInfo be responses body info.\n      const bodyInfo = response.bodyInfo\n\n      // 5. If responses timing allow passed flag is not set, then set timingInfo to the result of creating an\n      //    opaque timing info for timingInfo and set cacheState to the empty string.\n      if (!response.timingAllowPassed) {\n        timingInfo = createOpaqueTimingInfo(timingInfo)\n\n        cacheState = ''\n      }\n\n      // 6. Let responseStatus be 0.\n      let responseStatus = 0\n\n      // 7. If fetchParamss requests mode is not \"navigate\" or responses has-cross-origin-redirects is false:\n      if (fetchParams.request.mode !== 'navigator' || !response.hasCrossOriginRedirects) {\n        // 1. Set responseStatus to responses status.\n        responseStatus = response.status\n\n        // 2. Let mimeType be the result of extracting a MIME type from responses header list.\n        const mimeType = extractMimeType(response.headersList)\n\n        // 3. If mimeType is not failure, then set bodyInfos content type to the result of minimizing a supported MIME type given mimeType.\n        if (mimeType !== 'failure') {\n          bodyInfo.contentType = minimizeSupportedMimeType(mimeType)\n        }\n      }\n\n      // 8. If fetchParamss requests initiator type is non-null, then mark resource timing given timingInfo,\n      //    fetchParamss requests URL, fetchParamss requests initiator type, global, cacheState, bodyInfo,\n      //    and responseStatus.\n      if (fetchParams.request.initiatorType != null) {\n        // TODO: update markresourcetiming\n        markResourceTiming(timingInfo, fetchParams.request.url.href, fetchParams.request.initiatorType, globalThis, cacheState, bodyInfo, responseStatus)\n      }\n    }\n\n    // 4. Let processResponseEndOfBodyTask be the following steps:\n    const processResponseEndOfBodyTask = () => {\n      // 1. Set fetchParamss requests done flag.\n      fetchParams.request.done = true\n\n      // 2. If fetchParamss process response end-of-body is non-null, then run fetchParamss process\n      //    response end-of-body given response.\n      if (fetchParams.processResponseEndOfBody != null) {\n        queueMicrotask(() => fetchParams.processResponseEndOfBody(response))\n      }\n\n      // 3. If fetchParamss requests initiator type is non-null and fetchParamss requests clients\n      //    global object is fetchParamss task destination, then run fetchParamss controllers report\n      //    timing steps given fetchParamss requests clients global object.\n      if (fetchParams.request.initiatorType != null) {\n        fetchParams.controller.reportTimingSteps()\n      }\n    }\n\n    // 5. Queue a fetch task to run processResponseEndOfBodyTask with fetchParamss task destination\n    queueMicrotask(() => processResponseEndOfBodyTask())\n  }\n\n  // 4. If fetchParamss process response is non-null, then queue a fetch task to run fetchParamss\n  //    process response given response, with fetchParamss task destination.\n  if (fetchParams.processResponse != null) {\n    queueMicrotask(() => {\n      fetchParams.processResponse(response)\n      fetchParams.processResponse = null\n    })\n  }\n\n  // 5. Let internalResponse be response, if response is a network error; otherwise responses internal response.\n  const internalResponse = response.type === 'error' ? response : (response.internalResponse ?? response)\n\n  // 6. If internalResponses body is null, then run processResponseEndOfBody.\n  // 7. Otherwise:\n  if (internalResponse.body == null) {\n    processResponseEndOfBody()\n  } else {\n    // mcollina: all the following steps of the specs are skipped.\n    // The internal transform stream is not needed.\n    // See https://github.com/nodejs/undici/pull/3093#issuecomment-2050198541\n\n    // 1. Let transformStream be a new TransformStream.\n    // 2. Let identityTransformAlgorithm be an algorithm which, given chunk, enqueues chunk in transformStream.\n    // 3. Set up transformStream with transformAlgorithm set to identityTransformAlgorithm and flushAlgorithm\n    //    set to processResponseEndOfBody.\n    // 4. Set internalResponses bodys stream to the result of internalResponses bodys stream piped through transformStream.\n\n    finished(internalResponse.body.stream, () => {\n      processResponseEndOfBody()\n    })\n  }\n}\n\n// https://fetch.spec.whatwg.org/#http-fetch\nasync function httpFetch (fetchParams) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. Let actualResponse be null.\n  let actualResponse = null\n\n  // 4. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 5. If requests service-workers mode is \"all\", then:\n  if (request.serviceWorkers === 'all') {\n    // TODO\n  }\n\n  // 6. If response is null, then:\n  if (response === null) {\n    // 1. If makeCORSPreflight is true and one of these conditions is true:\n    // TODO\n\n    // 2. If requests redirect mode is \"follow\", then set requests\n    // service-workers mode to \"none\".\n    if (request.redirect === 'follow') {\n      request.serviceWorkers = 'none'\n    }\n\n    // 3. Set response and actualResponse to the result of running\n    // HTTP-network-or-cache fetch given fetchParams.\n    actualResponse = response = await httpNetworkOrCacheFetch(fetchParams)\n\n    // 4. If requests response tainting is \"cors\" and a CORS check\n    // for request and response returns failure, then return a network error.\n    if (\n      request.responseTainting === 'cors' &&\n      corsCheck(request, response) === 'failure'\n    ) {\n      return makeNetworkError('cors failure')\n    }\n\n    // 5. If the TAO check for request and response returns failure, then set\n    // requests timing allow failed flag.\n    if (TAOCheck(request, response) === 'failure') {\n      request.timingAllowFailed = true\n    }\n  }\n\n  // 7. If either requests response tainting or responses type\n  // is \"opaque\", and the cross-origin resource policy check with\n  // requests origin, requests client, requests destination,\n  // and actualResponse returns blocked, then return a network error.\n  if (\n    (request.responseTainting === 'opaque' || response.type === 'opaque') &&\n    crossOriginResourcePolicyCheck(\n      request.origin,\n      request.client,\n      request.destination,\n      actualResponse\n    ) === 'blocked'\n  ) {\n    return makeNetworkError('blocked')\n  }\n\n  // 8. If actualResponses status is a redirect status, then:\n  if (redirectStatusSet.has(actualResponse.status)) {\n    // 1. If actualResponses status is not 303, requests body is not null,\n    // and the connection uses HTTP/2, then user agents may, and are even\n    // encouraged to, transmit an RST_STREAM frame.\n    // See, https://github.com/whatwg/fetch/issues/1288\n    if (request.redirect !== 'manual') {\n      fetchParams.controller.connection.destroy(undefined, false)\n    }\n\n    // 2. Switch on requests redirect mode:\n    if (request.redirect === 'error') {\n      // Set response to a network error.\n      response = makeNetworkError('unexpected redirect')\n    } else if (request.redirect === 'manual') {\n      // Set response to an opaque-redirect filtered response whose internal\n      // response is actualResponse.\n      // NOTE(spec): On the web this would return an `opaqueredirect` response,\n      // but that doesn't make sense server side.\n      // See https://github.com/nodejs/undici/issues/1193.\n      response = actualResponse\n    } else if (request.redirect === 'follow') {\n      // Set response to the result of running HTTP-redirect fetch given\n      // fetchParams and response.\n      response = await httpRedirectFetch(fetchParams, response)\n    } else {\n      assert(false)\n    }\n  }\n\n  // 9. Set responses timing info to timingInfo.\n  response.timingInfo = timingInfo\n\n  // 10. Return response.\n  return response\n}\n\n// https://fetch.spec.whatwg.org/#http-redirect-fetch\nfunction httpRedirectFetch (fetchParams, response) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let actualResponse be response, if response is not a filtered response,\n  // and responses internal response otherwise.\n  const actualResponse = response.internalResponse\n    ? response.internalResponse\n    : response\n\n  // 3. Let locationURL be actualResponses location URL given requests current\n  // URLs fragment.\n  let locationURL\n\n  try {\n    locationURL = responseLocationURL(\n      actualResponse,\n      requestCurrentURL(request).hash\n    )\n\n    // 4. If locationURL is null, then return response.\n    if (locationURL == null) {\n      return response\n    }\n  } catch (err) {\n    // 5. If locationURL is failure, then return a network error.\n    return Promise.resolve(makeNetworkError(err))\n  }\n\n  // 6. If locationURLs scheme is not an HTTP(S) scheme, then return a network\n  // error.\n  if (!urlIsHttpHttpsScheme(locationURL)) {\n    return Promise.resolve(makeNetworkError('URL scheme must be a HTTP(S) scheme'))\n  }\n\n  // 7. If requests redirect count is 20, then return a network error.\n  if (request.redirectCount === 20) {\n    return Promise.resolve(makeNetworkError('redirect count exceeded'))\n  }\n\n  // 8. Increase requests redirect count by 1.\n  request.redirectCount += 1\n\n  // 9. If requests mode is \"cors\", locationURL includes credentials, and\n  // requests origin is not same origin with locationURLs origin, then return\n  //  a network error.\n  if (\n    request.mode === 'cors' &&\n    (locationURL.username || locationURL.password) &&\n    !sameOrigin(request, locationURL)\n  ) {\n    return Promise.resolve(makeNetworkError('cross origin not allowed for request mode \"cors\"'))\n  }\n\n  // 10. If requests response tainting is \"cors\" and locationURL includes\n  // credentials, then return a network error.\n  if (\n    request.responseTainting === 'cors' &&\n    (locationURL.username || locationURL.password)\n  ) {\n    return Promise.resolve(makeNetworkError(\n      'URL cannot contain credentials for request mode \"cors\"'\n    ))\n  }\n\n  // 11. If actualResponses status is not 303, requests body is non-null,\n  // and requests bodys source is null, then return a network error.\n  if (\n    actualResponse.status !== 303 &&\n    request.body != null &&\n    request.body.source == null\n  ) {\n    return Promise.resolve(makeNetworkError())\n  }\n\n  // 12. If one of the following is true\n  // - actualResponses status is 301 or 302 and requests method is `POST`\n  // - actualResponses status is 303 and requests method is not `GET` or `HEAD`\n  if (\n    ([301, 302].includes(actualResponse.status) && request.method === 'POST') ||\n    (actualResponse.status === 303 &&\n      !GET_OR_HEAD.includes(request.method))\n  ) {\n    // then:\n    // 1. Set requests method to `GET` and requests body to null.\n    request.method = 'GET'\n    request.body = null\n\n    // 2. For each headerName of request-body-header name, delete headerName from\n    // requests header list.\n    for (const headerName of requestBodyHeader) {\n      request.headersList.delete(headerName)\n    }\n  }\n\n  // 13. If requests current URLs origin is not same origin with locationURLs\n  //     origin, then for each headerName of CORS non-wildcard request-header name,\n  //     delete headerName from requests header list.\n  if (!sameOrigin(requestCurrentURL(request), locationURL)) {\n    // https://fetch.spec.whatwg.org/#cors-non-wildcard-request-header-name\n    request.headersList.delete('authorization', true)\n\n    // https://fetch.spec.whatwg.org/#authentication-entries\n    request.headersList.delete('proxy-authorization', true)\n\n    // \"Cookie\" and \"Host\" are forbidden request-headers, which undici doesn't implement.\n    request.headersList.delete('cookie', true)\n    request.headersList.delete('host', true)\n  }\n\n  // 14. If requests body is non-null, then set requests body to the first return\n  // value of safely extracting requests bodys source.\n  if (request.body != null) {\n    assert(request.body.source != null)\n    request.body = safelyExtractBody(request.body.source)[0]\n  }\n\n  // 15. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 16. Set timingInfos redirect end time and post-redirect start time to the\n  // coarsened shared current time given fetchParamss cross-origin isolated\n  // capability.\n  timingInfo.redirectEndTime = timingInfo.postRedirectStartTime =\n    coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability)\n\n  // 17. If timingInfos redirect start time is 0, then set timingInfos\n  //  redirect start time to timingInfos start time.\n  if (timingInfo.redirectStartTime === 0) {\n    timingInfo.redirectStartTime = timingInfo.startTime\n  }\n\n  // 18. Append locationURL to requests URL list.\n  request.urlList.push(locationURL)\n\n  // 19. Invoke set requests referrer policy on redirect on request and\n  // actualResponse.\n  setRequestReferrerPolicyOnRedirect(request, actualResponse)\n\n  // 20. Return the result of running main fetch given fetchParams and true.\n  return mainFetch(fetchParams, true)\n}\n\n// https://fetch.spec.whatwg.org/#http-network-or-cache-fetch\nasync function httpNetworkOrCacheFetch (\n  fetchParams,\n  isAuthenticationFetch = false,\n  isNewConnectionFetch = false\n) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let httpFetchParams be null.\n  let httpFetchParams = null\n\n  // 3. Let httpRequest be null.\n  let httpRequest = null\n\n  // 4. Let response be null.\n  let response = null\n\n  // 5. Let storedResponse be null.\n  // TODO: cache\n\n  // 6. Let httpCache be null.\n  const httpCache = null\n\n  // 7. Let the revalidatingFlag be unset.\n  const revalidatingFlag = false\n\n  // 8. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. If requests window is \"no-window\" and requests redirect mode is\n  //    \"error\", then set httpFetchParams to fetchParams and httpRequest to\n  //    request.\n  if (request.window === 'no-window' && request.redirect === 'error') {\n    httpFetchParams = fetchParams\n    httpRequest = request\n  } else {\n    // Otherwise:\n\n    // 1. Set httpRequest to a clone of request.\n    httpRequest = cloneRequest(request)\n\n    // 2. Set httpFetchParams to a copy of fetchParams.\n    httpFetchParams = { ...fetchParams }\n\n    // 3. Set httpFetchParamss request to httpRequest.\n    httpFetchParams.request = httpRequest\n  }\n\n  //    3. Let includeCredentials be true if one of\n  const includeCredentials =\n    request.credentials === 'include' ||\n    (request.credentials === 'same-origin' &&\n      request.responseTainting === 'basic')\n\n  //    4. Let contentLength be httpRequests bodys length, if httpRequests\n  //    body is non-null; otherwise null.\n  const contentLength = httpRequest.body ? httpRequest.body.length : null\n\n  //    5. Let contentLengthHeaderValue be null.\n  let contentLengthHeaderValue = null\n\n  //    6. If httpRequests body is null and httpRequests method is `POST` or\n  //    `PUT`, then set contentLengthHeaderValue to `0`.\n  if (\n    httpRequest.body == null &&\n    ['POST', 'PUT'].includes(httpRequest.method)\n  ) {\n    contentLengthHeaderValue = '0'\n  }\n\n  //    7. If contentLength is non-null, then set contentLengthHeaderValue to\n  //    contentLength, serialized and isomorphic encoded.\n  if (contentLength != null) {\n    contentLengthHeaderValue = isomorphicEncode(`${contentLength}`)\n  }\n\n  //    8. If contentLengthHeaderValue is non-null, then append\n  //    `Content-Length`/contentLengthHeaderValue to httpRequests header\n  //    list.\n  if (contentLengthHeaderValue != null) {\n    httpRequest.headersList.append('content-length', contentLengthHeaderValue, true)\n  }\n\n  //    9. If contentLengthHeaderValue is non-null, then append (`Content-Length`,\n  //    contentLengthHeaderValue) to httpRequests header list.\n\n  //    10. If contentLength is non-null and httpRequests keepalive is true,\n  //    then:\n  if (contentLength != null && httpRequest.keepalive) {\n    // NOTE: keepalive is a noop outside of browser context.\n  }\n\n  //    11. If httpRequests referrer is a URL, then append\n  //    `Referer`/httpRequests referrer, serialized and isomorphic encoded,\n  //     to httpRequests header list.\n  if (httpRequest.referrer instanceof URL) {\n    httpRequest.headersList.append('referer', isomorphicEncode(httpRequest.referrer.href), true)\n  }\n\n  //    12. Append a request `Origin` header for httpRequest.\n  appendRequestOriginHeader(httpRequest)\n\n  //    13. Append the Fetch metadata headers for httpRequest. [FETCH-METADATA]\n  appendFetchMetadata(httpRequest)\n\n  //    14. If httpRequests header list does not contain `User-Agent`, then\n  //    user agents should append `User-Agent`/default `User-Agent` value to\n  //    httpRequests header list.\n  if (!httpRequest.headersList.contains('user-agent', true)) {\n    httpRequest.headersList.append('user-agent', defaultUserAgent)\n  }\n\n  //    15. If httpRequests cache mode is \"default\" and httpRequests header\n  //    list contains `If-Modified-Since`, `If-None-Match`,\n  //    `If-Unmodified-Since`, `If-Match`, or `If-Range`, then set\n  //    httpRequests cache mode to \"no-store\".\n  if (\n    httpRequest.cache === 'default' &&\n    (httpRequest.headersList.contains('if-modified-since', true) ||\n      httpRequest.headersList.contains('if-none-match', true) ||\n      httpRequest.headersList.contains('if-unmodified-since', true) ||\n      httpRequest.headersList.contains('if-match', true) ||\n      httpRequest.headersList.contains('if-range', true))\n  ) {\n    httpRequest.cache = 'no-store'\n  }\n\n  //    16. If httpRequests cache mode is \"no-cache\", httpRequests prevent\n  //    no-cache cache-control header modification flag is unset, and\n  //    httpRequests header list does not contain `Cache-Control`, then append\n  //    `Cache-Control`/`max-age=0` to httpRequests header list.\n  if (\n    httpRequest.cache === 'no-cache' &&\n    !httpRequest.preventNoCacheCacheControlHeaderModification &&\n    !httpRequest.headersList.contains('cache-control', true)\n  ) {\n    httpRequest.headersList.append('cache-control', 'max-age=0', true)\n  }\n\n  //    17. If httpRequests cache mode is \"no-store\" or \"reload\", then:\n  if (httpRequest.cache === 'no-store' || httpRequest.cache === 'reload') {\n    // 1. If httpRequests header list does not contain `Pragma`, then append\n    // `Pragma`/`no-cache` to httpRequests header list.\n    if (!httpRequest.headersList.contains('pragma', true)) {\n      httpRequest.headersList.append('pragma', 'no-cache', true)\n    }\n\n    // 2. If httpRequests header list does not contain `Cache-Control`,\n    // then append `Cache-Control`/`no-cache` to httpRequests header list.\n    if (!httpRequest.headersList.contains('cache-control', true)) {\n      httpRequest.headersList.append('cache-control', 'no-cache', true)\n    }\n  }\n\n  //    18. If httpRequests header list contains `Range`, then append\n  //    `Accept-Encoding`/`identity` to httpRequests header list.\n  if (httpRequest.headersList.contains('range', true)) {\n    httpRequest.headersList.append('accept-encoding', 'identity', true)\n  }\n\n  //    19. Modify httpRequests header list per HTTP. Do not append a given\n  //    header if httpRequests header list contains that headers name.\n  //    TODO: https://github.com/whatwg/fetch/issues/1285#issuecomment-896560129\n  if (!httpRequest.headersList.contains('accept-encoding', true)) {\n    if (urlHasHttpsScheme(requestCurrentURL(httpRequest))) {\n      httpRequest.headersList.append('accept-encoding', 'br, gzip, deflate', true)\n    } else {\n      httpRequest.headersList.append('accept-encoding', 'gzip, deflate', true)\n    }\n  }\n\n  httpRequest.headersList.delete('host', true)\n\n  //    20. If includeCredentials is true, then:\n  if (includeCredentials) {\n    // 1. If the user agent is not configured to block cookies for httpRequest\n    // (see section 7 of [COOKIES]), then:\n    // TODO: credentials\n    // 2. If httpRequests header list does not contain `Authorization`, then:\n    // TODO: credentials\n  }\n\n  //    21. If theres a proxy-authentication entry, use it as appropriate.\n  //    TODO: proxy-authentication\n\n  //    22. Set httpCache to the result of determining the HTTP cache\n  //    partition, given httpRequest.\n  //    TODO: cache\n\n  //    23. If httpCache is null, then set httpRequests cache mode to\n  //    \"no-store\".\n  if (httpCache == null) {\n    httpRequest.cache = 'no-store'\n  }\n\n  //    24. If httpRequests cache mode is neither \"no-store\" nor \"reload\",\n  //    then:\n  if (httpRequest.cache !== 'no-store' && httpRequest.cache !== 'reload') {\n    // TODO: cache\n  }\n\n  // 9. If aborted, then return the appropriate network error for fetchParams.\n  // TODO\n\n  // 10. If response is null, then:\n  if (response == null) {\n    // 1. If httpRequests cache mode is \"only-if-cached\", then return a\n    // network error.\n    if (httpRequest.cache === 'only-if-cached') {\n      return makeNetworkError('only if cached')\n    }\n\n    // 2. Let forwardResponse be the result of running HTTP-network fetch\n    // given httpFetchParams, includeCredentials, and isNewConnectionFetch.\n    const forwardResponse = await httpNetworkFetch(\n      httpFetchParams,\n      includeCredentials,\n      isNewConnectionFetch\n    )\n\n    // 3. If httpRequests method is unsafe and forwardResponses status is\n    // in the range 200 to 399, inclusive, invalidate appropriate stored\n    // responses in httpCache, as per the \"Invalidation\" chapter of HTTP\n    // Caching, and set storedResponse to null. [HTTP-CACHING]\n    if (\n      !safeMethodsSet.has(httpRequest.method) &&\n      forwardResponse.status >= 200 &&\n      forwardResponse.status <= 399\n    ) {\n      // TODO: cache\n    }\n\n    // 4. If the revalidatingFlag is set and forwardResponses status is 304,\n    // then:\n    if (revalidatingFlag && forwardResponse.status === 304) {\n      // TODO: cache\n    }\n\n    // 5. If response is null, then:\n    if (response == null) {\n      // 1. Set response to forwardResponse.\n      response = forwardResponse\n\n      // 2. Store httpRequest and forwardResponse in httpCache, as per the\n      // \"Storing Responses in Caches\" chapter of HTTP Caching. [HTTP-CACHING]\n      // TODO: cache\n    }\n  }\n\n  // 11. Set responses URL list to a clone of httpRequests URL list.\n  response.urlList = [...httpRequest.urlList]\n\n  // 12. If httpRequests header list contains `Range`, then set responses\n  // range-requested flag.\n  if (httpRequest.headersList.contains('range', true)) {\n    response.rangeRequested = true\n  }\n\n  // 13. Set responses request-includes-credentials to includeCredentials.\n  response.requestIncludesCredentials = includeCredentials\n\n  // 14. If responses status is 401, httpRequests response tainting is not\n  // \"cors\", includeCredentials is true, and requests window is an environment\n  // settings object, then:\n  // TODO\n\n  // 15. If responses status is 407, then:\n  if (response.status === 407) {\n    // 1. If requests window is \"no-window\", then return a network error.\n    if (request.window === 'no-window') {\n      return makeNetworkError()\n    }\n\n    // 2. ???\n\n    // 3. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n    if (isCancelled(fetchParams)) {\n      return makeAppropriateNetworkError(fetchParams)\n    }\n\n    // 4. Prompt the end user as appropriate in requests window and store\n    // the result as a proxy-authentication entry. [HTTP-AUTH]\n    // TODO: Invoke some kind of callback?\n\n    // 5. Set response to the result of running HTTP-network-or-cache fetch given\n    // fetchParams.\n    // TODO\n    return makeNetworkError('proxy authentication required')\n  }\n\n  // 16. If all of the following are true\n  if (\n    // responses status is 421\n    response.status === 421 &&\n    // isNewConnectionFetch is false\n    !isNewConnectionFetch &&\n    // requests body is null, or requests body is non-null and requests bodys source is non-null\n    (request.body == null || request.body.source != null)\n  ) {\n    // then:\n\n    // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n    if (isCancelled(fetchParams)) {\n      return makeAppropriateNetworkError(fetchParams)\n    }\n\n    // 2. Set response to the result of running HTTP-network-or-cache\n    // fetch given fetchParams, isAuthenticationFetch, and true.\n\n    // TODO (spec): The spec doesn't specify this but we need to cancel\n    // the active response before we can start a new one.\n    // https://github.com/whatwg/fetch/issues/1293\n    fetchParams.controller.connection.destroy()\n\n    response = await httpNetworkOrCacheFetch(\n      fetchParams,\n      isAuthenticationFetch,\n      true\n    )\n  }\n\n  // 17. If isAuthenticationFetch is true, then create an authentication entry\n  if (isAuthenticationFetch) {\n    // TODO\n  }\n\n  // 18. Return response.\n  return response\n}\n\n// https://fetch.spec.whatwg.org/#http-network-fetch\nasync function httpNetworkFetch (\n  fetchParams,\n  includeCredentials = false,\n  forceNewConnection = false\n) {\n  assert(!fetchParams.controller.connection || fetchParams.controller.connection.destroyed)\n\n  fetchParams.controller.connection = {\n    abort: null,\n    destroyed: false,\n    destroy (err, abort = true) {\n      if (!this.destroyed) {\n        this.destroyed = true\n        if (abort) {\n          this.abort?.(err ?? new DOMException('The operation was aborted.', 'AbortError'))\n        }\n      }\n    }\n  }\n\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 4. Let httpCache be the result of determining the HTTP cache partition,\n  // given request.\n  // TODO: cache\n  const httpCache = null\n\n  // 5. If httpCache is null, then set requests cache mode to \"no-store\".\n  if (httpCache == null) {\n    request.cache = 'no-store'\n  }\n\n  // 6. Let networkPartitionKey be the result of determining the network\n  // partition key given request.\n  // TODO\n\n  // 7. Let newConnection be \"yes\" if forceNewConnection is true; otherwise\n  // \"no\".\n  const newConnection = forceNewConnection ? 'yes' : 'no' // eslint-disable-line no-unused-vars\n\n  // 8. Switch on requests mode:\n  if (request.mode === 'websocket') {\n    // Let connection be the result of obtaining a WebSocket connection,\n    // given requests current URL.\n    // TODO\n  } else {\n    // Let connection be the result of obtaining a connection, given\n    // networkPartitionKey, requests current URLs origin,\n    // includeCredentials, and forceNewConnection.\n    // TODO\n  }\n\n  // 9. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. If connection is failure, then return a network error.\n\n  //    2. Set timingInfos final connection timing info to the result of\n  //    calling clamp and coarsen connection timing info with connections\n  //    timing info, timingInfos post-redirect start time, and fetchParamss\n  //    cross-origin isolated capability.\n\n  //    3. If connection is not an HTTP/2 connection, requests body is non-null,\n  //    and requests bodys source is null, then append (`Transfer-Encoding`,\n  //    `chunked`) to requests header list.\n\n  //    4. Set timingInfos final network-request start time to the coarsened\n  //    shared current time given fetchParamss cross-origin isolated\n  //    capability.\n\n  //    5. Set response to the result of making an HTTP request over connection\n  //    using request with the following caveats:\n\n  //        - Follow the relevant requirements from HTTP. [HTTP] [HTTP-SEMANTICS]\n  //        [HTTP-COND] [HTTP-CACHING] [HTTP-AUTH]\n\n  //        - If requests body is non-null, and requests bodys source is null,\n  //        then the user agent may have a buffer of up to 64 kibibytes and store\n  //        a part of requests body in that buffer. If the user agent reads from\n  //        requests body beyond that buffers size and the user agent needs to\n  //        resend request, then instead return a network error.\n\n  //        - Set timingInfos final network-response start time to the coarsened\n  //        shared current time given fetchParamss cross-origin isolated capability,\n  //        immediately after the user agents HTTP parser receives the first byte\n  //        of the response (e.g., frame header bytes for HTTP/2 or response status\n  //        line for HTTP/1.x).\n\n  //        - Wait until all the headers are transmitted.\n\n  //        - Any responses whose status is in the range 100 to 199, inclusive,\n  //        and is not 101, are to be ignored, except for the purposes of setting\n  //        timingInfos final network-response start time above.\n\n  //    - If requests header list contains `Transfer-Encoding`/`chunked` and\n  //    response is transferred via HTTP/1.0 or older, then return a network\n  //    error.\n\n  //    - If the HTTP request results in a TLS client certificate dialog, then:\n\n  //        1. If requests window is an environment settings object, make the\n  //        dialog available in requests window.\n\n  //        2. Otherwise, return a network error.\n\n  // To transmit requests body body, run these steps:\n  let requestBody = null\n  // 1. If body is null and fetchParamss process request end-of-body is\n  // non-null, then queue a fetch task given fetchParamss process request\n  // end-of-body and fetchParamss task destination.\n  if (request.body == null && fetchParams.processRequestEndOfBody) {\n    queueMicrotask(() => fetchParams.processRequestEndOfBody())\n  } else if (request.body != null) {\n    // 2. Otherwise, if body is non-null:\n\n    //    1. Let processBodyChunk given bytes be these steps:\n    const processBodyChunk = async function * (bytes) {\n      // 1. If the ongoing fetch is terminated, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. Run this step in parallel: transmit bytes.\n      yield bytes\n\n      // 3. If fetchParamss process request body is non-null, then run\n      // fetchParamss process request body given bytess length.\n      fetchParams.processRequestBodyChunkLength?.(bytes.byteLength)\n    }\n\n    // 2. Let processEndOfBody be these steps:\n    const processEndOfBody = () => {\n      // 1. If fetchParams is canceled, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. If fetchParamss process request end-of-body is non-null,\n      // then run fetchParamss process request end-of-body.\n      if (fetchParams.processRequestEndOfBody) {\n        fetchParams.processRequestEndOfBody()\n      }\n    }\n\n    // 3. Let processBodyError given e be these steps:\n    const processBodyError = (e) => {\n      // 1. If fetchParams is canceled, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. If e is an \"AbortError\" DOMException, then abort fetchParamss controller.\n      if (e.name === 'AbortError') {\n        fetchParams.controller.abort()\n      } else {\n        fetchParams.controller.terminate(e)\n      }\n    }\n\n    // 4. Incrementally read requests body given processBodyChunk, processEndOfBody,\n    // processBodyError, and fetchParamss task destination.\n    requestBody = (async function * () {\n      try {\n        for await (const bytes of request.body.stream) {\n          yield * processBodyChunk(bytes)\n        }\n        processEndOfBody()\n      } catch (err) {\n        processBodyError(err)\n      }\n    })()\n  }\n\n  try {\n    // socket is only provided for websockets\n    const { body, status, statusText, headersList, socket } = await dispatch({ body: requestBody })\n\n    if (socket) {\n      response = makeResponse({ status, statusText, headersList, socket })\n    } else {\n      const iterator = body[Symbol.asyncIterator]()\n      fetchParams.controller.next = () => iterator.next()\n\n      response = makeResponse({ status, statusText, headersList })\n    }\n  } catch (err) {\n    // 10. If aborted, then:\n    if (err.name === 'AbortError') {\n      // 1. If connection uses HTTP/2, then transmit an RST_STREAM frame.\n      fetchParams.controller.connection.destroy()\n\n      // 2. Return the appropriate network error for fetchParams.\n      return makeAppropriateNetworkError(fetchParams, err)\n    }\n\n    return makeNetworkError(err)\n  }\n\n  // 11. Let pullAlgorithm be an action that resumes the ongoing fetch\n  // if it is suspended.\n  const pullAlgorithm = async () => {\n    await fetchParams.controller.resume()\n  }\n\n  // 12. Let cancelAlgorithm be an algorithm that aborts fetchParamss\n  // controller with reason, given reason.\n  const cancelAlgorithm = (reason) => {\n    // If the aborted fetch was already terminated, then we do not\n    // need to do anything.\n    if (!isCancelled(fetchParams)) {\n      fetchParams.controller.abort(reason)\n    }\n  }\n\n  // 13. Let highWaterMark be a non-negative, non-NaN number, chosen by\n  // the user agent.\n  // TODO\n\n  // 14. Let sizeAlgorithm be an algorithm that accepts a chunk object\n  // and returns a non-negative, non-NaN, non-infinite number, chosen by the user agent.\n  // TODO\n\n  // 15. Let stream be a new ReadableStream.\n  // 16. Set up stream with byte reading support with pullAlgorithm set to pullAlgorithm,\n  //     cancelAlgorithm set to cancelAlgorithm.\n  const stream = new ReadableStream(\n    {\n      async start (controller) {\n        fetchParams.controller.controller = controller\n      },\n      async pull (controller) {\n        await pullAlgorithm(controller)\n      },\n      async cancel (reason) {\n        await cancelAlgorithm(reason)\n      },\n      type: 'bytes'\n    }\n  )\n\n  // 17. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. Set responses body to a new body whose stream is stream.\n  response.body = { stream, source: null, length: null }\n\n  //    2. If response is not a network error and requests cache mode is\n  //    not \"no-store\", then update response in httpCache for request.\n  //    TODO\n\n  //    3. If includeCredentials is true and the user agent is not configured\n  //    to block cookies for request (see section 7 of [COOKIES]), then run the\n  //    \"set-cookie-string\" parsing algorithm (see section 5.2 of [COOKIES]) on\n  //    the value of each header whose name is a byte-case-insensitive match for\n  //    `Set-Cookie` in responses header list, if any, and requests current URL.\n  //    TODO\n\n  // 18. If aborted, then:\n  // TODO\n\n  // 19. Run these steps in parallel:\n\n  //    1. Run these steps, but abort when fetchParams is canceled:\n  fetchParams.controller.onAborted = onAborted\n  fetchParams.controller.on('terminated', onAborted)\n  fetchParams.controller.resume = async () => {\n    // 1. While true\n    while (true) {\n      // 1-3. See onData...\n\n      // 4. Set bytes to the result of handling content codings given\n      // codings and bytes.\n      let bytes\n      let isFailure\n      try {\n        const { done, value } = await fetchParams.controller.next()\n\n        if (isAborted(fetchParams)) {\n          break\n        }\n\n        bytes = done ? undefined : value\n      } catch (err) {\n        if (fetchParams.controller.ended && !timingInfo.encodedBodySize) {\n          // zlib doesn't like empty streams.\n          bytes = undefined\n        } else {\n          bytes = err\n\n          // err may be propagated from the result of calling readablestream.cancel,\n          // which might not be an error. https://github.com/nodejs/undici/issues/2009\n          isFailure = true\n        }\n      }\n\n      if (bytes === undefined) {\n        // 2. Otherwise, if the bytes transmission for responses message\n        // body is done normally and stream is readable, then close\n        // stream, finalize response for fetchParams and response, and\n        // abort these in-parallel steps.\n        readableStreamClose(fetchParams.controller.controller)\n\n        finalizeResponse(fetchParams, response)\n\n        return\n      }\n\n      // 5. Increase timingInfos decoded body size by bytess length.\n      timingInfo.decodedBodySize += bytes?.byteLength ?? 0\n\n      // 6. If bytes is failure, then terminate fetchParamss controller.\n      if (isFailure) {\n        fetchParams.controller.terminate(bytes)\n        return\n      }\n\n      // 7. Enqueue a Uint8Array wrapping an ArrayBuffer containing bytes\n      // into stream.\n      const buffer = new Uint8Array(bytes)\n      if (buffer.byteLength) {\n        fetchParams.controller.controller.enqueue(buffer)\n      }\n\n      // 8. If stream is errored, then terminate the ongoing fetch.\n      if (isErrored(stream)) {\n        fetchParams.controller.terminate()\n        return\n      }\n\n      // 9. If stream doesnt need more data ask the user agent to suspend\n      // the ongoing fetch.\n      if (fetchParams.controller.controller.desiredSize <= 0) {\n        return\n      }\n    }\n  }\n\n  //    2. If aborted, then:\n  function onAborted (reason) {\n    // 2. If fetchParams is aborted, then:\n    if (isAborted(fetchParams)) {\n      // 1. Set responses aborted flag.\n      response.aborted = true\n\n      // 2. If stream is readable, then error stream with the result of\n      //    deserialize a serialized abort reason given fetchParamss\n      //    controllers serialized abort reason and an\n      //    implementation-defined realm.\n      if (isReadable(stream)) {\n        fetchParams.controller.controller.error(\n          fetchParams.controller.serializedAbortReason\n        )\n      }\n    } else {\n      // 3. Otherwise, if stream is readable, error stream with a TypeError.\n      if (isReadable(stream)) {\n        fetchParams.controller.controller.error(new TypeError('terminated', {\n          cause: isErrorLike(reason) ? reason : undefined\n        }))\n      }\n    }\n\n    // 4. If connection uses HTTP/2, then transmit an RST_STREAM frame.\n    // 5. Otherwise, the user agent should close connection unless it would be bad for performance to do so.\n    fetchParams.controller.connection.destroy()\n  }\n\n  // 20. Return response.\n  return response\n\n  function dispatch ({ body }) {\n    const url = requestCurrentURL(request)\n    /** @type {import('../..').Agent} */\n    const agent = fetchParams.controller.dispatcher\n\n    return new Promise((resolve, reject) => agent.dispatch(\n      {\n        path: url.pathname + url.search,\n        origin: url.origin,\n        method: request.method,\n        body: agent.isMockActive ? request.body && (request.body.source || request.body.stream) : body,\n        headers: request.headersList.entries,\n        maxRedirections: 0,\n        upgrade: request.mode === 'websocket' ? 'websocket' : undefined\n      },\n      {\n        body: null,\n        abort: null,\n\n        onConnect (abort) {\n          // TODO (fix): Do we need connection here?\n          const { connection } = fetchParams.controller\n\n          // Set timingInfos final connection timing info to the result of calling clamp and coarsen\n          // connection timing info with connections timing info, timingInfos post-redirect start\n          // time, and fetchParamss cross-origin isolated capability.\n          // TODO: implement connection timing\n          timingInfo.finalConnectionTimingInfo = clampAndCoarsenConnectionTimingInfo(undefined, timingInfo.postRedirectStartTime, fetchParams.crossOriginIsolatedCapability)\n\n          if (connection.destroyed) {\n            abort(new DOMException('The operation was aborted.', 'AbortError'))\n          } else {\n            fetchParams.controller.on('terminated', abort)\n            this.abort = connection.abort = abort\n          }\n\n          // Set timingInfos final network-request start time to the coarsened shared current time given\n          // fetchParamss cross-origin isolated capability.\n          timingInfo.finalNetworkRequestStartTime = coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability)\n        },\n\n        onResponseStarted () {\n          // Set timingInfos final network-response start time to the coarsened shared current\n          // time given fetchParamss cross-origin isolated capability, immediately after the\n          // user agents HTTP parser receives the first byte of the response (e.g., frame header\n          // bytes for HTTP/2 or response status line for HTTP/1.x).\n          timingInfo.finalNetworkResponseStartTime = coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability)\n        },\n\n        onHeaders (status, rawHeaders, resume, statusText) {\n          if (status < 200) {\n            return\n          }\n\n          let location = ''\n\n          const headersList = new HeadersList()\n\n          for (let i = 0; i < rawHeaders.length; i += 2) {\n            headersList.append(bufferToLowerCasedHeaderName(rawHeaders[i]), rawHeaders[i + 1].toString('latin1'), true)\n          }\n          location = headersList.get('location', true)\n\n          this.body = new Readable({ read: resume })\n\n          const decoders = []\n\n          const willFollow = location && request.redirect === 'follow' &&\n            redirectStatusSet.has(status)\n\n          // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding\n          if (request.method !== 'HEAD' && request.method !== 'CONNECT' && !nullBodyStatus.includes(status) && !willFollow) {\n            // https://www.rfc-editor.org/rfc/rfc7231#section-3.1.2.1\n            const contentEncoding = headersList.get('content-encoding', true)\n            // \"All content-coding values are case-insensitive...\"\n            /** @type {string[]} */\n            const codings = contentEncoding ? contentEncoding.toLowerCase().split(',') : []\n\n            // Limit the number of content-encodings to prevent resource exhaustion.\n            // CVE fix similar to urllib3 (GHSA-gm62-xv2j-4w53) and curl (CVE-2022-32206).\n            const maxContentEncodings = 5\n            if (codings.length > maxContentEncodings) {\n              reject(new Error(`too many content-encodings in response: ${codings.length}, maximum allowed is ${maxContentEncodings}`))\n              return true\n            }\n\n            for (let i = codings.length - 1; i >= 0; --i) {\n              const coding = codings[i].trim()\n              // https://www.rfc-editor.org/rfc/rfc9112.html#section-7.2\n              if (coding === 'x-gzip' || coding === 'gzip') {\n                decoders.push(zlib.createGunzip({\n                  // Be less strict when decoding compressed responses, since sometimes\n                  // servers send slightly invalid responses that are still accepted\n                  // by common browsers.\n                  // Always using Z_SYNC_FLUSH is what cURL does.\n                  flush: zlib.constants.Z_SYNC_FLUSH,\n                  finishFlush: zlib.constants.Z_SYNC_FLUSH\n                }))\n              } else if (coding === 'deflate') {\n                decoders.push(createInflate({\n                  flush: zlib.constants.Z_SYNC_FLUSH,\n                  finishFlush: zlib.constants.Z_SYNC_FLUSH\n                }))\n              } else if (coding === 'br') {\n                decoders.push(zlib.createBrotliDecompress({\n                  flush: zlib.constants.BROTLI_OPERATION_FLUSH,\n                  finishFlush: zlib.constants.BROTLI_OPERATION_FLUSH\n                }))\n              } else {\n                decoders.length = 0\n                break\n              }\n            }\n          }\n\n          const onError = this.onError.bind(this)\n\n          resolve({\n            status,\n            statusText,\n            headersList,\n            body: decoders.length\n              ? pipeline(this.body, ...decoders, (err) => {\n                if (err) {\n                  this.onError(err)\n                }\n              }).on('error', onError)\n              : this.body.on('error', onError)\n          })\n\n          return true\n        },\n\n        onData (chunk) {\n          if (fetchParams.controller.dump) {\n            return\n          }\n\n          // 1. If one or more bytes have been transmitted from responses\n          // message body, then:\n\n          //  1. Let bytes be the transmitted bytes.\n          const bytes = chunk\n\n          //  2. Let codings be the result of extracting header list values\n          //  given `Content-Encoding` and responses header list.\n          //  See pullAlgorithm.\n\n          //  3. Increase timingInfos encoded body size by bytess length.\n          timingInfo.encodedBodySize += bytes.byteLength\n\n          //  4. See pullAlgorithm...\n\n          return this.body.push(bytes)\n        },\n\n        onComplete () {\n          if (this.abort) {\n            fetchParams.controller.off('terminated', this.abort)\n          }\n\n          if (fetchParams.controller.onAborted) {\n            fetchParams.controller.off('terminated', fetchParams.controller.onAborted)\n          }\n\n          fetchParams.controller.ended = true\n\n          this.body.push(null)\n        },\n\n        onError (error) {\n          if (this.abort) {\n            fetchParams.controller.off('terminated', this.abort)\n          }\n\n          this.body?.destroy(error)\n\n          fetchParams.controller.terminate(error)\n\n          reject(error)\n        },\n\n        onUpgrade (status, rawHeaders, socket) {\n          if (status !== 101) {\n            return\n          }\n\n          const headersList = new HeadersList()\n\n          for (let i = 0; i < rawHeaders.length; i += 2) {\n            headersList.append(bufferToLowerCasedHeaderName(rawHeaders[i]), rawHeaders[i + 1].toString('latin1'), true)\n          }\n\n          resolve({\n            status,\n            statusText: STATUS_CODES[status],\n            headersList,\n            socket\n          })\n\n          return true\n        }\n      }\n    ))\n  }\n}\n\nmodule.exports = {\n  fetch,\n  Fetch,\n  fetching,\n  finalizeAndReportTiming\n}\n","/* globals AbortController */\n\n'use strict'\n\nconst { extractBody, mixinBody, cloneBody, bodyUnusable } = require('./body')\nconst { Headers, fill: fillHeaders, HeadersList, setHeadersGuard, getHeadersGuard, setHeadersList, getHeadersList } = require('./headers')\nconst { FinalizationRegistry } = require('./dispatcher-weakref')()\nconst util = require('../../core/util')\nconst nodeUtil = require('node:util')\nconst {\n  isValidHTTPToken,\n  sameOrigin,\n  environmentSettingsObject\n} = require('./util')\nconst {\n  forbiddenMethodsSet,\n  corsSafeListedMethodsSet,\n  referrerPolicy,\n  requestRedirect,\n  requestMode,\n  requestCredentials,\n  requestCache,\n  requestDuplex\n} = require('./constants')\nconst { kEnumerableProperty, normalizedMethodRecordsBase, normalizedMethodRecords } = util\nconst { kHeaders, kSignal, kState, kDispatcher } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { URLSerializer } = require('./data-url')\nconst { kConstruct } = require('../../core/symbols')\nconst assert = require('node:assert')\nconst { getMaxListeners, setMaxListeners, getEventListeners, defaultMaxListeners } = require('node:events')\n\nconst kAbortController = Symbol('abortController')\n\nconst requestFinalizer = new FinalizationRegistry(({ signal, abort }) => {\n  signal.removeEventListener('abort', abort)\n})\n\nconst dependentControllerMap = new WeakMap()\n\nfunction buildAbort (acRef) {\n  return abort\n\n  function abort () {\n    const ac = acRef.deref()\n    if (ac !== undefined) {\n      // Currently, there is a problem with FinalizationRegistry.\n      // https://github.com/nodejs/node/issues/49344\n      // https://github.com/nodejs/node/issues/47748\n      // In the case of abort, the first step is to unregister from it.\n      // If the controller can refer to it, it is still registered.\n      // It will be removed in the future.\n      requestFinalizer.unregister(abort)\n\n      // Unsubscribe a listener.\n      // FinalizationRegistry will no longer be called, so this must be done.\n      this.removeEventListener('abort', abort)\n\n      ac.abort(this.reason)\n\n      const controllerList = dependentControllerMap.get(ac.signal)\n\n      if (controllerList !== undefined) {\n        if (controllerList.size !== 0) {\n          for (const ref of controllerList) {\n            const ctrl = ref.deref()\n            if (ctrl !== undefined) {\n              ctrl.abort(this.reason)\n            }\n          }\n          controllerList.clear()\n        }\n        dependentControllerMap.delete(ac.signal)\n      }\n    }\n  }\n}\n\nlet patchMethodWarning = false\n\n// https://fetch.spec.whatwg.org/#request-class\nclass Request {\n  // https://fetch.spec.whatwg.org/#dom-request\n  constructor (input, init = {}) {\n    webidl.util.markAsUncloneable(this)\n    if (input === kConstruct) {\n      return\n    }\n\n    const prefix = 'Request constructor'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    input = webidl.converters.RequestInfo(input, prefix, 'input')\n    init = webidl.converters.RequestInit(init, prefix, 'init')\n\n    // 1. Let request be null.\n    let request = null\n\n    // 2. Let fallbackMode be null.\n    let fallbackMode = null\n\n    // 3. Let baseURL be thiss relevant settings objects API base URL.\n    const baseUrl = environmentSettingsObject.settingsObject.baseUrl\n\n    // 4. Let signal be null.\n    let signal = null\n\n    // 5. If input is a string, then:\n    if (typeof input === 'string') {\n      this[kDispatcher] = init.dispatcher\n\n      // 1. Let parsedURL be the result of parsing input with baseURL.\n      // 2. If parsedURL is failure, then throw a TypeError.\n      let parsedURL\n      try {\n        parsedURL = new URL(input, baseUrl)\n      } catch (err) {\n        throw new TypeError('Failed to parse URL from ' + input, { cause: err })\n      }\n\n      // 3. If parsedURL includes credentials, then throw a TypeError.\n      if (parsedURL.username || parsedURL.password) {\n        throw new TypeError(\n          'Request cannot be constructed from a URL that includes credentials: ' +\n            input\n        )\n      }\n\n      // 4. Set request to a new request whose URL is parsedURL.\n      request = makeRequest({ urlList: [parsedURL] })\n\n      // 5. Set fallbackMode to \"cors\".\n      fallbackMode = 'cors'\n    } else {\n      this[kDispatcher] = init.dispatcher || input[kDispatcher]\n\n      // 6. Otherwise:\n\n      // 7. Assert: input is a Request object.\n      assert(input instanceof Request)\n\n      // 8. Set request to inputs request.\n      request = input[kState]\n\n      // 9. Set signal to inputs signal.\n      signal = input[kSignal]\n    }\n\n    // 7. Let origin be thiss relevant settings objects origin.\n    const origin = environmentSettingsObject.settingsObject.origin\n\n    // 8. Let window be \"client\".\n    let window = 'client'\n\n    // 9. If requests window is an environment settings object and its origin\n    // is same origin with origin, then set window to requests window.\n    if (\n      request.window?.constructor?.name === 'EnvironmentSettingsObject' &&\n      sameOrigin(request.window, origin)\n    ) {\n      window = request.window\n    }\n\n    // 10. If init[\"window\"] exists and is non-null, then throw a TypeError.\n    if (init.window != null) {\n      throw new TypeError(`'window' option '${window}' must be null`)\n    }\n\n    // 11. If init[\"window\"] exists, then set window to \"no-window\".\n    if ('window' in init) {\n      window = 'no-window'\n    }\n\n    // 12. Set request to a new request with the following properties:\n    request = makeRequest({\n      // URL requests URL.\n      // undici implementation note: this is set as the first item in request's urlList in makeRequest\n      // method requests method.\n      method: request.method,\n      // header list A copy of requests header list.\n      // undici implementation note: headersList is cloned in makeRequest\n      headersList: request.headersList,\n      // unsafe-request flag Set.\n      unsafeRequest: request.unsafeRequest,\n      // client Thiss relevant settings object.\n      client: environmentSettingsObject.settingsObject,\n      // window window.\n      window,\n      // priority requests priority.\n      priority: request.priority,\n      // origin requests origin. The propagation of the origin is only significant for navigation requests\n      // being handled by a service worker. In this scenario a request can have an origin that is different\n      // from the current client.\n      origin: request.origin,\n      // referrer requests referrer.\n      referrer: request.referrer,\n      // referrer policy requests referrer policy.\n      referrerPolicy: request.referrerPolicy,\n      // mode requests mode.\n      mode: request.mode,\n      // credentials mode requests credentials mode.\n      credentials: request.credentials,\n      // cache mode requests cache mode.\n      cache: request.cache,\n      // redirect mode requests redirect mode.\n      redirect: request.redirect,\n      // integrity metadata requests integrity metadata.\n      integrity: request.integrity,\n      // keepalive requests keepalive.\n      keepalive: request.keepalive,\n      // reload-navigation flag requests reload-navigation flag.\n      reloadNavigation: request.reloadNavigation,\n      // history-navigation flag requests history-navigation flag.\n      historyNavigation: request.historyNavigation,\n      // URL list A clone of requests URL list.\n      urlList: [...request.urlList]\n    })\n\n    const initHasKey = Object.keys(init).length !== 0\n\n    // 13. If init is not empty, then:\n    if (initHasKey) {\n      // 1. If requests mode is \"navigate\", then set it to \"same-origin\".\n      if (request.mode === 'navigate') {\n        request.mode = 'same-origin'\n      }\n\n      // 2. Unset requests reload-navigation flag.\n      request.reloadNavigation = false\n\n      // 3. Unset requests history-navigation flag.\n      request.historyNavigation = false\n\n      // 4. Set requests origin to \"client\".\n      request.origin = 'client'\n\n      // 5. Set requests referrer to \"client\"\n      request.referrer = 'client'\n\n      // 6. Set requests referrer policy to the empty string.\n      request.referrerPolicy = ''\n\n      // 7. Set requests URL to requests current URL.\n      request.url = request.urlList[request.urlList.length - 1]\n\n      // 8. Set requests URL list to  requests URL .\n      request.urlList = [request.url]\n    }\n\n    // 14. If init[\"referrer\"] exists, then:\n    if (init.referrer !== undefined) {\n      // 1. Let referrer be init[\"referrer\"].\n      const referrer = init.referrer\n\n      // 2. If referrer is the empty string, then set requests referrer to \"no-referrer\".\n      if (referrer === '') {\n        request.referrer = 'no-referrer'\n      } else {\n        // 1. Let parsedReferrer be the result of parsing referrer with\n        // baseURL.\n        // 2. If parsedReferrer is failure, then throw a TypeError.\n        let parsedReferrer\n        try {\n          parsedReferrer = new URL(referrer, baseUrl)\n        } catch (err) {\n          throw new TypeError(`Referrer \"${referrer}\" is not a valid URL.`, { cause: err })\n        }\n\n        // 3. If one of the following is true\n        // - parsedReferrers scheme is \"about\" and path is the string \"client\"\n        // - parsedReferrers origin is not same origin with origin\n        // then set requests referrer to \"client\".\n        if (\n          (parsedReferrer.protocol === 'about:' && parsedReferrer.hostname === 'client') ||\n          (origin && !sameOrigin(parsedReferrer, environmentSettingsObject.settingsObject.baseUrl))\n        ) {\n          request.referrer = 'client'\n        } else {\n          // 4. Otherwise, set requests referrer to parsedReferrer.\n          request.referrer = parsedReferrer\n        }\n      }\n    }\n\n    // 15. If init[\"referrerPolicy\"] exists, then set requests referrer policy\n    // to it.\n    if (init.referrerPolicy !== undefined) {\n      request.referrerPolicy = init.referrerPolicy\n    }\n\n    // 16. Let mode be init[\"mode\"] if it exists, and fallbackMode otherwise.\n    let mode\n    if (init.mode !== undefined) {\n      mode = init.mode\n    } else {\n      mode = fallbackMode\n    }\n\n    // 17. If mode is \"navigate\", then throw a TypeError.\n    if (mode === 'navigate') {\n      throw webidl.errors.exception({\n        header: 'Request constructor',\n        message: 'invalid request mode navigate.'\n      })\n    }\n\n    // 18. If mode is non-null, set requests mode to mode.\n    if (mode != null) {\n      request.mode = mode\n    }\n\n    // 19. If init[\"credentials\"] exists, then set requests credentials mode\n    // to it.\n    if (init.credentials !== undefined) {\n      request.credentials = init.credentials\n    }\n\n    // 18. If init[\"cache\"] exists, then set requests cache mode to it.\n    if (init.cache !== undefined) {\n      request.cache = init.cache\n    }\n\n    // 21. If requests cache mode is \"only-if-cached\" and requests mode is\n    // not \"same-origin\", then throw a TypeError.\n    if (request.cache === 'only-if-cached' && request.mode !== 'same-origin') {\n      throw new TypeError(\n        \"'only-if-cached' can be set only with 'same-origin' mode\"\n      )\n    }\n\n    // 22. If init[\"redirect\"] exists, then set requests redirect mode to it.\n    if (init.redirect !== undefined) {\n      request.redirect = init.redirect\n    }\n\n    // 23. If init[\"integrity\"] exists, then set requests integrity metadata to it.\n    if (init.integrity != null) {\n      request.integrity = String(init.integrity)\n    }\n\n    // 24. If init[\"keepalive\"] exists, then set requests keepalive to it.\n    if (init.keepalive !== undefined) {\n      request.keepalive = Boolean(init.keepalive)\n    }\n\n    // 25. If init[\"method\"] exists, then:\n    if (init.method !== undefined) {\n      // 1. Let method be init[\"method\"].\n      let method = init.method\n\n      const mayBeNormalized = normalizedMethodRecords[method]\n\n      if (mayBeNormalized !== undefined) {\n        // Note: Bypass validation DELETE, GET, HEAD, OPTIONS, POST, PUT, PATCH and these lowercase ones\n        request.method = mayBeNormalized\n      } else {\n        // 2. If method is not a method or method is a forbidden method, then\n        // throw a TypeError.\n        if (!isValidHTTPToken(method)) {\n          throw new TypeError(`'${method}' is not a valid HTTP method.`)\n        }\n\n        const upperCase = method.toUpperCase()\n\n        if (forbiddenMethodsSet.has(upperCase)) {\n          throw new TypeError(`'${method}' HTTP method is unsupported.`)\n        }\n\n        // 3. Normalize method.\n        // https://fetch.spec.whatwg.org/#concept-method-normalize\n        // Note: must be in uppercase\n        method = normalizedMethodRecordsBase[upperCase] ?? method\n\n        // 4. Set requests method to method.\n        request.method = method\n      }\n\n      if (!patchMethodWarning && request.method === 'patch') {\n        process.emitWarning('Using `patch` is highly likely to result in a `405 Method Not Allowed`. `PATCH` is much more likely to succeed.', {\n          code: 'UNDICI-FETCH-patch'\n        })\n\n        patchMethodWarning = true\n      }\n    }\n\n    // 26. If init[\"signal\"] exists, then set signal to it.\n    if (init.signal !== undefined) {\n      signal = init.signal\n    }\n\n    // 27. Set thiss request to request.\n    this[kState] = request\n\n    // 28. Set thiss signal to a new AbortSignal object with thiss relevant\n    // Realm.\n    // TODO: could this be simplified with AbortSignal.any\n    // (https://dom.spec.whatwg.org/#dom-abortsignal-any)\n    const ac = new AbortController()\n    this[kSignal] = ac.signal\n\n    // 29. If signal is not null, then make thiss signal follow signal.\n    if (signal != null) {\n      if (\n        !signal ||\n        typeof signal.aborted !== 'boolean' ||\n        typeof signal.addEventListener !== 'function'\n      ) {\n        throw new TypeError(\n          \"Failed to construct 'Request': member signal is not of type AbortSignal.\"\n        )\n      }\n\n      if (signal.aborted) {\n        ac.abort(signal.reason)\n      } else {\n        // Keep a strong ref to ac while request object\n        // is alive. This is needed to prevent AbortController\n        // from being prematurely garbage collected.\n        // See, https://github.com/nodejs/undici/issues/1926.\n        this[kAbortController] = ac\n\n        const acRef = new WeakRef(ac)\n        const abort = buildAbort(acRef)\n\n        // Third-party AbortControllers may not work with these.\n        // See, https://github.com/nodejs/undici/pull/1910#issuecomment-1464495619.\n        try {\n          // If the max amount of listeners is equal to the default, increase it\n          // This is only available in node >= v19.9.0\n          if (typeof getMaxListeners === 'function' && getMaxListeners(signal) === defaultMaxListeners) {\n            setMaxListeners(1500, signal)\n          } else if (getEventListeners(signal, 'abort').length >= defaultMaxListeners) {\n            setMaxListeners(1500, signal)\n          }\n        } catch {}\n\n        util.addAbortListener(signal, abort)\n        // The third argument must be a registry key to be unregistered.\n        // Without it, you cannot unregister.\n        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry\n        // abort is used as the unregister key. (because it is unique)\n        requestFinalizer.register(ac, { signal, abort }, abort)\n      }\n    }\n\n    // 30. Set thiss headers to a new Headers object with thiss relevant\n    // Realm, whose header list is requests header list and guard is\n    // \"request\".\n    this[kHeaders] = new Headers(kConstruct)\n    setHeadersList(this[kHeaders], request.headersList)\n    setHeadersGuard(this[kHeaders], 'request')\n\n    // 31. If thiss requests mode is \"no-cors\", then:\n    if (mode === 'no-cors') {\n      // 1. If thiss requests method is not a CORS-safelisted method,\n      // then throw a TypeError.\n      if (!corsSafeListedMethodsSet.has(request.method)) {\n        throw new TypeError(\n          `'${request.method} is unsupported in no-cors mode.`\n        )\n      }\n\n      // 2. Set thiss headerss guard to \"request-no-cors\".\n      setHeadersGuard(this[kHeaders], 'request-no-cors')\n    }\n\n    // 32. If init is not empty, then:\n    if (initHasKey) {\n      /** @type {HeadersList} */\n      const headersList = getHeadersList(this[kHeaders])\n      // 1. Let headers be a copy of thiss headers and its associated header\n      // list.\n      // 2. If init[\"headers\"] exists, then set headers to init[\"headers\"].\n      const headers = init.headers !== undefined ? init.headers : new HeadersList(headersList)\n\n      // 3. Empty thiss headerss header list.\n      headersList.clear()\n\n      // 4. If headers is a Headers object, then for each header in its header\n      // list, append headers name/headers value to thiss headers.\n      if (headers instanceof HeadersList) {\n        for (const { name, value } of headers.rawValues()) {\n          headersList.append(name, value, false)\n        }\n        // Note: Copy the `set-cookie` meta-data.\n        headersList.cookies = headers.cookies\n      } else {\n        // 5. Otherwise, fill thiss headers with headers.\n        fillHeaders(this[kHeaders], headers)\n      }\n    }\n\n    // 33. Let inputBody be inputs requests body if input is a Request\n    // object; otherwise null.\n    const inputBody = input instanceof Request ? input[kState].body : null\n\n    // 34. If either init[\"body\"] exists and is non-null or inputBody is\n    // non-null, and requests method is `GET` or `HEAD`, then throw a\n    // TypeError.\n    if (\n      (init.body != null || inputBody != null) &&\n      (request.method === 'GET' || request.method === 'HEAD')\n    ) {\n      throw new TypeError('Request with GET/HEAD method cannot have body.')\n    }\n\n    // 35. Let initBody be null.\n    let initBody = null\n\n    // 36. If init[\"body\"] exists and is non-null, then:\n    if (init.body != null) {\n      // 1. Let Content-Type be null.\n      // 2. Set initBody and Content-Type to the result of extracting\n      // init[\"body\"], with keepalive set to requests keepalive.\n      const [extractedBody, contentType] = extractBody(\n        init.body,\n        request.keepalive\n      )\n      initBody = extractedBody\n\n      // 3, If Content-Type is non-null and thiss headerss header list does\n      // not contain `Content-Type`, then append `Content-Type`/Content-Type to\n      // thiss headers.\n      if (contentType && !getHeadersList(this[kHeaders]).contains('content-type', true)) {\n        this[kHeaders].append('content-type', contentType)\n      }\n    }\n\n    // 37. Let inputOrInitBody be initBody if it is non-null; otherwise\n    // inputBody.\n    const inputOrInitBody = initBody ?? inputBody\n\n    // 38. If inputOrInitBody is non-null and inputOrInitBodys source is\n    // null, then:\n    if (inputOrInitBody != null && inputOrInitBody.source == null) {\n      // 1. If initBody is non-null and init[\"duplex\"] does not exist,\n      //    then throw a TypeError.\n      if (initBody != null && init.duplex == null) {\n        throw new TypeError('RequestInit: duplex option is required when sending a body.')\n      }\n\n      // 2. If thiss requests mode is neither \"same-origin\" nor \"cors\",\n      // then throw a TypeError.\n      if (request.mode !== 'same-origin' && request.mode !== 'cors') {\n        throw new TypeError(\n          'If request is made from ReadableStream, mode should be \"same-origin\" or \"cors\"'\n        )\n      }\n\n      // 3. Set thiss requests use-CORS-preflight flag.\n      request.useCORSPreflightFlag = true\n    }\n\n    // 39. Let finalBody be inputOrInitBody.\n    let finalBody = inputOrInitBody\n\n    // 40. If initBody is null and inputBody is non-null, then:\n    if (initBody == null && inputBody != null) {\n      // 1. If input is unusable, then throw a TypeError.\n      if (bodyUnusable(input)) {\n        throw new TypeError(\n          'Cannot construct a Request with a Request object that has already been used.'\n        )\n      }\n\n      // 2. Set finalBody to the result of creating a proxy for inputBody.\n      // https://streams.spec.whatwg.org/#readablestream-create-a-proxy\n      const identityTransform = new TransformStream()\n      inputBody.stream.pipeThrough(identityTransform)\n      finalBody = {\n        source: inputBody.source,\n        length: inputBody.length,\n        stream: identityTransform.readable\n      }\n    }\n\n    // 41. Set thiss requests body to finalBody.\n    this[kState].body = finalBody\n  }\n\n  // Returns requests HTTP method, which is \"GET\" by default.\n  get method () {\n    webidl.brandCheck(this, Request)\n\n    // The method getter steps are to return thiss requests method.\n    return this[kState].method\n  }\n\n  // Returns the URL of request as a string.\n  get url () {\n    webidl.brandCheck(this, Request)\n\n    // The url getter steps are to return thiss requests URL, serialized.\n    return URLSerializer(this[kState].url)\n  }\n\n  // Returns a Headers object consisting of the headers associated with request.\n  // Note that headers added in the network layer by the user agent will not\n  // be accounted for in this object, e.g., the \"Host\" header.\n  get headers () {\n    webidl.brandCheck(this, Request)\n\n    // The headers getter steps are to return thiss headers.\n    return this[kHeaders]\n  }\n\n  // Returns the kind of resource requested by request, e.g., \"document\"\n  // or \"script\".\n  get destination () {\n    webidl.brandCheck(this, Request)\n\n    // The destination getter are to return thiss requests destination.\n    return this[kState].destination\n  }\n\n  // Returns the referrer of request. Its value can be a same-origin URL if\n  // explicitly set in init, the empty string to indicate no referrer, and\n  // \"about:client\" when defaulting to the globals default. This is used\n  // during fetching to determine the value of the `Referer` header of the\n  // request being made.\n  get referrer () {\n    webidl.brandCheck(this, Request)\n\n    // 1. If thiss requests referrer is \"no-referrer\", then return the\n    // empty string.\n    if (this[kState].referrer === 'no-referrer') {\n      return ''\n    }\n\n    // 2. If thiss requests referrer is \"client\", then return\n    // \"about:client\".\n    if (this[kState].referrer === 'client') {\n      return 'about:client'\n    }\n\n    // Return thiss requests referrer, serialized.\n    return this[kState].referrer.toString()\n  }\n\n  // Returns the referrer policy associated with request.\n  // This is used during fetching to compute the value of the requests\n  // referrer.\n  get referrerPolicy () {\n    webidl.brandCheck(this, Request)\n\n    // The referrerPolicy getter steps are to return thiss requests referrer policy.\n    return this[kState].referrerPolicy\n  }\n\n  // Returns the mode associated with request, which is a string indicating\n  // whether the request will use CORS, or will be restricted to same-origin\n  // URLs.\n  get mode () {\n    webidl.brandCheck(this, Request)\n\n    // The mode getter steps are to return thiss requests mode.\n    return this[kState].mode\n  }\n\n  // Returns the credentials mode associated with request,\n  // which is a string indicating whether credentials will be sent with the\n  // request always, never, or only when sent to a same-origin URL.\n  get credentials () {\n    // The credentials getter steps are to return thiss requests credentials mode.\n    return this[kState].credentials\n  }\n\n  // Returns the cache mode associated with request,\n  // which is a string indicating how the request will\n  // interact with the browsers cache when fetching.\n  get cache () {\n    webidl.brandCheck(this, Request)\n\n    // The cache getter steps are to return thiss requests cache mode.\n    return this[kState].cache\n  }\n\n  // Returns the redirect mode associated with request,\n  // which is a string indicating how redirects for the\n  // request will be handled during fetching. A request\n  // will follow redirects by default.\n  get redirect () {\n    webidl.brandCheck(this, Request)\n\n    // The redirect getter steps are to return thiss requests redirect mode.\n    return this[kState].redirect\n  }\n\n  // Returns requests subresource integrity metadata, which is a\n  // cryptographic hash of the resource being fetched. Its value\n  // consists of multiple hashes separated by whitespace. [SRI]\n  get integrity () {\n    webidl.brandCheck(this, Request)\n\n    // The integrity getter steps are to return thiss requests integrity\n    // metadata.\n    return this[kState].integrity\n  }\n\n  // Returns a boolean indicating whether or not request can outlive the\n  // global in which it was created.\n  get keepalive () {\n    webidl.brandCheck(this, Request)\n\n    // The keepalive getter steps are to return thiss requests keepalive.\n    return this[kState].keepalive\n  }\n\n  // Returns a boolean indicating whether or not request is for a reload\n  // navigation.\n  get isReloadNavigation () {\n    webidl.brandCheck(this, Request)\n\n    // The isReloadNavigation getter steps are to return true if thiss\n    // requests reload-navigation flag is set; otherwise false.\n    return this[kState].reloadNavigation\n  }\n\n  // Returns a boolean indicating whether or not request is for a history\n  // navigation (a.k.a. back-forward navigation).\n  get isHistoryNavigation () {\n    webidl.brandCheck(this, Request)\n\n    // The isHistoryNavigation getter steps are to return true if thiss requests\n    // history-navigation flag is set; otherwise false.\n    return this[kState].historyNavigation\n  }\n\n  // Returns the signal associated with request, which is an AbortSignal\n  // object indicating whether or not request has been aborted, and its\n  // abort event handler.\n  get signal () {\n    webidl.brandCheck(this, Request)\n\n    // The signal getter steps are to return thiss signal.\n    return this[kSignal]\n  }\n\n  get body () {\n    webidl.brandCheck(this, Request)\n\n    return this[kState].body ? this[kState].body.stream : null\n  }\n\n  get bodyUsed () {\n    webidl.brandCheck(this, Request)\n\n    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)\n  }\n\n  get duplex () {\n    webidl.brandCheck(this, Request)\n\n    return 'half'\n  }\n\n  // Returns a clone of request.\n  clone () {\n    webidl.brandCheck(this, Request)\n\n    // 1. If this is unusable, then throw a TypeError.\n    if (bodyUnusable(this)) {\n      throw new TypeError('unusable')\n    }\n\n    // 2. Let clonedRequest be the result of cloning thiss request.\n    const clonedRequest = cloneRequest(this[kState])\n\n    // 3. Let clonedRequestObject be the result of creating a Request object,\n    // given clonedRequest, thiss headerss guard, and thiss relevant Realm.\n    // 4. Make clonedRequestObjects signal follow thiss signal.\n    const ac = new AbortController()\n    if (this.signal.aborted) {\n      ac.abort(this.signal.reason)\n    } else {\n      let list = dependentControllerMap.get(this.signal)\n      if (list === undefined) {\n        list = new Set()\n        dependentControllerMap.set(this.signal, list)\n      }\n      const acRef = new WeakRef(ac)\n      list.add(acRef)\n      util.addAbortListener(\n        ac.signal,\n        buildAbort(acRef)\n      )\n    }\n\n    // 4. Return clonedRequestObject.\n    return fromInnerRequest(clonedRequest, ac.signal, getHeadersGuard(this[kHeaders]))\n  }\n\n  [nodeUtil.inspect.custom] (depth, options) {\n    if (options.depth === null) {\n      options.depth = 2\n    }\n\n    options.colors ??= true\n\n    const properties = {\n      method: this.method,\n      url: this.url,\n      headers: this.headers,\n      destination: this.destination,\n      referrer: this.referrer,\n      referrerPolicy: this.referrerPolicy,\n      mode: this.mode,\n      credentials: this.credentials,\n      cache: this.cache,\n      redirect: this.redirect,\n      integrity: this.integrity,\n      keepalive: this.keepalive,\n      isReloadNavigation: this.isReloadNavigation,\n      isHistoryNavigation: this.isHistoryNavigation,\n      signal: this.signal\n    }\n\n    return `Request ${nodeUtil.formatWithOptions(options, properties)}`\n  }\n}\n\nmixinBody(Request)\n\n// https://fetch.spec.whatwg.org/#requests\nfunction makeRequest (init) {\n  return {\n    method: init.method ?? 'GET',\n    localURLsOnly: init.localURLsOnly ?? false,\n    unsafeRequest: init.unsafeRequest ?? false,\n    body: init.body ?? null,\n    client: init.client ?? null,\n    reservedClient: init.reservedClient ?? null,\n    replacesClientId: init.replacesClientId ?? '',\n    window: init.window ?? 'client',\n    keepalive: init.keepalive ?? false,\n    serviceWorkers: init.serviceWorkers ?? 'all',\n    initiator: init.initiator ?? '',\n    destination: init.destination ?? '',\n    priority: init.priority ?? null,\n    origin: init.origin ?? 'client',\n    policyContainer: init.policyContainer ?? 'client',\n    referrer: init.referrer ?? 'client',\n    referrerPolicy: init.referrerPolicy ?? '',\n    mode: init.mode ?? 'no-cors',\n    useCORSPreflightFlag: init.useCORSPreflightFlag ?? false,\n    credentials: init.credentials ?? 'same-origin',\n    useCredentials: init.useCredentials ?? false,\n    cache: init.cache ?? 'default',\n    redirect: init.redirect ?? 'follow',\n    integrity: init.integrity ?? '',\n    cryptoGraphicsNonceMetadata: init.cryptoGraphicsNonceMetadata ?? '',\n    parserMetadata: init.parserMetadata ?? '',\n    reloadNavigation: init.reloadNavigation ?? false,\n    historyNavigation: init.historyNavigation ?? false,\n    userActivation: init.userActivation ?? false,\n    taintedOrigin: init.taintedOrigin ?? false,\n    redirectCount: init.redirectCount ?? 0,\n    responseTainting: init.responseTainting ?? 'basic',\n    preventNoCacheCacheControlHeaderModification: init.preventNoCacheCacheControlHeaderModification ?? false,\n    done: init.done ?? false,\n    timingAllowFailed: init.timingAllowFailed ?? false,\n    urlList: init.urlList,\n    url: init.urlList[0],\n    headersList: init.headersList\n      ? new HeadersList(init.headersList)\n      : new HeadersList()\n  }\n}\n\n// https://fetch.spec.whatwg.org/#concept-request-clone\nfunction cloneRequest (request) {\n  // To clone a request request, run these steps:\n\n  // 1. Let newRequest be a copy of request, except for its body.\n  const newRequest = makeRequest({ ...request, body: null })\n\n  // 2. If requests body is non-null, set newRequests body to the\n  // result of cloning requests body.\n  if (request.body != null) {\n    newRequest.body = cloneBody(newRequest, request.body)\n  }\n\n  // 3. Return newRequest.\n  return newRequest\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#request-create\n * @param {any} innerRequest\n * @param {AbortSignal} signal\n * @param {'request' | 'immutable' | 'request-no-cors' | 'response' | 'none'} guard\n * @returns {Request}\n */\nfunction fromInnerRequest (innerRequest, signal, guard) {\n  const request = new Request(kConstruct)\n  request[kState] = innerRequest\n  request[kSignal] = signal\n  request[kHeaders] = new Headers(kConstruct)\n  setHeadersList(request[kHeaders], innerRequest.headersList)\n  setHeadersGuard(request[kHeaders], guard)\n  return request\n}\n\nObject.defineProperties(Request.prototype, {\n  method: kEnumerableProperty,\n  url: kEnumerableProperty,\n  headers: kEnumerableProperty,\n  redirect: kEnumerableProperty,\n  clone: kEnumerableProperty,\n  signal: kEnumerableProperty,\n  duplex: kEnumerableProperty,\n  destination: kEnumerableProperty,\n  body: kEnumerableProperty,\n  bodyUsed: kEnumerableProperty,\n  isHistoryNavigation: kEnumerableProperty,\n  isReloadNavigation: kEnumerableProperty,\n  keepalive: kEnumerableProperty,\n  integrity: kEnumerableProperty,\n  cache: kEnumerableProperty,\n  credentials: kEnumerableProperty,\n  attribute: kEnumerableProperty,\n  referrerPolicy: kEnumerableProperty,\n  referrer: kEnumerableProperty,\n  mode: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'Request',\n    configurable: true\n  }\n})\n\nwebidl.converters.Request = webidl.interfaceConverter(\n  Request\n)\n\n// https://fetch.spec.whatwg.org/#requestinfo\nwebidl.converters.RequestInfo = function (V, prefix, argument) {\n  if (typeof V === 'string') {\n    return webidl.converters.USVString(V, prefix, argument)\n  }\n\n  if (V instanceof Request) {\n    return webidl.converters.Request(V, prefix, argument)\n  }\n\n  return webidl.converters.USVString(V, prefix, argument)\n}\n\nwebidl.converters.AbortSignal = webidl.interfaceConverter(\n  AbortSignal\n)\n\n// https://fetch.spec.whatwg.org/#requestinit\nwebidl.converters.RequestInit = webidl.dictionaryConverter([\n  {\n    key: 'method',\n    converter: webidl.converters.ByteString\n  },\n  {\n    key: 'headers',\n    converter: webidl.converters.HeadersInit\n  },\n  {\n    key: 'body',\n    converter: webidl.nullableConverter(\n      webidl.converters.BodyInit\n    )\n  },\n  {\n    key: 'referrer',\n    converter: webidl.converters.USVString\n  },\n  {\n    key: 'referrerPolicy',\n    converter: webidl.converters.DOMString,\n    // https://w3c.github.io/webappsec-referrer-policy/#referrer-policy\n    allowedValues: referrerPolicy\n  },\n  {\n    key: 'mode',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#concept-request-mode\n    allowedValues: requestMode\n  },\n  {\n    key: 'credentials',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestcredentials\n    allowedValues: requestCredentials\n  },\n  {\n    key: 'cache',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestcache\n    allowedValues: requestCache\n  },\n  {\n    key: 'redirect',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestredirect\n    allowedValues: requestRedirect\n  },\n  {\n    key: 'integrity',\n    converter: webidl.converters.DOMString\n  },\n  {\n    key: 'keepalive',\n    converter: webidl.converters.boolean\n  },\n  {\n    key: 'signal',\n    converter: webidl.nullableConverter(\n      (signal) => webidl.converters.AbortSignal(\n        signal,\n        'RequestInit',\n        'signal',\n        { strict: false }\n      )\n    )\n  },\n  {\n    key: 'window',\n    converter: webidl.converters.any\n  },\n  {\n    key: 'duplex',\n    converter: webidl.converters.DOMString,\n    allowedValues: requestDuplex\n  },\n  {\n    key: 'dispatcher', // undici specific option\n    converter: webidl.converters.any\n  }\n])\n\nmodule.exports = { Request, makeRequest, fromInnerRequest, cloneRequest }\n","'use strict'\n\nconst { Headers, HeadersList, fill, getHeadersGuard, setHeadersGuard, setHeadersList } = require('./headers')\nconst { extractBody, cloneBody, mixinBody, hasFinalizationRegistry, streamRegistry, bodyUnusable } = require('./body')\nconst util = require('../../core/util')\nconst nodeUtil = require('node:util')\nconst { kEnumerableProperty } = util\nconst {\n  isValidReasonPhrase,\n  isCancelled,\n  isAborted,\n  isBlobLike,\n  serializeJavascriptValueToJSONString,\n  isErrorLike,\n  isomorphicEncode,\n  environmentSettingsObject: relevantRealm\n} = require('./util')\nconst {\n  redirectStatusSet,\n  nullBodyStatus\n} = require('./constants')\nconst { kState, kHeaders } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { FormData } = require('./formdata')\nconst { URLSerializer } = require('./data-url')\nconst { kConstruct } = require('../../core/symbols')\nconst assert = require('node:assert')\nconst { types } = require('node:util')\n\nconst textEncoder = new TextEncoder('utf-8')\n\n// https://fetch.spec.whatwg.org/#response-class\nclass Response {\n  // Creates network error Response.\n  static error () {\n    // The static error() method steps are to return the result of creating a\n    // Response object, given a new network error, \"immutable\", and thiss\n    // relevant Realm.\n    const responseObject = fromInnerResponse(makeNetworkError(), 'immutable')\n\n    return responseObject\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-response-json\n  static json (data, init = {}) {\n    webidl.argumentLengthCheck(arguments, 1, 'Response.json')\n\n    if (init !== null) {\n      init = webidl.converters.ResponseInit(init)\n    }\n\n    // 1. Let bytes the result of running serialize a JavaScript value to JSON bytes on data.\n    const bytes = textEncoder.encode(\n      serializeJavascriptValueToJSONString(data)\n    )\n\n    // 2. Let body be the result of extracting bytes.\n    const body = extractBody(bytes)\n\n    // 3. Let responseObject be the result of creating a Response object, given a new response,\n    //    \"response\", and thiss relevant Realm.\n    const responseObject = fromInnerResponse(makeResponse({}), 'response')\n\n    // 4. Perform initialize a response given responseObject, init, and (body, \"application/json\").\n    initializeResponse(responseObject, init, { body: body[0], type: 'application/json' })\n\n    // 5. Return responseObject.\n    return responseObject\n  }\n\n  // Creates a redirect Response that redirects to url with status status.\n  static redirect (url, status = 302) {\n    webidl.argumentLengthCheck(arguments, 1, 'Response.redirect')\n\n    url = webidl.converters.USVString(url)\n    status = webidl.converters['unsigned short'](status)\n\n    // 1. Let parsedURL be the result of parsing url with current settings\n    // objects API base URL.\n    // 2. If parsedURL is failure, then throw a TypeError.\n    // TODO: base-URL?\n    let parsedURL\n    try {\n      parsedURL = new URL(url, relevantRealm.settingsObject.baseUrl)\n    } catch (err) {\n      throw new TypeError(`Failed to parse URL from ${url}`, { cause: err })\n    }\n\n    // 3. If status is not a redirect status, then throw a RangeError.\n    if (!redirectStatusSet.has(status)) {\n      throw new RangeError(`Invalid status code ${status}`)\n    }\n\n    // 4. Let responseObject be the result of creating a Response object,\n    // given a new response, \"immutable\", and thiss relevant Realm.\n    const responseObject = fromInnerResponse(makeResponse({}), 'immutable')\n\n    // 5. Set responseObjects responses status to status.\n    responseObject[kState].status = status\n\n    // 6. Let value be parsedURL, serialized and isomorphic encoded.\n    const value = isomorphicEncode(URLSerializer(parsedURL))\n\n    // 7. Append `Location`/value to responseObjects responses header list.\n    responseObject[kState].headersList.append('location', value, true)\n\n    // 8. Return responseObject.\n    return responseObject\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-response\n  constructor (body = null, init = {}) {\n    webidl.util.markAsUncloneable(this)\n    if (body === kConstruct) {\n      return\n    }\n\n    if (body !== null) {\n      body = webidl.converters.BodyInit(body)\n    }\n\n    init = webidl.converters.ResponseInit(init)\n\n    // 1. Set thiss response to a new response.\n    this[kState] = makeResponse({})\n\n    // 2. Set thiss headers to a new Headers object with thiss relevant\n    // Realm, whose header list is thiss responses header list and guard\n    // is \"response\".\n    this[kHeaders] = new Headers(kConstruct)\n    setHeadersGuard(this[kHeaders], 'response')\n    setHeadersList(this[kHeaders], this[kState].headersList)\n\n    // 3. Let bodyWithType be null.\n    let bodyWithType = null\n\n    // 4. If body is non-null, then set bodyWithType to the result of extracting body.\n    if (body != null) {\n      const [extractedBody, type] = extractBody(body)\n      bodyWithType = { body: extractedBody, type }\n    }\n\n    // 5. Perform initialize a response given this, init, and bodyWithType.\n    initializeResponse(this, init, bodyWithType)\n  }\n\n  // Returns responses type, e.g., \"cors\".\n  get type () {\n    webidl.brandCheck(this, Response)\n\n    // The type getter steps are to return thiss responses type.\n    return this[kState].type\n  }\n\n  // Returns responses URL, if it has one; otherwise the empty string.\n  get url () {\n    webidl.brandCheck(this, Response)\n\n    const urlList = this[kState].urlList\n\n    // The url getter steps are to return the empty string if thiss\n    // responses URL is null; otherwise thiss responses URL,\n    // serialized with exclude fragment set to true.\n    const url = urlList[urlList.length - 1] ?? null\n\n    if (url === null) {\n      return ''\n    }\n\n    return URLSerializer(url, true)\n  }\n\n  // Returns whether response was obtained through a redirect.\n  get redirected () {\n    webidl.brandCheck(this, Response)\n\n    // The redirected getter steps are to return true if thiss responses URL\n    // list has more than one item; otherwise false.\n    return this[kState].urlList.length > 1\n  }\n\n  // Returns responses status.\n  get status () {\n    webidl.brandCheck(this, Response)\n\n    // The status getter steps are to return thiss responses status.\n    return this[kState].status\n  }\n\n  // Returns whether responses status is an ok status.\n  get ok () {\n    webidl.brandCheck(this, Response)\n\n    // The ok getter steps are to return true if thiss responses status is an\n    // ok status; otherwise false.\n    return this[kState].status >= 200 && this[kState].status <= 299\n  }\n\n  // Returns responses status message.\n  get statusText () {\n    webidl.brandCheck(this, Response)\n\n    // The statusText getter steps are to return thiss responses status\n    // message.\n    return this[kState].statusText\n  }\n\n  // Returns responses headers as Headers.\n  get headers () {\n    webidl.brandCheck(this, Response)\n\n    // The headers getter steps are to return thiss headers.\n    return this[kHeaders]\n  }\n\n  get body () {\n    webidl.brandCheck(this, Response)\n\n    return this[kState].body ? this[kState].body.stream : null\n  }\n\n  get bodyUsed () {\n    webidl.brandCheck(this, Response)\n\n    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)\n  }\n\n  // Returns a clone of response.\n  clone () {\n    webidl.brandCheck(this, Response)\n\n    // 1. If this is unusable, then throw a TypeError.\n    if (bodyUnusable(this)) {\n      throw webidl.errors.exception({\n        header: 'Response.clone',\n        message: 'Body has already been consumed.'\n      })\n    }\n\n    // 2. Let clonedResponse be the result of cloning thiss response.\n    const clonedResponse = cloneResponse(this[kState])\n\n    // Note: To re-register because of a new stream.\n    if (hasFinalizationRegistry && this[kState].body?.stream) {\n      streamRegistry.register(this, new WeakRef(this[kState].body.stream))\n    }\n\n    // 3. Return the result of creating a Response object, given\n    // clonedResponse, thiss headerss guard, and thiss relevant Realm.\n    return fromInnerResponse(clonedResponse, getHeadersGuard(this[kHeaders]))\n  }\n\n  [nodeUtil.inspect.custom] (depth, options) {\n    if (options.depth === null) {\n      options.depth = 2\n    }\n\n    options.colors ??= true\n\n    const properties = {\n      status: this.status,\n      statusText: this.statusText,\n      headers: this.headers,\n      body: this.body,\n      bodyUsed: this.bodyUsed,\n      ok: this.ok,\n      redirected: this.redirected,\n      type: this.type,\n      url: this.url\n    }\n\n    return `Response ${nodeUtil.formatWithOptions(options, properties)}`\n  }\n}\n\nmixinBody(Response)\n\nObject.defineProperties(Response.prototype, {\n  type: kEnumerableProperty,\n  url: kEnumerableProperty,\n  status: kEnumerableProperty,\n  ok: kEnumerableProperty,\n  redirected: kEnumerableProperty,\n  statusText: kEnumerableProperty,\n  headers: kEnumerableProperty,\n  clone: kEnumerableProperty,\n  body: kEnumerableProperty,\n  bodyUsed: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'Response',\n    configurable: true\n  }\n})\n\nObject.defineProperties(Response, {\n  json: kEnumerableProperty,\n  redirect: kEnumerableProperty,\n  error: kEnumerableProperty\n})\n\n// https://fetch.spec.whatwg.org/#concept-response-clone\nfunction cloneResponse (response) {\n  // To clone a response response, run these steps:\n\n  // 1. If response is a filtered response, then return a new identical\n  // filtered response whose internal response is a clone of responses\n  // internal response.\n  if (response.internalResponse) {\n    return filterResponse(\n      cloneResponse(response.internalResponse),\n      response.type\n    )\n  }\n\n  // 2. Let newResponse be a copy of response, except for its body.\n  const newResponse = makeResponse({ ...response, body: null })\n\n  // 3. If responses body is non-null, then set newResponses body to the\n  // result of cloning responses body.\n  if (response.body != null) {\n    newResponse.body = cloneBody(newResponse, response.body)\n  }\n\n  // 4. Return newResponse.\n  return newResponse\n}\n\nfunction makeResponse (init) {\n  return {\n    aborted: false,\n    rangeRequested: false,\n    timingAllowPassed: false,\n    requestIncludesCredentials: false,\n    type: 'default',\n    status: 200,\n    timingInfo: null,\n    cacheState: '',\n    statusText: '',\n    ...init,\n    headersList: init?.headersList\n      ? new HeadersList(init?.headersList)\n      : new HeadersList(),\n    urlList: init?.urlList ? [...init.urlList] : []\n  }\n}\n\nfunction makeNetworkError (reason) {\n  const isError = isErrorLike(reason)\n  return makeResponse({\n    type: 'error',\n    status: 0,\n    error: isError\n      ? reason\n      : new Error(reason ? String(reason) : reason),\n    aborted: reason && reason.name === 'AbortError'\n  })\n}\n\n// @see https://fetch.spec.whatwg.org/#concept-network-error\nfunction isNetworkError (response) {\n  return (\n    // A network error is a response whose type is \"error\",\n    response.type === 'error' &&\n    // status is 0\n    response.status === 0\n  )\n}\n\nfunction makeFilteredResponse (response, state) {\n  state = {\n    internalResponse: response,\n    ...state\n  }\n\n  return new Proxy(response, {\n    get (target, p) {\n      return p in state ? state[p] : target[p]\n    },\n    set (target, p, value) {\n      assert(!(p in state))\n      target[p] = value\n      return true\n    }\n  })\n}\n\n// https://fetch.spec.whatwg.org/#concept-filtered-response\nfunction filterResponse (response, type) {\n  // Set response to the following filtered response with response as its\n  // internal response, depending on requests response tainting:\n  if (type === 'basic') {\n    // A basic filtered response is a filtered response whose type is \"basic\"\n    // and header list excludes any headers in internal responses header list\n    // whose name is a forbidden response-header name.\n\n    // Note: undici does not implement forbidden response-header names\n    return makeFilteredResponse(response, {\n      type: 'basic',\n      headersList: response.headersList\n    })\n  } else if (type === 'cors') {\n    // A CORS filtered response is a filtered response whose type is \"cors\"\n    // and header list excludes any headers in internal responses header\n    // list whose name is not a CORS-safelisted response-header name, given\n    // internal responses CORS-exposed header-name list.\n\n    // Note: undici does not implement CORS-safelisted response-header names\n    return makeFilteredResponse(response, {\n      type: 'cors',\n      headersList: response.headersList\n    })\n  } else if (type === 'opaque') {\n    // An opaque filtered response is a filtered response whose type is\n    // \"opaque\", URL list is the empty list, status is 0, status message\n    // is the empty byte sequence, header list is empty, and body is null.\n\n    return makeFilteredResponse(response, {\n      type: 'opaque',\n      urlList: Object.freeze([]),\n      status: 0,\n      statusText: '',\n      body: null\n    })\n  } else if (type === 'opaqueredirect') {\n    // An opaque-redirect filtered response is a filtered response whose type\n    // is \"opaqueredirect\", status is 0, status message is the empty byte\n    // sequence, header list is empty, and body is null.\n\n    return makeFilteredResponse(response, {\n      type: 'opaqueredirect',\n      status: 0,\n      statusText: '',\n      headersList: [],\n      body: null\n    })\n  } else {\n    assert(false)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#appropriate-network-error\nfunction makeAppropriateNetworkError (fetchParams, err = null) {\n  // 1. Assert: fetchParams is canceled.\n  assert(isCancelled(fetchParams))\n\n  // 2. Return an aborted network error if fetchParams is aborted;\n  // otherwise return a network error.\n  return isAborted(fetchParams)\n    ? makeNetworkError(Object.assign(new DOMException('The operation was aborted.', 'AbortError'), { cause: err }))\n    : makeNetworkError(Object.assign(new DOMException('Request was cancelled.'), { cause: err }))\n}\n\n// https://whatpr.org/fetch/1392.html#initialize-a-response\nfunction initializeResponse (response, init, body) {\n  // 1. If init[\"status\"] is not in the range 200 to 599, inclusive, then\n  //    throw a RangeError.\n  if (init.status !== null && (init.status < 200 || init.status > 599)) {\n    throw new RangeError('init[\"status\"] must be in the range of 200 to 599, inclusive.')\n  }\n\n  // 2. If init[\"statusText\"] does not match the reason-phrase token production,\n  //    then throw a TypeError.\n  if ('statusText' in init && init.statusText != null) {\n    // See, https://datatracker.ietf.org/doc/html/rfc7230#section-3.1.2:\n    //   reason-phrase  = *( HTAB / SP / VCHAR / obs-text )\n    if (!isValidReasonPhrase(String(init.statusText))) {\n      throw new TypeError('Invalid statusText')\n    }\n  }\n\n  // 3. Set responses responses status to init[\"status\"].\n  if ('status' in init && init.status != null) {\n    response[kState].status = init.status\n  }\n\n  // 4. Set responses responses status message to init[\"statusText\"].\n  if ('statusText' in init && init.statusText != null) {\n    response[kState].statusText = init.statusText\n  }\n\n  // 5. If init[\"headers\"] exists, then fill responses headers with init[\"headers\"].\n  if ('headers' in init && init.headers != null) {\n    fill(response[kHeaders], init.headers)\n  }\n\n  // 6. If body was given, then:\n  if (body) {\n    // 1. If response's status is a null body status, then throw a TypeError.\n    if (nullBodyStatus.includes(response.status)) {\n      throw webidl.errors.exception({\n        header: 'Response constructor',\n        message: `Invalid response status code ${response.status}`\n      })\n    }\n\n    // 2. Set response's body to body's body.\n    response[kState].body = body.body\n\n    // 3. If body's type is non-null and response's header list does not contain\n    //    `Content-Type`, then append (`Content-Type`, body's type) to response's header list.\n    if (body.type != null && !response[kState].headersList.contains('content-type', true)) {\n      response[kState].headersList.append('content-type', body.type, true)\n    }\n  }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#response-create\n * @param {any} innerResponse\n * @param {'request' | 'immutable' | 'request-no-cors' | 'response' | 'none'} guard\n * @returns {Response}\n */\nfunction fromInnerResponse (innerResponse, guard) {\n  const response = new Response(kConstruct)\n  response[kState] = innerResponse\n  response[kHeaders] = new Headers(kConstruct)\n  setHeadersList(response[kHeaders], innerResponse.headersList)\n  setHeadersGuard(response[kHeaders], guard)\n\n  if (hasFinalizationRegistry && innerResponse.body?.stream) {\n    // If the target (response) is reclaimed, the cleanup callback may be called at some point with\n    // the held value provided for it (innerResponse.body.stream). The held value can be any value:\n    // a primitive or an object, even undefined. If the held value is an object, the registry keeps\n    // a strong reference to it (so it can pass it to the cleanup callback later). Reworded from\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/FinalizationRegistry\n    streamRegistry.register(response, new WeakRef(innerResponse.body.stream))\n  }\n\n  return response\n}\n\nwebidl.converters.ReadableStream = webidl.interfaceConverter(\n  ReadableStream\n)\n\nwebidl.converters.FormData = webidl.interfaceConverter(\n  FormData\n)\n\nwebidl.converters.URLSearchParams = webidl.interfaceConverter(\n  URLSearchParams\n)\n\n// https://fetch.spec.whatwg.org/#typedefdef-xmlhttprequestbodyinit\nwebidl.converters.XMLHttpRequestBodyInit = function (V, prefix, name) {\n  if (typeof V === 'string') {\n    return webidl.converters.USVString(V, prefix, name)\n  }\n\n  if (isBlobLike(V)) {\n    return webidl.converters.Blob(V, prefix, name, { strict: false })\n  }\n\n  if (ArrayBuffer.isView(V) || types.isArrayBuffer(V)) {\n    return webidl.converters.BufferSource(V, prefix, name)\n  }\n\n  if (util.isFormDataLike(V)) {\n    return webidl.converters.FormData(V, prefix, name, { strict: false })\n  }\n\n  if (V instanceof URLSearchParams) {\n    return webidl.converters.URLSearchParams(V, prefix, name)\n  }\n\n  return webidl.converters.DOMString(V, prefix, name)\n}\n\n// https://fetch.spec.whatwg.org/#bodyinit\nwebidl.converters.BodyInit = function (V, prefix, argument) {\n  if (V instanceof ReadableStream) {\n    return webidl.converters.ReadableStream(V, prefix, argument)\n  }\n\n  // Note: the spec doesn't include async iterables,\n  // this is an undici extension.\n  if (V?.[Symbol.asyncIterator]) {\n    return V\n  }\n\n  return webidl.converters.XMLHttpRequestBodyInit(V, prefix, argument)\n}\n\nwebidl.converters.ResponseInit = webidl.dictionaryConverter([\n  {\n    key: 'status',\n    converter: webidl.converters['unsigned short'],\n    defaultValue: () => 200\n  },\n  {\n    key: 'statusText',\n    converter: webidl.converters.ByteString,\n    defaultValue: () => ''\n  },\n  {\n    key: 'headers',\n    converter: webidl.converters.HeadersInit\n  }\n])\n\nmodule.exports = {\n  isNetworkError,\n  makeNetworkError,\n  makeResponse,\n  makeAppropriateNetworkError,\n  filterResponse,\n  Response,\n  cloneResponse,\n  fromInnerResponse\n}\n","'use strict'\n\nmodule.exports = {\n  kUrl: Symbol('url'),\n  kHeaders: Symbol('headers'),\n  kSignal: Symbol('signal'),\n  kState: Symbol('state'),\n  kDispatcher: Symbol('dispatcher')\n}\n","'use strict'\n\nconst { Transform } = require('node:stream')\nconst zlib = require('node:zlib')\nconst { redirectStatusSet, referrerPolicySet: referrerPolicyTokens, badPortsSet } = require('./constants')\nconst { getGlobalOrigin } = require('./global')\nconst { collectASequenceOfCodePoints, collectAnHTTPQuotedString, removeChars, parseMIMEType } = require('./data-url')\nconst { performance } = require('node:perf_hooks')\nconst { isBlobLike, ReadableStreamFrom, isValidHTTPToken, normalizedMethodRecordsBase } = require('../../core/util')\nconst assert = require('node:assert')\nconst { isUint8Array } = require('node:util/types')\nconst { webidl } = require('./webidl')\n\nlet supportedHashes = []\n\n// https://nodejs.org/api/crypto.html#determining-if-crypto-support-is-unavailable\n/** @type {import('crypto')} */\nlet crypto\ntry {\n  crypto = require('node:crypto')\n  const possibleRelevantHashes = ['sha256', 'sha384', 'sha512']\n  supportedHashes = crypto.getHashes().filter((hash) => possibleRelevantHashes.includes(hash))\n/* c8 ignore next 3 */\n} catch {\n\n}\n\nfunction responseURL (response) {\n  // https://fetch.spec.whatwg.org/#responses\n  // A response has an associated URL. It is a pointer to the last URL\n  // in responses URL list and null if responses URL list is empty.\n  const urlList = response.urlList\n  const length = urlList.length\n  return length === 0 ? null : urlList[length - 1].toString()\n}\n\n// https://fetch.spec.whatwg.org/#concept-response-location-url\nfunction responseLocationURL (response, requestFragment) {\n  // 1. If responses status is not a redirect status, then return null.\n  if (!redirectStatusSet.has(response.status)) {\n    return null\n  }\n\n  // 2. Let location be the result of extracting header list values given\n  // `Location` and responses header list.\n  let location = response.headersList.get('location', true)\n\n  // 3. If location is a header value, then set location to the result of\n  //    parsing location with responses URL.\n  if (location !== null && isValidHeaderValue(location)) {\n    if (!isValidEncodedURL(location)) {\n      // Some websites respond location header in UTF-8 form without encoding them as ASCII\n      // and major browsers redirect them to correctly UTF-8 encoded addresses.\n      // Here, we handle that behavior in the same way.\n      location = normalizeBinaryStringToUtf8(location)\n    }\n    location = new URL(location, responseURL(response))\n  }\n\n  // 4. If location is a URL whose fragment is null, then set locations\n  // fragment to requestFragment.\n  if (location && !location.hash) {\n    location.hash = requestFragment\n  }\n\n  // 5. Return location.\n  return location\n}\n\n/**\n * @see https://www.rfc-editor.org/rfc/rfc1738#section-2.2\n * @param {string} url\n * @returns {boolean}\n */\nfunction isValidEncodedURL (url) {\n  for (let i = 0; i < url.length; ++i) {\n    const code = url.charCodeAt(i)\n\n    if (\n      code > 0x7E || // Non-US-ASCII + DEL\n      code < 0x20 // Control characters NUL - US\n    ) {\n      return false\n    }\n  }\n  return true\n}\n\n/**\n * If string contains non-ASCII characters, assumes it's UTF-8 encoded and decodes it.\n * Since UTF-8 is a superset of ASCII, this will work for ASCII strings as well.\n * @param {string} value\n * @returns {string}\n */\nfunction normalizeBinaryStringToUtf8 (value) {\n  return Buffer.from(value, 'binary').toString('utf8')\n}\n\n/** @returns {URL} */\nfunction requestCurrentURL (request) {\n  return request.urlList[request.urlList.length - 1]\n}\n\nfunction requestBadPort (request) {\n  // 1. Let url be requests current URL.\n  const url = requestCurrentURL(request)\n\n  // 2. If urls scheme is an HTTP(S) scheme and urls port is a bad port,\n  // then return blocked.\n  if (urlIsHttpHttpsScheme(url) && badPortsSet.has(url.port)) {\n    return 'blocked'\n  }\n\n  // 3. Return allowed.\n  return 'allowed'\n}\n\nfunction isErrorLike (object) {\n  return object instanceof Error || (\n    object?.constructor?.name === 'Error' ||\n    object?.constructor?.name === 'DOMException'\n  )\n}\n\n// Check whether |statusText| is a ByteString and\n// matches the Reason-Phrase token production.\n// RFC 2616: https://tools.ietf.org/html/rfc2616\n// RFC 7230: https://tools.ietf.org/html/rfc7230\n// \"reason-phrase = *( HTAB / SP / VCHAR / obs-text )\"\n// https://github.com/chromium/chromium/blob/94.0.4604.1/third_party/blink/renderer/core/fetch/response.cc#L116\nfunction isValidReasonPhrase (statusText) {\n  for (let i = 0; i < statusText.length; ++i) {\n    const c = statusText.charCodeAt(i)\n    if (\n      !(\n        (\n          c === 0x09 || // HTAB\n          (c >= 0x20 && c <= 0x7e) || // SP / VCHAR\n          (c >= 0x80 && c <= 0xff)\n        ) // obs-text\n      )\n    ) {\n      return false\n    }\n  }\n  return true\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#header-name\n * @param {string} potentialValue\n */\nconst isValidHeaderName = isValidHTTPToken\n\n/**\n * @see https://fetch.spec.whatwg.org/#header-value\n * @param {string} potentialValue\n */\nfunction isValidHeaderValue (potentialValue) {\n  // - Has no leading or trailing HTTP tab or space bytes.\n  // - Contains no 0x00 (NUL) or HTTP newline bytes.\n  return (\n    potentialValue[0] === '\\t' ||\n    potentialValue[0] === ' ' ||\n    potentialValue[potentialValue.length - 1] === '\\t' ||\n    potentialValue[potentialValue.length - 1] === ' ' ||\n    potentialValue.includes('\\n') ||\n    potentialValue.includes('\\r') ||\n    potentialValue.includes('\\0')\n  ) === false\n}\n\n// https://w3c.github.io/webappsec-referrer-policy/#set-requests-referrer-policy-on-redirect\nfunction setRequestReferrerPolicyOnRedirect (request, actualResponse) {\n  //  Given a request request and a response actualResponse, this algorithm\n  //  updates requests referrer policy according to the Referrer-Policy\n  //  header (if any) in actualResponse.\n\n  // 1. Let policy be the result of executing  8.1 Parse a referrer policy\n  // from a Referrer-Policy header on actualResponse.\n\n  // 8.1 Parse a referrer policy from a Referrer-Policy header\n  // 1. Let policy-tokens be the result of extracting header list values given `Referrer-Policy` and responses header list.\n  const { headersList } = actualResponse\n  // 2. Let policy be the empty string.\n  // 3. For each token in policy-tokens, if token is a referrer policy and token is not the empty string, then set policy to token.\n  // 4. Return policy.\n  const policyHeader = (headersList.get('referrer-policy', true) ?? '').split(',')\n\n  // Note: As the referrer-policy can contain multiple policies\n  // separated by comma, we need to loop through all of them\n  // and pick the first valid one.\n  // Ref: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy#specify_a_fallback_policy\n  let policy = ''\n  if (policyHeader.length > 0) {\n    // The right-most policy takes precedence.\n    // The left-most policy is the fallback.\n    for (let i = policyHeader.length; i !== 0; i--) {\n      const token = policyHeader[i - 1].trim()\n      if (referrerPolicyTokens.has(token)) {\n        policy = token\n        break\n      }\n    }\n  }\n\n  // 2. If policy is not the empty string, then set requests referrer policy to policy.\n  if (policy !== '') {\n    request.referrerPolicy = policy\n  }\n}\n\n// https://fetch.spec.whatwg.org/#cross-origin-resource-policy-check\nfunction crossOriginResourcePolicyCheck () {\n  // TODO\n  return 'allowed'\n}\n\n// https://fetch.spec.whatwg.org/#concept-cors-check\nfunction corsCheck () {\n  // TODO\n  return 'success'\n}\n\n// https://fetch.spec.whatwg.org/#concept-tao-check\nfunction TAOCheck () {\n  // TODO\n  return 'success'\n}\n\nfunction appendFetchMetadata (httpRequest) {\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-dest-header\n  //  TODO\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-mode-header\n\n  //  1. Assert: rs url is a potentially trustworthy URL.\n  //  TODO\n\n  //  2. Let header be a Structured Header whose value is a token.\n  let header = null\n\n  //  3. Set headers value to rs mode.\n  header = httpRequest.mode\n\n  //  4. Set a structured field value `Sec-Fetch-Mode`/header in rs header list.\n  httpRequest.headersList.set('sec-fetch-mode', header, true)\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-site-header\n  //  TODO\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-user-header\n  //  TODO\n}\n\n// https://fetch.spec.whatwg.org/#append-a-request-origin-header\nfunction appendRequestOriginHeader (request) {\n  // 1. Let serializedOrigin be the result of byte-serializing a request origin\n  //    with request.\n  // TODO: implement \"byte-serializing a request origin\"\n  let serializedOrigin = request.origin\n\n  // - \"'client' is changed to an origin during fetching.\"\n  //   This doesn't happen in undici (in most cases) because undici, by default,\n  //   has no concept of origin.\n  // - request.origin can also be set to request.client.origin (client being\n  //   an environment settings object), which is undefined without using\n  //   setGlobalOrigin.\n  if (serializedOrigin === 'client' || serializedOrigin === undefined) {\n    return\n  }\n\n  // 2. If requests response tainting is \"cors\" or requests mode is \"websocket\",\n  //    then append (`Origin`, serializedOrigin) to requests header list.\n  // 3. Otherwise, if requests method is neither `GET` nor `HEAD`, then:\n  if (request.responseTainting === 'cors' || request.mode === 'websocket') {\n    request.headersList.append('origin', serializedOrigin, true)\n  } else if (request.method !== 'GET' && request.method !== 'HEAD') {\n    // 1. Switch on requests referrer policy:\n    switch (request.referrerPolicy) {\n      case 'no-referrer':\n        // Set serializedOrigin to `null`.\n        serializedOrigin = null\n        break\n      case 'no-referrer-when-downgrade':\n      case 'strict-origin':\n      case 'strict-origin-when-cross-origin':\n        // If requests origin is a tuple origin, its scheme is \"https\", and\n        // requests current URLs scheme is not \"https\", then set\n        // serializedOrigin to `null`.\n        if (request.origin && urlHasHttpsScheme(request.origin) && !urlHasHttpsScheme(requestCurrentURL(request))) {\n          serializedOrigin = null\n        }\n        break\n      case 'same-origin':\n        // If requests origin is not same origin with requests current URLs\n        // origin, then set serializedOrigin to `null`.\n        if (!sameOrigin(request, requestCurrentURL(request))) {\n          serializedOrigin = null\n        }\n        break\n      default:\n        // Do nothing.\n    }\n\n    // 2. Append (`Origin`, serializedOrigin) to requests header list.\n    request.headersList.append('origin', serializedOrigin, true)\n  }\n}\n\n// https://w3c.github.io/hr-time/#dfn-coarsen-time\nfunction coarsenTime (timestamp, crossOriginIsolatedCapability) {\n  // TODO\n  return timestamp\n}\n\n// https://fetch.spec.whatwg.org/#clamp-and-coarsen-connection-timing-info\nfunction clampAndCoarsenConnectionTimingInfo (connectionTimingInfo, defaultStartTime, crossOriginIsolatedCapability) {\n  if (!connectionTimingInfo?.startTime || connectionTimingInfo.startTime < defaultStartTime) {\n    return {\n      domainLookupStartTime: defaultStartTime,\n      domainLookupEndTime: defaultStartTime,\n      connectionStartTime: defaultStartTime,\n      connectionEndTime: defaultStartTime,\n      secureConnectionStartTime: defaultStartTime,\n      ALPNNegotiatedProtocol: connectionTimingInfo?.ALPNNegotiatedProtocol\n    }\n  }\n\n  return {\n    domainLookupStartTime: coarsenTime(connectionTimingInfo.domainLookupStartTime, crossOriginIsolatedCapability),\n    domainLookupEndTime: coarsenTime(connectionTimingInfo.domainLookupEndTime, crossOriginIsolatedCapability),\n    connectionStartTime: coarsenTime(connectionTimingInfo.connectionStartTime, crossOriginIsolatedCapability),\n    connectionEndTime: coarsenTime(connectionTimingInfo.connectionEndTime, crossOriginIsolatedCapability),\n    secureConnectionStartTime: coarsenTime(connectionTimingInfo.secureConnectionStartTime, crossOriginIsolatedCapability),\n    ALPNNegotiatedProtocol: connectionTimingInfo.ALPNNegotiatedProtocol\n  }\n}\n\n// https://w3c.github.io/hr-time/#dfn-coarsened-shared-current-time\nfunction coarsenedSharedCurrentTime (crossOriginIsolatedCapability) {\n  return coarsenTime(performance.now(), crossOriginIsolatedCapability)\n}\n\n// https://fetch.spec.whatwg.org/#create-an-opaque-timing-info\nfunction createOpaqueTimingInfo (timingInfo) {\n  return {\n    startTime: timingInfo.startTime ?? 0,\n    redirectStartTime: 0,\n    redirectEndTime: 0,\n    postRedirectStartTime: timingInfo.startTime ?? 0,\n    finalServiceWorkerStartTime: 0,\n    finalNetworkResponseStartTime: 0,\n    finalNetworkRequestStartTime: 0,\n    endTime: 0,\n    encodedBodySize: 0,\n    decodedBodySize: 0,\n    finalConnectionTimingInfo: null\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/origin.html#policy-container\nfunction makePolicyContainer () {\n  // Note: the fetch spec doesn't make use of embedder policy or CSP list\n  return {\n    referrerPolicy: 'strict-origin-when-cross-origin'\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/origin.html#clone-a-policy-container\nfunction clonePolicyContainer (policyContainer) {\n  return {\n    referrerPolicy: policyContainer.referrerPolicy\n  }\n}\n\n// https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer\nfunction determineRequestsReferrer (request) {\n  // 1. Let policy be request's referrer policy.\n  const policy = request.referrerPolicy\n\n  // Note: policy cannot (shouldn't) be null or an empty string.\n  assert(policy)\n\n  // 2. Let environment be requests client.\n\n  let referrerSource = null\n\n  // 3. Switch on requests referrer:\n  if (request.referrer === 'client') {\n    // Note: node isn't a browser and doesn't implement document/iframes,\n    // so we bypass this step and replace it with our own.\n\n    const globalOrigin = getGlobalOrigin()\n\n    if (!globalOrigin || globalOrigin.origin === 'null') {\n      return 'no-referrer'\n    }\n\n    // note: we need to clone it as it's mutated\n    referrerSource = new URL(globalOrigin)\n  } else if (request.referrer instanceof URL) {\n    // Let referrerSource be requests referrer.\n    referrerSource = request.referrer\n  }\n\n  // 4. Let requests referrerURL be the result of stripping referrerSource for\n  //    use as a referrer.\n  let referrerURL = stripURLForReferrer(referrerSource)\n\n  // 5. Let referrerOrigin be the result of stripping referrerSource for use as\n  //    a referrer, with the origin-only flag set to true.\n  const referrerOrigin = stripURLForReferrer(referrerSource, true)\n\n  // 6. If the result of serializing referrerURL is a string whose length is\n  //    greater than 4096, set referrerURL to referrerOrigin.\n  if (referrerURL.toString().length > 4096) {\n    referrerURL = referrerOrigin\n  }\n\n  const areSameOrigin = sameOrigin(request, referrerURL)\n  const isNonPotentiallyTrustWorthy = isURLPotentiallyTrustworthy(referrerURL) &&\n    !isURLPotentiallyTrustworthy(request.url)\n\n  // 8. Execute the switch statements corresponding to the value of policy:\n  switch (policy) {\n    case 'origin': return referrerOrigin != null ? referrerOrigin : stripURLForReferrer(referrerSource, true)\n    case 'unsafe-url': return referrerURL\n    case 'same-origin':\n      return areSameOrigin ? referrerOrigin : 'no-referrer'\n    case 'origin-when-cross-origin':\n      return areSameOrigin ? referrerURL : referrerOrigin\n    case 'strict-origin-when-cross-origin': {\n      const currentURL = requestCurrentURL(request)\n\n      // 1. If the origin of referrerURL and the origin of requests current\n      //    URL are the same, then return referrerURL.\n      if (sameOrigin(referrerURL, currentURL)) {\n        return referrerURL\n      }\n\n      // 2. If referrerURL is a potentially trustworthy URL and requests\n      //    current URL is not a potentially trustworthy URL, then return no\n      //    referrer.\n      if (isURLPotentiallyTrustworthy(referrerURL) && !isURLPotentiallyTrustworthy(currentURL)) {\n        return 'no-referrer'\n      }\n\n      // 3. Return referrerOrigin.\n      return referrerOrigin\n    }\n    case 'strict-origin': // eslint-disable-line\n      /**\n         * 1. If referrerURL is a potentially trustworthy URL and\n         * requests current URL is not a potentially trustworthy URL,\n         * then return no referrer.\n         * 2. Return referrerOrigin\n        */\n    case 'no-referrer-when-downgrade': // eslint-disable-line\n      /**\n       * 1. If referrerURL is a potentially trustworthy URL and\n       * requests current URL is not a potentially trustworthy URL,\n       * then return no referrer.\n       * 2. Return referrerOrigin\n      */\n\n    default: // eslint-disable-line\n      return isNonPotentiallyTrustWorthy ? 'no-referrer' : referrerOrigin\n  }\n}\n\n/**\n * @see https://w3c.github.io/webappsec-referrer-policy/#strip-url\n * @param {URL} url\n * @param {boolean|undefined} originOnly\n */\nfunction stripURLForReferrer (url, originOnly) {\n  // 1. Assert: url is a URL.\n  assert(url instanceof URL)\n\n  url = new URL(url)\n\n  // 2. If urls scheme is a local scheme, then return no referrer.\n  if (url.protocol === 'file:' || url.protocol === 'about:' || url.protocol === 'blank:') {\n    return 'no-referrer'\n  }\n\n  // 3. Set urls username to the empty string.\n  url.username = ''\n\n  // 4. Set urls password to the empty string.\n  url.password = ''\n\n  // 5. Set urls fragment to null.\n  url.hash = ''\n\n  // 6. If the origin-only flag is true, then:\n  if (originOnly) {\n    // 1. Set urls path to  the empty string .\n    url.pathname = ''\n\n    // 2. Set urls query to null.\n    url.search = ''\n  }\n\n  // 7. Return url.\n  return url\n}\n\nfunction isURLPotentiallyTrustworthy (url) {\n  if (!(url instanceof URL)) {\n    return false\n  }\n\n  // If child of about, return true\n  if (url.href === 'about:blank' || url.href === 'about:srcdoc') {\n    return true\n  }\n\n  // If scheme is data, return true\n  if (url.protocol === 'data:') return true\n\n  // If file, return true\n  if (url.protocol === 'file:') return true\n\n  return isOriginPotentiallyTrustworthy(url.origin)\n\n  function isOriginPotentiallyTrustworthy (origin) {\n    // If origin is explicitly null, return false\n    if (origin == null || origin === 'null') return false\n\n    const originAsURL = new URL(origin)\n\n    // If secure, return true\n    if (originAsURL.protocol === 'https:' || originAsURL.protocol === 'wss:') {\n      return true\n    }\n\n    // If localhost or variants, return true\n    if (/^127(?:\\.[0-9]+){0,2}\\.[0-9]+$|^\\[(?:0*:)*?:?0*1\\]$/.test(originAsURL.hostname) ||\n     (originAsURL.hostname === 'localhost' || originAsURL.hostname.includes('localhost.')) ||\n     (originAsURL.hostname.endsWith('.localhost'))) {\n      return true\n    }\n\n    // If any other, return false\n    return false\n  }\n}\n\n/**\n * @see https://w3c.github.io/webappsec-subresource-integrity/#does-response-match-metadatalist\n * @param {Uint8Array} bytes\n * @param {string} metadataList\n */\nfunction bytesMatch (bytes, metadataList) {\n  // If node is not built with OpenSSL support, we cannot check\n  // a request's integrity, so allow it by default (the spec will\n  // allow requests if an invalid hash is given, as precedence).\n  /* istanbul ignore if: only if node is built with --without-ssl */\n  if (crypto === undefined) {\n    return true\n  }\n\n  // 1. Let parsedMetadata be the result of parsing metadataList.\n  const parsedMetadata = parseMetadata(metadataList)\n\n  // 2. If parsedMetadata is no metadata, return true.\n  if (parsedMetadata === 'no metadata') {\n    return true\n  }\n\n  // 3. If response is not eligible for integrity validation, return false.\n  // TODO\n\n  // 4. If parsedMetadata is the empty set, return true.\n  if (parsedMetadata.length === 0) {\n    return true\n  }\n\n  // 5. Let metadata be the result of getting the strongest\n  //    metadata from parsedMetadata.\n  const strongest = getStrongestMetadata(parsedMetadata)\n  const metadata = filterMetadataListByAlgorithm(parsedMetadata, strongest)\n\n  // 6. For each item in metadata:\n  for (const item of metadata) {\n    // 1. Let algorithm be the alg component of item.\n    const algorithm = item.algo\n\n    // 2. Let expectedValue be the val component of item.\n    const expectedValue = item.hash\n\n    // See https://github.com/web-platform-tests/wpt/commit/e4c5cc7a5e48093220528dfdd1c4012dc3837a0e\n    // \"be liberal with padding\". This is annoying, and it's not even in the spec.\n\n    // 3. Let actualValue be the result of applying algorithm to bytes.\n    let actualValue = crypto.createHash(algorithm).update(bytes).digest('base64')\n\n    if (actualValue[actualValue.length - 1] === '=') {\n      if (actualValue[actualValue.length - 2] === '=') {\n        actualValue = actualValue.slice(0, -2)\n      } else {\n        actualValue = actualValue.slice(0, -1)\n      }\n    }\n\n    // 4. If actualValue is a case-sensitive match for expectedValue,\n    //    return true.\n    if (compareBase64Mixed(actualValue, expectedValue)) {\n      return true\n    }\n  }\n\n  // 7. Return false.\n  return false\n}\n\n// https://w3c.github.io/webappsec-subresource-integrity/#grammardef-hash-with-options\n// https://www.w3.org/TR/CSP2/#source-list-syntax\n// https://www.rfc-editor.org/rfc/rfc5234#appendix-B.1\nconst parseHashWithOptions = /(?<algo>sha256|sha384|sha512)-((?<hash>[A-Za-z0-9+/]+|[A-Za-z0-9_-]+)={0,2}(?:\\s|$)( +[!-~]*)?)?/i\n\n/**\n * @see https://w3c.github.io/webappsec-subresource-integrity/#parse-metadata\n * @param {string} metadata\n */\nfunction parseMetadata (metadata) {\n  // 1. Let result be the empty set.\n  /** @type {{ algo: string, hash: string }[]} */\n  const result = []\n\n  // 2. Let empty be equal to true.\n  let empty = true\n\n  // 3. For each token returned by splitting metadata on spaces:\n  for (const token of metadata.split(' ')) {\n    // 1. Set empty to false.\n    empty = false\n\n    // 2. Parse token as a hash-with-options.\n    const parsedToken = parseHashWithOptions.exec(token)\n\n    // 3. If token does not parse, continue to the next token.\n    if (\n      parsedToken === null ||\n      parsedToken.groups === undefined ||\n      parsedToken.groups.algo === undefined\n    ) {\n      // Note: Chromium blocks the request at this point, but Firefox\n      // gives a warning that an invalid integrity was given. The\n      // correct behavior is to ignore these, and subsequently not\n      // check the integrity of the resource.\n      continue\n    }\n\n    // 4. Let algorithm be the hash-algo component of token.\n    const algorithm = parsedToken.groups.algo.toLowerCase()\n\n    // 5. If algorithm is a hash function recognized by the user\n    //    agent, add the parsed token to result.\n    if (supportedHashes.includes(algorithm)) {\n      result.push(parsedToken.groups)\n    }\n  }\n\n  // 4. Return no metadata if empty is true, otherwise return result.\n  if (empty === true) {\n    return 'no metadata'\n  }\n\n  return result\n}\n\n/**\n * @param {{ algo: 'sha256' | 'sha384' | 'sha512' }[]} metadataList\n */\nfunction getStrongestMetadata (metadataList) {\n  // Let algorithm be the algo component of the first item in metadataList.\n  // Can be sha256\n  let algorithm = metadataList[0].algo\n  // If the algorithm is sha512, then it is the strongest\n  // and we can return immediately\n  if (algorithm[3] === '5') {\n    return algorithm\n  }\n\n  for (let i = 1; i < metadataList.length; ++i) {\n    const metadata = metadataList[i]\n    // If the algorithm is sha512, then it is the strongest\n    // and we can break the loop immediately\n    if (metadata.algo[3] === '5') {\n      algorithm = 'sha512'\n      break\n    // If the algorithm is sha384, then a potential sha256 or sha384 is ignored\n    } else if (algorithm[3] === '3') {\n      continue\n    // algorithm is sha256, check if algorithm is sha384 and if so, set it as\n    // the strongest\n    } else if (metadata.algo[3] === '3') {\n      algorithm = 'sha384'\n    }\n  }\n  return algorithm\n}\n\nfunction filterMetadataListByAlgorithm (metadataList, algorithm) {\n  if (metadataList.length === 1) {\n    return metadataList\n  }\n\n  let pos = 0\n  for (let i = 0; i < metadataList.length; ++i) {\n    if (metadataList[i].algo === algorithm) {\n      metadataList[pos++] = metadataList[i]\n    }\n  }\n\n  metadataList.length = pos\n\n  return metadataList\n}\n\n/**\n * Compares two base64 strings, allowing for base64url\n * in the second string.\n *\n* @param {string} actualValue always base64\n * @param {string} expectedValue base64 or base64url\n * @returns {boolean}\n */\nfunction compareBase64Mixed (actualValue, expectedValue) {\n  if (actualValue.length !== expectedValue.length) {\n    return false\n  }\n  for (let i = 0; i < actualValue.length; ++i) {\n    if (actualValue[i] !== expectedValue[i]) {\n      if (\n        (actualValue[i] === '+' && expectedValue[i] === '-') ||\n        (actualValue[i] === '/' && expectedValue[i] === '_')\n      ) {\n        continue\n      }\n      return false\n    }\n  }\n\n  return true\n}\n\n// https://w3c.github.io/webappsec-upgrade-insecure-requests/#upgrade-request\nfunction tryUpgradeRequestToAPotentiallyTrustworthyURL (request) {\n  // TODO\n}\n\n/**\n * @link {https://html.spec.whatwg.org/multipage/origin.html#same-origin}\n * @param {URL} A\n * @param {URL} B\n */\nfunction sameOrigin (A, B) {\n  // 1. If A and B are the same opaque origin, then return true.\n  if (A.origin === B.origin && A.origin === 'null') {\n    return true\n  }\n\n  // 2. If A and B are both tuple origins and their schemes,\n  //    hosts, and port are identical, then return true.\n  if (A.protocol === B.protocol && A.hostname === B.hostname && A.port === B.port) {\n    return true\n  }\n\n  // 3. Return false.\n  return false\n}\n\nfunction createDeferredPromise () {\n  let res\n  let rej\n  const promise = new Promise((resolve, reject) => {\n    res = resolve\n    rej = reject\n  })\n\n  return { promise, resolve: res, reject: rej }\n}\n\nfunction isAborted (fetchParams) {\n  return fetchParams.controller.state === 'aborted'\n}\n\nfunction isCancelled (fetchParams) {\n  return fetchParams.controller.state === 'aborted' ||\n    fetchParams.controller.state === 'terminated'\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-method-normalize\n * @param {string} method\n */\nfunction normalizeMethod (method) {\n  return normalizedMethodRecordsBase[method.toLowerCase()] ?? method\n}\n\n// https://infra.spec.whatwg.org/#serialize-a-javascript-value-to-a-json-string\nfunction serializeJavascriptValueToJSONString (value) {\n  // 1. Let result be ? Call(%JSON.stringify%, undefined,  value ).\n  const result = JSON.stringify(value)\n\n  // 2. If result is undefined, then throw a TypeError.\n  if (result === undefined) {\n    throw new TypeError('Value is not JSON serializable')\n  }\n\n  // 3. Assert: result is a string.\n  assert(typeof result === 'string')\n\n  // 4. Return result.\n  return result\n}\n\n// https://tc39.es/ecma262/#sec-%25iteratorprototype%25-object\nconst esIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf([][Symbol.iterator]()))\n\n/**\n * @see https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object\n * @param {string} name name of the instance\n * @param {symbol} kInternalIterator\n * @param {string | number} [keyIndex]\n * @param {string | number} [valueIndex]\n */\nfunction createIterator (name, kInternalIterator, keyIndex = 0, valueIndex = 1) {\n  class FastIterableIterator {\n    /** @type {any} */\n    #target\n    /** @type {'key' | 'value' | 'key+value'} */\n    #kind\n    /** @type {number} */\n    #index\n\n    /**\n     * @see https://webidl.spec.whatwg.org/#dfn-default-iterator-object\n     * @param {unknown} target\n     * @param {'key' | 'value' | 'key+value'} kind\n     */\n    constructor (target, kind) {\n      this.#target = target\n      this.#kind = kind\n      this.#index = 0\n    }\n\n    next () {\n      // 1. Let interface be the interface for which the iterator prototype object exists.\n      // 2. Let thisValue be the this value.\n      // 3. Let object be ? ToObject(thisValue).\n      // 4. If object is a platform object, then perform a security\n      //    check, passing:\n      // 5. If object is not a default iterator object for interface,\n      //    then throw a TypeError.\n      if (typeof this !== 'object' || this === null || !(#target in this)) {\n        throw new TypeError(\n          `'next' called on an object that does not implement interface ${name} Iterator.`\n        )\n      }\n\n      // 6. Let index be objects index.\n      // 7. Let kind be objects kind.\n      // 8. Let values be objects target's value pairs to iterate over.\n      const index = this.#index\n      const values = this.#target[kInternalIterator]\n\n      // 9. Let len be the length of values.\n      const len = values.length\n\n      // 10. If index is greater than or equal to len, then return\n      //     CreateIterResultObject(undefined, true).\n      if (index >= len) {\n        return {\n          value: undefined,\n          done: true\n        }\n      }\n\n      // 11. Let pair be the entry in values at index index.\n      const { [keyIndex]: key, [valueIndex]: value } = values[index]\n\n      // 12. Set objects index to index + 1.\n      this.#index = index + 1\n\n      // 13. Return the iterator result for pair and kind.\n\n      // https://webidl.spec.whatwg.org/#iterator-result\n\n      // 1. Let result be a value determined by the value of kind:\n      let result\n      switch (this.#kind) {\n        case 'key':\n          // 1. Let idlKey be pairs key.\n          // 2. Let key be the result of converting idlKey to an\n          //    ECMAScript value.\n          // 3. result is key.\n          result = key\n          break\n        case 'value':\n          // 1. Let idlValue be pairs value.\n          // 2. Let value be the result of converting idlValue to\n          //    an ECMAScript value.\n          // 3. result is value.\n          result = value\n          break\n        case 'key+value':\n          // 1. Let idlKey be pairs key.\n          // 2. Let idlValue be pairs value.\n          // 3. Let key be the result of converting idlKey to an\n          //    ECMAScript value.\n          // 4. Let value be the result of converting idlValue to\n          //    an ECMAScript value.\n          // 5. Let array be ! ArrayCreate(2).\n          // 6. Call ! CreateDataProperty(array, \"0\", key).\n          // 7. Call ! CreateDataProperty(array, \"1\", value).\n          // 8. result is array.\n          result = [key, value]\n          break\n      }\n\n      // 2. Return CreateIterResultObject(result, false).\n      return {\n        value: result,\n        done: false\n      }\n    }\n  }\n\n  // https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object\n  // @ts-ignore\n  delete FastIterableIterator.prototype.constructor\n\n  Object.setPrototypeOf(FastIterableIterator.prototype, esIteratorPrototype)\n\n  Object.defineProperties(FastIterableIterator.prototype, {\n    [Symbol.toStringTag]: {\n      writable: false,\n      enumerable: false,\n      configurable: true,\n      value: `${name} Iterator`\n    },\n    next: { writable: true, enumerable: true, configurable: true }\n  })\n\n  /**\n   * @param {unknown} target\n   * @param {'key' | 'value' | 'key+value'} kind\n   * @returns {IterableIterator<any>}\n   */\n  return function (target, kind) {\n    return new FastIterableIterator(target, kind)\n  }\n}\n\n/**\n * @see https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object\n * @param {string} name name of the instance\n * @param {any} object class\n * @param {symbol} kInternalIterator\n * @param {string | number} [keyIndex]\n * @param {string | number} [valueIndex]\n */\nfunction iteratorMixin (name, object, kInternalIterator, keyIndex = 0, valueIndex = 1) {\n  const makeIterator = createIterator(name, kInternalIterator, keyIndex, valueIndex)\n\n  const properties = {\n    keys: {\n      writable: true,\n      enumerable: true,\n      configurable: true,\n      value: function keys () {\n        webidl.brandCheck(this, object)\n        return makeIterator(this, 'key')\n      }\n    },\n    values: {\n      writable: true,\n      enumerable: true,\n      configurable: true,\n      value: function values () {\n        webidl.brandCheck(this, object)\n        return makeIterator(this, 'value')\n      }\n    },\n    entries: {\n      writable: true,\n      enumerable: true,\n      configurable: true,\n      value: function entries () {\n        webidl.brandCheck(this, object)\n        return makeIterator(this, 'key+value')\n      }\n    },\n    forEach: {\n      writable: true,\n      enumerable: true,\n      configurable: true,\n      value: function forEach (callbackfn, thisArg = globalThis) {\n        webidl.brandCheck(this, object)\n        webidl.argumentLengthCheck(arguments, 1, `${name}.forEach`)\n        if (typeof callbackfn !== 'function') {\n          throw new TypeError(\n            `Failed to execute 'forEach' on '${name}': parameter 1 is not of type 'Function'.`\n          )\n        }\n        for (const { 0: key, 1: value } of makeIterator(this, 'key+value')) {\n          callbackfn.call(thisArg, value, key, this)\n        }\n      }\n    }\n  }\n\n  return Object.defineProperties(object.prototype, {\n    ...properties,\n    [Symbol.iterator]: {\n      writable: true,\n      enumerable: false,\n      configurable: true,\n      value: properties.entries.value\n    }\n  })\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#body-fully-read\n */\nasync function fullyReadBody (body, processBody, processBodyError) {\n  // 1. If taskDestination is null, then set taskDestination to\n  //    the result of starting a new parallel queue.\n\n  // 2. Let successSteps given a byte sequence bytes be to queue a\n  //    fetch task to run processBody given bytes, with taskDestination.\n  const successSteps = processBody\n\n  // 3. Let errorSteps be to queue a fetch task to run processBodyError,\n  //    with taskDestination.\n  const errorSteps = processBodyError\n\n  // 4. Let reader be the result of getting a reader for bodys stream.\n  //    If that threw an exception, then run errorSteps with that\n  //    exception and return.\n  let reader\n\n  try {\n    reader = body.stream.getReader()\n  } catch (e) {\n    errorSteps(e)\n    return\n  }\n\n  // 5. Read all bytes from reader, given successSteps and errorSteps.\n  try {\n    successSteps(await readAllBytes(reader))\n  } catch (e) {\n    errorSteps(e)\n  }\n}\n\nfunction isReadableStreamLike (stream) {\n  return stream instanceof ReadableStream || (\n    stream[Symbol.toStringTag] === 'ReadableStream' &&\n    typeof stream.tee === 'function'\n  )\n}\n\n/**\n * @param {ReadableStreamController<Uint8Array>} controller\n */\nfunction readableStreamClose (controller) {\n  try {\n    controller.close()\n    controller.byobRequest?.respond(0)\n  } catch (err) {\n    // TODO: add comment explaining why this error occurs.\n    if (!err.message.includes('Controller is already closed') && !err.message.includes('ReadableStream is already closed')) {\n      throw err\n    }\n  }\n}\n\nconst invalidIsomorphicEncodeValueRegex = /[^\\x00-\\xFF]/ // eslint-disable-line\n\n/**\n * @see https://infra.spec.whatwg.org/#isomorphic-encode\n * @param {string} input\n */\nfunction isomorphicEncode (input) {\n  // 1. Assert: input contains no code points greater than U+00FF.\n  assert(!invalidIsomorphicEncodeValueRegex.test(input))\n\n  // 2. Return a byte sequence whose length is equal to inputs code\n  //    point length and whose bytes have the same values as the\n  //    values of inputs code points, in the same order\n  return input\n}\n\n/**\n * @see https://streams.spec.whatwg.org/#readablestreamdefaultreader-read-all-bytes\n * @see https://streams.spec.whatwg.org/#read-loop\n * @param {ReadableStreamDefaultReader} reader\n */\nasync function readAllBytes (reader) {\n  const bytes = []\n  let byteLength = 0\n\n  while (true) {\n    const { done, value: chunk } = await reader.read()\n\n    if (done) {\n      // 1. Call successSteps with bytes.\n      return Buffer.concat(bytes, byteLength)\n    }\n\n    // 1. If chunk is not a Uint8Array object, call failureSteps\n    //    with a TypeError and abort these steps.\n    if (!isUint8Array(chunk)) {\n      throw new TypeError('Received non-Uint8Array chunk')\n    }\n\n    // 2. Append the bytes represented by chunk to bytes.\n    bytes.push(chunk)\n    byteLength += chunk.length\n\n    // 3. Read-loop given reader, bytes, successSteps, and failureSteps.\n  }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#is-local\n * @param {URL} url\n */\nfunction urlIsLocal (url) {\n  assert('protocol' in url) // ensure it's a url object\n\n  const protocol = url.protocol\n\n  return protocol === 'about:' || protocol === 'blob:' || protocol === 'data:'\n}\n\n/**\n * @param {string|URL} url\n * @returns {boolean}\n */\nfunction urlHasHttpsScheme (url) {\n  return (\n    (\n      typeof url === 'string' &&\n      url[5] === ':' &&\n      url[0] === 'h' &&\n      url[1] === 't' &&\n      url[2] === 't' &&\n      url[3] === 'p' &&\n      url[4] === 's'\n    ) ||\n    url.protocol === 'https:'\n  )\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-scheme\n * @param {URL} url\n */\nfunction urlIsHttpHttpsScheme (url) {\n  assert('protocol' in url) // ensure it's a url object\n\n  const protocol = url.protocol\n\n  return protocol === 'http:' || protocol === 'https:'\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#simple-range-header-value\n * @param {string} value\n * @param {boolean} allowWhitespace\n */\nfunction simpleRangeHeaderValue (value, allowWhitespace) {\n  // 1. Let data be the isomorphic decoding of value.\n  // Note: isomorphic decoding takes a sequence of bytes (ie. a Uint8Array) and turns it into a string,\n  // nothing more. We obviously don't need to do that if value is a string already.\n  const data = value\n\n  // 2. If data does not start with \"bytes\", then return failure.\n  if (!data.startsWith('bytes')) {\n    return 'failure'\n  }\n\n  // 3. Let position be a position variable for data, initially pointing at the 5th code point of data.\n  const position = { position: 5 }\n\n  // 4. If allowWhitespace is true, collect a sequence of code points that are HTTP tab or space,\n  //    from data given position.\n  if (allowWhitespace) {\n    collectASequenceOfCodePoints(\n      (char) => char === '\\t' || char === ' ',\n      data,\n      position\n    )\n  }\n\n  // 5. If the code point at position within data is not U+003D (=), then return failure.\n  if (data.charCodeAt(position.position) !== 0x3D) {\n    return 'failure'\n  }\n\n  // 6. Advance position by 1.\n  position.position++\n\n  // 7. If allowWhitespace is true, collect a sequence of code points that are HTTP tab or space, from\n  //    data given position.\n  if (allowWhitespace) {\n    collectASequenceOfCodePoints(\n      (char) => char === '\\t' || char === ' ',\n      data,\n      position\n    )\n  }\n\n  // 8. Let rangeStart be the result of collecting a sequence of code points that are ASCII digits,\n  //    from data given position.\n  const rangeStart = collectASequenceOfCodePoints(\n    (char) => {\n      const code = char.charCodeAt(0)\n\n      return code >= 0x30 && code <= 0x39\n    },\n    data,\n    position\n  )\n\n  // 9. Let rangeStartValue be rangeStart, interpreted as decimal number, if rangeStart is not the\n  //    empty string; otherwise null.\n  const rangeStartValue = rangeStart.length ? Number(rangeStart) : null\n\n  // 10. If allowWhitespace is true, collect a sequence of code points that are HTTP tab or space,\n  //     from data given position.\n  if (allowWhitespace) {\n    collectASequenceOfCodePoints(\n      (char) => char === '\\t' || char === ' ',\n      data,\n      position\n    )\n  }\n\n  // 11. If the code point at position within data is not U+002D (-), then return failure.\n  if (data.charCodeAt(position.position) !== 0x2D) {\n    return 'failure'\n  }\n\n  // 12. Advance position by 1.\n  position.position++\n\n  // 13. If allowWhitespace is true, collect a sequence of code points that are HTTP tab\n  //     or space, from data given position.\n  // Note from Khafra: its the same step as in #8 again lol\n  if (allowWhitespace) {\n    collectASequenceOfCodePoints(\n      (char) => char === '\\t' || char === ' ',\n      data,\n      position\n    )\n  }\n\n  // 14. Let rangeEnd be the result of collecting a sequence of code points that are\n  //     ASCII digits, from data given position.\n  // Note from Khafra: you wouldn't guess it, but this is also the same step as #8\n  const rangeEnd = collectASequenceOfCodePoints(\n    (char) => {\n      const code = char.charCodeAt(0)\n\n      return code >= 0x30 && code <= 0x39\n    },\n    data,\n    position\n  )\n\n  // 15. Let rangeEndValue be rangeEnd, interpreted as decimal number, if rangeEnd\n  //     is not the empty string; otherwise null.\n  // Note from Khafra: THE SAME STEP, AGAIN!!!\n  // Note: why interpret as a decimal if we only collect ascii digits?\n  const rangeEndValue = rangeEnd.length ? Number(rangeEnd) : null\n\n  // 16. If position is not past the end of data, then return failure.\n  if (position.position < data.length) {\n    return 'failure'\n  }\n\n  // 17. If rangeEndValue and rangeStartValue are null, then return failure.\n  if (rangeEndValue === null && rangeStartValue === null) {\n    return 'failure'\n  }\n\n  // 18. If rangeStartValue and rangeEndValue are numbers, and rangeStartValue is\n  //     greater than rangeEndValue, then return failure.\n  // Note: ... when can they not be numbers?\n  if (rangeStartValue > rangeEndValue) {\n    return 'failure'\n  }\n\n  // 19. Return (rangeStartValue, rangeEndValue).\n  return { rangeStartValue, rangeEndValue }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#build-a-content-range\n * @param {number} rangeStart\n * @param {number} rangeEnd\n * @param {number} fullLength\n */\nfunction buildContentRange (rangeStart, rangeEnd, fullLength) {\n  // 1. Let contentRange be `bytes `.\n  let contentRange = 'bytes '\n\n  // 2. Append rangeStart, serialized and isomorphic encoded, to contentRange.\n  contentRange += isomorphicEncode(`${rangeStart}`)\n\n  // 3. Append 0x2D (-) to contentRange.\n  contentRange += '-'\n\n  // 4. Append rangeEnd, serialized and isomorphic encoded to contentRange.\n  contentRange += isomorphicEncode(`${rangeEnd}`)\n\n  // 5. Append 0x2F (/) to contentRange.\n  contentRange += '/'\n\n  // 6. Append fullLength, serialized and isomorphic encoded to contentRange.\n  contentRange += isomorphicEncode(`${fullLength}`)\n\n  // 7. Return contentRange.\n  return contentRange\n}\n\n// A Stream, which pipes the response to zlib.createInflate() or\n// zlib.createInflateRaw() depending on the first byte of the Buffer.\n// If the lower byte of the first byte is 0x08, then the stream is\n// interpreted as a zlib stream, otherwise it's interpreted as a\n// raw deflate stream.\nclass InflateStream extends Transform {\n  #zlibOptions\n\n  /** @param {zlib.ZlibOptions} [zlibOptions] */\n  constructor (zlibOptions) {\n    super()\n    this.#zlibOptions = zlibOptions\n  }\n\n  _transform (chunk, encoding, callback) {\n    if (!this._inflateStream) {\n      if (chunk.length === 0) {\n        callback()\n        return\n      }\n      this._inflateStream = (chunk[0] & 0x0F) === 0x08\n        ? zlib.createInflate(this.#zlibOptions)\n        : zlib.createInflateRaw(this.#zlibOptions)\n\n      this._inflateStream.on('data', this.push.bind(this))\n      this._inflateStream.on('end', () => this.push(null))\n      this._inflateStream.on('error', (err) => this.destroy(err))\n    }\n\n    this._inflateStream.write(chunk, encoding, callback)\n  }\n\n  _final (callback) {\n    if (this._inflateStream) {\n      this._inflateStream.end()\n      this._inflateStream = null\n    }\n    callback()\n  }\n}\n\n/**\n * @param {zlib.ZlibOptions} [zlibOptions]\n * @returns {InflateStream}\n */\nfunction createInflate (zlibOptions) {\n  return new InflateStream(zlibOptions)\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-header-extract-mime-type\n * @param {import('./headers').HeadersList} headers\n */\nfunction extractMimeType (headers) {\n  // 1. Let charset be null.\n  let charset = null\n\n  // 2. Let essence be null.\n  let essence = null\n\n  // 3. Let mimeType be null.\n  let mimeType = null\n\n  // 4. Let values be the result of getting, decoding, and splitting `Content-Type` from headers.\n  const values = getDecodeSplit('content-type', headers)\n\n  // 5. If values is null, then return failure.\n  if (values === null) {\n    return 'failure'\n  }\n\n  // 6. For each value of values:\n  for (const value of values) {\n    // 6.1. Let temporaryMimeType be the result of parsing value.\n    const temporaryMimeType = parseMIMEType(value)\n\n    // 6.2. If temporaryMimeType is failure or its essence is \"*/*\", then continue.\n    if (temporaryMimeType === 'failure' || temporaryMimeType.essence === '*/*') {\n      continue\n    }\n\n    // 6.3. Set mimeType to temporaryMimeType.\n    mimeType = temporaryMimeType\n\n    // 6.4. If mimeTypes essence is not essence, then:\n    if (mimeType.essence !== essence) {\n      // 6.4.1. Set charset to null.\n      charset = null\n\n      // 6.4.2. If mimeTypes parameters[\"charset\"] exists, then set charset to\n      //        mimeTypes parameters[\"charset\"].\n      if (mimeType.parameters.has('charset')) {\n        charset = mimeType.parameters.get('charset')\n      }\n\n      // 6.4.3. Set essence to mimeTypes essence.\n      essence = mimeType.essence\n    } else if (!mimeType.parameters.has('charset') && charset !== null) {\n      // 6.5. Otherwise, if mimeTypes parameters[\"charset\"] does not exist, and\n      //      charset is non-null, set mimeTypes parameters[\"charset\"] to charset.\n      mimeType.parameters.set('charset', charset)\n    }\n  }\n\n  // 7. If mimeType is null, then return failure.\n  if (mimeType == null) {\n    return 'failure'\n  }\n\n  // 8. Return mimeType.\n  return mimeType\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#header-value-get-decode-and-split\n * @param {string|null} value\n */\nfunction gettingDecodingSplitting (value) {\n  // 1. Let input be the result of isomorphic decoding value.\n  const input = value\n\n  // 2. Let position be a position variable for input, initially pointing at the start of input.\n  const position = { position: 0 }\n\n  // 3. Let values be a list of strings, initially empty.\n  const values = []\n\n  // 4. Let temporaryValue be the empty string.\n  let temporaryValue = ''\n\n  // 5. While position is not past the end of input:\n  while (position.position < input.length) {\n    // 5.1. Append the result of collecting a sequence of code points that are not U+0022 (\")\n    //      or U+002C (,) from input, given position, to temporaryValue.\n    temporaryValue += collectASequenceOfCodePoints(\n      (char) => char !== '\"' && char !== ',',\n      input,\n      position\n    )\n\n    // 5.2. If position is not past the end of input, then:\n    if (position.position < input.length) {\n      // 5.2.1. If the code point at position within input is U+0022 (\"), then:\n      if (input.charCodeAt(position.position) === 0x22) {\n        // 5.2.1.1. Append the result of collecting an HTTP quoted string from input, given position, to temporaryValue.\n        temporaryValue += collectAnHTTPQuotedString(\n          input,\n          position\n        )\n\n        // 5.2.1.2. If position is not past the end of input, then continue.\n        if (position.position < input.length) {\n          continue\n        }\n      } else {\n        // 5.2.2. Otherwise:\n\n        // 5.2.2.1. Assert: the code point at position within input is U+002C (,).\n        assert(input.charCodeAt(position.position) === 0x2C)\n\n        // 5.2.2.2. Advance position by 1.\n        position.position++\n      }\n    }\n\n    // 5.3. Remove all HTTP tab or space from the start and end of temporaryValue.\n    temporaryValue = removeChars(temporaryValue, true, true, (char) => char === 0x9 || char === 0x20)\n\n    // 5.4. Append temporaryValue to values.\n    values.push(temporaryValue)\n\n    // 5.6. Set temporaryValue to the empty string.\n    temporaryValue = ''\n  }\n\n  // 6. Return values.\n  return values\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-header-list-get-decode-split\n * @param {string} name lowercase header name\n * @param {import('./headers').HeadersList} list\n */\nfunction getDecodeSplit (name, list) {\n  // 1. Let value be the result of getting name from list.\n  const value = list.get(name, true)\n\n  // 2. If value is null, then return null.\n  if (value === null) {\n    return null\n  }\n\n  // 3. Return the result of getting, decoding, and splitting value.\n  return gettingDecodingSplitting(value)\n}\n\nconst textDecoder = new TextDecoder()\n\n/**\n * @see https://encoding.spec.whatwg.org/#utf-8-decode\n * @param {Buffer} buffer\n */\nfunction utf8DecodeBytes (buffer) {\n  if (buffer.length === 0) {\n    return ''\n  }\n\n  // 1. Let buffer be the result of peeking three bytes from\n  //    ioQueue, converted to a byte sequence.\n\n  // 2. If buffer is 0xEF 0xBB 0xBF, then read three\n  //    bytes from ioQueue. (Do nothing with those bytes.)\n  if (buffer[0] === 0xEF && buffer[1] === 0xBB && buffer[2] === 0xBF) {\n    buffer = buffer.subarray(3)\n  }\n\n  // 3. Process a queue with an instance of UTF-8s\n  //    decoder, ioQueue, output, and \"replacement\".\n  const output = textDecoder.decode(buffer)\n\n  // 4. Return output.\n  return output\n}\n\nclass EnvironmentSettingsObjectBase {\n  get baseUrl () {\n    return getGlobalOrigin()\n  }\n\n  get origin () {\n    return this.baseUrl?.origin\n  }\n\n  policyContainer = makePolicyContainer()\n}\n\nclass EnvironmentSettingsObject {\n  settingsObject = new EnvironmentSettingsObjectBase()\n}\n\nconst environmentSettingsObject = new EnvironmentSettingsObject()\n\nmodule.exports = {\n  isAborted,\n  isCancelled,\n  isValidEncodedURL,\n  createDeferredPromise,\n  ReadableStreamFrom,\n  tryUpgradeRequestToAPotentiallyTrustworthyURL,\n  clampAndCoarsenConnectionTimingInfo,\n  coarsenedSharedCurrentTime,\n  determineRequestsReferrer,\n  makePolicyContainer,\n  clonePolicyContainer,\n  appendFetchMetadata,\n  appendRequestOriginHeader,\n  TAOCheck,\n  corsCheck,\n  crossOriginResourcePolicyCheck,\n  createOpaqueTimingInfo,\n  setRequestReferrerPolicyOnRedirect,\n  isValidHTTPToken,\n  requestBadPort,\n  requestCurrentURL,\n  responseURL,\n  responseLocationURL,\n  isBlobLike,\n  isURLPotentiallyTrustworthy,\n  isValidReasonPhrase,\n  sameOrigin,\n  normalizeMethod,\n  serializeJavascriptValueToJSONString,\n  iteratorMixin,\n  createIterator,\n  isValidHeaderName,\n  isValidHeaderValue,\n  isErrorLike,\n  fullyReadBody,\n  bytesMatch,\n  isReadableStreamLike,\n  readableStreamClose,\n  isomorphicEncode,\n  urlIsLocal,\n  urlHasHttpsScheme,\n  urlIsHttpHttpsScheme,\n  readAllBytes,\n  simpleRangeHeaderValue,\n  buildContentRange,\n  parseMetadata,\n  createInflate,\n  extractMimeType,\n  getDecodeSplit,\n  utf8DecodeBytes,\n  environmentSettingsObject\n}\n","'use strict'\n\nconst { types, inspect } = require('node:util')\nconst { markAsUncloneable } = require('node:worker_threads')\nconst { toUSVString } = require('../../core/util')\n\n/** @type {import('../../../types/webidl').Webidl} */\nconst webidl = {}\nwebidl.converters = {}\nwebidl.util = {}\nwebidl.errors = {}\n\nwebidl.errors.exception = function (message) {\n  return new TypeError(`${message.header}: ${message.message}`)\n}\n\nwebidl.errors.conversionFailed = function (context) {\n  const plural = context.types.length === 1 ? '' : ' one of'\n  const message =\n    `${context.argument} could not be converted to` +\n    `${plural}: ${context.types.join(', ')}.`\n\n  return webidl.errors.exception({\n    header: context.prefix,\n    message\n  })\n}\n\nwebidl.errors.invalidArgument = function (context) {\n  return webidl.errors.exception({\n    header: context.prefix,\n    message: `\"${context.value}\" is an invalid ${context.type}.`\n  })\n}\n\n// https://webidl.spec.whatwg.org/#implements\nwebidl.brandCheck = function (V, I, opts) {\n  if (opts?.strict !== false) {\n    if (!(V instanceof I)) {\n      const err = new TypeError('Illegal invocation')\n      err.code = 'ERR_INVALID_THIS' // node compat.\n      throw err\n    }\n  } else {\n    if (V?.[Symbol.toStringTag] !== I.prototype[Symbol.toStringTag]) {\n      const err = new TypeError('Illegal invocation')\n      err.code = 'ERR_INVALID_THIS' // node compat.\n      throw err\n    }\n  }\n}\n\nwebidl.argumentLengthCheck = function ({ length }, min, ctx) {\n  if (length < min) {\n    throw webidl.errors.exception({\n      message: `${min} argument${min !== 1 ? 's' : ''} required, ` +\n               `but${length ? ' only' : ''} ${length} found.`,\n      header: ctx\n    })\n  }\n}\n\nwebidl.illegalConstructor = function () {\n  throw webidl.errors.exception({\n    header: 'TypeError',\n    message: 'Illegal constructor'\n  })\n}\n\n// https://tc39.es/ecma262/#sec-ecmascript-data-types-and-values\nwebidl.util.Type = function (V) {\n  switch (typeof V) {\n    case 'undefined': return 'Undefined'\n    case 'boolean': return 'Boolean'\n    case 'string': return 'String'\n    case 'symbol': return 'Symbol'\n    case 'number': return 'Number'\n    case 'bigint': return 'BigInt'\n    case 'function':\n    case 'object': {\n      if (V === null) {\n        return 'Null'\n      }\n\n      return 'Object'\n    }\n  }\n}\n\nwebidl.util.markAsUncloneable = markAsUncloneable || (() => {})\n// https://webidl.spec.whatwg.org/#abstract-opdef-converttoint\nwebidl.util.ConvertToInt = function (V, bitLength, signedness, opts) {\n  let upperBound\n  let lowerBound\n\n  // 1. If bitLength is 64, then:\n  if (bitLength === 64) {\n    // 1. Let upperBound be 2^53  1.\n    upperBound = Math.pow(2, 53) - 1\n\n    // 2. If signedness is \"unsigned\", then let lowerBound be 0.\n    if (signedness === 'unsigned') {\n      lowerBound = 0\n    } else {\n      // 3. Otherwise let lowerBound be 2^53 + 1.\n      lowerBound = Math.pow(-2, 53) + 1\n    }\n  } else if (signedness === 'unsigned') {\n    // 2. Otherwise, if signedness is \"unsigned\", then:\n\n    // 1. Let lowerBound be 0.\n    lowerBound = 0\n\n    // 2. Let upperBound be 2^bitLength  1.\n    upperBound = Math.pow(2, bitLength) - 1\n  } else {\n    // 3. Otherwise:\n\n    // 1. Let lowerBound be -2^bitLength  1.\n    lowerBound = Math.pow(-2, bitLength) - 1\n\n    // 2. Let upperBound be 2^bitLength  1  1.\n    upperBound = Math.pow(2, bitLength - 1) - 1\n  }\n\n  // 4. Let x be ? ToNumber(V).\n  let x = Number(V)\n\n  // 5. If x is 0, then set x to +0.\n  if (x === 0) {\n    x = 0\n  }\n\n  // 6. If the conversion is to an IDL type associated\n  //    with the [EnforceRange] extended attribute, then:\n  if (opts?.enforceRange === true) {\n    // 1. If x is NaN, +, or , then throw a TypeError.\n    if (\n      Number.isNaN(x) ||\n      x === Number.POSITIVE_INFINITY ||\n      x === Number.NEGATIVE_INFINITY\n    ) {\n      throw webidl.errors.exception({\n        header: 'Integer conversion',\n        message: `Could not convert ${webidl.util.Stringify(V)} to an integer.`\n      })\n    }\n\n    // 2. Set x to IntegerPart(x).\n    x = webidl.util.IntegerPart(x)\n\n    // 3. If x < lowerBound or x > upperBound, then\n    //    throw a TypeError.\n    if (x < lowerBound || x > upperBound) {\n      throw webidl.errors.exception({\n        header: 'Integer conversion',\n        message: `Value must be between ${lowerBound}-${upperBound}, got ${x}.`\n      })\n    }\n\n    // 4. Return x.\n    return x\n  }\n\n  // 7. If x is not NaN and the conversion is to an IDL\n  //    type associated with the [Clamp] extended\n  //    attribute, then:\n  if (!Number.isNaN(x) && opts?.clamp === true) {\n    // 1. Set x to min(max(x, lowerBound), upperBound).\n    x = Math.min(Math.max(x, lowerBound), upperBound)\n\n    // 2. Round x to the nearest integer, choosing the\n    //    even integer if it lies halfway between two,\n    //    and choosing +0 rather than 0.\n    if (Math.floor(x) % 2 === 0) {\n      x = Math.floor(x)\n    } else {\n      x = Math.ceil(x)\n    }\n\n    // 3. Return x.\n    return x\n  }\n\n  // 8. If x is NaN, +0, +, or , then return +0.\n  if (\n    Number.isNaN(x) ||\n    (x === 0 && Object.is(0, x)) ||\n    x === Number.POSITIVE_INFINITY ||\n    x === Number.NEGATIVE_INFINITY\n  ) {\n    return 0\n  }\n\n  // 9. Set x to IntegerPart(x).\n  x = webidl.util.IntegerPart(x)\n\n  // 10. Set x to x modulo 2^bitLength.\n  x = x % Math.pow(2, bitLength)\n\n  // 11. If signedness is \"signed\" and x  2^bitLength  1,\n  //    then return x  2^bitLength.\n  if (signedness === 'signed' && x >= Math.pow(2, bitLength) - 1) {\n    return x - Math.pow(2, bitLength)\n  }\n\n  // 12. Otherwise, return x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#abstract-opdef-integerpart\nwebidl.util.IntegerPart = function (n) {\n  // 1. Let r be floor(abs(n)).\n  const r = Math.floor(Math.abs(n))\n\n  // 2. If n < 0, then return -1  r.\n  if (n < 0) {\n    return -1 * r\n  }\n\n  // 3. Otherwise, return r.\n  return r\n}\n\nwebidl.util.Stringify = function (V) {\n  const type = webidl.util.Type(V)\n\n  switch (type) {\n    case 'Symbol':\n      return `Symbol(${V.description})`\n    case 'Object':\n      return inspect(V)\n    case 'String':\n      return `\"${V}\"`\n    default:\n      return `${V}`\n  }\n}\n\n// https://webidl.spec.whatwg.org/#es-sequence\nwebidl.sequenceConverter = function (converter) {\n  return (V, prefix, argument, Iterable) => {\n    // 1. If Type(V) is not Object, throw a TypeError.\n    if (webidl.util.Type(V) !== 'Object') {\n      throw webidl.errors.exception({\n        header: prefix,\n        message: `${argument} (${webidl.util.Stringify(V)}) is not iterable.`\n      })\n    }\n\n    // 2. Let method be ? GetMethod(V, @@iterator).\n    /** @type {Generator} */\n    const method = typeof Iterable === 'function' ? Iterable() : V?.[Symbol.iterator]?.()\n    const seq = []\n    let index = 0\n\n    // 3. If method is undefined, throw a TypeError.\n    if (\n      method === undefined ||\n      typeof method.next !== 'function'\n    ) {\n      throw webidl.errors.exception({\n        header: prefix,\n        message: `${argument} is not iterable.`\n      })\n    }\n\n    // https://webidl.spec.whatwg.org/#create-sequence-from-iterable\n    while (true) {\n      const { done, value } = method.next()\n\n      if (done) {\n        break\n      }\n\n      seq.push(converter(value, prefix, `${argument}[${index++}]`))\n    }\n\n    return seq\n  }\n}\n\n// https://webidl.spec.whatwg.org/#es-to-record\nwebidl.recordConverter = function (keyConverter, valueConverter) {\n  return (O, prefix, argument) => {\n    // 1. If Type(O) is not Object, throw a TypeError.\n    if (webidl.util.Type(O) !== 'Object') {\n      throw webidl.errors.exception({\n        header: prefix,\n        message: `${argument} (\"${webidl.util.Type(O)}\") is not an Object.`\n      })\n    }\n\n    // 2. Let result be a new empty instance of record<K, V>.\n    const result = {}\n\n    if (!types.isProxy(O)) {\n      // 1. Let desc be ? O.[[GetOwnProperty]](key).\n      const keys = [...Object.getOwnPropertyNames(O), ...Object.getOwnPropertySymbols(O)]\n\n      for (const key of keys) {\n        // 1. Let typedKey be key converted to an IDL value of type K.\n        const typedKey = keyConverter(key, prefix, argument)\n\n        // 2. Let value be ? Get(O, key).\n        // 3. Let typedValue be value converted to an IDL value of type V.\n        const typedValue = valueConverter(O[key], prefix, argument)\n\n        // 4. Set result[typedKey] to typedValue.\n        result[typedKey] = typedValue\n      }\n\n      // 5. Return result.\n      return result\n    }\n\n    // 3. Let keys be ? O.[[OwnPropertyKeys]]().\n    const keys = Reflect.ownKeys(O)\n\n    // 4. For each key of keys.\n    for (const key of keys) {\n      // 1. Let desc be ? O.[[GetOwnProperty]](key).\n      const desc = Reflect.getOwnPropertyDescriptor(O, key)\n\n      // 2. If desc is not undefined and desc.[[Enumerable]] is true:\n      if (desc?.enumerable) {\n        // 1. Let typedKey be key converted to an IDL value of type K.\n        const typedKey = keyConverter(key, prefix, argument)\n\n        // 2. Let value be ? Get(O, key).\n        // 3. Let typedValue be value converted to an IDL value of type V.\n        const typedValue = valueConverter(O[key], prefix, argument)\n\n        // 4. Set result[typedKey] to typedValue.\n        result[typedKey] = typedValue\n      }\n    }\n\n    // 5. Return result.\n    return result\n  }\n}\n\nwebidl.interfaceConverter = function (i) {\n  return (V, prefix, argument, opts) => {\n    if (opts?.strict !== false && !(V instanceof i)) {\n      throw webidl.errors.exception({\n        header: prefix,\n        message: `Expected ${argument} (\"${webidl.util.Stringify(V)}\") to be an instance of ${i.name}.`\n      })\n    }\n\n    return V\n  }\n}\n\nwebidl.dictionaryConverter = function (converters) {\n  return (dictionary, prefix, argument) => {\n    const type = webidl.util.Type(dictionary)\n    const dict = {}\n\n    if (type === 'Null' || type === 'Undefined') {\n      return dict\n    } else if (type !== 'Object') {\n      throw webidl.errors.exception({\n        header: prefix,\n        message: `Expected ${dictionary} to be one of: Null, Undefined, Object.`\n      })\n    }\n\n    for (const options of converters) {\n      const { key, defaultValue, required, converter } = options\n\n      if (required === true) {\n        if (!Object.hasOwn(dictionary, key)) {\n          throw webidl.errors.exception({\n            header: prefix,\n            message: `Missing required key \"${key}\".`\n          })\n        }\n      }\n\n      let value = dictionary[key]\n      const hasDefault = Object.hasOwn(options, 'defaultValue')\n\n      // Only use defaultValue if value is undefined and\n      // a defaultValue options was provided.\n      if (hasDefault && value !== null) {\n        value ??= defaultValue()\n      }\n\n      // A key can be optional and have no default value.\n      // When this happens, do not perform a conversion,\n      // and do not assign the key a value.\n      if (required || hasDefault || value !== undefined) {\n        value = converter(value, prefix, `${argument}.${key}`)\n\n        if (\n          options.allowedValues &&\n          !options.allowedValues.includes(value)\n        ) {\n          throw webidl.errors.exception({\n            header: prefix,\n            message: `${value} is not an accepted type. Expected one of ${options.allowedValues.join(', ')}.`\n          })\n        }\n\n        dict[key] = value\n      }\n    }\n\n    return dict\n  }\n}\n\nwebidl.nullableConverter = function (converter) {\n  return (V, prefix, argument) => {\n    if (V === null) {\n      return V\n    }\n\n    return converter(V, prefix, argument)\n  }\n}\n\n// https://webidl.spec.whatwg.org/#es-DOMString\nwebidl.converters.DOMString = function (V, prefix, argument, opts) {\n  // 1. If V is null and the conversion is to an IDL type\n  //    associated with the [LegacyNullToEmptyString]\n  //    extended attribute, then return the DOMString value\n  //    that represents the empty string.\n  if (V === null && opts?.legacyNullToEmptyString) {\n    return ''\n  }\n\n  // 2. Let x be ? ToString(V).\n  if (typeof V === 'symbol') {\n    throw webidl.errors.exception({\n      header: prefix,\n      message: `${argument} is a symbol, which cannot be converted to a DOMString.`\n    })\n  }\n\n  // 3. Return the IDL DOMString value that represents the\n  //    same sequence of code units as the one the\n  //    ECMAScript String value x represents.\n  return String(V)\n}\n\n// https://webidl.spec.whatwg.org/#es-ByteString\nwebidl.converters.ByteString = function (V, prefix, argument) {\n  // 1. Let x be ? ToString(V).\n  // Note: DOMString converter perform ? ToString(V)\n  const x = webidl.converters.DOMString(V, prefix, argument)\n\n  // 2. If the value of any element of x is greater than\n  //    255, then throw a TypeError.\n  for (let index = 0; index < x.length; index++) {\n    if (x.charCodeAt(index) > 255) {\n      throw new TypeError(\n        'Cannot convert argument to a ByteString because the character at ' +\n        `index ${index} has a value of ${x.charCodeAt(index)} which is greater than 255.`\n      )\n    }\n  }\n\n  // 3. Return an IDL ByteString value whose length is the\n  //    length of x, and where the value of each element is\n  //    the value of the corresponding element of x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-USVString\n// TODO: rewrite this so we can control the errors thrown\nwebidl.converters.USVString = toUSVString\n\n// https://webidl.spec.whatwg.org/#es-boolean\nwebidl.converters.boolean = function (V) {\n  // 1. Let x be the result of computing ToBoolean(V).\n  const x = Boolean(V)\n\n  // 2. Return the IDL boolean value that is the one that represents\n  //    the same truth value as the ECMAScript Boolean value x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-any\nwebidl.converters.any = function (V) {\n  return V\n}\n\n// https://webidl.spec.whatwg.org/#es-long-long\nwebidl.converters['long long'] = function (V, prefix, argument) {\n  // 1. Let x be ? ConvertToInt(V, 64, \"signed\").\n  const x = webidl.util.ConvertToInt(V, 64, 'signed', undefined, prefix, argument)\n\n  // 2. Return the IDL long long value that represents\n  //    the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-long-long\nwebidl.converters['unsigned long long'] = function (V, prefix, argument) {\n  // 1. Let x be ? ConvertToInt(V, 64, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 64, 'unsigned', undefined, prefix, argument)\n\n  // 2. Return the IDL unsigned long long value that\n  //    represents the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-long\nwebidl.converters['unsigned long'] = function (V, prefix, argument) {\n  // 1. Let x be ? ConvertToInt(V, 32, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 32, 'unsigned', undefined, prefix, argument)\n\n  // 2. Return the IDL unsigned long value that\n  //    represents the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-short\nwebidl.converters['unsigned short'] = function (V, prefix, argument, opts) {\n  // 1. Let x be ? ConvertToInt(V, 16, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 16, 'unsigned', opts, prefix, argument)\n\n  // 2. Return the IDL unsigned short value that represents\n  //    the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#idl-ArrayBuffer\nwebidl.converters.ArrayBuffer = function (V, prefix, argument, opts) {\n  // 1. If Type(V) is not Object, or V does not have an\n  //    [[ArrayBufferData]] internal slot, then throw a\n  //    TypeError.\n  // see: https://tc39.es/ecma262/#sec-properties-of-the-arraybuffer-instances\n  // see: https://tc39.es/ecma262/#sec-properties-of-the-sharedarraybuffer-instances\n  if (\n    webidl.util.Type(V) !== 'Object' ||\n    !types.isAnyArrayBuffer(V)\n  ) {\n    throw webidl.errors.conversionFailed({\n      prefix,\n      argument: `${argument} (\"${webidl.util.Stringify(V)}\")`,\n      types: ['ArrayBuffer']\n    })\n  }\n\n  // 2. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V) is true, then throw a\n  //    TypeError.\n  if (opts?.allowShared === false && types.isSharedArrayBuffer(V)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V) is true, then throw a\n  //    TypeError.\n  if (V.resizable || V.growable) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'Received a resizable ArrayBuffer.'\n    })\n  }\n\n  // 4. Return the IDL ArrayBuffer value that is a\n  //    reference to the same object as V.\n  return V\n}\n\nwebidl.converters.TypedArray = function (V, T, prefix, name, opts) {\n  // 1. Let T be the IDL type V is being converted to.\n\n  // 2. If Type(V) is not Object, or V does not have a\n  //    [[TypedArrayName]] internal slot with a value\n  //    equal to Ts name, then throw a TypeError.\n  if (\n    webidl.util.Type(V) !== 'Object' ||\n    !types.isTypedArray(V) ||\n    V.constructor.name !== T.name\n  ) {\n    throw webidl.errors.conversionFailed({\n      prefix,\n      argument: `${name} (\"${webidl.util.Stringify(V)}\")`,\n      types: [T.name]\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  if (opts?.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 4. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  if (V.buffer.resizable || V.buffer.growable) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'Received a resizable ArrayBuffer.'\n    })\n  }\n\n  // 5. Return the IDL value of type T that is a reference\n  //    to the same object as V.\n  return V\n}\n\nwebidl.converters.DataView = function (V, prefix, name, opts) {\n  // 1. If Type(V) is not Object, or V does not have a\n  //    [[DataView]] internal slot, then throw a TypeError.\n  if (webidl.util.Type(V) !== 'Object' || !types.isDataView(V)) {\n    throw webidl.errors.exception({\n      header: prefix,\n      message: `${name} is not a DataView.`\n    })\n  }\n\n  // 2. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is true,\n  //    then throw a TypeError.\n  if (opts?.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  if (V.buffer.resizable || V.buffer.growable) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'Received a resizable ArrayBuffer.'\n    })\n  }\n\n  // 4. Return the IDL DataView value that is a reference\n  //    to the same object as V.\n  return V\n}\n\n// https://webidl.spec.whatwg.org/#BufferSource\nwebidl.converters.BufferSource = function (V, prefix, name, opts) {\n  if (types.isAnyArrayBuffer(V)) {\n    return webidl.converters.ArrayBuffer(V, prefix, name, { ...opts, allowShared: false })\n  }\n\n  if (types.isTypedArray(V)) {\n    return webidl.converters.TypedArray(V, V.constructor, prefix, name, { ...opts, allowShared: false })\n  }\n\n  if (types.isDataView(V)) {\n    return webidl.converters.DataView(V, prefix, name, { ...opts, allowShared: false })\n  }\n\n  throw webidl.errors.conversionFailed({\n    prefix,\n    argument: `${name} (\"${webidl.util.Stringify(V)}\")`,\n    types: ['BufferSource']\n  })\n}\n\nwebidl.converters['sequence<ByteString>'] = webidl.sequenceConverter(\n  webidl.converters.ByteString\n)\n\nwebidl.converters['sequence<sequence<ByteString>>'] = webidl.sequenceConverter(\n  webidl.converters['sequence<ByteString>']\n)\n\nwebidl.converters['record<ByteString, ByteString>'] = webidl.recordConverter(\n  webidl.converters.ByteString,\n  webidl.converters.ByteString\n)\n\nmodule.exports = {\n  webidl\n}\n","'use strict'\n\n/**\n * @see https://encoding.spec.whatwg.org/#concept-encoding-get\n * @param {string|undefined} label\n */\nfunction getEncoding (label) {\n  if (!label) {\n    return 'failure'\n  }\n\n  // 1. Remove any leading and trailing ASCII whitespace from label.\n  // 2. If label is an ASCII case-insensitive match for any of the\n  //    labels listed in the table below, then return the\n  //    corresponding encoding; otherwise return failure.\n  switch (label.trim().toLowerCase()) {\n    case 'unicode-1-1-utf-8':\n    case 'unicode11utf8':\n    case 'unicode20utf8':\n    case 'utf-8':\n    case 'utf8':\n    case 'x-unicode20utf8':\n      return 'UTF-8'\n    case '866':\n    case 'cp866':\n    case 'csibm866':\n    case 'ibm866':\n      return 'IBM866'\n    case 'csisolatin2':\n    case 'iso-8859-2':\n    case 'iso-ir-101':\n    case 'iso8859-2':\n    case 'iso88592':\n    case 'iso_8859-2':\n    case 'iso_8859-2:1987':\n    case 'l2':\n    case 'latin2':\n      return 'ISO-8859-2'\n    case 'csisolatin3':\n    case 'iso-8859-3':\n    case 'iso-ir-109':\n    case 'iso8859-3':\n    case 'iso88593':\n    case 'iso_8859-3':\n    case 'iso_8859-3:1988':\n    case 'l3':\n    case 'latin3':\n      return 'ISO-8859-3'\n    case 'csisolatin4':\n    case 'iso-8859-4':\n    case 'iso-ir-110':\n    case 'iso8859-4':\n    case 'iso88594':\n    case 'iso_8859-4':\n    case 'iso_8859-4:1988':\n    case 'l4':\n    case 'latin4':\n      return 'ISO-8859-4'\n    case 'csisolatincyrillic':\n    case 'cyrillic':\n    case 'iso-8859-5':\n    case 'iso-ir-144':\n    case 'iso8859-5':\n    case 'iso88595':\n    case 'iso_8859-5':\n    case 'iso_8859-5:1988':\n      return 'ISO-8859-5'\n    case 'arabic':\n    case 'asmo-708':\n    case 'csiso88596e':\n    case 'csiso88596i':\n    case 'csisolatinarabic':\n    case 'ecma-114':\n    case 'iso-8859-6':\n    case 'iso-8859-6-e':\n    case 'iso-8859-6-i':\n    case 'iso-ir-127':\n    case 'iso8859-6':\n    case 'iso88596':\n    case 'iso_8859-6':\n    case 'iso_8859-6:1987':\n      return 'ISO-8859-6'\n    case 'csisolatingreek':\n    case 'ecma-118':\n    case 'elot_928':\n    case 'greek':\n    case 'greek8':\n    case 'iso-8859-7':\n    case 'iso-ir-126':\n    case 'iso8859-7':\n    case 'iso88597':\n    case 'iso_8859-7':\n    case 'iso_8859-7:1987':\n    case 'sun_eu_greek':\n      return 'ISO-8859-7'\n    case 'csiso88598e':\n    case 'csisolatinhebrew':\n    case 'hebrew':\n    case 'iso-8859-8':\n    case 'iso-8859-8-e':\n    case 'iso-ir-138':\n    case 'iso8859-8':\n    case 'iso88598':\n    case 'iso_8859-8':\n    case 'iso_8859-8:1988':\n    case 'visual':\n      return 'ISO-8859-8'\n    case 'csiso88598i':\n    case 'iso-8859-8-i':\n    case 'logical':\n      return 'ISO-8859-8-I'\n    case 'csisolatin6':\n    case 'iso-8859-10':\n    case 'iso-ir-157':\n    case 'iso8859-10':\n    case 'iso885910':\n    case 'l6':\n    case 'latin6':\n      return 'ISO-8859-10'\n    case 'iso-8859-13':\n    case 'iso8859-13':\n    case 'iso885913':\n      return 'ISO-8859-13'\n    case 'iso-8859-14':\n    case 'iso8859-14':\n    case 'iso885914':\n      return 'ISO-8859-14'\n    case 'csisolatin9':\n    case 'iso-8859-15':\n    case 'iso8859-15':\n    case 'iso885915':\n    case 'iso_8859-15':\n    case 'l9':\n      return 'ISO-8859-15'\n    case 'iso-8859-16':\n      return 'ISO-8859-16'\n    case 'cskoi8r':\n    case 'koi':\n    case 'koi8':\n    case 'koi8-r':\n    case 'koi8_r':\n      return 'KOI8-R'\n    case 'koi8-ru':\n    case 'koi8-u':\n      return 'KOI8-U'\n    case 'csmacintosh':\n    case 'mac':\n    case 'macintosh':\n    case 'x-mac-roman':\n      return 'macintosh'\n    case 'iso-8859-11':\n    case 'iso8859-11':\n    case 'iso885911':\n    case 'tis-620':\n    case 'windows-874':\n      return 'windows-874'\n    case 'cp1250':\n    case 'windows-1250':\n    case 'x-cp1250':\n      return 'windows-1250'\n    case 'cp1251':\n    case 'windows-1251':\n    case 'x-cp1251':\n      return 'windows-1251'\n    case 'ansi_x3.4-1968':\n    case 'ascii':\n    case 'cp1252':\n    case 'cp819':\n    case 'csisolatin1':\n    case 'ibm819':\n    case 'iso-8859-1':\n    case 'iso-ir-100':\n    case 'iso8859-1':\n    case 'iso88591':\n    case 'iso_8859-1':\n    case 'iso_8859-1:1987':\n    case 'l1':\n    case 'latin1':\n    case 'us-ascii':\n    case 'windows-1252':\n    case 'x-cp1252':\n      return 'windows-1252'\n    case 'cp1253':\n    case 'windows-1253':\n    case 'x-cp1253':\n      return 'windows-1253'\n    case 'cp1254':\n    case 'csisolatin5':\n    case 'iso-8859-9':\n    case 'iso-ir-148':\n    case 'iso8859-9':\n    case 'iso88599':\n    case 'iso_8859-9':\n    case 'iso_8859-9:1989':\n    case 'l5':\n    case 'latin5':\n    case 'windows-1254':\n    case 'x-cp1254':\n      return 'windows-1254'\n    case 'cp1255':\n    case 'windows-1255':\n    case 'x-cp1255':\n      return 'windows-1255'\n    case 'cp1256':\n    case 'windows-1256':\n    case 'x-cp1256':\n      return 'windows-1256'\n    case 'cp1257':\n    case 'windows-1257':\n    case 'x-cp1257':\n      return 'windows-1257'\n    case 'cp1258':\n    case 'windows-1258':\n    case 'x-cp1258':\n      return 'windows-1258'\n    case 'x-mac-cyrillic':\n    case 'x-mac-ukrainian':\n      return 'x-mac-cyrillic'\n    case 'chinese':\n    case 'csgb2312':\n    case 'csiso58gb231280':\n    case 'gb2312':\n    case 'gb_2312':\n    case 'gb_2312-80':\n    case 'gbk':\n    case 'iso-ir-58':\n    case 'x-gbk':\n      return 'GBK'\n    case 'gb18030':\n      return 'gb18030'\n    case 'big5':\n    case 'big5-hkscs':\n    case 'cn-big5':\n    case 'csbig5':\n    case 'x-x-big5':\n      return 'Big5'\n    case 'cseucpkdfmtjapanese':\n    case 'euc-jp':\n    case 'x-euc-jp':\n      return 'EUC-JP'\n    case 'csiso2022jp':\n    case 'iso-2022-jp':\n      return 'ISO-2022-JP'\n    case 'csshiftjis':\n    case 'ms932':\n    case 'ms_kanji':\n    case 'shift-jis':\n    case 'shift_jis':\n    case 'sjis':\n    case 'windows-31j':\n    case 'x-sjis':\n      return 'Shift_JIS'\n    case 'cseuckr':\n    case 'csksc56011987':\n    case 'euc-kr':\n    case 'iso-ir-149':\n    case 'korean':\n    case 'ks_c_5601-1987':\n    case 'ks_c_5601-1989':\n    case 'ksc5601':\n    case 'ksc_5601':\n    case 'windows-949':\n      return 'EUC-KR'\n    case 'csiso2022kr':\n    case 'hz-gb-2312':\n    case 'iso-2022-cn':\n    case 'iso-2022-cn-ext':\n    case 'iso-2022-kr':\n    case 'replacement':\n      return 'replacement'\n    case 'unicodefffe':\n    case 'utf-16be':\n      return 'UTF-16BE'\n    case 'csunicode':\n    case 'iso-10646-ucs-2':\n    case 'ucs-2':\n    case 'unicode':\n    case 'unicodefeff':\n    case 'utf-16':\n    case 'utf-16le':\n      return 'UTF-16LE'\n    case 'x-user-defined':\n      return 'x-user-defined'\n    default: return 'failure'\n  }\n}\n\nmodule.exports = {\n  getEncoding\n}\n","'use strict'\n\nconst {\n  staticPropertyDescriptors,\n  readOperation,\n  fireAProgressEvent\n} = require('./util')\nconst {\n  kState,\n  kError,\n  kResult,\n  kEvents,\n  kAborted\n} = require('./symbols')\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../../core/util')\n\nclass FileReader extends EventTarget {\n  constructor () {\n    super()\n\n    this[kState] = 'empty'\n    this[kResult] = null\n    this[kError] = null\n    this[kEvents] = {\n      loadend: null,\n      error: null,\n      abort: null,\n      load: null,\n      progress: null,\n      loadstart: null\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-readAsArrayBuffer\n   * @param {import('buffer').Blob} blob\n   */\n  readAsArrayBuffer (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, 'FileReader.readAsArrayBuffer')\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsArrayBuffer(blob) method, when invoked,\n    // must initiate a read operation for blob with ArrayBuffer.\n    readOperation(this, blob, 'ArrayBuffer')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#readAsBinaryString\n   * @param {import('buffer').Blob} blob\n   */\n  readAsBinaryString (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, 'FileReader.readAsBinaryString')\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsBinaryString(blob) method, when invoked,\n    // must initiate a read operation for blob with BinaryString.\n    readOperation(this, blob, 'BinaryString')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#readAsDataText\n   * @param {import('buffer').Blob} blob\n   * @param {string?} encoding\n   */\n  readAsText (blob, encoding = undefined) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, 'FileReader.readAsText')\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    if (encoding !== undefined) {\n      encoding = webidl.converters.DOMString(encoding, 'FileReader.readAsText', 'encoding')\n    }\n\n    // The readAsText(blob, encoding) method, when invoked,\n    // must initiate a read operation for blob with Text and encoding.\n    readOperation(this, blob, 'Text', encoding)\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-readAsDataURL\n   * @param {import('buffer').Blob} blob\n   */\n  readAsDataURL (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, 'FileReader.readAsDataURL')\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsDataURL(blob) method, when invoked, must\n    // initiate a read operation for blob with DataURL.\n    readOperation(this, blob, 'DataURL')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-abort\n   */\n  abort () {\n    // 1. If this's state is \"empty\" or if this's state is\n    //    \"done\" set this's result to null and terminate\n    //    this algorithm.\n    if (this[kState] === 'empty' || this[kState] === 'done') {\n      this[kResult] = null\n      return\n    }\n\n    // 2. If this's state is \"loading\" set this's state to\n    //    \"done\" and set this's result to null.\n    if (this[kState] === 'loading') {\n      this[kState] = 'done'\n      this[kResult] = null\n    }\n\n    // 3. If there are any tasks from this on the file reading\n    //    task source in an affiliated task queue, then remove\n    //    those tasks from that task queue.\n    this[kAborted] = true\n\n    // 4. Terminate the algorithm for the read method being processed.\n    // TODO\n\n    // 5. Fire a progress event called abort at this.\n    fireAProgressEvent('abort', this)\n\n    // 6. If this's state is not \"loading\", fire a progress\n    //    event called loadend at this.\n    if (this[kState] !== 'loading') {\n      fireAProgressEvent('loadend', this)\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-readystate\n   */\n  get readyState () {\n    webidl.brandCheck(this, FileReader)\n\n    switch (this[kState]) {\n      case 'empty': return this.EMPTY\n      case 'loading': return this.LOADING\n      case 'done': return this.DONE\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-result\n   */\n  get result () {\n    webidl.brandCheck(this, FileReader)\n\n    // The result attributes getter, when invoked, must return\n    // this's result.\n    return this[kResult]\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-error\n   */\n  get error () {\n    webidl.brandCheck(this, FileReader)\n\n    // The error attributes getter, when invoked, must return\n    // this's error.\n    return this[kError]\n  }\n\n  get onloadend () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].loadend\n  }\n\n  set onloadend (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].loadend) {\n      this.removeEventListener('loadend', this[kEvents].loadend)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].loadend = fn\n      this.addEventListener('loadend', fn)\n    } else {\n      this[kEvents].loadend = null\n    }\n  }\n\n  get onerror () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].error\n  }\n\n  set onerror (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].error) {\n      this.removeEventListener('error', this[kEvents].error)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].error = fn\n      this.addEventListener('error', fn)\n    } else {\n      this[kEvents].error = null\n    }\n  }\n\n  get onloadstart () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].loadstart\n  }\n\n  set onloadstart (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].loadstart) {\n      this.removeEventListener('loadstart', this[kEvents].loadstart)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].loadstart = fn\n      this.addEventListener('loadstart', fn)\n    } else {\n      this[kEvents].loadstart = null\n    }\n  }\n\n  get onprogress () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].progress\n  }\n\n  set onprogress (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].progress) {\n      this.removeEventListener('progress', this[kEvents].progress)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].progress = fn\n      this.addEventListener('progress', fn)\n    } else {\n      this[kEvents].progress = null\n    }\n  }\n\n  get onload () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].load\n  }\n\n  set onload (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].load) {\n      this.removeEventListener('load', this[kEvents].load)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].load = fn\n      this.addEventListener('load', fn)\n    } else {\n      this[kEvents].load = null\n    }\n  }\n\n  get onabort () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].abort\n  }\n\n  set onabort (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].abort) {\n      this.removeEventListener('abort', this[kEvents].abort)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].abort = fn\n      this.addEventListener('abort', fn)\n    } else {\n      this[kEvents].abort = null\n    }\n  }\n}\n\n// https://w3c.github.io/FileAPI/#dom-filereader-empty\nFileReader.EMPTY = FileReader.prototype.EMPTY = 0\n// https://w3c.github.io/FileAPI/#dom-filereader-loading\nFileReader.LOADING = FileReader.prototype.LOADING = 1\n// https://w3c.github.io/FileAPI/#dom-filereader-done\nFileReader.DONE = FileReader.prototype.DONE = 2\n\nObject.defineProperties(FileReader.prototype, {\n  EMPTY: staticPropertyDescriptors,\n  LOADING: staticPropertyDescriptors,\n  DONE: staticPropertyDescriptors,\n  readAsArrayBuffer: kEnumerableProperty,\n  readAsBinaryString: kEnumerableProperty,\n  readAsText: kEnumerableProperty,\n  readAsDataURL: kEnumerableProperty,\n  abort: kEnumerableProperty,\n  readyState: kEnumerableProperty,\n  result: kEnumerableProperty,\n  error: kEnumerableProperty,\n  onloadstart: kEnumerableProperty,\n  onprogress: kEnumerableProperty,\n  onload: kEnumerableProperty,\n  onabort: kEnumerableProperty,\n  onerror: kEnumerableProperty,\n  onloadend: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'FileReader',\n    writable: false,\n    enumerable: false,\n    configurable: true\n  }\n})\n\nObject.defineProperties(FileReader, {\n  EMPTY: staticPropertyDescriptors,\n  LOADING: staticPropertyDescriptors,\n  DONE: staticPropertyDescriptors\n})\n\nmodule.exports = {\n  FileReader\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\n\nconst kState = Symbol('ProgressEvent state')\n\n/**\n * @see https://xhr.spec.whatwg.org/#progressevent\n */\nclass ProgressEvent extends Event {\n  constructor (type, eventInitDict = {}) {\n    type = webidl.converters.DOMString(type, 'ProgressEvent constructor', 'type')\n    eventInitDict = webidl.converters.ProgressEventInit(eventInitDict ?? {})\n\n    super(type, eventInitDict)\n\n    this[kState] = {\n      lengthComputable: eventInitDict.lengthComputable,\n      loaded: eventInitDict.loaded,\n      total: eventInitDict.total\n    }\n  }\n\n  get lengthComputable () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].lengthComputable\n  }\n\n  get loaded () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].loaded\n  }\n\n  get total () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].total\n  }\n}\n\nwebidl.converters.ProgressEventInit = webidl.dictionaryConverter([\n  {\n    key: 'lengthComputable',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'loaded',\n    converter: webidl.converters['unsigned long long'],\n    defaultValue: () => 0\n  },\n  {\n    key: 'total',\n    converter: webidl.converters['unsigned long long'],\n    defaultValue: () => 0\n  },\n  {\n    key: 'bubbles',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'cancelable',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'composed',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  }\n])\n\nmodule.exports = {\n  ProgressEvent\n}\n","'use strict'\n\nmodule.exports = {\n  kState: Symbol('FileReader state'),\n  kResult: Symbol('FileReader result'),\n  kError: Symbol('FileReader error'),\n  kLastProgressEventFired: Symbol('FileReader last progress event fired timestamp'),\n  kEvents: Symbol('FileReader events'),\n  kAborted: Symbol('FileReader aborted')\n}\n","'use strict'\n\nconst {\n  kState,\n  kError,\n  kResult,\n  kAborted,\n  kLastProgressEventFired\n} = require('./symbols')\nconst { ProgressEvent } = require('./progressevent')\nconst { getEncoding } = require('./encoding')\nconst { serializeAMimeType, parseMIMEType } = require('../fetch/data-url')\nconst { types } = require('node:util')\nconst { StringDecoder } = require('string_decoder')\nconst { btoa } = require('node:buffer')\n\n/** @type {PropertyDescriptor} */\nconst staticPropertyDescriptors = {\n  enumerable: true,\n  writable: false,\n  configurable: false\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#readOperation\n * @param {import('./filereader').FileReader} fr\n * @param {import('buffer').Blob} blob\n * @param {string} type\n * @param {string?} encodingName\n */\nfunction readOperation (fr, blob, type, encodingName) {\n  // 1. If frs state is \"loading\", throw an InvalidStateError\n  //    DOMException.\n  if (fr[kState] === 'loading') {\n    throw new DOMException('Invalid state', 'InvalidStateError')\n  }\n\n  // 2. Set frs state to \"loading\".\n  fr[kState] = 'loading'\n\n  // 3. Set frs result to null.\n  fr[kResult] = null\n\n  // 4. Set frs error to null.\n  fr[kError] = null\n\n  // 5. Let stream be the result of calling get stream on blob.\n  /** @type {import('stream/web').ReadableStream} */\n  const stream = blob.stream()\n\n  // 6. Let reader be the result of getting a reader from stream.\n  const reader = stream.getReader()\n\n  // 7. Let bytes be an empty byte sequence.\n  /** @type {Uint8Array[]} */\n  const bytes = []\n\n  // 8. Let chunkPromise be the result of reading a chunk from\n  //    stream with reader.\n  let chunkPromise = reader.read()\n\n  // 9. Let isFirstChunk be true.\n  let isFirstChunk = true\n\n  // 10. In parallel, while true:\n  // Note: \"In parallel\" just means non-blocking\n  // Note 2: readOperation itself cannot be async as double\n  // reading the body would then reject the promise, instead\n  // of throwing an error.\n  ;(async () => {\n    while (!fr[kAborted]) {\n      // 1. Wait for chunkPromise to be fulfilled or rejected.\n      try {\n        const { done, value } = await chunkPromise\n\n        // 2. If chunkPromise is fulfilled, and isFirstChunk is\n        //    true, queue a task to fire a progress event called\n        //    loadstart at fr.\n        if (isFirstChunk && !fr[kAborted]) {\n          queueMicrotask(() => {\n            fireAProgressEvent('loadstart', fr)\n          })\n        }\n\n        // 3. Set isFirstChunk to false.\n        isFirstChunk = false\n\n        // 4. If chunkPromise is fulfilled with an object whose\n        //    done property is false and whose value property is\n        //    a Uint8Array object, run these steps:\n        if (!done && types.isUint8Array(value)) {\n          // 1. Let bs be the byte sequence represented by the\n          //    Uint8Array object.\n\n          // 2. Append bs to bytes.\n          bytes.push(value)\n\n          // 3. If roughly 50ms have passed since these steps\n          //    were last invoked, queue a task to fire a\n          //    progress event called progress at fr.\n          if (\n            (\n              fr[kLastProgressEventFired] === undefined ||\n              Date.now() - fr[kLastProgressEventFired] >= 50\n            ) &&\n            !fr[kAborted]\n          ) {\n            fr[kLastProgressEventFired] = Date.now()\n            queueMicrotask(() => {\n              fireAProgressEvent('progress', fr)\n            })\n          }\n\n          // 4. Set chunkPromise to the result of reading a\n          //    chunk from stream with reader.\n          chunkPromise = reader.read()\n        } else if (done) {\n          // 5. Otherwise, if chunkPromise is fulfilled with an\n          //    object whose done property is true, queue a task\n          //    to run the following steps and abort this algorithm:\n          queueMicrotask(() => {\n            // 1. Set frs state to \"done\".\n            fr[kState] = 'done'\n\n            // 2. Let result be the result of package data given\n            //    bytes, type, blobs type, and encodingName.\n            try {\n              const result = packageData(bytes, type, blob.type, encodingName)\n\n              // 4. Else:\n\n              if (fr[kAborted]) {\n                return\n              }\n\n              // 1. Set frs result to result.\n              fr[kResult] = result\n\n              // 2. Fire a progress event called load at the fr.\n              fireAProgressEvent('load', fr)\n            } catch (error) {\n              // 3. If package data threw an exception error:\n\n              // 1. Set frs error to error.\n              fr[kError] = error\n\n              // 2. Fire a progress event called error at fr.\n              fireAProgressEvent('error', fr)\n            }\n\n            // 5. If frs state is not \"loading\", fire a progress\n            //    event called loadend at the fr.\n            if (fr[kState] !== 'loading') {\n              fireAProgressEvent('loadend', fr)\n            }\n          })\n\n          break\n        }\n      } catch (error) {\n        if (fr[kAborted]) {\n          return\n        }\n\n        // 6. Otherwise, if chunkPromise is rejected with an\n        //    error error, queue a task to run the following\n        //    steps and abort this algorithm:\n        queueMicrotask(() => {\n          // 1. Set frs state to \"done\".\n          fr[kState] = 'done'\n\n          // 2. Set frs error to error.\n          fr[kError] = error\n\n          // 3. Fire a progress event called error at fr.\n          fireAProgressEvent('error', fr)\n\n          // 4. If frs state is not \"loading\", fire a progress\n          //    event called loadend at fr.\n          if (fr[kState] !== 'loading') {\n            fireAProgressEvent('loadend', fr)\n          }\n        })\n\n        break\n      }\n    }\n  })()\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#fire-a-progress-event\n * @see https://dom.spec.whatwg.org/#concept-event-fire\n * @param {string} e The name of the event\n * @param {import('./filereader').FileReader} reader\n */\nfunction fireAProgressEvent (e, reader) {\n  // The progress event e does not bubble. e.bubbles must be false\n  // The progress event e is NOT cancelable. e.cancelable must be false\n  const event = new ProgressEvent(e, {\n    bubbles: false,\n    cancelable: false\n  })\n\n  reader.dispatchEvent(event)\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#blob-package-data\n * @param {Uint8Array[]} bytes\n * @param {string} type\n * @param {string?} mimeType\n * @param {string?} encodingName\n */\nfunction packageData (bytes, type, mimeType, encodingName) {\n  // 1. A Blob has an associated package data algorithm, given\n  //    bytes, a type, a optional mimeType, and a optional\n  //    encodingName, which switches on type and runs the\n  //    associated steps:\n\n  switch (type) {\n    case 'DataURL': {\n      // 1. Return bytes as a DataURL [RFC2397] subject to\n      //    the considerations below:\n      //  * Use mimeType as part of the Data URL if it is\n      //    available in keeping with the Data URL\n      //    specification [RFC2397].\n      //  * If mimeType is not available return a Data URL\n      //    without a media-type. [RFC2397].\n\n      // https://datatracker.ietf.org/doc/html/rfc2397#section-3\n      // dataurl    := \"data:\" [ mediatype ] [ \";base64\" ] \",\" data\n      // mediatype  := [ type \"/\" subtype ] *( \";\" parameter )\n      // data       := *urlchar\n      // parameter  := attribute \"=\" value\n      let dataURL = 'data:'\n\n      const parsed = parseMIMEType(mimeType || 'application/octet-stream')\n\n      if (parsed !== 'failure') {\n        dataURL += serializeAMimeType(parsed)\n      }\n\n      dataURL += ';base64,'\n\n      const decoder = new StringDecoder('latin1')\n\n      for (const chunk of bytes) {\n        dataURL += btoa(decoder.write(chunk))\n      }\n\n      dataURL += btoa(decoder.end())\n\n      return dataURL\n    }\n    case 'Text': {\n      // 1. Let encoding be failure\n      let encoding = 'failure'\n\n      // 2. If the encodingName is present, set encoding to the\n      //    result of getting an encoding from encodingName.\n      if (encodingName) {\n        encoding = getEncoding(encodingName)\n      }\n\n      // 3. If encoding is failure, and mimeType is present:\n      if (encoding === 'failure' && mimeType) {\n        // 1. Let type be the result of parse a MIME type\n        //    given mimeType.\n        const type = parseMIMEType(mimeType)\n\n        // 2. If type is not failure, set encoding to the result\n        //    of getting an encoding from types parameters[\"charset\"].\n        if (type !== 'failure') {\n          encoding = getEncoding(type.parameters.get('charset'))\n        }\n      }\n\n      // 4. If encoding is failure, then set encoding to UTF-8.\n      if (encoding === 'failure') {\n        encoding = 'UTF-8'\n      }\n\n      // 5. Decode bytes using fallback encoding encoding, and\n      //    return the result.\n      return decode(bytes, encoding)\n    }\n    case 'ArrayBuffer': {\n      // Return a new ArrayBuffer whose contents are bytes.\n      const sequence = combineByteSequences(bytes)\n\n      return sequence.buffer\n    }\n    case 'BinaryString': {\n      // Return bytes as a binary string, in which every byte\n      //  is represented by a code unit of equal value [0..255].\n      let binaryString = ''\n\n      const decoder = new StringDecoder('latin1')\n\n      for (const chunk of bytes) {\n        binaryString += decoder.write(chunk)\n      }\n\n      binaryString += decoder.end()\n\n      return binaryString\n    }\n  }\n}\n\n/**\n * @see https://encoding.spec.whatwg.org/#decode\n * @param {Uint8Array[]} ioQueue\n * @param {string} encoding\n */\nfunction decode (ioQueue, encoding) {\n  const bytes = combineByteSequences(ioQueue)\n\n  // 1. Let BOMEncoding be the result of BOM sniffing ioQueue.\n  const BOMEncoding = BOMSniffing(bytes)\n\n  let slice = 0\n\n  // 2. If BOMEncoding is non-null:\n  if (BOMEncoding !== null) {\n    // 1. Set encoding to BOMEncoding.\n    encoding = BOMEncoding\n\n    // 2. Read three bytes from ioQueue, if BOMEncoding is\n    //    UTF-8; otherwise read two bytes.\n    //    (Do nothing with those bytes.)\n    slice = BOMEncoding === 'UTF-8' ? 3 : 2\n  }\n\n  // 3. Process a queue with an instance of encodings\n  //    decoder, ioQueue, output, and \"replacement\".\n\n  // 4. Return output.\n\n  const sliced = bytes.slice(slice)\n  return new TextDecoder(encoding).decode(sliced)\n}\n\n/**\n * @see https://encoding.spec.whatwg.org/#bom-sniff\n * @param {Uint8Array} ioQueue\n */\nfunction BOMSniffing (ioQueue) {\n  // 1. Let BOM be the result of peeking 3 bytes from ioQueue,\n  //    converted to a byte sequence.\n  const [a, b, c] = ioQueue\n\n  // 2. For each of the rows in the table below, starting with\n  //    the first one and going down, if BOM starts with the\n  //    bytes given in the first column, then return the\n  //    encoding given in the cell in the second column of that\n  //    row. Otherwise, return null.\n  if (a === 0xEF && b === 0xBB && c === 0xBF) {\n    return 'UTF-8'\n  } else if (a === 0xFE && b === 0xFF) {\n    return 'UTF-16BE'\n  } else if (a === 0xFF && b === 0xFE) {\n    return 'UTF-16LE'\n  }\n\n  return null\n}\n\n/**\n * @param {Uint8Array[]} sequences\n */\nfunction combineByteSequences (sequences) {\n  const size = sequences.reduce((a, b) => {\n    return a + b.byteLength\n  }, 0)\n\n  let offset = 0\n\n  return sequences.reduce((a, b) => {\n    a.set(b, offset)\n    offset += b.byteLength\n    return a\n  }, new Uint8Array(size))\n}\n\nmodule.exports = {\n  staticPropertyDescriptors,\n  readOperation,\n  fireAProgressEvent\n}\n","'use strict'\n\nconst { uid, states, sentCloseFrameState, emptyBuffer, opcodes } = require('./constants')\nconst {\n  kReadyState,\n  kSentClose,\n  kByteParser,\n  kReceivedClose,\n  kResponse\n} = require('./symbols')\nconst { fireEvent, failWebsocketConnection, isClosing, isClosed, isEstablished, parseExtensions } = require('./util')\nconst { channels } = require('../../core/diagnostics')\nconst { CloseEvent } = require('./events')\nconst { makeRequest } = require('../fetch/request')\nconst { fetching } = require('../fetch/index')\nconst { Headers, getHeadersList } = require('../fetch/headers')\nconst { getDecodeSplit } = require('../fetch/util')\nconst { WebsocketFrameSend } = require('./frame')\n\n/** @type {import('crypto')} */\nlet crypto\ntry {\n  crypto = require('node:crypto')\n/* c8 ignore next 3 */\n} catch {\n\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#concept-websocket-establish\n * @param {URL} url\n * @param {string|string[]} protocols\n * @param {import('./websocket').WebSocket} ws\n * @param {(response: any, extensions: string[] | undefined) => void} onEstablish\n * @param {Partial<import('../../types/websocket').WebSocketInit>} options\n */\nfunction establishWebSocketConnection (url, protocols, client, ws, onEstablish, options) {\n  // 1. Let requestURL be a copy of url, with its scheme set to \"http\", if urls\n  //    scheme is \"ws\", and to \"https\" otherwise.\n  const requestURL = url\n\n  requestURL.protocol = url.protocol === 'ws:' ? 'http:' : 'https:'\n\n  // 2. Let request be a new request, whose URL is requestURL, client is client,\n  //    service-workers mode is \"none\", referrer is \"no-referrer\", mode is\n  //    \"websocket\", credentials mode is \"include\", cache mode is \"no-store\" ,\n  //    and redirect mode is \"error\".\n  const request = makeRequest({\n    urlList: [requestURL],\n    client,\n    serviceWorkers: 'none',\n    referrer: 'no-referrer',\n    mode: 'websocket',\n    credentials: 'include',\n    cache: 'no-store',\n    redirect: 'error'\n  })\n\n  // Note: undici extension, allow setting custom headers.\n  if (options.headers) {\n    const headersList = getHeadersList(new Headers(options.headers))\n\n    request.headersList = headersList\n  }\n\n  // 3. Append (`Upgrade`, `websocket`) to requests header list.\n  // 4. Append (`Connection`, `Upgrade`) to requests header list.\n  // Note: both of these are handled by undici currently.\n  // https://github.com/nodejs/undici/blob/68c269c4144c446f3f1220951338daef4a6b5ec4/lib/client.js#L1397\n\n  // 5. Let keyValue be a nonce consisting of a randomly selected\n  //    16-byte value that has been forgiving-base64-encoded and\n  //    isomorphic encoded.\n  const keyValue = crypto.randomBytes(16).toString('base64')\n\n  // 6. Append (`Sec-WebSocket-Key`, keyValue) to requests\n  //    header list.\n  request.headersList.append('sec-websocket-key', keyValue)\n\n  // 7. Append (`Sec-WebSocket-Version`, `13`) to requests\n  //    header list.\n  request.headersList.append('sec-websocket-version', '13')\n\n  // 8. For each protocol in protocols, combine\n  //    (`Sec-WebSocket-Protocol`, protocol) in requests header\n  //    list.\n  for (const protocol of protocols) {\n    request.headersList.append('sec-websocket-protocol', protocol)\n  }\n\n  // 9. Let permessageDeflate be a user-agent defined\n  //    \"permessage-deflate\" extension header value.\n  // https://github.com/mozilla/gecko-dev/blob/ce78234f5e653a5d3916813ff990f053510227bc/netwerk/protocol/websocket/WebSocketChannel.cpp#L2673\n  const permessageDeflate = 'permessage-deflate; client_max_window_bits'\n\n  // 10. Append (`Sec-WebSocket-Extensions`, permessageDeflate) to\n  //     requests header list.\n  request.headersList.append('sec-websocket-extensions', permessageDeflate)\n\n  // 11. Fetch request with useParallelQueue set to true, and\n  //     processResponse given response being these steps:\n  const controller = fetching({\n    request,\n    useParallelQueue: true,\n    dispatcher: options.dispatcher,\n    processResponse (response) {\n      // 1. If response is a network error or its status is not 101,\n      //    fail the WebSocket connection.\n      if (response.type === 'error' || response.status !== 101) {\n        failWebsocketConnection(ws, 'Received network error or non-101 status code.')\n        return\n      }\n\n      // 2. If protocols is not the empty list and extracting header\n      //    list values given `Sec-WebSocket-Protocol` and responses\n      //    header list results in null, failure, or the empty byte\n      //    sequence, then fail the WebSocket connection.\n      if (protocols.length !== 0 && !response.headersList.get('Sec-WebSocket-Protocol')) {\n        failWebsocketConnection(ws, 'Server did not respond with sent protocols.')\n        return\n      }\n\n      // 3. Follow the requirements stated step 2 to step 6, inclusive,\n      //    of the last set of steps in section 4.1 of The WebSocket\n      //    Protocol to validate response. This either results in fail\n      //    the WebSocket connection or the WebSocket connection is\n      //    established.\n\n      // 2. If the response lacks an |Upgrade| header field or the |Upgrade|\n      //    header field contains a value that is not an ASCII case-\n      //    insensitive match for the value \"websocket\", the client MUST\n      //    _Fail the WebSocket Connection_.\n      if (response.headersList.get('Upgrade')?.toLowerCase() !== 'websocket') {\n        failWebsocketConnection(ws, 'Server did not set Upgrade header to \"websocket\".')\n        return\n      }\n\n      // 3. If the response lacks a |Connection| header field or the\n      //    |Connection| header field doesn't contain a token that is an\n      //    ASCII case-insensitive match for the value \"Upgrade\", the client\n      //    MUST _Fail the WebSocket Connection_.\n      if (response.headersList.get('Connection')?.toLowerCase() !== 'upgrade') {\n        failWebsocketConnection(ws, 'Server did not set Connection header to \"upgrade\".')\n        return\n      }\n\n      // 4. If the response lacks a |Sec-WebSocket-Accept| header field or\n      //    the |Sec-WebSocket-Accept| contains a value other than the\n      //    base64-encoded SHA-1 of the concatenation of the |Sec-WebSocket-\n      //    Key| (as a string, not base64-decoded) with the string \"258EAFA5-\n      //    E914-47DA-95CA-C5AB0DC85B11\" but ignoring any leading and\n      //    trailing whitespace, the client MUST _Fail the WebSocket\n      //    Connection_.\n      const secWSAccept = response.headersList.get('Sec-WebSocket-Accept')\n      const digest = crypto.createHash('sha1').update(keyValue + uid).digest('base64')\n      if (secWSAccept !== digest) {\n        failWebsocketConnection(ws, 'Incorrect hash received in Sec-WebSocket-Accept header.')\n        return\n      }\n\n      // 5. If the response includes a |Sec-WebSocket-Extensions| header\n      //    field and this header field indicates the use of an extension\n      //    that was not present in the client's handshake (the server has\n      //    indicated an extension not requested by the client), the client\n      //    MUST _Fail the WebSocket Connection_.  (The parsing of this\n      //    header field to determine which extensions are requested is\n      //    discussed in Section 9.1.)\n      const secExtension = response.headersList.get('Sec-WebSocket-Extensions')\n      let extensions\n\n      if (secExtension !== null) {\n        extensions = parseExtensions(secExtension)\n\n        if (!extensions.has('permessage-deflate')) {\n          failWebsocketConnection(ws, 'Sec-WebSocket-Extensions header does not match.')\n          return\n        }\n      }\n\n      // 6. If the response includes a |Sec-WebSocket-Protocol| header field\n      //    and this header field indicates the use of a subprotocol that was\n      //    not present in the client's handshake (the server has indicated a\n      //    subprotocol not requested by the client), the client MUST _Fail\n      //    the WebSocket Connection_.\n      const secProtocol = response.headersList.get('Sec-WebSocket-Protocol')\n\n      if (secProtocol !== null) {\n        const requestProtocols = getDecodeSplit('sec-websocket-protocol', request.headersList)\n\n        // The client can request that the server use a specific subprotocol by\n        // including the |Sec-WebSocket-Protocol| field in its handshake.  If it\n        // is specified, the server needs to include the same field and one of\n        // the selected subprotocol values in its response for the connection to\n        // be established.\n        if (!requestProtocols.includes(secProtocol)) {\n          failWebsocketConnection(ws, 'Protocol was not set in the opening handshake.')\n          return\n        }\n      }\n\n      response.socket.on('data', onSocketData)\n      response.socket.on('close', onSocketClose)\n      response.socket.on('error', onSocketError)\n\n      if (channels.open.hasSubscribers) {\n        channels.open.publish({\n          address: response.socket.address(),\n          protocol: secProtocol,\n          extensions: secExtension\n        })\n      }\n\n      onEstablish(response, extensions)\n    }\n  })\n\n  return controller\n}\n\nfunction closeWebSocketConnection (ws, code, reason, reasonByteLength) {\n  if (isClosing(ws) || isClosed(ws)) {\n    // If this's ready state is CLOSING (2) or CLOSED (3)\n    // Do nothing.\n  } else if (!isEstablished(ws)) {\n    // If the WebSocket connection is not yet established\n    // Fail the WebSocket connection and set this's ready state\n    // to CLOSING (2).\n    failWebsocketConnection(ws, 'Connection was closed before it was established.')\n    ws[kReadyState] = states.CLOSING\n  } else if (ws[kSentClose] === sentCloseFrameState.NOT_SENT) {\n    // If the WebSocket closing handshake has not yet been started\n    // Start the WebSocket closing handshake and set this's ready\n    // state to CLOSING (2).\n    // - If neither code nor reason is present, the WebSocket Close\n    //   message must not have a body.\n    // - If code is present, then the status code to use in the\n    //   WebSocket Close message must be the integer given by code.\n    // - If reason is also present, then reasonBytes must be\n    //   provided in the Close message after the status code.\n\n    ws[kSentClose] = sentCloseFrameState.PROCESSING\n\n    const frame = new WebsocketFrameSend()\n\n    // If neither code nor reason is present, the WebSocket Close\n    // message must not have a body.\n\n    // If code is present, then the status code to use in the\n    // WebSocket Close message must be the integer given by code.\n    if (code !== undefined && reason === undefined) {\n      frame.frameData = Buffer.allocUnsafe(2)\n      frame.frameData.writeUInt16BE(code, 0)\n    } else if (code !== undefined && reason !== undefined) {\n      // If reason is also present, then reasonBytes must be\n      // provided in the Close message after the status code.\n      frame.frameData = Buffer.allocUnsafe(2 + reasonByteLength)\n      frame.frameData.writeUInt16BE(code, 0)\n      // the body MAY contain UTF-8-encoded data with value /reason/\n      frame.frameData.write(reason, 2, 'utf-8')\n    } else {\n      frame.frameData = emptyBuffer\n    }\n\n    /** @type {import('stream').Duplex} */\n    const socket = ws[kResponse].socket\n\n    socket.write(frame.createFrame(opcodes.CLOSE))\n\n    ws[kSentClose] = sentCloseFrameState.SENT\n\n    // Upon either sending or receiving a Close control frame, it is said\n    // that _The WebSocket Closing Handshake is Started_ and that the\n    // WebSocket connection is in the CLOSING state.\n    ws[kReadyState] = states.CLOSING\n  } else {\n    // Otherwise\n    // Set this's ready state to CLOSING (2).\n    ws[kReadyState] = states.CLOSING\n  }\n}\n\n/**\n * @param {Buffer} chunk\n */\nfunction onSocketData (chunk) {\n  if (!this.ws[kByteParser].write(chunk)) {\n    this.pause()\n  }\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.4\n */\nfunction onSocketClose () {\n  const { ws } = this\n  const { [kResponse]: response } = ws\n\n  response.socket.off('data', onSocketData)\n  response.socket.off('close', onSocketClose)\n  response.socket.off('error', onSocketError)\n\n  // If the TCP connection was closed after the\n  // WebSocket closing handshake was completed, the WebSocket connection\n  // is said to have been closed _cleanly_.\n  const wasClean = ws[kSentClose] === sentCloseFrameState.SENT && ws[kReceivedClose]\n\n  let code = 1005\n  let reason = ''\n\n  const result = ws[kByteParser].closingInfo\n\n  if (result && !result.error) {\n    code = result.code ?? 1005\n    reason = result.reason\n  } else if (!ws[kReceivedClose]) {\n    // If _The WebSocket\n    // Connection is Closed_ and no Close control frame was received by the\n    // endpoint (such as could occur if the underlying transport connection\n    // is lost), _The WebSocket Connection Close Code_ is considered to be\n    // 1006.\n    code = 1006\n  }\n\n  // 1. Change the ready state to CLOSED (3).\n  ws[kReadyState] = states.CLOSED\n\n  // 2. If the user agent was required to fail the WebSocket\n  //    connection, or if the WebSocket connection was closed\n  //    after being flagged as full, fire an event named error\n  //    at the WebSocket object.\n  // TODO\n\n  // 3. Fire an event named close at the WebSocket object,\n  //    using CloseEvent, with the wasClean attribute\n  //    initialized to true if the connection closed cleanly\n  //    and false otherwise, the code attribute initialized to\n  //    the WebSocket connection close code, and the reason\n  //    attribute initialized to the result of applying UTF-8\n  //    decode without BOM to the WebSocket connection close\n  //    reason.\n  // TODO: process.nextTick\n  fireEvent('close', ws, (type, init) => new CloseEvent(type, init), {\n    wasClean, code, reason\n  })\n\n  if (channels.close.hasSubscribers) {\n    channels.close.publish({\n      websocket: ws,\n      code,\n      reason\n    })\n  }\n}\n\nfunction onSocketError (error) {\n  const { ws } = this\n\n  ws[kReadyState] = states.CLOSING\n\n  if (channels.socketError.hasSubscribers) {\n    channels.socketError.publish(error)\n  }\n\n  this.destroy()\n}\n\nmodule.exports = {\n  establishWebSocketConnection,\n  closeWebSocketConnection\n}\n","'use strict'\n\n// This is a Globally Unique Identifier unique used\n// to validate that the endpoint accepts websocket\n// connections.\n// See https://www.rfc-editor.org/rfc/rfc6455.html#section-1.3\nconst uid = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11'\n\n/** @type {PropertyDescriptor} */\nconst staticPropertyDescriptors = {\n  enumerable: true,\n  writable: false,\n  configurable: false\n}\n\nconst states = {\n  CONNECTING: 0,\n  OPEN: 1,\n  CLOSING: 2,\n  CLOSED: 3\n}\n\nconst sentCloseFrameState = {\n  NOT_SENT: 0,\n  PROCESSING: 1,\n  SENT: 2\n}\n\nconst opcodes = {\n  CONTINUATION: 0x0,\n  TEXT: 0x1,\n  BINARY: 0x2,\n  CLOSE: 0x8,\n  PING: 0x9,\n  PONG: 0xA\n}\n\nconst maxUnsigned16Bit = 2 ** 16 - 1 // 65535\n\nconst parserStates = {\n  INFO: 0,\n  PAYLOADLENGTH_16: 2,\n  PAYLOADLENGTH_64: 3,\n  READ_DATA: 4\n}\n\nconst emptyBuffer = Buffer.allocUnsafe(0)\n\nconst sendHints = {\n  string: 1,\n  typedArray: 2,\n  arrayBuffer: 3,\n  blob: 4\n}\n\nmodule.exports = {\n  uid,\n  sentCloseFrameState,\n  staticPropertyDescriptors,\n  states,\n  opcodes,\n  maxUnsigned16Bit,\n  parserStates,\n  emptyBuffer,\n  sendHints\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../../core/util')\nconst { kConstruct } = require('../../core/symbols')\nconst { MessagePort } = require('node:worker_threads')\n\n/**\n * @see https://html.spec.whatwg.org/multipage/comms.html#messageevent\n */\nclass MessageEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict = {}) {\n    if (type === kConstruct) {\n      super(arguments[1], arguments[2])\n      webidl.util.markAsUncloneable(this)\n      return\n    }\n\n    const prefix = 'MessageEvent constructor'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    type = webidl.converters.DOMString(type, prefix, 'type')\n    eventInitDict = webidl.converters.MessageEventInit(eventInitDict, prefix, 'eventInitDict')\n\n    super(type, eventInitDict)\n\n    this.#eventInit = eventInitDict\n    webidl.util.markAsUncloneable(this)\n  }\n\n  get data () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.data\n  }\n\n  get origin () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.origin\n  }\n\n  get lastEventId () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.lastEventId\n  }\n\n  get source () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.source\n  }\n\n  get ports () {\n    webidl.brandCheck(this, MessageEvent)\n\n    if (!Object.isFrozen(this.#eventInit.ports)) {\n      Object.freeze(this.#eventInit.ports)\n    }\n\n    return this.#eventInit.ports\n  }\n\n  initMessageEvent (\n    type,\n    bubbles = false,\n    cancelable = false,\n    data = null,\n    origin = '',\n    lastEventId = '',\n    source = null,\n    ports = []\n  ) {\n    webidl.brandCheck(this, MessageEvent)\n\n    webidl.argumentLengthCheck(arguments, 1, 'MessageEvent.initMessageEvent')\n\n    return new MessageEvent(type, {\n      bubbles, cancelable, data, origin, lastEventId, source, ports\n    })\n  }\n\n  static createFastMessageEvent (type, init) {\n    const messageEvent = new MessageEvent(kConstruct, type, init)\n    messageEvent.#eventInit = init\n    messageEvent.#eventInit.data ??= null\n    messageEvent.#eventInit.origin ??= ''\n    messageEvent.#eventInit.lastEventId ??= ''\n    messageEvent.#eventInit.source ??= null\n    messageEvent.#eventInit.ports ??= []\n    return messageEvent\n  }\n}\n\nconst { createFastMessageEvent } = MessageEvent\ndelete MessageEvent.createFastMessageEvent\n\n/**\n * @see https://websockets.spec.whatwg.org/#the-closeevent-interface\n */\nclass CloseEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict = {}) {\n    const prefix = 'CloseEvent constructor'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    type = webidl.converters.DOMString(type, prefix, 'type')\n    eventInitDict = webidl.converters.CloseEventInit(eventInitDict)\n\n    super(type, eventInitDict)\n\n    this.#eventInit = eventInitDict\n    webidl.util.markAsUncloneable(this)\n  }\n\n  get wasClean () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.wasClean\n  }\n\n  get code () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.code\n  }\n\n  get reason () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.reason\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/webappapis.html#the-errorevent-interface\nclass ErrorEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict) {\n    const prefix = 'ErrorEvent constructor'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    super(type, eventInitDict)\n    webidl.util.markAsUncloneable(this)\n\n    type = webidl.converters.DOMString(type, prefix, 'type')\n    eventInitDict = webidl.converters.ErrorEventInit(eventInitDict ?? {})\n\n    this.#eventInit = eventInitDict\n  }\n\n  get message () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.message\n  }\n\n  get filename () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.filename\n  }\n\n  get lineno () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.lineno\n  }\n\n  get colno () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.colno\n  }\n\n  get error () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.error\n  }\n}\n\nObject.defineProperties(MessageEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'MessageEvent',\n    configurable: true\n  },\n  data: kEnumerableProperty,\n  origin: kEnumerableProperty,\n  lastEventId: kEnumerableProperty,\n  source: kEnumerableProperty,\n  ports: kEnumerableProperty,\n  initMessageEvent: kEnumerableProperty\n})\n\nObject.defineProperties(CloseEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'CloseEvent',\n    configurable: true\n  },\n  reason: kEnumerableProperty,\n  code: kEnumerableProperty,\n  wasClean: kEnumerableProperty\n})\n\nObject.defineProperties(ErrorEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'ErrorEvent',\n    configurable: true\n  },\n  message: kEnumerableProperty,\n  filename: kEnumerableProperty,\n  lineno: kEnumerableProperty,\n  colno: kEnumerableProperty,\n  error: kEnumerableProperty\n})\n\nwebidl.converters.MessagePort = webidl.interfaceConverter(MessagePort)\n\nwebidl.converters['sequence<MessagePort>'] = webidl.sequenceConverter(\n  webidl.converters.MessagePort\n)\n\nconst eventInit = [\n  {\n    key: 'bubbles',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'cancelable',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'composed',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  }\n]\n\nwebidl.converters.MessageEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'data',\n    converter: webidl.converters.any,\n    defaultValue: () => null\n  },\n  {\n    key: 'origin',\n    converter: webidl.converters.USVString,\n    defaultValue: () => ''\n  },\n  {\n    key: 'lastEventId',\n    converter: webidl.converters.DOMString,\n    defaultValue: () => ''\n  },\n  {\n    key: 'source',\n    // Node doesn't implement WindowProxy or ServiceWorker, so the only\n    // valid value for source is a MessagePort.\n    converter: webidl.nullableConverter(webidl.converters.MessagePort),\n    defaultValue: () => null\n  },\n  {\n    key: 'ports',\n    converter: webidl.converters['sequence<MessagePort>'],\n    defaultValue: () => new Array(0)\n  }\n])\n\nwebidl.converters.CloseEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'wasClean',\n    converter: webidl.converters.boolean,\n    defaultValue: () => false\n  },\n  {\n    key: 'code',\n    converter: webidl.converters['unsigned short'],\n    defaultValue: () => 0\n  },\n  {\n    key: 'reason',\n    converter: webidl.converters.USVString,\n    defaultValue: () => ''\n  }\n])\n\nwebidl.converters.ErrorEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'message',\n    converter: webidl.converters.DOMString,\n    defaultValue: () => ''\n  },\n  {\n    key: 'filename',\n    converter: webidl.converters.USVString,\n    defaultValue: () => ''\n  },\n  {\n    key: 'lineno',\n    converter: webidl.converters['unsigned long'],\n    defaultValue: () => 0\n  },\n  {\n    key: 'colno',\n    converter: webidl.converters['unsigned long'],\n    defaultValue: () => 0\n  },\n  {\n    key: 'error',\n    converter: webidl.converters.any\n  }\n])\n\nmodule.exports = {\n  MessageEvent,\n  CloseEvent,\n  ErrorEvent,\n  createFastMessageEvent\n}\n","'use strict'\n\nconst { maxUnsigned16Bit } = require('./constants')\n\nconst BUFFER_SIZE = 16386\n\n/** @type {import('crypto')} */\nlet crypto\nlet buffer = null\nlet bufIdx = BUFFER_SIZE\n\ntry {\n  crypto = require('node:crypto')\n/* c8 ignore next 3 */\n} catch {\n  crypto = {\n    // not full compatibility, but minimum.\n    randomFillSync: function randomFillSync (buffer, _offset, _size) {\n      for (let i = 0; i < buffer.length; ++i) {\n        buffer[i] = Math.random() * 255 | 0\n      }\n      return buffer\n    }\n  }\n}\n\nfunction generateMask () {\n  if (bufIdx === BUFFER_SIZE) {\n    bufIdx = 0\n    crypto.randomFillSync((buffer ??= Buffer.allocUnsafe(BUFFER_SIZE)), 0, BUFFER_SIZE)\n  }\n  return [buffer[bufIdx++], buffer[bufIdx++], buffer[bufIdx++], buffer[bufIdx++]]\n}\n\nclass WebsocketFrameSend {\n  /**\n   * @param {Buffer|undefined} data\n   */\n  constructor (data) {\n    this.frameData = data\n  }\n\n  createFrame (opcode) {\n    const frameData = this.frameData\n    const maskKey = generateMask()\n    const bodyLength = frameData?.byteLength ?? 0\n\n    /** @type {number} */\n    let payloadLength = bodyLength // 0-125\n    let offset = 6\n\n    if (bodyLength > maxUnsigned16Bit) {\n      offset += 8 // payload length is next 8 bytes\n      payloadLength = 127\n    } else if (bodyLength > 125) {\n      offset += 2 // payload length is next 2 bytes\n      payloadLength = 126\n    }\n\n    const buffer = Buffer.allocUnsafe(bodyLength + offset)\n\n    // Clear first 2 bytes, everything else is overwritten\n    buffer[0] = buffer[1] = 0\n    buffer[0] |= 0x80 // FIN\n    buffer[0] = (buffer[0] & 0xF0) + opcode // opcode\n\n    /*! ws. MIT License. Einar Otto Stangvik <einaros@gmail.com> */\n    buffer[offset - 4] = maskKey[0]\n    buffer[offset - 3] = maskKey[1]\n    buffer[offset - 2] = maskKey[2]\n    buffer[offset - 1] = maskKey[3]\n\n    buffer[1] = payloadLength\n\n    if (payloadLength === 126) {\n      buffer.writeUInt16BE(bodyLength, 2)\n    } else if (payloadLength === 127) {\n      // Clear extended payload length\n      buffer[2] = buffer[3] = 0\n      buffer.writeUIntBE(bodyLength, 4, 6)\n    }\n\n    buffer[1] |= 0x80 // MASK\n\n    // mask body\n    for (let i = 0; i < bodyLength; ++i) {\n      buffer[offset + i] = frameData[i] ^ maskKey[i & 3]\n    }\n\n    return buffer\n  }\n}\n\nmodule.exports = {\n  WebsocketFrameSend\n}\n","'use strict'\n\nconst { createInflateRaw, Z_DEFAULT_WINDOWBITS } = require('node:zlib')\nconst { isValidClientWindowBits } = require('./util')\n\nconst tail = Buffer.from([0x00, 0x00, 0xff, 0xff])\nconst kBuffer = Symbol('kBuffer')\nconst kLength = Symbol('kLength')\n\nclass PerMessageDeflate {\n  /** @type {import('node:zlib').InflateRaw} */\n  #inflate\n\n  #options = {}\n\n  constructor (extensions) {\n    this.#options.serverNoContextTakeover = extensions.has('server_no_context_takeover')\n    this.#options.serverMaxWindowBits = extensions.get('server_max_window_bits')\n  }\n\n  decompress (chunk, fin, callback) {\n    // An endpoint uses the following algorithm to decompress a message.\n    // 1.  Append 4 octets of 0x00 0x00 0xff 0xff to the tail end of the\n    //     payload of the message.\n    // 2.  Decompress the resulting data using DEFLATE.\n\n    if (!this.#inflate) {\n      let windowBits = Z_DEFAULT_WINDOWBITS\n\n      if (this.#options.serverMaxWindowBits) { // empty values default to Z_DEFAULT_WINDOWBITS\n        if (!isValidClientWindowBits(this.#options.serverMaxWindowBits)) {\n          callback(new Error('Invalid server_max_window_bits'))\n          return\n        }\n\n        windowBits = Number.parseInt(this.#options.serverMaxWindowBits)\n      }\n\n      this.#inflate = createInflateRaw({ windowBits })\n      this.#inflate[kBuffer] = []\n      this.#inflate[kLength] = 0\n\n      this.#inflate.on('data', (data) => {\n        this.#inflate[kBuffer].push(data)\n        this.#inflate[kLength] += data.length\n      })\n\n      this.#inflate.on('error', (err) => {\n        this.#inflate = null\n        callback(err)\n      })\n    }\n\n    this.#inflate.write(chunk)\n    if (fin) {\n      this.#inflate.write(tail)\n    }\n\n    this.#inflate.flush(() => {\n      const full = Buffer.concat(this.#inflate[kBuffer], this.#inflate[kLength])\n\n      this.#inflate[kBuffer].length = 0\n      this.#inflate[kLength] = 0\n\n      callback(null, full)\n    })\n  }\n}\n\nmodule.exports = { PerMessageDeflate }\n","'use strict'\n\nconst { Writable } = require('node:stream')\nconst assert = require('node:assert')\nconst { parserStates, opcodes, states, emptyBuffer, sentCloseFrameState } = require('./constants')\nconst { kReadyState, kSentClose, kResponse, kReceivedClose } = require('./symbols')\nconst { channels } = require('../../core/diagnostics')\nconst {\n  isValidStatusCode,\n  isValidOpcode,\n  failWebsocketConnection,\n  websocketMessageReceived,\n  utf8Decode,\n  isControlFrame,\n  isTextBinaryFrame,\n  isContinuationFrame\n} = require('./util')\nconst { WebsocketFrameSend } = require('./frame')\nconst { closeWebSocketConnection } = require('./connection')\nconst { PerMessageDeflate } = require('./permessage-deflate')\n\n// This code was influenced by ws released under the MIT license.\n// Copyright (c) 2011 Einar Otto Stangvik <einaros@gmail.com>\n// Copyright (c) 2013 Arnout Kazemier and contributors\n// Copyright (c) 2016 Luigi Pinca and contributors\n\nclass ByteParser extends Writable {\n  #buffers = []\n  #byteOffset = 0\n  #loop = false\n\n  #state = parserStates.INFO\n\n  #info = {}\n  #fragments = []\n\n  /** @type {Map<string, PerMessageDeflate>} */\n  #extensions\n\n  constructor (ws, extensions) {\n    super()\n\n    this.ws = ws\n    this.#extensions = extensions == null ? new Map() : extensions\n\n    if (this.#extensions.has('permessage-deflate')) {\n      this.#extensions.set('permessage-deflate', new PerMessageDeflate(extensions))\n    }\n  }\n\n  /**\n   * @param {Buffer} chunk\n   * @param {() => void} callback\n   */\n  _write (chunk, _, callback) {\n    this.#buffers.push(chunk)\n    this.#byteOffset += chunk.length\n    this.#loop = true\n\n    this.run(callback)\n  }\n\n  /**\n   * Runs whenever a new chunk is received.\n   * Callback is called whenever there are no more chunks buffering,\n   * or not enough bytes are buffered to parse.\n   */\n  run (callback) {\n    while (this.#loop) {\n      if (this.#state === parserStates.INFO) {\n        // If there aren't enough bytes to parse the payload length, etc.\n        if (this.#byteOffset < 2) {\n          return callback()\n        }\n\n        const buffer = this.consume(2)\n        const fin = (buffer[0] & 0x80) !== 0\n        const opcode = buffer[0] & 0x0F\n        const masked = (buffer[1] & 0x80) === 0x80\n\n        const fragmented = !fin && opcode !== opcodes.CONTINUATION\n        const payloadLength = buffer[1] & 0x7F\n\n        const rsv1 = buffer[0] & 0x40\n        const rsv2 = buffer[0] & 0x20\n        const rsv3 = buffer[0] & 0x10\n\n        if (!isValidOpcode(opcode)) {\n          failWebsocketConnection(this.ws, 'Invalid opcode received')\n          return callback()\n        }\n\n        if (masked) {\n          failWebsocketConnection(this.ws, 'Frame cannot be masked')\n          return callback()\n        }\n\n        // MUST be 0 unless an extension is negotiated that defines meanings\n        // for non-zero values.  If a nonzero value is received and none of\n        // the negotiated extensions defines the meaning of such a nonzero\n        // value, the receiving endpoint MUST _Fail the WebSocket\n        // Connection_.\n        // This document allocates the RSV1 bit of the WebSocket header for\n        // PMCEs and calls the bit the \"Per-Message Compressed\" bit.  On a\n        // WebSocket connection where a PMCE is in use, this bit indicates\n        // whether a message is compressed or not.\n        if (rsv1 !== 0 && !this.#extensions.has('permessage-deflate')) {\n          failWebsocketConnection(this.ws, 'Expected RSV1 to be clear.')\n          return\n        }\n\n        if (rsv2 !== 0 || rsv3 !== 0) {\n          failWebsocketConnection(this.ws, 'RSV1, RSV2, RSV3 must be clear')\n          return\n        }\n\n        if (fragmented && !isTextBinaryFrame(opcode)) {\n          // Only text and binary frames can be fragmented\n          failWebsocketConnection(this.ws, 'Invalid frame type was fragmented.')\n          return\n        }\n\n        // If we are already parsing a text/binary frame and do not receive either\n        // a continuation frame or close frame, fail the connection.\n        if (isTextBinaryFrame(opcode) && this.#fragments.length > 0) {\n          failWebsocketConnection(this.ws, 'Expected continuation frame')\n          return\n        }\n\n        if (this.#info.fragmented && fragmented) {\n          // A fragmented frame can't be fragmented itself\n          failWebsocketConnection(this.ws, 'Fragmented frame exceeded 125 bytes.')\n          return\n        }\n\n        // \"All control frames MUST have a payload length of 125 bytes or less\n        // and MUST NOT be fragmented.\"\n        if ((payloadLength > 125 || fragmented) && isControlFrame(opcode)) {\n          failWebsocketConnection(this.ws, 'Control frame either too large or fragmented')\n          return\n        }\n\n        if (isContinuationFrame(opcode) && this.#fragments.length === 0 && !this.#info.compressed) {\n          failWebsocketConnection(this.ws, 'Unexpected continuation frame')\n          return\n        }\n\n        if (payloadLength <= 125) {\n          this.#info.payloadLength = payloadLength\n          this.#state = parserStates.READ_DATA\n        } else if (payloadLength === 126) {\n          this.#state = parserStates.PAYLOADLENGTH_16\n        } else if (payloadLength === 127) {\n          this.#state = parserStates.PAYLOADLENGTH_64\n        }\n\n        if (isTextBinaryFrame(opcode)) {\n          this.#info.binaryType = opcode\n          this.#info.compressed = rsv1 !== 0\n        }\n\n        this.#info.opcode = opcode\n        this.#info.masked = masked\n        this.#info.fin = fin\n        this.#info.fragmented = fragmented\n      } else if (this.#state === parserStates.PAYLOADLENGTH_16) {\n        if (this.#byteOffset < 2) {\n          return callback()\n        }\n\n        const buffer = this.consume(2)\n\n        this.#info.payloadLength = buffer.readUInt16BE(0)\n        this.#state = parserStates.READ_DATA\n      } else if (this.#state === parserStates.PAYLOADLENGTH_64) {\n        if (this.#byteOffset < 8) {\n          return callback()\n        }\n\n        const buffer = this.consume(8)\n        const upper = buffer.readUInt32BE(0)\n\n        // 2^31 is the maximum bytes an arraybuffer can contain\n        // on 32-bit systems. Although, on 64-bit systems, this is\n        // 2^53-1 bytes.\n        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Invalid_array_length\n        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/common/globals.h;drc=1946212ac0100668f14eb9e2843bdd846e510a1e;bpv=1;bpt=1;l=1275\n        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/js-array-buffer.h;l=34;drc=1946212ac0100668f14eb9e2843bdd846e510a1e\n        if (upper > 2 ** 31 - 1) {\n          failWebsocketConnection(this.ws, 'Received payload length > 2^31 bytes.')\n          return\n        }\n\n        const lower = buffer.readUInt32BE(4)\n\n        this.#info.payloadLength = (upper << 8) + lower\n        this.#state = parserStates.READ_DATA\n      } else if (this.#state === parserStates.READ_DATA) {\n        if (this.#byteOffset < this.#info.payloadLength) {\n          return callback()\n        }\n\n        const body = this.consume(this.#info.payloadLength)\n\n        if (isControlFrame(this.#info.opcode)) {\n          this.#loop = this.parseControlFrame(body)\n          this.#state = parserStates.INFO\n        } else {\n          if (!this.#info.compressed) {\n            this.#fragments.push(body)\n\n            // If the frame is not fragmented, a message has been received.\n            // If the frame is fragmented, it will terminate with a fin bit set\n            // and an opcode of 0 (continuation), therefore we handle that when\n            // parsing continuation frames, not here.\n            if (!this.#info.fragmented && this.#info.fin) {\n              const fullMessage = Buffer.concat(this.#fragments)\n              websocketMessageReceived(this.ws, this.#info.binaryType, fullMessage)\n              this.#fragments.length = 0\n            }\n\n            this.#state = parserStates.INFO\n          } else {\n            this.#extensions.get('permessage-deflate').decompress(body, this.#info.fin, (error, data) => {\n              if (error) {\n                closeWebSocketConnection(this.ws, 1007, error.message, error.message.length)\n                return\n              }\n\n              this.#fragments.push(data)\n\n              if (!this.#info.fin) {\n                this.#state = parserStates.INFO\n                this.#loop = true\n                this.run(callback)\n                return\n              }\n\n              websocketMessageReceived(this.ws, this.#info.binaryType, Buffer.concat(this.#fragments))\n\n              this.#loop = true\n              this.#state = parserStates.INFO\n              this.#fragments.length = 0\n              this.run(callback)\n            })\n\n            this.#loop = false\n            break\n          }\n        }\n      }\n    }\n  }\n\n  /**\n   * Take n bytes from the buffered Buffers\n   * @param {number} n\n   * @returns {Buffer}\n   */\n  consume (n) {\n    if (n > this.#byteOffset) {\n      throw new Error('Called consume() before buffers satiated.')\n    } else if (n === 0) {\n      return emptyBuffer\n    }\n\n    if (this.#buffers[0].length === n) {\n      this.#byteOffset -= this.#buffers[0].length\n      return this.#buffers.shift()\n    }\n\n    const buffer = Buffer.allocUnsafe(n)\n    let offset = 0\n\n    while (offset !== n) {\n      const next = this.#buffers[0]\n      const { length } = next\n\n      if (length + offset === n) {\n        buffer.set(this.#buffers.shift(), offset)\n        break\n      } else if (length + offset > n) {\n        buffer.set(next.subarray(0, n - offset), offset)\n        this.#buffers[0] = next.subarray(n - offset)\n        break\n      } else {\n        buffer.set(this.#buffers.shift(), offset)\n        offset += next.length\n      }\n    }\n\n    this.#byteOffset -= n\n\n    return buffer\n  }\n\n  parseCloseBody (data) {\n    assert(data.length !== 1)\n\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.5\n    /** @type {number|undefined} */\n    let code\n\n    if (data.length >= 2) {\n      // _The WebSocket Connection Close Code_ is\n      // defined as the status code (Section 7.4) contained in the first Close\n      // control frame received by the application\n      code = data.readUInt16BE(0)\n    }\n\n    if (code !== undefined && !isValidStatusCode(code)) {\n      return { code: 1002, reason: 'Invalid status code', error: true }\n    }\n\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.6\n    /** @type {Buffer} */\n    let reason = data.subarray(2)\n\n    // Remove BOM\n    if (reason[0] === 0xEF && reason[1] === 0xBB && reason[2] === 0xBF) {\n      reason = reason.subarray(3)\n    }\n\n    try {\n      reason = utf8Decode(reason)\n    } catch {\n      return { code: 1007, reason: 'Invalid UTF-8', error: true }\n    }\n\n    return { code, reason, error: false }\n  }\n\n  /**\n   * Parses control frames.\n   * @param {Buffer} body\n   */\n  parseControlFrame (body) {\n    const { opcode, payloadLength } = this.#info\n\n    if (opcode === opcodes.CLOSE) {\n      if (payloadLength === 1) {\n        failWebsocketConnection(this.ws, 'Received close frame with a 1-byte body.')\n        return false\n      }\n\n      this.#info.closeInfo = this.parseCloseBody(body)\n\n      if (this.#info.closeInfo.error) {\n        const { code, reason } = this.#info.closeInfo\n\n        closeWebSocketConnection(this.ws, code, reason, reason.length)\n        failWebsocketConnection(this.ws, reason)\n        return false\n      }\n\n      if (this.ws[kSentClose] !== sentCloseFrameState.SENT) {\n        // If an endpoint receives a Close frame and did not previously send a\n        // Close frame, the endpoint MUST send a Close frame in response.  (When\n        // sending a Close frame in response, the endpoint typically echos the\n        // status code it received.)\n        let body = emptyBuffer\n        if (this.#info.closeInfo.code) {\n          body = Buffer.allocUnsafe(2)\n          body.writeUInt16BE(this.#info.closeInfo.code, 0)\n        }\n        const closeFrame = new WebsocketFrameSend(body)\n\n        this.ws[kResponse].socket.write(\n          closeFrame.createFrame(opcodes.CLOSE),\n          (err) => {\n            if (!err) {\n              this.ws[kSentClose] = sentCloseFrameState.SENT\n            }\n          }\n        )\n      }\n\n      // Upon either sending or receiving a Close control frame, it is said\n      // that _The WebSocket Closing Handshake is Started_ and that the\n      // WebSocket connection is in the CLOSING state.\n      this.ws[kReadyState] = states.CLOSING\n      this.ws[kReceivedClose] = true\n\n      return false\n    } else if (opcode === opcodes.PING) {\n      // Upon receipt of a Ping frame, an endpoint MUST send a Pong frame in\n      // response, unless it already received a Close frame.\n      // A Pong frame sent in response to a Ping frame must have identical\n      // \"Application data\"\n\n      if (!this.ws[kReceivedClose]) {\n        const frame = new WebsocketFrameSend(body)\n\n        this.ws[kResponse].socket.write(frame.createFrame(opcodes.PONG))\n\n        if (channels.ping.hasSubscribers) {\n          channels.ping.publish({\n            payload: body\n          })\n        }\n      }\n    } else if (opcode === opcodes.PONG) {\n      // A Pong frame MAY be sent unsolicited.  This serves as a\n      // unidirectional heartbeat.  A response to an unsolicited Pong frame is\n      // not expected.\n\n      if (channels.pong.hasSubscribers) {\n        channels.pong.publish({\n          payload: body\n        })\n      }\n    }\n\n    return true\n  }\n\n  get closingInfo () {\n    return this.#info.closeInfo\n  }\n}\n\nmodule.exports = {\n  ByteParser\n}\n","'use strict'\n\nconst { WebsocketFrameSend } = require('./frame')\nconst { opcodes, sendHints } = require('./constants')\nconst FixedQueue = require('../../dispatcher/fixed-queue')\n\n/** @type {typeof Uint8Array} */\nconst FastBuffer = Buffer[Symbol.species]\n\n/**\n * @typedef {object} SendQueueNode\n * @property {Promise<void> | null} promise\n * @property {((...args: any[]) => any)} callback\n * @property {Buffer | null} frame\n */\n\nclass SendQueue {\n  /**\n   * @type {FixedQueue}\n   */\n  #queue = new FixedQueue()\n\n  /**\n   * @type {boolean}\n   */\n  #running = false\n\n  /** @type {import('node:net').Socket} */\n  #socket\n\n  constructor (socket) {\n    this.#socket = socket\n  }\n\n  add (item, cb, hint) {\n    if (hint !== sendHints.blob) {\n      const frame = createFrame(item, hint)\n      if (!this.#running) {\n        // fast-path\n        this.#socket.write(frame, cb)\n      } else {\n        /** @type {SendQueueNode} */\n        const node = {\n          promise: null,\n          callback: cb,\n          frame\n        }\n        this.#queue.push(node)\n      }\n      return\n    }\n\n    /** @type {SendQueueNode} */\n    const node = {\n      promise: item.arrayBuffer().then((ab) => {\n        node.promise = null\n        node.frame = createFrame(ab, hint)\n      }),\n      callback: cb,\n      frame: null\n    }\n\n    this.#queue.push(node)\n\n    if (!this.#running) {\n      this.#run()\n    }\n  }\n\n  async #run () {\n    this.#running = true\n    const queue = this.#queue\n    while (!queue.isEmpty()) {\n      const node = queue.shift()\n      // wait pending promise\n      if (node.promise !== null) {\n        await node.promise\n      }\n      // write\n      this.#socket.write(node.frame, node.callback)\n      // cleanup\n      node.callback = node.frame = null\n    }\n    this.#running = false\n  }\n}\n\nfunction createFrame (data, hint) {\n  return new WebsocketFrameSend(toBuffer(data, hint)).createFrame(hint === sendHints.string ? opcodes.TEXT : opcodes.BINARY)\n}\n\nfunction toBuffer (data, hint) {\n  switch (hint) {\n    case sendHints.string:\n      return Buffer.from(data)\n    case sendHints.arrayBuffer:\n    case sendHints.blob:\n      return new FastBuffer(data)\n    case sendHints.typedArray:\n      return new FastBuffer(data.buffer, data.byteOffset, data.byteLength)\n  }\n}\n\nmodule.exports = { SendQueue }\n","'use strict'\n\nmodule.exports = {\n  kWebSocketURL: Symbol('url'),\n  kReadyState: Symbol('ready state'),\n  kController: Symbol('controller'),\n  kResponse: Symbol('response'),\n  kBinaryType: Symbol('binary type'),\n  kSentClose: Symbol('sent close'),\n  kReceivedClose: Symbol('received close'),\n  kByteParser: Symbol('byte parser')\n}\n","'use strict'\n\nconst { kReadyState, kController, kResponse, kBinaryType, kWebSocketURL } = require('./symbols')\nconst { states, opcodes } = require('./constants')\nconst { ErrorEvent, createFastMessageEvent } = require('./events')\nconst { isUtf8 } = require('node:buffer')\nconst { collectASequenceOfCodePointsFast, removeHTTPWhitespace } = require('../fetch/data-url')\n\n/* globals Blob */\n\n/**\n * @param {import('./websocket').WebSocket} ws\n * @returns {boolean}\n */\nfunction isConnecting (ws) {\n  // If the WebSocket connection is not yet established, and the connection\n  // is not yet closed, then the WebSocket connection is in the CONNECTING state.\n  return ws[kReadyState] === states.CONNECTING\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n * @returns {boolean}\n */\nfunction isEstablished (ws) {\n  // If the server's response is validated as provided for above, it is\n  // said that _The WebSocket Connection is Established_ and that the\n  // WebSocket Connection is in the OPEN state.\n  return ws[kReadyState] === states.OPEN\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n * @returns {boolean}\n */\nfunction isClosing (ws) {\n  // Upon either sending or receiving a Close control frame, it is said\n  // that _The WebSocket Closing Handshake is Started_ and that the\n  // WebSocket connection is in the CLOSING state.\n  return ws[kReadyState] === states.CLOSING\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n * @returns {boolean}\n */\nfunction isClosed (ws) {\n  return ws[kReadyState] === states.CLOSED\n}\n\n/**\n * @see https://dom.spec.whatwg.org/#concept-event-fire\n * @param {string} e\n * @param {EventTarget} target\n * @param {(...args: ConstructorParameters<typeof Event>) => Event} eventFactory\n * @param {EventInit | undefined} eventInitDict\n */\nfunction fireEvent (e, target, eventFactory = (type, init) => new Event(type, init), eventInitDict = {}) {\n  // 1. If eventConstructor is not given, then let eventConstructor be Event.\n\n  // 2. Let event be the result of creating an event given eventConstructor,\n  //    in the relevant realm of target.\n  // 3. Initialize events type attribute to e.\n  const event = eventFactory(e, eventInitDict)\n\n  // 4. Initialize any other IDL attributes of event as described in the\n  //    invocation of this algorithm.\n\n  // 5. Return the result of dispatching event at target, with legacy target\n  //    override flag set if set.\n  target.dispatchEvent(event)\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n * @param {import('./websocket').WebSocket} ws\n * @param {number} type Opcode\n * @param {Buffer} data application data\n */\nfunction websocketMessageReceived (ws, type, data) {\n  // 1. If ready state is not OPEN (1), then return.\n  if (ws[kReadyState] !== states.OPEN) {\n    return\n  }\n\n  // 2. Let dataForEvent be determined by switching on type and binary type:\n  let dataForEvent\n\n  if (type === opcodes.TEXT) {\n    // -> type indicates that the data is Text\n    //      a new DOMString containing data\n    try {\n      dataForEvent = utf8Decode(data)\n    } catch {\n      failWebsocketConnection(ws, 'Received invalid UTF-8 in text frame.')\n      return\n    }\n  } else if (type === opcodes.BINARY) {\n    if (ws[kBinaryType] === 'blob') {\n      // -> type indicates that the data is Binary and binary type is \"blob\"\n      //      a new Blob object, created in the relevant Realm of the WebSocket\n      //      object, that represents data as its raw data\n      dataForEvent = new Blob([data])\n    } else {\n      // -> type indicates that the data is Binary and binary type is \"arraybuffer\"\n      //      a new ArrayBuffer object, created in the relevant Realm of the\n      //      WebSocket object, whose contents are data\n      dataForEvent = toArrayBuffer(data)\n    }\n  }\n\n  // 3. Fire an event named message at the WebSocket object, using MessageEvent,\n  //    with the origin attribute initialized to the serialization of the WebSocket\n  //    objects url's origin, and the data attribute initialized to dataForEvent.\n  fireEvent('message', ws, createFastMessageEvent, {\n    origin: ws[kWebSocketURL].origin,\n    data: dataForEvent\n  })\n}\n\nfunction toArrayBuffer (buffer) {\n  if (buffer.byteLength === buffer.buffer.byteLength) {\n    return buffer.buffer\n  }\n  return buffer.buffer.slice(buffer.byteOffset, buffer.byteOffset + buffer.byteLength)\n}\n\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc6455\n * @see https://datatracker.ietf.org/doc/html/rfc2616\n * @see https://bugs.chromium.org/p/chromium/issues/detail?id=398407\n * @param {string} protocol\n */\nfunction isValidSubprotocol (protocol) {\n  // If present, this value indicates one\n  // or more comma-separated subprotocol the client wishes to speak,\n  // ordered by preference.  The elements that comprise this value\n  // MUST be non-empty strings with characters in the range U+0021 to\n  // U+007E not including separator characters as defined in\n  // [RFC2616] and MUST all be unique strings.\n  if (protocol.length === 0) {\n    return false\n  }\n\n  for (let i = 0; i < protocol.length; ++i) {\n    const code = protocol.charCodeAt(i)\n\n    if (\n      code < 0x21 || // CTL, contains SP (0x20) and HT (0x09)\n      code > 0x7E ||\n      code === 0x22 || // \"\n      code === 0x28 || // (\n      code === 0x29 || // )\n      code === 0x2C || // ,\n      code === 0x2F || // /\n      code === 0x3A || // :\n      code === 0x3B || // ;\n      code === 0x3C || // <\n      code === 0x3D || // =\n      code === 0x3E || // >\n      code === 0x3F || // ?\n      code === 0x40 || // @\n      code === 0x5B || // [\n      code === 0x5C || // \\\n      code === 0x5D || // ]\n      code === 0x7B || // {\n      code === 0x7D // }\n    ) {\n      return false\n    }\n  }\n\n  return true\n}\n\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7-4\n * @param {number} code\n */\nfunction isValidStatusCode (code) {\n  if (code >= 1000 && code < 1015) {\n    return (\n      code !== 1004 && // reserved\n      code !== 1005 && // \"MUST NOT be set as a status code\"\n      code !== 1006 // \"MUST NOT be set as a status code\"\n    )\n  }\n\n  return code >= 3000 && code <= 4999\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n * @param {string|undefined} reason\n */\nfunction failWebsocketConnection (ws, reason) {\n  const { [kController]: controller, [kResponse]: response } = ws\n\n  controller.abort()\n\n  if (response?.socket && !response.socket.destroyed) {\n    response.socket.destroy()\n  }\n\n  if (reason) {\n    // TODO: process.nextTick\n    fireEvent('error', ws, (type, init) => new ErrorEvent(type, init), {\n      error: new Error(reason),\n      message: reason\n    })\n  }\n}\n\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc6455#section-5.5\n * @param {number} opcode\n */\nfunction isControlFrame (opcode) {\n  return (\n    opcode === opcodes.CLOSE ||\n    opcode === opcodes.PING ||\n    opcode === opcodes.PONG\n  )\n}\n\nfunction isContinuationFrame (opcode) {\n  return opcode === opcodes.CONTINUATION\n}\n\nfunction isTextBinaryFrame (opcode) {\n  return opcode === opcodes.TEXT || opcode === opcodes.BINARY\n}\n\nfunction isValidOpcode (opcode) {\n  return isTextBinaryFrame(opcode) || isContinuationFrame(opcode) || isControlFrame(opcode)\n}\n\n/**\n * Parses a Sec-WebSocket-Extensions header value.\n * @param {string} extensions\n * @returns {Map<string, string>}\n */\n// TODO(@Uzlopak, @KhafraDev): make compliant https://datatracker.ietf.org/doc/html/rfc6455#section-9.1\nfunction parseExtensions (extensions) {\n  const position = { position: 0 }\n  const extensionList = new Map()\n\n  while (position.position < extensions.length) {\n    const pair = collectASequenceOfCodePointsFast(';', extensions, position)\n    const [name, value = ''] = pair.split('=')\n\n    extensionList.set(\n      removeHTTPWhitespace(name, true, false),\n      removeHTTPWhitespace(value, false, true)\n    )\n\n    position.position++\n  }\n\n  return extensionList\n}\n\n/**\n * @see https://www.rfc-editor.org/rfc/rfc7692#section-7.1.2.2\n * @description \"client-max-window-bits = 1*DIGIT\"\n * @param {string} value\n */\nfunction isValidClientWindowBits (value) {\n  for (let i = 0; i < value.length; i++) {\n    const byte = value.charCodeAt(i)\n\n    if (byte < 0x30 || byte > 0x39) {\n      return false\n    }\n  }\n\n  return true\n}\n\n// https://nodejs.org/api/intl.html#detecting-internationalization-support\nconst hasIntl = typeof process.versions.icu === 'string'\nconst fatalDecoder = hasIntl ? new TextDecoder('utf-8', { fatal: true }) : undefined\n\n/**\n * Converts a Buffer to utf-8, even on platforms without icu.\n * @param {Buffer} buffer\n */\nconst utf8Decode = hasIntl\n  ? fatalDecoder.decode.bind(fatalDecoder)\n  : function (buffer) {\n    if (isUtf8(buffer)) {\n      return buffer.toString('utf-8')\n    }\n    throw new TypeError('Invalid utf-8 received.')\n  }\n\nmodule.exports = {\n  isConnecting,\n  isEstablished,\n  isClosing,\n  isClosed,\n  fireEvent,\n  isValidSubprotocol,\n  isValidStatusCode,\n  failWebsocketConnection,\n  websocketMessageReceived,\n  utf8Decode,\n  isControlFrame,\n  isContinuationFrame,\n  isTextBinaryFrame,\n  isValidOpcode,\n  parseExtensions,\n  isValidClientWindowBits\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\nconst { URLSerializer } = require('../fetch/data-url')\nconst { environmentSettingsObject } = require('../fetch/util')\nconst { staticPropertyDescriptors, states, sentCloseFrameState, sendHints } = require('./constants')\nconst {\n  kWebSocketURL,\n  kReadyState,\n  kController,\n  kBinaryType,\n  kResponse,\n  kSentClose,\n  kByteParser\n} = require('./symbols')\nconst {\n  isConnecting,\n  isEstablished,\n  isClosing,\n  isValidSubprotocol,\n  fireEvent\n} = require('./util')\nconst { establishWebSocketConnection, closeWebSocketConnection } = require('./connection')\nconst { ByteParser } = require('./receiver')\nconst { kEnumerableProperty, isBlobLike } = require('../../core/util')\nconst { getGlobalDispatcher } = require('../../global')\nconst { types } = require('node:util')\nconst { ErrorEvent, CloseEvent } = require('./events')\nconst { SendQueue } = require('./sender')\n\n// https://websockets.spec.whatwg.org/#interface-definition\nclass WebSocket extends EventTarget {\n  #events = {\n    open: null,\n    error: null,\n    close: null,\n    message: null\n  }\n\n  #bufferedAmount = 0\n  #protocol = ''\n  #extensions = ''\n\n  /** @type {SendQueue} */\n  #sendQueue\n\n  /**\n   * @param {string} url\n   * @param {string|string[]} protocols\n   */\n  constructor (url, protocols = []) {\n    super()\n\n    webidl.util.markAsUncloneable(this)\n\n    const prefix = 'WebSocket constructor'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    const options = webidl.converters['DOMString or sequence<DOMString> or WebSocketInit'](protocols, prefix, 'options')\n\n    url = webidl.converters.USVString(url, prefix, 'url')\n    protocols = options.protocols\n\n    // 1. Let baseURL be this's relevant settings object's API base URL.\n    const baseURL = environmentSettingsObject.settingsObject.baseUrl\n\n    // 1. Let urlRecord be the result of applying the URL parser to url with baseURL.\n    let urlRecord\n\n    try {\n      urlRecord = new URL(url, baseURL)\n    } catch (e) {\n      // 3. If urlRecord is failure, then throw a \"SyntaxError\" DOMException.\n      throw new DOMException(e, 'SyntaxError')\n    }\n\n    // 4. If urlRecords scheme is \"http\", then set urlRecords scheme to \"ws\".\n    if (urlRecord.protocol === 'http:') {\n      urlRecord.protocol = 'ws:'\n    } else if (urlRecord.protocol === 'https:') {\n      // 5. Otherwise, if urlRecords scheme is \"https\", set urlRecords scheme to \"wss\".\n      urlRecord.protocol = 'wss:'\n    }\n\n    // 6. If urlRecords scheme is not \"ws\" or \"wss\", then throw a \"SyntaxError\" DOMException.\n    if (urlRecord.protocol !== 'ws:' && urlRecord.protocol !== 'wss:') {\n      throw new DOMException(\n        `Expected a ws: or wss: protocol, got ${urlRecord.protocol}`,\n        'SyntaxError'\n      )\n    }\n\n    // 7. If urlRecords fragment is non-null, then throw a \"SyntaxError\"\n    //    DOMException.\n    if (urlRecord.hash || urlRecord.href.endsWith('#')) {\n      throw new DOMException('Got fragment', 'SyntaxError')\n    }\n\n    // 8. If protocols is a string, set protocols to a sequence consisting\n    //    of just that string.\n    if (typeof protocols === 'string') {\n      protocols = [protocols]\n    }\n\n    // 9. If any of the values in protocols occur more than once or otherwise\n    //    fail to match the requirements for elements that comprise the value\n    //    of `Sec-WebSocket-Protocol` fields as defined by The WebSocket\n    //    protocol, then throw a \"SyntaxError\" DOMException.\n    if (protocols.length !== new Set(protocols.map(p => p.toLowerCase())).size) {\n      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')\n    }\n\n    if (protocols.length > 0 && !protocols.every(p => isValidSubprotocol(p))) {\n      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')\n    }\n\n    // 10. Set this's url to urlRecord.\n    this[kWebSocketURL] = new URL(urlRecord.href)\n\n    // 11. Let client be this's relevant settings object.\n    const client = environmentSettingsObject.settingsObject\n\n    // 12. Run this step in parallel:\n\n    //    1. Establish a WebSocket connection given urlRecord, protocols,\n    //       and client.\n    this[kController] = establishWebSocketConnection(\n      urlRecord,\n      protocols,\n      client,\n      this,\n      (response, extensions) => this.#onConnectionEstablished(response, extensions),\n      options\n    )\n\n    // Each WebSocket object has an associated ready state, which is a\n    // number representing the state of the connection. Initially it must\n    // be CONNECTING (0).\n    this[kReadyState] = WebSocket.CONNECTING\n\n    this[kSentClose] = sentCloseFrameState.NOT_SENT\n\n    // The extensions attribute must initially return the empty string.\n\n    // The protocol attribute must initially return the empty string.\n\n    // Each WebSocket object has an associated binary type, which is a\n    // BinaryType. Initially it must be \"blob\".\n    this[kBinaryType] = 'blob'\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#dom-websocket-close\n   * @param {number|undefined} code\n   * @param {string|undefined} reason\n   */\n  close (code = undefined, reason = undefined) {\n    webidl.brandCheck(this, WebSocket)\n\n    const prefix = 'WebSocket.close'\n\n    if (code !== undefined) {\n      code = webidl.converters['unsigned short'](code, prefix, 'code', { clamp: true })\n    }\n\n    if (reason !== undefined) {\n      reason = webidl.converters.USVString(reason, prefix, 'reason')\n    }\n\n    // 1. If code is present, but is neither an integer equal to 1000 nor an\n    //    integer in the range 3000 to 4999, inclusive, throw an\n    //    \"InvalidAccessError\" DOMException.\n    if (code !== undefined) {\n      if (code !== 1000 && (code < 3000 || code > 4999)) {\n        throw new DOMException('invalid code', 'InvalidAccessError')\n      }\n    }\n\n    let reasonByteLength = 0\n\n    // 2. If reason is present, then run these substeps:\n    if (reason !== undefined) {\n      // 1. Let reasonBytes be the result of encoding reason.\n      // 2. If reasonBytes is longer than 123 bytes, then throw a\n      //    \"SyntaxError\" DOMException.\n      reasonByteLength = Buffer.byteLength(reason)\n\n      if (reasonByteLength > 123) {\n        throw new DOMException(\n          `Reason must be less than 123 bytes; received ${reasonByteLength}`,\n          'SyntaxError'\n        )\n      }\n    }\n\n    // 3. Run the first matching steps from the following list:\n    closeWebSocketConnection(this, code, reason, reasonByteLength)\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#dom-websocket-send\n   * @param {NodeJS.TypedArray|ArrayBuffer|Blob|string} data\n   */\n  send (data) {\n    webidl.brandCheck(this, WebSocket)\n\n    const prefix = 'WebSocket.send'\n    webidl.argumentLengthCheck(arguments, 1, prefix)\n\n    data = webidl.converters.WebSocketSendData(data, prefix, 'data')\n\n    // 1. If this's ready state is CONNECTING, then throw an\n    //    \"InvalidStateError\" DOMException.\n    if (isConnecting(this)) {\n      throw new DOMException('Sent before connected.', 'InvalidStateError')\n    }\n\n    // 2. Run the appropriate set of steps from the following list:\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-6.1\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-5.2\n\n    if (!isEstablished(this) || isClosing(this)) {\n      return\n    }\n\n    // If data is a string\n    if (typeof data === 'string') {\n      // If the WebSocket connection is established and the WebSocket\n      // closing handshake has not yet started, then the user agent\n      // must send a WebSocket Message comprised of the data argument\n      // using a text frame opcode; if the data cannot be sent, e.g.\n      // because it would need to be buffered but the buffer is full,\n      // the user agent must flag the WebSocket as full and then close\n      // the WebSocket connection. Any invocation of this method with a\n      // string argument that does not throw an exception must increase\n      // the bufferedAmount attribute by the number of bytes needed to\n      // express the argument as UTF-8.\n\n      const length = Buffer.byteLength(data)\n\n      this.#bufferedAmount += length\n      this.#sendQueue.add(data, () => {\n        this.#bufferedAmount -= length\n      }, sendHints.string)\n    } else if (types.isArrayBuffer(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need\n      // to be buffered but the buffer is full, the user agent must flag\n      // the WebSocket as full and then close the WebSocket connection.\n      // The data to be sent is the data stored in the buffer described\n      // by the ArrayBuffer object. Any invocation of this method with an\n      // ArrayBuffer argument that does not throw an exception must\n      // increase the bufferedAmount attribute by the length of the\n      // ArrayBuffer in bytes.\n\n      this.#bufferedAmount += data.byteLength\n      this.#sendQueue.add(data, () => {\n        this.#bufferedAmount -= data.byteLength\n      }, sendHints.arrayBuffer)\n    } else if (ArrayBuffer.isView(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need to\n      // be buffered but the buffer is full, the user agent must flag the\n      // WebSocket as full and then close the WebSocket connection. The\n      // data to be sent is the data stored in the section of the buffer\n      // described by the ArrayBuffer object that data references. Any\n      // invocation of this method with this kind of argument that does\n      // not throw an exception must increase the bufferedAmount attribute\n      // by the length of datas buffer in bytes.\n\n      this.#bufferedAmount += data.byteLength\n      this.#sendQueue.add(data, () => {\n        this.#bufferedAmount -= data.byteLength\n      }, sendHints.typedArray)\n    } else if (isBlobLike(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need to\n      // be buffered but the buffer is full, the user agent must flag the\n      // WebSocket as full and then close the WebSocket connection. The data\n      // to be sent is the raw data represented by the Blob object. Any\n      // invocation of this method with a Blob argument that does not throw\n      // an exception must increase the bufferedAmount attribute by the size\n      // of the Blob objects raw data, in bytes.\n\n      this.#bufferedAmount += data.size\n      this.#sendQueue.add(data, () => {\n        this.#bufferedAmount -= data.size\n      }, sendHints.blob)\n    }\n  }\n\n  get readyState () {\n    webidl.brandCheck(this, WebSocket)\n\n    // The readyState getter steps are to return this's ready state.\n    return this[kReadyState]\n  }\n\n  get bufferedAmount () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#bufferedAmount\n  }\n\n  get url () {\n    webidl.brandCheck(this, WebSocket)\n\n    // The url getter steps are to return this's url, serialized.\n    return URLSerializer(this[kWebSocketURL])\n  }\n\n  get extensions () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#extensions\n  }\n\n  get protocol () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#protocol\n  }\n\n  get onopen () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.open\n  }\n\n  set onopen (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.open) {\n      this.removeEventListener('open', this.#events.open)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.open = fn\n      this.addEventListener('open', fn)\n    } else {\n      this.#events.open = null\n    }\n  }\n\n  get onerror () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.error\n  }\n\n  set onerror (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.error) {\n      this.removeEventListener('error', this.#events.error)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.error = fn\n      this.addEventListener('error', fn)\n    } else {\n      this.#events.error = null\n    }\n  }\n\n  get onclose () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.close\n  }\n\n  set onclose (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.close) {\n      this.removeEventListener('close', this.#events.close)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.close = fn\n      this.addEventListener('close', fn)\n    } else {\n      this.#events.close = null\n    }\n  }\n\n  get onmessage () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.message\n  }\n\n  set onmessage (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.message) {\n      this.removeEventListener('message', this.#events.message)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.message = fn\n      this.addEventListener('message', fn)\n    } else {\n      this.#events.message = null\n    }\n  }\n\n  get binaryType () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this[kBinaryType]\n  }\n\n  set binaryType (type) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (type !== 'blob' && type !== 'arraybuffer') {\n      this[kBinaryType] = 'blob'\n    } else {\n      this[kBinaryType] = type\n    }\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n   */\n  #onConnectionEstablished (response, parsedExtensions) {\n    // processResponse is called when the \"responses header list has been received and initialized.\"\n    // once this happens, the connection is open\n    this[kResponse] = response\n\n    const parser = new ByteParser(this, parsedExtensions)\n    parser.on('drain', onParserDrain)\n    parser.on('error', onParserError.bind(this))\n\n    response.socket.ws = this\n    this[kByteParser] = parser\n\n    this.#sendQueue = new SendQueue(response.socket)\n\n    // 1. Change the ready state to OPEN (1).\n    this[kReadyState] = states.OPEN\n\n    // 2. Change the extensions attributes value to the extensions in use, if\n    //    it is not the null value.\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-9.1\n    const extensions = response.headersList.get('sec-websocket-extensions')\n\n    if (extensions !== null) {\n      this.#extensions = extensions\n    }\n\n    // 3. Change the protocol attributes value to the subprotocol in use, if\n    //    it is not the null value.\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-1.9\n    const protocol = response.headersList.get('sec-websocket-protocol')\n\n    if (protocol !== null) {\n      this.#protocol = protocol\n    }\n\n    // 4. Fire an event named open at the WebSocket object.\n    fireEvent('open', this)\n  }\n}\n\n// https://websockets.spec.whatwg.org/#dom-websocket-connecting\nWebSocket.CONNECTING = WebSocket.prototype.CONNECTING = states.CONNECTING\n// https://websockets.spec.whatwg.org/#dom-websocket-open\nWebSocket.OPEN = WebSocket.prototype.OPEN = states.OPEN\n// https://websockets.spec.whatwg.org/#dom-websocket-closing\nWebSocket.CLOSING = WebSocket.prototype.CLOSING = states.CLOSING\n// https://websockets.spec.whatwg.org/#dom-websocket-closed\nWebSocket.CLOSED = WebSocket.prototype.CLOSED = states.CLOSED\n\nObject.defineProperties(WebSocket.prototype, {\n  CONNECTING: staticPropertyDescriptors,\n  OPEN: staticPropertyDescriptors,\n  CLOSING: staticPropertyDescriptors,\n  CLOSED: staticPropertyDescriptors,\n  url: kEnumerableProperty,\n  readyState: kEnumerableProperty,\n  bufferedAmount: kEnumerableProperty,\n  onopen: kEnumerableProperty,\n  onerror: kEnumerableProperty,\n  onclose: kEnumerableProperty,\n  close: kEnumerableProperty,\n  onmessage: kEnumerableProperty,\n  binaryType: kEnumerableProperty,\n  send: kEnumerableProperty,\n  extensions: kEnumerableProperty,\n  protocol: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'WebSocket',\n    writable: false,\n    enumerable: false,\n    configurable: true\n  }\n})\n\nObject.defineProperties(WebSocket, {\n  CONNECTING: staticPropertyDescriptors,\n  OPEN: staticPropertyDescriptors,\n  CLOSING: staticPropertyDescriptors,\n  CLOSED: staticPropertyDescriptors\n})\n\nwebidl.converters['sequence<DOMString>'] = webidl.sequenceConverter(\n  webidl.converters.DOMString\n)\n\nwebidl.converters['DOMString or sequence<DOMString>'] = function (V, prefix, argument) {\n  if (webidl.util.Type(V) === 'Object' && Symbol.iterator in V) {\n    return webidl.converters['sequence<DOMString>'](V)\n  }\n\n  return webidl.converters.DOMString(V, prefix, argument)\n}\n\n// This implements the proposal made in https://github.com/whatwg/websockets/issues/42\nwebidl.converters.WebSocketInit = webidl.dictionaryConverter([\n  {\n    key: 'protocols',\n    converter: webidl.converters['DOMString or sequence<DOMString>'],\n    defaultValue: () => new Array(0)\n  },\n  {\n    key: 'dispatcher',\n    converter: webidl.converters.any,\n    defaultValue: () => getGlobalDispatcher()\n  },\n  {\n    key: 'headers',\n    converter: webidl.nullableConverter(webidl.converters.HeadersInit)\n  }\n])\n\nwebidl.converters['DOMString or sequence<DOMString> or WebSocketInit'] = function (V) {\n  if (webidl.util.Type(V) === 'Object' && !(Symbol.iterator in V)) {\n    return webidl.converters.WebSocketInit(V)\n  }\n\n  return { protocols: webidl.converters['DOMString or sequence<DOMString>'](V) }\n}\n\nwebidl.converters.WebSocketSendData = function (V) {\n  if (webidl.util.Type(V) === 'Object') {\n    if (isBlobLike(V)) {\n      return webidl.converters.Blob(V, { strict: false })\n    }\n\n    if (ArrayBuffer.isView(V) || types.isArrayBuffer(V)) {\n      return webidl.converters.BufferSource(V)\n    }\n  }\n\n  return webidl.converters.USVString(V)\n}\n\nfunction onParserDrain () {\n  this.ws[kResponse].socket.resume()\n}\n\nfunction onParserError (err) {\n  let message\n  let code\n\n  if (err instanceof CloseEvent) {\n    message = err.reason\n    code = err.code\n  } else {\n    message = err.message\n  }\n\n  fireEvent('error', this, () => new ErrorEvent('error', { error: err, message }))\n\n  closeWebSocketConnection(this, code)\n}\n\nmodule.exports = {\n  WebSocket\n}\n","\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = require('util').deprecate;\n","/**\n * ZipStream\n *\n * @ignore\n * @license [MIT]{@link https://github.com/archiverjs/node-zip-stream/blob/master/LICENSE}\n * @copyright (c) 2014 Chris Talkington, contributors.\n */\nvar inherits = require('util').inherits;\n\nvar ZipArchiveOutputStream = require('compress-commons').ZipArchiveOutputStream;\nvar ZipArchiveEntry = require('compress-commons').ZipArchiveEntry;\n\nvar util = require('archiver-utils');\n\n/**\n * @constructor\n * @extends external:ZipArchiveOutputStream\n * @param {Object} [options]\n * @param {String} [options.comment] Sets the zip archive comment.\n * @param {Boolean} [options.forceLocalTime=false] Forces the archive to contain local file times instead of UTC.\n * @param {Boolean} [options.forceZip64=false] Forces the archive to contain ZIP64 headers.\n * @param {Boolean} [options.store=false] Sets the compression method to STORE.\n * @param {Object} [options.zlib] Passed to [zlib]{@link https://nodejs.org/api/zlib.html#zlib_class_options}\n * to control compression.\n */\nvar ZipStream = module.exports = function(options) {\n  if (!(this instanceof ZipStream)) {\n    return new ZipStream(options);\n  }\n\n  options = this.options = options || {};\n  options.zlib = options.zlib || {};\n\n  ZipArchiveOutputStream.call(this, options);\n\n  if (typeof options.level === 'number' && options.level >= 0) {\n    options.zlib.level = options.level;\n    delete options.level;\n  }\n\n  if (!options.forceZip64 && typeof options.zlib.level === 'number' && options.zlib.level === 0) {\n    options.store = true;\n  }\n\n  options.namePrependSlash = options.namePrependSlash || false;\n\n  if (options.comment && options.comment.length > 0) {\n    this.setComment(options.comment);\n  }\n};\n\ninherits(ZipStream, ZipArchiveOutputStream);\n\n/**\n * Normalizes entry data with fallbacks for key properties.\n *\n * @private\n * @param  {Object} data\n * @return {Object}\n */\nZipStream.prototype._normalizeFileData = function(data) {\n  data = util.defaults(data, {\n    type: 'file',\n    name: null,\n    namePrependSlash: this.options.namePrependSlash,\n    linkname: null,\n    date: null,\n    mode: null,\n    store: this.options.store,\n    comment: ''\n  });\n\n  var isDir = data.type === 'directory';\n  var isSymlink = data.type === 'symlink';\n\n  if (data.name) {\n    data.name = util.sanitizePath(data.name);\n\n    if (!isSymlink && data.name.slice(-1) === '/') {\n      isDir = true;\n      data.type = 'directory';\n    } else if (isDir) {\n      data.name += '/';\n    }\n  }\n\n  if (isDir || isSymlink) {\n    data.store = true;\n  }\n\n  data.date = util.dateify(data.date);\n\n  return data;\n};\n\n/**\n * Appends an entry given an input source (text string, buffer, or stream).\n *\n * @param  {(Buffer|Stream|String)} source The input source.\n * @param  {Object} data\n * @param  {String} data.name Sets the entry name including internal path.\n * @param  {String} [data.comment] Sets the entry comment.\n * @param  {(String|Date)} [data.date=NOW()] Sets the entry date.\n * @param  {Number} [data.mode=D:0755/F:0644] Sets the entry permissions.\n * @param  {Boolean} [data.store=options.store] Sets the compression method to STORE.\n * @param  {String} [data.type=file] Sets the entry type. Defaults to `directory`\n * if name ends with trailing slash.\n * @param  {Function} callback\n * @return this\n */\nZipStream.prototype.entry = function(source, data, callback) {\n  if (typeof callback !== 'function') {\n    callback = this._emitErrorCallback.bind(this);\n  }\n\n  data = this._normalizeFileData(data);\n\n  if (data.type !== 'file' && data.type !== 'directory' && data.type !== 'symlink') {\n    callback(new Error(data.type + ' entries not currently supported'));\n    return;\n  }\n\n  if (typeof data.name !== 'string' || data.name.length === 0) {\n    callback(new Error('entry name must be a non-empty string value'));\n    return;\n  }\n\n  if (data.type === 'symlink' && typeof data.linkname !== 'string') {\n    callback(new Error('entry linkname must be a non-empty string value when type equals symlink'));\n    return;\n  }\n\n  var entry = new ZipArchiveEntry(data.name);\n  entry.setTime(data.date, this.options.forceLocalTime);\n\n  if (data.namePrependSlash) {\n    entry.setName(data.name, true);\n  }\n\n  if (data.store) {\n    entry.setMethod(0);\n  }\n\n  if (data.comment.length > 0) {\n    entry.setComment(data.comment);\n  }\n\n  if (data.type === 'symlink' && typeof data.mode !== 'number') {\n    data.mode = 40960; // 0120000\n  }\n\n  if (typeof data.mode === 'number') {\n    if (data.type === 'symlink') {\n      data.mode |= 40960;\n    }\n\n    entry.setUnixMode(data.mode);\n  }\n\n  if (data.type === 'symlink' && typeof data.linkname === 'string') {\n    source = Buffer.from(data.linkname);\n  }\n\n  return ZipArchiveOutputStream.prototype.entry.call(this, entry, source, callback);\n};\n\n/**\n * Finalizes the instance and prevents further appending to the archive\n * structure (queue will continue til drained).\n *\n * @return void\n */\nZipStream.prototype.finalize = function() {\n  this.finish();\n};\n\n/**\n * Returns the current number of bytes written to this stream.\n * @function ZipStream#getBytesWritten\n * @returns {Number}\n */\n\n/**\n * Compress Commons ZipArchiveOutputStream\n * @external ZipArchiveOutputStream\n * @see {@link https://github.com/archiverjs/node-compress-commons}\n */\n","import { ElasticBeanstalkClient } from '@aws-sdk/client-elastic-beanstalk';\nimport { S3Client } from '@aws-sdk/client-s3';\nimport { STSClient } from '@aws-sdk/client-sts';\n\n/**\n * Manages AWS SDK clients as singletons to avoid recreating instances\n * for every operation.\n */\nexport class AWSClients {\n  private static instances: Map<string, AWSClients> = new Map();\n\n  private readonly ebClient: ElasticBeanstalkClient;\n  private readonly s3Client: S3Client;\n  private readonly stsClient: STSClient;\n\n  private constructor(region: string) {\n    this.ebClient = new ElasticBeanstalkClient({ region });\n    this.s3Client = new S3Client({ region });\n    this.stsClient = new STSClient({ region });\n  }\n\n  /**\n   * Get or create AWSClients instance for a specific region\n   */\n  public static getInstance(region: string): AWSClients {\n    if (!AWSClients.instances.has(region)) {\n      AWSClients.instances.set(region, new AWSClients(region));\n    }\n    return AWSClients.instances.get(region)!;\n  }\n\n  /**\n   * Clear all cached client instances\n   */\n  public static clearInstances(): void {\n    AWSClients.instances.clear();\n  }\n\n  public getElasticBeanstalkClient(): ElasticBeanstalkClient {\n    return this.ebClient;\n  }\n\n  public getS3Client(): S3Client {\n    return this.s3Client;\n  }\n\n  public getSTSClient(): STSClient {\n    return this.stsClient;\n  }\n}\n","import * as core from '@actions/core';\nimport {\n  CreateApplicationVersionCommand,\n  UpdateEnvironmentCommand,\n  CreateEnvironmentCommand,\n  DescribeEnvironmentsCommand,\n  DescribeApplicationVersionsCommand,\n} from '@aws-sdk/client-elastic-beanstalk';\nimport { PutObjectCommand, HeadBucketCommand, CreateBucketCommand } from '@aws-sdk/client-s3';\nimport { GetCallerIdentityCommand } from '@aws-sdk/client-sts';\nimport * as fs from 'fs';\nimport * as path from 'path';\nimport { AWSClients } from './aws-clients';\nimport { parseJsonInput } from './validations';\n\n/**\n * Maximum deployment package size in bytes (500 MB)\n * AWS Elastic Beanstalk limit: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/applications-sourcebundle.html\n */\nexport const MAX_DEPLOYMENT_PACKAGE_SIZE_BYTES = 500 * 1024 * 1024;\n\n/**\n * Validate that option-settings contains required IAM roles when creating an environment\n */\nexport function validateOptionSettingsForCreate(optionSettingsJson: string | undefined): void {\n  if (!optionSettingsJson) {\n    throw new Error('option-settings is required when creating a new environment. Must include IamInstanceProfile and ServiceRole.');\n  }\n\n  const parsedSettings = JSON.parse(optionSettingsJson);\n\n  let hasIamInstanceProfile = false;\n  let hasServiceRole = false;\n\n  for (const setting of parsedSettings) {\n    if (setting.Namespace === 'aws:autoscaling:launchconfiguration' && \n        setting.OptionName === 'IamInstanceProfile') {\n      hasIamInstanceProfile = true;\n    }\n\n    if (setting.Namespace === 'aws:elasticbeanstalk:environment' && \n        setting.OptionName === 'ServiceRole') {\n      hasServiceRole = true;\n    }\n  }\n\n  if (!hasIamInstanceProfile) {\n    throw new Error('option-settings must include IamInstanceProfile setting with Namespace \"aws:autoscaling:launchconfiguration\" and OptionName \"IamInstanceProfile\"');\n  }\n\n  if (!hasServiceRole) {\n    throw new Error('option-settings must include ServiceRole setting with Namespace \"aws:elasticbeanstalk:environment\" and OptionName \"ServiceRole\"');\n  }\n}\n\n/**\n * AWS S3 LocationConstraint regions\n * Used for S3 bucket creation outside of us-east-1\n */\nexport const AWS_S3_REGIONS = [\n  'af-south-1',\n  'ap-east-1',\n  'ap-northeast-1',\n  'ap-northeast-2',\n  'ap-northeast-3',\n  'ap-south-1',\n  'ap-southeast-1',\n  'ap-southeast-2',\n  'ca-central-1',\n  'cn-north-1',\n  'cn-northwest-1',\n  'eu-central-1',\n  'eu-north-1',\n  'eu-south-1',\n  'eu-west-1',\n  'eu-west-2',\n  'eu-west-3',\n  'me-south-1',\n  'sa-east-1',\n  'us-east-2',\n  'us-gov-east-1',\n  'us-gov-west-1',\n  'us-west-1',\n  'us-west-2',\n] as const;\n\nexport type AWSS3Region = typeof AWS_S3_REGIONS[number];\n\n/**\n * Retry a function with exponential backoff\n */\nexport async function retryWithBackoff<T>(\n  fn: () => Promise<T>,\n  maxRetries: number,\n  retryDelay: number,\n  operationName: string\n): Promise<T> {\n  let lastError: Error | undefined;\n\n  const totalAttempts = maxRetries + 1;\n\n  for (let attempt = 1; attempt <= totalAttempts; attempt++) {\n    try {\n      return await fn();\n    } catch (error) {\n      const err = error as Error & { name?: string; $metadata?: { httpStatusCode?: number } };\n      const message = err.message || '';\n\n      // non-retryable authorization/permission errors - fail fast\n      const isAuthError =\n        /accessdenied|access denied|not authorized|unauthorizedoperation|you do not have permission/i.test(message) ||\n        err.name === 'AccessDeniedException' ||\n        err.name === 'UnauthorizedOperation';\n\n      // non-retryable EB application version already-exists errors - fail fast\n      const isAppVersionExistsError =\n        /application version .* already exists/i.test(message) ||\n        (err.name === 'InvalidParameterValueException' && /already exists/i.test(message));\n\n      if (isAuthError || isAppVersionExistsError) {\n        throw err;\n      }\n\n      lastError = err;\n\n      if (attempt < totalAttempts) {\n        const delay = retryDelay * Math.pow(2, attempt - 1);\n        core.warning(` ${operationName} failed (attempt ${attempt}/${totalAttempts}). Retrying in ${delay}s...`);\n        await new Promise(resolve => setTimeout(resolve, delay * 1000));\n      }\n    }\n  }\n\n  const retryWord = maxRetries === 1 ? 'retry' : 'retries';\n  const errorMessage = `${operationName} failed after ${totalAttempts} attempts (${maxRetries} ${retryWord}): ${lastError?.message}`;\n  core.error(errorMessage);\n  throw new Error(errorMessage);\n}\n\n/**\n * Get AWS account ID\n */\nexport async function getAwsAccountId(\n  clients: AWSClients,\n  maxRetries: number,\n  retryDelay: number\n): Promise<string> {\n  return retryWithBackoff(\n    async () => {\n      const command = new GetCallerIdentityCommand({});\n      const response = await clients.getSTSClient().send(command);\n      return response.Account!;\n    },\n    maxRetries,\n    retryDelay,\n    'Get AWS Account ID'\n  );\n}\n\n/**\n * Check if an application version exists\n */\nexport async function applicationVersionExists(\n  clients: AWSClients,\n  applicationName: string,\n  versionLabel: string\n): Promise<boolean> {\n  try {\n    const command = new DescribeApplicationVersionsCommand({\n      ApplicationName: applicationName,\n      VersionLabels: [versionLabel],\n    });\n\n    const response = await clients.getElasticBeanstalkClient().send(command);\n    return (response.ApplicationVersions?.length ?? 0) > 0;\n  } catch (error) {\n    core.debug(`Error checking application version ${versionLabel} existence: ${error}`);\n    return false;\n  }\n}\n\n/**\n * Get S3 location for an existing version\n */\nexport async function getVersionS3Location(\n  clients: AWSClients,\n  applicationName: string,\n  versionLabel: string\n): Promise<{ bucket: string; key: string }> {\n  try {\n    const command = new DescribeApplicationVersionsCommand({\n      ApplicationName: applicationName,\n      VersionLabels: [versionLabel],\n    });\n\n    const response = await clients.getElasticBeanstalkClient().send(command);\n\n    if (!response.ApplicationVersions || response.ApplicationVersions.length === 0) {\n      throw new Error(`Version ${versionLabel} not found`);\n    }\n\n    const version = response.ApplicationVersions[0];\n    const bucket = version.SourceBundle?.S3Bucket;\n    const key = version.SourceBundle?.S3Key;\n\n    if (!bucket || !key) {\n      throw new Error(\n        `Application Version ${versionLabel} has incomplete S3 source bundle information. ` +\n        `Bucket ${bucket ? 'found' : 'missing'}, Key ${key ? 'found' : 'missing'}`\n      );\n    }\n\n    return { bucket, key };\n  } catch (error) {\n    throw new Error(`Failed to get S3 location for application version ${versionLabel}: ${error}`);\n  }\n}\n\n/**\n * Check if an environment exists\n */\nexport async function environmentExists(\n  clients: AWSClients,\n  applicationName: string,\n  environmentName: string\n): Promise<{ exists: boolean; status?: string; health?: string }> {\n  try {\n    const command = new DescribeEnvironmentsCommand({\n      ApplicationName: applicationName,\n      EnvironmentNames: [environmentName],\n    });\n\n    const response = await clients.getElasticBeanstalkClient().send(command);\n\n    if (response.Environments && response.Environments.length > 0) {\n      const env = response.Environments[0];\n      const status = env.Status;\n      const health = env.Health;\n      core.info(`Environment ${environmentName} found - Status: ${status}, Health: ${health}`);\n\n      const exists = status !== 'Terminated';\n      return { exists, status, health };\n    }\n\n    core.info(`No environments found with name ${environmentName}`);\n    return { exists: false };\n  } catch (error) {\n    const err = error as Error & { name?: string; $metadata?: { httpStatusCode?: number } };\n    const statusCode = err.$metadata?.httpStatusCode;\n    // Only treat \"not found\" responses as non-existent; rethrow real errors\n    // so callers receive a clear failure rather than a silent false negative.\n    if (statusCode === 404 || err.name === 'NoSuchEntityException') {\n      return { exists: false };\n    }\n    throw error;\n  }\n}\n\n/**\n * Upload deployment package to S3\n */\nexport async function uploadToS3(\n  clients: AWSClients,\n  region: string,\n  accountId: string,\n  applicationName: string,\n  versionLabel: string,\n  packagePath: string,\n  maxRetries: number,\n  retryDelay: number,\n  createBucketIfNotExists: boolean,\n  customBucketName?: string\n): Promise<{ bucket: string; key: string }> {\n  const bucket = customBucketName || `elasticbeanstalk-${region}-${accountId}`;\n  const packageExtension = path.extname(packagePath);\n  const key = `${applicationName}/${versionLabel}${packageExtension}`;\n\n  // Validate deployment package size\n  const fileStats = fs.statSync(packagePath);\n  const fileSizeBytes = fileStats.size;\n  const fileSizeMB = (fileSizeBytes / 1024 / 1024).toFixed(2);\n\n  if (fileSizeBytes > MAX_DEPLOYMENT_PACKAGE_SIZE_BYTES) {\n    const maxSizeMB = (MAX_DEPLOYMENT_PACKAGE_SIZE_BYTES / 1024 / 1024).toFixed(0);\n    throw new Error(\n      `Deployment package size (${fileSizeMB} MB) exceeds the maximum allowed size of ${maxSizeMB} MB. ` +\n      `Please reduce the package size and try again.`\n    );\n  }\n\n  if (createBucketIfNotExists) {\n    await createS3Bucket(clients, region, bucket, accountId, maxRetries, retryDelay);\n  } else {\n    // Verify bucket exists and is owned by this account before uploading.\n    // ExpectedBucketOwner causes a 403 if owned by a different account,\n    // which is safer than a raw PutObject that might write to the wrong bucket.\n    await clients.getS3Client().send(new HeadBucketCommand({\n      Bucket: bucket,\n      ExpectedBucketOwner: accountId,\n    }));\n  }\n\n  core.info(`  Uploading deployment package to S3`);\n  core.info(`   File size: ${fileSizeMB} MB`);\n\n  await retryWithBackoff(\n    async () => {\n      const command = new PutObjectCommand({\n        Bucket: bucket,\n        Key: key,\n        Body: fs.createReadStream(packagePath),\n        ContentLength: fileSizeBytes,\n      });\n\n      await clients.getS3Client().send(command);\n    },\n    maxRetries,\n    retryDelay,\n    'Upload to S3'\n  );\n\n  core.info(' Upload complete');\n  return { bucket, key };\n}\n\n/**\n * Create S3 bucket exists if not exists\n */\nexport async function createS3Bucket(\n  clients: AWSClients,\n  region: string,\n  bucket: string,\n  accountId: string,\n  maxRetries: number,\n  retryDelay: number\n): Promise<void> {\n  try {\n    core.info(' Checking if S3 bucket exists');\n    // ExpectedBucketOwner verifies ownership in the same request:\n    // - 200: bucket exists and is owned by this account\n    // - 403: bucket exists but is owned by a different account\n    // - 404: bucket does not exist\n    await clients.getS3Client().send(new HeadBucketCommand({\n      Bucket: bucket,\n      ExpectedBucketOwner: accountId,\n    }));\n    core.info(' S3 bucket exists');\n  } catch (error) {\n    const err = error as Error & { $metadata?: { httpStatusCode?: number } };\n\n    if (err.$metadata?.httpStatusCode === 403) {\n      throw new Error(\n        `S3 bucket '${bucket}' exists but is not owned by this AWS account (${accountId}). ` +\n        'Specify a different bucket name using the s3-bucket-name input.'\n      );\n    }\n\n    core.info(' S3 bucket does not exist, creating S3 bucket');\n\n    await retryWithBackoff(\n      async () => {\n        const createParams = region === 'us-east-1'\n          ? { Bucket: bucket }\n          : {\n              Bucket: bucket,\n              CreateBucketConfiguration: {\n                LocationConstraint: region as AWSS3Region,\n              },\n            };\n\n        await clients.getS3Client().send(new CreateBucketCommand(createParams));\n      },\n      maxRetries,\n      retryDelay,\n      'Create S3 bucket'\n    );\n\n    core.info(' S3 bucket created');\n  }\n}\n\n/**\n * Create an application version\n */\nexport async function createApplicationVersion(\n  clients: AWSClients,\n  applicationName: string,\n  versionLabel: string,\n  s3Bucket: string,\n  s3Key: string,\n  maxRetries: number,\n  retryDelay: number,\n  autoCreateApplication: boolean\n): Promise<void> {\n  core.info(` Creating application version: ${versionLabel}`);\n\n  await retryWithBackoff(\n    async () => {\n      const command = new CreateApplicationVersionCommand({\n        ApplicationName: applicationName,\n        VersionLabel: versionLabel,\n        SourceBundle: {\n          S3Bucket: s3Bucket,\n          S3Key: s3Key,\n        },\n        Description: `Deployed from GitHub Actions - ${process.env.GITHUB_SHA || 'manual'}`,\n        AutoCreateApplication: autoCreateApplication,\n      });\n\n      await clients.getElasticBeanstalkClient().send(command);\n    },\n    maxRetries,\n    retryDelay,\n    'Create application version'\n  );\n\n  core.info(` Application version ${versionLabel} created`);\n}\n\n/**\n * Update an existing environment\n */\nexport async function updateEnvironment(\n  clients: AWSClients,\n  applicationName: string,\n  environmentName: string,\n  versionLabel: string,\n  optionSettings: string | undefined,\n  solutionStackName: string | undefined,\n  platformArn: string | undefined,\n  maxRetries: number,\n  retryDelay: number\n): Promise<void> {\n  core.info(` Updating environment: ${environmentName}`);\n\n  let parsedOptionSettings: Array<{\n    Namespace?: string;\n    OptionName?: string;\n    Value?: string;\n  }> | undefined = undefined;\n  if (optionSettings) {\n    try {\n      const customSettings = parseJsonInput(optionSettings, 'option-settings');\n      if (Array.isArray(customSettings)) {\n        parsedOptionSettings = customSettings;\n      }\n    } catch (error) {\n      throw new Error(`Failed to parse option-settings: ${(error as Error).message}`);\n    }\n  }\n\n  await retryWithBackoff(\n    async () => {\n      const commandParams: any = {\n        ApplicationName: applicationName,\n        EnvironmentName: environmentName,\n        VersionLabel: versionLabel,\n        OptionSettings: parsedOptionSettings,\n      };\n\n      // Only set one of SolutionStackName or PlatformArn\n      if (solutionStackName) {\n        commandParams.SolutionStackName = solutionStackName;\n      } else if (platformArn) {\n        commandParams.PlatformArn = platformArn;\n      }\n\n      const command = new UpdateEnvironmentCommand(commandParams);\n\n      await clients.getElasticBeanstalkClient().send(command);\n    },\n    maxRetries,\n    retryDelay,\n    'Update environment'\n  );\n\n  core.info(` Environment update initiated for ${environmentName}`);\n}\n\n/**\n * Create a new environment\n */\nexport async function createEnvironment(\n  clients: AWSClients,\n  applicationName: string,\n  environmentName: string,\n  versionLabel: string,\n  optionSettingsJson: string,\n  solutionStackName: string | undefined,\n  platformArn: string | undefined,\n  maxRetries: number,\n  retryDelay: number\n): Promise<void> {\n  core.info(` Creating new environment: ${environmentName}`);\n\n  const optionSettings = parseJsonInput(optionSettingsJson, 'option-settings');\n\n  await retryWithBackoff(\n    async () => {\n      const commandParams: any = {\n        ApplicationName: applicationName,\n        EnvironmentName: environmentName,\n        VersionLabel: versionLabel,\n        CNAMEPrefix: environmentName,\n        OptionSettings: optionSettings,\n      };\n\n      // Only set one of SolutionStackName or PlatformArn\n      if (solutionStackName) {\n        commandParams.SolutionStackName = solutionStackName;\n      } else if (platformArn) {\n        commandParams.PlatformArn = platformArn;\n      }\n\n      const command = new CreateEnvironmentCommand(commandParams);\n\n      await clients.getElasticBeanstalkClient().send(command);\n    },\n    maxRetries,\n    retryDelay,\n    'Create environment'\n  );\n\n  core.info(` Environment creation initiated for ${environmentName}`);\n}\n\n/**\n * Get environment information\n */\nexport async function getEnvironmentInfo(\n  clients: AWSClients,\n  applicationName: string,\n  environmentName: string\n): Promise<{ url: string; id: string; status: string; health: string }> {\n  const command = new DescribeEnvironmentsCommand({\n    ApplicationName: applicationName,\n    EnvironmentNames: [environmentName],\n  });\n\n  const response = await clients.getElasticBeanstalkClient().send(command);\n\n  if (!response.Environments || response.Environments.length === 0) {\n    throw new Error(`Environment ${environmentName} not found after deployment`);\n  }\n\n  const env = response.Environments[0];\n\n  return {\n    url: env.CNAME || '',\n    id: env.EnvironmentId || '',\n    status: env.Status || '',\n    health: env.Health || '',\n  };\n}\n","import * as core from '@actions/core';\nimport * as fs from 'fs';\nimport archiver from 'archiver';\n\n/**\n * Creates a deployment package for Elastic Beanstalk\n * @param packagePath - Path to existing package (optional)\n * @param versionLabel - Version label for the deployment\n * @param excludePatternsInput - Comma-separated patterns to exclude\n * @returns Object containing the path to the deployment package\n */\nexport async function createDeploymentPackage(\n  packagePath: string | undefined,\n  versionLabel: string,\n  excludePatternsInput: string\n): Promise<{ path: string }> {\n  if (packagePath) {\n    // deployment-package-path explicitly provided by user\n    if (!fs.existsSync(packagePath)) {\n      throw new Error(\n        `deployment-package-path '${packagePath}' does not exist. ` +\n        'Either provide a valid file path or omit deployment-package-path to have the action create a package automatically.'\n      );\n    }\n\n    const stats = fs.statSync(packagePath);\n    if (!stats.isFile()) {\n      throw new Error(\n        `deployment-package-path '${packagePath}' is not a file. ` +\n        'It must point to an existing deployment archive file (e.g., .zip, .war).'\n      );\n    }\n\n    core.info(` Using existing deployment package: ${packagePath}`);\n    return { path: packagePath };\n  }\n\n  // No explicit package path provided  create a new deployment package from the workspace.\n  const zipFileName = `deploy-${versionLabel}.zip`;\n  core.info(` Creating deployment package: ${zipFileName}`);\n\n  const excludePatterns = excludePatternsInput\n    .split(',')\n    .map(p => p.trim())\n    .filter(p => p.length > 0);\n\n  await createZipFile(zipFileName, excludePatterns);\n\n  return { path: zipFileName };\n}\n\n/**\n * Creates a zip file using archiver\n */\nasync function createZipFile(zipFileName: string, excludePatterns: string[]): Promise<void> {\n  return new Promise((resolve, reject) => {\n    const output = fs.createWriteStream(zipFileName);\n    const archive = archiver('zip');\n\n    output.on('close', () => resolve());\n    archive.on('error', reject);\n\n    archive.pipe(output);\n    archive.glob('**/*', { ignore: excludePatterns, dot: true });\n    archive.finalize();\n  });\n}\n","import * as core from '@actions/core';\nimport { validateAllInputs, Inputs } from './validations';\nimport { AWSClients } from './aws-clients';\nimport { createDeploymentPackage } from './deploymentpackage';\nimport {\n  getAwsAccountId,\n  applicationVersionExists,\n  getVersionS3Location,\n  uploadToS3,\n  createApplicationVersion,\n  environmentExists,\n  updateEnvironment,\n  createEnvironment,\n  getEnvironmentInfo,\n  validateOptionSettingsForCreate,\n} from './aws-operations';\nimport { waitForDeploymentCompletion, waitForHealthRecovery } from './monitoring';\n\nexport async function run(): Promise<void> {\n  const startTime = Date.now();\n\n  try {\n    core.info(' Starting Elastic Beanstalk deployment...');\n\n    const inputs = validateAllInputs();\n    if (!inputs.valid) {\n      return;\n    }\n\n    const {\n      awsRegion, applicationName, environmentName, applicationVersionLabel,\n      deploymentPackagePath, solutionStackName, platformArn,\n      createEnvironmentIfNotExists, createApplicationIfNotExists, waitForDeployment,\n      waitForEnvironmentRecovery, deploymentTimeout, maxRetries, retryDelay,\n      useExistingApplicationVersionIfAvailable, createS3BucketIfNotExists, s3BucketName, excludePatterns,\n      optionSettings\n    } = inputs as Inputs;\n\n    core.startGroup(' Validating inputs');\n    core.info(`Application: ${applicationName}`);\n    core.info(`Environment: ${environmentName}`);\n    core.info(`Version: ${applicationVersionLabel}`);\n    core.info(`Region: ${awsRegion}`);\n    core.endGroup();\n\n    // Initialize AWS clients singleton\n    const clients = AWSClients.getInstance(awsRegion);\n\n    core.startGroup(' Getting AWS account information');\n    const accountId = await getAwsAccountId(clients, maxRetries, retryDelay);\n    core.info(' AWS account verified');\n    core.endGroup();\n\n    core.startGroup(' Creating deployment package');\n    const { path: packagePath } = await createDeploymentPackage(\n      deploymentPackagePath,\n      applicationVersionLabel,\n      excludePatterns\n    );\n    core.endGroup();\n\n    // Check if we should reuse existing application version\n    let bucket: string;\n    let key: string;\n    const shouldCreateNewApplicationVersion = !useExistingApplicationVersionIfAvailable || !(await applicationVersionExists(clients, applicationName, applicationVersionLabel));\n\n    if (shouldCreateNewApplicationVersion) {\n      core.startGroup('  Uploading to S3');\n      const uploadResult = await uploadToS3(\n        clients,\n        awsRegion,\n        accountId,\n        applicationName,\n        applicationVersionLabel,\n        packagePath,\n        maxRetries,\n        retryDelay,\n        createS3BucketIfNotExists,\n        s3BucketName\n      );\n      bucket = uploadResult.bucket;\n      key = uploadResult.key;\n      core.endGroup();\n\n      core.startGroup(` Creating application version ${applicationVersionLabel}`);\n      await createApplicationVersion(\n        clients,\n        applicationName,\n        applicationVersionLabel,\n        bucket,\n        key,\n        maxRetries,\n        retryDelay,\n        createApplicationIfNotExists\n      );\n      core.endGroup();\n    } else {\n      core.startGroup('  Reusing existing version');\n      core.info(`Version ${applicationVersionLabel} already exists, skipping S3 upload and version creation`);\n      const s3Location = await getVersionS3Location(clients, applicationName, applicationVersionLabel);\n      bucket = s3Location.bucket;\n      key = s3Location.key;\n      core.endGroup();\n    }\n\n    core.startGroup(' Checking environment status');\n    const { exists: envExists } = await environmentExists(\n      clients,\n      applicationName,\n      environmentName\n    );\n    core.endGroup();\n\n    let deploymentActionType: 'create' | 'update';\n    const deploymentStartTime = new Date();\n\n    if (envExists) {\n      core.startGroup(' Updating environment');\n      await updateEnvironment(\n        clients,\n        applicationName,\n        environmentName,\n        applicationVersionLabel,\n        optionSettings,\n        solutionStackName,\n        platformArn,\n        maxRetries,\n        retryDelay\n      );\n      deploymentActionType = 'update';\n      core.endGroup();\n    } else {\n      if (!createEnvironmentIfNotExists) {\n        throw new Error(`Environment ${environmentName} does not exist and create-environment-if-not-exists is false`);\n      }\n\n      // Validate option-settings with IAM roles are provided when creating environment\n      validateOptionSettingsForCreate(optionSettings);\n\n      // When creating a new environment, either solution-stack-name or platform-arn must be provided\n      if (!solutionStackName && !platformArn) {\n        throw new Error('Either solution-stack-name or platform-arn must be provided when creating a new environment');\n      }\n\n      core.startGroup(' Creating new environment');\n      \n      await createEnvironment(\n        clients,\n        applicationName,\n        environmentName,\n        applicationVersionLabel,\n        optionSettings!,\n        solutionStackName,\n        platformArn,\n        maxRetries,\n        retryDelay\n      );\n      deploymentActionType = 'create';\n      core.endGroup();\n    }\n\n    let lastSeenEventDate: Date | undefined;\n    if (waitForDeployment) {\n      core.startGroup(' Waiting for deployment');\n      lastSeenEventDate = await waitForDeploymentCompletion(clients, applicationName, environmentName, deploymentTimeout, deploymentActionType, deploymentStartTime);\n      core.endGroup();\n    }\n    if (waitForEnvironmentRecovery) {\n      core.startGroup(' Waiting for environment health');\n      await waitForHealthRecovery(clients, applicationName, environmentName, deploymentTimeout, deploymentStartTime, lastSeenEventDate);\n      core.endGroup();\n    }\n\n    const envInfo = await getEnvironmentInfo(clients, applicationName, environmentName);\n\n    core.setOutput('environment-url', envInfo.url);\n    core.setOutput('environment-id', envInfo.id);\n    core.setOutput('environment-status', envInfo.status);\n    core.setOutput('environment-health', envInfo.health);\n    core.setOutput('deployment-action-type', deploymentActionType);\n    core.setOutput('version-label', applicationVersionLabel);\n\n    const totalTime = Math.round((Date.now() - startTime) / 1000);\n    \n    core.startGroup(' Deployment Outputs');\n    core.info(`Environment URL: ${envInfo.url}`);\n    core.info(`Environment ID: ${envInfo.id}`);\n    core.info(`Environment Status: ${envInfo.status}`);\n    core.info(`Environment Health: ${envInfo.health}`);\n    core.info(`Deployment Action: ${deploymentActionType}`);\n    core.info(`Application Version Label: ${applicationVersionLabel}`);\n    core.endGroup();\n    \n    core.info(` Deployment successful! (${deploymentActionType}) - Total time: ${totalTime}s`);\n\n  } catch (error) {\n    const totalTime = Math.round((Date.now() - startTime) / 1000);\n    core.error(` Deployment failed after ${totalTime}s: ${(error as Error).message}`);\n    core.setFailed(`Deployment failed: ${(error as Error).message}`);\n  }\n}\n\nif (require.main === module) {\n  void run();\n}\n","import * as core from '@actions/core';\nimport {\n  DescribeEnvironmentsCommand,\n  DescribeEventsCommand,\n} from '@aws-sdk/client-elastic-beanstalk';\nimport { AWSClients } from './aws-clients';\n\n/**\n * Fetch recent environment events for debugging and check for fatal/error events\n */\nasync function describeRecentEvents(\n  clients: AWSClients,\n  applicationName: string,\n  environmentName: string,\n  lastSeenEventDate?: Date,\n  deploymentStartTime?: Date\n): Promise<{ hasError: boolean; errorMessage?: string; lastEventDate?: Date }> {\n  try {\n    const command = new DescribeEventsCommand({\n      ApplicationName: applicationName,\n      EnvironmentName: environmentName,\n      MaxRecords: 10,\n    });\n\n    const response = await clients.getElasticBeanstalkClient().send(command);\n\n    if (response.Events && response.Events.length > 0) {\n      const newEvents = response.Events.filter((event) => {\n        const eventDate = event.EventDate;\n        if (!eventDate) return false;\n\n        // Must be after deployment start time\n        if (deploymentStartTime && eventDate <= deploymentStartTime) {\n          return false;\n        }\n\n        // Must be after last seen event date\n        if (lastSeenEventDate && eventDate <= lastSeenEventDate) {\n          return false;\n        }\n\n        return true;\n      });\n\n      if (newEvents.length > 0) {\n        // Only show header on first call\n        if (!lastSeenEventDate) {\n          core.info(' Recent events:');\n        }\n        \n        // Sort events by timestamp in ascending order (oldest first)\n        const sortedEvents = [...newEvents].sort((a, b) => {\n          const dateA = a.EventDate?.getTime() || 0;\n          const dateB = b.EventDate?.getTime() || 0;\n          return dateA - dateB;\n        });\n        \n        const fatalOrErrorEvents: Array<{ message: string }> = [];\n        let mostRecentDate: Date | undefined;\n        \n        sortedEvents.forEach((event) => {\n          const eventDate = event.EventDate;\n          if (eventDate) {\n            // Track the most recent event date\n            if (!mostRecentDate || eventDate > mostRecentDate) {\n              mostRecentDate = eventDate;\n            }\n          }\n          \n          const timestamp = eventDate?.toISOString() || 'Unknown time';\n          const severity = event.Severity || 'INFO';\n          const message = event.Message || 'No message';\n\n          if (severity === 'ERROR' || severity === 'FATAL') {\n            core.error(`  [${timestamp}] ${severity}: ${message}`);\n            fatalOrErrorEvents.push({ message });\n          } else if (severity === 'WARN') {\n            core.warning(`  [${timestamp}] ${severity}: ${message}`);\n          } else {\n            core.info(`  [${timestamp}] ${severity}: ${message}`);\n          }\n        });\n\n        if (fatalOrErrorEvents.length > 0) {\n          const errorMessage = fatalOrErrorEvents[0].message || 'Unknown error occurred';\n          return { hasError: true, errorMessage, lastEventDate: mostRecentDate };\n        }\n        \n        return { hasError: false, lastEventDate: mostRecentDate };\n      }\n    }    \n    return { hasError: false, lastEventDate: lastSeenEventDate };\n  } catch (error) {\n    // If we can't fetch events, just log and continue\n    core.debug(`Failed to fetch events: ${error}`);\n    return { hasError: false, lastEventDate: lastSeenEventDate };\n  }\n}\n\n/**\n * Wait for deployment to complete\n * Returns the last seen event date to avoid duplicate events in subsequent monitoring\n */\nexport async function waitForDeploymentCompletion(\n  clients: AWSClients,\n  applicationName: string,\n  environmentName: string,\n  timeout: number,\n  deploymentActionType?: 'create' | 'update',\n  deploymentStartTime?: Date\n): Promise<Date | undefined> {\n  core.info(' Waiting for deployment to complete...');\n\n  const startTime = Date.now();\n  const maxWait = timeout * 1000;\n  let previousStatus: string | undefined;\n  let lastSeenEventDate: Date | undefined;\n  \n  // Poll every 20 seconds for create, 10 seconds for update\n  const pollInterval = deploymentActionType === 'create' ? 20000 : 10000;\n\n  while (Date.now() - startTime < maxWait) {\n    const command = new DescribeEnvironmentsCommand({\n      ApplicationName: applicationName,\n      EnvironmentNames: [environmentName],\n    });\n\n    const response = await clients.getElasticBeanstalkClient().send(command);\n\n    if (response.Environments && response.Environments.length > 0) {\n      const env = response.Environments[0];\n      const status = env.Status;\n\n      if (status === 'Ready') {\n        // Fetch and display final events before completing\n        const finalEvents = await describeRecentEvents(\n          clients,\n          applicationName,\n          environmentName,\n          lastSeenEventDate,\n          deploymentStartTime\n        );\n        core.info(' Deployment complete');\n        return finalEvents.lastEventDate || lastSeenEventDate;\n      }\n\n      // Check for fatal/error events during deployment\n      const eventCheck = await describeRecentEvents(\n        clients,\n        applicationName,\n        environmentName,\n        lastSeenEventDate,\n        deploymentStartTime\n      );\n\n      lastSeenEventDate = eventCheck.lastEventDate;\n\n      if (eventCheck.hasError) {\n        throw new Error(\n          `Environment deployment failed - fatal or error event detected: ${eventCheck.errorMessage}`\n        );\n      }\n\n      // Only log when status changes\n      if (status !== previousStatus) {\n        core.info(`Current status: ${status}`);\n        previousStatus = status;\n      }\n    }\n\n    await new Promise(resolve => setTimeout(resolve, pollInterval));\n  }\n\n  // Timeout occurred - fetch events to help diagnose\n  await describeRecentEvents(clients, applicationName, environmentName, lastSeenEventDate, deploymentStartTime);\n  throw new Error(`Deployment timed out after ${timeout}s`);\n}\n\n/**\n * Wait for environment health to recover\n */\nexport async function waitForHealthRecovery(\n  clients: AWSClients,\n  applicationName: string,\n  environmentName: string,\n  timeout: number,\n  deploymentStartTime?: Date,\n  lastEventDateFromDeployment?: Date\n): Promise<void> {\n  core.info(' Waiting for environment health to recover...');\n\n  const startTime = Date.now();\n  const maxWait = timeout * 1000;\n  let previousStatus: string | undefined;\n  let previousHealth: string | undefined;\n  let lastSeenEventDate: Date | undefined = lastEventDateFromDeployment;\n\n  while (Date.now() - startTime < maxWait) {\n    const command = new DescribeEnvironmentsCommand({\n      ApplicationName: applicationName,\n      EnvironmentNames: [environmentName],\n    });\n\n    const response = await clients.getElasticBeanstalkClient().send(command);\n\n    if (response.Environments && response.Environments.length > 0) {\n      const env = response.Environments[0];\n      const health = env.Health;\n      const status = env.Status;\n\n      if (health === 'Green' || health === 'Yellow') {\n        core.info(' Environment is healthy!');\n        return;\n      }\n\n      if (health === 'Grey' || health === undefined || health === 'Red') {\n        const eventCheck = await describeRecentEvents(\n          clients,\n          applicationName,\n          environmentName,\n          lastSeenEventDate,\n          deploymentStartTime\n        );\n\n        if (eventCheck.lastEventDate) {\n          lastSeenEventDate = eventCheck.lastEventDate;\n        }\n\n        if (eventCheck.hasError) {\n          throw new Error(\n            `Environment health recovery failed - fatal or error event detected: ${eventCheck.errorMessage}`\n          );\n        }\n\n        if (health === 'Red' && status === 'Ready') {\n          throw new Error('Environment health recovery failed - health is Red');\n        }\n      }\n\n      if (status !== previousStatus || health !== previousHealth) {\n        core.info(`Current status: ${status}, health: ${health}`);\n        previousStatus = status;\n        previousHealth = health;\n      }\n    }\n    await new Promise(resolve => setTimeout(resolve, 15000));\n  }\n\n  // Timeout occurred - fetch events to help diagnose\n  await describeRecentEvents(clients, applicationName, environmentName, lastSeenEventDate, deploymentStartTime);\n  throw new Error(`Environment health recovery timed out after ${timeout}s`);\n}\n","import * as core from '@actions/core';\n\nexport interface Inputs {\n  awsRegion: string;\n  applicationName: string;\n  environmentName: string;\n  applicationVersionLabel: string;\n  deploymentPackagePath?: string;\n  solutionStackName?: string;\n  platformArn?: string;\n  createEnvironmentIfNotExists: boolean;\n  createApplicationIfNotExists: boolean;\n  waitForDeployment: boolean;\n  waitForEnvironmentRecovery: boolean;\n  deploymentTimeout: number;\n  maxRetries: number;\n  retryDelay: number;\n  useExistingApplicationVersionIfAvailable: boolean;\n  createS3BucketIfNotExists: boolean;\n  s3BucketName?: string;\n  excludePatterns: string;\n  optionSettings?: string;\n}\n\nfunction validateRequiredInputs() {\n  const awsRegion = core.getInput('aws-region', { required: true });\n  const applicationName = core.getInput('application-name', { required: true });\n  const environmentName = core.getInput('environment-name', { required: true });\n  const solutionStackName = core.getInput('solution-stack-name') || undefined;\n  const platformArn = core.getInput('platform-arn') || undefined;\n\n  // Validate that both solution-stack-name AND platform-arn are not provided together\n  if (solutionStackName && platformArn) {\n    core.setFailed('Cannot specify both solution-stack-name and platform-arn. Use only one.');\n    return { valid: false };\n  }\n\n  // Validate AWS region format (e.g., us-east-1, eu-west-2, us-gov-east-1)\n  const regionPattern = /^(us(-gov)?|af|ap|ca|eu|il|me|sa)-(north|south|east|west|central|northeast|southeast|northwest|southwest)-\\d$/;\n  if (!regionPattern.test(awsRegion)) {\n    core.setFailed(`Invalid AWS region format: ${awsRegion}. Expected format like 'us-east-1' or 'us-gov-east-1'`);\n    return { valid: false };\n  }\n\n  return {\n    valid: true,\n    awsRegion,\n    applicationName,\n    environmentName,\n    solutionStackName,\n    platformArn\n  };\n}\n\nfunction validateNumericInputs() {\n  const deploymentTimeoutInput = core.getInput('deployment-timeout') || '900';\n  const maxRetriesInput = core.getInput('max-retries') || '2';\n  const retryDelayInput = core.getInput('retry-delay') || '5';\n\n  const deploymentTimeout = parseInt(deploymentTimeoutInput, 10);\n  const maxRetries = parseInt(maxRetriesInput, 10);\n  const retryDelay = parseInt(retryDelayInput, 10);\n\n  if (isNaN(deploymentTimeout)) {\n    core.setFailed(`Deployment timeout must be a number, got: ${deploymentTimeoutInput}`);\n    return { valid: false };\n  }\n\n  if (deploymentTimeout < 60) {\n    core.setFailed(`Deployment timeout must be at least 60 seconds, got: ${deploymentTimeout}`);\n    return { valid: false };\n  }\n\n  if (deploymentTimeout > 3600) {\n    core.setFailed(`Deployment timeout cannot exceed 3600 seconds (1 hour), got: ${deploymentTimeout}`);\n    return { valid: false };\n  }\n\n  if (isNaN(maxRetries)) {\n    core.setFailed(`Max retries must be a number, got: ${maxRetriesInput}`);\n    return { valid: false };\n  }\n\n  if (maxRetries < 0) {\n    core.setFailed(`Max retries cannot be negative, got: ${maxRetries}`);\n    return { valid: false };\n  }\n\n  if (maxRetries > 10) {\n    core.setFailed(`Max retries cannot exceed 10, got: ${maxRetries}`);\n    return { valid: false };\n  }\n\n  if (isNaN(retryDelay)) {\n    core.setFailed(`Retry delay must be a number, got: ${retryDelayInput}`);\n    return { valid: false };\n  }\n\n  if (retryDelay < 1) {\n    core.setFailed(`Retry delay must be at least 1 second, got: ${retryDelay}`);\n    return { valid: false };\n  }\n\n  if (retryDelay > 60) {\n    core.setFailed(`Retry delay cannot exceed 60 seconds, got: ${retryDelay}`);\n    return { valid: false };\n  }\n\n  return {\n    valid: true,\n    deploymentTimeout,\n    maxRetries,\n    retryDelay\n  };\n}\n\nfunction validateOptionalInputs() {\n  const applicationVersionLabel = core.getInput('version-label') || process.env.GITHUB_SHA || `v${Date.now()}`;\n  const deploymentPackagePath = core.getInput('deployment-package-path').trim() || undefined;\n  const excludePatterns = core.getInput('exclude-patterns').trim() || '';\n  const s3BucketName = core.getInput('s3-bucket-name') || undefined;\n  const optionSettings = core.getInput('option-settings') || undefined;\n\n  // Validate option-settings is valid JSON array if provided\n  if (optionSettings) {\n    try {\n      const parsed = JSON.parse(optionSettings);\n      if (!Array.isArray(parsed)) {\n        core.setFailed('option-settings must be a JSON array');\n        return { valid: false };\n      }\n    } catch (error) {\n      core.setFailed(`Invalid JSON in option-settings: ${(error as Error).message}`);\n      return { valid: false };\n    }\n  }\n\n  const createEnvironmentIfNotExists = core.getBooleanInput('create-environment-if-not-exists');\n  const createApplicationIfNotExists = core.getBooleanInput('create-application-if-not-exists');\n  const waitForDeployment = core.getBooleanInput('wait-for-deployment');\n  const waitForEnvironmentRecovery = core.getBooleanInput('wait-for-environment-recovery');\n  const useExistingApplicationVersionIfAvailable = core.getBooleanInput('use-existing-application-version-if-available');\n  const createS3BucketIfNotExists = core.getBooleanInput('create-s3-bucket-if-not-exists');\n\n  return {\n    valid: true,\n    applicationVersionLabel,\n    deploymentPackagePath,\n    createEnvironmentIfNotExists,\n    createApplicationIfNotExists,\n    waitForDeployment,\n    waitForEnvironmentRecovery,\n    useExistingApplicationVersionIfAvailable,\n    createS3BucketIfNotExists,\n    s3BucketName,\n    excludePatterns,\n    optionSettings\n  };\n}\n\nfunction checkInputConflicts(inputs: Partial<Inputs>): void {\n  // Check if deployment-package-path is provided WITH exclude-patterns\n  if (inputs.deploymentPackagePath && inputs.excludePatterns !== '') {\n    core.warning(\n      'Both deployment-package-path and exclude-patterns are specified. ' +\n      'exclude-patterns will be ignored since deployment-package-path takes precedence.'\n    );\n  }\n\n  // Check if create-application-if-not-exists is true but create-environment-if-not-exists is false\n  if (inputs.createApplicationIfNotExists && !inputs.createEnvironmentIfNotExists) {\n    core.warning(\n      'create-application-if-not-exists is true, but create-environment-if-not-exists is false. ' +\n      'The application will be created, but the environment will NOT be created if it does not exist.'\n    );\n  }\n\n  // Check if use-existing-application-version-if-available is true with deployment-timeout very low\n  if (inputs.useExistingApplicationVersionIfAvailable && inputs.deploymentTimeout && inputs.deploymentTimeout < 120) {\n    core.warning(\n      `use-existing-application-version-if-available is true with a low deployment-timeout (${inputs.deploymentTimeout}s). ` +\n      'If a new version needs to be created, deployment may timeout.'\n    );\n  }\n\n  // Check if max-retries is 0\n  if (inputs.maxRetries === 0) {\n    core.warning(\n      'max-retries is set to 0. API calls will not be retried on failure, which may cause transient errors to fail the deployment.'\n    );\n  }\n\n  // Check if create-s3-bucket-if-not-exists is false without a custom bucket name\n  if (inputs.createS3BucketIfNotExists === false && !inputs.s3BucketName) {\n    core.warning(\n      'create-s3-bucket-if-not-exists is false and no custom s3-bucket-name was provided. ' +\n      'The action will use the default Elastic Beanstalk bucket elasticbeanstalk-<region>-<account-id>. ' +\n      'If that bucket does not exist or is not writable, deployment will fail. Either create the default bucket or set s3-bucket-name to an existing bucket.'\n    );\n  }\n}\n\nexport function validateAllInputs(): { valid: boolean } & Partial<Inputs> {\n  const requiredInputs = validateRequiredInputs();\n  if (!requiredInputs.valid) {\n    return { valid: false };\n  }\n\n  const numericInputs = validateNumericInputs();\n  if (!numericInputs.valid) {\n    return { valid: false };\n  }\n\n  const optionalInputs = validateOptionalInputs();\n  if (!optionalInputs.valid) {\n    return { valid: false };\n  }\n\n  const validatedInputs = {\n    valid: true,\n    awsRegion: requiredInputs.awsRegion,\n    applicationName: requiredInputs.applicationName,\n    environmentName: requiredInputs.environmentName,\n    solutionStackName: requiredInputs.solutionStackName,\n    platformArn: requiredInputs.platformArn,\n    deploymentTimeout: numericInputs.deploymentTimeout,\n    maxRetries: numericInputs.maxRetries,\n    retryDelay: numericInputs.retryDelay,\n    applicationVersionLabel: optionalInputs.applicationVersionLabel!,\n    deploymentPackagePath: optionalInputs.deploymentPackagePath,\n    createEnvironmentIfNotExists: optionalInputs.createEnvironmentIfNotExists!,\n    createApplicationIfNotExists: optionalInputs.createApplicationIfNotExists!,\n    waitForDeployment: optionalInputs.waitForDeployment!,\n    waitForEnvironmentRecovery: optionalInputs.waitForEnvironmentRecovery!,\n    useExistingApplicationVersionIfAvailable: optionalInputs.useExistingApplicationVersionIfAvailable!,\n    createS3BucketIfNotExists: optionalInputs.createS3BucketIfNotExists!,\n    s3BucketName: optionalInputs.s3BucketName,\n    excludePatterns: optionalInputs.excludePatterns!,\n    optionSettings: optionalInputs.optionSettings\n  };\n\n  checkInputConflicts(validatedInputs);\n\n  return validatedInputs;\n}\n\nexport function parseJsonInput(jsonString: string, inputName: string) {\n  try {\n    return JSON.parse(jsonString);\n  } catch (error) {\n    throw new Error(`Invalid JSON in ${inputName} input: ${(error as Error).message}`);\n  }\n}\n","module.exports = require(\"assert\");","module.exports = require(\"buffer\");","module.exports = require(\"child_process\");","module.exports = require(\"constants\");","module.exports = require(\"crypto\");","module.exports = require(\"events\");","module.exports = require(\"fs\");","module.exports = require(\"fs/promises\");","module.exports = require(\"http\");","module.exports = require(\"http2\");","module.exports = require(\"https\");","module.exports = require(\"net\");","module.exports = require(\"node:assert\");","module.exports = require(\"node:async_hooks\");","module.exports = require(\"node:buffer\");","module.exports = require(\"node:console\");","module.exports = require(\"node:crypto\");","module.exports = require(\"node:diagnostics_channel\");","module.exports = require(\"node:dns\");","module.exports = require(\"node:events\");","module.exports = require(\"node:fs\");","module.exports = require(\"node:fs/promises\");","module.exports = require(\"node:http\");","module.exports = require(\"node:http2\");","module.exports = require(\"node:net\");","module.exports = require(\"node:os\");","module.exports = require(\"node:path\");","module.exports = require(\"node:perf_hooks\");","module.exports = require(\"node:querystring\");","module.exports = require(\"node:stream\");","module.exports = require(\"node:string_decoder\");","module.exports = require(\"node:tls\");","module.exports = require(\"node:url\");","module.exports = require(\"node:util\");","module.exports = require(\"node:util/types\");","module.exports = require(\"node:worker_threads\");","module.exports = require(\"node:zlib\");","module.exports = require(\"os\");","module.exports = require(\"path\");","module.exports = require(\"process\");","module.exports = require(\"stream\");","module.exports = require(\"string_decoder\");","module.exports = require(\"timers\");","module.exports = require(\"tls\");","module.exports = require(\"url\");","module.exports = require(\"util\");","module.exports = require(\"zlib\");","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Glob = void 0;\nconst minimatch_1 = require(\"minimatch\");\nconst node_url_1 = require(\"node:url\");\nconst path_scurry_1 = require(\"path-scurry\");\nconst pattern_js_1 = require(\"./pattern.js\");\nconst walker_js_1 = require(\"./walker.js\");\n// if no process global, just call it linux.\n// so we default to case-sensitive, / separators\nconst defaultPlatform = (typeof process === 'object' &&\n    process &&\n    typeof process.platform === 'string') ?\n    process.platform\n    : 'linux';\n/**\n * An object that can perform glob pattern traversals.\n */\nclass Glob {\n    absolute;\n    cwd;\n    root;\n    dot;\n    dotRelative;\n    follow;\n    ignore;\n    magicalBraces;\n    mark;\n    matchBase;\n    maxDepth;\n    nobrace;\n    nocase;\n    nodir;\n    noext;\n    noglobstar;\n    pattern;\n    platform;\n    realpath;\n    scurry;\n    stat;\n    signal;\n    windowsPathsNoEscape;\n    withFileTypes;\n    includeChildMatches;\n    /**\n     * The options provided to the constructor.\n     */\n    opts;\n    /**\n     * An array of parsed immutable {@link Pattern} objects.\n     */\n    patterns;\n    /**\n     * All options are stored as properties on the `Glob` object.\n     *\n     * See {@link GlobOptions} for full options descriptions.\n     *\n     * Note that a previous `Glob` object can be passed as the\n     * `GlobOptions` to another `Glob` instantiation to re-use settings\n     * and caches with a new pattern.\n     *\n     * Traversal functions can be called multiple times to run the walk\n     * again.\n     */\n    constructor(pattern, opts) {\n        /* c8 ignore start */\n        if (!opts)\n            throw new TypeError('glob options required');\n        /* c8 ignore stop */\n        this.withFileTypes = !!opts.withFileTypes;\n        this.signal = opts.signal;\n        this.follow = !!opts.follow;\n        this.dot = !!opts.dot;\n        this.dotRelative = !!opts.dotRelative;\n        this.nodir = !!opts.nodir;\n        this.mark = !!opts.mark;\n        if (!opts.cwd) {\n            this.cwd = '';\n        }\n        else if (opts.cwd instanceof URL || opts.cwd.startsWith('file://')) {\n            opts.cwd = (0, node_url_1.fileURLToPath)(opts.cwd);\n        }\n        this.cwd = opts.cwd || '';\n        this.root = opts.root;\n        this.magicalBraces = !!opts.magicalBraces;\n        this.nobrace = !!opts.nobrace;\n        this.noext = !!opts.noext;\n        this.realpath = !!opts.realpath;\n        this.absolute = opts.absolute;\n        this.includeChildMatches = opts.includeChildMatches !== false;\n        this.noglobstar = !!opts.noglobstar;\n        this.matchBase = !!opts.matchBase;\n        this.maxDepth =\n            typeof opts.maxDepth === 'number' ? opts.maxDepth : Infinity;\n        this.stat = !!opts.stat;\n        this.ignore = opts.ignore;\n        if (this.withFileTypes && this.absolute !== undefined) {\n            throw new Error('cannot set absolute and withFileTypes:true');\n        }\n        if (typeof pattern === 'string') {\n            pattern = [pattern];\n        }\n        this.windowsPathsNoEscape =\n            !!opts.windowsPathsNoEscape ||\n                opts.allowWindowsEscape ===\n                    false;\n        if (this.windowsPathsNoEscape) {\n            pattern = pattern.map(p => p.replace(/\\\\/g, '/'));\n        }\n        if (this.matchBase) {\n            if (opts.noglobstar) {\n                throw new TypeError('base matching requires globstar');\n            }\n            pattern = pattern.map(p => (p.includes('/') ? p : `./**/${p}`));\n        }\n        this.pattern = pattern;\n        this.platform = opts.platform || defaultPlatform;\n        this.opts = { ...opts, platform: this.platform };\n        if (opts.scurry) {\n            this.scurry = opts.scurry;\n            if (opts.nocase !== undefined &&\n                opts.nocase !== opts.scurry.nocase) {\n                throw new Error('nocase option contradicts provided scurry option');\n            }\n        }\n        else {\n            const Scurry = opts.platform === 'win32' ? path_scurry_1.PathScurryWin32\n                : opts.platform === 'darwin' ? path_scurry_1.PathScurryDarwin\n                    : opts.platform ? path_scurry_1.PathScurryPosix\n                        : path_scurry_1.PathScurry;\n            this.scurry = new Scurry(this.cwd, {\n                nocase: opts.nocase,\n                fs: opts.fs,\n            });\n        }\n        this.nocase = this.scurry.nocase;\n        // If you do nocase:true on a case-sensitive file system, then\n        // we need to use regexps instead of strings for non-magic\n        // path portions, because statting `aBc` won't return results\n        // for the file `AbC` for example.\n        const nocaseMagicOnly = this.platform === 'darwin' || this.platform === 'win32';\n        const mmo = {\n            // default nocase based on platform\n            ...opts,\n            dot: this.dot,\n            matchBase: this.matchBase,\n            nobrace: this.nobrace,\n            nocase: this.nocase,\n            nocaseMagicOnly,\n            nocomment: true,\n            noext: this.noext,\n            nonegate: true,\n            optimizationLevel: 2,\n            platform: this.platform,\n            windowsPathsNoEscape: this.windowsPathsNoEscape,\n            debug: !!this.opts.debug,\n        };\n        const mms = this.pattern.map(p => new minimatch_1.Minimatch(p, mmo));\n        const [matchSet, globParts] = mms.reduce((set, m) => {\n            set[0].push(...m.set);\n            set[1].push(...m.globParts);\n            return set;\n        }, [[], []]);\n        this.patterns = matchSet.map((set, i) => {\n            const g = globParts[i];\n            /* c8 ignore start */\n            if (!g)\n                throw new Error('invalid pattern object');\n            /* c8 ignore stop */\n            return new pattern_js_1.Pattern(set, g, 0, this.platform);\n        });\n    }\n    async walk() {\n        // Walkers always return array of Path objects, so we just have to\n        // coerce them into the right shape.  It will have already called\n        // realpath() if the option was set to do so, so we know that's cached.\n        // start out knowing the cwd, at least\n        return [\n            ...(await new walker_js_1.GlobWalker(this.patterns, this.scurry.cwd, {\n                ...this.opts,\n                maxDepth: this.maxDepth !== Infinity ?\n                    this.maxDepth + this.scurry.cwd.depth()\n                    : Infinity,\n                platform: this.platform,\n                nocase: this.nocase,\n                includeChildMatches: this.includeChildMatches,\n            }).walk()),\n        ];\n    }\n    walkSync() {\n        return [\n            ...new walker_js_1.GlobWalker(this.patterns, this.scurry.cwd, {\n                ...this.opts,\n                maxDepth: this.maxDepth !== Infinity ?\n                    this.maxDepth + this.scurry.cwd.depth()\n                    : Infinity,\n                platform: this.platform,\n                nocase: this.nocase,\n                includeChildMatches: this.includeChildMatches,\n            }).walkSync(),\n        ];\n    }\n    stream() {\n        return new walker_js_1.GlobStream(this.patterns, this.scurry.cwd, {\n            ...this.opts,\n            maxDepth: this.maxDepth !== Infinity ?\n                this.maxDepth + this.scurry.cwd.depth()\n                : Infinity,\n            platform: this.platform,\n            nocase: this.nocase,\n            includeChildMatches: this.includeChildMatches,\n        }).stream();\n    }\n    streamSync() {\n        return new walker_js_1.GlobStream(this.patterns, this.scurry.cwd, {\n            ...this.opts,\n            maxDepth: this.maxDepth !== Infinity ?\n                this.maxDepth + this.scurry.cwd.depth()\n                : Infinity,\n            platform: this.platform,\n            nocase: this.nocase,\n            includeChildMatches: this.includeChildMatches,\n        }).streamSync();\n    }\n    /**\n     * Default sync iteration function. Returns a Generator that\n     * iterates over the results.\n     */\n    iterateSync() {\n        return this.streamSync()[Symbol.iterator]();\n    }\n    [Symbol.iterator]() {\n        return this.iterateSync();\n    }\n    /**\n     * Default async iteration function. Returns an AsyncGenerator that\n     * iterates over the results.\n     */\n    iterate() {\n        return this.stream()[Symbol.asyncIterator]();\n    }\n    [Symbol.asyncIterator]() {\n        return this.iterate();\n    }\n}\nexports.Glob = Glob;\n//# sourceMappingURL=glob.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.hasMagic = void 0;\nconst minimatch_1 = require(\"minimatch\");\n/**\n * Return true if the patterns provided contain any magic glob characters,\n * given the options provided.\n *\n * Brace expansion is not considered \"magic\" unless the `magicalBraces` option\n * is set, as brace expansion just turns one string into an array of strings.\n * So a pattern like `'x{a,b}y'` would return `false`, because `'xay'` and\n * `'xby'` both do not contain any magic glob characters, and it's treated the\n * same as if you had called it on `['xay', 'xby']`. When `magicalBraces:true`\n * is in the options, brace expansion _is_ treated as a pattern having magic.\n */\nconst hasMagic = (pattern, options = {}) => {\n    if (!Array.isArray(pattern)) {\n        pattern = [pattern];\n    }\n    for (const p of pattern) {\n        if (new minimatch_1.Minimatch(p, options).hasMagic())\n            return true;\n    }\n    return false;\n};\nexports.hasMagic = hasMagic;\n//# sourceMappingURL=has-magic.js.map","\"use strict\";\n// give it a pattern, and it'll be able to tell you if\n// a given path should be ignored.\n// Ignoring a path ignores its children if the pattern ends in /**\n// Ignores are always parsed in dot:true mode\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Ignore = void 0;\nconst minimatch_1 = require(\"minimatch\");\nconst pattern_js_1 = require(\"./pattern.js\");\nconst defaultPlatform = (typeof process === 'object' &&\n    process &&\n    typeof process.platform === 'string') ?\n    process.platform\n    : 'linux';\n/**\n * Class used to process ignored patterns\n */\nclass Ignore {\n    relative;\n    relativeChildren;\n    absolute;\n    absoluteChildren;\n    platform;\n    mmopts;\n    constructor(ignored, { nobrace, nocase, noext, noglobstar, platform = defaultPlatform, }) {\n        this.relative = [];\n        this.absolute = [];\n        this.relativeChildren = [];\n        this.absoluteChildren = [];\n        this.platform = platform;\n        this.mmopts = {\n            dot: true,\n            nobrace,\n            nocase,\n            noext,\n            noglobstar,\n            optimizationLevel: 2,\n            platform,\n            nocomment: true,\n            nonegate: true,\n        };\n        for (const ign of ignored)\n            this.add(ign);\n    }\n    add(ign) {\n        // this is a little weird, but it gives us a clean set of optimized\n        // minimatch matchers, without getting tripped up if one of them\n        // ends in /** inside a brace section, and it's only inefficient at\n        // the start of the walk, not along it.\n        // It'd be nice if the Pattern class just had a .test() method, but\n        // handling globstars is a bit of a pita, and that code already lives\n        // in minimatch anyway.\n        // Another way would be if maybe Minimatch could take its set/globParts\n        // as an option, and then we could at least just use Pattern to test\n        // for absolute-ness.\n        // Yet another way, Minimatch could take an array of glob strings, and\n        // a cwd option, and do the right thing.\n        const mm = new minimatch_1.Minimatch(ign, this.mmopts);\n        for (let i = 0; i < mm.set.length; i++) {\n            const parsed = mm.set[i];\n            const globParts = mm.globParts[i];\n            /* c8 ignore start */\n            if (!parsed || !globParts) {\n                throw new Error('invalid pattern object');\n            }\n            // strip off leading ./ portions\n            // https://github.com/isaacs/node-glob/issues/570\n            while (parsed[0] === '.' && globParts[0] === '.') {\n                parsed.shift();\n                globParts.shift();\n            }\n            /* c8 ignore stop */\n            const p = new pattern_js_1.Pattern(parsed, globParts, 0, this.platform);\n            const m = new minimatch_1.Minimatch(p.globString(), this.mmopts);\n            const children = globParts[globParts.length - 1] === '**';\n            const absolute = p.isAbsolute();\n            if (absolute)\n                this.absolute.push(m);\n            else\n                this.relative.push(m);\n            if (children) {\n                if (absolute)\n                    this.absoluteChildren.push(m);\n                else\n                    this.relativeChildren.push(m);\n            }\n        }\n    }\n    ignored(p) {\n        const fullpath = p.fullpath();\n        const fullpaths = `${fullpath}/`;\n        const relative = p.relative() || '.';\n        const relatives = `${relative}/`;\n        for (const m of this.relative) {\n            if (m.match(relative) || m.match(relatives))\n                return true;\n        }\n        for (const m of this.absolute) {\n            if (m.match(fullpath) || m.match(fullpaths))\n                return true;\n        }\n        return false;\n    }\n    childrenIgnored(p) {\n        const fullpath = p.fullpath() + '/';\n        const relative = (p.relative() || '.') + '/';\n        for (const m of this.relativeChildren) {\n            if (m.match(relative))\n                return true;\n        }\n        for (const m of this.absoluteChildren) {\n            if (m.match(fullpath))\n                return true;\n        }\n        return false;\n    }\n}\nexports.Ignore = Ignore;\n//# sourceMappingURL=ignore.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.glob = exports.sync = exports.iterate = exports.iterateSync = exports.stream = exports.streamSync = exports.Ignore = exports.hasMagic = exports.Glob = exports.unescape = exports.escape = void 0;\nexports.globStreamSync = globStreamSync;\nexports.globStream = globStream;\nexports.globSync = globSync;\nexports.globIterateSync = globIterateSync;\nexports.globIterate = globIterate;\nconst minimatch_1 = require(\"minimatch\");\nconst glob_js_1 = require(\"./glob.js\");\nconst has_magic_js_1 = require(\"./has-magic.js\");\nvar minimatch_2 = require(\"minimatch\");\nObject.defineProperty(exports, \"escape\", { enumerable: true, get: function () { return minimatch_2.escape; } });\nObject.defineProperty(exports, \"unescape\", { enumerable: true, get: function () { return minimatch_2.unescape; } });\nvar glob_js_2 = require(\"./glob.js\");\nObject.defineProperty(exports, \"Glob\", { enumerable: true, get: function () { return glob_js_2.Glob; } });\nvar has_magic_js_2 = require(\"./has-magic.js\");\nObject.defineProperty(exports, \"hasMagic\", { enumerable: true, get: function () { return has_magic_js_2.hasMagic; } });\nvar ignore_js_1 = require(\"./ignore.js\");\nObject.defineProperty(exports, \"Ignore\", { enumerable: true, get: function () { return ignore_js_1.Ignore; } });\nfunction globStreamSync(pattern, options = {}) {\n    return new glob_js_1.Glob(pattern, options).streamSync();\n}\nfunction globStream(pattern, options = {}) {\n    return new glob_js_1.Glob(pattern, options).stream();\n}\nfunction globSync(pattern, options = {}) {\n    return new glob_js_1.Glob(pattern, options).walkSync();\n}\nasync function glob_(pattern, options = {}) {\n    return new glob_js_1.Glob(pattern, options).walk();\n}\nfunction globIterateSync(pattern, options = {}) {\n    return new glob_js_1.Glob(pattern, options).iterateSync();\n}\nfunction globIterate(pattern, options = {}) {\n    return new glob_js_1.Glob(pattern, options).iterate();\n}\n// aliases: glob.sync.stream() glob.stream.sync() glob.sync() etc\nexports.streamSync = globStreamSync;\nexports.stream = Object.assign(globStream, { sync: globStreamSync });\nexports.iterateSync = globIterateSync;\nexports.iterate = Object.assign(globIterate, {\n    sync: globIterateSync,\n});\nexports.sync = Object.assign(globSync, {\n    stream: globStreamSync,\n    iterate: globIterateSync,\n});\nexports.glob = Object.assign(glob_, {\n    glob: glob_,\n    globSync,\n    sync: exports.sync,\n    globStream,\n    stream: exports.stream,\n    globStreamSync,\n    streamSync: exports.streamSync,\n    globIterate,\n    iterate: exports.iterate,\n    globIterateSync,\n    iterateSync: exports.iterateSync,\n    Glob: glob_js_1.Glob,\n    hasMagic: has_magic_js_1.hasMagic,\n    escape: minimatch_1.escape,\n    unescape: minimatch_1.unescape,\n});\nexports.glob.glob = exports.glob;\n//# sourceMappingURL=index.js.map","\"use strict\";\n// this is just a very light wrapper around 2 arrays with an offset index\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Pattern = void 0;\nconst minimatch_1 = require(\"minimatch\");\nconst isPatternList = (pl) => pl.length >= 1;\nconst isGlobList = (gl) => gl.length >= 1;\n/**\n * An immutable-ish view on an array of glob parts and their parsed\n * results\n */\nclass Pattern {\n    #patternList;\n    #globList;\n    #index;\n    length;\n    #platform;\n    #rest;\n    #globString;\n    #isDrive;\n    #isUNC;\n    #isAbsolute;\n    #followGlobstar = true;\n    constructor(patternList, globList, index, platform) {\n        if (!isPatternList(patternList)) {\n            throw new TypeError('empty pattern list');\n        }\n        if (!isGlobList(globList)) {\n            throw new TypeError('empty glob list');\n        }\n        if (globList.length !== patternList.length) {\n            throw new TypeError('mismatched pattern list and glob list lengths');\n        }\n        this.length = patternList.length;\n        if (index < 0 || index >= this.length) {\n            throw new TypeError('index out of range');\n        }\n        this.#patternList = patternList;\n        this.#globList = globList;\n        this.#index = index;\n        this.#platform = platform;\n        // normalize root entries of absolute patterns on initial creation.\n        if (this.#index === 0) {\n            // c: => ['c:/']\n            // C:/ => ['C:/']\n            // C:/x => ['C:/', 'x']\n            // //host/share => ['//host/share/']\n            // //host/share/ => ['//host/share/']\n            // //host/share/x => ['//host/share/', 'x']\n            // /etc => ['/', 'etc']\n            // / => ['/']\n            if (this.isUNC()) {\n                // '' / '' / 'host' / 'share'\n                const [p0, p1, p2, p3, ...prest] = this.#patternList;\n                const [g0, g1, g2, g3, ...grest] = this.#globList;\n                if (prest[0] === '') {\n                    // ends in /\n                    prest.shift();\n                    grest.shift();\n                }\n                const p = [p0, p1, p2, p3, ''].join('/');\n                const g = [g0, g1, g2, g3, ''].join('/');\n                this.#patternList = [p, ...prest];\n                this.#globList = [g, ...grest];\n                this.length = this.#patternList.length;\n            }\n            else if (this.isDrive() || this.isAbsolute()) {\n                const [p1, ...prest] = this.#patternList;\n                const [g1, ...grest] = this.#globList;\n                if (prest[0] === '') {\n                    // ends in /\n                    prest.shift();\n                    grest.shift();\n                }\n                const p = p1 + '/';\n                const g = g1 + '/';\n                this.#patternList = [p, ...prest];\n                this.#globList = [g, ...grest];\n                this.length = this.#patternList.length;\n            }\n        }\n    }\n    /**\n     * The first entry in the parsed list of patterns\n     */\n    pattern() {\n        return this.#patternList[this.#index];\n    }\n    /**\n     * true of if pattern() returns a string\n     */\n    isString() {\n        return typeof this.#patternList[this.#index] === 'string';\n    }\n    /**\n     * true of if pattern() returns GLOBSTAR\n     */\n    isGlobstar() {\n        return this.#patternList[this.#index] === minimatch_1.GLOBSTAR;\n    }\n    /**\n     * true if pattern() returns a regexp\n     */\n    isRegExp() {\n        return this.#patternList[this.#index] instanceof RegExp;\n    }\n    /**\n     * The /-joined set of glob parts that make up this pattern\n     */\n    globString() {\n        return (this.#globString =\n            this.#globString ||\n                (this.#index === 0 ?\n                    this.isAbsolute() ?\n                        this.#globList[0] + this.#globList.slice(1).join('/')\n                        : this.#globList.join('/')\n                    : this.#globList.slice(this.#index).join('/')));\n    }\n    /**\n     * true if there are more pattern parts after this one\n     */\n    hasMore() {\n        return this.length > this.#index + 1;\n    }\n    /**\n     * The rest of the pattern after this part, or null if this is the end\n     */\n    rest() {\n        if (this.#rest !== undefined)\n            return this.#rest;\n        if (!this.hasMore())\n            return (this.#rest = null);\n        this.#rest = new Pattern(this.#patternList, this.#globList, this.#index + 1, this.#platform);\n        this.#rest.#isAbsolute = this.#isAbsolute;\n        this.#rest.#isUNC = this.#isUNC;\n        this.#rest.#isDrive = this.#isDrive;\n        return this.#rest;\n    }\n    /**\n     * true if the pattern represents a //unc/path/ on windows\n     */\n    isUNC() {\n        const pl = this.#patternList;\n        return this.#isUNC !== undefined ?\n            this.#isUNC\n            : (this.#isUNC =\n                this.#platform === 'win32' &&\n                    this.#index === 0 &&\n                    pl[0] === '' &&\n                    pl[1] === '' &&\n                    typeof pl[2] === 'string' &&\n                    !!pl[2] &&\n                    typeof pl[3] === 'string' &&\n                    !!pl[3]);\n    }\n    // pattern like C:/...\n    // split = ['C:', ...]\n    // XXX: would be nice to handle patterns like `c:*` to test the cwd\n    // in c: for *, but I don't know of a way to even figure out what that\n    // cwd is without actually chdir'ing into it?\n    /**\n     * True if the pattern starts with a drive letter on Windows\n     */\n    isDrive() {\n        const pl = this.#patternList;\n        return this.#isDrive !== undefined ?\n            this.#isDrive\n            : (this.#isDrive =\n                this.#platform === 'win32' &&\n                    this.#index === 0 &&\n                    this.length > 1 &&\n                    typeof pl[0] === 'string' &&\n                    /^[a-z]:$/i.test(pl[0]));\n    }\n    // pattern = '/' or '/...' or '/x/...'\n    // split = ['', ''] or ['', ...] or ['', 'x', ...]\n    // Drive and UNC both considered absolute on windows\n    /**\n     * True if the pattern is rooted on an absolute path\n     */\n    isAbsolute() {\n        const pl = this.#patternList;\n        return this.#isAbsolute !== undefined ?\n            this.#isAbsolute\n            : (this.#isAbsolute =\n                (pl[0] === '' && pl.length > 1) ||\n                    this.isDrive() ||\n                    this.isUNC());\n    }\n    /**\n     * consume the root of the pattern, and return it\n     */\n    root() {\n        const p = this.#patternList[0];\n        return (typeof p === 'string' && this.isAbsolute() && this.#index === 0) ?\n            p\n            : '';\n    }\n    /**\n     * Check to see if the current globstar pattern is allowed to follow\n     * a symbolic link.\n     */\n    checkFollowGlobstar() {\n        return !(this.#index === 0 ||\n            !this.isGlobstar() ||\n            !this.#followGlobstar);\n    }\n    /**\n     * Mark that the current globstar pattern is following a symbolic link\n     */\n    markFollowGlobstar() {\n        if (this.#index === 0 || !this.isGlobstar() || !this.#followGlobstar)\n            return false;\n        this.#followGlobstar = false;\n        return true;\n    }\n}\nexports.Pattern = Pattern;\n//# sourceMappingURL=pattern.js.map","\"use strict\";\n// synchronous utility for filtering entries and calculating subwalks\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Processor = exports.SubWalks = exports.MatchRecord = exports.HasWalkedCache = void 0;\nconst minimatch_1 = require(\"minimatch\");\n/**\n * A cache of which patterns have been processed for a given Path\n */\nclass HasWalkedCache {\n    store;\n    constructor(store = new Map()) {\n        this.store = store;\n    }\n    copy() {\n        return new HasWalkedCache(new Map(this.store));\n    }\n    hasWalked(target, pattern) {\n        return this.store.get(target.fullpath())?.has(pattern.globString());\n    }\n    storeWalked(target, pattern) {\n        const fullpath = target.fullpath();\n        const cached = this.store.get(fullpath);\n        if (cached)\n            cached.add(pattern.globString());\n        else\n            this.store.set(fullpath, new Set([pattern.globString()]));\n    }\n}\nexports.HasWalkedCache = HasWalkedCache;\n/**\n * A record of which paths have been matched in a given walk step,\n * and whether they only are considered a match if they are a directory,\n * and whether their absolute or relative path should be returned.\n */\nclass MatchRecord {\n    store = new Map();\n    add(target, absolute, ifDir) {\n        const n = (absolute ? 2 : 0) | (ifDir ? 1 : 0);\n        const current = this.store.get(target);\n        this.store.set(target, current === undefined ? n : n & current);\n    }\n    // match, absolute, ifdir\n    entries() {\n        return [...this.store.entries()].map(([path, n]) => [\n            path,\n            !!(n & 2),\n            !!(n & 1),\n        ]);\n    }\n}\nexports.MatchRecord = MatchRecord;\n/**\n * A collection of patterns that must be processed in a subsequent step\n * for a given path.\n */\nclass SubWalks {\n    store = new Map();\n    add(target, pattern) {\n        if (!target.canReaddir()) {\n            return;\n        }\n        const subs = this.store.get(target);\n        if (subs) {\n            if (!subs.find(p => p.globString() === pattern.globString())) {\n                subs.push(pattern);\n            }\n        }\n        else\n            this.store.set(target, [pattern]);\n    }\n    get(target) {\n        const subs = this.store.get(target);\n        /* c8 ignore start */\n        if (!subs) {\n            throw new Error('attempting to walk unknown path');\n        }\n        /* c8 ignore stop */\n        return subs;\n    }\n    entries() {\n        return this.keys().map(k => [k, this.store.get(k)]);\n    }\n    keys() {\n        return [...this.store.keys()].filter(t => t.canReaddir());\n    }\n}\nexports.SubWalks = SubWalks;\n/**\n * The class that processes patterns for a given path.\n *\n * Handles child entry filtering, and determining whether a path's\n * directory contents must be read.\n */\nclass Processor {\n    hasWalkedCache;\n    matches = new MatchRecord();\n    subwalks = new SubWalks();\n    patterns;\n    follow;\n    dot;\n    opts;\n    constructor(opts, hasWalkedCache) {\n        this.opts = opts;\n        this.follow = !!opts.follow;\n        this.dot = !!opts.dot;\n        this.hasWalkedCache =\n            hasWalkedCache ? hasWalkedCache.copy() : new HasWalkedCache();\n    }\n    processPatterns(target, patterns) {\n        this.patterns = patterns;\n        const processingSet = patterns.map(p => [target, p]);\n        // map of paths to the magic-starting subwalks they need to walk\n        // first item in patterns is the filter\n        for (let [t, pattern] of processingSet) {\n            this.hasWalkedCache.storeWalked(t, pattern);\n            const root = pattern.root();\n            const absolute = pattern.isAbsolute() && this.opts.absolute !== false;\n            // start absolute patterns at root\n            if (root) {\n                t = t.resolve(root === '/' && this.opts.root !== undefined ?\n                    this.opts.root\n                    : root);\n                const rest = pattern.rest();\n                if (!rest) {\n                    this.matches.add(t, true, false);\n                    continue;\n                }\n                else {\n                    pattern = rest;\n                }\n            }\n            if (t.isENOENT())\n                continue;\n            let p;\n            let rest;\n            let changed = false;\n            while (typeof (p = pattern.pattern()) === 'string' &&\n                (rest = pattern.rest())) {\n                const c = t.resolve(p);\n                t = c;\n                pattern = rest;\n                changed = true;\n            }\n            p = pattern.pattern();\n            rest = pattern.rest();\n            if (changed) {\n                if (this.hasWalkedCache.hasWalked(t, pattern))\n                    continue;\n                this.hasWalkedCache.storeWalked(t, pattern);\n            }\n            // now we have either a final string for a known entry,\n            // more strings for an unknown entry,\n            // or a pattern starting with magic, mounted on t.\n            if (typeof p === 'string') {\n                // must not be final entry, otherwise we would have\n                // concatenated it earlier.\n                const ifDir = p === '..' || p === '' || p === '.';\n                this.matches.add(t.resolve(p), absolute, ifDir);\n                continue;\n            }\n            else if (p === minimatch_1.GLOBSTAR) {\n                // if no rest, match and subwalk pattern\n                // if rest, process rest and subwalk pattern\n                // if it's a symlink, but we didn't get here by way of a\n                // globstar match (meaning it's the first time THIS globstar\n                // has traversed a symlink), then we follow it. Otherwise, stop.\n                if (!t.isSymbolicLink() ||\n                    this.follow ||\n                    pattern.checkFollowGlobstar()) {\n                    this.subwalks.add(t, pattern);\n                }\n                const rp = rest?.pattern();\n                const rrest = rest?.rest();\n                if (!rest || ((rp === '' || rp === '.') && !rrest)) {\n                    // only HAS to be a dir if it ends in **/ or **/.\n                    // but ending in ** will match files as well.\n                    this.matches.add(t, absolute, rp === '' || rp === '.');\n                }\n                else {\n                    if (rp === '..') {\n                        // this would mean you're matching **/.. at the fs root,\n                        // and no thanks, I'm not gonna test that specific case.\n                        /* c8 ignore start */\n                        const tp = t.parent || t;\n                        /* c8 ignore stop */\n                        if (!rrest)\n                            this.matches.add(tp, absolute, true);\n                        else if (!this.hasWalkedCache.hasWalked(tp, rrest)) {\n                            this.subwalks.add(tp, rrest);\n                        }\n                    }\n                }\n            }\n            else if (p instanceof RegExp) {\n                this.subwalks.add(t, pattern);\n            }\n        }\n        return this;\n    }\n    subwalkTargets() {\n        return this.subwalks.keys();\n    }\n    child() {\n        return new Processor(this.opts, this.hasWalkedCache);\n    }\n    // return a new Processor containing the subwalks for each\n    // child entry, and a set of matches, and\n    // a hasWalkedCache that's a copy of this one\n    // then we're going to call\n    filterEntries(parent, entries) {\n        const patterns = this.subwalks.get(parent);\n        // put matches and entry walks into the results processor\n        const results = this.child();\n        for (const e of entries) {\n            for (const pattern of patterns) {\n                const absolute = pattern.isAbsolute();\n                const p = pattern.pattern();\n                const rest = pattern.rest();\n                if (p === minimatch_1.GLOBSTAR) {\n                    results.testGlobstar(e, pattern, rest, absolute);\n                }\n                else if (p instanceof RegExp) {\n                    results.testRegExp(e, p, rest, absolute);\n                }\n                else {\n                    results.testString(e, p, rest, absolute);\n                }\n            }\n        }\n        return results;\n    }\n    testGlobstar(e, pattern, rest, absolute) {\n        if (this.dot || !e.name.startsWith('.')) {\n            if (!pattern.hasMore()) {\n                this.matches.add(e, absolute, false);\n            }\n            if (e.canReaddir()) {\n                // if we're in follow mode or it's not a symlink, just keep\n                // testing the same pattern. If there's more after the globstar,\n                // then this symlink consumes the globstar. If not, then we can\n                // follow at most ONE symlink along the way, so we mark it, which\n                // also checks to ensure that it wasn't already marked.\n                if (this.follow || !e.isSymbolicLink()) {\n                    this.subwalks.add(e, pattern);\n                }\n                else if (e.isSymbolicLink()) {\n                    if (rest && pattern.checkFollowGlobstar()) {\n                        this.subwalks.add(e, rest);\n                    }\n                    else if (pattern.markFollowGlobstar()) {\n                        this.subwalks.add(e, pattern);\n                    }\n                }\n            }\n        }\n        // if the NEXT thing matches this entry, then also add\n        // the rest.\n        if (rest) {\n            const rp = rest.pattern();\n            if (typeof rp === 'string' &&\n                // dots and empty were handled already\n                rp !== '..' &&\n                rp !== '' &&\n                rp !== '.') {\n                this.testString(e, rp, rest.rest(), absolute);\n            }\n            else if (rp === '..') {\n                /* c8 ignore start */\n                const ep = e.parent || e;\n                /* c8 ignore stop */\n                this.subwalks.add(ep, rest);\n            }\n            else if (rp instanceof RegExp) {\n                this.testRegExp(e, rp, rest.rest(), absolute);\n            }\n        }\n    }\n    testRegExp(e, p, rest, absolute) {\n        if (!p.test(e.name))\n            return;\n        if (!rest) {\n            this.matches.add(e, absolute, false);\n        }\n        else {\n            this.subwalks.add(e, rest);\n        }\n    }\n    testString(e, p, rest, absolute) {\n        // should never happen?\n        if (!e.isNamed(p))\n            return;\n        if (!rest) {\n            this.matches.add(e, absolute, false);\n        }\n        else {\n            this.subwalks.add(e, rest);\n        }\n    }\n}\nexports.Processor = Processor;\n//# sourceMappingURL=processor.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.GlobStream = exports.GlobWalker = exports.GlobUtil = void 0;\n/**\n * Single-use utility classes to provide functionality to the {@link Glob}\n * methods.\n *\n * @module\n */\nconst minipass_1 = require(\"minipass\");\nconst ignore_js_1 = require(\"./ignore.js\");\nconst processor_js_1 = require(\"./processor.js\");\nconst makeIgnore = (ignore, opts) => typeof ignore === 'string' ? new ignore_js_1.Ignore([ignore], opts)\n    : Array.isArray(ignore) ? new ignore_js_1.Ignore(ignore, opts)\n        : ignore;\n/**\n * basic walking utilities that all the glob walker types use\n */\nclass GlobUtil {\n    path;\n    patterns;\n    opts;\n    seen = new Set();\n    paused = false;\n    aborted = false;\n    #onResume = [];\n    #ignore;\n    #sep;\n    signal;\n    maxDepth;\n    includeChildMatches;\n    constructor(patterns, path, opts) {\n        this.patterns = patterns;\n        this.path = path;\n        this.opts = opts;\n        this.#sep = !opts.posix && opts.platform === 'win32' ? '\\\\' : '/';\n        this.includeChildMatches = opts.includeChildMatches !== false;\n        if (opts.ignore || !this.includeChildMatches) {\n            this.#ignore = makeIgnore(opts.ignore ?? [], opts);\n            if (!this.includeChildMatches &&\n                typeof this.#ignore.add !== 'function') {\n                const m = 'cannot ignore child matches, ignore lacks add() method.';\n                throw new Error(m);\n            }\n        }\n        // ignore, always set with maxDepth, but it's optional on the\n        // GlobOptions type\n        /* c8 ignore start */\n        this.maxDepth = opts.maxDepth || Infinity;\n        /* c8 ignore stop */\n        if (opts.signal) {\n            this.signal = opts.signal;\n            this.signal.addEventListener('abort', () => {\n                this.#onResume.length = 0;\n            });\n        }\n    }\n    #ignored(path) {\n        return this.seen.has(path) || !!this.#ignore?.ignored?.(path);\n    }\n    #childrenIgnored(path) {\n        return !!this.#ignore?.childrenIgnored?.(path);\n    }\n    // backpressure mechanism\n    pause() {\n        this.paused = true;\n    }\n    resume() {\n        /* c8 ignore start */\n        if (this.signal?.aborted)\n            return;\n        /* c8 ignore stop */\n        this.paused = false;\n        let fn = undefined;\n        while (!this.paused && (fn = this.#onResume.shift())) {\n            fn();\n        }\n    }\n    onResume(fn) {\n        if (this.signal?.aborted)\n            return;\n        /* c8 ignore start */\n        if (!this.paused) {\n            fn();\n        }\n        else {\n            /* c8 ignore stop */\n            this.#onResume.push(fn);\n        }\n    }\n    // do the requisite realpath/stat checking, and return the path\n    // to add or undefined to filter it out.\n    async matchCheck(e, ifDir) {\n        if (ifDir && this.opts.nodir)\n            return undefined;\n        let rpc;\n        if (this.opts.realpath) {\n            rpc = e.realpathCached() || (await e.realpath());\n            if (!rpc)\n                return undefined;\n            e = rpc;\n        }\n        const needStat = e.isUnknown() || this.opts.stat;\n        const s = needStat ? await e.lstat() : e;\n        if (this.opts.follow && this.opts.nodir && s?.isSymbolicLink()) {\n            const target = await s.realpath();\n            /* c8 ignore start */\n            if (target && (target.isUnknown() || this.opts.stat)) {\n                await target.lstat();\n            }\n            /* c8 ignore stop */\n        }\n        return this.matchCheckTest(s, ifDir);\n    }\n    matchCheckTest(e, ifDir) {\n        return (e &&\n            (this.maxDepth === Infinity || e.depth() <= this.maxDepth) &&\n            (!ifDir || e.canReaddir()) &&\n            (!this.opts.nodir || !e.isDirectory()) &&\n            (!this.opts.nodir ||\n                !this.opts.follow ||\n                !e.isSymbolicLink() ||\n                !e.realpathCached()?.isDirectory()) &&\n            !this.#ignored(e)) ?\n            e\n            : undefined;\n    }\n    matchCheckSync(e, ifDir) {\n        if (ifDir && this.opts.nodir)\n            return undefined;\n        let rpc;\n        if (this.opts.realpath) {\n            rpc = e.realpathCached() || e.realpathSync();\n            if (!rpc)\n                return undefined;\n            e = rpc;\n        }\n        const needStat = e.isUnknown() || this.opts.stat;\n        const s = needStat ? e.lstatSync() : e;\n        if (this.opts.follow && this.opts.nodir && s?.isSymbolicLink()) {\n            const target = s.realpathSync();\n            if (target && (target?.isUnknown() || this.opts.stat)) {\n                target.lstatSync();\n            }\n        }\n        return this.matchCheckTest(s, ifDir);\n    }\n    matchFinish(e, absolute) {\n        if (this.#ignored(e))\n            return;\n        // we know we have an ignore if this is false, but TS doesn't\n        if (!this.includeChildMatches && this.#ignore?.add) {\n            const ign = `${e.relativePosix()}/**`;\n            this.#ignore.add(ign);\n        }\n        const abs = this.opts.absolute === undefined ? absolute : this.opts.absolute;\n        this.seen.add(e);\n        const mark = this.opts.mark && e.isDirectory() ? this.#sep : '';\n        // ok, we have what we need!\n        if (this.opts.withFileTypes) {\n            this.matchEmit(e);\n        }\n        else if (abs) {\n            const abs = this.opts.posix ? e.fullpathPosix() : e.fullpath();\n            this.matchEmit(abs + mark);\n        }\n        else {\n            const rel = this.opts.posix ? e.relativePosix() : e.relative();\n            const pre = this.opts.dotRelative && !rel.startsWith('..' + this.#sep) ?\n                '.' + this.#sep\n                : '';\n            this.matchEmit(!rel ? '.' + mark : pre + rel + mark);\n        }\n    }\n    async match(e, absolute, ifDir) {\n        const p = await this.matchCheck(e, ifDir);\n        if (p)\n            this.matchFinish(p, absolute);\n    }\n    matchSync(e, absolute, ifDir) {\n        const p = this.matchCheckSync(e, ifDir);\n        if (p)\n            this.matchFinish(p, absolute);\n    }\n    walkCB(target, patterns, cb) {\n        /* c8 ignore start */\n        if (this.signal?.aborted)\n            cb();\n        /* c8 ignore stop */\n        this.walkCB2(target, patterns, new processor_js_1.Processor(this.opts), cb);\n    }\n    walkCB2(target, patterns, processor, cb) {\n        if (this.#childrenIgnored(target))\n            return cb();\n        if (this.signal?.aborted)\n            cb();\n        if (this.paused) {\n            this.onResume(() => this.walkCB2(target, patterns, processor, cb));\n            return;\n        }\n        processor.processPatterns(target, patterns);\n        // done processing.  all of the above is sync, can be abstracted out.\n        // subwalks is a map of paths to the entry filters they need\n        // matches is a map of paths to [absolute, ifDir] tuples.\n        let tasks = 1;\n        const next = () => {\n            if (--tasks === 0)\n                cb();\n        };\n        for (const [m, absolute, ifDir] of processor.matches.entries()) {\n            if (this.#ignored(m))\n                continue;\n            tasks++;\n            this.match(m, absolute, ifDir).then(() => next());\n        }\n        for (const t of processor.subwalkTargets()) {\n            if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {\n                continue;\n            }\n            tasks++;\n            const childrenCached = t.readdirCached();\n            if (t.calledReaddir())\n                this.walkCB3(t, childrenCached, processor, next);\n            else {\n                t.readdirCB((_, entries) => this.walkCB3(t, entries, processor, next), true);\n            }\n        }\n        next();\n    }\n    walkCB3(target, entries, processor, cb) {\n        processor = processor.filterEntries(target, entries);\n        let tasks = 1;\n        const next = () => {\n            if (--tasks === 0)\n                cb();\n        };\n        for (const [m, absolute, ifDir] of processor.matches.entries()) {\n            if (this.#ignored(m))\n                continue;\n            tasks++;\n            this.match(m, absolute, ifDir).then(() => next());\n        }\n        for (const [target, patterns] of processor.subwalks.entries()) {\n            tasks++;\n            this.walkCB2(target, patterns, processor.child(), next);\n        }\n        next();\n    }\n    walkCBSync(target, patterns, cb) {\n        /* c8 ignore start */\n        if (this.signal?.aborted)\n            cb();\n        /* c8 ignore stop */\n        this.walkCB2Sync(target, patterns, new processor_js_1.Processor(this.opts), cb);\n    }\n    walkCB2Sync(target, patterns, processor, cb) {\n        if (this.#childrenIgnored(target))\n            return cb();\n        if (this.signal?.aborted)\n            cb();\n        if (this.paused) {\n            this.onResume(() => this.walkCB2Sync(target, patterns, processor, cb));\n            return;\n        }\n        processor.processPatterns(target, patterns);\n        // done processing.  all of the above is sync, can be abstracted out.\n        // subwalks is a map of paths to the entry filters they need\n        // matches is a map of paths to [absolute, ifDir] tuples.\n        let tasks = 1;\n        const next = () => {\n            if (--tasks === 0)\n                cb();\n        };\n        for (const [m, absolute, ifDir] of processor.matches.entries()) {\n            if (this.#ignored(m))\n                continue;\n            this.matchSync(m, absolute, ifDir);\n        }\n        for (const t of processor.subwalkTargets()) {\n            if (this.maxDepth !== Infinity && t.depth() >= this.maxDepth) {\n                continue;\n            }\n            tasks++;\n            const children = t.readdirSync();\n            this.walkCB3Sync(t, children, processor, next);\n        }\n        next();\n    }\n    walkCB3Sync(target, entries, processor, cb) {\n        processor = processor.filterEntries(target, entries);\n        let tasks = 1;\n        const next = () => {\n            if (--tasks === 0)\n                cb();\n        };\n        for (const [m, absolute, ifDir] of processor.matches.entries()) {\n            if (this.#ignored(m))\n                continue;\n            this.matchSync(m, absolute, ifDir);\n        }\n        for (const [target, patterns] of processor.subwalks.entries()) {\n            tasks++;\n            this.walkCB2Sync(target, patterns, processor.child(), next);\n        }\n        next();\n    }\n}\nexports.GlobUtil = GlobUtil;\nclass GlobWalker extends GlobUtil {\n    matches = new Set();\n    constructor(patterns, path, opts) {\n        super(patterns, path, opts);\n    }\n    matchEmit(e) {\n        this.matches.add(e);\n    }\n    async walk() {\n        if (this.signal?.aborted)\n            throw this.signal.reason;\n        if (this.path.isUnknown()) {\n            await this.path.lstat();\n        }\n        await new Promise((res, rej) => {\n            this.walkCB(this.path, this.patterns, () => {\n                if (this.signal?.aborted) {\n                    rej(this.signal.reason);\n                }\n                else {\n                    res(this.matches);\n                }\n            });\n        });\n        return this.matches;\n    }\n    walkSync() {\n        if (this.signal?.aborted)\n            throw this.signal.reason;\n        if (this.path.isUnknown()) {\n            this.path.lstatSync();\n        }\n        // nothing for the callback to do, because this never pauses\n        this.walkCBSync(this.path, this.patterns, () => {\n            if (this.signal?.aborted)\n                throw this.signal.reason;\n        });\n        return this.matches;\n    }\n}\nexports.GlobWalker = GlobWalker;\nclass GlobStream extends GlobUtil {\n    results;\n    constructor(patterns, path, opts) {\n        super(patterns, path, opts);\n        this.results = new minipass_1.Minipass({\n            signal: this.signal,\n            objectMode: true,\n        });\n        this.results.on('drain', () => this.resume());\n        this.results.on('resume', () => this.resume());\n    }\n    matchEmit(e) {\n        this.results.write(e);\n        if (!this.results.flowing)\n            this.pause();\n    }\n    stream() {\n        const target = this.path;\n        if (target.isUnknown()) {\n            target.lstat().then(() => {\n                this.walkCB(target, this.patterns, () => this.results.end());\n            });\n        }\n        else {\n            this.walkCB(target, this.patterns, () => this.results.end());\n        }\n        return this.results;\n    }\n    streamSync() {\n        if (this.path.isUnknown()) {\n            this.path.lstatSync();\n        }\n        this.walkCBSync(this.path, this.patterns, () => this.results.end());\n        return this.results;\n    }\n}\nexports.GlobStream = GlobStream;\n//# sourceMappingURL=walker.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.assertValidPattern = void 0;\nconst MAX_PATTERN_LENGTH = 1024 * 64;\nconst assertValidPattern = (pattern) => {\n    if (typeof pattern !== 'string') {\n        throw new TypeError('invalid pattern');\n    }\n    if (pattern.length > MAX_PATTERN_LENGTH) {\n        throw new TypeError('pattern is too long');\n    }\n};\nexports.assertValidPattern = assertValidPattern;\n//# sourceMappingURL=assert-valid-pattern.js.map","\"use strict\";\n// parse a single path portion\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AST = void 0;\nconst brace_expressions_js_1 = require(\"./brace-expressions.js\");\nconst unescape_js_1 = require(\"./unescape.js\");\nconst types = new Set(['!', '?', '+', '*', '@']);\nconst isExtglobType = (c) => types.has(c);\n// Patterns that get prepended to bind to the start of either the\n// entire string, or just a single path portion, to prevent dots\n// and/or traversal patterns, when needed.\n// Exts don't need the ^ or / bit, because the root binds that already.\nconst startNoTraversal = '(?!(?:^|/)\\\\.\\\\.?(?:$|/))';\nconst startNoDot = '(?!\\\\.)';\n// characters that indicate a start of pattern needs the \"no dots\" bit,\n// because a dot *might* be matched. ( is not in the list, because in\n// the case of a child extglob, it will handle the prevention itself.\nconst addPatternStart = new Set(['[', '.']);\n// cases where traversal is A-OK, no dot prevention needed\nconst justDots = new Set(['..', '.']);\nconst reSpecials = new Set('().*{}+?[]^$\\\\!');\nconst regExpEscape = (s) => s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\n// any single thing other than /\nconst qmark = '[^/]';\n// * => any number of characters\nconst star = qmark + '*?';\n// use + when we need to ensure that *something* matches, because the * is\n// the only thing in the path portion.\nconst starNoEmpty = qmark + '+?';\n// remove the \\ chars that we added if we end up doing a nonmagic compare\n// const deslash = (s: string) => s.replace(/\\\\(.)/g, '$1')\nclass AST {\n    type;\n    #root;\n    #hasMagic;\n    #uflag = false;\n    #parts = [];\n    #parent;\n    #parentIndex;\n    #negs;\n    #filledNegs = false;\n    #options;\n    #toString;\n    // set to true if it's an extglob with no children\n    // (which really means one child of '')\n    #emptyExt = false;\n    constructor(type, parent, options = {}) {\n        this.type = type;\n        // extglobs are inherently magical\n        if (type)\n            this.#hasMagic = true;\n        this.#parent = parent;\n        this.#root = this.#parent ? this.#parent.#root : this;\n        this.#options = this.#root === this ? options : this.#root.#options;\n        this.#negs = this.#root === this ? [] : this.#root.#negs;\n        if (type === '!' && !this.#root.#filledNegs)\n            this.#negs.push(this);\n        this.#parentIndex = this.#parent ? this.#parent.#parts.length : 0;\n    }\n    get hasMagic() {\n        /* c8 ignore start */\n        if (this.#hasMagic !== undefined)\n            return this.#hasMagic;\n        /* c8 ignore stop */\n        for (const p of this.#parts) {\n            if (typeof p === 'string')\n                continue;\n            if (p.type || p.hasMagic)\n                return (this.#hasMagic = true);\n        }\n        // note: will be undefined until we generate the regexp src and find out\n        return this.#hasMagic;\n    }\n    // reconstructs the pattern\n    toString() {\n        if (this.#toString !== undefined)\n            return this.#toString;\n        if (!this.type) {\n            return (this.#toString = this.#parts.map(p => String(p)).join(''));\n        }\n        else {\n            return (this.#toString =\n                this.type + '(' + this.#parts.map(p => String(p)).join('|') + ')');\n        }\n    }\n    #fillNegs() {\n        /* c8 ignore start */\n        if (this !== this.#root)\n            throw new Error('should only call on root');\n        if (this.#filledNegs)\n            return this;\n        /* c8 ignore stop */\n        // call toString() once to fill this out\n        this.toString();\n        this.#filledNegs = true;\n        let n;\n        while ((n = this.#negs.pop())) {\n            if (n.type !== '!')\n                continue;\n            // walk up the tree, appending everthing that comes AFTER parentIndex\n            let p = n;\n            let pp = p.#parent;\n            while (pp) {\n                for (let i = p.#parentIndex + 1; !pp.type && i < pp.#parts.length; i++) {\n                    for (const part of n.#parts) {\n                        /* c8 ignore start */\n                        if (typeof part === 'string') {\n                            throw new Error('string part in extglob AST??');\n                        }\n                        /* c8 ignore stop */\n                        part.copyIn(pp.#parts[i]);\n                    }\n                }\n                p = pp;\n                pp = p.#parent;\n            }\n        }\n        return this;\n    }\n    push(...parts) {\n        for (const p of parts) {\n            if (p === '')\n                continue;\n            /* c8 ignore start */\n            if (typeof p !== 'string' && !(p instanceof AST && p.#parent === this)) {\n                throw new Error('invalid part: ' + p);\n            }\n            /* c8 ignore stop */\n            this.#parts.push(p);\n        }\n    }\n    toJSON() {\n        const ret = this.type === null\n            ? this.#parts.slice().map(p => (typeof p === 'string' ? p : p.toJSON()))\n            : [this.type, ...this.#parts.map(p => p.toJSON())];\n        if (this.isStart() && !this.type)\n            ret.unshift([]);\n        if (this.isEnd() &&\n            (this === this.#root ||\n                (this.#root.#filledNegs && this.#parent?.type === '!'))) {\n            ret.push({});\n        }\n        return ret;\n    }\n    isStart() {\n        if (this.#root === this)\n            return true;\n        // if (this.type) return !!this.#parent?.isStart()\n        if (!this.#parent?.isStart())\n            return false;\n        if (this.#parentIndex === 0)\n            return true;\n        // if everything AHEAD of this is a negation, then it's still the \"start\"\n        const p = this.#parent;\n        for (let i = 0; i < this.#parentIndex; i++) {\n            const pp = p.#parts[i];\n            if (!(pp instanceof AST && pp.type === '!')) {\n                return false;\n            }\n        }\n        return true;\n    }\n    isEnd() {\n        if (this.#root === this)\n            return true;\n        if (this.#parent?.type === '!')\n            return true;\n        if (!this.#parent?.isEnd())\n            return false;\n        if (!this.type)\n            return this.#parent?.isEnd();\n        // if not root, it'll always have a parent\n        /* c8 ignore start */\n        const pl = this.#parent ? this.#parent.#parts.length : 0;\n        /* c8 ignore stop */\n        return this.#parentIndex === pl - 1;\n    }\n    copyIn(part) {\n        if (typeof part === 'string')\n            this.push(part);\n        else\n            this.push(part.clone(this));\n    }\n    clone(parent) {\n        const c = new AST(this.type, parent);\n        for (const p of this.#parts) {\n            c.copyIn(p);\n        }\n        return c;\n    }\n    static #parseAST(str, ast, pos, opt) {\n        let escaping = false;\n        let inBrace = false;\n        let braceStart = -1;\n        let braceNeg = false;\n        if (ast.type === null) {\n            // outside of a extglob, append until we find a start\n            let i = pos;\n            let acc = '';\n            while (i < str.length) {\n                const c = str.charAt(i++);\n                // still accumulate escapes at this point, but we do ignore\n                // starts that are escaped\n                if (escaping || c === '\\\\') {\n                    escaping = !escaping;\n                    acc += c;\n                    continue;\n                }\n                if (inBrace) {\n                    if (i === braceStart + 1) {\n                        if (c === '^' || c === '!') {\n                            braceNeg = true;\n                        }\n                    }\n                    else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {\n                        inBrace = false;\n                    }\n                    acc += c;\n                    continue;\n                }\n                else if (c === '[') {\n                    inBrace = true;\n                    braceStart = i;\n                    braceNeg = false;\n                    acc += c;\n                    continue;\n                }\n                if (!opt.noext && isExtglobType(c) && str.charAt(i) === '(') {\n                    ast.push(acc);\n                    acc = '';\n                    const ext = new AST(c, ast);\n                    i = AST.#parseAST(str, ext, i, opt);\n                    ast.push(ext);\n                    continue;\n                }\n                acc += c;\n            }\n            ast.push(acc);\n            return i;\n        }\n        // some kind of extglob, pos is at the (\n        // find the next | or )\n        let i = pos + 1;\n        let part = new AST(null, ast);\n        const parts = [];\n        let acc = '';\n        while (i < str.length) {\n            const c = str.charAt(i++);\n            // still accumulate escapes at this point, but we do ignore\n            // starts that are escaped\n            if (escaping || c === '\\\\') {\n                escaping = !escaping;\n                acc += c;\n                continue;\n            }\n            if (inBrace) {\n                if (i === braceStart + 1) {\n                    if (c === '^' || c === '!') {\n                        braceNeg = true;\n                    }\n                }\n                else if (c === ']' && !(i === braceStart + 2 && braceNeg)) {\n                    inBrace = false;\n                }\n                acc += c;\n                continue;\n            }\n            else if (c === '[') {\n                inBrace = true;\n                braceStart = i;\n                braceNeg = false;\n                acc += c;\n                continue;\n            }\n            if (isExtglobType(c) && str.charAt(i) === '(') {\n                part.push(acc);\n                acc = '';\n                const ext = new AST(c, part);\n                part.push(ext);\n                i = AST.#parseAST(str, ext, i, opt);\n                continue;\n            }\n            if (c === '|') {\n                part.push(acc);\n                acc = '';\n                parts.push(part);\n                part = new AST(null, ast);\n                continue;\n            }\n            if (c === ')') {\n                if (acc === '' && ast.#parts.length === 0) {\n                    ast.#emptyExt = true;\n                }\n                part.push(acc);\n                acc = '';\n                ast.push(...parts, part);\n                return i;\n            }\n            acc += c;\n        }\n        // unfinished extglob\n        // if we got here, it was a malformed extglob! not an extglob, but\n        // maybe something else in there.\n        ast.type = null;\n        ast.#hasMagic = undefined;\n        ast.#parts = [str.substring(pos - 1)];\n        return i;\n    }\n    static fromGlob(pattern, options = {}) {\n        const ast = new AST(null, undefined, options);\n        AST.#parseAST(pattern, ast, 0, options);\n        return ast;\n    }\n    // returns the regular expression if there's magic, or the unescaped\n    // string if not.\n    toMMPattern() {\n        // should only be called on root\n        /* c8 ignore start */\n        if (this !== this.#root)\n            return this.#root.toMMPattern();\n        /* c8 ignore stop */\n        const glob = this.toString();\n        const [re, body, hasMagic, uflag] = this.toRegExpSource();\n        // if we're in nocase mode, and not nocaseMagicOnly, then we do\n        // still need a regular expression if we have to case-insensitively\n        // match capital/lowercase characters.\n        const anyMagic = hasMagic ||\n            this.#hasMagic ||\n            (this.#options.nocase &&\n                !this.#options.nocaseMagicOnly &&\n                glob.toUpperCase() !== glob.toLowerCase());\n        if (!anyMagic) {\n            return body;\n        }\n        const flags = (this.#options.nocase ? 'i' : '') + (uflag ? 'u' : '');\n        return Object.assign(new RegExp(`^${re}$`, flags), {\n            _src: re,\n            _glob: glob,\n        });\n    }\n    get options() {\n        return this.#options;\n    }\n    // returns the string match, the regexp source, whether there's magic\n    // in the regexp (so a regular expression is required) and whether or\n    // not the uflag is needed for the regular expression (for posix classes)\n    // TODO: instead of injecting the start/end at this point, just return\n    // the BODY of the regexp, along with the start/end portions suitable\n    // for binding the start/end in either a joined full-path makeRe context\n    // (where we bind to (^|/), or a standalone matchPart context (where\n    // we bind to ^, and not /).  Otherwise slashes get duped!\n    //\n    // In part-matching mode, the start is:\n    // - if not isStart: nothing\n    // - if traversal possible, but not allowed: ^(?!\\.\\.?$)\n    // - if dots allowed or not possible: ^\n    // - if dots possible and not allowed: ^(?!\\.)\n    // end is:\n    // - if not isEnd(): nothing\n    // - else: $\n    //\n    // In full-path matching mode, we put the slash at the START of the\n    // pattern, so start is:\n    // - if first pattern: same as part-matching mode\n    // - if not isStart(): nothing\n    // - if traversal possible, but not allowed: /(?!\\.\\.?(?:$|/))\n    // - if dots allowed or not possible: /\n    // - if dots possible and not allowed: /(?!\\.)\n    // end is:\n    // - if last pattern, same as part-matching mode\n    // - else nothing\n    //\n    // Always put the (?:$|/) on negated tails, though, because that has to be\n    // there to bind the end of the negated pattern portion, and it's easier to\n    // just stick it in now rather than try to inject it later in the middle of\n    // the pattern.\n    //\n    // We can just always return the same end, and leave it up to the caller\n    // to know whether it's going to be used joined or in parts.\n    // And, if the start is adjusted slightly, can do the same there:\n    // - if not isStart: nothing\n    // - if traversal possible, but not allowed: (?:/|^)(?!\\.\\.?$)\n    // - if dots allowed or not possible: (?:/|^)\n    // - if dots possible and not allowed: (?:/|^)(?!\\.)\n    //\n    // But it's better to have a simpler binding without a conditional, for\n    // performance, so probably better to return both start options.\n    //\n    // Then the caller just ignores the end if it's not the first pattern,\n    // and the start always gets applied.\n    //\n    // But that's always going to be $ if it's the ending pattern, or nothing,\n    // so the caller can just attach $ at the end of the pattern when building.\n    //\n    // So the todo is:\n    // - better detect what kind of start is needed\n    // - return both flavors of starting pattern\n    // - attach $ at the end of the pattern when creating the actual RegExp\n    //\n    // Ah, but wait, no, that all only applies to the root when the first pattern\n    // is not an extglob. If the first pattern IS an extglob, then we need all\n    // that dot prevention biz to live in the extglob portions, because eg\n    // +(*|.x*) can match .xy but not .yx.\n    //\n    // So, return the two flavors if it's #root and the first child is not an\n    // AST, otherwise leave it to the child AST to handle it, and there,\n    // use the (?:^|/) style of start binding.\n    //\n    // Even simplified further:\n    // - Since the start for a join is eg /(?!\\.) and the start for a part\n    // is ^(?!\\.), we can just prepend (?!\\.) to the pattern (either root\n    // or start or whatever) and prepend ^ or / at the Regexp construction.\n    toRegExpSource(allowDot) {\n        const dot = allowDot ?? !!this.#options.dot;\n        if (this.#root === this)\n            this.#fillNegs();\n        if (!this.type) {\n            const noEmpty = this.isStart() && this.isEnd();\n            const src = this.#parts\n                .map(p => {\n                const [re, _, hasMagic, uflag] = typeof p === 'string'\n                    ? AST.#parseGlob(p, this.#hasMagic, noEmpty)\n                    : p.toRegExpSource(allowDot);\n                this.#hasMagic = this.#hasMagic || hasMagic;\n                this.#uflag = this.#uflag || uflag;\n                return re;\n            })\n                .join('');\n            let start = '';\n            if (this.isStart()) {\n                if (typeof this.#parts[0] === 'string') {\n                    // this is the string that will match the start of the pattern,\n                    // so we need to protect against dots and such.\n                    // '.' and '..' cannot match unless the pattern is that exactly,\n                    // even if it starts with . or dot:true is set.\n                    const dotTravAllowed = this.#parts.length === 1 && justDots.has(this.#parts[0]);\n                    if (!dotTravAllowed) {\n                        const aps = addPatternStart;\n                        // check if we have a possibility of matching . or ..,\n                        // and prevent that.\n                        const needNoTrav = \n                        // dots are allowed, and the pattern starts with [ or .\n                        (dot && aps.has(src.charAt(0))) ||\n                            // the pattern starts with \\., and then [ or .\n                            (src.startsWith('\\\\.') && aps.has(src.charAt(2))) ||\n                            // the pattern starts with \\.\\., and then [ or .\n                            (src.startsWith('\\\\.\\\\.') && aps.has(src.charAt(4)));\n                        // no need to prevent dots if it can't match a dot, or if a\n                        // sub-pattern will be preventing it anyway.\n                        const needNoDot = !dot && !allowDot && aps.has(src.charAt(0));\n                        start = needNoTrav ? startNoTraversal : needNoDot ? startNoDot : '';\n                    }\n                }\n            }\n            // append the \"end of path portion\" pattern to negation tails\n            let end = '';\n            if (this.isEnd() &&\n                this.#root.#filledNegs &&\n                this.#parent?.type === '!') {\n                end = '(?:$|\\\\/)';\n            }\n            const final = start + src + end;\n            return [\n                final,\n                (0, unescape_js_1.unescape)(src),\n                (this.#hasMagic = !!this.#hasMagic),\n                this.#uflag,\n            ];\n        }\n        // We need to calculate the body *twice* if it's a repeat pattern\n        // at the start, once in nodot mode, then again in dot mode, so a\n        // pattern like *(?) can match 'x.y'\n        const repeated = this.type === '*' || this.type === '+';\n        // some kind of extglob\n        const start = this.type === '!' ? '(?:(?!(?:' : '(?:';\n        let body = this.#partsToRegExp(dot);\n        if (this.isStart() && this.isEnd() && !body && this.type !== '!') {\n            // invalid extglob, has to at least be *something* present, if it's\n            // the entire path portion.\n            const s = this.toString();\n            this.#parts = [s];\n            this.type = null;\n            this.#hasMagic = undefined;\n            return [s, (0, unescape_js_1.unescape)(this.toString()), false, false];\n        }\n        // XXX abstract out this map method\n        let bodyDotAllowed = !repeated || allowDot || dot || !startNoDot\n            ? ''\n            : this.#partsToRegExp(true);\n        if (bodyDotAllowed === body) {\n            bodyDotAllowed = '';\n        }\n        if (bodyDotAllowed) {\n            body = `(?:${body})(?:${bodyDotAllowed})*?`;\n        }\n        // an empty !() is exactly equivalent to a starNoEmpty\n        let final = '';\n        if (this.type === '!' && this.#emptyExt) {\n            final = (this.isStart() && !dot ? startNoDot : '') + starNoEmpty;\n        }\n        else {\n            const close = this.type === '!'\n                ? // !() must match something,but !(x) can match ''\n                    '))' +\n                        (this.isStart() && !dot && !allowDot ? startNoDot : '') +\n                        star +\n                        ')'\n                : this.type === '@'\n                    ? ')'\n                    : this.type === '?'\n                        ? ')?'\n                        : this.type === '+' && bodyDotAllowed\n                            ? ')'\n                            : this.type === '*' && bodyDotAllowed\n                                ? `)?`\n                                : `)${this.type}`;\n            final = start + body + close;\n        }\n        return [\n            final,\n            (0, unescape_js_1.unescape)(body),\n            (this.#hasMagic = !!this.#hasMagic),\n            this.#uflag,\n        ];\n    }\n    #partsToRegExp(dot) {\n        return this.#parts\n            .map(p => {\n            // extglob ASTs should only contain parent ASTs\n            /* c8 ignore start */\n            if (typeof p === 'string') {\n                throw new Error('string type in extglob ast??');\n            }\n            /* c8 ignore stop */\n            // can ignore hasMagic, because extglobs are already always magic\n            const [re, _, _hasMagic, uflag] = p.toRegExpSource(dot);\n            this.#uflag = this.#uflag || uflag;\n            return re;\n        })\n            .filter(p => !(this.isStart() && this.isEnd()) || !!p)\n            .join('|');\n    }\n    static #parseGlob(glob, hasMagic, noEmpty = false) {\n        let escaping = false;\n        let re = '';\n        let uflag = false;\n        for (let i = 0; i < glob.length; i++) {\n            const c = glob.charAt(i);\n            if (escaping) {\n                escaping = false;\n                re += (reSpecials.has(c) ? '\\\\' : '') + c;\n                continue;\n            }\n            if (c === '\\\\') {\n                if (i === glob.length - 1) {\n                    re += '\\\\\\\\';\n                }\n                else {\n                    escaping = true;\n                }\n                continue;\n            }\n            if (c === '[') {\n                const [src, needUflag, consumed, magic] = (0, brace_expressions_js_1.parseClass)(glob, i);\n                if (consumed) {\n                    re += src;\n                    uflag = uflag || needUflag;\n                    i += consumed - 1;\n                    hasMagic = hasMagic || magic;\n                    continue;\n                }\n            }\n            if (c === '*') {\n                if (noEmpty && glob === '*')\n                    re += starNoEmpty;\n                else\n                    re += star;\n                hasMagic = true;\n                continue;\n            }\n            if (c === '?') {\n                re += qmark;\n                hasMagic = true;\n                continue;\n            }\n            re += regExpEscape(c);\n        }\n        return [re, (0, unescape_js_1.unescape)(glob), !!hasMagic, uflag];\n    }\n}\nexports.AST = AST;\n//# sourceMappingURL=ast.js.map","\"use strict\";\n// translate the various posix character classes into unicode properties\n// this works across all unicode locales\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.parseClass = void 0;\n// { <posix class>: [<translation>, /u flag required, negated]\nconst posixClasses = {\n    '[:alnum:]': ['\\\\p{L}\\\\p{Nl}\\\\p{Nd}', true],\n    '[:alpha:]': ['\\\\p{L}\\\\p{Nl}', true],\n    '[:ascii:]': ['\\\\x' + '00-\\\\x' + '7f', false],\n    '[:blank:]': ['\\\\p{Zs}\\\\t', true],\n    '[:cntrl:]': ['\\\\p{Cc}', true],\n    '[:digit:]': ['\\\\p{Nd}', true],\n    '[:graph:]': ['\\\\p{Z}\\\\p{C}', true, true],\n    '[:lower:]': ['\\\\p{Ll}', true],\n    '[:print:]': ['\\\\p{C}', true],\n    '[:punct:]': ['\\\\p{P}', true],\n    '[:space:]': ['\\\\p{Z}\\\\t\\\\r\\\\n\\\\v\\\\f', true],\n    '[:upper:]': ['\\\\p{Lu}', true],\n    '[:word:]': ['\\\\p{L}\\\\p{Nl}\\\\p{Nd}\\\\p{Pc}', true],\n    '[:xdigit:]': ['A-Fa-f0-9', false],\n};\n// only need to escape a few things inside of brace expressions\n// escapes: [ \\ ] -\nconst braceEscape = (s) => s.replace(/[[\\]\\\\-]/g, '\\\\$&');\n// escape all regexp magic characters\nconst regexpEscape = (s) => s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\n// everything has already been escaped, we just have to join\nconst rangesToString = (ranges) => ranges.join('');\n// takes a glob string at a posix brace expression, and returns\n// an equivalent regular expression source, and boolean indicating\n// whether the /u flag needs to be applied, and the number of chars\n// consumed to parse the character class.\n// This also removes out of order ranges, and returns ($.) if the\n// entire class just no good.\nconst parseClass = (glob, position) => {\n    const pos = position;\n    /* c8 ignore start */\n    if (glob.charAt(pos) !== '[') {\n        throw new Error('not in a brace expression');\n    }\n    /* c8 ignore stop */\n    const ranges = [];\n    const negs = [];\n    let i = pos + 1;\n    let sawStart = false;\n    let uflag = false;\n    let escaping = false;\n    let negate = false;\n    let endPos = pos;\n    let rangeStart = '';\n    WHILE: while (i < glob.length) {\n        const c = glob.charAt(i);\n        if ((c === '!' || c === '^') && i === pos + 1) {\n            negate = true;\n            i++;\n            continue;\n        }\n        if (c === ']' && sawStart && !escaping) {\n            endPos = i + 1;\n            break;\n        }\n        sawStart = true;\n        if (c === '\\\\') {\n            if (!escaping) {\n                escaping = true;\n                i++;\n                continue;\n            }\n            // escaped \\ char, fall through and treat like normal char\n        }\n        if (c === '[' && !escaping) {\n            // either a posix class, a collation equivalent, or just a [\n            for (const [cls, [unip, u, neg]] of Object.entries(posixClasses)) {\n                if (glob.startsWith(cls, i)) {\n                    // invalid, [a-[] is fine, but not [a-[:alpha]]\n                    if (rangeStart) {\n                        return ['$.', false, glob.length - pos, true];\n                    }\n                    i += cls.length;\n                    if (neg)\n                        negs.push(unip);\n                    else\n                        ranges.push(unip);\n                    uflag = uflag || u;\n                    continue WHILE;\n                }\n            }\n        }\n        // now it's just a normal character, effectively\n        escaping = false;\n        if (rangeStart) {\n            // throw this range away if it's not valid, but others\n            // can still match.\n            if (c > rangeStart) {\n                ranges.push(braceEscape(rangeStart) + '-' + braceEscape(c));\n            }\n            else if (c === rangeStart) {\n                ranges.push(braceEscape(c));\n            }\n            rangeStart = '';\n            i++;\n            continue;\n        }\n        // now might be the start of a range.\n        // can be either c-d or c-] or c<more...>] or c] at this point\n        if (glob.startsWith('-]', i + 1)) {\n            ranges.push(braceEscape(c + '-'));\n            i += 2;\n            continue;\n        }\n        if (glob.startsWith('-', i + 1)) {\n            rangeStart = c;\n            i += 2;\n            continue;\n        }\n        // not the start of a range, just a single character\n        ranges.push(braceEscape(c));\n        i++;\n    }\n    if (endPos < i) {\n        // didn't see the end of the class, not a valid class,\n        // but might still be valid as a literal match.\n        return ['', false, 0, false];\n    }\n    // if we got no ranges and no negates, then we have a range that\n    // cannot possibly match anything, and that poisons the whole glob\n    if (!ranges.length && !negs.length) {\n        return ['$.', false, glob.length - pos, true];\n    }\n    // if we got one positive range, and it's a single character, then that's\n    // not actually a magic pattern, it's just that one literal character.\n    // we should not treat that as \"magic\", we should just return the literal\n    // character. [_] is a perfectly valid way to escape glob magic chars.\n    if (negs.length === 0 &&\n        ranges.length === 1 &&\n        /^\\\\?.$/.test(ranges[0]) &&\n        !negate) {\n        const r = ranges[0].length === 2 ? ranges[0].slice(-1) : ranges[0];\n        return [regexpEscape(r), false, endPos - pos, false];\n    }\n    const sranges = '[' + (negate ? '^' : '') + rangesToString(ranges) + ']';\n    const snegs = '[' + (negate ? '' : '^') + rangesToString(negs) + ']';\n    const comb = ranges.length && negs.length\n        ? '(' + sranges + '|' + snegs + ')'\n        : ranges.length\n            ? sranges\n            : snegs;\n    return [comb, uflag, endPos - pos, true];\n};\nexports.parseClass = parseClass;\n//# sourceMappingURL=brace-expressions.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.escape = void 0;\n/**\n * Escape all magic characters in a glob pattern.\n *\n * If the {@link windowsPathsNoEscape | GlobOptions.windowsPathsNoEscape}\n * option is used, then characters are escaped by wrapping in `[]`, because\n * a magic character wrapped in a character class can only be satisfied by\n * that exact character.  In this mode, `\\` is _not_ escaped, because it is\n * not interpreted as a magic character, but instead as a path separator.\n */\nconst escape = (s, { windowsPathsNoEscape = false, } = {}) => {\n    // don't need to escape +@! because we escape the parens\n    // that make those magic, and escaping ! as [!] isn't valid,\n    // because [!]] is a valid glob class meaning not ']'.\n    return windowsPathsNoEscape\n        ? s.replace(/[?*()[\\]]/g, '[$&]')\n        : s.replace(/[?*()[\\]\\\\]/g, '\\\\$&');\n};\nexports.escape = escape;\n//# sourceMappingURL=escape.js.map","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.unescape = exports.escape = exports.AST = exports.Minimatch = exports.match = exports.makeRe = exports.braceExpand = exports.defaults = exports.filter = exports.GLOBSTAR = exports.sep = exports.minimatch = void 0;\nconst brace_expansion_1 = __importDefault(require(\"brace-expansion\"));\nconst assert_valid_pattern_js_1 = require(\"./assert-valid-pattern.js\");\nconst ast_js_1 = require(\"./ast.js\");\nconst escape_js_1 = require(\"./escape.js\");\nconst unescape_js_1 = require(\"./unescape.js\");\nconst minimatch = (p, pattern, options = {}) => {\n    (0, assert_valid_pattern_js_1.assertValidPattern)(pattern);\n    // shortcut: comments match nothing.\n    if (!options.nocomment && pattern.charAt(0) === '#') {\n        return false;\n    }\n    return new Minimatch(pattern, options).match(p);\n};\nexports.minimatch = minimatch;\n// Optimized checking for the most common glob patterns.\nconst starDotExtRE = /^\\*+([^+@!?\\*\\[\\(]*)$/;\nconst starDotExtTest = (ext) => (f) => !f.startsWith('.') && f.endsWith(ext);\nconst starDotExtTestDot = (ext) => (f) => f.endsWith(ext);\nconst starDotExtTestNocase = (ext) => {\n    ext = ext.toLowerCase();\n    return (f) => !f.startsWith('.') && f.toLowerCase().endsWith(ext);\n};\nconst starDotExtTestNocaseDot = (ext) => {\n    ext = ext.toLowerCase();\n    return (f) => f.toLowerCase().endsWith(ext);\n};\nconst starDotStarRE = /^\\*+\\.\\*+$/;\nconst starDotStarTest = (f) => !f.startsWith('.') && f.includes('.');\nconst starDotStarTestDot = (f) => f !== '.' && f !== '..' && f.includes('.');\nconst dotStarRE = /^\\.\\*+$/;\nconst dotStarTest = (f) => f !== '.' && f !== '..' && f.startsWith('.');\nconst starRE = /^\\*+$/;\nconst starTest = (f) => f.length !== 0 && !f.startsWith('.');\nconst starTestDot = (f) => f.length !== 0 && f !== '.' && f !== '..';\nconst qmarksRE = /^\\?+([^+@!?\\*\\[\\(]*)?$/;\nconst qmarksTestNocase = ([$0, ext = '']) => {\n    const noext = qmarksTestNoExt([$0]);\n    if (!ext)\n        return noext;\n    ext = ext.toLowerCase();\n    return (f) => noext(f) && f.toLowerCase().endsWith(ext);\n};\nconst qmarksTestNocaseDot = ([$0, ext = '']) => {\n    const noext = qmarksTestNoExtDot([$0]);\n    if (!ext)\n        return noext;\n    ext = ext.toLowerCase();\n    return (f) => noext(f) && f.toLowerCase().endsWith(ext);\n};\nconst qmarksTestDot = ([$0, ext = '']) => {\n    const noext = qmarksTestNoExtDot([$0]);\n    return !ext ? noext : (f) => noext(f) && f.endsWith(ext);\n};\nconst qmarksTest = ([$0, ext = '']) => {\n    const noext = qmarksTestNoExt([$0]);\n    return !ext ? noext : (f) => noext(f) && f.endsWith(ext);\n};\nconst qmarksTestNoExt = ([$0]) => {\n    const len = $0.length;\n    return (f) => f.length === len && !f.startsWith('.');\n};\nconst qmarksTestNoExtDot = ([$0]) => {\n    const len = $0.length;\n    return (f) => f.length === len && f !== '.' && f !== '..';\n};\n/* c8 ignore start */\nconst defaultPlatform = (typeof process === 'object' && process\n    ? (typeof process.env === 'object' &&\n        process.env &&\n        process.env.__MINIMATCH_TESTING_PLATFORM__) ||\n        process.platform\n    : 'posix');\nconst path = {\n    win32: { sep: '\\\\' },\n    posix: { sep: '/' },\n};\n/* c8 ignore stop */\nexports.sep = defaultPlatform === 'win32' ? path.win32.sep : path.posix.sep;\nexports.minimatch.sep = exports.sep;\nexports.GLOBSTAR = Symbol('globstar **');\nexports.minimatch.GLOBSTAR = exports.GLOBSTAR;\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nconst qmark = '[^/]';\n// * => any number of characters\nconst star = qmark + '*?';\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nconst twoStarDot = '(?:(?!(?:\\\\/|^)(?:\\\\.{1,2})($|\\\\/)).)*?';\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nconst twoStarNoDot = '(?:(?!(?:\\\\/|^)\\\\.).)*?';\nconst filter = (pattern, options = {}) => (p) => (0, exports.minimatch)(p, pattern, options);\nexports.filter = filter;\nexports.minimatch.filter = exports.filter;\nconst ext = (a, b = {}) => Object.assign({}, a, b);\nconst defaults = (def) => {\n    if (!def || typeof def !== 'object' || !Object.keys(def).length) {\n        return exports.minimatch;\n    }\n    const orig = exports.minimatch;\n    const m = (p, pattern, options = {}) => orig(p, pattern, ext(def, options));\n    return Object.assign(m, {\n        Minimatch: class Minimatch extends orig.Minimatch {\n            constructor(pattern, options = {}) {\n                super(pattern, ext(def, options));\n            }\n            static defaults(options) {\n                return orig.defaults(ext(def, options)).Minimatch;\n            }\n        },\n        AST: class AST extends orig.AST {\n            /* c8 ignore start */\n            constructor(type, parent, options = {}) {\n                super(type, parent, ext(def, options));\n            }\n            /* c8 ignore stop */\n            static fromGlob(pattern, options = {}) {\n                return orig.AST.fromGlob(pattern, ext(def, options));\n            }\n        },\n        unescape: (s, options = {}) => orig.unescape(s, ext(def, options)),\n        escape: (s, options = {}) => orig.escape(s, ext(def, options)),\n        filter: (pattern, options = {}) => orig.filter(pattern, ext(def, options)),\n        defaults: (options) => orig.defaults(ext(def, options)),\n        makeRe: (pattern, options = {}) => orig.makeRe(pattern, ext(def, options)),\n        braceExpand: (pattern, options = {}) => orig.braceExpand(pattern, ext(def, options)),\n        match: (list, pattern, options = {}) => orig.match(list, pattern, ext(def, options)),\n        sep: orig.sep,\n        GLOBSTAR: exports.GLOBSTAR,\n    });\n};\nexports.defaults = defaults;\nexports.minimatch.defaults = exports.defaults;\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nconst braceExpand = (pattern, options = {}) => {\n    (0, assert_valid_pattern_js_1.assertValidPattern)(pattern);\n    // Thanks to Yeting Li <https://github.com/yetingli> for\n    // improving this regexp to avoid a ReDOS vulnerability.\n    if (options.nobrace || !/\\{(?:(?!\\{).)*\\}/.test(pattern)) {\n        // shortcut. no need to expand.\n        return [pattern];\n    }\n    return (0, brace_expansion_1.default)(pattern);\n};\nexports.braceExpand = braceExpand;\nexports.minimatch.braceExpand = exports.braceExpand;\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nconst makeRe = (pattern, options = {}) => new Minimatch(pattern, options).makeRe();\nexports.makeRe = makeRe;\nexports.minimatch.makeRe = exports.makeRe;\nconst match = (list, pattern, options = {}) => {\n    const mm = new Minimatch(pattern, options);\n    list = list.filter(f => mm.match(f));\n    if (mm.options.nonull && !list.length) {\n        list.push(pattern);\n    }\n    return list;\n};\nexports.match = match;\nexports.minimatch.match = exports.match;\n// replace stuff like \\* with *\nconst globMagic = /[?*]|[+@!]\\(.*?\\)|\\[|\\]/;\nconst regExpEscape = (s) => s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&');\nclass Minimatch {\n    options;\n    set;\n    pattern;\n    windowsPathsNoEscape;\n    nonegate;\n    negate;\n    comment;\n    empty;\n    preserveMultipleSlashes;\n    partial;\n    globSet;\n    globParts;\n    nocase;\n    isWindows;\n    platform;\n    windowsNoMagicRoot;\n    regexp;\n    constructor(pattern, options = {}) {\n        (0, assert_valid_pattern_js_1.assertValidPattern)(pattern);\n        options = options || {};\n        this.options = options;\n        this.pattern = pattern;\n        this.platform = options.platform || defaultPlatform;\n        this.isWindows = this.platform === 'win32';\n        this.windowsPathsNoEscape =\n            !!options.windowsPathsNoEscape || options.allowWindowsEscape === false;\n        if (this.windowsPathsNoEscape) {\n            this.pattern = this.pattern.replace(/\\\\/g, '/');\n        }\n        this.preserveMultipleSlashes = !!options.preserveMultipleSlashes;\n        this.regexp = null;\n        this.negate = false;\n        this.nonegate = !!options.nonegate;\n        this.comment = false;\n        this.empty = false;\n        this.partial = !!options.partial;\n        this.nocase = !!this.options.nocase;\n        this.windowsNoMagicRoot =\n            options.windowsNoMagicRoot !== undefined\n                ? options.windowsNoMagicRoot\n                : !!(this.isWindows && this.nocase);\n        this.globSet = [];\n        this.globParts = [];\n        this.set = [];\n        // make the set of regexps etc.\n        this.make();\n    }\n    hasMagic() {\n        if (this.options.magicalBraces && this.set.length > 1) {\n            return true;\n        }\n        for (const pattern of this.set) {\n            for (const part of pattern) {\n                if (typeof part !== 'string')\n                    return true;\n            }\n        }\n        return false;\n    }\n    debug(..._) { }\n    make() {\n        const pattern = this.pattern;\n        const options = this.options;\n        // empty patterns and comments match nothing.\n        if (!options.nocomment && pattern.charAt(0) === '#') {\n            this.comment = true;\n            return;\n        }\n        if (!pattern) {\n            this.empty = true;\n            return;\n        }\n        // step 1: figure out negation, etc.\n        this.parseNegate();\n        // step 2: expand braces\n        this.globSet = [...new Set(this.braceExpand())];\n        if (options.debug) {\n            this.debug = (...args) => console.error(...args);\n        }\n        this.debug(this.pattern, this.globSet);\n        // step 3: now we have a set, so turn each one into a series of\n        // path-portion matching patterns.\n        // These will be regexps, except in the case of \"**\", which is\n        // set to the GLOBSTAR object for globstar behavior,\n        // and will not contain any / characters\n        //\n        // First, we preprocess to make the glob pattern sets a bit simpler\n        // and deduped.  There are some perf-killing patterns that can cause\n        // problems with a glob walk, but we can simplify them down a bit.\n        const rawGlobParts = this.globSet.map(s => this.slashSplit(s));\n        this.globParts = this.preprocess(rawGlobParts);\n        this.debug(this.pattern, this.globParts);\n        // glob --> regexps\n        let set = this.globParts.map((s, _, __) => {\n            if (this.isWindows && this.windowsNoMagicRoot) {\n                // check if it's a drive or unc path.\n                const isUNC = s[0] === '' &&\n                    s[1] === '' &&\n                    (s[2] === '?' || !globMagic.test(s[2])) &&\n                    !globMagic.test(s[3]);\n                const isDrive = /^[a-z]:/i.test(s[0]);\n                if (isUNC) {\n                    return [...s.slice(0, 4), ...s.slice(4).map(ss => this.parse(ss))];\n                }\n                else if (isDrive) {\n                    return [s[0], ...s.slice(1).map(ss => this.parse(ss))];\n                }\n            }\n            return s.map(ss => this.parse(ss));\n        });\n        this.debug(this.pattern, set);\n        // filter out everything that didn't compile properly.\n        this.set = set.filter(s => s.indexOf(false) === -1);\n        // do not treat the ? in UNC paths as magic\n        if (this.isWindows) {\n            for (let i = 0; i < this.set.length; i++) {\n                const p = this.set[i];\n                if (p[0] === '' &&\n                    p[1] === '' &&\n                    this.globParts[i][2] === '?' &&\n                    typeof p[3] === 'string' &&\n                    /^[a-z]:$/i.test(p[3])) {\n                    p[2] = '?';\n                }\n            }\n        }\n        this.debug(this.pattern, this.set);\n    }\n    // various transforms to equivalent pattern sets that are\n    // faster to process in a filesystem walk.  The goal is to\n    // eliminate what we can, and push all ** patterns as far\n    // to the right as possible, even if it increases the number\n    // of patterns that we have to process.\n    preprocess(globParts) {\n        // if we're not in globstar mode, then turn all ** into *\n        if (this.options.noglobstar) {\n            for (let i = 0; i < globParts.length; i++) {\n                for (let j = 0; j < globParts[i].length; j++) {\n                    if (globParts[i][j] === '**') {\n                        globParts[i][j] = '*';\n                    }\n                }\n            }\n        }\n        const { optimizationLevel = 1 } = this.options;\n        if (optimizationLevel >= 2) {\n            // aggressive optimization for the purpose of fs walking\n            globParts = this.firstPhasePreProcess(globParts);\n            globParts = this.secondPhasePreProcess(globParts);\n        }\n        else if (optimizationLevel >= 1) {\n            // just basic optimizations to remove some .. parts\n            globParts = this.levelOneOptimize(globParts);\n        }\n        else {\n            // just collapse multiple ** portions into one\n            globParts = this.adjascentGlobstarOptimize(globParts);\n        }\n        return globParts;\n    }\n    // just get rid of adjascent ** portions\n    adjascentGlobstarOptimize(globParts) {\n        return globParts.map(parts => {\n            let gs = -1;\n            while (-1 !== (gs = parts.indexOf('**', gs + 1))) {\n                let i = gs;\n                while (parts[i + 1] === '**') {\n                    i++;\n                }\n                if (i !== gs) {\n                    parts.splice(gs, i - gs);\n                }\n            }\n            return parts;\n        });\n    }\n    // get rid of adjascent ** and resolve .. portions\n    levelOneOptimize(globParts) {\n        return globParts.map(parts => {\n            parts = parts.reduce((set, part) => {\n                const prev = set[set.length - 1];\n                if (part === '**' && prev === '**') {\n                    return set;\n                }\n                if (part === '..') {\n                    if (prev && prev !== '..' && prev !== '.' && prev !== '**') {\n                        set.pop();\n                        return set;\n                    }\n                }\n                set.push(part);\n                return set;\n            }, []);\n            return parts.length === 0 ? [''] : parts;\n        });\n    }\n    levelTwoFileOptimize(parts) {\n        if (!Array.isArray(parts)) {\n            parts = this.slashSplit(parts);\n        }\n        let didSomething = false;\n        do {\n            didSomething = false;\n            // <pre>/<e>/<rest> -> <pre>/<rest>\n            if (!this.preserveMultipleSlashes) {\n                for (let i = 1; i < parts.length - 1; i++) {\n                    const p = parts[i];\n                    // don't squeeze out UNC patterns\n                    if (i === 1 && p === '' && parts[0] === '')\n                        continue;\n                    if (p === '.' || p === '') {\n                        didSomething = true;\n                        parts.splice(i, 1);\n                        i--;\n                    }\n                }\n                if (parts[0] === '.' &&\n                    parts.length === 2 &&\n                    (parts[1] === '.' || parts[1] === '')) {\n                    didSomething = true;\n                    parts.pop();\n                }\n            }\n            // <pre>/<p>/../<rest> -> <pre>/<rest>\n            let dd = 0;\n            while (-1 !== (dd = parts.indexOf('..', dd + 1))) {\n                const p = parts[dd - 1];\n                if (p && p !== '.' && p !== '..' && p !== '**') {\n                    didSomething = true;\n                    parts.splice(dd - 1, 2);\n                    dd -= 2;\n                }\n            }\n        } while (didSomething);\n        return parts.length === 0 ? [''] : parts;\n    }\n    // First phase: single-pattern processing\n    // <pre> is 1 or more portions\n    // <rest> is 1 or more portions\n    // <p> is any portion other than ., .., '', or **\n    // <e> is . or ''\n    //\n    // **/.. is *brutal* for filesystem walking performance, because\n    // it effectively resets the recursive walk each time it occurs,\n    // and ** cannot be reduced out by a .. pattern part like a regexp\n    // or most strings (other than .., ., and '') can be.\n    //\n    // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}\n    // <pre>/<e>/<rest> -> <pre>/<rest>\n    // <pre>/<p>/../<rest> -> <pre>/<rest>\n    // **/**/<rest> -> **/<rest>\n    //\n    // **/*/<rest> -> */**/<rest> <== not valid because ** doesn't follow\n    // this WOULD be allowed if ** did follow symlinks, or * didn't\n    firstPhasePreProcess(globParts) {\n        let didSomething = false;\n        do {\n            didSomething = false;\n            // <pre>/**/../<p>/<p>/<rest> -> {<pre>/../<p>/<p>/<rest>,<pre>/**/<p>/<p>/<rest>}\n            for (let parts of globParts) {\n                let gs = -1;\n                while (-1 !== (gs = parts.indexOf('**', gs + 1))) {\n                    let gss = gs;\n                    while (parts[gss + 1] === '**') {\n                        // <pre>/**/**/<rest> -> <pre>/**/<rest>\n                        gss++;\n                    }\n                    // eg, if gs is 2 and gss is 4, that means we have 3 **\n                    // parts, and can remove 2 of them.\n                    if (gss > gs) {\n                        parts.splice(gs + 1, gss - gs);\n                    }\n                    let next = parts[gs + 1];\n                    const p = parts[gs + 2];\n                    const p2 = parts[gs + 3];\n                    if (next !== '..')\n                        continue;\n                    if (!p ||\n                        p === '.' ||\n                        p === '..' ||\n                        !p2 ||\n                        p2 === '.' ||\n                        p2 === '..') {\n                        continue;\n                    }\n                    didSomething = true;\n                    // edit parts in place, and push the new one\n                    parts.splice(gs, 1);\n                    const other = parts.slice(0);\n                    other[gs] = '**';\n                    globParts.push(other);\n                    gs--;\n                }\n                // <pre>/<e>/<rest> -> <pre>/<rest>\n                if (!this.preserveMultipleSlashes) {\n                    for (let i = 1; i < parts.length - 1; i++) {\n                        const p = parts[i];\n                        // don't squeeze out UNC patterns\n                        if (i === 1 && p === '' && parts[0] === '')\n                            continue;\n                        if (p === '.' || p === '') {\n                            didSomething = true;\n                            parts.splice(i, 1);\n                            i--;\n                        }\n                    }\n                    if (parts[0] === '.' &&\n                        parts.length === 2 &&\n                        (parts[1] === '.' || parts[1] === '')) {\n                        didSomething = true;\n                        parts.pop();\n                    }\n                }\n                // <pre>/<p>/../<rest> -> <pre>/<rest>\n                let dd = 0;\n                while (-1 !== (dd = parts.indexOf('..', dd + 1))) {\n                    const p = parts[dd - 1];\n                    if (p && p !== '.' && p !== '..' && p !== '**') {\n                        didSomething = true;\n                        const needDot = dd === 1 && parts[dd + 1] === '**';\n                        const splin = needDot ? ['.'] : [];\n                        parts.splice(dd - 1, 2, ...splin);\n                        if (parts.length === 0)\n                            parts.push('');\n                        dd -= 2;\n                    }\n                }\n            }\n        } while (didSomething);\n        return globParts;\n    }\n    // second phase: multi-pattern dedupes\n    // {<pre>/*/<rest>,<pre>/<p>/<rest>} -> <pre>/*/<rest>\n    // {<pre>/<rest>,<pre>/<rest>} -> <pre>/<rest>\n    // {<pre>/**/<rest>,<pre>/<rest>} -> <pre>/**/<rest>\n    //\n    // {<pre>/**/<rest>,<pre>/**/<p>/<rest>} -> <pre>/**/<rest>\n    // ^-- not valid because ** doens't follow symlinks\n    secondPhasePreProcess(globParts) {\n        for (let i = 0; i < globParts.length - 1; i++) {\n            for (let j = i + 1; j < globParts.length; j++) {\n                const matched = this.partsMatch(globParts[i], globParts[j], !this.preserveMultipleSlashes);\n                if (matched) {\n                    globParts[i] = [];\n                    globParts[j] = matched;\n                    break;\n                }\n            }\n        }\n        return globParts.filter(gs => gs.length);\n    }\n    partsMatch(a, b, emptyGSMatch = false) {\n        let ai = 0;\n        let bi = 0;\n        let result = [];\n        let which = '';\n        while (ai < a.length && bi < b.length) {\n            if (a[ai] === b[bi]) {\n                result.push(which === 'b' ? b[bi] : a[ai]);\n                ai++;\n                bi++;\n            }\n            else if (emptyGSMatch && a[ai] === '**' && b[bi] === a[ai + 1]) {\n                result.push(a[ai]);\n                ai++;\n            }\n            else if (emptyGSMatch && b[bi] === '**' && a[ai] === b[bi + 1]) {\n                result.push(b[bi]);\n                bi++;\n            }\n            else if (a[ai] === '*' &&\n                b[bi] &&\n                (this.options.dot || !b[bi].startsWith('.')) &&\n                b[bi] !== '**') {\n                if (which === 'b')\n                    return false;\n                which = 'a';\n                result.push(a[ai]);\n                ai++;\n                bi++;\n            }\n            else if (b[bi] === '*' &&\n                a[ai] &&\n                (this.options.dot || !a[ai].startsWith('.')) &&\n                a[ai] !== '**') {\n                if (which === 'a')\n                    return false;\n                which = 'b';\n                result.push(b[bi]);\n                ai++;\n                bi++;\n            }\n            else {\n                return false;\n            }\n        }\n        // if we fall out of the loop, it means they two are identical\n        // as long as their lengths match\n        return a.length === b.length && result;\n    }\n    parseNegate() {\n        if (this.nonegate)\n            return;\n        const pattern = this.pattern;\n        let negate = false;\n        let negateOffset = 0;\n        for (let i = 0; i < pattern.length && pattern.charAt(i) === '!'; i++) {\n            negate = !negate;\n            negateOffset++;\n        }\n        if (negateOffset)\n            this.pattern = pattern.slice(negateOffset);\n        this.negate = negate;\n    }\n    // set partial to true to test if, for example,\n    // \"/a/b\" matches the start of \"/*/b/*/d\"\n    // Partial means, if you run out of file before you run\n    // out of pattern, then that's fine, as long as all\n    // the parts match.\n    matchOne(file, pattern, partial = false) {\n        const options = this.options;\n        // UNC paths like //?/X:/... can match X:/... and vice versa\n        // Drive letters in absolute drive or unc paths are always compared\n        // case-insensitively.\n        if (this.isWindows) {\n            const fileDrive = typeof file[0] === 'string' && /^[a-z]:$/i.test(file[0]);\n            const fileUNC = !fileDrive &&\n                file[0] === '' &&\n                file[1] === '' &&\n                file[2] === '?' &&\n                /^[a-z]:$/i.test(file[3]);\n            const patternDrive = typeof pattern[0] === 'string' && /^[a-z]:$/i.test(pattern[0]);\n            const patternUNC = !patternDrive &&\n                pattern[0] === '' &&\n                pattern[1] === '' &&\n                pattern[2] === '?' &&\n                typeof pattern[3] === 'string' &&\n                /^[a-z]:$/i.test(pattern[3]);\n            const fdi = fileUNC ? 3 : fileDrive ? 0 : undefined;\n            const pdi = patternUNC ? 3 : patternDrive ? 0 : undefined;\n            if (typeof fdi === 'number' && typeof pdi === 'number') {\n                const [fd, pd] = [file[fdi], pattern[pdi]];\n                if (fd.toLowerCase() === pd.toLowerCase()) {\n                    pattern[pdi] = fd;\n                    if (pdi > fdi) {\n                        pattern = pattern.slice(pdi);\n                    }\n                    else if (fdi > pdi) {\n                        file = file.slice(fdi);\n                    }\n                }\n            }\n        }\n        // resolve and reduce . and .. portions in the file as well.\n        // dont' need to do the second phase, because it's only one string[]\n        const { optimizationLevel = 1 } = this.options;\n        if (optimizationLevel >= 2) {\n            file = this.levelTwoFileOptimize(file);\n        }\n        this.debug('matchOne', this, { file, pattern });\n        this.debug('matchOne', file.length, pattern.length);\n        for (var fi = 0, pi = 0, fl = file.length, pl = pattern.length; fi < fl && pi < pl; fi++, pi++) {\n            this.debug('matchOne loop');\n            var p = pattern[pi];\n            var f = file[fi];\n            this.debug(pattern, p, f);\n            // should be impossible.\n            // some invalid regexp stuff in the set.\n            /* c8 ignore start */\n            if (p === false) {\n                return false;\n            }\n            /* c8 ignore stop */\n            if (p === exports.GLOBSTAR) {\n                this.debug('GLOBSTAR', [pattern, p, f]);\n                // \"**\"\n                // a/**/b/**/c would match the following:\n                // a/b/x/y/z/c\n                // a/x/y/z/b/c\n                // a/b/x/b/x/c\n                // a/b/c\n                // To do this, take the rest of the pattern after\n                // the **, and see if it would match the file remainder.\n                // If so, return success.\n                // If not, the ** \"swallows\" a segment, and try again.\n                // This is recursively awful.\n                //\n                // a/**/b/**/c matching a/b/x/y/z/c\n                // - a matches a\n                // - doublestar\n                //   - matchOne(b/x/y/z/c, b/**/c)\n                //     - b matches b\n                //     - doublestar\n                //       - matchOne(x/y/z/c, c) -> no\n                //       - matchOne(y/z/c, c) -> no\n                //       - matchOne(z/c, c) -> no\n                //       - matchOne(c, c) yes, hit\n                var fr = fi;\n                var pr = pi + 1;\n                if (pr === pl) {\n                    this.debug('** at the end');\n                    // a ** at the end will just swallow the rest.\n                    // We have found a match.\n                    // however, it will not swallow /.x, unless\n                    // options.dot is set.\n                    // . and .. are *never* matched by **, for explosively\n                    // exponential reasons.\n                    for (; fi < fl; fi++) {\n                        if (file[fi] === '.' ||\n                            file[fi] === '..' ||\n                            (!options.dot && file[fi].charAt(0) === '.'))\n                            return false;\n                    }\n                    return true;\n                }\n                // ok, let's see if we can swallow whatever we can.\n                while (fr < fl) {\n                    var swallowee = file[fr];\n                    this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee);\n                    // XXX remove this slice.  Just pass the start index.\n                    if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n                        this.debug('globstar found match!', fr, fl, swallowee);\n                        // found a match.\n                        return true;\n                    }\n                    else {\n                        // can't swallow \".\" or \"..\" ever.\n                        // can only swallow \".foo\" when explicitly asked.\n                        if (swallowee === '.' ||\n                            swallowee === '..' ||\n                            (!options.dot && swallowee.charAt(0) === '.')) {\n                            this.debug('dot detected!', file, fr, pattern, pr);\n                            break;\n                        }\n                        // ** swallows a segment, and continue.\n                        this.debug('globstar swallow a segment, and continue');\n                        fr++;\n                    }\n                }\n                // no match was found.\n                // However, in partial mode, we can't say this is necessarily over.\n                /* c8 ignore start */\n                if (partial) {\n                    // ran out of file\n                    this.debug('\\n>>> no match, partial?', file, fr, pattern, pr);\n                    if (fr === fl) {\n                        return true;\n                    }\n                }\n                /* c8 ignore stop */\n                return false;\n            }\n            // something other than **\n            // non-magic patterns just have to match exactly\n            // patterns with magic have been turned into regexps.\n            let hit;\n            if (typeof p === 'string') {\n                hit = f === p;\n                this.debug('string match', p, f, hit);\n            }\n            else {\n                hit = p.test(f);\n                this.debug('pattern match', p, f, hit);\n            }\n            if (!hit)\n                return false;\n        }\n        // Note: ending in / means that we'll get a final \"\"\n        // at the end of the pattern.  This can only match a\n        // corresponding \"\" at the end of the file.\n        // If the file ends in /, then it can only match a\n        // a pattern that ends in /, unless the pattern just\n        // doesn't have any more for it. But, a/b/ should *not*\n        // match \"a/b/*\", even though \"\" matches against the\n        // [^/]*? pattern, except in partial mode, where it might\n        // simply not be reached yet.\n        // However, a/b/ should still satisfy a/*\n        // now either we fell off the end of the pattern, or we're done.\n        if (fi === fl && pi === pl) {\n            // ran out of pattern and filename at the same time.\n            // an exact hit!\n            return true;\n        }\n        else if (fi === fl) {\n            // ran out of file, but still had pattern left.\n            // this is ok if we're doing the match as part of\n            // a glob fs traversal.\n            return partial;\n        }\n        else if (pi === pl) {\n            // ran out of pattern, still have file left.\n            // this is only acceptable if we're on the very last\n            // empty segment of a file with a trailing slash.\n            // a/* should match a/b/\n            return fi === fl - 1 && file[fi] === '';\n            /* c8 ignore start */\n        }\n        else {\n            // should be unreachable.\n            throw new Error('wtf?');\n        }\n        /* c8 ignore stop */\n    }\n    braceExpand() {\n        return (0, exports.braceExpand)(this.pattern, this.options);\n    }\n    parse(pattern) {\n        (0, assert_valid_pattern_js_1.assertValidPattern)(pattern);\n        const options = this.options;\n        // shortcuts\n        if (pattern === '**')\n            return exports.GLOBSTAR;\n        if (pattern === '')\n            return '';\n        // far and away, the most common glob pattern parts are\n        // *, *.*, and *.<ext>  Add a fast check method for those.\n        let m;\n        let fastTest = null;\n        if ((m = pattern.match(starRE))) {\n            fastTest = options.dot ? starTestDot : starTest;\n        }\n        else if ((m = pattern.match(starDotExtRE))) {\n            fastTest = (options.nocase\n                ? options.dot\n                    ? starDotExtTestNocaseDot\n                    : starDotExtTestNocase\n                : options.dot\n                    ? starDotExtTestDot\n                    : starDotExtTest)(m[1]);\n        }\n        else if ((m = pattern.match(qmarksRE))) {\n            fastTest = (options.nocase\n                ? options.dot\n                    ? qmarksTestNocaseDot\n                    : qmarksTestNocase\n                : options.dot\n                    ? qmarksTestDot\n                    : qmarksTest)(m);\n        }\n        else if ((m = pattern.match(starDotStarRE))) {\n            fastTest = options.dot ? starDotStarTestDot : starDotStarTest;\n        }\n        else if ((m = pattern.match(dotStarRE))) {\n            fastTest = dotStarTest;\n        }\n        const re = ast_js_1.AST.fromGlob(pattern, this.options).toMMPattern();\n        if (fastTest && typeof re === 'object') {\n            // Avoids overriding in frozen environments\n            Reflect.defineProperty(re, 'test', { value: fastTest });\n        }\n        return re;\n    }\n    makeRe() {\n        if (this.regexp || this.regexp === false)\n            return this.regexp;\n        // at this point, this.set is a 2d array of partial\n        // pattern strings, or \"**\".\n        //\n        // It's better to use .match().  This function shouldn't\n        // be used, really, but it's pretty convenient sometimes,\n        // when you just want to work with a regex.\n        const set = this.set;\n        if (!set.length) {\n            this.regexp = false;\n            return this.regexp;\n        }\n        const options = this.options;\n        const twoStar = options.noglobstar\n            ? star\n            : options.dot\n                ? twoStarDot\n                : twoStarNoDot;\n        const flags = new Set(options.nocase ? ['i'] : []);\n        // regexpify non-globstar patterns\n        // if ** is only item, then we just do one twoStar\n        // if ** is first, and there are more, prepend (\\/|twoStar\\/)? to next\n        // if ** is last, append (\\/twoStar|) to previous\n        // if ** is in the middle, append (\\/|\\/twoStar\\/) to previous\n        // then filter out GLOBSTAR symbols\n        let re = set\n            .map(pattern => {\n            const pp = pattern.map(p => {\n                if (p instanceof RegExp) {\n                    for (const f of p.flags.split(''))\n                        flags.add(f);\n                }\n                return typeof p === 'string'\n                    ? regExpEscape(p)\n                    : p === exports.GLOBSTAR\n                        ? exports.GLOBSTAR\n                        : p._src;\n            });\n            pp.forEach((p, i) => {\n                const next = pp[i + 1];\n                const prev = pp[i - 1];\n                if (p !== exports.GLOBSTAR || prev === exports.GLOBSTAR) {\n                    return;\n                }\n                if (prev === undefined) {\n                    if (next !== undefined && next !== exports.GLOBSTAR) {\n                        pp[i + 1] = '(?:\\\\/|' + twoStar + '\\\\/)?' + next;\n                    }\n                    else {\n                        pp[i] = twoStar;\n                    }\n                }\n                else if (next === undefined) {\n                    pp[i - 1] = prev + '(?:\\\\/|' + twoStar + ')?';\n                }\n                else if (next !== exports.GLOBSTAR) {\n                    pp[i - 1] = prev + '(?:\\\\/|\\\\/' + twoStar + '\\\\/)' + next;\n                    pp[i + 1] = exports.GLOBSTAR;\n                }\n            });\n            return pp.filter(p => p !== exports.GLOBSTAR).join('/');\n        })\n            .join('|');\n        // need to wrap in parens if we had more than one thing with |,\n        // otherwise only the first will be anchored to ^ and the last to $\n        const [open, close] = set.length > 1 ? ['(?:', ')'] : ['', ''];\n        // must match entire pattern\n        // ending in a * or ** will make it less strict.\n        re = '^' + open + re + close + '$';\n        // can match anything, as long as it's not this.\n        if (this.negate)\n            re = '^(?!' + re + ').+$';\n        try {\n            this.regexp = new RegExp(re, [...flags].join(''));\n            /* c8 ignore start */\n        }\n        catch (ex) {\n            // should be impossible\n            this.regexp = false;\n        }\n        /* c8 ignore stop */\n        return this.regexp;\n    }\n    slashSplit(p) {\n        // if p starts with // on windows, we preserve that\n        // so that UNC paths aren't broken.  Otherwise, any number of\n        // / characters are coalesced into one, unless\n        // preserveMultipleSlashes is set to true.\n        if (this.preserveMultipleSlashes) {\n            return p.split('/');\n        }\n        else if (this.isWindows && /^\\/\\/[^\\/]+/.test(p)) {\n            // add an extra '' for the one we lose\n            return ['', ...p.split(/\\/+/)];\n        }\n        else {\n            return p.split(/\\/+/);\n        }\n    }\n    match(f, partial = this.partial) {\n        this.debug('match', f, this.pattern);\n        // short-circuit in the case of busted things.\n        // comments, etc.\n        if (this.comment) {\n            return false;\n        }\n        if (this.empty) {\n            return f === '';\n        }\n        if (f === '/' && partial) {\n            return true;\n        }\n        const options = this.options;\n        // windows: need to use /, not \\\n        if (this.isWindows) {\n            f = f.split('\\\\').join('/');\n        }\n        // treat the test path as a set of pathparts.\n        const ff = this.slashSplit(f);\n        this.debug(this.pattern, 'split', ff);\n        // just ONE of the pattern sets in this.set needs to match\n        // in order for it to be valid.  If negating, then just one\n        // match means that we have failed.\n        // Either way, return on the first hit.\n        const set = this.set;\n        this.debug(this.pattern, 'set', set);\n        // Find the basename of the path by looking for the last non-empty segment\n        let filename = ff[ff.length - 1];\n        if (!filename) {\n            for (let i = ff.length - 2; !filename && i >= 0; i--) {\n                filename = ff[i];\n            }\n        }\n        for (let i = 0; i < set.length; i++) {\n            const pattern = set[i];\n            let file = ff;\n            if (options.matchBase && pattern.length === 1) {\n                file = [filename];\n            }\n            const hit = this.matchOne(file, pattern, partial);\n            if (hit) {\n                if (options.flipNegate) {\n                    return true;\n                }\n                return !this.negate;\n            }\n        }\n        // didn't get any hits.  this is success if it's a negative\n        // pattern, failure otherwise.\n        if (options.flipNegate) {\n            return false;\n        }\n        return this.negate;\n    }\n    static defaults(def) {\n        return exports.minimatch.defaults(def).Minimatch;\n    }\n}\nexports.Minimatch = Minimatch;\n/* c8 ignore start */\nvar ast_js_2 = require(\"./ast.js\");\nObject.defineProperty(exports, \"AST\", { enumerable: true, get: function () { return ast_js_2.AST; } });\nvar escape_js_2 = require(\"./escape.js\");\nObject.defineProperty(exports, \"escape\", { enumerable: true, get: function () { return escape_js_2.escape; } });\nvar unescape_js_2 = require(\"./unescape.js\");\nObject.defineProperty(exports, \"unescape\", { enumerable: true, get: function () { return unescape_js_2.unescape; } });\n/* c8 ignore stop */\nexports.minimatch.AST = ast_js_1.AST;\nexports.minimatch.Minimatch = Minimatch;\nexports.minimatch.escape = escape_js_1.escape;\nexports.minimatch.unescape = unescape_js_1.unescape;\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.unescape = void 0;\n/**\n * Un-escape a string that has been escaped with {@link escape}.\n *\n * If the {@link windowsPathsNoEscape} option is used, then square-brace\n * escapes are removed, but not backslash escapes.  For example, it will turn\n * the string `'[*]'` into `*`, but it will not turn `'\\\\*'` into `'*'`,\n * becuase `\\` is a path separator in `windowsPathsNoEscape` mode.\n *\n * When `windowsPathsNoEscape` is not set, then both brace escapes and\n * backslash escapes are removed.\n *\n * Slashes (and backslashes in `windowsPathsNoEscape` mode) cannot be escaped\n * or unescaped.\n */\nconst unescape = (s, { windowsPathsNoEscape = false, } = {}) => {\n    return windowsPathsNoEscape\n        ? s.replace(/\\[([^\\/\\\\])\\]/g, '$1')\n        : s.replace(/((?!\\\\).|^)\\[([^\\/\\\\])\\]/g, '$1$2').replace(/\\\\([^\\/])/g, '$1');\n};\nexports.unescape = unescape;\n//# sourceMappingURL=unescape.js.map","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Minipass = exports.isWritable = exports.isReadable = exports.isStream = void 0;\nconst proc = typeof process === 'object' && process\n    ? process\n    : {\n        stdout: null,\n        stderr: null,\n    };\nconst node_events_1 = require(\"node:events\");\nconst node_stream_1 = __importDefault(require(\"node:stream\"));\nconst node_string_decoder_1 = require(\"node:string_decoder\");\n/**\n * Return true if the argument is a Minipass stream, Node stream, or something\n * else that Minipass can interact with.\n */\nconst isStream = (s) => !!s &&\n    typeof s === 'object' &&\n    (s instanceof Minipass ||\n        s instanceof node_stream_1.default ||\n        (0, exports.isReadable)(s) ||\n        (0, exports.isWritable)(s));\nexports.isStream = isStream;\n/**\n * Return true if the argument is a valid {@link Minipass.Readable}\n */\nconst isReadable = (s) => !!s &&\n    typeof s === 'object' &&\n    s instanceof node_events_1.EventEmitter &&\n    typeof s.pipe === 'function' &&\n    // node core Writable streams have a pipe() method, but it throws\n    s.pipe !== node_stream_1.default.Writable.prototype.pipe;\nexports.isReadable = isReadable;\n/**\n * Return true if the argument is a valid {@link Minipass.Writable}\n */\nconst isWritable = (s) => !!s &&\n    typeof s === 'object' &&\n    s instanceof node_events_1.EventEmitter &&\n    typeof s.write === 'function' &&\n    typeof s.end === 'function';\nexports.isWritable = isWritable;\nconst EOF = Symbol('EOF');\nconst MAYBE_EMIT_END = Symbol('maybeEmitEnd');\nconst EMITTED_END = Symbol('emittedEnd');\nconst EMITTING_END = Symbol('emittingEnd');\nconst EMITTED_ERROR = Symbol('emittedError');\nconst CLOSED = Symbol('closed');\nconst READ = Symbol('read');\nconst FLUSH = Symbol('flush');\nconst FLUSHCHUNK = Symbol('flushChunk');\nconst ENCODING = Symbol('encoding');\nconst DECODER = Symbol('decoder');\nconst FLOWING = Symbol('flowing');\nconst PAUSED = Symbol('paused');\nconst RESUME = Symbol('resume');\nconst BUFFER = Symbol('buffer');\nconst PIPES = Symbol('pipes');\nconst BUFFERLENGTH = Symbol('bufferLength');\nconst BUFFERPUSH = Symbol('bufferPush');\nconst BUFFERSHIFT = Symbol('bufferShift');\nconst OBJECTMODE = Symbol('objectMode');\n// internal event when stream is destroyed\nconst DESTROYED = Symbol('destroyed');\n// internal event when stream has an error\nconst ERROR = Symbol('error');\nconst EMITDATA = Symbol('emitData');\nconst EMITEND = Symbol('emitEnd');\nconst EMITEND2 = Symbol('emitEnd2');\nconst ASYNC = Symbol('async');\nconst ABORT = Symbol('abort');\nconst ABORTED = Symbol('aborted');\nconst SIGNAL = Symbol('signal');\nconst DATALISTENERS = Symbol('dataListeners');\nconst DISCARDED = Symbol('discarded');\nconst defer = (fn) => Promise.resolve().then(fn);\nconst nodefer = (fn) => fn();\nconst isEndish = (ev) => ev === 'end' || ev === 'finish' || ev === 'prefinish';\nconst isArrayBufferLike = (b) => b instanceof ArrayBuffer ||\n    (!!b &&\n        typeof b === 'object' &&\n        b.constructor &&\n        b.constructor.name === 'ArrayBuffer' &&\n        b.byteLength >= 0);\nconst isArrayBufferView = (b) => !Buffer.isBuffer(b) && ArrayBuffer.isView(b);\n/**\n * Internal class representing a pipe to a destination stream.\n *\n * @internal\n */\nclass Pipe {\n    src;\n    dest;\n    opts;\n    ondrain;\n    constructor(src, dest, opts) {\n        this.src = src;\n        this.dest = dest;\n        this.opts = opts;\n        this.ondrain = () => src[RESUME]();\n        this.dest.on('drain', this.ondrain);\n    }\n    unpipe() {\n        this.dest.removeListener('drain', this.ondrain);\n    }\n    // only here for the prototype\n    /* c8 ignore start */\n    proxyErrors(_er) { }\n    /* c8 ignore stop */\n    end() {\n        this.unpipe();\n        if (this.opts.end)\n            this.dest.end();\n    }\n}\n/**\n * Internal class representing a pipe to a destination stream where\n * errors are proxied.\n *\n * @internal\n */\nclass PipeProxyErrors extends Pipe {\n    unpipe() {\n        this.src.removeListener('error', this.proxyErrors);\n        super.unpipe();\n    }\n    constructor(src, dest, opts) {\n        super(src, dest, opts);\n        this.proxyErrors = er => dest.emit('error', er);\n        src.on('error', this.proxyErrors);\n    }\n}\nconst isObjectModeOptions = (o) => !!o.objectMode;\nconst isEncodingOptions = (o) => !o.objectMode && !!o.encoding && o.encoding !== 'buffer';\n/**\n * Main export, the Minipass class\n *\n * `RType` is the type of data emitted, defaults to Buffer\n *\n * `WType` is the type of data to be written, if RType is buffer or string,\n * then any {@link Minipass.ContiguousData} is allowed.\n *\n * `Events` is the set of event handler signatures that this object\n * will emit, see {@link Minipass.Events}\n */\nclass Minipass extends node_events_1.EventEmitter {\n    [FLOWING] = false;\n    [PAUSED] = false;\n    [PIPES] = [];\n    [BUFFER] = [];\n    [OBJECTMODE];\n    [ENCODING];\n    [ASYNC];\n    [DECODER];\n    [EOF] = false;\n    [EMITTED_END] = false;\n    [EMITTING_END] = false;\n    [CLOSED] = false;\n    [EMITTED_ERROR] = null;\n    [BUFFERLENGTH] = 0;\n    [DESTROYED] = false;\n    [SIGNAL];\n    [ABORTED] = false;\n    [DATALISTENERS] = 0;\n    [DISCARDED] = false;\n    /**\n     * true if the stream can be written\n     */\n    writable = true;\n    /**\n     * true if the stream can be read\n     */\n    readable = true;\n    /**\n     * If `RType` is Buffer, then options do not need to be provided.\n     * Otherwise, an options object must be provided to specify either\n     * {@link Minipass.SharedOptions.objectMode} or\n     * {@link Minipass.SharedOptions.encoding}, as appropriate.\n     */\n    constructor(...args) {\n        const options = (args[0] ||\n            {});\n        super();\n        if (options.objectMode && typeof options.encoding === 'string') {\n            throw new TypeError('Encoding and objectMode may not be used together');\n        }\n        if (isObjectModeOptions(options)) {\n            this[OBJECTMODE] = true;\n            this[ENCODING] = null;\n        }\n        else if (isEncodingOptions(options)) {\n            this[ENCODING] = options.encoding;\n            this[OBJECTMODE] = false;\n        }\n        else {\n            this[OBJECTMODE] = false;\n            this[ENCODING] = null;\n        }\n        this[ASYNC] = !!options.async;\n        this[DECODER] = this[ENCODING]\n            ? new node_string_decoder_1.StringDecoder(this[ENCODING])\n            : null;\n        //@ts-ignore - private option for debugging and testing\n        if (options && options.debugExposeBuffer === true) {\n            Object.defineProperty(this, 'buffer', { get: () => this[BUFFER] });\n        }\n        //@ts-ignore - private option for debugging and testing\n        if (options && options.debugExposePipes === true) {\n            Object.defineProperty(this, 'pipes', { get: () => this[PIPES] });\n        }\n        const { signal } = options;\n        if (signal) {\n            this[SIGNAL] = signal;\n            if (signal.aborted) {\n                this[ABORT]();\n            }\n            else {\n                signal.addEventListener('abort', () => this[ABORT]());\n            }\n        }\n    }\n    /**\n     * The amount of data stored in the buffer waiting to be read.\n     *\n     * For Buffer strings, this will be the total byte length.\n     * For string encoding streams, this will be the string character length,\n     * according to JavaScript's `string.length` logic.\n     * For objectMode streams, this is a count of the items waiting to be\n     * emitted.\n     */\n    get bufferLength() {\n        return this[BUFFERLENGTH];\n    }\n    /**\n     * The `BufferEncoding` currently in use, or `null`\n     */\n    get encoding() {\n        return this[ENCODING];\n    }\n    /**\n     * @deprecated - This is a read only property\n     */\n    set encoding(_enc) {\n        throw new Error('Encoding must be set at instantiation time');\n    }\n    /**\n     * @deprecated - Encoding may only be set at instantiation time\n     */\n    setEncoding(_enc) {\n        throw new Error('Encoding must be set at instantiation time');\n    }\n    /**\n     * True if this is an objectMode stream\n     */\n    get objectMode() {\n        return this[OBJECTMODE];\n    }\n    /**\n     * @deprecated - This is a read-only property\n     */\n    set objectMode(_om) {\n        throw new Error('objectMode must be set at instantiation time');\n    }\n    /**\n     * true if this is an async stream\n     */\n    get ['async']() {\n        return this[ASYNC];\n    }\n    /**\n     * Set to true to make this stream async.\n     *\n     * Once set, it cannot be unset, as this would potentially cause incorrect\n     * behavior.  Ie, a sync stream can be made async, but an async stream\n     * cannot be safely made sync.\n     */\n    set ['async'](a) {\n        this[ASYNC] = this[ASYNC] || !!a;\n    }\n    // drop everything and get out of the flow completely\n    [ABORT]() {\n        this[ABORTED] = true;\n        this.emit('abort', this[SIGNAL]?.reason);\n        this.destroy(this[SIGNAL]?.reason);\n    }\n    /**\n     * True if the stream has been aborted.\n     */\n    get aborted() {\n        return this[ABORTED];\n    }\n    /**\n     * No-op setter. Stream aborted status is set via the AbortSignal provided\n     * in the constructor options.\n     */\n    set aborted(_) { }\n    write(chunk, encoding, cb) {\n        if (this[ABORTED])\n            return false;\n        if (this[EOF])\n            throw new Error('write after end');\n        if (this[DESTROYED]) {\n            this.emit('error', Object.assign(new Error('Cannot call write after a stream was destroyed'), { code: 'ERR_STREAM_DESTROYED' }));\n            return true;\n        }\n        if (typeof encoding === 'function') {\n            cb = encoding;\n            encoding = 'utf8';\n        }\n        if (!encoding)\n            encoding = 'utf8';\n        const fn = this[ASYNC] ? defer : nodefer;\n        // convert array buffers and typed array views into buffers\n        // at some point in the future, we may want to do the opposite!\n        // leave strings and buffers as-is\n        // anything is only allowed if in object mode, so throw\n        if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {\n            if (isArrayBufferView(chunk)) {\n                //@ts-ignore - sinful unsafe type changing\n                chunk = Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength);\n            }\n            else if (isArrayBufferLike(chunk)) {\n                //@ts-ignore - sinful unsafe type changing\n                chunk = Buffer.from(chunk);\n            }\n            else if (typeof chunk !== 'string') {\n                throw new Error('Non-contiguous data written to non-objectMode stream');\n            }\n        }\n        // handle object mode up front, since it's simpler\n        // this yields better performance, fewer checks later.\n        if (this[OBJECTMODE]) {\n            // maybe impossible?\n            /* c8 ignore start */\n            if (this[FLOWING] && this[BUFFERLENGTH] !== 0)\n                this[FLUSH](true);\n            /* c8 ignore stop */\n            if (this[FLOWING])\n                this.emit('data', chunk);\n            else\n                this[BUFFERPUSH](chunk);\n            if (this[BUFFERLENGTH] !== 0)\n                this.emit('readable');\n            if (cb)\n                fn(cb);\n            return this[FLOWING];\n        }\n        // at this point the chunk is a buffer or string\n        // don't buffer it up or send it to the decoder\n        if (!chunk.length) {\n            if (this[BUFFERLENGTH] !== 0)\n                this.emit('readable');\n            if (cb)\n                fn(cb);\n            return this[FLOWING];\n        }\n        // fast-path writing strings of same encoding to a stream with\n        // an empty buffer, skipping the buffer/decoder dance\n        if (typeof chunk === 'string' &&\n            // unless it is a string already ready for us to use\n            !(encoding === this[ENCODING] && !this[DECODER]?.lastNeed)) {\n            //@ts-ignore - sinful unsafe type change\n            chunk = Buffer.from(chunk, encoding);\n        }\n        if (Buffer.isBuffer(chunk) && this[ENCODING]) {\n            //@ts-ignore - sinful unsafe type change\n            chunk = this[DECODER].write(chunk);\n        }\n        // Note: flushing CAN potentially switch us into not-flowing mode\n        if (this[FLOWING] && this[BUFFERLENGTH] !== 0)\n            this[FLUSH](true);\n        if (this[FLOWING])\n            this.emit('data', chunk);\n        else\n            this[BUFFERPUSH](chunk);\n        if (this[BUFFERLENGTH] !== 0)\n            this.emit('readable');\n        if (cb)\n            fn(cb);\n        return this[FLOWING];\n    }\n    /**\n     * Low-level explicit read method.\n     *\n     * In objectMode, the argument is ignored, and one item is returned if\n     * available.\n     *\n     * `n` is the number of bytes (or in the case of encoding streams,\n     * characters) to consume. If `n` is not provided, then the entire buffer\n     * is returned, or `null` is returned if no data is available.\n     *\n     * If `n` is greater that the amount of data in the internal buffer,\n     * then `null` is returned.\n     */\n    read(n) {\n        if (this[DESTROYED])\n            return null;\n        this[DISCARDED] = false;\n        if (this[BUFFERLENGTH] === 0 ||\n            n === 0 ||\n            (n && n > this[BUFFERLENGTH])) {\n            this[MAYBE_EMIT_END]();\n            return null;\n        }\n        if (this[OBJECTMODE])\n            n = null;\n        if (this[BUFFER].length > 1 && !this[OBJECTMODE]) {\n            // not object mode, so if we have an encoding, then RType is string\n            // otherwise, must be Buffer\n            this[BUFFER] = [\n                (this[ENCODING]\n                    ? this[BUFFER].join('')\n                    : Buffer.concat(this[BUFFER], this[BUFFERLENGTH])),\n            ];\n        }\n        const ret = this[READ](n || null, this[BUFFER][0]);\n        this[MAYBE_EMIT_END]();\n        return ret;\n    }\n    [READ](n, chunk) {\n        if (this[OBJECTMODE])\n            this[BUFFERSHIFT]();\n        else {\n            const c = chunk;\n            if (n === c.length || n === null)\n                this[BUFFERSHIFT]();\n            else if (typeof c === 'string') {\n                this[BUFFER][0] = c.slice(n);\n                chunk = c.slice(0, n);\n                this[BUFFERLENGTH] -= n;\n            }\n            else {\n                this[BUFFER][0] = c.subarray(n);\n                chunk = c.subarray(0, n);\n                this[BUFFERLENGTH] -= n;\n            }\n        }\n        this.emit('data', chunk);\n        if (!this[BUFFER].length && !this[EOF])\n            this.emit('drain');\n        return chunk;\n    }\n    end(chunk, encoding, cb) {\n        if (typeof chunk === 'function') {\n            cb = chunk;\n            chunk = undefined;\n        }\n        if (typeof encoding === 'function') {\n            cb = encoding;\n            encoding = 'utf8';\n        }\n        if (chunk !== undefined)\n            this.write(chunk, encoding);\n        if (cb)\n            this.once('end', cb);\n        this[EOF] = true;\n        this.writable = false;\n        // if we haven't written anything, then go ahead and emit,\n        // even if we're not reading.\n        // we'll re-emit if a new 'end' listener is added anyway.\n        // This makes MP more suitable to write-only use cases.\n        if (this[FLOWING] || !this[PAUSED])\n            this[MAYBE_EMIT_END]();\n        return this;\n    }\n    // don't let the internal resume be overwritten\n    [RESUME]() {\n        if (this[DESTROYED])\n            return;\n        if (!this[DATALISTENERS] && !this[PIPES].length) {\n            this[DISCARDED] = true;\n        }\n        this[PAUSED] = false;\n        this[FLOWING] = true;\n        this.emit('resume');\n        if (this[BUFFER].length)\n            this[FLUSH]();\n        else if (this[EOF])\n            this[MAYBE_EMIT_END]();\n        else\n            this.emit('drain');\n    }\n    /**\n     * Resume the stream if it is currently in a paused state\n     *\n     * If called when there are no pipe destinations or `data` event listeners,\n     * this will place the stream in a \"discarded\" state, where all data will\n     * be thrown away. The discarded state is removed if a pipe destination or\n     * data handler is added, if pause() is called, or if any synchronous or\n     * asynchronous iteration is started.\n     */\n    resume() {\n        return this[RESUME]();\n    }\n    /**\n     * Pause the stream\n     */\n    pause() {\n        this[FLOWING] = false;\n        this[PAUSED] = true;\n        this[DISCARDED] = false;\n    }\n    /**\n     * true if the stream has been forcibly destroyed\n     */\n    get destroyed() {\n        return this[DESTROYED];\n    }\n    /**\n     * true if the stream is currently in a flowing state, meaning that\n     * any writes will be immediately emitted.\n     */\n    get flowing() {\n        return this[FLOWING];\n    }\n    /**\n     * true if the stream is currently in a paused state\n     */\n    get paused() {\n        return this[PAUSED];\n    }\n    [BUFFERPUSH](chunk) {\n        if (this[OBJECTMODE])\n            this[BUFFERLENGTH] += 1;\n        else\n            this[BUFFERLENGTH] += chunk.length;\n        this[BUFFER].push(chunk);\n    }\n    [BUFFERSHIFT]() {\n        if (this[OBJECTMODE])\n            this[BUFFERLENGTH] -= 1;\n        else\n            this[BUFFERLENGTH] -= this[BUFFER][0].length;\n        return this[BUFFER].shift();\n    }\n    [FLUSH](noDrain = false) {\n        do { } while (this[FLUSHCHUNK](this[BUFFERSHIFT]()) &&\n            this[BUFFER].length);\n        if (!noDrain && !this[BUFFER].length && !this[EOF])\n            this.emit('drain');\n    }\n    [FLUSHCHUNK](chunk) {\n        this.emit('data', chunk);\n        return this[FLOWING];\n    }\n    /**\n     * Pipe all data emitted by this stream into the destination provided.\n     *\n     * Triggers the flow of data.\n     */\n    pipe(dest, opts) {\n        if (this[DESTROYED])\n            return dest;\n        this[DISCARDED] = false;\n        const ended = this[EMITTED_END];\n        opts = opts || {};\n        if (dest === proc.stdout || dest === proc.stderr)\n            opts.end = false;\n        else\n            opts.end = opts.end !== false;\n        opts.proxyErrors = !!opts.proxyErrors;\n        // piping an ended stream ends immediately\n        if (ended) {\n            if (opts.end)\n                dest.end();\n        }\n        else {\n            // \"as\" here just ignores the WType, which pipes don't care about,\n            // since they're only consuming from us, and writing to the dest\n            this[PIPES].push(!opts.proxyErrors\n                ? new Pipe(this, dest, opts)\n                : new PipeProxyErrors(this, dest, opts));\n            if (this[ASYNC])\n                defer(() => this[RESUME]());\n            else\n                this[RESUME]();\n        }\n        return dest;\n    }\n    /**\n     * Fully unhook a piped destination stream.\n     *\n     * If the destination stream was the only consumer of this stream (ie,\n     * there are no other piped destinations or `'data'` event listeners)\n     * then the flow of data will stop until there is another consumer or\n     * {@link Minipass#resume} is explicitly called.\n     */\n    unpipe(dest) {\n        const p = this[PIPES].find(p => p.dest === dest);\n        if (p) {\n            if (this[PIPES].length === 1) {\n                if (this[FLOWING] && this[DATALISTENERS] === 0) {\n                    this[FLOWING] = false;\n                }\n                this[PIPES] = [];\n            }\n            else\n                this[PIPES].splice(this[PIPES].indexOf(p), 1);\n            p.unpipe();\n        }\n    }\n    /**\n     * Alias for {@link Minipass#on}\n     */\n    addListener(ev, handler) {\n        return this.on(ev, handler);\n    }\n    /**\n     * Mostly identical to `EventEmitter.on`, with the following\n     * behavior differences to prevent data loss and unnecessary hangs:\n     *\n     * - Adding a 'data' event handler will trigger the flow of data\n     *\n     * - Adding a 'readable' event handler when there is data waiting to be read\n     *   will cause 'readable' to be emitted immediately.\n     *\n     * - Adding an 'endish' event handler ('end', 'finish', etc.) which has\n     *   already passed will cause the event to be emitted immediately and all\n     *   handlers removed.\n     *\n     * - Adding an 'error' event handler after an error has been emitted will\n     *   cause the event to be re-emitted immediately with the error previously\n     *   raised.\n     */\n    on(ev, handler) {\n        const ret = super.on(ev, handler);\n        if (ev === 'data') {\n            this[DISCARDED] = false;\n            this[DATALISTENERS]++;\n            if (!this[PIPES].length && !this[FLOWING]) {\n                this[RESUME]();\n            }\n        }\n        else if (ev === 'readable' && this[BUFFERLENGTH] !== 0) {\n            super.emit('readable');\n        }\n        else if (isEndish(ev) && this[EMITTED_END]) {\n            super.emit(ev);\n            this.removeAllListeners(ev);\n        }\n        else if (ev === 'error' && this[EMITTED_ERROR]) {\n            const h = handler;\n            if (this[ASYNC])\n                defer(() => h.call(this, this[EMITTED_ERROR]));\n            else\n                h.call(this, this[EMITTED_ERROR]);\n        }\n        return ret;\n    }\n    /**\n     * Alias for {@link Minipass#off}\n     */\n    removeListener(ev, handler) {\n        return this.off(ev, handler);\n    }\n    /**\n     * Mostly identical to `EventEmitter.off`\n     *\n     * If a 'data' event handler is removed, and it was the last consumer\n     * (ie, there are no pipe destinations or other 'data' event listeners),\n     * then the flow of data will stop until there is another consumer or\n     * {@link Minipass#resume} is explicitly called.\n     */\n    off(ev, handler) {\n        const ret = super.off(ev, handler);\n        // if we previously had listeners, and now we don't, and we don't\n        // have any pipes, then stop the flow, unless it's been explicitly\n        // put in a discarded flowing state via stream.resume().\n        if (ev === 'data') {\n            this[DATALISTENERS] = this.listeners('data').length;\n            if (this[DATALISTENERS] === 0 &&\n                !this[DISCARDED] &&\n                !this[PIPES].length) {\n                this[FLOWING] = false;\n            }\n        }\n        return ret;\n    }\n    /**\n     * Mostly identical to `EventEmitter.removeAllListeners`\n     *\n     * If all 'data' event handlers are removed, and they were the last consumer\n     * (ie, there are no pipe destinations), then the flow of data will stop\n     * until there is another consumer or {@link Minipass#resume} is explicitly\n     * called.\n     */\n    removeAllListeners(ev) {\n        const ret = super.removeAllListeners(ev);\n        if (ev === 'data' || ev === undefined) {\n            this[DATALISTENERS] = 0;\n            if (!this[DISCARDED] && !this[PIPES].length) {\n                this[FLOWING] = false;\n            }\n        }\n        return ret;\n    }\n    /**\n     * true if the 'end' event has been emitted\n     */\n    get emittedEnd() {\n        return this[EMITTED_END];\n    }\n    [MAYBE_EMIT_END]() {\n        if (!this[EMITTING_END] &&\n            !this[EMITTED_END] &&\n            !this[DESTROYED] &&\n            this[BUFFER].length === 0 &&\n            this[EOF]) {\n            this[EMITTING_END] = true;\n            this.emit('end');\n            this.emit('prefinish');\n            this.emit('finish');\n            if (this[CLOSED])\n                this.emit('close');\n            this[EMITTING_END] = false;\n        }\n    }\n    /**\n     * Mostly identical to `EventEmitter.emit`, with the following\n     * behavior differences to prevent data loss and unnecessary hangs:\n     *\n     * If the stream has been destroyed, and the event is something other\n     * than 'close' or 'error', then `false` is returned and no handlers\n     * are called.\n     *\n     * If the event is 'end', and has already been emitted, then the event\n     * is ignored. If the stream is in a paused or non-flowing state, then\n     * the event will be deferred until data flow resumes. If the stream is\n     * async, then handlers will be called on the next tick rather than\n     * immediately.\n     *\n     * If the event is 'close', and 'end' has not yet been emitted, then\n     * the event will be deferred until after 'end' is emitted.\n     *\n     * If the event is 'error', and an AbortSignal was provided for the stream,\n     * and there are no listeners, then the event is ignored, matching the\n     * behavior of node core streams in the presense of an AbortSignal.\n     *\n     * If the event is 'finish' or 'prefinish', then all listeners will be\n     * removed after emitting the event, to prevent double-firing.\n     */\n    emit(ev, ...args) {\n        const data = args[0];\n        // error and close are only events allowed after calling destroy()\n        if (ev !== 'error' &&\n            ev !== 'close' &&\n            ev !== DESTROYED &&\n            this[DESTROYED]) {\n            return false;\n        }\n        else if (ev === 'data') {\n            return !this[OBJECTMODE] && !data\n                ? false\n                : this[ASYNC]\n                    ? (defer(() => this[EMITDATA](data)), true)\n                    : this[EMITDATA](data);\n        }\n        else if (ev === 'end') {\n            return this[EMITEND]();\n        }\n        else if (ev === 'close') {\n            this[CLOSED] = true;\n            // don't emit close before 'end' and 'finish'\n            if (!this[EMITTED_END] && !this[DESTROYED])\n                return false;\n            const ret = super.emit('close');\n            this.removeAllListeners('close');\n            return ret;\n        }\n        else if (ev === 'error') {\n            this[EMITTED_ERROR] = data;\n            super.emit(ERROR, data);\n            const ret = !this[SIGNAL] || this.listeners('error').length\n                ? super.emit('error', data)\n                : false;\n            this[MAYBE_EMIT_END]();\n            return ret;\n        }\n        else if (ev === 'resume') {\n            const ret = super.emit('resume');\n            this[MAYBE_EMIT_END]();\n            return ret;\n        }\n        else if (ev === 'finish' || ev === 'prefinish') {\n            const ret = super.emit(ev);\n            this.removeAllListeners(ev);\n            return ret;\n        }\n        // Some other unknown event\n        const ret = super.emit(ev, ...args);\n        this[MAYBE_EMIT_END]();\n        return ret;\n    }\n    [EMITDATA](data) {\n        for (const p of this[PIPES]) {\n            if (p.dest.write(data) === false)\n                this.pause();\n        }\n        const ret = this[DISCARDED] ? false : super.emit('data', data);\n        this[MAYBE_EMIT_END]();\n        return ret;\n    }\n    [EMITEND]() {\n        if (this[EMITTED_END])\n            return false;\n        this[EMITTED_END] = true;\n        this.readable = false;\n        return this[ASYNC]\n            ? (defer(() => this[EMITEND2]()), true)\n            : this[EMITEND2]();\n    }\n    [EMITEND2]() {\n        if (this[DECODER]) {\n            const data = this[DECODER].end();\n            if (data) {\n                for (const p of this[PIPES]) {\n                    p.dest.write(data);\n                }\n                if (!this[DISCARDED])\n                    super.emit('data', data);\n            }\n        }\n        for (const p of this[PIPES]) {\n            p.end();\n        }\n        const ret = super.emit('end');\n        this.removeAllListeners('end');\n        return ret;\n    }\n    /**\n     * Return a Promise that resolves to an array of all emitted data once\n     * the stream ends.\n     */\n    async collect() {\n        const buf = Object.assign([], {\n            dataLength: 0,\n        });\n        if (!this[OBJECTMODE])\n            buf.dataLength = 0;\n        // set the promise first, in case an error is raised\n        // by triggering the flow here.\n        const p = this.promise();\n        this.on('data', c => {\n            buf.push(c);\n            if (!this[OBJECTMODE])\n                buf.dataLength += c.length;\n        });\n        await p;\n        return buf;\n    }\n    /**\n     * Return a Promise that resolves to the concatenation of all emitted data\n     * once the stream ends.\n     *\n     * Not allowed on objectMode streams.\n     */\n    async concat() {\n        if (this[OBJECTMODE]) {\n            throw new Error('cannot concat in objectMode');\n        }\n        const buf = await this.collect();\n        return (this[ENCODING]\n            ? buf.join('')\n            : Buffer.concat(buf, buf.dataLength));\n    }\n    /**\n     * Return a void Promise that resolves once the stream ends.\n     */\n    async promise() {\n        return new Promise((resolve, reject) => {\n            this.on(DESTROYED, () => reject(new Error('stream destroyed')));\n            this.on('error', er => reject(er));\n            this.on('end', () => resolve());\n        });\n    }\n    /**\n     * Asynchronous `for await of` iteration.\n     *\n     * This will continue emitting all chunks until the stream terminates.\n     */\n    [Symbol.asyncIterator]() {\n        // set this up front, in case the consumer doesn't call next()\n        // right away.\n        this[DISCARDED] = false;\n        let stopped = false;\n        const stop = async () => {\n            this.pause();\n            stopped = true;\n            return { value: undefined, done: true };\n        };\n        const next = () => {\n            if (stopped)\n                return stop();\n            const res = this.read();\n            if (res !== null)\n                return Promise.resolve({ done: false, value: res });\n            if (this[EOF])\n                return stop();\n            let resolve;\n            let reject;\n            const onerr = (er) => {\n                this.off('data', ondata);\n                this.off('end', onend);\n                this.off(DESTROYED, ondestroy);\n                stop();\n                reject(er);\n            };\n            const ondata = (value) => {\n                this.off('error', onerr);\n                this.off('end', onend);\n                this.off(DESTROYED, ondestroy);\n                this.pause();\n                resolve({ value, done: !!this[EOF] });\n            };\n            const onend = () => {\n                this.off('error', onerr);\n                this.off('data', ondata);\n                this.off(DESTROYED, ondestroy);\n                stop();\n                resolve({ done: true, value: undefined });\n            };\n            const ondestroy = () => onerr(new Error('stream destroyed'));\n            return new Promise((res, rej) => {\n                reject = rej;\n                resolve = res;\n                this.once(DESTROYED, ondestroy);\n                this.once('error', onerr);\n                this.once('end', onend);\n                this.once('data', ondata);\n            });\n        };\n        return {\n            next,\n            throw: stop,\n            return: stop,\n            [Symbol.asyncIterator]() {\n                return this;\n            },\n        };\n    }\n    /**\n     * Synchronous `for of` iteration.\n     *\n     * The iteration will terminate when the internal buffer runs out, even\n     * if the stream has not yet terminated.\n     */\n    [Symbol.iterator]() {\n        // set this up front, in case the consumer doesn't call next()\n        // right away.\n        this[DISCARDED] = false;\n        let stopped = false;\n        const stop = () => {\n            this.pause();\n            this.off(ERROR, stop);\n            this.off(DESTROYED, stop);\n            this.off('end', stop);\n            stopped = true;\n            return { done: true, value: undefined };\n        };\n        const next = () => {\n            if (stopped)\n                return stop();\n            const value = this.read();\n            return value === null ? stop() : { done: false, value };\n        };\n        this.once('end', stop);\n        this.once(ERROR, stop);\n        this.once(DESTROYED, stop);\n        return {\n            next,\n            throw: stop,\n            return: stop,\n            [Symbol.iterator]() {\n                return this;\n            },\n        };\n    }\n    /**\n     * Destroy a stream, preventing it from being used for any further purpose.\n     *\n     * If the stream has a `close()` method, then it will be called on\n     * destruction.\n     *\n     * After destruction, any attempt to write data, read data, or emit most\n     * events will be ignored.\n     *\n     * If an error argument is provided, then it will be emitted in an\n     * 'error' event.\n     */\n    destroy(er) {\n        if (this[DESTROYED]) {\n            if (er)\n                this.emit('error', er);\n            else\n                this.emit(DESTROYED);\n            return this;\n        }\n        this[DESTROYED] = true;\n        this[DISCARDED] = true;\n        // throw away all buffered data, it's never coming out\n        this[BUFFER].length = 0;\n        this[BUFFERLENGTH] = 0;\n        const wc = this;\n        if (typeof wc.close === 'function' && !this[CLOSED])\n            wc.close();\n        if (er)\n            this.emit('error', er);\n        // if no error to emit, still reject pending promises\n        else\n            this.emit(DESTROYED);\n        return this;\n    }\n    /**\n     * Alias for {@link isStream}\n     *\n     * Former export location, maintained for backwards compatibility.\n     *\n     * @deprecated\n     */\n    static get isStream() {\n        return exports.isStream;\n    }\n}\nexports.Minipass = Minipass;\n//# sourceMappingURL=index.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.PathScurry = exports.Path = exports.PathScurryDarwin = exports.PathScurryPosix = exports.PathScurryWin32 = exports.PathScurryBase = exports.PathPosix = exports.PathWin32 = exports.PathBase = exports.ChildrenCache = exports.ResolveCache = void 0;\nconst lru_cache_1 = require(\"lru-cache\");\nconst node_path_1 = require(\"node:path\");\nconst node_url_1 = require(\"node:url\");\nconst fs_1 = require(\"fs\");\nconst actualFS = __importStar(require(\"node:fs\"));\nconst realpathSync = fs_1.realpathSync.native;\n// TODO: test perf of fs/promises realpath vs realpathCB,\n// since the promises one uses realpath.native\nconst promises_1 = require(\"node:fs/promises\");\nconst minipass_1 = require(\"minipass\");\nconst defaultFS = {\n    lstatSync: fs_1.lstatSync,\n    readdir: fs_1.readdir,\n    readdirSync: fs_1.readdirSync,\n    readlinkSync: fs_1.readlinkSync,\n    realpathSync,\n    promises: {\n        lstat: promises_1.lstat,\n        readdir: promises_1.readdir,\n        readlink: promises_1.readlink,\n        realpath: promises_1.realpath,\n    },\n};\n// if they just gave us require('fs') then use our default\nconst fsFromOption = (fsOption) => !fsOption || fsOption === defaultFS || fsOption === actualFS ?\n    defaultFS\n    : {\n        ...defaultFS,\n        ...fsOption,\n        promises: {\n            ...defaultFS.promises,\n            ...(fsOption.promises || {}),\n        },\n    };\n// turn something like //?/c:/ into c:\\\nconst uncDriveRegexp = /^\\\\\\\\\\?\\\\([a-z]:)\\\\?$/i;\nconst uncToDrive = (rootPath) => rootPath.replace(/\\//g, '\\\\').replace(uncDriveRegexp, '$1\\\\');\n// windows paths are separated by either / or \\\nconst eitherSep = /[\\\\\\/]/;\nconst UNKNOWN = 0; // may not even exist, for all we know\nconst IFIFO = 0b0001;\nconst IFCHR = 0b0010;\nconst IFDIR = 0b0100;\nconst IFBLK = 0b0110;\nconst IFREG = 0b1000;\nconst IFLNK = 0b1010;\nconst IFSOCK = 0b1100;\nconst IFMT = 0b1111;\n// mask to unset low 4 bits\nconst IFMT_UNKNOWN = ~IFMT;\n// set after successfully calling readdir() and getting entries.\nconst READDIR_CALLED = 0b0000_0001_0000;\n// set after a successful lstat()\nconst LSTAT_CALLED = 0b0000_0010_0000;\n// set if an entry (or one of its parents) is definitely not a dir\nconst ENOTDIR = 0b0000_0100_0000;\n// set if an entry (or one of its parents) does not exist\n// (can also be set on lstat errors like EACCES or ENAMETOOLONG)\nconst ENOENT = 0b0000_1000_0000;\n// cannot have child entries -- also verify &IFMT is either IFDIR or IFLNK\n// set if we fail to readlink\nconst ENOREADLINK = 0b0001_0000_0000;\n// set if we know realpath() will fail\nconst ENOREALPATH = 0b0010_0000_0000;\nconst ENOCHILD = ENOTDIR | ENOENT | ENOREALPATH;\nconst TYPEMASK = 0b0011_1111_1111;\nconst entToType = (s) => s.isFile() ? IFREG\n    : s.isDirectory() ? IFDIR\n        : s.isSymbolicLink() ? IFLNK\n            : s.isCharacterDevice() ? IFCHR\n                : s.isBlockDevice() ? IFBLK\n                    : s.isSocket() ? IFSOCK\n                        : s.isFIFO() ? IFIFO\n                            : UNKNOWN;\n// normalize unicode path names\nconst normalizeCache = new Map();\nconst normalize = (s) => {\n    const c = normalizeCache.get(s);\n    if (c)\n        return c;\n    const n = s.normalize('NFKD');\n    normalizeCache.set(s, n);\n    return n;\n};\nconst normalizeNocaseCache = new Map();\nconst normalizeNocase = (s) => {\n    const c = normalizeNocaseCache.get(s);\n    if (c)\n        return c;\n    const n = normalize(s.toLowerCase());\n    normalizeNocaseCache.set(s, n);\n    return n;\n};\n/**\n * An LRUCache for storing resolved path strings or Path objects.\n * @internal\n */\nclass ResolveCache extends lru_cache_1.LRUCache {\n    constructor() {\n        super({ max: 256 });\n    }\n}\nexports.ResolveCache = ResolveCache;\n// In order to prevent blowing out the js heap by allocating hundreds of\n// thousands of Path entries when walking extremely large trees, the \"children\"\n// in this tree are represented by storing an array of Path entries in an\n// LRUCache, indexed by the parent.  At any time, Path.children() may return an\n// empty array, indicating that it doesn't know about any of its children, and\n// thus has to rebuild that cache.  This is fine, it just means that we don't\n// benefit as much from having the cached entries, but huge directory walks\n// don't blow out the stack, and smaller ones are still as fast as possible.\n//\n//It does impose some complexity when building up the readdir data, because we\n//need to pass a reference to the children array that we started with.\n/**\n * an LRUCache for storing child entries.\n * @internal\n */\nclass ChildrenCache extends lru_cache_1.LRUCache {\n    constructor(maxSize = 16 * 1024) {\n        super({\n            maxSize,\n            // parent + children\n            sizeCalculation: a => a.length + 1,\n        });\n    }\n}\nexports.ChildrenCache = ChildrenCache;\nconst setAsCwd = Symbol('PathScurry setAsCwd');\n/**\n * Path objects are sort of like a super-powered\n * {@link https://nodejs.org/docs/latest/api/fs.html#class-fsdirent fs.Dirent}\n *\n * Each one represents a single filesystem entry on disk, which may or may not\n * exist. It includes methods for reading various types of information via\n * lstat, readlink, and readdir, and caches all information to the greatest\n * degree possible.\n *\n * Note that fs operations that would normally throw will instead return an\n * \"empty\" value. This is in order to prevent excessive overhead from error\n * stack traces.\n */\nclass PathBase {\n    /**\n     * the basename of this path\n     *\n     * **Important**: *always* test the path name against any test string\n     * usingthe {@link isNamed} method, and not by directly comparing this\n     * string. Otherwise, unicode path strings that the system sees as identical\n     * will not be properly treated as the same path, leading to incorrect\n     * behavior and possible security issues.\n     */\n    name;\n    /**\n     * the Path entry corresponding to the path root.\n     *\n     * @internal\n     */\n    root;\n    /**\n     * All roots found within the current PathScurry family\n     *\n     * @internal\n     */\n    roots;\n    /**\n     * a reference to the parent path, or undefined in the case of root entries\n     *\n     * @internal\n     */\n    parent;\n    /**\n     * boolean indicating whether paths are compared case-insensitively\n     * @internal\n     */\n    nocase;\n    /**\n     * boolean indicating that this path is the current working directory\n     * of the PathScurry collection that contains it.\n     */\n    isCWD = false;\n    // potential default fs override\n    #fs;\n    // Stats fields\n    #dev;\n    get dev() {\n        return this.#dev;\n    }\n    #mode;\n    get mode() {\n        return this.#mode;\n    }\n    #nlink;\n    get nlink() {\n        return this.#nlink;\n    }\n    #uid;\n    get uid() {\n        return this.#uid;\n    }\n    #gid;\n    get gid() {\n        return this.#gid;\n    }\n    #rdev;\n    get rdev() {\n        return this.#rdev;\n    }\n    #blksize;\n    get blksize() {\n        return this.#blksize;\n    }\n    #ino;\n    get ino() {\n        return this.#ino;\n    }\n    #size;\n    get size() {\n        return this.#size;\n    }\n    #blocks;\n    get blocks() {\n        return this.#blocks;\n    }\n    #atimeMs;\n    get atimeMs() {\n        return this.#atimeMs;\n    }\n    #mtimeMs;\n    get mtimeMs() {\n        return this.#mtimeMs;\n    }\n    #ctimeMs;\n    get ctimeMs() {\n        return this.#ctimeMs;\n    }\n    #birthtimeMs;\n    get birthtimeMs() {\n        return this.#birthtimeMs;\n    }\n    #atime;\n    get atime() {\n        return this.#atime;\n    }\n    #mtime;\n    get mtime() {\n        return this.#mtime;\n    }\n    #ctime;\n    get ctime() {\n        return this.#ctime;\n    }\n    #birthtime;\n    get birthtime() {\n        return this.#birthtime;\n    }\n    #matchName;\n    #depth;\n    #fullpath;\n    #fullpathPosix;\n    #relative;\n    #relativePosix;\n    #type;\n    #children;\n    #linkTarget;\n    #realpath;\n    /**\n     * This property is for compatibility with the Dirent class as of\n     * Node v20, where Dirent['parentPath'] refers to the path of the\n     * directory that was passed to readdir. For root entries, it's the path\n     * to the entry itself.\n     */\n    get parentPath() {\n        return (this.parent || this).fullpath();\n    }\n    /**\n     * Deprecated alias for Dirent['parentPath'] Somewhat counterintuitively,\n     * this property refers to the *parent* path, not the path object itself.\n     */\n    get path() {\n        return this.parentPath;\n    }\n    /**\n     * Do not create new Path objects directly.  They should always be accessed\n     * via the PathScurry class or other methods on the Path class.\n     *\n     * @internal\n     */\n    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {\n        this.name = name;\n        this.#matchName = nocase ? normalizeNocase(name) : normalize(name);\n        this.#type = type & TYPEMASK;\n        this.nocase = nocase;\n        this.roots = roots;\n        this.root = root || this;\n        this.#children = children;\n        this.#fullpath = opts.fullpath;\n        this.#relative = opts.relative;\n        this.#relativePosix = opts.relativePosix;\n        this.parent = opts.parent;\n        if (this.parent) {\n            this.#fs = this.parent.#fs;\n        }\n        else {\n            this.#fs = fsFromOption(opts.fs);\n        }\n    }\n    /**\n     * Returns the depth of the Path object from its root.\n     *\n     * For example, a path at `/foo/bar` would have a depth of 2.\n     */\n    depth() {\n        if (this.#depth !== undefined)\n            return this.#depth;\n        if (!this.parent)\n            return (this.#depth = 0);\n        return (this.#depth = this.parent.depth() + 1);\n    }\n    /**\n     * @internal\n     */\n    childrenCache() {\n        return this.#children;\n    }\n    /**\n     * Get the Path object referenced by the string path, resolved from this Path\n     */\n    resolve(path) {\n        if (!path) {\n            return this;\n        }\n        const rootPath = this.getRootString(path);\n        const dir = path.substring(rootPath.length);\n        const dirParts = dir.split(this.splitSep);\n        const result = rootPath ?\n            this.getRoot(rootPath).#resolveParts(dirParts)\n            : this.#resolveParts(dirParts);\n        return result;\n    }\n    #resolveParts(dirParts) {\n        let p = this;\n        for (const part of dirParts) {\n            p = p.child(part);\n        }\n        return p;\n    }\n    /**\n     * Returns the cached children Path objects, if still available.  If they\n     * have fallen out of the cache, then returns an empty array, and resets the\n     * READDIR_CALLED bit, so that future calls to readdir() will require an fs\n     * lookup.\n     *\n     * @internal\n     */\n    children() {\n        const cached = this.#children.get(this);\n        if (cached) {\n            return cached;\n        }\n        const children = Object.assign([], { provisional: 0 });\n        this.#children.set(this, children);\n        this.#type &= ~READDIR_CALLED;\n        return children;\n    }\n    /**\n     * Resolves a path portion and returns or creates the child Path.\n     *\n     * Returns `this` if pathPart is `''` or `'.'`, or `parent` if pathPart is\n     * `'..'`.\n     *\n     * This should not be called directly.  If `pathPart` contains any path\n     * separators, it will lead to unsafe undefined behavior.\n     *\n     * Use `Path.resolve()` instead.\n     *\n     * @internal\n     */\n    child(pathPart, opts) {\n        if (pathPart === '' || pathPart === '.') {\n            return this;\n        }\n        if (pathPart === '..') {\n            return this.parent || this;\n        }\n        // find the child\n        const children = this.children();\n        const name = this.nocase ? normalizeNocase(pathPart) : normalize(pathPart);\n        for (const p of children) {\n            if (p.#matchName === name) {\n                return p;\n            }\n        }\n        // didn't find it, create provisional child, since it might not\n        // actually exist.  If we know the parent isn't a dir, then\n        // in fact it CAN'T exist.\n        const s = this.parent ? this.sep : '';\n        const fullpath = this.#fullpath ? this.#fullpath + s + pathPart : undefined;\n        const pchild = this.newChild(pathPart, UNKNOWN, {\n            ...opts,\n            parent: this,\n            fullpath,\n        });\n        if (!this.canReaddir()) {\n            pchild.#type |= ENOENT;\n        }\n        // don't have to update provisional, because if we have real children,\n        // then provisional is set to children.length, otherwise a lower number\n        children.push(pchild);\n        return pchild;\n    }\n    /**\n     * The relative path from the cwd. If it does not share an ancestor with\n     * the cwd, then this ends up being equivalent to the fullpath()\n     */\n    relative() {\n        if (this.isCWD)\n            return '';\n        if (this.#relative !== undefined) {\n            return this.#relative;\n        }\n        const name = this.name;\n        const p = this.parent;\n        if (!p) {\n            return (this.#relative = this.name);\n        }\n        const pv = p.relative();\n        return pv + (!pv || !p.parent ? '' : this.sep) + name;\n    }\n    /**\n     * The relative path from the cwd, using / as the path separator.\n     * If it does not share an ancestor with\n     * the cwd, then this ends up being equivalent to the fullpathPosix()\n     * On posix systems, this is identical to relative().\n     */\n    relativePosix() {\n        if (this.sep === '/')\n            return this.relative();\n        if (this.isCWD)\n            return '';\n        if (this.#relativePosix !== undefined)\n            return this.#relativePosix;\n        const name = this.name;\n        const p = this.parent;\n        if (!p) {\n            return (this.#relativePosix = this.fullpathPosix());\n        }\n        const pv = p.relativePosix();\n        return pv + (!pv || !p.parent ? '' : '/') + name;\n    }\n    /**\n     * The fully resolved path string for this Path entry\n     */\n    fullpath() {\n        if (this.#fullpath !== undefined) {\n            return this.#fullpath;\n        }\n        const name = this.name;\n        const p = this.parent;\n        if (!p) {\n            return (this.#fullpath = this.name);\n        }\n        const pv = p.fullpath();\n        const fp = pv + (!p.parent ? '' : this.sep) + name;\n        return (this.#fullpath = fp);\n    }\n    /**\n     * On platforms other than windows, this is identical to fullpath.\n     *\n     * On windows, this is overridden to return the forward-slash form of the\n     * full UNC path.\n     */\n    fullpathPosix() {\n        if (this.#fullpathPosix !== undefined)\n            return this.#fullpathPosix;\n        if (this.sep === '/')\n            return (this.#fullpathPosix = this.fullpath());\n        if (!this.parent) {\n            const p = this.fullpath().replace(/\\\\/g, '/');\n            if (/^[a-z]:\\//i.test(p)) {\n                return (this.#fullpathPosix = `//?/${p}`);\n            }\n            else {\n                return (this.#fullpathPosix = p);\n            }\n        }\n        const p = this.parent;\n        const pfpp = p.fullpathPosix();\n        const fpp = pfpp + (!pfpp || !p.parent ? '' : '/') + this.name;\n        return (this.#fullpathPosix = fpp);\n    }\n    /**\n     * Is the Path of an unknown type?\n     *\n     * Note that we might know *something* about it if there has been a previous\n     * filesystem operation, for example that it does not exist, or is not a\n     * link, or whether it has child entries.\n     */\n    isUnknown() {\n        return (this.#type & IFMT) === UNKNOWN;\n    }\n    isType(type) {\n        return this[`is${type}`]();\n    }\n    getType() {\n        return (this.isUnknown() ? 'Unknown'\n            : this.isDirectory() ? 'Directory'\n                : this.isFile() ? 'File'\n                    : this.isSymbolicLink() ? 'SymbolicLink'\n                        : this.isFIFO() ? 'FIFO'\n                            : this.isCharacterDevice() ? 'CharacterDevice'\n                                : this.isBlockDevice() ? 'BlockDevice'\n                                    : /* c8 ignore start */ this.isSocket() ? 'Socket'\n                                        : 'Unknown');\n        /* c8 ignore stop */\n    }\n    /**\n     * Is the Path a regular file?\n     */\n    isFile() {\n        return (this.#type & IFMT) === IFREG;\n    }\n    /**\n     * Is the Path a directory?\n     */\n    isDirectory() {\n        return (this.#type & IFMT) === IFDIR;\n    }\n    /**\n     * Is the path a character device?\n     */\n    isCharacterDevice() {\n        return (this.#type & IFMT) === IFCHR;\n    }\n    /**\n     * Is the path a block device?\n     */\n    isBlockDevice() {\n        return (this.#type & IFMT) === IFBLK;\n    }\n    /**\n     * Is the path a FIFO pipe?\n     */\n    isFIFO() {\n        return (this.#type & IFMT) === IFIFO;\n    }\n    /**\n     * Is the path a socket?\n     */\n    isSocket() {\n        return (this.#type & IFMT) === IFSOCK;\n    }\n    /**\n     * Is the path a symbolic link?\n     */\n    isSymbolicLink() {\n        return (this.#type & IFLNK) === IFLNK;\n    }\n    /**\n     * Return the entry if it has been subject of a successful lstat, or\n     * undefined otherwise.\n     *\n     * Does not read the filesystem, so an undefined result *could* simply\n     * mean that we haven't called lstat on it.\n     */\n    lstatCached() {\n        return this.#type & LSTAT_CALLED ? this : undefined;\n    }\n    /**\n     * Return the cached link target if the entry has been the subject of a\n     * successful readlink, or undefined otherwise.\n     *\n     * Does not read the filesystem, so an undefined result *could* just mean we\n     * don't have any cached data. Only use it if you are very sure that a\n     * readlink() has been called at some point.\n     */\n    readlinkCached() {\n        return this.#linkTarget;\n    }\n    /**\n     * Returns the cached realpath target if the entry has been the subject\n     * of a successful realpath, or undefined otherwise.\n     *\n     * Does not read the filesystem, so an undefined result *could* just mean we\n     * don't have any cached data. Only use it if you are very sure that a\n     * realpath() has been called at some point.\n     */\n    realpathCached() {\n        return this.#realpath;\n    }\n    /**\n     * Returns the cached child Path entries array if the entry has been the\n     * subject of a successful readdir(), or [] otherwise.\n     *\n     * Does not read the filesystem, so an empty array *could* just mean we\n     * don't have any cached data. Only use it if you are very sure that a\n     * readdir() has been called recently enough to still be valid.\n     */\n    readdirCached() {\n        const children = this.children();\n        return children.slice(0, children.provisional);\n    }\n    /**\n     * Return true if it's worth trying to readlink.  Ie, we don't (yet) have\n     * any indication that readlink will definitely fail.\n     *\n     * Returns false if the path is known to not be a symlink, if a previous\n     * readlink failed, or if the entry does not exist.\n     */\n    canReadlink() {\n        if (this.#linkTarget)\n            return true;\n        if (!this.parent)\n            return false;\n        // cases where it cannot possibly succeed\n        const ifmt = this.#type & IFMT;\n        return !((ifmt !== UNKNOWN && ifmt !== IFLNK) ||\n            this.#type & ENOREADLINK ||\n            this.#type & ENOENT);\n    }\n    /**\n     * Return true if readdir has previously been successfully called on this\n     * path, indicating that cachedReaddir() is likely valid.\n     */\n    calledReaddir() {\n        return !!(this.#type & READDIR_CALLED);\n    }\n    /**\n     * Returns true if the path is known to not exist. That is, a previous lstat\n     * or readdir failed to verify its existence when that would have been\n     * expected, or a parent entry was marked either enoent or enotdir.\n     */\n    isENOENT() {\n        return !!(this.#type & ENOENT);\n    }\n    /**\n     * Return true if the path is a match for the given path name.  This handles\n     * case sensitivity and unicode normalization.\n     *\n     * Note: even on case-sensitive systems, it is **not** safe to test the\n     * equality of the `.name` property to determine whether a given pathname\n     * matches, due to unicode normalization mismatches.\n     *\n     * Always use this method instead of testing the `path.name` property\n     * directly.\n     */\n    isNamed(n) {\n        return !this.nocase ?\n            this.#matchName === normalize(n)\n            : this.#matchName === normalizeNocase(n);\n    }\n    /**\n     * Return the Path object corresponding to the target of a symbolic link.\n     *\n     * If the Path is not a symbolic link, or if the readlink call fails for any\n     * reason, `undefined` is returned.\n     *\n     * Result is cached, and thus may be outdated if the filesystem is mutated.\n     */\n    async readlink() {\n        const target = this.#linkTarget;\n        if (target) {\n            return target;\n        }\n        if (!this.canReadlink()) {\n            return undefined;\n        }\n        /* c8 ignore start */\n        // already covered by the canReadlink test, here for ts grumples\n        if (!this.parent) {\n            return undefined;\n        }\n        /* c8 ignore stop */\n        try {\n            const read = await this.#fs.promises.readlink(this.fullpath());\n            const linkTarget = (await this.parent.realpath())?.resolve(read);\n            if (linkTarget) {\n                return (this.#linkTarget = linkTarget);\n            }\n        }\n        catch (er) {\n            this.#readlinkFail(er.code);\n            return undefined;\n        }\n    }\n    /**\n     * Synchronous {@link PathBase.readlink}\n     */\n    readlinkSync() {\n        const target = this.#linkTarget;\n        if (target) {\n            return target;\n        }\n        if (!this.canReadlink()) {\n            return undefined;\n        }\n        /* c8 ignore start */\n        // already covered by the canReadlink test, here for ts grumples\n        if (!this.parent) {\n            return undefined;\n        }\n        /* c8 ignore stop */\n        try {\n            const read = this.#fs.readlinkSync(this.fullpath());\n            const linkTarget = this.parent.realpathSync()?.resolve(read);\n            if (linkTarget) {\n                return (this.#linkTarget = linkTarget);\n            }\n        }\n        catch (er) {\n            this.#readlinkFail(er.code);\n            return undefined;\n        }\n    }\n    #readdirSuccess(children) {\n        // succeeded, mark readdir called bit\n        this.#type |= READDIR_CALLED;\n        // mark all remaining provisional children as ENOENT\n        for (let p = children.provisional; p < children.length; p++) {\n            const c = children[p];\n            if (c)\n                c.#markENOENT();\n        }\n    }\n    #markENOENT() {\n        // mark as UNKNOWN and ENOENT\n        if (this.#type & ENOENT)\n            return;\n        this.#type = (this.#type | ENOENT) & IFMT_UNKNOWN;\n        this.#markChildrenENOENT();\n    }\n    #markChildrenENOENT() {\n        // all children are provisional and do not exist\n        const children = this.children();\n        children.provisional = 0;\n        for (const p of children) {\n            p.#markENOENT();\n        }\n    }\n    #markENOREALPATH() {\n        this.#type |= ENOREALPATH;\n        this.#markENOTDIR();\n    }\n    // save the information when we know the entry is not a dir\n    #markENOTDIR() {\n        // entry is not a directory, so any children can't exist.\n        // this *should* be impossible, since any children created\n        // after it's been marked ENOTDIR should be marked ENOENT,\n        // so it won't even get to this point.\n        /* c8 ignore start */\n        if (this.#type & ENOTDIR)\n            return;\n        /* c8 ignore stop */\n        let t = this.#type;\n        // this could happen if we stat a dir, then delete it,\n        // then try to read it or one of its children.\n        if ((t & IFMT) === IFDIR)\n            t &= IFMT_UNKNOWN;\n        this.#type = t | ENOTDIR;\n        this.#markChildrenENOENT();\n    }\n    #readdirFail(code = '') {\n        // markENOTDIR and markENOENT also set provisional=0\n        if (code === 'ENOTDIR' || code === 'EPERM') {\n            this.#markENOTDIR();\n        }\n        else if (code === 'ENOENT') {\n            this.#markENOENT();\n        }\n        else {\n            this.children().provisional = 0;\n        }\n    }\n    #lstatFail(code = '') {\n        // Windows just raises ENOENT in this case, disable for win CI\n        /* c8 ignore start */\n        if (code === 'ENOTDIR') {\n            // already know it has a parent by this point\n            const p = this.parent;\n            p.#markENOTDIR();\n        }\n        else if (code === 'ENOENT') {\n            /* c8 ignore stop */\n            this.#markENOENT();\n        }\n    }\n    #readlinkFail(code = '') {\n        let ter = this.#type;\n        ter |= ENOREADLINK;\n        if (code === 'ENOENT')\n            ter |= ENOENT;\n        // windows gets a weird error when you try to readlink a file\n        if (code === 'EINVAL' || code === 'UNKNOWN') {\n            // exists, but not a symlink, we don't know WHAT it is, so remove\n            // all IFMT bits.\n            ter &= IFMT_UNKNOWN;\n        }\n        this.#type = ter;\n        // windows just gets ENOENT in this case.  We do cover the case,\n        // just disabled because it's impossible on Windows CI\n        /* c8 ignore start */\n        if (code === 'ENOTDIR' && this.parent) {\n            this.parent.#markENOTDIR();\n        }\n        /* c8 ignore stop */\n    }\n    #readdirAddChild(e, c) {\n        return (this.#readdirMaybePromoteChild(e, c) ||\n            this.#readdirAddNewChild(e, c));\n    }\n    #readdirAddNewChild(e, c) {\n        // alloc new entry at head, so it's never provisional\n        const type = entToType(e);\n        const child = this.newChild(e.name, type, { parent: this });\n        const ifmt = child.#type & IFMT;\n        if (ifmt !== IFDIR && ifmt !== IFLNK && ifmt !== UNKNOWN) {\n            child.#type |= ENOTDIR;\n        }\n        c.unshift(child);\n        c.provisional++;\n        return child;\n    }\n    #readdirMaybePromoteChild(e, c) {\n        for (let p = c.provisional; p < c.length; p++) {\n            const pchild = c[p];\n            const name = this.nocase ? normalizeNocase(e.name) : normalize(e.name);\n            if (name !== pchild.#matchName) {\n                continue;\n            }\n            return this.#readdirPromoteChild(e, pchild, p, c);\n        }\n    }\n    #readdirPromoteChild(e, p, index, c) {\n        const v = p.name;\n        // retain any other flags, but set ifmt from dirent\n        p.#type = (p.#type & IFMT_UNKNOWN) | entToType(e);\n        // case sensitivity fixing when we learn the true name.\n        if (v !== e.name)\n            p.name = e.name;\n        // just advance provisional index (potentially off the list),\n        // otherwise we have to splice/pop it out and re-insert at head\n        if (index !== c.provisional) {\n            if (index === c.length - 1)\n                c.pop();\n            else\n                c.splice(index, 1);\n            c.unshift(p);\n        }\n        c.provisional++;\n        return p;\n    }\n    /**\n     * Call lstat() on this Path, and update all known information that can be\n     * determined.\n     *\n     * Note that unlike `fs.lstat()`, the returned value does not contain some\n     * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that\n     * information is required, you will need to call `fs.lstat` yourself.\n     *\n     * If the Path refers to a nonexistent file, or if the lstat call fails for\n     * any reason, `undefined` is returned.  Otherwise the updated Path object is\n     * returned.\n     *\n     * Results are cached, and thus may be out of date if the filesystem is\n     * mutated.\n     */\n    async lstat() {\n        if ((this.#type & ENOENT) === 0) {\n            try {\n                this.#applyStat(await this.#fs.promises.lstat(this.fullpath()));\n                return this;\n            }\n            catch (er) {\n                this.#lstatFail(er.code);\n            }\n        }\n    }\n    /**\n     * synchronous {@link PathBase.lstat}\n     */\n    lstatSync() {\n        if ((this.#type & ENOENT) === 0) {\n            try {\n                this.#applyStat(this.#fs.lstatSync(this.fullpath()));\n                return this;\n            }\n            catch (er) {\n                this.#lstatFail(er.code);\n            }\n        }\n    }\n    #applyStat(st) {\n        const { atime, atimeMs, birthtime, birthtimeMs, blksize, blocks, ctime, ctimeMs, dev, gid, ino, mode, mtime, mtimeMs, nlink, rdev, size, uid, } = st;\n        this.#atime = atime;\n        this.#atimeMs = atimeMs;\n        this.#birthtime = birthtime;\n        this.#birthtimeMs = birthtimeMs;\n        this.#blksize = blksize;\n        this.#blocks = blocks;\n        this.#ctime = ctime;\n        this.#ctimeMs = ctimeMs;\n        this.#dev = dev;\n        this.#gid = gid;\n        this.#ino = ino;\n        this.#mode = mode;\n        this.#mtime = mtime;\n        this.#mtimeMs = mtimeMs;\n        this.#nlink = nlink;\n        this.#rdev = rdev;\n        this.#size = size;\n        this.#uid = uid;\n        const ifmt = entToType(st);\n        // retain any other flags, but set the ifmt\n        this.#type = (this.#type & IFMT_UNKNOWN) | ifmt | LSTAT_CALLED;\n        if (ifmt !== UNKNOWN && ifmt !== IFDIR && ifmt !== IFLNK) {\n            this.#type |= ENOTDIR;\n        }\n    }\n    #onReaddirCB = [];\n    #readdirCBInFlight = false;\n    #callOnReaddirCB(children) {\n        this.#readdirCBInFlight = false;\n        const cbs = this.#onReaddirCB.slice();\n        this.#onReaddirCB.length = 0;\n        cbs.forEach(cb => cb(null, children));\n    }\n    /**\n     * Standard node-style callback interface to get list of directory entries.\n     *\n     * If the Path cannot or does not contain any children, then an empty array\n     * is returned.\n     *\n     * Results are cached, and thus may be out of date if the filesystem is\n     * mutated.\n     *\n     * @param cb The callback called with (er, entries).  Note that the `er`\n     * param is somewhat extraneous, as all readdir() errors are handled and\n     * simply result in an empty set of entries being returned.\n     * @param allowZalgo Boolean indicating that immediately known results should\n     * *not* be deferred with `queueMicrotask`. Defaults to `false`. Release\n     * zalgo at your peril, the dark pony lord is devious and unforgiving.\n     */\n    readdirCB(cb, allowZalgo = false) {\n        if (!this.canReaddir()) {\n            if (allowZalgo)\n                cb(null, []);\n            else\n                queueMicrotask(() => cb(null, []));\n            return;\n        }\n        const children = this.children();\n        if (this.calledReaddir()) {\n            const c = children.slice(0, children.provisional);\n            if (allowZalgo)\n                cb(null, c);\n            else\n                queueMicrotask(() => cb(null, c));\n            return;\n        }\n        // don't have to worry about zalgo at this point.\n        this.#onReaddirCB.push(cb);\n        if (this.#readdirCBInFlight) {\n            return;\n        }\n        this.#readdirCBInFlight = true;\n        // else read the directory, fill up children\n        // de-provisionalize any provisional children.\n        const fullpath = this.fullpath();\n        this.#fs.readdir(fullpath, { withFileTypes: true }, (er, entries) => {\n            if (er) {\n                this.#readdirFail(er.code);\n                children.provisional = 0;\n            }\n            else {\n                // if we didn't get an error, we always get entries.\n                //@ts-ignore\n                for (const e of entries) {\n                    this.#readdirAddChild(e, children);\n                }\n                this.#readdirSuccess(children);\n            }\n            this.#callOnReaddirCB(children.slice(0, children.provisional));\n            return;\n        });\n    }\n    #asyncReaddirInFlight;\n    /**\n     * Return an array of known child entries.\n     *\n     * If the Path cannot or does not contain any children, then an empty array\n     * is returned.\n     *\n     * Results are cached, and thus may be out of date if the filesystem is\n     * mutated.\n     */\n    async readdir() {\n        if (!this.canReaddir()) {\n            return [];\n        }\n        const children = this.children();\n        if (this.calledReaddir()) {\n            return children.slice(0, children.provisional);\n        }\n        // else read the directory, fill up children\n        // de-provisionalize any provisional children.\n        const fullpath = this.fullpath();\n        if (this.#asyncReaddirInFlight) {\n            await this.#asyncReaddirInFlight;\n        }\n        else {\n            /* c8 ignore start */\n            let resolve = () => { };\n            /* c8 ignore stop */\n            this.#asyncReaddirInFlight = new Promise(res => (resolve = res));\n            try {\n                for (const e of await this.#fs.promises.readdir(fullpath, {\n                    withFileTypes: true,\n                })) {\n                    this.#readdirAddChild(e, children);\n                }\n                this.#readdirSuccess(children);\n            }\n            catch (er) {\n                this.#readdirFail(er.code);\n                children.provisional = 0;\n            }\n            this.#asyncReaddirInFlight = undefined;\n            resolve();\n        }\n        return children.slice(0, children.provisional);\n    }\n    /**\n     * synchronous {@link PathBase.readdir}\n     */\n    readdirSync() {\n        if (!this.canReaddir()) {\n            return [];\n        }\n        const children = this.children();\n        if (this.calledReaddir()) {\n            return children.slice(0, children.provisional);\n        }\n        // else read the directory, fill up children\n        // de-provisionalize any provisional children.\n        const fullpath = this.fullpath();\n        try {\n            for (const e of this.#fs.readdirSync(fullpath, {\n                withFileTypes: true,\n            })) {\n                this.#readdirAddChild(e, children);\n            }\n            this.#readdirSuccess(children);\n        }\n        catch (er) {\n            this.#readdirFail(er.code);\n            children.provisional = 0;\n        }\n        return children.slice(0, children.provisional);\n    }\n    canReaddir() {\n        if (this.#type & ENOCHILD)\n            return false;\n        const ifmt = IFMT & this.#type;\n        // we always set ENOTDIR when setting IFMT, so should be impossible\n        /* c8 ignore start */\n        if (!(ifmt === UNKNOWN || ifmt === IFDIR || ifmt === IFLNK)) {\n            return false;\n        }\n        /* c8 ignore stop */\n        return true;\n    }\n    shouldWalk(dirs, walkFilter) {\n        return ((this.#type & IFDIR) === IFDIR &&\n            !(this.#type & ENOCHILD) &&\n            !dirs.has(this) &&\n            (!walkFilter || walkFilter(this)));\n    }\n    /**\n     * Return the Path object corresponding to path as resolved\n     * by realpath(3).\n     *\n     * If the realpath call fails for any reason, `undefined` is returned.\n     *\n     * Result is cached, and thus may be outdated if the filesystem is mutated.\n     * On success, returns a Path object.\n     */\n    async realpath() {\n        if (this.#realpath)\n            return this.#realpath;\n        if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type)\n            return undefined;\n        try {\n            const rp = await this.#fs.promises.realpath(this.fullpath());\n            return (this.#realpath = this.resolve(rp));\n        }\n        catch (_) {\n            this.#markENOREALPATH();\n        }\n    }\n    /**\n     * Synchronous {@link realpath}\n     */\n    realpathSync() {\n        if (this.#realpath)\n            return this.#realpath;\n        if ((ENOREALPATH | ENOREADLINK | ENOENT) & this.#type)\n            return undefined;\n        try {\n            const rp = this.#fs.realpathSync(this.fullpath());\n            return (this.#realpath = this.resolve(rp));\n        }\n        catch (_) {\n            this.#markENOREALPATH();\n        }\n    }\n    /**\n     * Internal method to mark this Path object as the scurry cwd,\n     * called by {@link PathScurry#chdir}\n     *\n     * @internal\n     */\n    [setAsCwd](oldCwd) {\n        if (oldCwd === this)\n            return;\n        oldCwd.isCWD = false;\n        this.isCWD = true;\n        const changed = new Set([]);\n        let rp = [];\n        let p = this;\n        while (p && p.parent) {\n            changed.add(p);\n            p.#relative = rp.join(this.sep);\n            p.#relativePosix = rp.join('/');\n            p = p.parent;\n            rp.push('..');\n        }\n        // now un-memoize parents of old cwd\n        p = oldCwd;\n        while (p && p.parent && !changed.has(p)) {\n            p.#relative = undefined;\n            p.#relativePosix = undefined;\n            p = p.parent;\n        }\n    }\n}\nexports.PathBase = PathBase;\n/**\n * Path class used on win32 systems\n *\n * Uses `'\\\\'` as the path separator for returned paths, either `'\\\\'` or `'/'`\n * as the path separator for parsing paths.\n */\nclass PathWin32 extends PathBase {\n    /**\n     * Separator for generating path strings.\n     */\n    sep = '\\\\';\n    /**\n     * Separator for parsing path strings.\n     */\n    splitSep = eitherSep;\n    /**\n     * Do not create new Path objects directly.  They should always be accessed\n     * via the PathScurry class or other methods on the Path class.\n     *\n     * @internal\n     */\n    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {\n        super(name, type, root, roots, nocase, children, opts);\n    }\n    /**\n     * @internal\n     */\n    newChild(name, type = UNKNOWN, opts = {}) {\n        return new PathWin32(name, type, this.root, this.roots, this.nocase, this.childrenCache(), opts);\n    }\n    /**\n     * @internal\n     */\n    getRootString(path) {\n        return node_path_1.win32.parse(path).root;\n    }\n    /**\n     * @internal\n     */\n    getRoot(rootPath) {\n        rootPath = uncToDrive(rootPath.toUpperCase());\n        if (rootPath === this.root.name) {\n            return this.root;\n        }\n        // ok, not that one, check if it matches another we know about\n        for (const [compare, root] of Object.entries(this.roots)) {\n            if (this.sameRoot(rootPath, compare)) {\n                return (this.roots[rootPath] = root);\n            }\n        }\n        // otherwise, have to create a new one.\n        return (this.roots[rootPath] = new PathScurryWin32(rootPath, this).root);\n    }\n    /**\n     * @internal\n     */\n    sameRoot(rootPath, compare = this.root.name) {\n        // windows can (rarely) have case-sensitive filesystem, but\n        // UNC and drive letters are always case-insensitive, and canonically\n        // represented uppercase.\n        rootPath = rootPath\n            .toUpperCase()\n            .replace(/\\//g, '\\\\')\n            .replace(uncDriveRegexp, '$1\\\\');\n        return rootPath === compare;\n    }\n}\nexports.PathWin32 = PathWin32;\n/**\n * Path class used on all posix systems.\n *\n * Uses `'/'` as the path separator.\n */\nclass PathPosix extends PathBase {\n    /**\n     * separator for parsing path strings\n     */\n    splitSep = '/';\n    /**\n     * separator for generating path strings\n     */\n    sep = '/';\n    /**\n     * Do not create new Path objects directly.  They should always be accessed\n     * via the PathScurry class or other methods on the Path class.\n     *\n     * @internal\n     */\n    constructor(name, type = UNKNOWN, root, roots, nocase, children, opts) {\n        super(name, type, root, roots, nocase, children, opts);\n    }\n    /**\n     * @internal\n     */\n    getRootString(path) {\n        return path.startsWith('/') ? '/' : '';\n    }\n    /**\n     * @internal\n     */\n    getRoot(_rootPath) {\n        return this.root;\n    }\n    /**\n     * @internal\n     */\n    newChild(name, type = UNKNOWN, opts = {}) {\n        return new PathPosix(name, type, this.root, this.roots, this.nocase, this.childrenCache(), opts);\n    }\n}\nexports.PathPosix = PathPosix;\n/**\n * The base class for all PathScurry classes, providing the interface for path\n * resolution and filesystem operations.\n *\n * Typically, you should *not* instantiate this class directly, but rather one\n * of the platform-specific classes, or the exported {@link PathScurry} which\n * defaults to the current platform.\n */\nclass PathScurryBase {\n    /**\n     * The root Path entry for the current working directory of this Scurry\n     */\n    root;\n    /**\n     * The string path for the root of this Scurry's current working directory\n     */\n    rootPath;\n    /**\n     * A collection of all roots encountered, referenced by rootPath\n     */\n    roots;\n    /**\n     * The Path entry corresponding to this PathScurry's current working directory.\n     */\n    cwd;\n    #resolveCache;\n    #resolvePosixCache;\n    #children;\n    /**\n     * Perform path comparisons case-insensitively.\n     *\n     * Defaults true on Darwin and Windows systems, false elsewhere.\n     */\n    nocase;\n    #fs;\n    /**\n     * This class should not be instantiated directly.\n     *\n     * Use PathScurryWin32, PathScurryDarwin, PathScurryPosix, or PathScurry\n     *\n     * @internal\n     */\n    constructor(cwd = process.cwd(), pathImpl, sep, { nocase, childrenCacheSize = 16 * 1024, fs = defaultFS, } = {}) {\n        this.#fs = fsFromOption(fs);\n        if (cwd instanceof URL || cwd.startsWith('file://')) {\n            cwd = (0, node_url_1.fileURLToPath)(cwd);\n        }\n        // resolve and split root, and then add to the store.\n        // this is the only time we call path.resolve()\n        const cwdPath = pathImpl.resolve(cwd);\n        this.roots = Object.create(null);\n        this.rootPath = this.parseRootPath(cwdPath);\n        this.#resolveCache = new ResolveCache();\n        this.#resolvePosixCache = new ResolveCache();\n        this.#children = new ChildrenCache(childrenCacheSize);\n        const split = cwdPath.substring(this.rootPath.length).split(sep);\n        // resolve('/') leaves '', splits to [''], we don't want that.\n        if (split.length === 1 && !split[0]) {\n            split.pop();\n        }\n        /* c8 ignore start */\n        if (nocase === undefined) {\n            throw new TypeError('must provide nocase setting to PathScurryBase ctor');\n        }\n        /* c8 ignore stop */\n        this.nocase = nocase;\n        this.root = this.newRoot(this.#fs);\n        this.roots[this.rootPath] = this.root;\n        let prev = this.root;\n        let len = split.length - 1;\n        const joinSep = pathImpl.sep;\n        let abs = this.rootPath;\n        let sawFirst = false;\n        for (const part of split) {\n            const l = len--;\n            prev = prev.child(part, {\n                relative: new Array(l).fill('..').join(joinSep),\n                relativePosix: new Array(l).fill('..').join('/'),\n                fullpath: (abs += (sawFirst ? '' : joinSep) + part),\n            });\n            sawFirst = true;\n        }\n        this.cwd = prev;\n    }\n    /**\n     * Get the depth of a provided path, string, or the cwd\n     */\n    depth(path = this.cwd) {\n        if (typeof path === 'string') {\n            path = this.cwd.resolve(path);\n        }\n        return path.depth();\n    }\n    /**\n     * Return the cache of child entries.  Exposed so subclasses can create\n     * child Path objects in a platform-specific way.\n     *\n     * @internal\n     */\n    childrenCache() {\n        return this.#children;\n    }\n    /**\n     * Resolve one or more path strings to a resolved string\n     *\n     * Same interface as require('path').resolve.\n     *\n     * Much faster than path.resolve() when called multiple times for the same\n     * path, because the resolved Path objects are cached.  Much slower\n     * otherwise.\n     */\n    resolve(...paths) {\n        // first figure out the minimum number of paths we have to test\n        // we always start at cwd, but any absolutes will bump the start\n        let r = '';\n        for (let i = paths.length - 1; i >= 0; i--) {\n            const p = paths[i];\n            if (!p || p === '.')\n                continue;\n            r = r ? `${p}/${r}` : p;\n            if (this.isAbsolute(p)) {\n                break;\n            }\n        }\n        const cached = this.#resolveCache.get(r);\n        if (cached !== undefined) {\n            return cached;\n        }\n        const result = this.cwd.resolve(r).fullpath();\n        this.#resolveCache.set(r, result);\n        return result;\n    }\n    /**\n     * Resolve one or more path strings to a resolved string, returning\n     * the posix path.  Identical to .resolve() on posix systems, but on\n     * windows will return a forward-slash separated UNC path.\n     *\n     * Same interface as require('path').resolve.\n     *\n     * Much faster than path.resolve() when called multiple times for the same\n     * path, because the resolved Path objects are cached.  Much slower\n     * otherwise.\n     */\n    resolvePosix(...paths) {\n        // first figure out the minimum number of paths we have to test\n        // we always start at cwd, but any absolutes will bump the start\n        let r = '';\n        for (let i = paths.length - 1; i >= 0; i--) {\n            const p = paths[i];\n            if (!p || p === '.')\n                continue;\n            r = r ? `${p}/${r}` : p;\n            if (this.isAbsolute(p)) {\n                break;\n            }\n        }\n        const cached = this.#resolvePosixCache.get(r);\n        if (cached !== undefined) {\n            return cached;\n        }\n        const result = this.cwd.resolve(r).fullpathPosix();\n        this.#resolvePosixCache.set(r, result);\n        return result;\n    }\n    /**\n     * find the relative path from the cwd to the supplied path string or entry\n     */\n    relative(entry = this.cwd) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        return entry.relative();\n    }\n    /**\n     * find the relative path from the cwd to the supplied path string or\n     * entry, using / as the path delimiter, even on Windows.\n     */\n    relativePosix(entry = this.cwd) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        return entry.relativePosix();\n    }\n    /**\n     * Return the basename for the provided string or Path object\n     */\n    basename(entry = this.cwd) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        return entry.name;\n    }\n    /**\n     * Return the dirname for the provided string or Path object\n     */\n    dirname(entry = this.cwd) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        return (entry.parent || entry).fullpath();\n    }\n    async readdir(entry = this.cwd, opts = {\n        withFileTypes: true,\n    }) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            opts = entry;\n            entry = this.cwd;\n        }\n        const { withFileTypes } = opts;\n        if (!entry.canReaddir()) {\n            return [];\n        }\n        else {\n            const p = await entry.readdir();\n            return withFileTypes ? p : p.map(e => e.name);\n        }\n    }\n    readdirSync(entry = this.cwd, opts = {\n        withFileTypes: true,\n    }) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            opts = entry;\n            entry = this.cwd;\n        }\n        const { withFileTypes = true } = opts;\n        if (!entry.canReaddir()) {\n            return [];\n        }\n        else if (withFileTypes) {\n            return entry.readdirSync();\n        }\n        else {\n            return entry.readdirSync().map(e => e.name);\n        }\n    }\n    /**\n     * Call lstat() on the string or Path object, and update all known\n     * information that can be determined.\n     *\n     * Note that unlike `fs.lstat()`, the returned value does not contain some\n     * information, such as `mode`, `dev`, `nlink`, and `ino`.  If that\n     * information is required, you will need to call `fs.lstat` yourself.\n     *\n     * If the Path refers to a nonexistent file, or if the lstat call fails for\n     * any reason, `undefined` is returned.  Otherwise the updated Path object is\n     * returned.\n     *\n     * Results are cached, and thus may be out of date if the filesystem is\n     * mutated.\n     */\n    async lstat(entry = this.cwd) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        return entry.lstat();\n    }\n    /**\n     * synchronous {@link PathScurryBase.lstat}\n     */\n    lstatSync(entry = this.cwd) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        return entry.lstatSync();\n    }\n    async readlink(entry = this.cwd, { withFileTypes } = {\n        withFileTypes: false,\n    }) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            withFileTypes = entry.withFileTypes;\n            entry = this.cwd;\n        }\n        const e = await entry.readlink();\n        return withFileTypes ? e : e?.fullpath();\n    }\n    readlinkSync(entry = this.cwd, { withFileTypes } = {\n        withFileTypes: false,\n    }) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            withFileTypes = entry.withFileTypes;\n            entry = this.cwd;\n        }\n        const e = entry.readlinkSync();\n        return withFileTypes ? e : e?.fullpath();\n    }\n    async realpath(entry = this.cwd, { withFileTypes } = {\n        withFileTypes: false,\n    }) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            withFileTypes = entry.withFileTypes;\n            entry = this.cwd;\n        }\n        const e = await entry.realpath();\n        return withFileTypes ? e : e?.fullpath();\n    }\n    realpathSync(entry = this.cwd, { withFileTypes } = {\n        withFileTypes: false,\n    }) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            withFileTypes = entry.withFileTypes;\n            entry = this.cwd;\n        }\n        const e = entry.realpathSync();\n        return withFileTypes ? e : e?.fullpath();\n    }\n    async walk(entry = this.cwd, opts = {}) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            opts = entry;\n            entry = this.cwd;\n        }\n        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;\n        const results = [];\n        if (!filter || filter(entry)) {\n            results.push(withFileTypes ? entry : entry.fullpath());\n        }\n        const dirs = new Set();\n        const walk = (dir, cb) => {\n            dirs.add(dir);\n            dir.readdirCB((er, entries) => {\n                /* c8 ignore start */\n                if (er) {\n                    return cb(er);\n                }\n                /* c8 ignore stop */\n                let len = entries.length;\n                if (!len)\n                    return cb();\n                const next = () => {\n                    if (--len === 0) {\n                        cb();\n                    }\n                };\n                for (const e of entries) {\n                    if (!filter || filter(e)) {\n                        results.push(withFileTypes ? e : e.fullpath());\n                    }\n                    if (follow && e.isSymbolicLink()) {\n                        e.realpath()\n                            .then(r => (r?.isUnknown() ? r.lstat() : r))\n                            .then(r => r?.shouldWalk(dirs, walkFilter) ? walk(r, next) : next());\n                    }\n                    else {\n                        if (e.shouldWalk(dirs, walkFilter)) {\n                            walk(e, next);\n                        }\n                        else {\n                            next();\n                        }\n                    }\n                }\n            }, true); // zalgooooooo\n        };\n        const start = entry;\n        return new Promise((res, rej) => {\n            walk(start, er => {\n                /* c8 ignore start */\n                if (er)\n                    return rej(er);\n                /* c8 ignore stop */\n                res(results);\n            });\n        });\n    }\n    walkSync(entry = this.cwd, opts = {}) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            opts = entry;\n            entry = this.cwd;\n        }\n        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;\n        const results = [];\n        if (!filter || filter(entry)) {\n            results.push(withFileTypes ? entry : entry.fullpath());\n        }\n        const dirs = new Set([entry]);\n        for (const dir of dirs) {\n            const entries = dir.readdirSync();\n            for (const e of entries) {\n                if (!filter || filter(e)) {\n                    results.push(withFileTypes ? e : e.fullpath());\n                }\n                let r = e;\n                if (e.isSymbolicLink()) {\n                    if (!(follow && (r = e.realpathSync())))\n                        continue;\n                    if (r.isUnknown())\n                        r.lstatSync();\n                }\n                if (r.shouldWalk(dirs, walkFilter)) {\n                    dirs.add(r);\n                }\n            }\n        }\n        return results;\n    }\n    /**\n     * Support for `for await`\n     *\n     * Alias for {@link PathScurryBase.iterate}\n     *\n     * Note: As of Node 19, this is very slow, compared to other methods of\n     * walking.  Consider using {@link PathScurryBase.stream} if memory overhead\n     * and backpressure are concerns, or {@link PathScurryBase.walk} if not.\n     */\n    [Symbol.asyncIterator]() {\n        return this.iterate();\n    }\n    iterate(entry = this.cwd, options = {}) {\n        // iterating async over the stream is significantly more performant,\n        // especially in the warm-cache scenario, because it buffers up directory\n        // entries in the background instead of waiting for a yield for each one.\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            options = entry;\n            entry = this.cwd;\n        }\n        return this.stream(entry, options)[Symbol.asyncIterator]();\n    }\n    /**\n     * Iterating over a PathScurry performs a synchronous walk.\n     *\n     * Alias for {@link PathScurryBase.iterateSync}\n     */\n    [Symbol.iterator]() {\n        return this.iterateSync();\n    }\n    *iterateSync(entry = this.cwd, opts = {}) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            opts = entry;\n            entry = this.cwd;\n        }\n        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;\n        if (!filter || filter(entry)) {\n            yield withFileTypes ? entry : entry.fullpath();\n        }\n        const dirs = new Set([entry]);\n        for (const dir of dirs) {\n            const entries = dir.readdirSync();\n            for (const e of entries) {\n                if (!filter || filter(e)) {\n                    yield withFileTypes ? e : e.fullpath();\n                }\n                let r = e;\n                if (e.isSymbolicLink()) {\n                    if (!(follow && (r = e.realpathSync())))\n                        continue;\n                    if (r.isUnknown())\n                        r.lstatSync();\n                }\n                if (r.shouldWalk(dirs, walkFilter)) {\n                    dirs.add(r);\n                }\n            }\n        }\n    }\n    stream(entry = this.cwd, opts = {}) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            opts = entry;\n            entry = this.cwd;\n        }\n        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;\n        const results = new minipass_1.Minipass({ objectMode: true });\n        if (!filter || filter(entry)) {\n            results.write(withFileTypes ? entry : entry.fullpath());\n        }\n        const dirs = new Set();\n        const queue = [entry];\n        let processing = 0;\n        const process = () => {\n            let paused = false;\n            while (!paused) {\n                const dir = queue.shift();\n                if (!dir) {\n                    if (processing === 0)\n                        results.end();\n                    return;\n                }\n                processing++;\n                dirs.add(dir);\n                const onReaddir = (er, entries, didRealpaths = false) => {\n                    /* c8 ignore start */\n                    if (er)\n                        return results.emit('error', er);\n                    /* c8 ignore stop */\n                    if (follow && !didRealpaths) {\n                        const promises = [];\n                        for (const e of entries) {\n                            if (e.isSymbolicLink()) {\n                                promises.push(e\n                                    .realpath()\n                                    .then((r) => r?.isUnknown() ? r.lstat() : r));\n                            }\n                        }\n                        if (promises.length) {\n                            Promise.all(promises).then(() => onReaddir(null, entries, true));\n                            return;\n                        }\n                    }\n                    for (const e of entries) {\n                        if (e && (!filter || filter(e))) {\n                            if (!results.write(withFileTypes ? e : e.fullpath())) {\n                                paused = true;\n                            }\n                        }\n                    }\n                    processing--;\n                    for (const e of entries) {\n                        const r = e.realpathCached() || e;\n                        if (r.shouldWalk(dirs, walkFilter)) {\n                            queue.push(r);\n                        }\n                    }\n                    if (paused && !results.flowing) {\n                        results.once('drain', process);\n                    }\n                    else if (!sync) {\n                        process();\n                    }\n                };\n                // zalgo containment\n                let sync = true;\n                dir.readdirCB(onReaddir, true);\n                sync = false;\n            }\n        };\n        process();\n        return results;\n    }\n    streamSync(entry = this.cwd, opts = {}) {\n        if (typeof entry === 'string') {\n            entry = this.cwd.resolve(entry);\n        }\n        else if (!(entry instanceof PathBase)) {\n            opts = entry;\n            entry = this.cwd;\n        }\n        const { withFileTypes = true, follow = false, filter, walkFilter, } = opts;\n        const results = new minipass_1.Minipass({ objectMode: true });\n        const dirs = new Set();\n        if (!filter || filter(entry)) {\n            results.write(withFileTypes ? entry : entry.fullpath());\n        }\n        const queue = [entry];\n        let processing = 0;\n        const process = () => {\n            let paused = false;\n            while (!paused) {\n                const dir = queue.shift();\n                if (!dir) {\n                    if (processing === 0)\n                        results.end();\n                    return;\n                }\n                processing++;\n                dirs.add(dir);\n                const entries = dir.readdirSync();\n                for (const e of entries) {\n                    if (!filter || filter(e)) {\n                        if (!results.write(withFileTypes ? e : e.fullpath())) {\n                            paused = true;\n                        }\n                    }\n                }\n                processing--;\n                for (const e of entries) {\n                    let r = e;\n                    if (e.isSymbolicLink()) {\n                        if (!(follow && (r = e.realpathSync())))\n                            continue;\n                        if (r.isUnknown())\n                            r.lstatSync();\n                    }\n                    if (r.shouldWalk(dirs, walkFilter)) {\n                        queue.push(r);\n                    }\n                }\n            }\n            if (paused && !results.flowing)\n                results.once('drain', process);\n        };\n        process();\n        return results;\n    }\n    chdir(path = this.cwd) {\n        const oldCwd = this.cwd;\n        this.cwd = typeof path === 'string' ? this.cwd.resolve(path) : path;\n        this.cwd[setAsCwd](oldCwd);\n    }\n}\nexports.PathScurryBase = PathScurryBase;\n/**\n * Windows implementation of {@link PathScurryBase}\n *\n * Defaults to case insensitve, uses `'\\\\'` to generate path strings.  Uses\n * {@link PathWin32} for Path objects.\n */\nclass PathScurryWin32 extends PathScurryBase {\n    /**\n     * separator for generating path strings\n     */\n    sep = '\\\\';\n    constructor(cwd = process.cwd(), opts = {}) {\n        const { nocase = true } = opts;\n        super(cwd, node_path_1.win32, '\\\\', { ...opts, nocase });\n        this.nocase = nocase;\n        for (let p = this.cwd; p; p = p.parent) {\n            p.nocase = this.nocase;\n        }\n    }\n    /**\n     * @internal\n     */\n    parseRootPath(dir) {\n        // if the path starts with a single separator, it's not a UNC, and we'll\n        // just get separator as the root, and driveFromUNC will return \\\n        // In that case, mount \\ on the root from the cwd.\n        return node_path_1.win32.parse(dir).root.toUpperCase();\n    }\n    /**\n     * @internal\n     */\n    newRoot(fs) {\n        return new PathWin32(this.rootPath, IFDIR, undefined, this.roots, this.nocase, this.childrenCache(), { fs });\n    }\n    /**\n     * Return true if the provided path string is an absolute path\n     */\n    isAbsolute(p) {\n        return (p.startsWith('/') || p.startsWith('\\\\') || /^[a-z]:(\\/|\\\\)/i.test(p));\n    }\n}\nexports.PathScurryWin32 = PathScurryWin32;\n/**\n * {@link PathScurryBase} implementation for all posix systems other than Darwin.\n *\n * Defaults to case-sensitive matching, uses `'/'` to generate path strings.\n *\n * Uses {@link PathPosix} for Path objects.\n */\nclass PathScurryPosix extends PathScurryBase {\n    /**\n     * separator for generating path strings\n     */\n    sep = '/';\n    constructor(cwd = process.cwd(), opts = {}) {\n        const { nocase = false } = opts;\n        super(cwd, node_path_1.posix, '/', { ...opts, nocase });\n        this.nocase = nocase;\n    }\n    /**\n     * @internal\n     */\n    parseRootPath(_dir) {\n        return '/';\n    }\n    /**\n     * @internal\n     */\n    newRoot(fs) {\n        return new PathPosix(this.rootPath, IFDIR, undefined, this.roots, this.nocase, this.childrenCache(), { fs });\n    }\n    /**\n     * Return true if the provided path string is an absolute path\n     */\n    isAbsolute(p) {\n        return p.startsWith('/');\n    }\n}\nexports.PathScurryPosix = PathScurryPosix;\n/**\n * {@link PathScurryBase} implementation for Darwin (macOS) systems.\n *\n * Defaults to case-insensitive matching, uses `'/'` for generating path\n * strings.\n *\n * Uses {@link PathPosix} for Path objects.\n */\nclass PathScurryDarwin extends PathScurryPosix {\n    constructor(cwd = process.cwd(), opts = {}) {\n        const { nocase = true } = opts;\n        super(cwd, { ...opts, nocase });\n    }\n}\nexports.PathScurryDarwin = PathScurryDarwin;\n/**\n * Default {@link PathBase} implementation for the current platform.\n *\n * {@link PathWin32} on Windows systems, {@link PathPosix} on all others.\n */\nexports.Path = process.platform === 'win32' ? PathWin32 : PathPosix;\n/**\n * Default {@link PathScurryBase} implementation for the current platform.\n *\n * {@link PathScurryWin32} on Windows systems, {@link PathScurryDarwin} on\n * Darwin (macOS) systems, {@link PathScurryPosix} on all others.\n */\nexports.PathScurry = process.platform === 'win32' ? PathScurryWin32\n    : process.platform === 'darwin' ? PathScurryDarwin\n        : PathScurryPosix;\n//# sourceMappingURL=index.js.map","\"use strict\";\n/**\n * @module LRUCache\n */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.LRUCache = void 0;\nconst perf = typeof performance === 'object' &&\n    performance &&\n    typeof performance.now === 'function'\n    ? performance\n    : Date;\nconst warned = new Set();\n/* c8 ignore start */\nconst PROCESS = (typeof process === 'object' && !!process ? process : {});\n/* c8 ignore start */\nconst emitWarning = (msg, type, code, fn) => {\n    typeof PROCESS.emitWarning === 'function'\n        ? PROCESS.emitWarning(msg, type, code, fn)\n        : console.error(`[${code}] ${type}: ${msg}`);\n};\nlet AC = globalThis.AbortController;\nlet AS = globalThis.AbortSignal;\n/* c8 ignore start */\nif (typeof AC === 'undefined') {\n    //@ts-ignore\n    AS = class AbortSignal {\n        onabort;\n        _onabort = [];\n        reason;\n        aborted = false;\n        addEventListener(_, fn) {\n            this._onabort.push(fn);\n        }\n    };\n    //@ts-ignore\n    AC = class AbortController {\n        constructor() {\n            warnACPolyfill();\n        }\n        signal = new AS();\n        abort(reason) {\n            if (this.signal.aborted)\n                return;\n            //@ts-ignore\n            this.signal.reason = reason;\n            //@ts-ignore\n            this.signal.aborted = true;\n            //@ts-ignore\n            for (const fn of this.signal._onabort) {\n                fn(reason);\n            }\n            this.signal.onabort?.(reason);\n        }\n    };\n    let printACPolyfillWarning = PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1';\n    const warnACPolyfill = () => {\n        if (!printACPolyfillWarning)\n            return;\n        printACPolyfillWarning = false;\n        emitWarning('AbortController is not defined. If using lru-cache in ' +\n            'node 14, load an AbortController polyfill from the ' +\n            '`node-abort-controller` package. A minimal polyfill is ' +\n            'provided for use by LRUCache.fetch(), but it should not be ' +\n            'relied upon in other contexts (eg, passing it to other APIs that ' +\n            'use AbortController/AbortSignal might have undesirable effects). ' +\n            'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.', 'NO_ABORT_CONTROLLER', 'ENOTSUP', warnACPolyfill);\n    };\n}\n/* c8 ignore stop */\nconst shouldWarn = (code) => !warned.has(code);\nconst TYPE = Symbol('type');\nconst isPosInt = (n) => n && n === Math.floor(n) && n > 0 && isFinite(n);\n/* c8 ignore start */\n// This is a little bit ridiculous, tbh.\n// The maximum array length is 2^32-1 or thereabouts on most JS impls.\n// And well before that point, you're caching the entire world, I mean,\n// that's ~32GB of just integers for the next/prev links, plus whatever\n// else to hold that many keys and values.  Just filling the memory with\n// zeroes at init time is brutal when you get that big.\n// But why not be complete?\n// Maybe in the future, these limits will have expanded.\nconst getUintArray = (max) => !isPosInt(max)\n    ? null\n    : max <= Math.pow(2, 8)\n        ? Uint8Array\n        : max <= Math.pow(2, 16)\n            ? Uint16Array\n            : max <= Math.pow(2, 32)\n                ? Uint32Array\n                : max <= Number.MAX_SAFE_INTEGER\n                    ? ZeroArray\n                    : null;\n/* c8 ignore stop */\nclass ZeroArray extends Array {\n    constructor(size) {\n        super(size);\n        this.fill(0);\n    }\n}\nclass Stack {\n    heap;\n    length;\n    // private constructor\n    static #constructing = false;\n    static create(max) {\n        const HeapCls = getUintArray(max);\n        if (!HeapCls)\n            return [];\n        Stack.#constructing = true;\n        const s = new Stack(max, HeapCls);\n        Stack.#constructing = false;\n        return s;\n    }\n    constructor(max, HeapCls) {\n        /* c8 ignore start */\n        if (!Stack.#constructing) {\n            throw new TypeError('instantiate Stack using Stack.create(n)');\n        }\n        /* c8 ignore stop */\n        this.heap = new HeapCls(max);\n        this.length = 0;\n    }\n    push(n) {\n        this.heap[this.length++] = n;\n    }\n    pop() {\n        return this.heap[--this.length];\n    }\n}\n/**\n * Default export, the thing you're using this module to get.\n *\n * The `K` and `V` types define the key and value types, respectively. The\n * optional `FC` type defines the type of the `context` object passed to\n * `cache.fetch()` and `cache.memo()`.\n *\n * Keys and values **must not** be `null` or `undefined`.\n *\n * All properties from the options object (with the exception of `max`,\n * `maxSize`, `fetchMethod`, `memoMethod`, `dispose` and `disposeAfter`) are\n * added as normal public members. (The listed options are read-only getters.)\n *\n * Changing any of these will alter the defaults for subsequent method calls.\n */\nclass LRUCache {\n    // options that cannot be changed without disaster\n    #max;\n    #maxSize;\n    #dispose;\n    #disposeAfter;\n    #fetchMethod;\n    #memoMethod;\n    /**\n     * {@link LRUCache.OptionsBase.ttl}\n     */\n    ttl;\n    /**\n     * {@link LRUCache.OptionsBase.ttlResolution}\n     */\n    ttlResolution;\n    /**\n     * {@link LRUCache.OptionsBase.ttlAutopurge}\n     */\n    ttlAutopurge;\n    /**\n     * {@link LRUCache.OptionsBase.updateAgeOnGet}\n     */\n    updateAgeOnGet;\n    /**\n     * {@link LRUCache.OptionsBase.updateAgeOnHas}\n     */\n    updateAgeOnHas;\n    /**\n     * {@link LRUCache.OptionsBase.allowStale}\n     */\n    allowStale;\n    /**\n     * {@link LRUCache.OptionsBase.noDisposeOnSet}\n     */\n    noDisposeOnSet;\n    /**\n     * {@link LRUCache.OptionsBase.noUpdateTTL}\n     */\n    noUpdateTTL;\n    /**\n     * {@link LRUCache.OptionsBase.maxEntrySize}\n     */\n    maxEntrySize;\n    /**\n     * {@link LRUCache.OptionsBase.sizeCalculation}\n     */\n    sizeCalculation;\n    /**\n     * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}\n     */\n    noDeleteOnFetchRejection;\n    /**\n     * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}\n     */\n    noDeleteOnStaleGet;\n    /**\n     * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}\n     */\n    allowStaleOnFetchAbort;\n    /**\n     * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}\n     */\n    allowStaleOnFetchRejection;\n    /**\n     * {@link LRUCache.OptionsBase.ignoreFetchAbort}\n     */\n    ignoreFetchAbort;\n    // computed properties\n    #size;\n    #calculatedSize;\n    #keyMap;\n    #keyList;\n    #valList;\n    #next;\n    #prev;\n    #head;\n    #tail;\n    #free;\n    #disposed;\n    #sizes;\n    #starts;\n    #ttls;\n    #hasDispose;\n    #hasFetchMethod;\n    #hasDisposeAfter;\n    /**\n     * Do not call this method unless you need to inspect the\n     * inner workings of the cache.  If anything returned by this\n     * object is modified in any way, strange breakage may occur.\n     *\n     * These fields are private for a reason!\n     *\n     * @internal\n     */\n    static unsafeExposeInternals(c) {\n        return {\n            // properties\n            starts: c.#starts,\n            ttls: c.#ttls,\n            sizes: c.#sizes,\n            keyMap: c.#keyMap,\n            keyList: c.#keyList,\n            valList: c.#valList,\n            next: c.#next,\n            prev: c.#prev,\n            get head() {\n                return c.#head;\n            },\n            get tail() {\n                return c.#tail;\n            },\n            free: c.#free,\n            // methods\n            isBackgroundFetch: (p) => c.#isBackgroundFetch(p),\n            backgroundFetch: (k, index, options, context) => c.#backgroundFetch(k, index, options, context),\n            moveToTail: (index) => c.#moveToTail(index),\n            indexes: (options) => c.#indexes(options),\n            rindexes: (options) => c.#rindexes(options),\n            isStale: (index) => c.#isStale(index),\n        };\n    }\n    // Protected read-only members\n    /**\n     * {@link LRUCache.OptionsBase.max} (read-only)\n     */\n    get max() {\n        return this.#max;\n    }\n    /**\n     * {@link LRUCache.OptionsBase.maxSize} (read-only)\n     */\n    get maxSize() {\n        return this.#maxSize;\n    }\n    /**\n     * The total computed size of items in the cache (read-only)\n     */\n    get calculatedSize() {\n        return this.#calculatedSize;\n    }\n    /**\n     * The number of items stored in the cache (read-only)\n     */\n    get size() {\n        return this.#size;\n    }\n    /**\n     * {@link LRUCache.OptionsBase.fetchMethod} (read-only)\n     */\n    get fetchMethod() {\n        return this.#fetchMethod;\n    }\n    get memoMethod() {\n        return this.#memoMethod;\n    }\n    /**\n     * {@link LRUCache.OptionsBase.dispose} (read-only)\n     */\n    get dispose() {\n        return this.#dispose;\n    }\n    /**\n     * {@link LRUCache.OptionsBase.disposeAfter} (read-only)\n     */\n    get disposeAfter() {\n        return this.#disposeAfter;\n    }\n    constructor(options) {\n        const { max = 0, ttl, ttlResolution = 1, ttlAutopurge, updateAgeOnGet, updateAgeOnHas, allowStale, dispose, disposeAfter, noDisposeOnSet, noUpdateTTL, maxSize = 0, maxEntrySize = 0, sizeCalculation, fetchMethod, memoMethod, noDeleteOnFetchRejection, noDeleteOnStaleGet, allowStaleOnFetchRejection, allowStaleOnFetchAbort, ignoreFetchAbort, } = options;\n        if (max !== 0 && !isPosInt(max)) {\n            throw new TypeError('max option must be a nonnegative integer');\n        }\n        const UintArray = max ? getUintArray(max) : Array;\n        if (!UintArray) {\n            throw new Error('invalid max value: ' + max);\n        }\n        this.#max = max;\n        this.#maxSize = maxSize;\n        this.maxEntrySize = maxEntrySize || this.#maxSize;\n        this.sizeCalculation = sizeCalculation;\n        if (this.sizeCalculation) {\n            if (!this.#maxSize && !this.maxEntrySize) {\n                throw new TypeError('cannot set sizeCalculation without setting maxSize or maxEntrySize');\n            }\n            if (typeof this.sizeCalculation !== 'function') {\n                throw new TypeError('sizeCalculation set to non-function');\n            }\n        }\n        if (memoMethod !== undefined &&\n            typeof memoMethod !== 'function') {\n            throw new TypeError('memoMethod must be a function if defined');\n        }\n        this.#memoMethod = memoMethod;\n        if (fetchMethod !== undefined &&\n            typeof fetchMethod !== 'function') {\n            throw new TypeError('fetchMethod must be a function if specified');\n        }\n        this.#fetchMethod = fetchMethod;\n        this.#hasFetchMethod = !!fetchMethod;\n        this.#keyMap = new Map();\n        this.#keyList = new Array(max).fill(undefined);\n        this.#valList = new Array(max).fill(undefined);\n        this.#next = new UintArray(max);\n        this.#prev = new UintArray(max);\n        this.#head = 0;\n        this.#tail = 0;\n        this.#free = Stack.create(max);\n        this.#size = 0;\n        this.#calculatedSize = 0;\n        if (typeof dispose === 'function') {\n            this.#dispose = dispose;\n        }\n        if (typeof disposeAfter === 'function') {\n            this.#disposeAfter = disposeAfter;\n            this.#disposed = [];\n        }\n        else {\n            this.#disposeAfter = undefined;\n            this.#disposed = undefined;\n        }\n        this.#hasDispose = !!this.#dispose;\n        this.#hasDisposeAfter = !!this.#disposeAfter;\n        this.noDisposeOnSet = !!noDisposeOnSet;\n        this.noUpdateTTL = !!noUpdateTTL;\n        this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection;\n        this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection;\n        this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort;\n        this.ignoreFetchAbort = !!ignoreFetchAbort;\n        // NB: maxEntrySize is set to maxSize if it's set\n        if (this.maxEntrySize !== 0) {\n            if (this.#maxSize !== 0) {\n                if (!isPosInt(this.#maxSize)) {\n                    throw new TypeError('maxSize must be a positive integer if specified');\n                }\n            }\n            if (!isPosInt(this.maxEntrySize)) {\n                throw new TypeError('maxEntrySize must be a positive integer if specified');\n            }\n            this.#initializeSizeTracking();\n        }\n        this.allowStale = !!allowStale;\n        this.noDeleteOnStaleGet = !!noDeleteOnStaleGet;\n        this.updateAgeOnGet = !!updateAgeOnGet;\n        this.updateAgeOnHas = !!updateAgeOnHas;\n        this.ttlResolution =\n            isPosInt(ttlResolution) || ttlResolution === 0\n                ? ttlResolution\n                : 1;\n        this.ttlAutopurge = !!ttlAutopurge;\n        this.ttl = ttl || 0;\n        if (this.ttl) {\n            if (!isPosInt(this.ttl)) {\n                throw new TypeError('ttl must be a positive integer if specified');\n            }\n            this.#initializeTTLTracking();\n        }\n        // do not allow completely unbounded caches\n        if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {\n            throw new TypeError('At least one of max, maxSize, or ttl is required');\n        }\n        if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {\n            const code = 'LRU_CACHE_UNBOUNDED';\n            if (shouldWarn(code)) {\n                warned.add(code);\n                const msg = 'TTL caching without ttlAutopurge, max, or maxSize can ' +\n                    'result in unbounded memory consumption.';\n                emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache);\n            }\n        }\n    }\n    /**\n     * Return the number of ms left in the item's TTL. If item is not in cache,\n     * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.\n     */\n    getRemainingTTL(key) {\n        return this.#keyMap.has(key) ? Infinity : 0;\n    }\n    #initializeTTLTracking() {\n        const ttls = new ZeroArray(this.#max);\n        const starts = new ZeroArray(this.#max);\n        this.#ttls = ttls;\n        this.#starts = starts;\n        this.#setItemTTL = (index, ttl, start = perf.now()) => {\n            starts[index] = ttl !== 0 ? start : 0;\n            ttls[index] = ttl;\n            if (ttl !== 0 && this.ttlAutopurge) {\n                const t = setTimeout(() => {\n                    if (this.#isStale(index)) {\n                        this.#delete(this.#keyList[index], 'expire');\n                    }\n                }, ttl + 1);\n                // unref() not supported on all platforms\n                /* c8 ignore start */\n                if (t.unref) {\n                    t.unref();\n                }\n                /* c8 ignore stop */\n            }\n        };\n        this.#updateItemAge = index => {\n            starts[index] = ttls[index] !== 0 ? perf.now() : 0;\n        };\n        this.#statusTTL = (status, index) => {\n            if (ttls[index]) {\n                const ttl = ttls[index];\n                const start = starts[index];\n                /* c8 ignore next */\n                if (!ttl || !start)\n                    return;\n                status.ttl = ttl;\n                status.start = start;\n                status.now = cachedNow || getNow();\n                const age = status.now - start;\n                status.remainingTTL = ttl - age;\n            }\n        };\n        // debounce calls to perf.now() to 1s so we're not hitting\n        // that costly call repeatedly.\n        let cachedNow = 0;\n        const getNow = () => {\n            const n = perf.now();\n            if (this.ttlResolution > 0) {\n                cachedNow = n;\n                const t = setTimeout(() => (cachedNow = 0), this.ttlResolution);\n                // not available on all platforms\n                /* c8 ignore start */\n                if (t.unref) {\n                    t.unref();\n                }\n                /* c8 ignore stop */\n            }\n            return n;\n        };\n        this.getRemainingTTL = key => {\n            const index = this.#keyMap.get(key);\n            if (index === undefined) {\n                return 0;\n            }\n            const ttl = ttls[index];\n            const start = starts[index];\n            if (!ttl || !start) {\n                return Infinity;\n            }\n            const age = (cachedNow || getNow()) - start;\n            return ttl - age;\n        };\n        this.#isStale = index => {\n            const s = starts[index];\n            const t = ttls[index];\n            return !!t && !!s && (cachedNow || getNow()) - s > t;\n        };\n    }\n    // conditionally set private methods related to TTL\n    #updateItemAge = () => { };\n    #statusTTL = () => { };\n    #setItemTTL = () => { };\n    /* c8 ignore stop */\n    #isStale = () => false;\n    #initializeSizeTracking() {\n        const sizes = new ZeroArray(this.#max);\n        this.#calculatedSize = 0;\n        this.#sizes = sizes;\n        this.#removeItemSize = index => {\n            this.#calculatedSize -= sizes[index];\n            sizes[index] = 0;\n        };\n        this.#requireSize = (k, v, size, sizeCalculation) => {\n            // provisionally accept background fetches.\n            // actual value size will be checked when they return.\n            if (this.#isBackgroundFetch(v)) {\n                return 0;\n            }\n            if (!isPosInt(size)) {\n                if (sizeCalculation) {\n                    if (typeof sizeCalculation !== 'function') {\n                        throw new TypeError('sizeCalculation must be a function');\n                    }\n                    size = sizeCalculation(v, k);\n                    if (!isPosInt(size)) {\n                        throw new TypeError('sizeCalculation return invalid (expect positive integer)');\n                    }\n                }\n                else {\n                    throw new TypeError('invalid size value (must be positive integer). ' +\n                        'When maxSize or maxEntrySize is used, sizeCalculation ' +\n                        'or size must be set.');\n                }\n            }\n            return size;\n        };\n        this.#addItemSize = (index, size, status) => {\n            sizes[index] = size;\n            if (this.#maxSize) {\n                const maxSize = this.#maxSize - sizes[index];\n                while (this.#calculatedSize > maxSize) {\n                    this.#evict(true);\n                }\n            }\n            this.#calculatedSize += sizes[index];\n            if (status) {\n                status.entrySize = size;\n                status.totalCalculatedSize = this.#calculatedSize;\n            }\n        };\n    }\n    #removeItemSize = _i => { };\n    #addItemSize = (_i, _s, _st) => { };\n    #requireSize = (_k, _v, size, sizeCalculation) => {\n        if (size || sizeCalculation) {\n            throw new TypeError('cannot set size without setting maxSize or maxEntrySize on cache');\n        }\n        return 0;\n    };\n    *#indexes({ allowStale = this.allowStale } = {}) {\n        if (this.#size) {\n            for (let i = this.#tail; true;) {\n                if (!this.#isValidIndex(i)) {\n                    break;\n                }\n                if (allowStale || !this.#isStale(i)) {\n                    yield i;\n                }\n                if (i === this.#head) {\n                    break;\n                }\n                else {\n                    i = this.#prev[i];\n                }\n            }\n        }\n    }\n    *#rindexes({ allowStale = this.allowStale } = {}) {\n        if (this.#size) {\n            for (let i = this.#head; true;) {\n                if (!this.#isValidIndex(i)) {\n                    break;\n                }\n                if (allowStale || !this.#isStale(i)) {\n                    yield i;\n                }\n                if (i === this.#tail) {\n                    break;\n                }\n                else {\n                    i = this.#next[i];\n                }\n            }\n        }\n    }\n    #isValidIndex(index) {\n        return (index !== undefined &&\n            this.#keyMap.get(this.#keyList[index]) === index);\n    }\n    /**\n     * Return a generator yielding `[key, value]` pairs,\n     * in order from most recently used to least recently used.\n     */\n    *entries() {\n        for (const i of this.#indexes()) {\n            if (this.#valList[i] !== undefined &&\n                this.#keyList[i] !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield [this.#keyList[i], this.#valList[i]];\n            }\n        }\n    }\n    /**\n     * Inverse order version of {@link LRUCache.entries}\n     *\n     * Return a generator yielding `[key, value]` pairs,\n     * in order from least recently used to most recently used.\n     */\n    *rentries() {\n        for (const i of this.#rindexes()) {\n            if (this.#valList[i] !== undefined &&\n                this.#keyList[i] !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield [this.#keyList[i], this.#valList[i]];\n            }\n        }\n    }\n    /**\n     * Return a generator yielding the keys in the cache,\n     * in order from most recently used to least recently used.\n     */\n    *keys() {\n        for (const i of this.#indexes()) {\n            const k = this.#keyList[i];\n            if (k !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield k;\n            }\n        }\n    }\n    /**\n     * Inverse order version of {@link LRUCache.keys}\n     *\n     * Return a generator yielding the keys in the cache,\n     * in order from least recently used to most recently used.\n     */\n    *rkeys() {\n        for (const i of this.#rindexes()) {\n            const k = this.#keyList[i];\n            if (k !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield k;\n            }\n        }\n    }\n    /**\n     * Return a generator yielding the values in the cache,\n     * in order from most recently used to least recently used.\n     */\n    *values() {\n        for (const i of this.#indexes()) {\n            const v = this.#valList[i];\n            if (v !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield this.#valList[i];\n            }\n        }\n    }\n    /**\n     * Inverse order version of {@link LRUCache.values}\n     *\n     * Return a generator yielding the values in the cache,\n     * in order from least recently used to most recently used.\n     */\n    *rvalues() {\n        for (const i of this.#rindexes()) {\n            const v = this.#valList[i];\n            if (v !== undefined &&\n                !this.#isBackgroundFetch(this.#valList[i])) {\n                yield this.#valList[i];\n            }\n        }\n    }\n    /**\n     * Iterating over the cache itself yields the same results as\n     * {@link LRUCache.entries}\n     */\n    [Symbol.iterator]() {\n        return this.entries();\n    }\n    /**\n     * A String value that is used in the creation of the default string\n     * description of an object. Called by the built-in method\n     * `Object.prototype.toString`.\n     */\n    [Symbol.toStringTag] = 'LRUCache';\n    /**\n     * Find a value for which the supplied fn method returns a truthy value,\n     * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.\n     */\n    find(fn, getOptions = {}) {\n        for (const i of this.#indexes()) {\n            const v = this.#valList[i];\n            const value = this.#isBackgroundFetch(v)\n                ? v.__staleWhileFetching\n                : v;\n            if (value === undefined)\n                continue;\n            if (fn(value, this.#keyList[i], this)) {\n                return this.get(this.#keyList[i], getOptions);\n            }\n        }\n    }\n    /**\n     * Call the supplied function on each item in the cache, in order from most\n     * recently used to least recently used.\n     *\n     * `fn` is called as `fn(value, key, cache)`.\n     *\n     * If `thisp` is provided, function will be called in the `this`-context of\n     * the provided object, or the cache if no `thisp` object is provided.\n     *\n     * Does not update age or recenty of use, or iterate over stale values.\n     */\n    forEach(fn, thisp = this) {\n        for (const i of this.#indexes()) {\n            const v = this.#valList[i];\n            const value = this.#isBackgroundFetch(v)\n                ? v.__staleWhileFetching\n                : v;\n            if (value === undefined)\n                continue;\n            fn.call(thisp, value, this.#keyList[i], this);\n        }\n    }\n    /**\n     * The same as {@link LRUCache.forEach} but items are iterated over in\n     * reverse order.  (ie, less recently used items are iterated over first.)\n     */\n    rforEach(fn, thisp = this) {\n        for (const i of this.#rindexes()) {\n            const v = this.#valList[i];\n            const value = this.#isBackgroundFetch(v)\n                ? v.__staleWhileFetching\n                : v;\n            if (value === undefined)\n                continue;\n            fn.call(thisp, value, this.#keyList[i], this);\n        }\n    }\n    /**\n     * Delete any stale entries. Returns true if anything was removed,\n     * false otherwise.\n     */\n    purgeStale() {\n        let deleted = false;\n        for (const i of this.#rindexes({ allowStale: true })) {\n            if (this.#isStale(i)) {\n                this.#delete(this.#keyList[i], 'expire');\n                deleted = true;\n            }\n        }\n        return deleted;\n    }\n    /**\n     * Get the extended info about a given entry, to get its value, size, and\n     * TTL info simultaneously. Returns `undefined` if the key is not present.\n     *\n     * Unlike {@link LRUCache#dump}, which is designed to be portable and survive\n     * serialization, the `start` value is always the current timestamp, and the\n     * `ttl` is a calculated remaining time to live (negative if expired).\n     *\n     * Always returns stale values, if their info is found in the cache, so be\n     * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})\n     * if relevant.\n     */\n    info(key) {\n        const i = this.#keyMap.get(key);\n        if (i === undefined)\n            return undefined;\n        const v = this.#valList[i];\n        const value = this.#isBackgroundFetch(v)\n            ? v.__staleWhileFetching\n            : v;\n        if (value === undefined)\n            return undefined;\n        const entry = { value };\n        if (this.#ttls && this.#starts) {\n            const ttl = this.#ttls[i];\n            const start = this.#starts[i];\n            if (ttl && start) {\n                const remain = ttl - (perf.now() - start);\n                entry.ttl = remain;\n                entry.start = Date.now();\n            }\n        }\n        if (this.#sizes) {\n            entry.size = this.#sizes[i];\n        }\n        return entry;\n    }\n    /**\n     * Return an array of [key, {@link LRUCache.Entry}] tuples which can be\n     * passed to {@link LRLUCache#load}.\n     *\n     * The `start` fields are calculated relative to a portable `Date.now()`\n     * timestamp, even if `performance.now()` is available.\n     *\n     * Stale entries are always included in the `dump`, even if\n     * {@link LRUCache.OptionsBase.allowStale} is false.\n     *\n     * Note: this returns an actual array, not a generator, so it can be more\n     * easily passed around.\n     */\n    dump() {\n        const arr = [];\n        for (const i of this.#indexes({ allowStale: true })) {\n            const key = this.#keyList[i];\n            const v = this.#valList[i];\n            const value = this.#isBackgroundFetch(v)\n                ? v.__staleWhileFetching\n                : v;\n            if (value === undefined || key === undefined)\n                continue;\n            const entry = { value };\n            if (this.#ttls && this.#starts) {\n                entry.ttl = this.#ttls[i];\n                // always dump the start relative to a portable timestamp\n                // it's ok for this to be a bit slow, it's a rare operation.\n                const age = perf.now() - this.#starts[i];\n                entry.start = Math.floor(Date.now() - age);\n            }\n            if (this.#sizes) {\n                entry.size = this.#sizes[i];\n            }\n            arr.unshift([key, entry]);\n        }\n        return arr;\n    }\n    /**\n     * Reset the cache and load in the items in entries in the order listed.\n     *\n     * The shape of the resulting cache may be different if the same options are\n     * not used in both caches.\n     *\n     * The `start` fields are assumed to be calculated relative to a portable\n     * `Date.now()` timestamp, even if `performance.now()` is available.\n     */\n    load(arr) {\n        this.clear();\n        for (const [key, entry] of arr) {\n            if (entry.start) {\n                // entry.start is a portable timestamp, but we may be using\n                // node's performance.now(), so calculate the offset, so that\n                // we get the intended remaining TTL, no matter how long it's\n                // been on ice.\n                //\n                // it's ok for this to be a bit slow, it's a rare operation.\n                const age = Date.now() - entry.start;\n                entry.start = perf.now() - age;\n            }\n            this.set(key, entry.value, entry);\n        }\n    }\n    /**\n     * Add a value to the cache.\n     *\n     * Note: if `undefined` is specified as a value, this is an alias for\n     * {@link LRUCache#delete}\n     *\n     * Fields on the {@link LRUCache.SetOptions} options param will override\n     * their corresponding values in the constructor options for the scope\n     * of this single `set()` operation.\n     *\n     * If `start` is provided, then that will set the effective start\n     * time for the TTL calculation. Note that this must be a previous\n     * value of `performance.now()` if supported, or a previous value of\n     * `Date.now()` if not.\n     *\n     * Options object may also include `size`, which will prevent\n     * calling the `sizeCalculation` function and just use the specified\n     * number if it is a positive integer, and `noDisposeOnSet` which\n     * will prevent calling a `dispose` function in the case of\n     * overwrites.\n     *\n     * If the `size` (or return value of `sizeCalculation`) for a given\n     * entry is greater than `maxEntrySize`, then the item will not be\n     * added to the cache.\n     *\n     * Will update the recency of the entry.\n     *\n     * If the value is `undefined`, then this is an alias for\n     * `cache.delete(key)`. `undefined` is never stored in the cache.\n     */\n    set(k, v, setOptions = {}) {\n        if (v === undefined) {\n            this.delete(k);\n            return this;\n        }\n        const { ttl = this.ttl, start, noDisposeOnSet = this.noDisposeOnSet, sizeCalculation = this.sizeCalculation, status, } = setOptions;\n        let { noUpdateTTL = this.noUpdateTTL } = setOptions;\n        const size = this.#requireSize(k, v, setOptions.size || 0, sizeCalculation);\n        // if the item doesn't fit, don't do anything\n        // NB: maxEntrySize set to maxSize by default\n        if (this.maxEntrySize && size > this.maxEntrySize) {\n            if (status) {\n                status.set = 'miss';\n                status.maxEntrySizeExceeded = true;\n            }\n            // have to delete, in case something is there already.\n            this.#delete(k, 'set');\n            return this;\n        }\n        let index = this.#size === 0 ? undefined : this.#keyMap.get(k);\n        if (index === undefined) {\n            // addition\n            index = (this.#size === 0\n                ? this.#tail\n                : this.#free.length !== 0\n                    ? this.#free.pop()\n                    : this.#size === this.#max\n                        ? this.#evict(false)\n                        : this.#size);\n            this.#keyList[index] = k;\n            this.#valList[index] = v;\n            this.#keyMap.set(k, index);\n            this.#next[this.#tail] = index;\n            this.#prev[index] = this.#tail;\n            this.#tail = index;\n            this.#size++;\n            this.#addItemSize(index, size, status);\n            if (status)\n                status.set = 'add';\n            noUpdateTTL = false;\n        }\n        else {\n            // update\n            this.#moveToTail(index);\n            const oldVal = this.#valList[index];\n            if (v !== oldVal) {\n                if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {\n                    oldVal.__abortController.abort(new Error('replaced'));\n                    const { __staleWhileFetching: s } = oldVal;\n                    if (s !== undefined && !noDisposeOnSet) {\n                        if (this.#hasDispose) {\n                            this.#dispose?.(s, k, 'set');\n                        }\n                        if (this.#hasDisposeAfter) {\n                            this.#disposed?.push([s, k, 'set']);\n                        }\n                    }\n                }\n                else if (!noDisposeOnSet) {\n                    if (this.#hasDispose) {\n                        this.#dispose?.(oldVal, k, 'set');\n                    }\n                    if (this.#hasDisposeAfter) {\n                        this.#disposed?.push([oldVal, k, 'set']);\n                    }\n                }\n                this.#removeItemSize(index);\n                this.#addItemSize(index, size, status);\n                this.#valList[index] = v;\n                if (status) {\n                    status.set = 'replace';\n                    const oldValue = oldVal && this.#isBackgroundFetch(oldVal)\n                        ? oldVal.__staleWhileFetching\n                        : oldVal;\n                    if (oldValue !== undefined)\n                        status.oldValue = oldValue;\n                }\n            }\n            else if (status) {\n                status.set = 'update';\n            }\n        }\n        if (ttl !== 0 && !this.#ttls) {\n            this.#initializeTTLTracking();\n        }\n        if (this.#ttls) {\n            if (!noUpdateTTL) {\n                this.#setItemTTL(index, ttl, start);\n            }\n            if (status)\n                this.#statusTTL(status, index);\n        }\n        if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {\n            const dt = this.#disposed;\n            let task;\n            while ((task = dt?.shift())) {\n                this.#disposeAfter?.(...task);\n            }\n        }\n        return this;\n    }\n    /**\n     * Evict the least recently used item, returning its value or\n     * `undefined` if cache is empty.\n     */\n    pop() {\n        try {\n            while (this.#size) {\n                const val = this.#valList[this.#head];\n                this.#evict(true);\n                if (this.#isBackgroundFetch(val)) {\n                    if (val.__staleWhileFetching) {\n                        return val.__staleWhileFetching;\n                    }\n                }\n                else if (val !== undefined) {\n                    return val;\n                }\n            }\n        }\n        finally {\n            if (this.#hasDisposeAfter && this.#disposed) {\n                const dt = this.#disposed;\n                let task;\n                while ((task = dt?.shift())) {\n                    this.#disposeAfter?.(...task);\n                }\n            }\n        }\n    }\n    #evict(free) {\n        const head = this.#head;\n        const k = this.#keyList[head];\n        const v = this.#valList[head];\n        if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {\n            v.__abortController.abort(new Error('evicted'));\n        }\n        else if (this.#hasDispose || this.#hasDisposeAfter) {\n            if (this.#hasDispose) {\n                this.#dispose?.(v, k, 'evict');\n            }\n            if (this.#hasDisposeAfter) {\n                this.#disposed?.push([v, k, 'evict']);\n            }\n        }\n        this.#removeItemSize(head);\n        // if we aren't about to use the index, then null these out\n        if (free) {\n            this.#keyList[head] = undefined;\n            this.#valList[head] = undefined;\n            this.#free.push(head);\n        }\n        if (this.#size === 1) {\n            this.#head = this.#tail = 0;\n            this.#free.length = 0;\n        }\n        else {\n            this.#head = this.#next[head];\n        }\n        this.#keyMap.delete(k);\n        this.#size--;\n        return head;\n    }\n    /**\n     * Check if a key is in the cache, without updating the recency of use.\n     * Will return false if the item is stale, even though it is technically\n     * in the cache.\n     *\n     * Check if a key is in the cache, without updating the recency of\n     * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set\n     * to `true` in either the options or the constructor.\n     *\n     * Will return `false` if the item is stale, even though it is technically in\n     * the cache. The difference can be determined (if it matters) by using a\n     * `status` argument, and inspecting the `has` field.\n     *\n     * Will not update item age unless\n     * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.\n     */\n    has(k, hasOptions = {}) {\n        const { updateAgeOnHas = this.updateAgeOnHas, status } = hasOptions;\n        const index = this.#keyMap.get(k);\n        if (index !== undefined) {\n            const v = this.#valList[index];\n            if (this.#isBackgroundFetch(v) &&\n                v.__staleWhileFetching === undefined) {\n                return false;\n            }\n            if (!this.#isStale(index)) {\n                if (updateAgeOnHas) {\n                    this.#updateItemAge(index);\n                }\n                if (status) {\n                    status.has = 'hit';\n                    this.#statusTTL(status, index);\n                }\n                return true;\n            }\n            else if (status) {\n                status.has = 'stale';\n                this.#statusTTL(status, index);\n            }\n        }\n        else if (status) {\n            status.has = 'miss';\n        }\n        return false;\n    }\n    /**\n     * Like {@link LRUCache#get} but doesn't update recency or delete stale\n     * items.\n     *\n     * Returns `undefined` if the item is stale, unless\n     * {@link LRUCache.OptionsBase.allowStale} is set.\n     */\n    peek(k, peekOptions = {}) {\n        const { allowStale = this.allowStale } = peekOptions;\n        const index = this.#keyMap.get(k);\n        if (index === undefined ||\n            (!allowStale && this.#isStale(index))) {\n            return;\n        }\n        const v = this.#valList[index];\n        // either stale and allowed, or forcing a refresh of non-stale value\n        return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;\n    }\n    #backgroundFetch(k, index, options, context) {\n        const v = index === undefined ? undefined : this.#valList[index];\n        if (this.#isBackgroundFetch(v)) {\n            return v;\n        }\n        const ac = new AC();\n        const { signal } = options;\n        // when/if our AC signals, then stop listening to theirs.\n        signal?.addEventListener('abort', () => ac.abort(signal.reason), {\n            signal: ac.signal,\n        });\n        const fetchOpts = {\n            signal: ac.signal,\n            options,\n            context,\n        };\n        const cb = (v, updateCache = false) => {\n            const { aborted } = ac.signal;\n            const ignoreAbort = options.ignoreFetchAbort && v !== undefined;\n            if (options.status) {\n                if (aborted && !updateCache) {\n                    options.status.fetchAborted = true;\n                    options.status.fetchError = ac.signal.reason;\n                    if (ignoreAbort)\n                        options.status.fetchAbortIgnored = true;\n                }\n                else {\n                    options.status.fetchResolved = true;\n                }\n            }\n            if (aborted && !ignoreAbort && !updateCache) {\n                return fetchFail(ac.signal.reason);\n            }\n            // either we didn't abort, and are still here, or we did, and ignored\n            const bf = p;\n            if (this.#valList[index] === p) {\n                if (v === undefined) {\n                    if (bf.__staleWhileFetching) {\n                        this.#valList[index] = bf.__staleWhileFetching;\n                    }\n                    else {\n                        this.#delete(k, 'fetch');\n                    }\n                }\n                else {\n                    if (options.status)\n                        options.status.fetchUpdated = true;\n                    this.set(k, v, fetchOpts.options);\n                }\n            }\n            return v;\n        };\n        const eb = (er) => {\n            if (options.status) {\n                options.status.fetchRejected = true;\n                options.status.fetchError = er;\n            }\n            return fetchFail(er);\n        };\n        const fetchFail = (er) => {\n            const { aborted } = ac.signal;\n            const allowStaleAborted = aborted && options.allowStaleOnFetchAbort;\n            const allowStale = allowStaleAborted || options.allowStaleOnFetchRejection;\n            const noDelete = allowStale || options.noDeleteOnFetchRejection;\n            const bf = p;\n            if (this.#valList[index] === p) {\n                // if we allow stale on fetch rejections, then we need to ensure that\n                // the stale value is not removed from the cache when the fetch fails.\n                const del = !noDelete || bf.__staleWhileFetching === undefined;\n                if (del) {\n                    this.#delete(k, 'fetch');\n                }\n                else if (!allowStaleAborted) {\n                    // still replace the *promise* with the stale value,\n                    // since we are done with the promise at this point.\n                    // leave it untouched if we're still waiting for an\n                    // aborted background fetch that hasn't yet returned.\n                    this.#valList[index] = bf.__staleWhileFetching;\n                }\n            }\n            if (allowStale) {\n                if (options.status && bf.__staleWhileFetching !== undefined) {\n                    options.status.returnedStale = true;\n                }\n                return bf.__staleWhileFetching;\n            }\n            else if (bf.__returned === bf) {\n                throw er;\n            }\n        };\n        const pcall = (res, rej) => {\n            const fmp = this.#fetchMethod?.(k, v, fetchOpts);\n            if (fmp && fmp instanceof Promise) {\n                fmp.then(v => res(v === undefined ? undefined : v), rej);\n            }\n            // ignored, we go until we finish, regardless.\n            // defer check until we are actually aborting,\n            // so fetchMethod can override.\n            ac.signal.addEventListener('abort', () => {\n                if (!options.ignoreFetchAbort ||\n                    options.allowStaleOnFetchAbort) {\n                    res(undefined);\n                    // when it eventually resolves, update the cache.\n                    if (options.allowStaleOnFetchAbort) {\n                        res = v => cb(v, true);\n                    }\n                }\n            });\n        };\n        if (options.status)\n            options.status.fetchDispatched = true;\n        const p = new Promise(pcall).then(cb, eb);\n        const bf = Object.assign(p, {\n            __abortController: ac,\n            __staleWhileFetching: v,\n            __returned: undefined,\n        });\n        if (index === undefined) {\n            // internal, don't expose status.\n            this.set(k, bf, { ...fetchOpts.options, status: undefined });\n            index = this.#keyMap.get(k);\n        }\n        else {\n            this.#valList[index] = bf;\n        }\n        return bf;\n    }\n    #isBackgroundFetch(p) {\n        if (!this.#hasFetchMethod)\n            return false;\n        const b = p;\n        return (!!b &&\n            b instanceof Promise &&\n            b.hasOwnProperty('__staleWhileFetching') &&\n            b.__abortController instanceof AC);\n    }\n    async fetch(k, fetchOptions = {}) {\n        const { \n        // get options\n        allowStale = this.allowStale, updateAgeOnGet = this.updateAgeOnGet, noDeleteOnStaleGet = this.noDeleteOnStaleGet, \n        // set options\n        ttl = this.ttl, noDisposeOnSet = this.noDisposeOnSet, size = 0, sizeCalculation = this.sizeCalculation, noUpdateTTL = this.noUpdateTTL, \n        // fetch exclusive options\n        noDeleteOnFetchRejection = this.noDeleteOnFetchRejection, allowStaleOnFetchRejection = this.allowStaleOnFetchRejection, ignoreFetchAbort = this.ignoreFetchAbort, allowStaleOnFetchAbort = this.allowStaleOnFetchAbort, context, forceRefresh = false, status, signal, } = fetchOptions;\n        if (!this.#hasFetchMethod) {\n            if (status)\n                status.fetch = 'get';\n            return this.get(k, {\n                allowStale,\n                updateAgeOnGet,\n                noDeleteOnStaleGet,\n                status,\n            });\n        }\n        const options = {\n            allowStale,\n            updateAgeOnGet,\n            noDeleteOnStaleGet,\n            ttl,\n            noDisposeOnSet,\n            size,\n            sizeCalculation,\n            noUpdateTTL,\n            noDeleteOnFetchRejection,\n            allowStaleOnFetchRejection,\n            allowStaleOnFetchAbort,\n            ignoreFetchAbort,\n            status,\n            signal,\n        };\n        let index = this.#keyMap.get(k);\n        if (index === undefined) {\n            if (status)\n                status.fetch = 'miss';\n            const p = this.#backgroundFetch(k, index, options, context);\n            return (p.__returned = p);\n        }\n        else {\n            // in cache, maybe already fetching\n            const v = this.#valList[index];\n            if (this.#isBackgroundFetch(v)) {\n                const stale = allowStale && v.__staleWhileFetching !== undefined;\n                if (status) {\n                    status.fetch = 'inflight';\n                    if (stale)\n                        status.returnedStale = true;\n                }\n                return stale ? v.__staleWhileFetching : (v.__returned = v);\n            }\n            // if we force a refresh, that means do NOT serve the cached value,\n            // unless we are already in the process of refreshing the cache.\n            const isStale = this.#isStale(index);\n            if (!forceRefresh && !isStale) {\n                if (status)\n                    status.fetch = 'hit';\n                this.#moveToTail(index);\n                if (updateAgeOnGet) {\n                    this.#updateItemAge(index);\n                }\n                if (status)\n                    this.#statusTTL(status, index);\n                return v;\n            }\n            // ok, it is stale or a forced refresh, and not already fetching.\n            // refresh the cache.\n            const p = this.#backgroundFetch(k, index, options, context);\n            const hasStale = p.__staleWhileFetching !== undefined;\n            const staleVal = hasStale && allowStale;\n            if (status) {\n                status.fetch = isStale ? 'stale' : 'refresh';\n                if (staleVal && isStale)\n                    status.returnedStale = true;\n            }\n            return staleVal ? p.__staleWhileFetching : (p.__returned = p);\n        }\n    }\n    async forceFetch(k, fetchOptions = {}) {\n        const v = await this.fetch(k, fetchOptions);\n        if (v === undefined)\n            throw new Error('fetch() returned undefined');\n        return v;\n    }\n    memo(k, memoOptions = {}) {\n        const memoMethod = this.#memoMethod;\n        if (!memoMethod) {\n            throw new Error('no memoMethod provided to constructor');\n        }\n        const { context, forceRefresh, ...options } = memoOptions;\n        const v = this.get(k, options);\n        if (!forceRefresh && v !== undefined)\n            return v;\n        const vv = memoMethod(k, v, {\n            options,\n            context,\n        });\n        this.set(k, vv, options);\n        return vv;\n    }\n    /**\n     * Return a value from the cache. Will update the recency of the cache\n     * entry found.\n     *\n     * If the key is not found, get() will return `undefined`.\n     */\n    get(k, getOptions = {}) {\n        const { allowStale = this.allowStale, updateAgeOnGet = this.updateAgeOnGet, noDeleteOnStaleGet = this.noDeleteOnStaleGet, status, } = getOptions;\n        const index = this.#keyMap.get(k);\n        if (index !== undefined) {\n            const value = this.#valList[index];\n            const fetching = this.#isBackgroundFetch(value);\n            if (status)\n                this.#statusTTL(status, index);\n            if (this.#isStale(index)) {\n                if (status)\n                    status.get = 'stale';\n                // delete only if not an in-flight background fetch\n                if (!fetching) {\n                    if (!noDeleteOnStaleGet) {\n                        this.#delete(k, 'expire');\n                    }\n                    if (status && allowStale)\n                        status.returnedStale = true;\n                    return allowStale ? value : undefined;\n                }\n                else {\n                    if (status &&\n                        allowStale &&\n                        value.__staleWhileFetching !== undefined) {\n                        status.returnedStale = true;\n                    }\n                    return allowStale ? value.__staleWhileFetching : undefined;\n                }\n            }\n            else {\n                if (status)\n                    status.get = 'hit';\n                // if we're currently fetching it, we don't actually have it yet\n                // it's not stale, which means this isn't a staleWhileRefetching.\n                // If it's not stale, and fetching, AND has a __staleWhileFetching\n                // value, then that means the user fetched with {forceRefresh:true},\n                // so it's safe to return that value.\n                if (fetching) {\n                    return value.__staleWhileFetching;\n                }\n                this.#moveToTail(index);\n                if (updateAgeOnGet) {\n                    this.#updateItemAge(index);\n                }\n                return value;\n            }\n        }\n        else if (status) {\n            status.get = 'miss';\n        }\n    }\n    #connect(p, n) {\n        this.#prev[n] = p;\n        this.#next[p] = n;\n    }\n    #moveToTail(index) {\n        // if tail already, nothing to do\n        // if head, move head to next[index]\n        // else\n        //   move next[prev[index]] to next[index] (head has no prev)\n        //   move prev[next[index]] to prev[index]\n        // prev[index] = tail\n        // next[tail] = index\n        // tail = index\n        if (index !== this.#tail) {\n            if (index === this.#head) {\n                this.#head = this.#next[index];\n            }\n            else {\n                this.#connect(this.#prev[index], this.#next[index]);\n            }\n            this.#connect(this.#tail, index);\n            this.#tail = index;\n        }\n    }\n    /**\n     * Deletes a key out of the cache.\n     *\n     * Returns true if the key was deleted, false otherwise.\n     */\n    delete(k) {\n        return this.#delete(k, 'delete');\n    }\n    #delete(k, reason) {\n        let deleted = false;\n        if (this.#size !== 0) {\n            const index = this.#keyMap.get(k);\n            if (index !== undefined) {\n                deleted = true;\n                if (this.#size === 1) {\n                    this.#clear(reason);\n                }\n                else {\n                    this.#removeItemSize(index);\n                    const v = this.#valList[index];\n                    if (this.#isBackgroundFetch(v)) {\n                        v.__abortController.abort(new Error('deleted'));\n                    }\n                    else if (this.#hasDispose || this.#hasDisposeAfter) {\n                        if (this.#hasDispose) {\n                            this.#dispose?.(v, k, reason);\n                        }\n                        if (this.#hasDisposeAfter) {\n                            this.#disposed?.push([v, k, reason]);\n                        }\n                    }\n                    this.#keyMap.delete(k);\n                    this.#keyList[index] = undefined;\n                    this.#valList[index] = undefined;\n                    if (index === this.#tail) {\n                        this.#tail = this.#prev[index];\n                    }\n                    else if (index === this.#head) {\n                        this.#head = this.#next[index];\n                    }\n                    else {\n                        const pi = this.#prev[index];\n                        this.#next[pi] = this.#next[index];\n                        const ni = this.#next[index];\n                        this.#prev[ni] = this.#prev[index];\n                    }\n                    this.#size--;\n                    this.#free.push(index);\n                }\n            }\n        }\n        if (this.#hasDisposeAfter && this.#disposed?.length) {\n            const dt = this.#disposed;\n            let task;\n            while ((task = dt?.shift())) {\n                this.#disposeAfter?.(...task);\n            }\n        }\n        return deleted;\n    }\n    /**\n     * Clear the cache entirely, throwing away all values.\n     */\n    clear() {\n        return this.#clear('delete');\n    }\n    #clear(reason) {\n        for (const index of this.#rindexes({ allowStale: true })) {\n            const v = this.#valList[index];\n            if (this.#isBackgroundFetch(v)) {\n                v.__abortController.abort(new Error('deleted'));\n            }\n            else {\n                const k = this.#keyList[index];\n                if (this.#hasDispose) {\n                    this.#dispose?.(v, k, reason);\n                }\n                if (this.#hasDisposeAfter) {\n                    this.#disposed?.push([v, k, reason]);\n                }\n            }\n        }\n        this.#keyMap.clear();\n        this.#valList.fill(undefined);\n        this.#keyList.fill(undefined);\n        if (this.#ttls && this.#starts) {\n            this.#ttls.fill(0);\n            this.#starts.fill(0);\n        }\n        if (this.#sizes) {\n            this.#sizes.fill(0);\n        }\n        this.#head = 0;\n        this.#tail = 0;\n        this.#free.length = 0;\n        this.#calculatedSize = 0;\n        this.#size = 0;\n        if (this.#hasDisposeAfter && this.#disposed) {\n            const dt = this.#disposed;\n            let task;\n            while ((task = dt?.shift())) {\n                this.#disposeAfter?.(...task);\n            }\n        }\n    }\n}\nexports.LRUCache = LRUCache;\n//# sourceMappingURL=index.js.map","'use strict';\n\nfunction getDefaultExportFromCjs (x) {\n\treturn x && x.__esModule && Object.prototype.hasOwnProperty.call(x, 'default') ? x['default'] : x;\n}\n\nconst CRC_TABLE = new Int32Array([\n  0,\n  1996959894,\n  3993919788,\n  2567524794,\n  124634137,\n  1886057615,\n  3915621685,\n  2657392035,\n  249268274,\n  2044508324,\n  3772115230,\n  2547177864,\n  162941995,\n  2125561021,\n  3887607047,\n  2428444049,\n  498536548,\n  1789927666,\n  4089016648,\n  2227061214,\n  450548861,\n  1843258603,\n  4107580753,\n  2211677639,\n  325883990,\n  1684777152,\n  4251122042,\n  2321926636,\n  335633487,\n  1661365465,\n  4195302755,\n  2366115317,\n  997073096,\n  1281953886,\n  3579855332,\n  2724688242,\n  1006888145,\n  1258607687,\n  3524101629,\n  2768942443,\n  901097722,\n  1119000684,\n  3686517206,\n  2898065728,\n  853044451,\n  1172266101,\n  3705015759,\n  2882616665,\n  651767980,\n  1373503546,\n  3369554304,\n  3218104598,\n  565507253,\n  1454621731,\n  3485111705,\n  3099436303,\n  671266974,\n  1594198024,\n  3322730930,\n  2970347812,\n  795835527,\n  1483230225,\n  3244367275,\n  3060149565,\n  1994146192,\n  31158534,\n  2563907772,\n  4023717930,\n  1907459465,\n  112637215,\n  2680153253,\n  3904427059,\n  2013776290,\n  251722036,\n  2517215374,\n  3775830040,\n  2137656763,\n  141376813,\n  2439277719,\n  3865271297,\n  1802195444,\n  476864866,\n  2238001368,\n  4066508878,\n  1812370925,\n  453092731,\n  2181625025,\n  4111451223,\n  1706088902,\n  314042704,\n  2344532202,\n  4240017532,\n  1658658271,\n  366619977,\n  2362670323,\n  4224994405,\n  1303535960,\n  984961486,\n  2747007092,\n  3569037538,\n  1256170817,\n  1037604311,\n  2765210733,\n  3554079995,\n  1131014506,\n  879679996,\n  2909243462,\n  3663771856,\n  1141124467,\n  855842277,\n  2852801631,\n  3708648649,\n  1342533948,\n  654459306,\n  3188396048,\n  3373015174,\n  1466479909,\n  544179635,\n  3110523913,\n  3462522015,\n  1591671054,\n  702138776,\n  2966460450,\n  3352799412,\n  1504918807,\n  783551873,\n  3082640443,\n  3233442989,\n  3988292384,\n  2596254646,\n  62317068,\n  1957810842,\n  3939845945,\n  2647816111,\n  81470997,\n  1943803523,\n  3814918930,\n  2489596804,\n  225274430,\n  2053790376,\n  3826175755,\n  2466906013,\n  167816743,\n  2097651377,\n  4027552580,\n  2265490386,\n  503444072,\n  1762050814,\n  4150417245,\n  2154129355,\n  426522225,\n  1852507879,\n  4275313526,\n  2312317920,\n  282753626,\n  1742555852,\n  4189708143,\n  2394877945,\n  397917763,\n  1622183637,\n  3604390888,\n  2714866558,\n  953729732,\n  1340076626,\n  3518719985,\n  2797360999,\n  1068828381,\n  1219638859,\n  3624741850,\n  2936675148,\n  906185462,\n  1090812512,\n  3747672003,\n  2825379669,\n  829329135,\n  1181335161,\n  3412177804,\n  3160834842,\n  628085408,\n  1382605366,\n  3423369109,\n  3138078467,\n  570562233,\n  1426400815,\n  3317316542,\n  2998733608,\n  733239954,\n  1555261956,\n  3268935591,\n  3050360625,\n  752459403,\n  1541320221,\n  2607071920,\n  3965973030,\n  1969922972,\n  40735498,\n  2617837225,\n  3943577151,\n  1913087877,\n  83908371,\n  2512341634,\n  3803740692,\n  2075208622,\n  213261112,\n  2463272603,\n  3855990285,\n  2094854071,\n  198958881,\n  2262029012,\n  4057260610,\n  1759359992,\n  534414190,\n  2176718541,\n  4139329115,\n  1873836001,\n  414664567,\n  2282248934,\n  4279200368,\n  1711684554,\n  285281116,\n  2405801727,\n  4167216745,\n  1634467795,\n  376229701,\n  2685067896,\n  3608007406,\n  1308918612,\n  956543938,\n  2808555105,\n  3495958263,\n  1231636301,\n  1047427035,\n  2932959818,\n  3654703836,\n  1088359270,\n  936918e3,\n  2847714899,\n  3736837829,\n  1202900863,\n  817233897,\n  3183342108,\n  3401237130,\n  1404277552,\n  615818150,\n  3134207493,\n  3453421203,\n  1423857449,\n  601450431,\n  3009837614,\n  3294710456,\n  1567103746,\n  711928724,\n  3020668471,\n  3272380065,\n  1510334235,\n  755167117\n]);\nfunction ensureBuffer(input) {\n  if (Buffer.isBuffer(input)) {\n    return input;\n  }\n  if (typeof input === \"number\") {\n    return Buffer.alloc(input);\n  } else if (typeof input === \"string\") {\n    return Buffer.from(input);\n  } else {\n    throw new Error(\"input must be buffer, number, or string, received \" + typeof input);\n  }\n}\nfunction bufferizeInt(num) {\n  const tmp = ensureBuffer(4);\n  tmp.writeInt32BE(num, 0);\n  return tmp;\n}\nfunction _crc32(buf, previous) {\n  buf = ensureBuffer(buf);\n  if (Buffer.isBuffer(previous)) {\n    previous = previous.readUInt32BE(0);\n  }\n  let crc = ~~previous ^ -1;\n  for (var n = 0; n < buf.length; n++) {\n    crc = CRC_TABLE[(crc ^ buf[n]) & 255] ^ crc >>> 8;\n  }\n  return crc ^ -1;\n}\nfunction crc32() {\n  return bufferizeInt(_crc32.apply(null, arguments));\n}\ncrc32.signed = function() {\n  return _crc32.apply(null, arguments);\n};\ncrc32.unsigned = function() {\n  return _crc32.apply(null, arguments) >>> 0;\n};\nvar bufferCrc32 = crc32;\n\nconst index = /*@__PURE__*/getDefaultExportFromCjs(bufferCrc32);\n\nmodule.exports = index;\n","(()=>{\"use strict\";var t={d:(e,n)=>{for(var i in n)t.o(n,i)&&!t.o(e,i)&&Object.defineProperty(e,i,{enumerable:!0,get:n[i]})},o:(t,e)=>Object.prototype.hasOwnProperty.call(t,e),r:t=>{\"undefined\"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:\"Module\"}),Object.defineProperty(t,\"__esModule\",{value:!0})}},e={};t.r(e),t.d(e,{XMLBuilder:()=>dt,XMLParser:()=>it,XMLValidator:()=>gt});const n=\":A-Za-z_\\\\u00C0-\\\\u00D6\\\\u00D8-\\\\u00F6\\\\u00F8-\\\\u02FF\\\\u0370-\\\\u037D\\\\u037F-\\\\u1FFF\\\\u200C-\\\\u200D\\\\u2070-\\\\u218F\\\\u2C00-\\\\u2FEF\\\\u3001-\\\\uD7FF\\\\uF900-\\\\uFDCF\\\\uFDF0-\\\\uFFFD\",i=new RegExp(\"^[\"+n+\"][\"+n+\"\\\\-.\\\\d\\\\u00B7\\\\u0300-\\\\u036F\\\\u203F-\\\\u2040]*$\");function s(t,e){const n=[];let i=e.exec(t);for(;i;){const s=[];s.startIndex=e.lastIndex-i[0].length;const r=i.length;for(let t=0;t<r;t++)s.push(i[t]);n.push(s),i=e.exec(t)}return n}const r=function(t){return!(null==i.exec(t))},o={allowBooleanAttributes:!1,unpairedTags:[]};function a(t,e){e=Object.assign({},o,e);const n=[];let i=!1,s=!1;\"\\ufeff\"===t[0]&&(t=t.substr(1));for(let o=0;o<t.length;o++)if(\"<\"===t[o]&&\"?\"===t[o+1]){if(o+=2,o=u(t,o),o.err)return o}else{if(\"<\"!==t[o]){if(l(t[o]))continue;return m(\"InvalidChar\",\"char '\"+t[o]+\"' is not expected.\",b(t,o))}{let a=o;if(o++,\"!\"===t[o]){o=h(t,o);continue}{let d=!1;\"/\"===t[o]&&(d=!0,o++);let p=\"\";for(;o<t.length&&\">\"!==t[o]&&\" \"!==t[o]&&\"\\t\"!==t[o]&&\"\\n\"!==t[o]&&\"\\r\"!==t[o];o++)p+=t[o];if(p=p.trim(),\"/\"===p[p.length-1]&&(p=p.substring(0,p.length-1),o--),!r(p)){let e;return e=0===p.trim().length?\"Invalid space after '<'.\":\"Tag '\"+p+\"' is an invalid name.\",m(\"InvalidTag\",e,b(t,o))}const c=f(t,o);if(!1===c)return m(\"InvalidAttr\",\"Attributes for '\"+p+\"' have open quote.\",b(t,o));let E=c.value;if(o=c.index,\"/\"===E[E.length-1]){const n=o-E.length;E=E.substring(0,E.length-1);const s=g(E,e);if(!0!==s)return m(s.err.code,s.err.msg,b(t,n+s.err.line));i=!0}else if(d){if(!c.tagClosed)return m(\"InvalidTag\",\"Closing tag '\"+p+\"' doesn't have proper closing.\",b(t,o));if(E.trim().length>0)return m(\"InvalidTag\",\"Closing tag '\"+p+\"' can't have attributes or invalid starting.\",b(t,a));if(0===n.length)return m(\"InvalidTag\",\"Closing tag '\"+p+\"' has not been opened.\",b(t,a));{const e=n.pop();if(p!==e.tagName){let n=b(t,e.tagStartPos);return m(\"InvalidTag\",\"Expected closing tag '\"+e.tagName+\"' (opened in line \"+n.line+\", col \"+n.col+\") instead of closing tag '\"+p+\"'.\",b(t,a))}0==n.length&&(s=!0)}}else{const r=g(E,e);if(!0!==r)return m(r.err.code,r.err.msg,b(t,o-E.length+r.err.line));if(!0===s)return m(\"InvalidXml\",\"Multiple possible root nodes found.\",b(t,o));-1!==e.unpairedTags.indexOf(p)||n.push({tagName:p,tagStartPos:a}),i=!0}for(o++;o<t.length;o++)if(\"<\"===t[o]){if(\"!\"===t[o+1]){o++,o=h(t,o);continue}if(\"?\"!==t[o+1])break;if(o=u(t,++o),o.err)return o}else if(\"&\"===t[o]){const e=x(t,o);if(-1==e)return m(\"InvalidChar\",\"char '&' is not expected.\",b(t,o));o=e}else if(!0===s&&!l(t[o]))return m(\"InvalidXml\",\"Extra text at the end\",b(t,o));\"<\"===t[o]&&o--}}}return i?1==n.length?m(\"InvalidTag\",\"Unclosed tag '\"+n[0].tagName+\"'.\",b(t,n[0].tagStartPos)):!(n.length>0)||m(\"InvalidXml\",\"Invalid '\"+JSON.stringify(n.map((t=>t.tagName)),null,4).replace(/\\r?\\n/g,\"\")+\"' found.\",{line:1,col:1}):m(\"InvalidXml\",\"Start tag expected.\",1)}function l(t){return\" \"===t||\"\\t\"===t||\"\\n\"===t||\"\\r\"===t}function u(t,e){const n=e;for(;e<t.length;e++)if(\"?\"!=t[e]&&\" \"!=t[e]);else{const i=t.substr(n,e-n);if(e>5&&\"xml\"===i)return m(\"InvalidXml\",\"XML declaration allowed only at the start of the document.\",b(t,e));if(\"?\"==t[e]&&\">\"==t[e+1]){e++;break}}return e}function h(t,e){if(t.length>e+5&&\"-\"===t[e+1]&&\"-\"===t[e+2]){for(e+=3;e<t.length;e++)if(\"-\"===t[e]&&\"-\"===t[e+1]&&\">\"===t[e+2]){e+=2;break}}else if(t.length>e+8&&\"D\"===t[e+1]&&\"O\"===t[e+2]&&\"C\"===t[e+3]&&\"T\"===t[e+4]&&\"Y\"===t[e+5]&&\"P\"===t[e+6]&&\"E\"===t[e+7]){let n=1;for(e+=8;e<t.length;e++)if(\"<\"===t[e])n++;else if(\">\"===t[e]&&(n--,0===n))break}else if(t.length>e+9&&\"[\"===t[e+1]&&\"C\"===t[e+2]&&\"D\"===t[e+3]&&\"A\"===t[e+4]&&\"T\"===t[e+5]&&\"A\"===t[e+6]&&\"[\"===t[e+7])for(e+=8;e<t.length;e++)if(\"]\"===t[e]&&\"]\"===t[e+1]&&\">\"===t[e+2]){e+=2;break}return e}const d='\"',p=\"'\";function f(t,e){let n=\"\",i=\"\",s=!1;for(;e<t.length;e++){if(t[e]===d||t[e]===p)\"\"===i?i=t[e]:i!==t[e]||(i=\"\");else if(\">\"===t[e]&&\"\"===i){s=!0;break}n+=t[e]}return\"\"===i&&{value:n,index:e,tagClosed:s}}const c=new RegExp(\"(\\\\s*)([^\\\\s=]+)(\\\\s*=)?(\\\\s*(['\\\"])(([\\\\s\\\\S])*?)\\\\5)?\",\"g\");function g(t,e){const n=s(t,c),i={};for(let t=0;t<n.length;t++){if(0===n[t][1].length)return m(\"InvalidAttr\",\"Attribute '\"+n[t][2]+\"' has no space in starting.\",N(n[t]));if(void 0!==n[t][3]&&void 0===n[t][4])return m(\"InvalidAttr\",\"Attribute '\"+n[t][2]+\"' is without value.\",N(n[t]));if(void 0===n[t][3]&&!e.allowBooleanAttributes)return m(\"InvalidAttr\",\"boolean attribute '\"+n[t][2]+\"' is not allowed.\",N(n[t]));const s=n[t][2];if(!E(s))return m(\"InvalidAttr\",\"Attribute '\"+s+\"' is an invalid name.\",N(n[t]));if(i.hasOwnProperty(s))return m(\"InvalidAttr\",\"Attribute '\"+s+\"' is repeated.\",N(n[t]));i[s]=1}return!0}function x(t,e){if(\";\"===t[++e])return-1;if(\"#\"===t[e])return function(t,e){let n=/\\d/;for(\"x\"===t[e]&&(e++,n=/[\\da-fA-F]/);e<t.length;e++){if(\";\"===t[e])return e;if(!t[e].match(n))break}return-1}(t,++e);let n=0;for(;e<t.length;e++,n++)if(!(t[e].match(/\\w/)&&n<20)){if(\";\"===t[e])break;return-1}return e}function m(t,e,n){return{err:{code:t,msg:e,line:n.line||n,col:n.col}}}function E(t){return r(t)}function b(t,e){const n=t.substring(0,e).split(/\\r?\\n/);return{line:n.length,col:n[n.length-1].length+1}}function N(t){return t.startIndex+t[1].length}const y={preserveOrder:!1,attributeNamePrefix:\"@_\",attributesGroupName:!1,textNodeName:\"#text\",ignoreAttributes:!0,removeNSPrefix:!1,allowBooleanAttributes:!1,parseTagValue:!0,parseAttributeValue:!1,trimValues:!0,cdataPropName:!1,numberParseOptions:{hex:!0,leadingZeros:!0,eNotation:!0},tagValueProcessor:function(t,e){return e},attributeValueProcessor:function(t,e){return e},stopNodes:[],alwaysCreateTextNode:!1,isArray:()=>!1,commentPropName:!1,unpairedTags:[],processEntities:!0,htmlEntities:!1,ignoreDeclaration:!1,ignorePiTags:!1,transformTagName:!1,transformAttributeName:!1,updateTag:function(t,e,n){return t},captureMetaData:!1};function T(t){return\"boolean\"==typeof t?{enabled:t,maxEntitySize:1e4,maxExpansionDepth:10,maxTotalExpansions:1e3,maxExpandedLength:1e5,allowedTags:null,tagFilter:null}:\"object\"==typeof t&&null!==t?{enabled:!1!==t.enabled,maxEntitySize:t.maxEntitySize??1e4,maxExpansionDepth:t.maxExpansionDepth??10,maxTotalExpansions:t.maxTotalExpansions??1e3,maxExpandedLength:t.maxExpandedLength??1e5,allowedTags:t.allowedTags??null,tagFilter:t.tagFilter??null}:T(!0)}const w=function(t){const e=Object.assign({},y,t);return e.processEntities=T(e.processEntities),e};let v;v=\"function\"!=typeof Symbol?\"@@xmlMetadata\":Symbol(\"XML Node Metadata\");class I{constructor(t){this.tagname=t,this.child=[],this[\":@\"]={}}add(t,e){\"__proto__\"===t&&(t=\"#__proto__\"),this.child.push({[t]:e})}addChild(t,e){\"__proto__\"===t.tagname&&(t.tagname=\"#__proto__\"),t[\":@\"]&&Object.keys(t[\":@\"]).length>0?this.child.push({[t.tagname]:t.child,\":@\":t[\":@\"]}):this.child.push({[t.tagname]:t.child}),void 0!==e&&(this.child[this.child.length-1][v]={startIndex:e})}static getMetaDataSymbol(){return v}}class O{constructor(t){this.suppressValidationErr=!t,this.options=t}readDocType(t,e){const n={};if(\"O\"!==t[e+3]||\"C\"!==t[e+4]||\"T\"!==t[e+5]||\"Y\"!==t[e+6]||\"P\"!==t[e+7]||\"E\"!==t[e+8])throw new Error(\"Invalid Tag instead of DOCTYPE\");{e+=9;let i=1,s=!1,r=!1,o=\"\";for(;e<t.length;e++)if(\"<\"!==t[e]||r)if(\">\"===t[e]){if(r?\"-\"===t[e-1]&&\"-\"===t[e-2]&&(r=!1,i--):i--,0===i)break}else\"[\"===t[e]?s=!0:o+=t[e];else{if(s&&A(t,\"!ENTITY\",e)){let i,s;if(e+=7,[i,s,e]=this.readEntityExp(t,e+1,this.suppressValidationErr),-1===s.indexOf(\"&\")){const t=i.replace(/[.\\-+*:]/g,\"\\\\.\");n[i]={regx:RegExp(`&${t};`,\"g\"),val:s}}}else if(s&&A(t,\"!ELEMENT\",e)){e+=8;const{index:n}=this.readElementExp(t,e+1);e=n}else if(s&&A(t,\"!ATTLIST\",e))e+=8;else if(s&&A(t,\"!NOTATION\",e)){e+=9;const{index:n}=this.readNotationExp(t,e+1,this.suppressValidationErr);e=n}else{if(!A(t,\"!--\",e))throw new Error(\"Invalid DOCTYPE\");r=!0}i++,o=\"\"}if(0!==i)throw new Error(\"Unclosed DOCTYPE\")}return{entities:n,i:e}}readEntityExp(t,e){e=P(t,e);let n=\"\";for(;e<t.length&&!/\\s/.test(t[e])&&'\"'!==t[e]&&\"'\"!==t[e];)n+=t[e],e++;if(S(n),e=P(t,e),!this.suppressValidationErr){if(\"SYSTEM\"===t.substring(e,e+6).toUpperCase())throw new Error(\"External entities are not supported\");if(\"%\"===t[e])throw new Error(\"Parameter entities are not supported\")}let i=\"\";if([e,i]=this.readIdentifierVal(t,e,\"entity\"),!1!==this.options.enabled&&this.options.maxEntitySize&&i.length>this.options.maxEntitySize)throw new Error(`Entity \"${n}\" size (${i.length}) exceeds maximum allowed size (${this.options.maxEntitySize})`);return[n,i,--e]}readNotationExp(t,e){e=P(t,e);let n=\"\";for(;e<t.length&&!/\\s/.test(t[e]);)n+=t[e],e++;!this.suppressValidationErr&&S(n),e=P(t,e);const i=t.substring(e,e+6).toUpperCase();if(!this.suppressValidationErr&&\"SYSTEM\"!==i&&\"PUBLIC\"!==i)throw new Error(`Expected SYSTEM or PUBLIC, found \"${i}\"`);e+=i.length,e=P(t,e);let s=null,r=null;if(\"PUBLIC\"===i)[e,s]=this.readIdentifierVal(t,e,\"publicIdentifier\"),'\"'!==t[e=P(t,e)]&&\"'\"!==t[e]||([e,r]=this.readIdentifierVal(t,e,\"systemIdentifier\"));else if(\"SYSTEM\"===i&&([e,r]=this.readIdentifierVal(t,e,\"systemIdentifier\"),!this.suppressValidationErr&&!r))throw new Error(\"Missing mandatory system identifier for SYSTEM notation\");return{notationName:n,publicIdentifier:s,systemIdentifier:r,index:--e}}readIdentifierVal(t,e,n){let i=\"\";const s=t[e];if('\"'!==s&&\"'\"!==s)throw new Error(`Expected quoted string, found \"${s}\"`);for(e++;e<t.length&&t[e]!==s;)i+=t[e],e++;if(t[e]!==s)throw new Error(`Unterminated ${n} value`);return[++e,i]}readElementExp(t,e){e=P(t,e);let n=\"\";for(;e<t.length&&!/\\s/.test(t[e]);)n+=t[e],e++;if(!this.suppressValidationErr&&!r(n))throw new Error(`Invalid element name: \"${n}\"`);let i=\"\";if(\"E\"===t[e=P(t,e)]&&A(t,\"MPTY\",e))e+=4;else if(\"A\"===t[e]&&A(t,\"NY\",e))e+=2;else if(\"(\"===t[e]){for(e++;e<t.length&&\")\"!==t[e];)i+=t[e],e++;if(\")\"!==t[e])throw new Error(\"Unterminated content model\")}else if(!this.suppressValidationErr)throw new Error(`Invalid Element Expression, found \"${t[e]}\"`);return{elementName:n,contentModel:i.trim(),index:e}}readAttlistExp(t,e){e=P(t,e);let n=\"\";for(;e<t.length&&!/\\s/.test(t[e]);)n+=t[e],e++;S(n),e=P(t,e);let i=\"\";for(;e<t.length&&!/\\s/.test(t[e]);)i+=t[e],e++;if(!S(i))throw new Error(`Invalid attribute name: \"${i}\"`);e=P(t,e);let s=\"\";if(\"NOTATION\"===t.substring(e,e+8).toUpperCase()){if(s=\"NOTATION\",\"(\"!==t[e=P(t,e+=8)])throw new Error(`Expected '(', found \"${t[e]}\"`);e++;let n=[];for(;e<t.length&&\")\"!==t[e];){let i=\"\";for(;e<t.length&&\"|\"!==t[e]&&\")\"!==t[e];)i+=t[e],e++;if(i=i.trim(),!S(i))throw new Error(`Invalid notation name: \"${i}\"`);n.push(i),\"|\"===t[e]&&(e++,e=P(t,e))}if(\")\"!==t[e])throw new Error(\"Unterminated list of notations\");e++,s+=\" (\"+n.join(\"|\")+\")\"}else{for(;e<t.length&&!/\\s/.test(t[e]);)s+=t[e],e++;const n=[\"CDATA\",\"ID\",\"IDREF\",\"IDREFS\",\"ENTITY\",\"ENTITIES\",\"NMTOKEN\",\"NMTOKENS\"];if(!this.suppressValidationErr&&!n.includes(s.toUpperCase()))throw new Error(`Invalid attribute type: \"${s}\"`)}e=P(t,e);let r=\"\";return\"#REQUIRED\"===t.substring(e,e+8).toUpperCase()?(r=\"#REQUIRED\",e+=8):\"#IMPLIED\"===t.substring(e,e+7).toUpperCase()?(r=\"#IMPLIED\",e+=7):[e,r]=this.readIdentifierVal(t,e,\"ATTLIST\"),{elementName:n,attributeName:i,attributeType:s,defaultValue:r,index:e}}}const P=(t,e)=>{for(;e<t.length&&/\\s/.test(t[e]);)e++;return e};function A(t,e,n){for(let i=0;i<e.length;i++)if(e[i]!==t[n+i+1])return!1;return!0}function S(t){if(r(t))return t;throw new Error(`Invalid entity name ${t}`)}const C=/^[-+]?0x[a-fA-F0-9]+$/,$=/^([\\-\\+])?(0*)([0-9]*(\\.[0-9]*)?)$/,V={hex:!0,leadingZeros:!0,decimalPoint:\".\",eNotation:!0};const D=/^([-+])?(0*)(\\d*(\\.\\d*)?[eE][-\\+]?\\d+)$/;function L(t){return\"function\"==typeof t?t:Array.isArray(t)?e=>{for(const n of t){if(\"string\"==typeof n&&e===n)return!0;if(n instanceof RegExp&&n.test(e))return!0}}:()=>!1}class F{constructor(t){if(this.options=t,this.currentNode=null,this.tagsNodeStack=[],this.docTypeEntities={},this.lastEntities={apos:{regex:/&(apos|#39|#x27);/g,val:\"'\"},gt:{regex:/&(gt|#62|#x3E);/g,val:\">\"},lt:{regex:/&(lt|#60|#x3C);/g,val:\"<\"},quot:{regex:/&(quot|#34|#x22);/g,val:'\"'}},this.ampEntity={regex:/&(amp|#38|#x26);/g,val:\"&\"},this.htmlEntities={space:{regex:/&(nbsp|#160);/g,val:\" \"},cent:{regex:/&(cent|#162);/g,val:\"\"},pound:{regex:/&(pound|#163);/g,val:\"\"},yen:{regex:/&(yen|#165);/g,val:\"\"},euro:{regex:/&(euro|#8364);/g,val:\"\"},copyright:{regex:/&(copy|#169);/g,val:\"\"},reg:{regex:/&(reg|#174);/g,val:\"\"},inr:{regex:/&(inr|#8377);/g,val:\"\"},num_dec:{regex:/&#([0-9]{1,7});/g,val:(t,e)=>K(e,10,\"&#\")},num_hex:{regex:/&#x([0-9a-fA-F]{1,6});/g,val:(t,e)=>K(e,16,\"&#x\")}},this.addExternalEntities=j,this.parseXml=B,this.parseTextData=M,this.resolveNameSpace=_,this.buildAttributesMap=U,this.isItStopNode=X,this.replaceEntitiesValue=Y,this.readStopNodeData=q,this.saveTextToParentTag=G,this.addChild=R,this.ignoreAttributesFn=L(this.options.ignoreAttributes),this.entityExpansionCount=0,this.currentExpandedLength=0,this.options.stopNodes&&this.options.stopNodes.length>0){this.stopNodesExact=new Set,this.stopNodesWildcard=new Set;for(let t=0;t<this.options.stopNodes.length;t++){const e=this.options.stopNodes[t];\"string\"==typeof e&&(e.startsWith(\"*.\")?this.stopNodesWildcard.add(e.substring(2)):this.stopNodesExact.add(e))}}}}function j(t){const e=Object.keys(t);for(let n=0;n<e.length;n++){const i=e[n],s=i.replace(/[.\\-+*:]/g,\"\\\\.\");this.lastEntities[i]={regex:new RegExp(\"&\"+s+\";\",\"g\"),val:t[i]}}}function M(t,e,n,i,s,r,o){if(void 0!==t&&(this.options.trimValues&&!i&&(t=t.trim()),t.length>0)){o||(t=this.replaceEntitiesValue(t,e,n));const i=this.options.tagValueProcessor(e,t,n,s,r);return null==i?t:typeof i!=typeof t||i!==t?i:this.options.trimValues||t.trim()===t?Z(t,this.options.parseTagValue,this.options.numberParseOptions):t}}function _(t){if(this.options.removeNSPrefix){const e=t.split(\":\"),n=\"/\"===t.charAt(0)?\"/\":\"\";if(\"xmlns\"===e[0])return\"\";2===e.length&&(t=n+e[1])}return t}const k=new RegExp(\"([^\\\\s=]+)\\\\s*(=\\\\s*(['\\\"])([\\\\s\\\\S]*?)\\\\3)?\",\"gm\");function U(t,e,n){if(!0!==this.options.ignoreAttributes&&\"string\"==typeof t){const i=s(t,k),r=i.length,o={};for(let t=0;t<r;t++){const s=this.resolveNameSpace(i[t][1]);if(this.ignoreAttributesFn(s,e))continue;let r=i[t][4],a=this.options.attributeNamePrefix+s;if(s.length)if(this.options.transformAttributeName&&(a=this.options.transformAttributeName(a)),\"__proto__\"===a&&(a=\"#__proto__\"),void 0!==r){this.options.trimValues&&(r=r.trim()),r=this.replaceEntitiesValue(r,n,e);const t=this.options.attributeValueProcessor(s,r,e);o[a]=null==t?r:typeof t!=typeof r||t!==r?t:Z(r,this.options.parseAttributeValue,this.options.numberParseOptions)}else this.options.allowBooleanAttributes&&(o[a]=!0)}if(!Object.keys(o).length)return;if(this.options.attributesGroupName){const t={};return t[this.options.attributesGroupName]=o,t}return o}}const B=function(t){t=t.replace(/\\r\\n?/g,\"\\n\");const e=new I(\"!xml\");let n=e,i=\"\",s=\"\";this.entityExpansionCount=0,this.currentExpandedLength=0;const r=new O(this.options.processEntities);for(let o=0;o<t.length;o++)if(\"<\"===t[o])if(\"/\"===t[o+1]){const e=z(t,\">\",o,\"Closing Tag is not closed.\");let r=t.substring(o+2,e).trim();if(this.options.removeNSPrefix){const t=r.indexOf(\":\");-1!==t&&(r=r.substr(t+1))}this.options.transformTagName&&(r=this.options.transformTagName(r)),n&&(i=this.saveTextToParentTag(i,n,s));const a=s.substring(s.lastIndexOf(\".\")+1);if(r&&-1!==this.options.unpairedTags.indexOf(r))throw new Error(`Unpaired tag can not be used as closing tag: </${r}>`);let l=0;a&&-1!==this.options.unpairedTags.indexOf(a)?(l=s.lastIndexOf(\".\",s.lastIndexOf(\".\")-1),this.tagsNodeStack.pop()):l=s.lastIndexOf(\".\"),s=s.substring(0,l),n=this.tagsNodeStack.pop(),i=\"\",o=e}else if(\"?\"===t[o+1]){let e=W(t,o,!1,\"?>\");if(!e)throw new Error(\"Pi Tag is not closed.\");if(i=this.saveTextToParentTag(i,n,s),this.options.ignoreDeclaration&&\"?xml\"===e.tagName||this.options.ignorePiTags);else{const t=new I(e.tagName);t.add(this.options.textNodeName,\"\"),e.tagName!==e.tagExp&&e.attrExpPresent&&(t[\":@\"]=this.buildAttributesMap(e.tagExp,s,e.tagName)),this.addChild(n,t,s,o)}o=e.closeIndex+1}else if(\"!--\"===t.substr(o+1,3)){const e=z(t,\"--\\x3e\",o+4,\"Comment is not closed.\");if(this.options.commentPropName){const r=t.substring(o+4,e-2);i=this.saveTextToParentTag(i,n,s),n.add(this.options.commentPropName,[{[this.options.textNodeName]:r}])}o=e}else if(\"!D\"===t.substr(o+1,2)){const e=r.readDocType(t,o);this.docTypeEntities=e.entities,o=e.i}else if(\"![\"===t.substr(o+1,2)){const e=z(t,\"]]>\",o,\"CDATA is not closed.\")-2,r=t.substring(o+9,e);i=this.saveTextToParentTag(i,n,s);let a=this.parseTextData(r,n.tagname,s,!0,!1,!0,!0);null==a&&(a=\"\"),this.options.cdataPropName?n.add(this.options.cdataPropName,[{[this.options.textNodeName]:r}]):n.add(this.options.textNodeName,a),o=e+2}else{let r=W(t,o,this.options.removeNSPrefix),a=r.tagName;const l=r.rawTagName;let u=r.tagExp,h=r.attrExpPresent,d=r.closeIndex;if(this.options.transformTagName){const t=this.options.transformTagName(a);u===a&&(u=t),a=t}n&&i&&\"!xml\"!==n.tagname&&(i=this.saveTextToParentTag(i,n,s,!1));const p=n;p&&-1!==this.options.unpairedTags.indexOf(p.tagname)&&(n=this.tagsNodeStack.pop(),s=s.substring(0,s.lastIndexOf(\".\"))),a!==e.tagname&&(s+=s?\".\"+a:a);const f=o;if(this.isItStopNode(this.stopNodesExact,this.stopNodesWildcard,s,a)){let e=\"\";if(u.length>0&&u.lastIndexOf(\"/\")===u.length-1)\"/\"===a[a.length-1]?(a=a.substr(0,a.length-1),s=s.substr(0,s.length-1),u=a):u=u.substr(0,u.length-1),o=r.closeIndex;else if(-1!==this.options.unpairedTags.indexOf(a))o=r.closeIndex;else{const n=this.readStopNodeData(t,l,d+1);if(!n)throw new Error(`Unexpected end of ${l}`);o=n.i,e=n.tagContent}const i=new I(a);a!==u&&h&&(i[\":@\"]=this.buildAttributesMap(u,s,a)),e&&(e=this.parseTextData(e,a,s,!0,h,!0,!0)),s=s.substr(0,s.lastIndexOf(\".\")),i.add(this.options.textNodeName,e),this.addChild(n,i,s,f)}else{if(u.length>0&&u.lastIndexOf(\"/\")===u.length-1){if(\"/\"===a[a.length-1]?(a=a.substr(0,a.length-1),s=s.substr(0,s.length-1),u=a):u=u.substr(0,u.length-1),this.options.transformTagName){const t=this.options.transformTagName(a);u===a&&(u=t),a=t}const t=new I(a);a!==u&&h&&(t[\":@\"]=this.buildAttributesMap(u,s,a)),this.addChild(n,t,s,f),s=s.substr(0,s.lastIndexOf(\".\"))}else{const t=new I(a);this.tagsNodeStack.push(n),a!==u&&h&&(t[\":@\"]=this.buildAttributesMap(u,s,a)),this.addChild(n,t,s,f),n=t}i=\"\",o=d}}else i+=t[o];return e.child};function R(t,e,n,i){this.options.captureMetaData||(i=void 0);const s=this.options.updateTag(e.tagname,n,e[\":@\"]);!1===s||(\"string\"==typeof s?(e.tagname=s,t.addChild(e,i)):t.addChild(e,i))}const Y=function(t,e,n){if(-1===t.indexOf(\"&\"))return t;const i=this.options.processEntities;if(!i.enabled)return t;if(i.allowedTags&&!i.allowedTags.includes(e))return t;if(i.tagFilter&&!i.tagFilter(e,n))return t;for(let e in this.docTypeEntities){const n=this.docTypeEntities[e],s=t.match(n.regx);if(s){if(this.entityExpansionCount+=s.length,i.maxTotalExpansions&&this.entityExpansionCount>i.maxTotalExpansions)throw new Error(`Entity expansion limit exceeded: ${this.entityExpansionCount} > ${i.maxTotalExpansions}`);const e=t.length;if(t=t.replace(n.regx,n.val),i.maxExpandedLength&&(this.currentExpandedLength+=t.length-e,this.currentExpandedLength>i.maxExpandedLength))throw new Error(`Total expanded content size exceeded: ${this.currentExpandedLength} > ${i.maxExpandedLength}`)}}if(-1===t.indexOf(\"&\"))return t;for(let e in this.lastEntities){const n=this.lastEntities[e];t=t.replace(n.regex,n.val)}if(-1===t.indexOf(\"&\"))return t;if(this.options.htmlEntities)for(let e in this.htmlEntities){const n=this.htmlEntities[e];t=t.replace(n.regex,n.val)}return t.replace(this.ampEntity.regex,this.ampEntity.val)};function G(t,e,n,i){return t&&(void 0===i&&(i=0===e.child.length),void 0!==(t=this.parseTextData(t,e.tagname,n,!1,!!e[\":@\"]&&0!==Object.keys(e[\":@\"]).length,i))&&\"\"!==t&&e.add(this.options.textNodeName,t),t=\"\"),t}function X(t,e,n,i){return!(!e||!e.has(i))||!(!t||!t.has(n))}function z(t,e,n,i){const s=t.indexOf(e,n);if(-1===s)throw new Error(i);return s+e.length-1}function W(t,e,n,i=\">\"){const s=function(t,e,n=\">\"){let i,s=\"\";for(let r=e;r<t.length;r++){let e=t[r];if(i)e===i&&(i=\"\");else if('\"'===e||\"'\"===e)i=e;else if(e===n[0]){if(!n[1])return{data:s,index:r};if(t[r+1]===n[1])return{data:s,index:r}}else\"\\t\"===e&&(e=\" \");s+=e}}(t,e+1,i);if(!s)return;let r=s.data;const o=s.index,a=r.search(/\\s/);let l=r,u=!0;-1!==a&&(l=r.substring(0,a),r=r.substring(a+1).trimStart());const h=l;if(n){const t=l.indexOf(\":\");-1!==t&&(l=l.substr(t+1),u=l!==s.data.substr(t+1))}return{tagName:l,tagExp:r,closeIndex:o,attrExpPresent:u,rawTagName:h}}function q(t,e,n){const i=n;let s=1;for(;n<t.length;n++)if(\"<\"===t[n])if(\"/\"===t[n+1]){const r=z(t,\">\",n,`${e} is not closed`);if(t.substring(n+2,r).trim()===e&&(s--,0===s))return{tagContent:t.substring(i,n),i:r};n=r}else if(\"?\"===t[n+1])n=z(t,\"?>\",n+1,\"StopNode is not closed.\");else if(\"!--\"===t.substr(n+1,3))n=z(t,\"--\\x3e\",n+3,\"StopNode is not closed.\");else if(\"![\"===t.substr(n+1,2))n=z(t,\"]]>\",n,\"StopNode is not closed.\")-2;else{const i=W(t,n,\">\");i&&((i&&i.tagName)===e&&\"/\"!==i.tagExp[i.tagExp.length-1]&&s++,n=i.closeIndex)}}function Z(t,e,n){if(e&&\"string\"==typeof t){const e=t.trim();return\"true\"===e||\"false\"!==e&&function(t,e={}){if(e=Object.assign({},V,e),!t||\"string\"!=typeof t)return t;let n=t.trim();if(void 0!==e.skipLike&&e.skipLike.test(n))return t;if(\"0\"===t)return 0;if(e.hex&&C.test(n))return function(t){if(parseInt)return parseInt(t,16);if(Number.parseInt)return Number.parseInt(t,16);if(window&&window.parseInt)return window.parseInt(t,16);throw new Error(\"parseInt, Number.parseInt, window.parseInt are not supported\")}(n);if(-1!==n.search(/.+[eE].+/))return function(t,e,n){if(!n.eNotation)return t;const i=e.match(D);if(i){let s=i[1]||\"\";const r=-1===i[3].indexOf(\"e\")?\"E\":\"e\",o=i[2],a=s?t[o.length+1]===r:t[o.length]===r;return o.length>1&&a?t:1!==o.length||!i[3].startsWith(`.${r}`)&&i[3][0]!==r?n.leadingZeros&&!a?(e=(i[1]||\"\")+i[3],Number(e)):t:Number(e)}return t}(t,n,e);{const s=$.exec(n);if(s){const r=s[1]||\"\",o=s[2];let a=(i=s[3])&&-1!==i.indexOf(\".\")?(\".\"===(i=i.replace(/0+$/,\"\"))?i=\"0\":\".\"===i[0]?i=\"0\"+i:\".\"===i[i.length-1]&&(i=i.substring(0,i.length-1)),i):i;const l=r?\".\"===t[o.length+1]:\".\"===t[o.length];if(!e.leadingZeros&&(o.length>1||1===o.length&&!l))return t;{const i=Number(n),s=String(i);if(0===i||-0===i)return i;if(-1!==s.search(/[eE]/))return e.eNotation?i:t;if(-1!==n.indexOf(\".\"))return\"0\"===s||s===a||s===`${r}${a}`?i:t;let l=o?a:n;return o?l===s||r+l===s?i:t:l===s||l===r+s?i:t}}return t}var i}(t,n)}return void 0!==t?t:\"\"}function K(t,e,n){const i=Number.parseInt(t,e);return i>=0&&i<=1114111?String.fromCodePoint(i):n+t+\";\"}const Q=I.getMetaDataSymbol();function J(t,e){return H(t,e)}function H(t,e,n){let i;const s={};for(let r=0;r<t.length;r++){const o=t[r],a=tt(o);let l=\"\";if(l=void 0===n?a:n+\".\"+a,a===e.textNodeName)void 0===i?i=o[a]:i+=\"\"+o[a];else{if(void 0===a)continue;if(o[a]){let t=H(o[a],e,l);const n=nt(t,e);void 0!==o[Q]&&(t[Q]=o[Q]),o[\":@\"]?et(t,o[\":@\"],l,e):1!==Object.keys(t).length||void 0===t[e.textNodeName]||e.alwaysCreateTextNode?0===Object.keys(t).length&&(e.alwaysCreateTextNode?t[e.textNodeName]=\"\":t=\"\"):t=t[e.textNodeName],void 0!==s[a]&&s.hasOwnProperty(a)?(Array.isArray(s[a])||(s[a]=[s[a]]),s[a].push(t)):e.isArray(a,l,n)?s[a]=[t]:s[a]=t}}}return\"string\"==typeof i?i.length>0&&(s[e.textNodeName]=i):void 0!==i&&(s[e.textNodeName]=i),s}function tt(t){const e=Object.keys(t);for(let t=0;t<e.length;t++){const n=e[t];if(\":@\"!==n)return n}}function et(t,e,n,i){if(e){const s=Object.keys(e),r=s.length;for(let o=0;o<r;o++){const r=s[o];i.isArray(r,n+\".\"+r,!0,!0)?t[r]=[e[r]]:t[r]=e[r]}}}function nt(t,e){const{textNodeName:n}=e,i=Object.keys(t).length;return 0===i||!(1!==i||!t[n]&&\"boolean\"!=typeof t[n]&&0!==t[n])}class it{constructor(t){this.externalEntities={},this.options=w(t)}parse(t,e){if(\"string\"!=typeof t&&t.toString)t=t.toString();else if(\"string\"!=typeof t)throw new Error(\"XML data is accepted in String or Bytes[] form.\");if(e){!0===e&&(e={});const n=a(t,e);if(!0!==n)throw Error(`${n.err.msg}:${n.err.line}:${n.err.col}`)}const n=new F(this.options);n.addExternalEntities(this.externalEntities);const i=n.parseXml(t);return this.options.preserveOrder||void 0===i?i:J(i,this.options)}addEntity(t,e){if(-1!==e.indexOf(\"&\"))throw new Error(\"Entity value can't have '&'\");if(-1!==t.indexOf(\"&\")||-1!==t.indexOf(\";\"))throw new Error(\"An entity must be set without '&' and ';'. Eg. use '#xD' for '&#xD;'\");if(\"&\"===e)throw new Error(\"An entity with value '&' is not permitted\");this.externalEntities[t]=e}static getMetaDataSymbol(){return I.getMetaDataSymbol()}}function st(t,e){let n=\"\";return e.format&&e.indentBy.length>0&&(n=\"\\n\"),rt(t,e,\"\",n)}function rt(t,e,n,i){let s=\"\",r=!1;for(let o=0;o<t.length;o++){const a=t[o],l=ot(a);if(void 0===l)continue;let u=\"\";if(u=0===n.length?l:`${n}.${l}`,l===e.textNodeName){let t=a[l];lt(u,e)||(t=e.tagValueProcessor(l,t),t=ut(t,e)),r&&(s+=i),s+=t,r=!1;continue}if(l===e.cdataPropName){r&&(s+=i),s+=`<![CDATA[${a[l][0][e.textNodeName]}]]>`,r=!1;continue}if(l===e.commentPropName){s+=i+`\\x3c!--${a[l][0][e.textNodeName]}--\\x3e`,r=!0;continue}if(\"?\"===l[0]){const t=at(a[\":@\"],e),n=\"?xml\"===l?\"\":i;let o=a[l][0][e.textNodeName];o=0!==o.length?\" \"+o:\"\",s+=n+`<${l}${o}${t}?>`,r=!0;continue}let h=i;\"\"!==h&&(h+=e.indentBy);const d=i+`<${l}${at(a[\":@\"],e)}`,p=rt(a[l],e,u,h);-1!==e.unpairedTags.indexOf(l)?e.suppressUnpairedNode?s+=d+\">\":s+=d+\"/>\":p&&0!==p.length||!e.suppressEmptyNode?p&&p.endsWith(\">\")?s+=d+`>${p}${i}</${l}>`:(s+=d+\">\",p&&\"\"!==i&&(p.includes(\"/>\")||p.includes(\"</\"))?s+=i+e.indentBy+p+i:s+=p,s+=`</${l}>`):s+=d+\"/>\",r=!0}return s}function ot(t){const e=Object.keys(t);for(let n=0;n<e.length;n++){const i=e[n];if(t.hasOwnProperty(i)&&\":@\"!==i)return i}}function at(t,e){let n=\"\";if(t&&!e.ignoreAttributes)for(let i in t){if(!t.hasOwnProperty(i))continue;let s=e.attributeValueProcessor(i,t[i]);s=ut(s,e),!0===s&&e.suppressBooleanAttributes?n+=` ${i.substr(e.attributeNamePrefix.length)}`:n+=` ${i.substr(e.attributeNamePrefix.length)}=\"${s}\"`}return n}function lt(t,e){let n=(t=t.substr(0,t.length-e.textNodeName.length-1)).substr(t.lastIndexOf(\".\")+1);for(let i in e.stopNodes)if(e.stopNodes[i]===t||e.stopNodes[i]===\"*.\"+n)return!0;return!1}function ut(t,e){if(t&&t.length>0&&e.processEntities)for(let n=0;n<e.entities.length;n++){const i=e.entities[n];t=t.replace(i.regex,i.val)}return t}const ht={attributeNamePrefix:\"@_\",attributesGroupName:!1,textNodeName:\"#text\",ignoreAttributes:!0,cdataPropName:!1,format:!1,indentBy:\"  \",suppressEmptyNode:!1,suppressUnpairedNode:!0,suppressBooleanAttributes:!0,tagValueProcessor:function(t,e){return e},attributeValueProcessor:function(t,e){return e},preserveOrder:!1,commentPropName:!1,unpairedTags:[],entities:[{regex:new RegExp(\"&\",\"g\"),val:\"&amp;\"},{regex:new RegExp(\">\",\"g\"),val:\"&gt;\"},{regex:new RegExp(\"<\",\"g\"),val:\"&lt;\"},{regex:new RegExp(\"'\",\"g\"),val:\"&apos;\"},{regex:new RegExp('\"',\"g\"),val:\"&quot;\"}],processEntities:!0,stopNodes:[],oneListGroup:!1};function dt(t){this.options=Object.assign({},ht,t),!0===this.options.ignoreAttributes||this.options.attributesGroupName?this.isAttribute=function(){return!1}:(this.ignoreAttributesFn=L(this.options.ignoreAttributes),this.attrPrefixLen=this.options.attributeNamePrefix.length,this.isAttribute=ct),this.processTextOrObjNode=pt,this.options.format?(this.indentate=ft,this.tagEndChar=\">\\n\",this.newLine=\"\\n\"):(this.indentate=function(){return\"\"},this.tagEndChar=\">\",this.newLine=\"\")}function pt(t,e,n,i){const s=this.j2x(t,n+1,i.concat(e));return void 0!==t[this.options.textNodeName]&&1===Object.keys(t).length?this.buildTextValNode(t[this.options.textNodeName],e,s.attrStr,n):this.buildObjectNode(s.val,e,s.attrStr,n)}function ft(t){return this.options.indentBy.repeat(t)}function ct(t){return!(!t.startsWith(this.options.attributeNamePrefix)||t===this.options.textNodeName)&&t.substr(this.attrPrefixLen)}dt.prototype.build=function(t){return this.options.preserveOrder?st(t,this.options):(Array.isArray(t)&&this.options.arrayNodeName&&this.options.arrayNodeName.length>1&&(t={[this.options.arrayNodeName]:t}),this.j2x(t,0,[]).val)},dt.prototype.j2x=function(t,e,n){let i=\"\",s=\"\";const r=n.join(\".\");for(let o in t)if(Object.prototype.hasOwnProperty.call(t,o))if(void 0===t[o])this.isAttribute(o)&&(s+=\"\");else if(null===t[o])this.isAttribute(o)||o===this.options.cdataPropName?s+=\"\":\"?\"===o[0]?s+=this.indentate(e)+\"<\"+o+\"?\"+this.tagEndChar:s+=this.indentate(e)+\"<\"+o+\"/\"+this.tagEndChar;else if(t[o]instanceof Date)s+=this.buildTextValNode(t[o],o,\"\",e);else if(\"object\"!=typeof t[o]){const n=this.isAttribute(o);if(n&&!this.ignoreAttributesFn(n,r))i+=this.buildAttrPairStr(n,\"\"+t[o]);else if(!n)if(o===this.options.textNodeName){let e=this.options.tagValueProcessor(o,\"\"+t[o]);s+=this.replaceEntitiesValue(e)}else s+=this.buildTextValNode(t[o],o,\"\",e)}else if(Array.isArray(t[o])){const i=t[o].length;let r=\"\",a=\"\";for(let l=0;l<i;l++){const i=t[o][l];if(void 0===i);else if(null===i)\"?\"===o[0]?s+=this.indentate(e)+\"<\"+o+\"?\"+this.tagEndChar:s+=this.indentate(e)+\"<\"+o+\"/\"+this.tagEndChar;else if(\"object\"==typeof i)if(this.options.oneListGroup){const t=this.j2x(i,e+1,n.concat(o));r+=t.val,this.options.attributesGroupName&&i.hasOwnProperty(this.options.attributesGroupName)&&(a+=t.attrStr)}else r+=this.processTextOrObjNode(i,o,e,n);else if(this.options.oneListGroup){let t=this.options.tagValueProcessor(o,i);t=this.replaceEntitiesValue(t),r+=t}else r+=this.buildTextValNode(i,o,\"\",e)}this.options.oneListGroup&&(r=this.buildObjectNode(r,o,a,e)),s+=r}else if(this.options.attributesGroupName&&o===this.options.attributesGroupName){const e=Object.keys(t[o]),n=e.length;for(let s=0;s<n;s++)i+=this.buildAttrPairStr(e[s],\"\"+t[o][e[s]])}else s+=this.processTextOrObjNode(t[o],o,e,n);return{attrStr:i,val:s}},dt.prototype.buildAttrPairStr=function(t,e){return e=this.options.attributeValueProcessor(t,\"\"+e),e=this.replaceEntitiesValue(e),this.options.suppressBooleanAttributes&&\"true\"===e?\" \"+t:\" \"+t+'=\"'+e+'\"'},dt.prototype.buildObjectNode=function(t,e,n,i){if(\"\"===t)return\"?\"===e[0]?this.indentate(i)+\"<\"+e+n+\"?\"+this.tagEndChar:this.indentate(i)+\"<\"+e+n+this.closeTag(e)+this.tagEndChar;{let s=\"</\"+e+this.tagEndChar,r=\"\";return\"?\"===e[0]&&(r=\"?\",s=\"\"),!n&&\"\"!==n||-1!==t.indexOf(\"<\")?!1!==this.options.commentPropName&&e===this.options.commentPropName&&0===r.length?this.indentate(i)+`\\x3c!--${t}--\\x3e`+this.newLine:this.indentate(i)+\"<\"+e+n+r+this.tagEndChar+t+this.indentate(i)+s:this.indentate(i)+\"<\"+e+n+r+\">\"+t+s}},dt.prototype.closeTag=function(t){let e=\"\";return-1!==this.options.unpairedTags.indexOf(t)?this.options.suppressUnpairedNode||(e=\"/\"):e=this.options.suppressEmptyNode?\"/\":`></${t}`,e},dt.prototype.buildTextValNode=function(t,e,n,i){if(!1!==this.options.cdataPropName&&e===this.options.cdataPropName)return this.indentate(i)+`<![CDATA[${t}]]>`+this.newLine;if(!1!==this.options.commentPropName&&e===this.options.commentPropName)return this.indentate(i)+`\\x3c!--${t}--\\x3e`+this.newLine;if(\"?\"===e[0])return this.indentate(i)+\"<\"+e+n+\"?\"+this.tagEndChar;{let s=this.options.tagValueProcessor(e,t);return s=this.replaceEntitiesValue(s),\"\"===s?this.indentate(i)+\"<\"+e+n+this.closeTag(e)+this.tagEndChar:this.indentate(i)+\"<\"+e+n+\">\"+s+\"</\"+e+this.tagEndChar}},dt.prototype.replaceEntitiesValue=function(t){if(t&&t.length>0&&this.options.processEntities)for(let e=0;e<this.options.entities.length;e++){const n=this.options.entities[e];t=t.replace(n.regex,n.val)}return t};const gt={validate:a};module.exports=e})();","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\tid: moduleId,\n\t\tloaded: false,\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Flag the module as loaded\n\tmodule.loaded = true;\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n// expose the modules object (__webpack_modules__)\n__webpack_require__.m = __webpack_modules__;\n\n","var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);\nvar leafPrototypes;\n// create a fake namespace object\n// mode & 1: value is a module id, require it\n// mode & 2: merge all properties of value into the ns\n// mode & 4: return value when already ns object\n// mode & 16: return value when it's Promise-like\n// mode & 8|1: behave like require\n__webpack_require__.t = function(value, mode) {\n\tif(mode & 1) value = this(value);\n\tif(mode & 8) return value;\n\tif(typeof value === 'object' && value) {\n\t\tif((mode & 4) && value.__esModule) return value;\n\t\tif((mode & 16) && typeof value.then === 'function') return value;\n\t}\n\tvar ns = Object.create(null);\n\t__webpack_require__.r(ns);\n\tvar def = {};\n\tleafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];\n\tfor(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {\n\t\tObject.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));\n\t}\n\tdef['default'] = () => (value);\n\t__webpack_require__.d(ns, def);\n\treturn ns;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = (chunkId) => {\n\treturn Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {\n\t\t__webpack_require__.f[key](chunkId, promises);\n\t\treturn promises;\n\t}, []));\n};","// This function allow to reference async chunks\n__webpack_require__.u = (chunkId) => {\n\t// return url for filenames based on template\n\treturn \"\" + chunkId + \".index.js\";\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","__webpack_require__.nmd = (module) => {\n\tmodule.paths = [];\n\tif (!module.children) module.children = [];\n\treturn module;\n};","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = __dirname + \"/\";","// no baseURI\n\n// object to store loaded chunks\n// \"1\" means \"loaded\", otherwise not loaded yet\nvar installedChunks = {\n\t792: 1\n};\n\n// no on chunks loaded\n\nvar installChunk = (chunk) => {\n\tvar moreModules = chunk.modules, chunkIds = chunk.ids, runtime = chunk.runtime;\n\tfor(var moduleId in moreModules) {\n\t\tif(__webpack_require__.o(moreModules, moduleId)) {\n\t\t\t__webpack_require__.m[moduleId] = moreModules[moduleId];\n\t\t}\n\t}\n\tif(runtime) runtime(__webpack_require__);\n\tfor(var i = 0; i < chunkIds.length; i++)\n\t\tinstalledChunks[chunkIds[i]] = 1;\n\n};\n\n// require() chunk loading for javascript\n__webpack_require__.f.require = (chunkId, promises) => {\n\t// \"1\" is the signal for \"already loaded\"\n\tif(!installedChunks[chunkId]) {\n\t\tif(true) { // all chunks have JS\n\t\t\tinstallChunk(require(\"./\" + __webpack_require__.u(chunkId)));\n\t\t} else installedChunks[chunkId] = 1;\n\t}\n};\n\n// no external install chunk\n\n// no HMR\n\n// no HMR manifest","","// startup\n// Load entry module and return exports\n// This entry module is referenced by other modules so it can't be inlined\nvar __webpack_exports__ = __webpack_require__(41730);\n",""],"names":[],"sourceRoot":""}